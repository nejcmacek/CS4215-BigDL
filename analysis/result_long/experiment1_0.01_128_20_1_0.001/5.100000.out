2019-10-23 23:57:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-23 23:57:08 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-23 23:57:08 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-23 23:57:08 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-23 23:57:08 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-23 23:57:08 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-23 23:57:08 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-23 23:57:08 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-23 23:57:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38569.
2019-10-23 23:57:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-23 23:57:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-23 23:57:09 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 23:57:09 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-23 23:57:09 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-c3335449-8d3a-4a56-8b9d-8e55203697ce
2019-10-23 23:57:09 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-23 23:57:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-23 23:57:09 INFO  log:192 - Logging initialized @5354ms
2019-10-23 23:57:09 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-23 23:57:09 INFO  Server:414 - Started @5494ms
2019-10-23 23:57:09 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-10-23 23:57:09 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2019-10-23 23:57:09 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2019-10-23 23:57:09 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2019-10-23 23:57:09 INFO  AbstractConnector:278 - Started ServerConnector@5294896d{HTTP/1.1,[http/1.1]}{0.0.0.0:4044}
2019-10-23 23:57:09 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4044.
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c69ee10{/jobs,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@756f75e6{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29e198a2{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77a1e7f1{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@796f7ca6{/stages,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ceecfa1{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44a61beb{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1471602c{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@607c580a{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b10690e{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@243b8d54{/storage,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bd4e9ff{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39ea5a87{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61ea0cad{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19c36ce9{/environment,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c4f53f{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e11a962{/executors,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f2f5f69{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5d09d441{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f46afd2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c7f53e1{/static,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7dcb2e4a{/,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7be54975{/api,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72140bd{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53ee843d{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 23:57:09 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4044
2019-10-23 23:57:09 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:38569/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571875029984
2019-10-23 23:57:10 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:38569/files/lenet5.py with timestamp 1571875030158
2019-10-23 23:57:10 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-8cc3b53b-9c99-4477-97a1-7fb0ef55b225/userFiles-1c65d84f-b535-4925-b055-4b7b84db6ad3/lenet5.py
2019-10-23 23:57:10 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:38569/files/bigdl-0.8.0-python-api.zip with timestamp 1571875030205
2019-10-23 23:57:10 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-8cc3b53b-9c99-4477-97a1-7fb0ef55b225/userFiles-1c65d84f-b535-4925-b055-4b7b84db6ad3/bigdl-0.8.0-python-api.zip
2019-10-23 23:57:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-23 23:57:10 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 101 ms (0 ms spent in bootstraps)
2019-10-23 23:57:10 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191023235710-0245
2019-10-23 23:57:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191023235710-0245/0 on worker-20191023161312-10.164.0.18-44405 (10.164.0.18:44405) with 1 core(s)
2019-10-23 23:57:10 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38237.
2019-10-23 23:57:10 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:38237
2019-10-23 23:57:10 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-23 23:57:10 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191023235710-0245/0 on hostPort 10.164.0.18:44405 with 1 core(s), 1024.0 MB RAM
2019-10-23 23:57:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191023235710-0245/0 is now RUNNING
2019-10-23 23:57:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 38237, None)
2019-10-23 23:57:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:38237 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 38237, None)
2019-10-23 23:57:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 38237, None)
2019-10-23 23:57:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 38237, None)
2019-10-23 23:57:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ea99ed1{/metrics/json,null,AVAILABLE,@Spark}
2019-10-23 23:57:13 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.18:38282) with ID 0
2019-10-23 23:57:13 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-23 23:57:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.18:35629 with 413.9 MB RAM, BlockManagerId(0, 10.164.0.18, 35629, None)
2019-10-23 23:57:14 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-23 23:57:14 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-23 23:57:14 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 18
2019-10-23 23:57:14 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.01
('Extracting', '~/bd/datasets/mnist/train-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-23 23:57:18 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-23 23:57:35 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-23 23:57:35 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-23 23:57:35 INFO  DistriOptimizer$:154 - Count dataset
2019-10-23 23:57:36 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.49306049s
2019-10-23 23:57:36 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-23 23:57:36 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-23 23:57:36 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.051566792s
2019-10-23 23:57:37 INFO  DistriOptimizer$:408 - [Epoch 1 128/60000][Iteration 1][Wall Clock 0.798636596s] Trained 128 records in 0.798636596 seconds. Throughput is 160.27315 records/second. Loss is 2.2805488. Sequential31006cbd's hyper parameters: Current learning rate is 0.01. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:37 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 2][Wall Clock 1.300521045s] Trained 128 records in 0.501884449 seconds. Throughput is 255.03877 records/second. Loss is 2.3098977. Sequential31006cbd's hyper parameters: Current learning rate is 0.009998000399920017. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:38 INFO  DistriOptimizer$:408 - [Epoch 1 384/60000][Iteration 3][Wall Clock 1.670360127s] Trained 128 records in 0.369839082 seconds. Throughput is 346.09647 records/second. Loss is 2.310544. Sequential31006cbd's hyper parameters: Current learning rate is 0.009996001599360257. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:38 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 4][Wall Clock 2.005065602s] Trained 128 records in 0.334705475 seconds. Throughput is 382.42578 records/second. Loss is 2.303001. Sequential31006cbd's hyper parameters: Current learning rate is 0.009994003597841297. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:38 INFO  DistriOptimizer$:408 - [Epoch 1 640/60000][Iteration 5][Wall Clock 2.358115376s] Trained 128 records in 0.353049774 seconds. Throughput is 362.5551 records/second. Loss is 2.293197. Sequential31006cbd's hyper parameters: Current learning rate is 0.009992006394884094. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:39 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 6][Wall Clock 2.642827055s] Trained 128 records in 0.284711679 seconds. Throughput is 449.5776 records/second. Loss is 2.307154. Sequential31006cbd's hyper parameters: Current learning rate is 0.009990009990009992. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:39 INFO  DistriOptimizer$:408 - [Epoch 1 896/60000][Iteration 7][Wall Clock 2.89291315s] Trained 128 records in 0.250086095 seconds. Throughput is 511.82373 records/second. Loss is 2.2973614. Sequential31006cbd's hyper parameters: Current learning rate is 0.00998801438274071. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:39 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 8][Wall Clock 3.130081572s] Trained 128 records in 0.237168422 seconds. Throughput is 539.70087 records/second. Loss is 2.2749834. Sequential31006cbd's hyper parameters: Current learning rate is 0.009986019572598362. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:39 INFO  DistriOptimizer$:408 - [Epoch 1 1152/60000][Iteration 9][Wall Clock 3.349947298s] Trained 128 records in 0.219865726 seconds. Throughput is 582.1735 records/second. Loss is 2.2865102. Sequential31006cbd's hyper parameters: Current learning rate is 0.009984025559105431. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:40 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 10][Wall Clock 3.5970561s] Trained 128 records in 0.247108802 seconds. Throughput is 517.9905 records/second. Loss is 2.2988386. Sequential31006cbd's hyper parameters: Current learning rate is 0.009982032341784788. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:40 INFO  DistriOptimizer$:408 - [Epoch 1 1408/60000][Iteration 11][Wall Clock 3.816393243s] Trained 128 records in 0.219337143 seconds. Throughput is 583.57654 records/second. Loss is 2.292684. Sequential31006cbd's hyper parameters: Current learning rate is 0.00998003992015968. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:40 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 12][Wall Clock 4.049741945s] Trained 128 records in 0.233348702 seconds. Throughput is 548.53534 records/second. Loss is 2.2900531. Sequential31006cbd's hyper parameters: Current learning rate is 0.009978048293753742. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:40 INFO  DistriOptimizer$:408 - [Epoch 1 1664/60000][Iteration 13][Wall Clock 4.277010987s] Trained 128 records in 0.227269042 seconds. Throughput is 563.20917 records/second. Loss is 2.2859666. Sequential31006cbd's hyper parameters: Current learning rate is 0.009976057462090982. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:40 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 14][Wall Clock 4.469999072s] Trained 128 records in 0.192988085 seconds. Throughput is 663.2534 records/second. Loss is 2.2626553. Sequential31006cbd's hyper parameters: Current learning rate is 0.009974067424695792. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:41 INFO  DistriOptimizer$:408 - [Epoch 1 1920/60000][Iteration 15][Wall Clock 4.65307066s] Trained 128 records in 0.183071588 seconds. Throughput is 699.18005 records/second. Loss is 2.2850587. Sequential31006cbd's hyper parameters: Current learning rate is 0.009972078181092942. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:41 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 16][Wall Clock 4.859732765s] Trained 128 records in 0.206662105 seconds. Throughput is 619.3685 records/second. Loss is 2.290234. Sequential31006cbd's hyper parameters: Current learning rate is 0.009970089730807579. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:41 INFO  DistriOptimizer$:408 - [Epoch 1 2176/60000][Iteration 17][Wall Clock 5.204650621s] Trained 128 records in 0.344917856 seconds. Throughput is 371.10284 records/second. Loss is 2.2890408. Sequential31006cbd's hyper parameters: Current learning rate is 0.00996810207336523. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:41 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 18][Wall Clock 5.425333751s] Trained 128 records in 0.22068313 seconds. Throughput is 580.01715 records/second. Loss is 2.27182. Sequential31006cbd's hyper parameters: Current learning rate is 0.009966115208291807. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:42 INFO  DistriOptimizer$:408 - [Epoch 1 2432/60000][Iteration 19][Wall Clock 5.616772835s] Trained 128 records in 0.191439084 seconds. Throughput is 668.62 records/second. Loss is 2.2778535. Sequential31006cbd's hyper parameters: Current learning rate is 0.00996412913511359. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:42 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 20][Wall Clock 5.815287553s] Trained 128 records in 0.198514718 seconds. Throughput is 644.78845 records/second. Loss is 2.2584743. Sequential31006cbd's hyper parameters: Current learning rate is 0.009962143853357242. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:42 INFO  DistriOptimizer$:408 - [Epoch 1 2688/60000][Iteration 21][Wall Clock 6.044356281s] Trained 128 records in 0.229068728 seconds. Throughput is 558.78424 records/second. Loss is 2.2763078. Sequential31006cbd's hyper parameters: Current learning rate is 0.0099601593625498. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:42 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 22][Wall Clock 6.286584266s] Trained 128 records in 0.242227985 seconds. Throughput is 528.4278 records/second. Loss is 2.2723377. Sequential31006cbd's hyper parameters: Current learning rate is 0.009958175662218682. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:42 INFO  DistriOptimizer$:408 - [Epoch 1 2944/60000][Iteration 23][Wall Clock 6.462954424s] Trained 128 records in 0.176370158 seconds. Throughput is 725.74634 records/second. Loss is 2.2592368. Sequential31006cbd's hyper parameters: Current learning rate is 0.009956192751891677. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:43 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 24][Wall Clock 6.725566024s] Trained 128 records in 0.2626116 seconds. Throughput is 487.41183 records/second. Loss is 2.2707355. Sequential31006cbd's hyper parameters: Current learning rate is 0.009954210631096954. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:43 INFO  DistriOptimizer$:408 - [Epoch 1 3200/60000][Iteration 25][Wall Clock 6.907321048s] Trained 128 records in 0.181755024 seconds. Throughput is 704.2446 records/second. Loss is 2.2805424. Sequential31006cbd's hyper parameters: Current learning rate is 0.009952229299363059. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:43 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 26][Wall Clock 7.075056863s] Trained 128 records in 0.167735815 seconds. Throughput is 763.10474 records/second. Loss is 2.256852. Sequential31006cbd's hyper parameters: Current learning rate is 0.009950248756218907. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:43 INFO  DistriOptimizer$:408 - [Epoch 1 3456/60000][Iteration 27][Wall Clock 7.229605136s] Trained 128 records in 0.154548273 seconds. Throughput is 828.2202 records/second. Loss is 2.2532723. Sequential31006cbd's hyper parameters: Current learning rate is 0.00994826900119379. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:43 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 28][Wall Clock 7.397708554s] Trained 128 records in 0.168103418 seconds. Throughput is 761.43604 records/second. Loss is 2.2549372. Sequential31006cbd's hyper parameters: Current learning rate is 0.009946290033817386. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:44 INFO  DistriOptimizer$:408 - [Epoch 1 3712/60000][Iteration 29][Wall Clock 7.591107933s] Trained 128 records in 0.193399379 seconds. Throughput is 661.84283 records/second. Loss is 2.261256. Sequential31006cbd's hyper parameters: Current learning rate is 0.00994431185361973. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:44 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 30][Wall Clock 7.827825649s] Trained 128 records in 0.236717716 seconds. Throughput is 540.72845 records/second. Loss is 2.254991. Sequential31006cbd's hyper parameters: Current learning rate is 0.00994233446013124. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:44 INFO  DistriOptimizer$:408 - [Epoch 1 3968/60000][Iteration 31][Wall Clock 7.994227685s] Trained 128 records in 0.166402036 seconds. Throughput is 769.2213 records/second. Loss is 2.2556672. Sequential31006cbd's hyper parameters: Current learning rate is 0.009940357852882704. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:44 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 32][Wall Clock 8.143217562s] Trained 128 records in 0.148989877 seconds. Throughput is 859.1188 records/second. Loss is 2.2691603. Sequential31006cbd's hyper parameters: Current learning rate is 0.009938382031405287. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:44 INFO  DistriOptimizer$:408 - [Epoch 1 4224/60000][Iteration 33][Wall Clock 8.324916957s] Trained 128 records in 0.181699395 seconds. Throughput is 704.46027 records/second. Loss is 2.2345355. Sequential31006cbd's hyper parameters: Current learning rate is 0.009936406995230525. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:45 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 34][Wall Clock 8.509350542s] Trained 128 records in 0.184433585 seconds. Throughput is 694.0168 records/second. Loss is 2.2374005. Sequential31006cbd's hyper parameters: Current learning rate is 0.009934432743890324. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:45 INFO  DistriOptimizer$:408 - [Epoch 1 4480/60000][Iteration 35][Wall Clock 8.722311415s] Trained 128 records in 0.212960873 seconds. Throughput is 601.0494 records/second. Loss is 2.2516885. Sequential31006cbd's hyper parameters: Current learning rate is 0.009932459276916966. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:45 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 36][Wall Clock 8.938072992s] Trained 128 records in 0.215761577 seconds. Throughput is 593.24744 records/second. Loss is 2.2460077. Sequential31006cbd's hyper parameters: Current learning rate is 0.0099304865938431. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:45 INFO  DistriOptimizer$:408 - [Epoch 1 4736/60000][Iteration 37][Wall Clock 9.090426172s] Trained 128 records in 0.15235318 seconds. Throughput is 840.15314 records/second. Loss is 2.2604766. Sequential31006cbd's hyper parameters: Current learning rate is 0.009928514694201746. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:45 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 38][Wall Clock 9.272322847s] Trained 128 records in 0.181896675 seconds. Throughput is 703.6962 records/second. Loss is 2.2443805. Sequential31006cbd's hyper parameters: Current learning rate is 0.009926543577526304. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:46 INFO  DistriOptimizer$:408 - [Epoch 1 4992/60000][Iteration 39][Wall Clock 9.472509593s] Trained 128 records in 0.200186746 seconds. Throughput is 639.40295 records/second. Loss is 2.2346234. Sequential31006cbd's hyper parameters: Current learning rate is 0.009924573243350535. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:46 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 40][Wall Clock 9.630193313s] Trained 128 records in 0.15768372 seconds. Throughput is 811.7515 records/second. Loss is 2.2360184. Sequential31006cbd's hyper parameters: Current learning rate is 0.009922603691208573. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:46 INFO  DistriOptimizer$:408 - [Epoch 1 5248/60000][Iteration 41][Wall Clock 9.76120072s] Trained 128 records in 0.131007407 seconds. Throughput is 977.044 records/second. Loss is 2.2364805. Sequential31006cbd's hyper parameters: Current learning rate is 0.00992063492063492. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:46 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 42][Wall Clock 9.982343996s] Trained 128 records in 0.221143276 seconds. Throughput is 578.8103 records/second. Loss is 2.2285645. Sequential31006cbd's hyper parameters: Current learning rate is 0.009918666931164452. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:46 INFO  DistriOptimizer$:408 - [Epoch 1 5504/60000][Iteration 43][Wall Clock 10.136803618s] Trained 128 records in 0.154459622 seconds. Throughput is 828.6955 records/second. Loss is 2.248363. Sequential31006cbd's hyper parameters: Current learning rate is 0.009916699722332408. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:46 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 44][Wall Clock 10.325335963s] Trained 128 records in 0.188532345 seconds. Throughput is 678.9286 records/second. Loss is 2.2557862. Sequential31006cbd's hyper parameters: Current learning rate is 0.009914733293674401. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 5760/60000][Iteration 45][Wall Clock 10.463965913s] Trained 128 records in 0.13862995 seconds. Throughput is 923.3215 records/second. Loss is 2.221915. Sequential31006cbd's hyper parameters: Current learning rate is 0.009912767644726409. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 46][Wall Clock 10.619983958s] Trained 128 records in 0.156018045 seconds. Throughput is 820.4179 records/second. Loss is 2.222825. Sequential31006cbd's hyper parameters: Current learning rate is 0.009910802775024779. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 6016/60000][Iteration 47][Wall Clock 10.781300193s] Trained 128 records in 0.161316235 seconds. Throughput is 793.47253 records/second. Loss is 2.238683. Sequential31006cbd's hyper parameters: Current learning rate is 0.009908838684106223. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 48][Wall Clock 10.96254921s] Trained 128 records in 0.181249017 seconds. Throughput is 706.2107 records/second. Loss is 2.2333522. Sequential31006cbd's hyper parameters: Current learning rate is 0.009906875371507825. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 6272/60000][Iteration 49][Wall Clock 11.109608755s] Trained 128 records in 0.147059545 seconds. Throughput is 870.39575 records/second. Loss is 2.2215228. Sequential31006cbd's hyper parameters: Current learning rate is 0.009904912836767036. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 50][Wall Clock 11.241064609s] Trained 128 records in 0.131455854 seconds. Throughput is 973.71094 records/second. Loss is 2.220802. Sequential31006cbd's hyper parameters: Current learning rate is 0.009902951079421667. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:47 INFO  DistriOptimizer$:408 - [Epoch 1 6528/60000][Iteration 51][Wall Clock 11.409070662s] Trained 128 records in 0.168006053 seconds. Throughput is 761.8773 records/second. Loss is 2.223834. Sequential31006cbd's hyper parameters: Current learning rate is 0.009900990099009901. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:48 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 52][Wall Clock 11.61806731s] Trained 128 records in 0.208996648 seconds. Throughput is 612.45 records/second. Loss is 2.2135286. Sequential31006cbd's hyper parameters: Current learning rate is 0.009899029895070284. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:48 INFO  DistriOptimizer$:408 - [Epoch 1 6784/60000][Iteration 53][Wall Clock 11.759040656s] Trained 128 records in 0.140973346 seconds. Throughput is 907.9731 records/second. Loss is 2.2186332. Sequential31006cbd's hyper parameters: Current learning rate is 0.009897070467141727. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:48 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 54][Wall Clock 11.939693607s] Trained 128 records in 0.180652951 seconds. Throughput is 708.5409 records/second. Loss is 2.2150474. Sequential31006cbd's hyper parameters: Current learning rate is 0.009895111814763508. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:48 INFO  DistriOptimizer$:408 - [Epoch 1 7040/60000][Iteration 55][Wall Clock 12.100392994s] Trained 128 records in 0.160699387 seconds. Throughput is 796.5183 records/second. Loss is 2.2183197. Sequential31006cbd's hyper parameters: Current learning rate is 0.009893153937475268. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:48 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 56][Wall Clock 12.23929392s] Trained 128 records in 0.138900926 seconds. Throughput is 921.52014 records/second. Loss is 2.2044227. Sequential31006cbd's hyper parameters: Current learning rate is 0.009891196834817014. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:49 INFO  DistriOptimizer$:408 - [Epoch 1 7296/60000][Iteration 57][Wall Clock 12.44215104s] Trained 128 records in 0.20285712 seconds. Throughput is 630.98596 records/second. Loss is 2.2094634. Sequential31006cbd's hyper parameters: Current learning rate is 0.009889240506329113. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:49 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 58][Wall Clock 12.626596747s] Trained 128 records in 0.184445707 seconds. Throughput is 693.9711 records/second. Loss is 2.2217479. Sequential31006cbd's hyper parameters: Current learning rate is 0.009887284951552304. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:49 INFO  DistriOptimizer$:408 - [Epoch 1 7552/60000][Iteration 59][Wall Clock 12.819088712s] Trained 128 records in 0.192491965 seconds. Throughput is 664.9628 records/second. Loss is 2.214861. Sequential31006cbd's hyper parameters: Current learning rate is 0.009885330170027679. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:49 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 60][Wall Clock 13.021828223s] Trained 128 records in 0.202739511 seconds. Throughput is 631.35205 records/second. Loss is 2.2015533. Sequential31006cbd's hyper parameters: Current learning rate is 0.0098833761612967. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:49 INFO  DistriOptimizer$:408 - [Epoch 1 7808/60000][Iteration 61][Wall Clock 13.178990038s] Trained 128 records in 0.157161815 seconds. Throughput is 814.4472 records/second. Loss is 2.2003329. Sequential31006cbd's hyper parameters: Current learning rate is 0.009881422924901186. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:49 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 62][Wall Clock 13.339527279s] Trained 128 records in 0.160537241 seconds. Throughput is 797.32275 records/second. Loss is 2.2002661. Sequential31006cbd's hyper parameters: Current learning rate is 0.009879470460383323. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8064/60000][Iteration 63][Wall Clock 13.525972767s] Trained 128 records in 0.186445488 seconds. Throughput is 686.5277 records/second. Loss is 2.1869435. Sequential31006cbd's hyper parameters: Current learning rate is 0.009877518767285659. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 64][Wall Clock 13.68075844s] Trained 128 records in 0.154785673 seconds. Throughput is 826.9499 records/second. Loss is 2.196926. Sequential31006cbd's hyper parameters: Current learning rate is 0.009875567845151097. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8320/60000][Iteration 65][Wall Clock 13.822495465s] Trained 128 records in 0.141737025 seconds. Throughput is 903.0809 records/second. Loss is 2.202366. Sequential31006cbd's hyper parameters: Current learning rate is 0.009873617693522907. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 66][Wall Clock 13.964932754s] Trained 128 records in 0.142437289 seconds. Throughput is 898.64105 records/second. Loss is 2.1974335. Sequential31006cbd's hyper parameters: Current learning rate is 0.00987166831194472. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8576/60000][Iteration 67][Wall Clock 14.118538658s] Trained 128 records in 0.153605904 seconds. Throughput is 833.3013 records/second. Loss is 2.1920397. Sequential31006cbd's hyper parameters: Current learning rate is 0.00986971969996052. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 68][Wall Clock 14.25823816s] Trained 128 records in 0.139699502 seconds. Throughput is 916.2524 records/second. Loss is 2.1906903. Sequential31006cbd's hyper parameters: Current learning rate is 0.009867771857114663. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:50 INFO  DistriOptimizer$:408 - [Epoch 1 8832/60000][Iteration 69][Wall Clock 14.385246813s] Trained 128 records in 0.127008653 seconds. Throughput is 1007.8054 records/second. Loss is 2.171777. Sequential31006cbd's hyper parameters: Current learning rate is 0.009865824782951855. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 70][Wall Clock 14.505831215s] Trained 128 records in 0.120584402 seconds. Throughput is 1061.4972 records/second. Loss is 2.1983135. Sequential31006cbd's hyper parameters: Current learning rate is 0.009863878477017163. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 9088/60000][Iteration 71][Wall Clock 14.655504281s] Trained 128 records in 0.149673066 seconds. Throughput is 855.1973 records/second. Loss is 2.1823285. Sequential31006cbd's hyper parameters: Current learning rate is 0.009861932938856016. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 72][Wall Clock 14.83508663s] Trained 128 records in 0.179582349 seconds. Throughput is 712.76495 records/second. Loss is 2.1780949. Sequential31006cbd's hyper parameters: Current learning rate is 0.009859988168014198. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 9344/60000][Iteration 73][Wall Clock 14.955047087s] Trained 128 records in 0.119960457 seconds. Throughput is 1067.0183 records/second. Loss is 2.1764867. Sequential31006cbd's hyper parameters: Current learning rate is 0.009858044164037856. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 74][Wall Clock 15.097602076s] Trained 128 records in 0.142554989 seconds. Throughput is 897.8992 records/second. Loss is 2.149767. Sequential31006cbd's hyper parameters: Current learning rate is 0.009856100926473488. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 9600/60000][Iteration 75][Wall Clock 15.212949457s] Trained 128 records in 0.115347381 seconds. Throughput is 1109.6914 records/second. Loss is 2.190653. Sequential31006cbd's hyper parameters: Current learning rate is 0.009854158454867956. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:51 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 76][Wall Clock 15.331051113s] Trained 128 records in 0.118101656 seconds. Throughput is 1083.812 records/second. Loss is 2.1783261. Sequential31006cbd's hyper parameters: Current learning rate is 0.009852216748768475. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 9856/60000][Iteration 77][Wall Clock 15.458804045s] Trained 128 records in 0.127752932 seconds. Throughput is 1001.93396 records/second. Loss is 2.1697977. Sequential31006cbd's hyper parameters: Current learning rate is 0.009850275807722615. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 78][Wall Clock 15.62193782s] Trained 128 records in 0.163133775 seconds. Throughput is 784.63214 records/second. Loss is 2.1534522. Sequential31006cbd's hyper parameters: Current learning rate is 0.009848335631278314. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 10112/60000][Iteration 79][Wall Clock 15.762273793s] Trained 128 records in 0.140335973 seconds. Throughput is 912.0968 records/second. Loss is 2.164289. Sequential31006cbd's hyper parameters: Current learning rate is 0.009846396218983852. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 80][Wall Clock 15.906925841s] Trained 128 records in 0.144652048 seconds. Throughput is 884.882 records/second. Loss is 2.1601343. Sequential31006cbd's hyper parameters: Current learning rate is 0.009844457570387872. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 10368/60000][Iteration 81][Wall Clock 16.023831843s] Trained 128 records in 0.116906002 seconds. Throughput is 1094.8967 records/second. Loss is 2.1646235. Sequential31006cbd's hyper parameters: Current learning rate is 0.00984251968503937. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 82][Wall Clock 16.159613702s] Trained 128 records in 0.135781859 seconds. Throughput is 942.68854 records/second. Loss is 2.151288. Sequential31006cbd's hyper parameters: Current learning rate is 0.0098405825624877. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:52 INFO  DistriOptimizer$:408 - [Epoch 1 10624/60000][Iteration 83][Wall Clock 16.31698346s] Trained 128 records in 0.157369758 seconds. Throughput is 813.371 records/second. Loss is 2.186751. Sequential31006cbd's hyper parameters: Current learning rate is 0.009838646202282567. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 84][Wall Clock 16.456906419s] Trained 128 records in 0.139922959 seconds. Throughput is 914.7891 records/second. Loss is 2.1627293. Sequential31006cbd's hyper parameters: Current learning rate is 0.009836710603974032. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 10880/60000][Iteration 85][Wall Clock 16.59353221s] Trained 128 records in 0.136625791 seconds. Throughput is 936.86554 records/second. Loss is 2.1424654. Sequential31006cbd's hyper parameters: Current learning rate is 0.009834775767112511. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 86][Wall Clock 16.725659202s] Trained 128 records in 0.132126992 seconds. Throughput is 968.765 records/second. Loss is 2.1573167. Sequential31006cbd's hyper parameters: Current learning rate is 0.009832841691248772. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 11136/60000][Iteration 87][Wall Clock 16.843345444s] Trained 128 records in 0.117686242 seconds. Throughput is 1087.6377 records/second. Loss is 2.1558666. Sequential31006cbd's hyper parameters: Current learning rate is 0.009830908375933936. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 88][Wall Clock 16.969677102s] Trained 128 records in 0.126331658 seconds. Throughput is 1013.20605 records/second. Loss is 2.1576655. Sequential31006cbd's hyper parameters: Current learning rate is 0.00982897582071948. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 11392/60000][Iteration 89][Wall Clock 17.113151708s] Trained 128 records in 0.143474606 seconds. Throughput is 892.1439 records/second. Loss is 2.1340365. Sequential31006cbd's hyper parameters: Current learning rate is 0.009827044025157232. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 90][Wall Clock 17.238112556s] Trained 128 records in 0.124960848 seconds. Throughput is 1024.3208 records/second. Loss is 2.1325374. Sequential31006cbd's hyper parameters: Current learning rate is 0.009825112988799371. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:53 INFO  DistriOptimizer$:408 - [Epoch 1 11648/60000][Iteration 91][Wall Clock 17.379492192s] Trained 128 records in 0.141379636 seconds. Throughput is 905.3638 records/second. Loss is 2.1338372. Sequential31006cbd's hyper parameters: Current learning rate is 0.009823182711198428. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 92][Wall Clock 17.514478118s] Trained 128 records in 0.134985926 seconds. Throughput is 948.247 records/second. Loss is 2.1241903. Sequential31006cbd's hyper parameters: Current learning rate is 0.009821253191907287. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 11904/60000][Iteration 93][Wall Clock 17.621809525s] Trained 128 records in 0.107331407 seconds. Throughput is 1192.568 records/second. Loss is 2.1063397. Sequential31006cbd's hyper parameters: Current learning rate is 0.009819324430479184. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 94][Wall Clock 17.762543272s] Trained 128 records in 0.140733747 seconds. Throughput is 909.51886 records/second. Loss is 2.1080163. Sequential31006cbd's hyper parameters: Current learning rate is 0.009817396426467702. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 12160/60000][Iteration 95][Wall Clock 17.890597241s] Trained 128 records in 0.128053969 seconds. Throughput is 999.5786 records/second. Loss is 2.1317554. Sequential31006cbd's hyper parameters: Current learning rate is 0.009815469179426778. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 96][Wall Clock 18.012969325s] Trained 128 records in 0.122372084 seconds. Throughput is 1045.9902 records/second. Loss is 2.1286325. Sequential31006cbd's hyper parameters: Current learning rate is 0.009813542688910697. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 12416/60000][Iteration 97][Wall Clock 18.13591249s] Trained 128 records in 0.122943165 seconds. Throughput is 1041.1315 records/second. Loss is 2.1280534. Sequential31006cbd's hyper parameters: Current learning rate is 0.009811616954474096. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:54 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 98][Wall Clock 18.289509246s] Trained 128 records in 0.153596756 seconds. Throughput is 833.3509 records/second. Loss is 2.109727. Sequential31006cbd's hyper parameters: Current learning rate is 0.009809691975671964. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 12672/60000][Iteration 99][Wall Clock 18.419892227s] Trained 128 records in 0.130382981 seconds. Throughput is 981.7232 records/second. Loss is 2.113352. Sequential31006cbd's hyper parameters: Current learning rate is 0.00980776775205963. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 100][Wall Clock 18.539700845s] Trained 128 records in 0.119808618 seconds. Throughput is 1068.3705 records/second. Loss is 2.0952764. Sequential31006cbd's hyper parameters: Current learning rate is 0.009805844283192783. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 12928/60000][Iteration 101][Wall Clock 18.640404242s] Trained 128 records in 0.100703397 seconds. Throughput is 1271.0594 records/second. Loss is 2.1094239. Sequential31006cbd's hyper parameters: Current learning rate is 0.00980392156862745. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 102][Wall Clock 18.748503868s] Trained 128 records in 0.108099626 seconds. Throughput is 1184.0929 records/second. Loss is 2.073554. Sequential31006cbd's hyper parameters: Current learning rate is 0.009801999607920015. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 13184/60000][Iteration 103][Wall Clock 18.864790944s] Trained 128 records in 0.116287076 seconds. Throughput is 1100.7242 records/second. Loss is 2.119484. Sequential31006cbd's hyper parameters: Current learning rate is 0.009800078400627205. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 104][Wall Clock 18.992792719s] Trained 128 records in 0.128001775 seconds. Throughput is 999.9861 records/second. Loss is 2.1146128. Sequential31006cbd's hyper parameters: Current learning rate is 0.009798157946306094. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 13440/60000][Iteration 105][Wall Clock 19.109388539s] Trained 128 records in 0.11659582 seconds. Throughput is 1097.8096 records/second. Loss is 2.077197. Sequential31006cbd's hyper parameters: Current learning rate is 0.009796238244514107. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 106][Wall Clock 19.250796158s] Trained 128 records in 0.141407619 seconds. Throughput is 905.1846 records/second. Loss is 2.106685. Sequential31006cbd's hyper parameters: Current learning rate is 0.009794319294809012. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:55 INFO  DistriOptimizer$:408 - [Epoch 1 13696/60000][Iteration 107][Wall Clock 19.346992478s] Trained 128 records in 0.09619632 seconds. Throughput is 1330.6122 records/second. Loss is 2.0879254. Sequential31006cbd's hyper parameters: Current learning rate is 0.009792401096748922. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 108][Wall Clock 19.46559978s] Trained 128 records in 0.118607302 seconds. Throughput is 1079.1915 records/second. Loss is 2.0844324. Sequential31006cbd's hyper parameters: Current learning rate is 0.009790483649892304. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 13952/60000][Iteration 109][Wall Clock 19.573339073s] Trained 128 records in 0.107739293 seconds. Throughput is 1188.0531 records/second. Loss is 2.086411. Sequential31006cbd's hyper parameters: Current learning rate is 0.009788566953797963. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 110][Wall Clock 19.671765832s] Trained 128 records in 0.098426759 seconds. Throughput is 1300.4594 records/second. Loss is 2.0770664. Sequential31006cbd's hyper parameters: Current learning rate is 0.009786651008025053. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 14208/60000][Iteration 111][Wall Clock 19.809905284s] Trained 128 records in 0.138139452 seconds. Throughput is 926.59985 records/second. Loss is 2.0795858. Sequential31006cbd's hyper parameters: Current learning rate is 0.009784735812133072. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 112][Wall Clock 19.951378466s] Trained 128 records in 0.141473182 seconds. Throughput is 904.7651 records/second. Loss is 2.0591538. Sequential31006cbd's hyper parameters: Current learning rate is 0.009782821365681862. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 14464/60000][Iteration 113][Wall Clock 20.128828947s] Trained 128 records in 0.177450481 seconds. Throughput is 721.328 records/second. Loss is 2.0726092. Sequential31006cbd's hyper parameters: Current learning rate is 0.009780907668231613. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 114][Wall Clock 20.248210361s] Trained 128 records in 0.119381414 seconds. Throughput is 1072.1937 records/second. Loss is 2.0823796. Sequential31006cbd's hyper parameters: Current learning rate is 0.009778994719342852. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:56 INFO  DistriOptimizer$:408 - [Epoch 1 14720/60000][Iteration 115][Wall Clock 20.362990934s] Trained 128 records in 0.114780573 seconds. Throughput is 1115.1713 records/second. Loss is 2.0471847. Sequential31006cbd's hyper parameters: Current learning rate is 0.009777082518576457. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 116][Wall Clock 20.483114101s] Trained 128 records in 0.120123167 seconds. Throughput is 1065.573 records/second. Loss is 2.0475917. Sequential31006cbd's hyper parameters: Current learning rate is 0.009775171065493648. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 14976/60000][Iteration 117][Wall Clock 20.61081022s] Trained 128 records in 0.127696119 seconds. Throughput is 1002.37976 records/second. Loss is 2.0415926. Sequential31006cbd's hyper parameters: Current learning rate is 0.009773260359655981. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 118][Wall Clock 20.75659379s] Trained 128 records in 0.14578357 seconds. Throughput is 878.01385 records/second. Loss is 2.073772. Sequential31006cbd's hyper parameters: Current learning rate is 0.009771350400625366. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 15232/60000][Iteration 119][Wall Clock 20.867395983s] Trained 128 records in 0.110802193 seconds. Throughput is 1155.2118 records/second. Loss is 2.038093. Sequential31006cbd's hyper parameters: Current learning rate is 0.009769441187964047. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 120][Wall Clock 20.989262635s] Trained 128 records in 0.121866652 seconds. Throughput is 1050.3284 records/second. Loss is 2.0260813. Sequential31006cbd's hyper parameters: Current learning rate is 0.009767532721234616. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 15488/60000][Iteration 121][Wall Clock 21.10987237s] Trained 128 records in 0.120609735 seconds. Throughput is 1061.2742 records/second. Loss is 2.0538762. Sequential31006cbd's hyper parameters: Current learning rate is 0.009765625. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:57 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 122][Wall Clock 21.237260634s] Trained 128 records in 0.127388264 seconds. Throughput is 1004.8021 records/second. Loss is 2.024154. Sequential31006cbd's hyper parameters: Current learning rate is 0.009763718023823472. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 15744/60000][Iteration 123][Wall Clock 21.437021662s] Trained 128 records in 0.199761028 seconds. Throughput is 640.7656 records/second. Loss is 2.039318. Sequential31006cbd's hyper parameters: Current learning rate is 0.009761811792268645. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 124][Wall Clock 21.592873231s] Trained 128 records in 0.155851569 seconds. Throughput is 821.29425 records/second. Loss is 2.0184834. Sequential31006cbd's hyper parameters: Current learning rate is 0.009759906304899474. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 16000/60000][Iteration 125][Wall Clock 21.724094701s] Trained 128 records in 0.13122147 seconds. Throughput is 975.45013 records/second. Loss is 2.0133667. Sequential31006cbd's hyper parameters: Current learning rate is 0.00975800156128025. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 126][Wall Clock 21.853498471s] Trained 128 records in 0.12940377 seconds. Throughput is 989.15204 records/second. Loss is 2.027366. Sequential31006cbd's hyper parameters: Current learning rate is 0.009756097560975611. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 16256/60000][Iteration 127][Wall Clock 21.978448237s] Trained 128 records in 0.124949766 seconds. Throughput is 1024.4116 records/second. Loss is 2.0125937. Sequential31006cbd's hyper parameters: Current learning rate is 0.009754194303550527. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 128][Wall Clock 22.128058434s] Trained 128 records in 0.149610197 seconds. Throughput is 855.5567 records/second. Loss is 1.9987601. Sequential31006cbd's hyper parameters: Current learning rate is 0.009752291788570313. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 16512/60000][Iteration 129][Wall Clock 22.240546514s] Trained 128 records in 0.11248808 seconds. Throughput is 1137.8983 records/second. Loss is 2.0130918. Sequential31006cbd's hyper parameters: Current learning rate is 0.009750390015600624. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:58 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 130][Wall Clock 22.353317144s] Trained 128 records in 0.11277063 seconds. Throughput is 1135.0472 records/second. Loss is 2.0142329. Sequential31006cbd's hyper parameters: Current learning rate is 0.009748488984207448. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 16768/60000][Iteration 131][Wall Clock 22.533680573s] Trained 128 records in 0.180363429 seconds. Throughput is 709.6782 records/second. Loss is 2.0337143. Sequential31006cbd's hyper parameters: Current learning rate is 0.009746588693957114. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 132][Wall Clock 22.686610787s] Trained 128 records in 0.152930214 seconds. Throughput is 836.9831 records/second. Loss is 2.0027184. Sequential31006cbd's hyper parameters: Current learning rate is 0.009744689144416294. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 17024/60000][Iteration 133][Wall Clock 22.790502022s] Trained 128 records in 0.103891235 seconds. Throughput is 1232.0577 records/second. Loss is 2.0081072. Sequential31006cbd's hyper parameters: Current learning rate is 0.009742790335151987. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 134][Wall Clock 22.899776236s] Trained 128 records in 0.109274214 seconds. Throughput is 1171.3651 records/second. Loss is 1.9777685. Sequential31006cbd's hyper parameters: Current learning rate is 0.009740892265731542. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 17280/60000][Iteration 135][Wall Clock 23.014785921s] Trained 128 records in 0.115009685 seconds. Throughput is 1112.9497 records/second. Loss is 2.0556133. Sequential31006cbd's hyper parameters: Current learning rate is 0.009738994935722634. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 136][Wall Clock 23.121498016s] Trained 128 records in 0.106712095 seconds. Throughput is 1199.4891 records/second. Loss is 2.024605. Sequential31006cbd's hyper parameters: Current learning rate is 0.009737098344693282. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:57:59 INFO  DistriOptimizer$:408 - [Epoch 1 17536/60000][Iteration 137][Wall Clock 23.274006294s] Trained 128 records in 0.152508278 seconds. Throughput is 839.2987 records/second. Loss is 2.0099406. Sequential31006cbd's hyper parameters: Current learning rate is 0.009735202492211837. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 138][Wall Clock 23.399962815s] Trained 128 records in 0.125956521 seconds. Throughput is 1016.2237 records/second. Loss is 2.012177. Sequential31006cbd's hyper parameters: Current learning rate is 0.009733307377846992. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 17792/60000][Iteration 139][Wall Clock 23.52620507s] Trained 128 records in 0.126242255 seconds. Throughput is 1013.92365 records/second. Loss is 1.9972442. Sequential31006cbd's hyper parameters: Current learning rate is 0.009731413001167769. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 140][Wall Clock 23.641265907s] Trained 128 records in 0.115060837 seconds. Throughput is 1112.455 records/second. Loss is 1.9757481. Sequential31006cbd's hyper parameters: Current learning rate is 0.00972951936174353. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 18048/60000][Iteration 141][Wall Clock 23.762170006s] Trained 128 records in 0.120904099 seconds. Throughput is 1058.6903 records/second. Loss is 1.9895777. Sequential31006cbd's hyper parameters: Current learning rate is 0.009727626459143969. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 142][Wall Clock 23.911312576s] Trained 128 records in 0.14914257 seconds. Throughput is 858.23926 records/second. Loss is 1.9925722. Sequential31006cbd's hyper parameters: Current learning rate is 0.009725734292939117. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 18304/60000][Iteration 143][Wall Clock 24.034718089s] Trained 128 records in 0.123405513 seconds. Throughput is 1037.2308 records/second. Loss is 1.9772675. Sequential31006cbd's hyper parameters: Current learning rate is 0.009723842862699339. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 144][Wall Clock 24.148596945s] Trained 128 records in 0.113878856 seconds. Throughput is 1124.0015 records/second. Loss is 1.9636518. Sequential31006cbd's hyper parameters: Current learning rate is 0.009721952167995334. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 18560/60000][Iteration 145][Wall Clock 24.244492615s] Trained 128 records in 0.09589567 seconds. Throughput is 1334.7839 records/second. Loss is 1.996247. Sequential31006cbd's hyper parameters: Current learning rate is 0.009720062208398135. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:00 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 146][Wall Clock 24.351655136s] Trained 128 records in 0.107162521 seconds. Throughput is 1194.4475 records/second. Loss is 1.9410051. Sequential31006cbd's hyper parameters: Current learning rate is 0.009718172983479108. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 18816/60000][Iteration 147][Wall Clock 24.480998646s] Trained 128 records in 0.12934351 seconds. Throughput is 989.61285 records/second. Loss is 1.987053. Sequential31006cbd's hyper parameters: Current learning rate is 0.009716284492809951. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 148][Wall Clock 24.60243686s] Trained 128 records in 0.121438214 seconds. Throughput is 1054.0339 records/second. Loss is 1.9835119. Sequential31006cbd's hyper parameters: Current learning rate is 0.009714396735962695. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 19072/60000][Iteration 149][Wall Clock 24.711765185s] Trained 128 records in 0.109328325 seconds. Throughput is 1170.7854 records/second. Loss is 1.9538565. Sequential31006cbd's hyper parameters: Current learning rate is 0.009712509712509712. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 150][Wall Clock 24.847857862s] Trained 128 records in 0.136092677 seconds. Throughput is 940.5355 records/second. Loss is 1.9295161. Sequential31006cbd's hyper parameters: Current learning rate is 0.009710623422023694. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 19328/60000][Iteration 151][Wall Clock 24.988228018s] Trained 128 records in 0.140370156 seconds. Throughput is 911.8747 records/second. Loss is 1.9230851. Sequential31006cbd's hyper parameters: Current learning rate is 0.009708737864077669. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 152][Wall Clock 25.109003553s] Trained 128 records in 0.120775535 seconds. Throughput is 1059.8173 records/second. Loss is 1.9246501. Sequential31006cbd's hyper parameters: Current learning rate is 0.009706853038245. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:01 INFO  DistriOptimizer$:408 - [Epoch 1 19584/60000][Iteration 153][Wall Clock 25.222214375s] Trained 128 records in 0.113210822 seconds. Throughput is 1130.634 records/second. Loss is 1.9421006. Sequential31006cbd's hyper parameters: Current learning rate is 0.00970496894409938. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 154][Wall Clock 25.35590533s] Trained 128 records in 0.133690955 seconds. Throughput is 957.432 records/second. Loss is 1.9377655. Sequential31006cbd's hyper parameters: Current learning rate is 0.009703085581214826. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 19840/60000][Iteration 155][Wall Clock 25.479593382s] Trained 128 records in 0.123688052 seconds. Throughput is 1034.8615 records/second. Loss is 1.9598119. Sequential31006cbd's hyper parameters: Current learning rate is 0.009701202949165696. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 156][Wall Clock 25.59001667s] Trained 128 records in 0.110423288 seconds. Throughput is 1159.1758 records/second. Loss is 1.9287963. Sequential31006cbd's hyper parameters: Current learning rate is 0.009699321047526674. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 20096/60000][Iteration 157][Wall Clock 25.697179242s] Trained 128 records in 0.107162572 seconds. Throughput is 1194.4469 records/second. Loss is 1.9065254. Sequential31006cbd's hyper parameters: Current learning rate is 0.00969743987587277. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 158][Wall Clock 25.83196277s] Trained 128 records in 0.134783528 seconds. Throughput is 949.67096 records/second. Loss is 1.9126583. Sequential31006cbd's hyper parameters: Current learning rate is 0.009695559433779328. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 20352/60000][Iteration 159][Wall Clock 25.937366465s] Trained 128 records in 0.105403695 seconds. Throughput is 1214.3787 records/second. Loss is 1.8970054. Sequential31006cbd's hyper parameters: Current learning rate is 0.009693679720822024. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 160][Wall Clock 26.047313004s] Trained 128 records in 0.109946539 seconds. Throughput is 1164.2021 records/second. Loss is 1.9609588. Sequential31006cbd's hyper parameters: Current learning rate is 0.009691800736576855. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:02 INFO  DistriOptimizer$:408 - [Epoch 1 20608/60000][Iteration 161][Wall Clock 26.20985358s] Trained 128 records in 0.162540576 seconds. Throughput is 787.4957 records/second. Loss is 1.9230672. Sequential31006cbd's hyper parameters: Current learning rate is 0.009689922480620155. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 162][Wall Clock 26.351575225s] Trained 128 records in 0.141721645 seconds. Throughput is 903.1789 records/second. Loss is 1.8730857. Sequential31006cbd's hyper parameters: Current learning rate is 0.00968804495252858. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 20864/60000][Iteration 163][Wall Clock 26.47283705s] Trained 128 records in 0.121261825 seconds. Throughput is 1055.5671 records/second. Loss is 1.8982325. Sequential31006cbd's hyper parameters: Current learning rate is 0.009686168151879117. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 164][Wall Clock 26.560554193s] Trained 128 records in 0.087717143 seconds. Throughput is 1459.2358 records/second. Loss is 1.905461. Sequential31006cbd's hyper parameters: Current learning rate is 0.00968429207824908. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 21120/60000][Iteration 165][Wall Clock 26.660829675s] Trained 128 records in 0.100275482 seconds. Throughput is 1276.4835 records/second. Loss is 1.8965415. Sequential31006cbd's hyper parameters: Current learning rate is 0.009682416731216113. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 166][Wall Clock 26.767547777s] Trained 128 records in 0.106718102 seconds. Throughput is 1199.4216 records/second. Loss is 1.8793589. Sequential31006cbd's hyper parameters: Current learning rate is 0.009680542110358181. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 21376/60000][Iteration 167][Wall Clock 26.883979013s] Trained 128 records in 0.116431236 seconds. Throughput is 1099.3613 records/second. Loss is 1.9065375. Sequential31006cbd's hyper parameters: Current learning rate is 0.009678668215253582. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 168][Wall Clock 26.997050644s] Trained 128 records in 0.113071631 seconds. Throughput is 1132.0258 records/second. Loss is 1.9109353. Sequential31006cbd's hyper parameters: Current learning rate is 0.009676795045480935. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 21632/60000][Iteration 169][Wall Clock 27.107290921s] Trained 128 records in 0.110240277 seconds. Throughput is 1161.1001 records/second. Loss is 1.8642219. Sequential31006cbd's hyper parameters: Current learning rate is 0.009674922600619194. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:03 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 170][Wall Clock 27.217226987s] Trained 128 records in 0.109936066 seconds. Throughput is 1164.3131 records/second. Loss is 1.9080505. Sequential31006cbd's hyper parameters: Current learning rate is 0.009673050880247629. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 21888/60000][Iteration 171][Wall Clock 27.359782957s] Trained 128 records in 0.14255597 seconds. Throughput is 897.89294 records/second. Loss is 1.8562452. Sequential31006cbd's hyper parameters: Current learning rate is 0.009671179883945842. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 172][Wall Clock 27.481085394s] Trained 128 records in 0.121302437 seconds. Throughput is 1055.2137 records/second. Loss is 1.8283702. Sequential31006cbd's hyper parameters: Current learning rate is 0.009669309611293754. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22144/60000][Iteration 173][Wall Clock 27.608318392s] Trained 128 records in 0.127232998 seconds. Throughput is 1006.0283 records/second. Loss is 1.8803079. Sequential31006cbd's hyper parameters: Current learning rate is 0.009667440061871617. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 174][Wall Clock 27.739122439s] Trained 128 records in 0.130804047 seconds. Throughput is 978.563 records/second. Loss is 1.8729448. Sequential31006cbd's hyper parameters: Current learning rate is 0.009665571235260004. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22400/60000][Iteration 175][Wall Clock 27.851760988s] Trained 128 records in 0.112638549 seconds. Throughput is 1136.3783 records/second. Loss is 1.8386434. Sequential31006cbd's hyper parameters: Current learning rate is 0.009663703131039815. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 176][Wall Clock 27.964696553s] Trained 128 records in 0.112935565 seconds. Throughput is 1133.3896 records/second. Loss is 1.9193342. Sequential31006cbd's hyper parameters: Current learning rate is 0.009661835748792272. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22656/60000][Iteration 177][Wall Clock 28.071027541s] Trained 128 records in 0.106330988 seconds. Throughput is 1203.7883 records/second. Loss is 1.8147155. Sequential31006cbd's hyper parameters: Current learning rate is 0.00965996908809892. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:04 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 178][Wall Clock 28.197155014s] Trained 128 records in 0.126127473 seconds. Throughput is 1014.8464 records/second. Loss is 1.8320334. Sequential31006cbd's hyper parameters: Current learning rate is 0.009658103148541626. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 22912/60000][Iteration 179][Wall Clock 28.348295339s] Trained 128 records in 0.151140325 seconds. Throughput is 846.8951 records/second. Loss is 1.910373. Sequential31006cbd's hyper parameters: Current learning rate is 0.009656237929702587. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 180][Wall Clock 28.487354725s] Trained 128 records in 0.139059386 seconds. Throughput is 920.4701 records/second. Loss is 1.870817. Sequential31006cbd's hyper parameters: Current learning rate is 0.009654373431164317. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23168/60000][Iteration 181][Wall Clock 28.611554624s] Trained 128 records in 0.124199899 seconds. Throughput is 1030.5967 records/second. Loss is 1.8282323. Sequential31006cbd's hyper parameters: Current learning rate is 0.009652509652509652. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 182][Wall Clock 28.721416447s] Trained 128 records in 0.109861823 seconds. Throughput is 1165.1 records/second. Loss is 1.7983043. Sequential31006cbd's hyper parameters: Current learning rate is 0.009650646593321753. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23424/60000][Iteration 183][Wall Clock 28.840910725s] Trained 128 records in 0.119494278 seconds. Throughput is 1071.1809 records/second. Loss is 1.817197. Sequential31006cbd's hyper parameters: Current learning rate is 0.0096487842531841. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 184][Wall Clock 28.976142162s] Trained 128 records in 0.135231437 seconds. Throughput is 946.5255 records/second. Loss is 1.8337435. Sequential31006cbd's hyper parameters: Current learning rate is 0.009646922631680495. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23680/60000][Iteration 185][Wall Clock 29.092920616s] Trained 128 records in 0.116778454 seconds. Throughput is 1096.0927 records/second. Loss is 1.7512704. Sequential31006cbd's hyper parameters: Current learning rate is 0.009645061728395063. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 186][Wall Clock 29.22253461s] Trained 128 records in 0.129613994 seconds. Throughput is 987.54767 records/second. Loss is 1.8002006. Sequential31006cbd's hyper parameters: Current learning rate is 0.009643201542912247. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:05 INFO  DistriOptimizer$:408 - [Epoch 1 23936/60000][Iteration 187][Wall Clock 29.328589525s] Trained 128 records in 0.106054915 seconds. Throughput is 1206.9219 records/second. Loss is 1.7916898. Sequential31006cbd's hyper parameters: Current learning rate is 0.009641342074816815. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 188][Wall Clock 29.460118998s] Trained 128 records in 0.131529473 seconds. Throughput is 973.16583 records/second. Loss is 1.7683027. Sequential31006cbd's hyper parameters: Current learning rate is 0.009639483323693849. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24192/60000][Iteration 189][Wall Clock 29.567386645s] Trained 128 records in 0.107267647 seconds. Throughput is 1193.2769 records/second. Loss is 1.8013877. Sequential31006cbd's hyper parameters: Current learning rate is 0.009637625289128758. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 190][Wall Clock 29.670188362s] Trained 128 records in 0.102801717 seconds. Throughput is 1245.1154 records/second. Loss is 1.7784325. Sequential31006cbd's hyper parameters: Current learning rate is 0.009635767970707265. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24448/60000][Iteration 191][Wall Clock 29.773628344s] Trained 128 records in 0.103439982 seconds. Throughput is 1237.4326 records/second. Loss is 1.7609935. Sequential31006cbd's hyper parameters: Current learning rate is 0.009633911368015413. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 192][Wall Clock 29.906331763s] Trained 128 records in 0.132703419 seconds. Throughput is 964.5569 records/second. Loss is 1.8118639. Sequential31006cbd's hyper parameters: Current learning rate is 0.009632055480639569. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24704/60000][Iteration 193][Wall Clock 29.996674353s] Trained 128 records in 0.09034259 seconds. Throughput is 1416.829 records/second. Loss is 1.7617793. Sequential31006cbd's hyper parameters: Current learning rate is 0.009630200308166411. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 194][Wall Clock 30.102164394s] Trained 128 records in 0.105490041 seconds. Throughput is 1213.3846 records/second. Loss is 1.7605951. Sequential31006cbd's hyper parameters: Current learning rate is 0.00962834585018294. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:06 INFO  DistriOptimizer$:408 - [Epoch 1 24960/60000][Iteration 195][Wall Clock 30.267792893s] Trained 128 records in 0.165628499 seconds. Throughput is 772.8139 records/second. Loss is 1.7083035. Sequential31006cbd's hyper parameters: Current learning rate is 0.009626492106276474. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 196][Wall Clock 30.400234726s] Trained 128 records in 0.132441833 seconds. Throughput is 966.462 records/second. Loss is 1.795537. Sequential31006cbd's hyper parameters: Current learning rate is 0.00962463907603465. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25216/60000][Iteration 197][Wall Clock 30.504118184s] Trained 128 records in 0.103883458 seconds. Throughput is 1232.1499 records/second. Loss is 1.7967973. Sequential31006cbd's hyper parameters: Current learning rate is 0.009622786759045421. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 198][Wall Clock 30.607467342s] Trained 128 records in 0.103349158 seconds. Throughput is 1238.52 records/second. Loss is 1.7389328. Sequential31006cbd's hyper parameters: Current learning rate is 0.009620935154897056. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25472/60000][Iteration 199][Wall Clock 30.708744009s] Trained 128 records in 0.101276667 seconds. Throughput is 1263.8646 records/second. Loss is 1.7090237. Sequential31006cbd's hyper parameters: Current learning rate is 0.009619084263178144. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 200][Wall Clock 30.816448807s] Trained 128 records in 0.107704798 seconds. Throughput is 1188.4336 records/second. Loss is 1.7414445. Sequential31006cbd's hyper parameters: Current learning rate is 0.009617234083477592. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25728/60000][Iteration 201][Wall Clock 30.929774568s] Trained 128 records in 0.113325761 seconds. Throughput is 1129.4872 records/second. Loss is 1.7415797. Sequential31006cbd's hyper parameters: Current learning rate is 0.009615384615384616. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 202][Wall Clock 31.05923525s] Trained 128 records in 0.129460682 seconds. Throughput is 988.7172 records/second. Loss is 1.7108206. Sequential31006cbd's hyper parameters: Current learning rate is 0.009613535858488752. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 25984/60000][Iteration 203][Wall Clock 31.175602713s] Trained 128 records in 0.116367463 seconds. Throughput is 1099.9639 records/second. Loss is 1.6922789. Sequential31006cbd's hyper parameters: Current learning rate is 0.009611687812379853. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:07 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 204][Wall Clock 31.30372267s] Trained 128 records in 0.128119957 seconds. Throughput is 999.06366 records/second. Loss is 1.7319388. Sequential31006cbd's hyper parameters: Current learning rate is 0.009609840476648089. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 26240/60000][Iteration 205][Wall Clock 31.40836913s] Trained 128 records in 0.10464646 seconds. Throughput is 1223.1661 records/second. Loss is 1.7497575. Sequential31006cbd's hyper parameters: Current learning rate is 0.009607993850883937. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 206][Wall Clock 31.507994523s] Trained 128 records in 0.099625393 seconds. Throughput is 1284.813 records/second. Loss is 1.7017776. Sequential31006cbd's hyper parameters: Current learning rate is 0.009606147934678195. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 26496/60000][Iteration 207][Wall Clock 31.623579433s] Trained 128 records in 0.11558491 seconds. Throughput is 1107.411 records/second. Loss is 1.7544059. Sequential31006cbd's hyper parameters: Current learning rate is 0.009604302727621975. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 208][Wall Clock 31.744085523s] Trained 128 records in 0.12050609 seconds. Throughput is 1062.187 records/second. Loss is 1.6683501. Sequential31006cbd's hyper parameters: Current learning rate is 0.009602458229306702. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 26752/60000][Iteration 209][Wall Clock 31.854915141s] Trained 128 records in 0.110829618 seconds. Throughput is 1154.9259 records/second. Loss is 1.7280402. Sequential31006cbd's hyper parameters: Current learning rate is 0.009600614439324116. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 210][Wall Clock 31.952738121s] Trained 128 records in 0.09782298 seconds. Throughput is 1308.486 records/second. Loss is 1.6917987. Sequential31006cbd's hyper parameters: Current learning rate is 0.00959877135726627. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 27008/60000][Iteration 211][Wall Clock 32.047175742s] Trained 128 records in 0.094437621 seconds. Throughput is 1355.3921 records/second. Loss is 1.6775558. Sequential31006cbd's hyper parameters: Current learning rate is 0.009596928982725527. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 212][Wall Clock 32.16218028s] Trained 128 records in 0.115004538 seconds. Throughput is 1112.9995 records/second. Loss is 1.6448952. Sequential31006cbd's hyper parameters: Current learning rate is 0.009595087315294569. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:08 INFO  DistriOptimizer$:408 - [Epoch 1 27264/60000][Iteration 213][Wall Clock 32.284845197s] Trained 128 records in 0.122664917 seconds. Throughput is 1043.4932 records/second. Loss is 1.690894. Sequential31006cbd's hyper parameters: Current learning rate is 0.009593246354566386. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 214][Wall Clock 32.383002625s] Trained 128 records in 0.098157428 seconds. Throughput is 1304.0276 records/second. Loss is 1.6503322. Sequential31006cbd's hyper parameters: Current learning rate is 0.00959140610013428. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 27520/60000][Iteration 215][Wall Clock 32.471887954s] Trained 128 records in 0.088885329 seconds. Throughput is 1440.0576 records/second. Loss is 1.7840748. Sequential31006cbd's hyper parameters: Current learning rate is 0.009589566551591868. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 216][Wall Clock 32.570296802s] Trained 128 records in 0.098408848 seconds. Throughput is 1300.696 records/second. Loss is 1.6152861. Sequential31006cbd's hyper parameters: Current learning rate is 0.009587727708533078. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 27776/60000][Iteration 217][Wall Clock 32.663113589s] Trained 128 records in 0.092816787 seconds. Throughput is 1379.0609 records/second. Loss is 1.6111943. Sequential31006cbd's hyper parameters: Current learning rate is 0.00958588957055215. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 218][Wall Clock 32.775885275s] Trained 128 records in 0.112771686 seconds. Throughput is 1135.0367 records/second. Loss is 1.7244072. Sequential31006cbd's hyper parameters: Current learning rate is 0.009584052137243625. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 28032/60000][Iteration 219][Wall Clock 32.886256833s] Trained 128 records in 0.110371558 seconds. Throughput is 1159.719 records/second. Loss is 1.6029347. Sequential31006cbd's hyper parameters: Current learning rate is 0.009582215408202376. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 220][Wall Clock 33.024368054s] Trained 128 records in 0.138111221 seconds. Throughput is 926.7893 records/second. Loss is 1.6072463. Sequential31006cbd's hyper parameters: Current learning rate is 0.009580379383023568. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 28288/60000][Iteration 221][Wall Clock 33.138847037s] Trained 128 records in 0.114478983 seconds. Throughput is 1118.1091 records/second. Loss is 1.6045064. Sequential31006cbd's hyper parameters: Current learning rate is 0.009578544061302681. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:09 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 222][Wall Clock 33.270303483s] Trained 128 records in 0.131456446 seconds. Throughput is 973.7065 records/second. Loss is 1.6898752. Sequential31006cbd's hyper parameters: Current learning rate is 0.00957670944263551. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 28544/60000][Iteration 223][Wall Clock 33.410364383s] Trained 128 records in 0.1400609 seconds. Throughput is 913.8882 records/second. Loss is 1.6394671. Sequential31006cbd's hyper parameters: Current learning rate is 0.009574875526618154. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 224][Wall Clock 33.517889572s] Trained 128 records in 0.107525189 seconds. Throughput is 1190.4187 records/second. Loss is 1.6430366. Sequential31006cbd's hyper parameters: Current learning rate is 0.009573042312847023. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 28800/60000][Iteration 225][Wall Clock 33.63457461s] Trained 128 records in 0.116685038 seconds. Throughput is 1096.9701 records/second. Loss is 1.6549941. Sequential31006cbd's hyper parameters: Current learning rate is 0.009571209800918837. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 226][Wall Clock 33.763401026s] Trained 128 records in 0.128826416 seconds. Throughput is 993.5851 records/second. Loss is 1.670514. Sequential31006cbd's hyper parameters: Current learning rate is 0.009569377990430623. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 29056/60000][Iteration 227][Wall Clock 33.861188841s] Trained 128 records in 0.097787815 seconds. Throughput is 1308.9565 records/second. Loss is 1.5569915. Sequential31006cbd's hyper parameters: Current learning rate is 0.009567546880979718. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 228][Wall Clock 33.971110488s] Trained 128 records in 0.109921647 seconds. Throughput is 1164.4658 records/second. Loss is 1.6497375. Sequential31006cbd's hyper parameters: Current learning rate is 0.009565716472163765. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 29312/60000][Iteration 229][Wall Clock 34.061482071s] Trained 128 records in 0.090371583 seconds. Throughput is 1416.3744 records/second. Loss is 1.6199913. Sequential31006cbd's hyper parameters: Current learning rate is 0.009563886763580718. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 230][Wall Clock 34.167993338s] Trained 128 records in 0.106511267 seconds. Throughput is 1201.7509 records/second. Loss is 1.6353624. Sequential31006cbd's hyper parameters: Current learning rate is 0.009562057754828839. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:10 INFO  DistriOptimizer$:408 - [Epoch 1 29568/60000][Iteration 231][Wall Clock 34.268529497s] Trained 128 records in 0.100536159 seconds. Throughput is 1273.1737 records/second. Loss is 1.6370255. Sequential31006cbd's hyper parameters: Current learning rate is 0.009560229445506692. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 232][Wall Clock 34.368989155s] Trained 128 records in 0.100459658 seconds. Throughput is 1274.1433 records/second. Loss is 1.5853921. Sequential31006cbd's hyper parameters: Current learning rate is 0.009558401835213153. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 29824/60000][Iteration 233][Wall Clock 34.495600215s] Trained 128 records in 0.12661106 seconds. Throughput is 1010.97015 records/second. Loss is 1.6563368. Sequential31006cbd's hyper parameters: Current learning rate is 0.0095565749235474. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 234][Wall Clock 34.593428772s] Trained 128 records in 0.097828557 seconds. Throughput is 1308.4114 records/second. Loss is 1.6359408. Sequential31006cbd's hyper parameters: Current learning rate is 0.009554748710108925. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 30080/60000][Iteration 235][Wall Clock 34.704577557s] Trained 128 records in 0.111148785 seconds. Throughput is 1151.6096 records/second. Loss is 1.614449. Sequential31006cbd's hyper parameters: Current learning rate is 0.009552923194497517. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 236][Wall Clock 34.818471588s] Trained 128 records in 0.113894031 seconds. Throughput is 1123.8517 records/second. Loss is 1.6498729. Sequential31006cbd's hyper parameters: Current learning rate is 0.009551098376313277. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 30336/60000][Iteration 237][Wall Clock 34.927652225s] Trained 128 records in 0.109180637 seconds. Throughput is 1172.369 records/second. Loss is 1.5342476. Sequential31006cbd's hyper parameters: Current learning rate is 0.00954927425515661. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 238][Wall Clock 35.015869896s] Trained 128 records in 0.088217671 seconds. Throughput is 1450.9565 records/second. Loss is 1.5684143. Sequential31006cbd's hyper parameters: Current learning rate is 0.009547450830628221. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 30592/60000][Iteration 239][Wall Clock 35.126209189s] Trained 128 records in 0.110339293 seconds. Throughput is 1160.0582 records/second. Loss is 1.5400481. Sequential31006cbd's hyper parameters: Current learning rate is 0.009545628102329133. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:11 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 240][Wall Clock 35.235542072s] Trained 128 records in 0.109332883 seconds. Throughput is 1170.7366 records/second. Loss is 1.5475825. Sequential31006cbd's hyper parameters: Current learning rate is 0.00954380606986066. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 30848/60000][Iteration 241][Wall Clock 35.362473251s] Trained 128 records in 0.126931179 seconds. Throughput is 1008.42053 records/second. Loss is 1.5613133. Sequential31006cbd's hyper parameters: Current learning rate is 0.009541984732824428. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 242][Wall Clock 35.501759089s] Trained 128 records in 0.139285838 seconds. Throughput is 918.9736 records/second. Loss is 1.5460125. Sequential31006cbd's hyper parameters: Current learning rate is 0.009540164090822362. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 31104/60000][Iteration 243][Wall Clock 35.642819325s] Trained 128 records in 0.141060236 seconds. Throughput is 907.41376 records/second. Loss is 1.5041276. Sequential31006cbd's hyper parameters: Current learning rate is 0.009538344143456697. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 244][Wall Clock 35.770111909s] Trained 128 records in 0.127292584 seconds. Throughput is 1005.5574 records/second. Loss is 1.5506638. Sequential31006cbd's hyper parameters: Current learning rate is 0.009536524890329964. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 31360/60000][Iteration 245][Wall Clock 35.898340528s] Trained 128 records in 0.128228619 seconds. Throughput is 998.2171 records/second. Loss is 1.4947042. Sequential31006cbd's hyper parameters: Current learning rate is 0.009534706331045004. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 246][Wall Clock 36.034799338s] Trained 128 records in 0.13645881 seconds. Throughput is 938.01196 records/second. Loss is 1.5489737. Sequential31006cbd's hyper parameters: Current learning rate is 0.009532888465204958. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:12 INFO  DistriOptimizer$:408 - [Epoch 1 31616/60000][Iteration 247][Wall Clock 36.178071283s] Trained 128 records in 0.143271945 seconds. Throughput is 893.40594 records/second. Loss is 1.6040642. Sequential31006cbd's hyper parameters: Current learning rate is 0.009531071292413268. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 248][Wall Clock 36.338831025s] Trained 128 records in 0.160759742 seconds. Throughput is 796.21924 records/second. Loss is 1.5566028. Sequential31006cbd's hyper parameters: Current learning rate is 0.009529254812273681. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 31872/60000][Iteration 249][Wall Clock 36.468609477s] Trained 128 records in 0.129778452 seconds. Throughput is 986.2963 records/second. Loss is 1.6338168. Sequential31006cbd's hyper parameters: Current learning rate is 0.009527439024390244. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 250][Wall Clock 36.562693338s] Trained 128 records in 0.094083861 seconds. Throughput is 1360.4884 records/second. Loss is 1.5115908. Sequential31006cbd's hyper parameters: Current learning rate is 0.009525623928367307. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32128/60000][Iteration 251][Wall Clock 36.669027845s] Trained 128 records in 0.106334507 seconds. Throughput is 1203.7484 records/second. Loss is 1.5031971. Sequential31006cbd's hyper parameters: Current learning rate is 0.009523809523809523. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 252][Wall Clock 36.792104423s] Trained 128 records in 0.123076578 seconds. Throughput is 1040.0029 records/second. Loss is 1.5497892. Sequential31006cbd's hyper parameters: Current learning rate is 0.009521995810321843. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32384/60000][Iteration 253][Wall Clock 36.886617308s] Trained 128 records in 0.094512885 seconds. Throughput is 1354.3126 records/second. Loss is 1.5315024. Sequential31006cbd's hyper parameters: Current learning rate is 0.00952018278750952. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 254][Wall Clock 36.986488084s] Trained 128 records in 0.099870776 seconds. Throughput is 1281.6561 records/second. Loss is 1.457118. Sequential31006cbd's hyper parameters: Current learning rate is 0.009518370454978109. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32640/60000][Iteration 255][Wall Clock 37.095419203s] Trained 128 records in 0.108931119 seconds. Throughput is 1175.0546 records/second. Loss is 1.4657565. Sequential31006cbd's hyper parameters: Current learning rate is 0.00951655881233346. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:13 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 256][Wall Clock 37.222727107s] Trained 128 records in 0.127307904 seconds. Throughput is 1005.4364 records/second. Loss is 1.5378413. Sequential31006cbd's hyper parameters: Current learning rate is 0.009514747859181733. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 32896/60000][Iteration 257][Wall Clock 37.344924209s] Trained 128 records in 0.122197102 seconds. Throughput is 1047.488 records/second. Loss is 1.4994221. Sequential31006cbd's hyper parameters: Current learning rate is 0.009512937595129377. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 258][Wall Clock 37.45985277s] Trained 128 records in 0.114928561 seconds. Throughput is 1113.7354 records/second. Loss is 1.5519522. Sequential31006cbd's hyper parameters: Current learning rate is 0.009511128019783146. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33152/60000][Iteration 259][Wall Clock 37.564282532s] Trained 128 records in 0.104429762 seconds. Throughput is 1225.7042 records/second. Loss is 1.501907. Sequential31006cbd's hyper parameters: Current learning rate is 0.009509319132750094. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 260][Wall Clock 37.664680255s] Trained 128 records in 0.100397723 seconds. Throughput is 1274.9293 records/second. Loss is 1.446734. Sequential31006cbd's hyper parameters: Current learning rate is 0.009507510933637574. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33408/60000][Iteration 261][Wall Clock 37.790248043s] Trained 128 records in 0.125567788 seconds. Throughput is 1019.3697 records/second. Loss is 1.4853786. Sequential31006cbd's hyper parameters: Current learning rate is 0.009505703422053232. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 262][Wall Clock 37.896183622s] Trained 128 records in 0.105935579 seconds. Throughput is 1208.2815 records/second. Loss is 1.478078. Sequential31006cbd's hyper parameters: Current learning rate is 0.009503896597605019. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33664/60000][Iteration 263][Wall Clock 37.999314949s] Trained 128 records in 0.103131327 seconds. Throughput is 1241.136 records/second. Loss is 1.5270114. Sequential31006cbd's hyper parameters: Current learning rate is 0.00950209045990118. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 264][Wall Clock 38.121659482s] Trained 128 records in 0.122344533 seconds. Throughput is 1046.2257 records/second. Loss is 1.4302435. Sequential31006cbd's hyper parameters: Current learning rate is 0.009500285008550257. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:14 INFO  DistriOptimizer$:408 - [Epoch 1 33920/60000][Iteration 265][Wall Clock 38.267585918s] Trained 128 records in 0.145926436 seconds. Throughput is 877.1543 records/second. Loss is 1.4443274. Sequential31006cbd's hyper parameters: Current learning rate is 0.009498480243161096. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 266][Wall Clock 38.373215334s] Trained 128 records in 0.105629416 seconds. Throughput is 1211.7837 records/second. Loss is 1.4513882. Sequential31006cbd's hyper parameters: Current learning rate is 0.009496676163342831. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34176/60000][Iteration 267][Wall Clock 38.469229756s] Trained 128 records in 0.096014422 seconds. Throughput is 1333.133 records/second. Loss is 1.4672679. Sequential31006cbd's hyper parameters: Current learning rate is 0.0094948727687049. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 268][Wall Clock 38.584403623s] Trained 128 records in 0.115173867 seconds. Throughput is 1111.3632 records/second. Loss is 1.4687167. Sequential31006cbd's hyper parameters: Current learning rate is 0.009493070058857035. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34432/60000][Iteration 269][Wall Clock 38.739734411s] Trained 128 records in 0.155330788 seconds. Throughput is 824.0478 records/second. Loss is 1.4478486. Sequential31006cbd's hyper parameters: Current learning rate is 0.009491268033409262. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 270][Wall Clock 38.878654529s] Trained 128 records in 0.138920118 seconds. Throughput is 921.3929 records/second. Loss is 1.4485312. Sequential31006cbd's hyper parameters: Current learning rate is 0.00948946669197191. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34688/60000][Iteration 271][Wall Clock 38.984675771s] Trained 128 records in 0.106021242 seconds. Throughput is 1207.3053 records/second. Loss is 1.4143025. Sequential31006cbd's hyper parameters: Current learning rate is 0.009487666034155597. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 272][Wall Clock 39.100964598s] Trained 128 records in 0.116288827 seconds. Throughput is 1100.7076 records/second. Loss is 1.4354994. Sequential31006cbd's hyper parameters: Current learning rate is 0.00948586605957124. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:15 INFO  DistriOptimizer$:408 - [Epoch 1 34944/60000][Iteration 273][Wall Clock 39.192087539s] Trained 128 records in 0.091122941 seconds. Throughput is 1404.6957 records/second. Loss is 1.3985093. Sequential31006cbd's hyper parameters: Current learning rate is 0.009484066767830045. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 274][Wall Clock 39.296832397s] Trained 128 records in 0.104744858 seconds. Throughput is 1222.017 records/second. Loss is 1.4801372. Sequential31006cbd's hyper parameters: Current learning rate is 0.009482268158543524. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35200/60000][Iteration 275][Wall Clock 39.394307738s] Trained 128 records in 0.097475341 seconds. Throughput is 1313.1526 records/second. Loss is 1.3813413. Sequential31006cbd's hyper parameters: Current learning rate is 0.009480470231323474. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 276][Wall Clock 39.494660772s] Trained 128 records in 0.100353034 seconds. Throughput is 1275.4971 records/second. Loss is 1.4623399. Sequential31006cbd's hyper parameters: Current learning rate is 0.009478672985781991. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35456/60000][Iteration 277][Wall Clock 39.616669867s] Trained 128 records in 0.122009095 seconds. Throughput is 1049.102 records/second. Loss is 1.465184. Sequential31006cbd's hyper parameters: Current learning rate is 0.009476876421531465. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 278][Wall Clock 39.703213632s] Trained 128 records in 0.086543765 seconds. Throughput is 1479.0204 records/second. Loss is 1.3597369. Sequential31006cbd's hyper parameters: Current learning rate is 0.009475080538184574. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35712/60000][Iteration 279][Wall Clock 39.804030368s] Trained 128 records in 0.100816736 seconds. Throughput is 1269.6305 records/second. Loss is 1.413902. Sequential31006cbd's hyper parameters: Current learning rate is 0.0094732853353543. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 280][Wall Clock 39.902968771s] Trained 128 records in 0.098938403 seconds. Throughput is 1293.7343 records/second. Loss is 1.4204574. Sequential31006cbd's hyper parameters: Current learning rate is 0.009471490812653912. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 35968/60000][Iteration 281][Wall Clock 40.03211368s] Trained 128 records in 0.129144909 seconds. Throughput is 991.1347 records/second. Loss is 1.3776425. Sequential31006cbd's hyper parameters: Current learning rate is 0.00946969696969697. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 282][Wall Clock 40.171164861s] Trained 128 records in 0.139051181 seconds. Throughput is 920.52435 records/second. Loss is 1.4483888. Sequential31006cbd's hyper parameters: Current learning rate is 0.00946790380609733. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:16 INFO  DistriOptimizer$:408 - [Epoch 1 36224/60000][Iteration 283][Wall Clock 40.274535105s] Trained 128 records in 0.103370244 seconds. Throughput is 1238.2673 records/second. Loss is 1.442856. Sequential31006cbd's hyper parameters: Current learning rate is 0.00946611132146914. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 284][Wall Clock 40.378820638s] Trained 128 records in 0.104285533 seconds. Throughput is 1227.3994 records/second. Loss is 1.3751271. Sequential31006cbd's hyper parameters: Current learning rate is 0.00946431951542684. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 36480/60000][Iteration 285][Wall Clock 40.501487731s] Trained 128 records in 0.122667093 seconds. Throughput is 1043.4746 records/second. Loss is 1.3730884. Sequential31006cbd's hyper parameters: Current learning rate is 0.009462528387585163. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 286][Wall Clock 40.601434443s] Trained 128 records in 0.099946712 seconds. Throughput is 1280.6824 records/second. Loss is 1.5103664. Sequential31006cbd's hyper parameters: Current learning rate is 0.00946073793755913. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 36736/60000][Iteration 287][Wall Clock 40.70669122s] Trained 128 records in 0.105256777 seconds. Throughput is 1216.0737 records/second. Loss is 1.3972722. Sequential31006cbd's hyper parameters: Current learning rate is 0.009458948164964056. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 288][Wall Clock 40.805717746s] Trained 128 records in 0.099026526 seconds. Throughput is 1292.583 records/second. Loss is 1.3120658. Sequential31006cbd's hyper parameters: Current learning rate is 0.00945715906941555. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 36992/60000][Iteration 289][Wall Clock 40.90677664s] Trained 128 records in 0.101058894 seconds. Throughput is 1266.5881 records/second. Loss is 1.4344941. Sequential31006cbd's hyper parameters: Current learning rate is 0.0094553706505295. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 290][Wall Clock 41.043165793s] Trained 128 records in 0.136389153 seconds. Throughput is 938.4911 records/second. Loss is 1.3508987. Sequential31006cbd's hyper parameters: Current learning rate is 0.009453582907922102. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:17 INFO  DistriOptimizer$:408 - [Epoch 1 37248/60000][Iteration 291][Wall Clock 41.173352715s] Trained 128 records in 0.130186922 seconds. Throughput is 983.2017 records/second. Loss is 1.3587211. Sequential31006cbd's hyper parameters: Current learning rate is 0.00945179584120983. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 292][Wall Clock 41.309243532s] Trained 128 records in 0.135890817 seconds. Throughput is 941.9327 records/second. Loss is 1.3912117. Sequential31006cbd's hyper parameters: Current learning rate is 0.00945000945000945. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 37504/60000][Iteration 293][Wall Clock 41.442649105s] Trained 128 records in 0.133405573 seconds. Throughput is 959.4802 records/second. Loss is 1.4064307. Sequential31006cbd's hyper parameters: Current learning rate is 0.00944822373393802. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 294][Wall Clock 41.559630468s] Trained 128 records in 0.116981363 seconds. Throughput is 1094.1914 records/second. Loss is 1.3035403. Sequential31006cbd's hyper parameters: Current learning rate is 0.009446438692612885. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 37760/60000][Iteration 295][Wall Clock 41.684897273s] Trained 128 records in 0.125266805 seconds. Throughput is 1021.819 records/second. Loss is 1.3705846. Sequential31006cbd's hyper parameters: Current learning rate is 0.009444654325651681. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 296][Wall Clock 41.839842838s] Trained 128 records in 0.154945565 seconds. Throughput is 826.09656 records/second. Loss is 1.3443531. Sequential31006cbd's hyper parameters: Current learning rate is 0.009442870632672334. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 38016/60000][Iteration 297][Wall Clock 41.948266548s] Trained 128 records in 0.10842371 seconds. Throughput is 1180.5536 records/second. Loss is 1.3793548. Sequential31006cbd's hyper parameters: Current learning rate is 0.009441087613293053. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 298][Wall Clock 42.052812635s] Trained 128 records in 0.104546087 seconds. Throughput is 1224.3405 records/second. Loss is 1.3690224. Sequential31006cbd's hyper parameters: Current learning rate is 0.00943930526713234. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 38272/60000][Iteration 299][Wall Clock 42.155608529s] Trained 128 records in 0.102795894 seconds. Throughput is 1245.1859 records/second. Loss is 1.3756523. Sequential31006cbd's hyper parameters: Current learning rate is 0.009437523593808984. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:18 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 300][Wall Clock 42.262468391s] Trained 128 records in 0.106859862 seconds. Throughput is 1197.8304 records/second. Loss is 1.4422221. Sequential31006cbd's hyper parameters: Current learning rate is 0.009435742592942064. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 38528/60000][Iteration 301][Wall Clock 42.370454928s] Trained 128 records in 0.107986537 seconds. Throughput is 1185.3329 records/second. Loss is 1.2159796. Sequential31006cbd's hyper parameters: Current learning rate is 0.009433962264150943. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 302][Wall Clock 42.495787279s] Trained 128 records in 0.125332351 seconds. Throughput is 1021.28455 records/second. Loss is 1.3315753. Sequential31006cbd's hyper parameters: Current learning rate is 0.009432182607055273. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 38784/60000][Iteration 303][Wall Clock 42.589452667s] Trained 128 records in 0.093665388 seconds. Throughput is 1366.5667 records/second. Loss is 1.290507. Sequential31006cbd's hyper parameters: Current learning rate is 0.00943040362127499. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 304][Wall Clock 42.678847064s] Trained 128 records in 0.089394397 seconds. Throughput is 1431.857 records/second. Loss is 1.3394785. Sequential31006cbd's hyper parameters: Current learning rate is 0.009428625306430323. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 39040/60000][Iteration 305][Wall Clock 42.764753013s] Trained 128 records in 0.085905949 seconds. Throughput is 1490.0016 records/second. Loss is 1.3090793. Sequential31006cbd's hyper parameters: Current learning rate is 0.009426847662141781. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 306][Wall Clock 42.865896971s] Trained 128 records in 0.101143958 seconds. Throughput is 1265.523 records/second. Loss is 1.3971044. Sequential31006cbd's hyper parameters: Current learning rate is 0.009425070688030161. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 39296/60000][Iteration 307][Wall Clock 42.992216333s] Trained 128 records in 0.126319362 seconds. Throughput is 1013.3047 records/second. Loss is 1.3455416. Sequential31006cbd's hyper parameters: Current learning rate is 0.009423294383716549. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 308][Wall Clock 43.084313066s] Trained 128 records in 0.092096733 seconds. Throughput is 1389.843 records/second. Loss is 1.3561647. Sequential31006cbd's hyper parameters: Current learning rate is 0.009421518748822312. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:19 INFO  DistriOptimizer$:408 - [Epoch 1 39552/60000][Iteration 309][Wall Clock 43.218279463s] Trained 128 records in 0.133966397 seconds. Throughput is 955.46344 records/second. Loss is 1.3629956. Sequential31006cbd's hyper parameters: Current learning rate is 0.009419743782969102. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 310][Wall Clock 43.310778232s] Trained 128 records in 0.092498769 seconds. Throughput is 1383.8021 records/second. Loss is 1.4200797. Sequential31006cbd's hyper parameters: Current learning rate is 0.009417969485778865. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 39808/60000][Iteration 311][Wall Clock 43.411486408s] Trained 128 records in 0.100708176 seconds. Throughput is 1270.999 records/second. Loss is 1.3138012. Sequential31006cbd's hyper parameters: Current learning rate is 0.009416195856873822. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 312][Wall Clock 43.516222974s] Trained 128 records in 0.104736566 seconds. Throughput is 1222.1138 records/second. Loss is 1.3218305. Sequential31006cbd's hyper parameters: Current learning rate is 0.009414422895876483. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 40064/60000][Iteration 313][Wall Clock 43.609696188s] Trained 128 records in 0.093473214 seconds. Throughput is 1369.3763 records/second. Loss is 1.2272618. Sequential31006cbd's hyper parameters: Current learning rate is 0.00941265060240964. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 314][Wall Clock 43.715404676s] Trained 128 records in 0.105708488 seconds. Throughput is 1210.8772 records/second. Loss is 1.2630733. Sequential31006cbd's hyper parameters: Current learning rate is 0.009410878976096368. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 40320/60000][Iteration 315][Wall Clock 43.847921248s] Trained 128 records in 0.132516572 seconds. Throughput is 965.9169 records/second. Loss is 1.3041033. Sequential31006cbd's hyper parameters: Current learning rate is 0.00940910801656003. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 316][Wall Clock 44.017646629s] Trained 128 records in 0.169725381 seconds. Throughput is 754.1594 records/second. Loss is 1.3137811. Sequential31006cbd's hyper parameters: Current learning rate is 0.009407337723424272. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 40576/60000][Iteration 317][Wall Clock 44.145003455s] Trained 128 records in 0.127356826 seconds. Throughput is 1005.0502 records/second. Loss is 1.2886127. Sequential31006cbd's hyper parameters: Current learning rate is 0.009405568096313018. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:20 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 318][Wall Clock 44.245664683s] Trained 128 records in 0.100661228 seconds. Throughput is 1271.5919 records/second. Loss is 1.2932078. Sequential31006cbd's hyper parameters: Current learning rate is 0.00940379913485048. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 40832/60000][Iteration 319][Wall Clock 44.337613701s] Trained 128 records in 0.091949018 seconds. Throughput is 1392.0758 records/second. Loss is 1.2978935. Sequential31006cbd's hyper parameters: Current learning rate is 0.00940203083866115. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 320][Wall Clock 44.428577267s] Trained 128 records in 0.090963566 seconds. Throughput is 1407.1569 records/second. Loss is 1.2935373. Sequential31006cbd's hyper parameters: Current learning rate is 0.009400263207369806. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41088/60000][Iteration 321][Wall Clock 44.531698748s] Trained 128 records in 0.103121481 seconds. Throughput is 1241.2545 records/second. Loss is 1.2175618. Sequential31006cbd's hyper parameters: Current learning rate is 0.009398496240601503. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 322][Wall Clock 44.627686292s] Trained 128 records in 0.095987544 seconds. Throughput is 1333.5063 records/second. Loss is 1.2445453. Sequential31006cbd's hyper parameters: Current learning rate is 0.009396729937981583. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41344/60000][Iteration 323][Wall Clock 44.719331934s] Trained 128 records in 0.091645642 seconds. Throughput is 1396.684 records/second. Loss is 1.3916278. Sequential31006cbd's hyper parameters: Current learning rate is 0.009394964299135663. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 324][Wall Clock 44.812786672s] Trained 128 records in 0.093454738 seconds. Throughput is 1369.647 records/second. Loss is 1.2945976. Sequential31006cbd's hyper parameters: Current learning rate is 0.00939319932368965. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41600/60000][Iteration 325][Wall Clock 44.912513191s] Trained 128 records in 0.099726519 seconds. Throughput is 1283.5101 records/second. Loss is 1.2553269. Sequential31006cbd's hyper parameters: Current learning rate is 0.009391435011269723. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 326][Wall Clock 45.011190994s] Trained 128 records in 0.098677803 seconds. Throughput is 1297.1509 records/second. Loss is 1.2107462. Sequential31006cbd's hyper parameters: Current learning rate is 0.009389671361502348. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41856/60000][Iteration 327][Wall Clock 45.113997511s] Trained 128 records in 0.102806517 seconds. Throughput is 1245.0573 records/second. Loss is 1.2908932. Sequential31006cbd's hyper parameters: Current learning rate is 0.009387908374014271. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:21 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 328][Wall Clock 45.216940258s] Trained 128 records in 0.102942747 seconds. Throughput is 1243.4095 records/second. Loss is 1.2535549. Sequential31006cbd's hyper parameters: Current learning rate is 0.009386146048432515. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42112/60000][Iteration 329][Wall Clock 45.333493176s] Trained 128 records in 0.116552918 seconds. Throughput is 1098.2136 records/second. Loss is 1.2105861. Sequential31006cbd's hyper parameters: Current learning rate is 0.009384384384384385. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 330][Wall Clock 45.427206037s] Trained 128 records in 0.093712861 seconds. Throughput is 1365.8745 records/second. Loss is 1.2408417. Sequential31006cbd's hyper parameters: Current learning rate is 0.009382623381497467. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42368/60000][Iteration 331][Wall Clock 45.524856973s] Trained 128 records in 0.097650936 seconds. Throughput is 1310.7913 records/second. Loss is 1.3096976. Sequential31006cbd's hyper parameters: Current learning rate is 0.009380863039399624. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 332][Wall Clock 45.632593323s] Trained 128 records in 0.10773635 seconds. Throughput is 1188.0856 records/second. Loss is 1.2505178. Sequential31006cbd's hyper parameters: Current learning rate is 0.009379103357719002. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42624/60000][Iteration 333][Wall Clock 45.722040833s] Trained 128 records in 0.08944751 seconds. Throughput is 1431.0068 records/second. Loss is 1.207152. Sequential31006cbd's hyper parameters: Current learning rate is 0.009377344336084021. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 334][Wall Clock 45.80251095s] Trained 128 records in 0.080470117 seconds. Throughput is 1590.6526 records/second. Loss is 1.2175932. Sequential31006cbd's hyper parameters: Current learning rate is 0.009375585974123383. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 42880/60000][Iteration 335][Wall Clock 45.917358781s] Trained 128 records in 0.114847831 seconds. Throughput is 1114.5182 records/second. Loss is 1.1936729. Sequential31006cbd's hyper parameters: Current learning rate is 0.009373828271466067. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 336][Wall Clock 46.017350795s] Trained 128 records in 0.099992014 seconds. Throughput is 1280.1022 records/second. Loss is 1.2582458. Sequential31006cbd's hyper parameters: Current learning rate is 0.009372071227741332. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 43136/60000][Iteration 337][Wall Clock 46.120653676s] Trained 128 records in 0.103302881 seconds. Throughput is 1239.0748 records/second. Loss is 1.2458724. Sequential31006cbd's hyper parameters: Current learning rate is 0.009370314842578711. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:22 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 338][Wall Clock 46.219230225s] Trained 128 records in 0.098576549 seconds. Throughput is 1298.4833 records/second. Loss is 1.2060107. Sequential31006cbd's hyper parameters: Current learning rate is 0.00936855911560802. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 43392/60000][Iteration 339][Wall Clock 46.313304986s] Trained 128 records in 0.094074761 seconds. Throughput is 1360.62 records/second. Loss is 1.2243948. Sequential31006cbd's hyper parameters: Current learning rate is 0.009366804046459348. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 340][Wall Clock 46.434945407s] Trained 128 records in 0.121640421 seconds. Throughput is 1052.2817 records/second. Loss is 1.2212073. Sequential31006cbd's hyper parameters: Current learning rate is 0.009365049634763064. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 43648/60000][Iteration 341][Wall Clock 46.560484222s] Trained 128 records in 0.125538815 seconds. Throughput is 1019.605 records/second. Loss is 1.2200097. Sequential31006cbd's hyper parameters: Current learning rate is 0.009363295880149813. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 342][Wall Clock 46.671631072s] Trained 128 records in 0.11114685 seconds. Throughput is 1151.6295 records/second. Loss is 1.1845847. Sequential31006cbd's hyper parameters: Current learning rate is 0.009361542782250515. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 43904/60000][Iteration 343][Wall Clock 46.76563445s] Trained 128 records in 0.094003378 seconds. Throughput is 1361.6532 records/second. Loss is 1.2404151. Sequential31006cbd's hyper parameters: Current learning rate is 0.009359790340696368. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 344][Wall Clock 46.851166054s] Trained 128 records in 0.085531604 seconds. Throughput is 1496.5228 records/second. Loss is 1.3120006. Sequential31006cbd's hyper parameters: Current learning rate is 0.009358038555118848. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 44160/60000][Iteration 345][Wall Clock 46.942749593s] Trained 128 records in 0.091583539 seconds. Throughput is 1397.631 records/second. Loss is 1.1682928. Sequential31006cbd's hyper parameters: Current learning rate is 0.009356287425149701. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 346][Wall Clock 47.035354918s] Trained 128 records in 0.092605325 seconds. Throughput is 1382.21 records/second. Loss is 1.1953766. Sequential31006cbd's hyper parameters: Current learning rate is 0.009354536950420956. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 44416/60000][Iteration 347][Wall Clock 47.115791824s] Trained 128 records in 0.080436906 seconds. Throughput is 1591.3093 records/second. Loss is 1.2613204. Sequential31006cbd's hyper parameters: Current learning rate is 0.00935278713056491. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:23 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 348][Wall Clock 47.205244467s] Trained 128 records in 0.089452643 seconds. Throughput is 1430.9247 records/second. Loss is 1.1496563. Sequential31006cbd's hyper parameters: Current learning rate is 0.009351037965214139. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 44672/60000][Iteration 349][Wall Clock 47.308451539s] Trained 128 records in 0.103207072 seconds. Throughput is 1240.2251 records/second. Loss is 1.1146411. Sequential31006cbd's hyper parameters: Current learning rate is 0.009349289454001495. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 350][Wall Clock 47.410930386s] Trained 128 records in 0.102478847 seconds. Throughput is 1249.0382 records/second. Loss is 1.1982145. Sequential31006cbd's hyper parameters: Current learning rate is 0.009347541596560104. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 44928/60000][Iteration 351][Wall Clock 47.543971586s] Trained 128 records in 0.1330412 seconds. Throughput is 962.108 records/second. Loss is 1.1437685. Sequential31006cbd's hyper parameters: Current learning rate is 0.009345794392523364. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 352][Wall Clock 47.652357163s] Trained 128 records in 0.108385577 seconds. Throughput is 1180.9689 records/second. Loss is 1.1326298. Sequential31006cbd's hyper parameters: Current learning rate is 0.009344047841524948. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 45184/60000][Iteration 353][Wall Clock 47.767919053s] Trained 128 records in 0.11556189 seconds. Throughput is 1107.6316 records/second. Loss is 1.2436734. Sequential31006cbd's hyper parameters: Current learning rate is 0.009342301943198805. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 354][Wall Clock 47.858074478s] Trained 128 records in 0.090155425 seconds. Throughput is 1419.7704 records/second. Loss is 1.1589811. Sequential31006cbd's hyper parameters: Current learning rate is 0.009340556697179153. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 45440/60000][Iteration 355][Wall Clock 47.972676224s] Trained 128 records in 0.114601746 seconds. Throughput is 1116.9114 records/second. Loss is 1.2256275. Sequential31006cbd's hyper parameters: Current learning rate is 0.009338812103100487. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 356][Wall Clock 48.086483704s] Trained 128 records in 0.11380748 seconds. Throughput is 1124.7064 records/second. Loss is 1.124609. Sequential31006cbd's hyper parameters: Current learning rate is 0.009337068160597572. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:24 INFO  DistriOptimizer$:408 - [Epoch 1 45696/60000][Iteration 357][Wall Clock 48.182980191s] Trained 128 records in 0.096496487 seconds. Throughput is 1326.4731 records/second. Loss is 1.0829422. Sequential31006cbd's hyper parameters: Current learning rate is 0.009335324869305453. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 358][Wall Clock 48.273734122s] Trained 128 records in 0.090753931 seconds. Throughput is 1410.4072 records/second. Loss is 1.12681. Sequential31006cbd's hyper parameters: Current learning rate is 0.009333582228859437. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 45952/60000][Iteration 359][Wall Clock 48.365280315s] Trained 128 records in 0.091546193 seconds. Throughput is 1398.2013 records/second. Loss is 1.1280775. Sequential31006cbd's hyper parameters: Current learning rate is 0.00933184023889511. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 360][Wall Clock 48.463679303s] Trained 128 records in 0.098398988 seconds. Throughput is 1300.8263 records/second. Loss is 1.1922958. Sequential31006cbd's hyper parameters: Current learning rate is 0.009330098899048329. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46208/60000][Iteration 361][Wall Clock 48.562766484s] Trained 128 records in 0.099087181 seconds. Throughput is 1291.7917 records/second. Loss is 1.1664459. Sequential31006cbd's hyper parameters: Current learning rate is 0.009328358208955223. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 362][Wall Clock 48.655114683s] Trained 128 records in 0.092348199 seconds. Throughput is 1386.0585 records/second. Loss is 1.154262. Sequential31006cbd's hyper parameters: Current learning rate is 0.009326618168252192. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46464/60000][Iteration 363][Wall Clock 48.754066713s] Trained 128 records in 0.09895203 seconds. Throughput is 1293.556 records/second. Loss is 1.2202308. Sequential31006cbd's hyper parameters: Current learning rate is 0.009324878776575904. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 364][Wall Clock 48.855040877s] Trained 128 records in 0.100974164 seconds. Throughput is 1267.651 records/second. Loss is 1.067527. Sequential31006cbd's hyper parameters: Current learning rate is 0.009323140033563304. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46720/60000][Iteration 365][Wall Clock 48.969363352s] Trained 128 records in 0.114322475 seconds. Throughput is 1119.6399 records/second. Loss is 1.1893352. Sequential31006cbd's hyper parameters: Current learning rate is 0.009321401938851604. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 366][Wall Clock 49.088952154s] Trained 128 records in 0.119588802 seconds. Throughput is 1070.3344 records/second. Loss is 1.1950055. Sequential31006cbd's hyper parameters: Current learning rate is 0.009319664492078286. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:25 INFO  DistriOptimizer$:408 - [Epoch 1 46976/60000][Iteration 367][Wall Clock 49.187837154s] Trained 128 records in 0.098885 seconds. Throughput is 1294.433 records/second. Loss is 1.2006588. Sequential31006cbd's hyper parameters: Current learning rate is 0.009317927692881103. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 368][Wall Clock 49.275035976s] Trained 128 records in 0.087198822 seconds. Throughput is 1467.9097 records/second. Loss is 1.1177553. Sequential31006cbd's hyper parameters: Current learning rate is 0.009316191540898081. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47232/60000][Iteration 369][Wall Clock 49.392130116s] Trained 128 records in 0.11709414 seconds. Throughput is 1093.1376 records/second. Loss is 1.1555759. Sequential31006cbd's hyper parameters: Current learning rate is 0.009314456035767513. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 370][Wall Clock 49.493143546s] Trained 128 records in 0.10101343 seconds. Throughput is 1267.1582 records/second. Loss is 1.108522. Sequential31006cbd's hyper parameters: Current learning rate is 0.009312721177127956. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47488/60000][Iteration 371][Wall Clock 49.614832856s] Trained 128 records in 0.12168931 seconds. Throughput is 1051.859 records/second. Loss is 1.1639233. Sequential31006cbd's hyper parameters: Current learning rate is 0.009310986964618248. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 372][Wall Clock 49.708377009s] Trained 128 records in 0.093544153 seconds. Throughput is 1368.3378 records/second. Loss is 1.0569446. Sequential31006cbd's hyper parameters: Current learning rate is 0.00930925339787749. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47744/60000][Iteration 373][Wall Clock 49.811669941s] Trained 128 records in 0.103292932 seconds. Throughput is 1239.1941 records/second. Loss is 1.1251277. Sequential31006cbd's hyper parameters: Current learning rate is 0.009307520476545048. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 374][Wall Clock 49.944873959s] Trained 128 records in 0.133204018 seconds. Throughput is 960.932 records/second. Loss is 1.090571. Sequential31006cbd's hyper parameters: Current learning rate is 0.009305788200260562. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 48000/60000][Iteration 375][Wall Clock 50.060001931s] Trained 128 records in 0.115127972 seconds. Throughput is 1111.8063 records/second. Loss is 1.1354182. Sequential31006cbd's hyper parameters: Current learning rate is 0.009304056568663939. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:26 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 376][Wall Clock 50.194463061s] Trained 128 records in 0.13446113 seconds. Throughput is 951.94794 records/second. Loss is 1.0347189. Sequential31006cbd's hyper parameters: Current learning rate is 0.009302325581395349. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 48256/60000][Iteration 377][Wall Clock 50.322819907s] Trained 128 records in 0.128356846 seconds. Throughput is 997.2199 records/second. Loss is 1.0699561. Sequential31006cbd's hyper parameters: Current learning rate is 0.009300595238095238. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 378][Wall Clock 50.421189962s] Trained 128 records in 0.098370055 seconds. Throughput is 1301.209 records/second. Loss is 1.0927144. Sequential31006cbd's hyper parameters: Current learning rate is 0.009298865538404316. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 48512/60000][Iteration 379][Wall Clock 50.505498675s] Trained 128 records in 0.084308713 seconds. Throughput is 1518.2297 records/second. Loss is 1.0025767. Sequential31006cbd's hyper parameters: Current learning rate is 0.009297136481963555. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 380][Wall Clock 50.610300903s] Trained 128 records in 0.104802228 seconds. Throughput is 1221.348 records/second. Loss is 1.1230772. Sequential31006cbd's hyper parameters: Current learning rate is 0.009295408068414203. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 48768/60000][Iteration 381][Wall Clock 50.716068348s] Trained 128 records in 0.105767445 seconds. Throughput is 1210.2023 records/second. Loss is 1.085325. Sequential31006cbd's hyper parameters: Current learning rate is 0.00929368029739777. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 382][Wall Clock 50.815051734s] Trained 128 records in 0.098983386 seconds. Throughput is 1293.1464 records/second. Loss is 1.0971571. Sequential31006cbd's hyper parameters: Current learning rate is 0.00929195316855603. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 49024/60000][Iteration 383][Wall Clock 50.921168968s] Trained 128 records in 0.106117234 seconds. Throughput is 1206.2131 records/second. Loss is 1.139035. Sequential31006cbd's hyper parameters: Current learning rate is 0.00929022668153103. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 384][Wall Clock 51.031144373s] Trained 128 records in 0.109975405 seconds. Throughput is 1163.8966 records/second. Loss is 1.1053597. Sequential31006cbd's hyper parameters: Current learning rate is 0.009288500835965075. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 49280/60000][Iteration 385][Wall Clock 51.130356416s] Trained 128 records in 0.099212043 seconds. Throughput is 1290.1659 records/second. Loss is 1.2118292. Sequential31006cbd's hyper parameters: Current learning rate is 0.009286775631500743. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:27 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 386][Wall Clock 51.225180293s] Trained 128 records in 0.094823877 seconds. Throughput is 1349.871 records/second. Loss is 1.1299616. Sequential31006cbd's hyper parameters: Current learning rate is 0.009285051067780874. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 49536/60000][Iteration 387][Wall Clock 51.331515744s] Trained 128 records in 0.106335451 seconds. Throughput is 1203.7378 records/second. Loss is 0.98766863. Sequential31006cbd's hyper parameters: Current learning rate is 0.00928332714444857. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 388][Wall Clock 51.432943994s] Trained 128 records in 0.10142825 seconds. Throughput is 1261.9758 records/second. Loss is 1.024318. Sequential31006cbd's hyper parameters: Current learning rate is 0.009281603861147207. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 49792/60000][Iteration 389][Wall Clock 51.604315636s] Trained 128 records in 0.171371642 seconds. Throughput is 746.91473 records/second. Loss is 1.1131581. Sequential31006cbd's hyper parameters: Current learning rate is 0.009279881217520417. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 390][Wall Clock 51.743655829s] Trained 128 records in 0.139340193 seconds. Throughput is 918.61505 records/second. Loss is 1.106364. Sequential31006cbd's hyper parameters: Current learning rate is 0.009278159213212098. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 50048/60000][Iteration 391][Wall Clock 51.850246275s] Trained 128 records in 0.106590446 seconds. Throughput is 1200.8582 records/second. Loss is 1.0175939. Sequential31006cbd's hyper parameters: Current learning rate is 0.00927643784786642. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 392][Wall Clock 51.956300139s] Trained 128 records in 0.106053864 seconds. Throughput is 1206.9338 records/second. Loss is 1.1445314. Sequential31006cbd's hyper parameters: Current learning rate is 0.009274717121127806. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 50304/60000][Iteration 393][Wall Clock 52.054223704s] Trained 128 records in 0.097923565 seconds. Throughput is 1307.142 records/second. Loss is 1.109524. Sequential31006cbd's hyper parameters: Current learning rate is 0.009272997032640949. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:28 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 394][Wall Clock 52.14321265s] Trained 128 records in 0.088988946 seconds. Throughput is 1438.3809 records/second. Loss is 1.0801457. Sequential31006cbd's hyper parameters: Current learning rate is 0.009271277582050807. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 50560/60000][Iteration 395][Wall Clock 52.232472181s] Trained 128 records in 0.089259531 seconds. Throughput is 1434.0206 records/second. Loss is 0.99786204. Sequential31006cbd's hyper parameters: Current learning rate is 0.009269558769002597. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 396][Wall Clock 52.327752228s] Trained 128 records in 0.095280047 seconds. Throughput is 1343.4083 records/second. Loss is 1.1353557. Sequential31006cbd's hyper parameters: Current learning rate is 0.009267840593141799. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 50816/60000][Iteration 397][Wall Clock 52.416219785s] Trained 128 records in 0.088467557 seconds. Throughput is 1446.858 records/second. Loss is 1.0029068. Sequential31006cbd's hyper parameters: Current learning rate is 0.009266123054114159. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 398][Wall Clock 52.512470614s] Trained 128 records in 0.096250829 seconds. Throughput is 1329.8586 records/second. Loss is 0.97853786. Sequential31006cbd's hyper parameters: Current learning rate is 0.009264406151565686. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51072/60000][Iteration 399][Wall Clock 52.614421179s] Trained 128 records in 0.101950565 seconds. Throughput is 1255.5105 records/second. Loss is 1.0676156. Sequential31006cbd's hyper parameters: Current learning rate is 0.009262689885142644. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 400][Wall Clock 52.723567595s] Trained 128 records in 0.109146416 seconds. Throughput is 1172.7366 records/second. Loss is 0.9836366. Sequential31006cbd's hyper parameters: Current learning rate is 0.009260974254491572. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51328/60000][Iteration 401][Wall Clock 52.830118642s] Trained 128 records in 0.106551047 seconds. Throughput is 1201.3021 records/second. Loss is 1.0003734. Sequential31006cbd's hyper parameters: Current learning rate is 0.009259259259259259. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 402][Wall Clock 52.920710991s] Trained 128 records in 0.090592349 seconds. Throughput is 1412.9229 records/second. Loss is 1.07155. Sequential31006cbd's hyper parameters: Current learning rate is 0.00925754489909276. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51584/60000][Iteration 403][Wall Clock 53.003851367s] Trained 128 records in 0.083140376 seconds. Throughput is 1539.565 records/second. Loss is 1.0219135. Sequential31006cbd's hyper parameters: Current learning rate is 0.009255831173639394. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 404][Wall Clock 53.092076781s] Trained 128 records in 0.088225414 seconds. Throughput is 1450.8291 records/second. Loss is 0.9795888. Sequential31006cbd's hyper parameters: Current learning rate is 0.009254118082546734. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:29 INFO  DistriOptimizer$:408 - [Epoch 1 51840/60000][Iteration 405][Wall Clock 53.178481703s] Trained 128 records in 0.086404922 seconds. Throughput is 1481.3971 records/second. Loss is 1.1010956. Sequential31006cbd's hyper parameters: Current learning rate is 0.009252405625462621. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 406][Wall Clock 53.265787689s] Trained 128 records in 0.087305986 seconds. Throughput is 1466.1079 records/second. Loss is 0.98711425. Sequential31006cbd's hyper parameters: Current learning rate is 0.009250693802035153. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52096/60000][Iteration 407][Wall Clock 53.358254568s] Trained 128 records in 0.092466879 seconds. Throughput is 1384.2795 records/second. Loss is 0.9513096. Sequential31006cbd's hyper parameters: Current learning rate is 0.00924898261191269. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 408][Wall Clock 53.460676889s] Trained 128 records in 0.102422321 seconds. Throughput is 1249.7277 records/second. Loss is 1.0346372. Sequential31006cbd's hyper parameters: Current learning rate is 0.009247272054743851. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52352/60000][Iteration 409][Wall Clock 53.562762575s] Trained 128 records in 0.102085686 seconds. Throughput is 1253.8486 records/second. Loss is 1.0841085. Sequential31006cbd's hyper parameters: Current learning rate is 0.009245562130177515. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 410][Wall Clock 53.655578076s] Trained 128 records in 0.092815501 seconds. Throughput is 1379.08 records/second. Loss is 1.0042045. Sequential31006cbd's hyper parameters: Current learning rate is 0.009243852837862821. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52608/60000][Iteration 411][Wall Clock 53.748557191s] Trained 128 records in 0.092979115 seconds. Throughput is 1376.6532 records/second. Loss is 1.014492. Sequential31006cbd's hyper parameters: Current learning rate is 0.009242144177449167. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 412][Wall Clock 53.872386343s] Trained 128 records in 0.123829152 seconds. Throughput is 1033.6823 records/second. Loss is 1.015621. Sequential31006cbd's hyper parameters: Current learning rate is 0.009240436148586212. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52864/60000][Iteration 413][Wall Clock 53.960313895s] Trained 128 records in 0.087927552 seconds. Throughput is 1455.744 records/second. Loss is 1.0274397. Sequential31006cbd's hyper parameters: Current learning rate is 0.009238728750923873. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 414][Wall Clock 54.048845365s] Trained 128 records in 0.08853147 seconds. Throughput is 1445.8135 records/second. Loss is 1.0148218. Sequential31006cbd's hyper parameters: Current learning rate is 0.009237021984112323. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:30 INFO  DistriOptimizer$:408 - [Epoch 1 53120/60000][Iteration 415][Wall Clock 54.186995175s] Trained 128 records in 0.13814981 seconds. Throughput is 926.5304 records/second. Loss is 1.0496004. Sequential31006cbd's hyper parameters: Current learning rate is 0.009235315847801994. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 416][Wall Clock 54.280351845s] Trained 128 records in 0.09335667 seconds. Throughput is 1371.0858 records/second. Loss is 0.98638475. Sequential31006cbd's hyper parameters: Current learning rate is 0.009233610341643583. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 53376/60000][Iteration 417][Wall Clock 54.374342966s] Trained 128 records in 0.093991121 seconds. Throughput is 1361.8307 records/second. Loss is 0.91472536. Sequential31006cbd's hyper parameters: Current learning rate is 0.009231905465288036. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 418][Wall Clock 54.470976949s] Trained 128 records in 0.096633983 seconds. Throughput is 1324.5857 records/second. Loss is 0.9786399. Sequential31006cbd's hyper parameters: Current learning rate is 0.009230201218386561. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 53632/60000][Iteration 419][Wall Clock 54.557399027s] Trained 128 records in 0.086422078 seconds. Throughput is 1481.103 records/second. Loss is 0.9974807. Sequential31006cbd's hyper parameters: Current learning rate is 0.009228497600590623. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 420][Wall Clock 54.645610871s] Trained 128 records in 0.088211844 seconds. Throughput is 1451.0524 records/second. Loss is 1.0316633. Sequential31006cbd's hyper parameters: Current learning rate is 0.009226794611551946. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 53888/60000][Iteration 421][Wall Clock 54.755896215s] Trained 128 records in 0.110285344 seconds. Throughput is 1160.6257 records/second. Loss is 0.9969699. Sequential31006cbd's hyper parameters: Current learning rate is 0.00922509225092251. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 422][Wall Clock 54.866030756s] Trained 128 records in 0.110134541 seconds. Throughput is 1162.2148 records/second. Loss is 0.99880075. Sequential31006cbd's hyper parameters: Current learning rate is 0.009223390518354546. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 54144/60000][Iteration 423][Wall Clock 54.963481448s] Trained 128 records in 0.097450692 seconds. Throughput is 1313.4849 records/second. Loss is 1.0386451. Sequential31006cbd's hyper parameters: Current learning rate is 0.009221689413500553. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 424][Wall Clock 55.0894469s] Trained 128 records in 0.125965452 seconds. Throughput is 1016.1517 records/second. Loss is 1.0169064. Sequential31006cbd's hyper parameters: Current learning rate is 0.009219988936013277. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:31 INFO  DistriOptimizer$:408 - [Epoch 1 54400/60000][Iteration 425][Wall Clock 55.192667696s] Trained 128 records in 0.103220796 seconds. Throughput is 1240.0602 records/second. Loss is 0.9036566. Sequential31006cbd's hyper parameters: Current learning rate is 0.009218289085545723. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 426][Wall Clock 55.288598065s] Trained 128 records in 0.095930369 seconds. Throughput is 1334.3011 records/second. Loss is 0.95089185. Sequential31006cbd's hyper parameters: Current learning rate is 0.009216589861751152. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 54656/60000][Iteration 427][Wall Clock 55.375807244s] Trained 128 records in 0.087209179 seconds. Throughput is 1467.7354 records/second. Loss is 1.1288811. Sequential31006cbd's hyper parameters: Current learning rate is 0.009214891264283083. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 428][Wall Clock 55.462908415s] Trained 128 records in 0.087101171 seconds. Throughput is 1469.5554 records/second. Loss is 1.0209107. Sequential31006cbd's hyper parameters: Current learning rate is 0.009213193292795284. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 54912/60000][Iteration 429][Wall Clock 55.562854032s] Trained 128 records in 0.099945617 seconds. Throughput is 1280.6964 records/second. Loss is 1.0441146. Sequential31006cbd's hyper parameters: Current learning rate is 0.009211495946941784. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 430][Wall Clock 55.661612355s] Trained 128 records in 0.098758323 seconds. Throughput is 1296.0933 records/second. Loss is 0.9558502. Sequential31006cbd's hyper parameters: Current learning rate is 0.009209799226376865. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55168/60000][Iteration 431][Wall Clock 55.755706352s] Trained 128 records in 0.094093997 seconds. Throughput is 1360.3419 records/second. Loss is 0.9602858. Sequential31006cbd's hyper parameters: Current learning rate is 0.009208103130755063. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 432][Wall Clock 55.856817819s] Trained 128 records in 0.101111467 seconds. Throughput is 1265.9297 records/second. Loss is 0.96247125. Sequential31006cbd's hyper parameters: Current learning rate is 0.009206407659731172. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55424/60000][Iteration 433][Wall Clock 55.942976162s] Trained 128 records in 0.086158343 seconds. Throughput is 1485.6367 records/second. Loss is 0.9392118. Sequential31006cbd's hyper parameters: Current learning rate is 0.009204712812960236. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 434][Wall Clock 56.026423993s] Trained 128 records in 0.083447831 seconds. Throughput is 1533.8925 records/second. Loss is 1.0576226. Sequential31006cbd's hyper parameters: Current learning rate is 0.009203018590097553. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55680/60000][Iteration 435][Wall Clock 56.112070569s] Trained 128 records in 0.085646576 seconds. Throughput is 1494.5139 records/second. Loss is 0.9376863. Sequential31006cbd's hyper parameters: Current learning rate is 0.009201324990798676. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:32 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 436][Wall Clock 56.200301735s] Trained 128 records in 0.088231166 seconds. Throughput is 1450.7345 records/second. Loss is 1.0030322. Sequential31006cbd's hyper parameters: Current learning rate is 0.009199632014719412. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 55936/60000][Iteration 437][Wall Clock 56.293478392s] Trained 128 records in 0.093176657 seconds. Throughput is 1373.7346 records/second. Loss is 1.0050529. Sequential31006cbd's hyper parameters: Current learning rate is 0.009197939661515822. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 438][Wall Clock 56.379168519s] Trained 128 records in 0.085690127 seconds. Throughput is 1493.7544 records/second. Loss is 0.9527601. Sequential31006cbd's hyper parameters: Current learning rate is 0.009196247930844217. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56192/60000][Iteration 439][Wall Clock 56.463528014s] Trained 128 records in 0.084359495 seconds. Throughput is 1517.3158 records/second. Loss is 0.95065385. Sequential31006cbd's hyper parameters: Current learning rate is 0.009194556822361163. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 440][Wall Clock 56.573462514s] Trained 128 records in 0.1099345 seconds. Throughput is 1164.3297 records/second. Loss is 0.9584373. Sequential31006cbd's hyper parameters: Current learning rate is 0.009192866335723478. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56448/60000][Iteration 441][Wall Clock 56.666225254s] Trained 128 records in 0.09276274 seconds. Throughput is 1379.8644 records/second. Loss is 0.953859. Sequential31006cbd's hyper parameters: Current learning rate is 0.009191176470588236. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 442][Wall Clock 56.779701162s] Trained 128 records in 0.113475908 seconds. Throughput is 1127.9927 records/second. Loss is 0.88421285. Sequential31006cbd's hyper parameters: Current learning rate is 0.009189487226612754. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56704/60000][Iteration 443][Wall Clock 56.900195524s] Trained 128 records in 0.120494362 seconds. Throughput is 1062.2903 records/second. Loss is 0.96405053. Sequential31006cbd's hyper parameters: Current learning rate is 0.009187798603454611. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 444][Wall Clock 57.000005896s] Trained 128 records in 0.099810372 seconds. Throughput is 1282.4319 records/second. Loss is 0.85450524. Sequential31006cbd's hyper parameters: Current learning rate is 0.009186110600771633. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:33 INFO  DistriOptimizer$:408 - [Epoch 1 56960/60000][Iteration 445][Wall Clock 57.107748635s] Trained 128 records in 0.107742739 seconds. Throughput is 1188.015 records/second. Loss is 1.0381583. Sequential31006cbd's hyper parameters: Current learning rate is 0.009184423218221896. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 446][Wall Clock 57.251778639s] Trained 128 records in 0.144030004 seconds. Throughput is 888.70374 records/second. Loss is 1.0243332. Sequential31006cbd's hyper parameters: Current learning rate is 0.009182736455463728. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57216/60000][Iteration 447][Wall Clock 57.348448682s] Trained 128 records in 0.096670043 seconds. Throughput is 1324.0917 records/second. Loss is 0.9260842. Sequential31006cbd's hyper parameters: Current learning rate is 0.00918105031215571. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 448][Wall Clock 57.453271828s] Trained 128 records in 0.104823146 seconds. Throughput is 1221.1044 records/second. Loss is 0.9882746. Sequential31006cbd's hyper parameters: Current learning rate is 0.009179364787956674. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57472/60000][Iteration 449][Wall Clock 57.553854522s] Trained 128 records in 0.100582694 seconds. Throughput is 1272.5847 records/second. Loss is 1.0038189. Sequential31006cbd's hyper parameters: Current learning rate is 0.009177679882525698. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 450][Wall Clock 57.653621699s] Trained 128 records in 0.099767177 seconds. Throughput is 1282.987 records/second. Loss is 1.068664. Sequential31006cbd's hyper parameters: Current learning rate is 0.009175995595522114. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57728/60000][Iteration 451][Wall Clock 57.761497863s] Trained 128 records in 0.107876164 seconds. Throughput is 1186.5457 records/second. Loss is 0.8634494. Sequential31006cbd's hyper parameters: Current learning rate is 0.009174311926605503. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 452][Wall Clock 57.859305557s] Trained 128 records in 0.097807694 seconds. Throughput is 1308.6906 records/second. Loss is 0.78654754. Sequential31006cbd's hyper parameters: Current learning rate is 0.0091726288754357. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 57984/60000][Iteration 453][Wall Clock 57.956992238s] Trained 128 records in 0.097686681 seconds. Throughput is 1310.3118 records/second. Loss is 0.94997495. Sequential31006cbd's hyper parameters: Current learning rate is 0.009170946441672781. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 454][Wall Clock 58.045063433s] Trained 128 records in 0.088071195 seconds. Throughput is 1453.3696 records/second. Loss is 0.8705674. Sequential31006cbd's hyper parameters: Current learning rate is 0.009169264624977077. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:34 INFO  DistriOptimizer$:408 - [Epoch 1 58240/60000][Iteration 455][Wall Clock 58.128949936s] Trained 128 records in 0.083886503 seconds. Throughput is 1525.8712 records/second. Loss is 0.90733606. Sequential31006cbd's hyper parameters: Current learning rate is 0.009167583425009168. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 456][Wall Clock 58.232789288s] Trained 128 records in 0.103839352 seconds. Throughput is 1232.6733 records/second. Loss is 0.888381. Sequential31006cbd's hyper parameters: Current learning rate is 0.00916590284142988. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 58496/60000][Iteration 457][Wall Clock 58.325383558s] Trained 128 records in 0.09259427 seconds. Throughput is 1382.3749 records/second. Loss is 0.91590405. Sequential31006cbd's hyper parameters: Current learning rate is 0.009164222873900294. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 458][Wall Clock 58.4115741s] Trained 128 records in 0.086190542 seconds. Throughput is 1485.0817 records/second. Loss is 1.0227784. Sequential31006cbd's hyper parameters: Current learning rate is 0.00916254352208173. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 58752/60000][Iteration 459][Wall Clock 58.510834133s] Trained 128 records in 0.099260033 seconds. Throughput is 1289.5422 records/second. Loss is 1.0377679. Sequential31006cbd's hyper parameters: Current learning rate is 0.009160864785635764. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 460][Wall Clock 58.610760493s] Trained 128 records in 0.09992636 seconds. Throughput is 1280.9432 records/second. Loss is 0.97999763. Sequential31006cbd's hyper parameters: Current learning rate is 0.009159186664224217. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 59008/60000][Iteration 461][Wall Clock 58.720948886s] Trained 128 records in 0.110188393 seconds. Throughput is 1161.6469 records/second. Loss is 0.90130055. Sequential31006cbd's hyper parameters: Current learning rate is 0.009157509157509156. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 462][Wall Clock 58.816275002s] Trained 128 records in 0.095326116 seconds. Throughput is 1342.7589 records/second. Loss is 0.78801304. Sequential31006cbd's hyper parameters: Current learning rate is 0.009155832265152902. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 59264/60000][Iteration 463][Wall Clock 58.908191634s] Trained 128 records in 0.091916632 seconds. Throughput is 1392.5662 records/second. Loss is 0.92809176. Sequential31006cbd's hyper parameters: Current learning rate is 0.009154155986818015. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 464][Wall Clock 59.004276422s] Trained 128 records in 0.096084788 seconds. Throughput is 1332.1567 records/second. Loss is 1.0100031. Sequential31006cbd's hyper parameters: Current learning rate is 0.009152480322167308. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:35 INFO  DistriOptimizer$:408 - [Epoch 1 59520/60000][Iteration 465][Wall Clock 59.132251227s] Trained 128 records in 0.127974805 seconds. Throughput is 1000.19684 records/second. Loss is 0.9389817. Sequential31006cbd's hyper parameters: Current learning rate is 0.009150805270863836. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:36 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 466][Wall Clock 59.229285014s] Trained 128 records in 0.097033787 seconds. Throughput is 1319.1282 records/second. Loss is 1.0497526. Sequential31006cbd's hyper parameters: Current learning rate is 0.009149130832570906. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:36 INFO  DistriOptimizer$:408 - [Epoch 1 59776/60000][Iteration 467][Wall Clock 59.328915256s] Trained 128 records in 0.099630242 seconds. Throughput is 1284.7505 records/second. Loss is 0.9342195. Sequential31006cbd's hyper parameters: Current learning rate is 0.009147457006952069. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:36 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 468][Wall Clock 59.426797288s] Trained 128 records in 0.097882032 seconds. Throughput is 1307.6965 records/second. Loss is 0.9621299. Sequential31006cbd's hyper parameters: Current learning rate is 0.009145783793671118. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:36 INFO  DistriOptimizer$:408 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 59.520848964s] Trained 128 records in 0.094051676 seconds. Throughput is 1360.954 records/second. Loss is 0.94901335. Sequential31006cbd's hyper parameters: Current learning rate is 0.0091441111923921. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:36 INFO  DistriOptimizer$:452 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 59.520848964s] Epoch finished. Wall clock time is 59857.229604 ms
2019-10-23 23:58:36 INFO  DistriOptimizer$:111 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 59.520848964s] Validate model...
2019-10-23 23:58:37 INFO  DistriOptimizer$:178 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 59.520848964s] validate model throughput is 9109.627 records/second
2019-10-23 23:58:37 INFO  DistriOptimizer$:181 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 59.520848964s] Top1Accuracy is Accuracy(correct: 7949, count: 10000, accuracy: 0.7949)
2019-10-23 23:58:37 INFO  DistriOptimizer$:221 - [Wall Clock 59.857229604s] Save model to /tmp/lenet5/20191023_235735
2019-10-23 23:58:37 INFO  DistriOptimizer$:226 - [Wall Clock 59.857229604s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-23 23:58:37 INFO  DistriOptimizer$:408 - [Epoch 2 128/60000][Iteration 470][Wall Clock 60.00733951s] Trained 128 records in 0.150109906 seconds. Throughput is 852.70856 records/second. Loss is 0.85107213. Sequential31006cbd's hyper parameters: Current learning rate is 0.0091424392027793. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:37 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 471][Wall Clock 60.105376382s] Trained 128 records in 0.098036872 seconds. Throughput is 1305.6312 records/second. Loss is 0.91521907. Sequential31006cbd's hyper parameters: Current learning rate is 0.009140767824497258. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:37 INFO  DistriOptimizer$:408 - [Epoch 2 384/60000][Iteration 472][Wall Clock 60.233337166s] Trained 128 records in 0.127960784 seconds. Throughput is 1000.30646 records/second. Loss is 0.8988659. Sequential31006cbd's hyper parameters: Current learning rate is 0.009139097057210747. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 473][Wall Clock 60.323142244s] Trained 128 records in 0.089805078 seconds. Throughput is 1425.3091 records/second. Loss is 0.8576628. Sequential31006cbd's hyper parameters: Current learning rate is 0.009137426900584795. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 640/60000][Iteration 474][Wall Clock 60.446125998s] Trained 128 records in 0.122983754 seconds. Throughput is 1040.7878 records/second. Loss is 0.9665085. Sequential31006cbd's hyper parameters: Current learning rate is 0.00913575735428467. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 475][Wall Clock 60.581896012s] Trained 128 records in 0.135770014 seconds. Throughput is 942.7708 records/second. Loss is 0.7845691. Sequential31006cbd's hyper parameters: Current learning rate is 0.009134088417975887. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 896/60000][Iteration 476][Wall Clock 60.713986247s] Trained 128 records in 0.132090235 seconds. Throughput is 969.0345 records/second. Loss is 0.8451779. Sequential31006cbd's hyper parameters: Current learning rate is 0.009132420091324202. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 477][Wall Clock 60.831600196s] Trained 128 records in 0.117613949 seconds. Throughput is 1088.3063 records/second. Loss is 0.8858474. Sequential31006cbd's hyper parameters: Current learning rate is 0.009130752373995618. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 1152/60000][Iteration 478][Wall Clock 60.915695379s] Trained 128 records in 0.084095183 seconds. Throughput is 1522.0848 records/second. Loss is 0.91584545. Sequential31006cbd's hyper parameters: Current learning rate is 0.009129085265656383. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 479][Wall Clock 60.99938369s] Trained 128 records in 0.083688311 seconds. Throughput is 1529.4847 records/second. Loss is 0.94906026. Sequential31006cbd's hyper parameters: Current learning rate is 0.009127418765972983. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 1408/60000][Iteration 480][Wall Clock 61.093043311s] Trained 128 records in 0.093659621 seconds. Throughput is 1366.6508 records/second. Loss is 0.88777953. Sequential31006cbd's hyper parameters: Current learning rate is 0.009125752874612154. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:38 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 481][Wall Clock 61.186667737s] Trained 128 records in 0.093624426 seconds. Throughput is 1367.1646 records/second. Loss is 0.85665524. Sequential31006cbd's hyper parameters: Current learning rate is 0.009124087591240875. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 1664/60000][Iteration 482][Wall Clock 61.295605548s] Trained 128 records in 0.108937811 seconds. Throughput is 1174.9823 records/second. Loss is 0.89362717. Sequential31006cbd's hyper parameters: Current learning rate is 0.009122422915526363. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 483][Wall Clock 61.395627737s] Trained 128 records in 0.100022189 seconds. Throughput is 1279.7161 records/second. Loss is 0.75898933. Sequential31006cbd's hyper parameters: Current learning rate is 0.009120758847136081. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 1920/60000][Iteration 484][Wall Clock 61.490223103s] Trained 128 records in 0.094595366 seconds. Throughput is 1353.1318 records/second. Loss is 0.8448164. Sequential31006cbd's hyper parameters: Current learning rate is 0.009119095385737734. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 485][Wall Clock 61.582477954s] Trained 128 records in 0.092254851 seconds. Throughput is 1387.4609 records/second. Loss is 0.9029207. Sequential31006cbd's hyper parameters: Current learning rate is 0.00911743253099927. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2176/60000][Iteration 486][Wall Clock 61.678005715s] Trained 128 records in 0.095527761 seconds. Throughput is 1339.9247 records/second. Loss is 0.9345699. Sequential31006cbd's hyper parameters: Current learning rate is 0.00911577028258888. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 487][Wall Clock 61.764362916s] Trained 128 records in 0.086357201 seconds. Throughput is 1482.2157 records/second. Loss is 0.84458125. Sequential31006cbd's hyper parameters: Current learning rate is 0.009114108640174992. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2432/60000][Iteration 488][Wall Clock 61.862825426s] Trained 128 records in 0.09846251 seconds. Throughput is 1299.9872 records/second. Loss is 0.7990214. Sequential31006cbd's hyper parameters: Current learning rate is 0.00911244760342628. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 489][Wall Clock 61.979494497s] Trained 128 records in 0.116669071 seconds. Throughput is 1097.1202 records/second. Loss is 0.9214461. Sequential31006cbd's hyper parameters: Current learning rate is 0.009110787172011662. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2688/60000][Iteration 490][Wall Clock 62.098980194s] Trained 128 records in 0.119485697 seconds. Throughput is 1071.2579 records/second. Loss is 0.8720986. Sequential31006cbd's hyper parameters: Current learning rate is 0.009109127345600293. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:39 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 491][Wall Clock 62.19487803s] Trained 128 records in 0.095897836 seconds. Throughput is 1334.7538 records/second. Loss is 0.8532721. Sequential31006cbd's hyper parameters: Current learning rate is 0.009107468123861566. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 2944/60000][Iteration 492][Wall Clock 62.286200601s] Trained 128 records in 0.091322571 seconds. Throughput is 1401.625 records/second. Loss is 0.8569569. Sequential31006cbd's hyper parameters: Current learning rate is 0.009105809506465124. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 493][Wall Clock 62.381770919s] Trained 128 records in 0.095570318 seconds. Throughput is 1339.328 records/second. Loss is 0.9127192. Sequential31006cbd's hyper parameters: Current learning rate is 0.009104151493080845. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3200/60000][Iteration 494][Wall Clock 62.485697664s] Trained 128 records in 0.103926745 seconds. Throughput is 1231.6367 records/second. Loss is 0.9469563. Sequential31006cbd's hyper parameters: Current learning rate is 0.009102494083378846. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 495][Wall Clock 62.583165918s] Trained 128 records in 0.097468254 seconds. Throughput is 1313.248 records/second. Loss is 0.73544496. Sequential31006cbd's hyper parameters: Current learning rate is 0.009100837277029487. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3456/60000][Iteration 496][Wall Clock 62.696897161s] Trained 128 records in 0.113731243 seconds. Throughput is 1125.4603 records/second. Loss is 0.8634773. Sequential31006cbd's hyper parameters: Current learning rate is 0.009099181073703368. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 497][Wall Clock 62.811782785s] Trained 128 records in 0.114885624 seconds. Throughput is 1114.1516 records/second. Loss is 0.9260162. Sequential31006cbd's hyper parameters: Current learning rate is 0.009097525473071326. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3712/60000][Iteration 498][Wall Clock 62.90714862s] Trained 128 records in 0.095365835 seconds. Throughput is 1342.1997 records/second. Loss is 0.8645642. Sequential31006cbd's hyper parameters: Current learning rate is 0.00909587047480444. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 499][Wall Clock 63.010845866s] Trained 128 records in 0.103697246 seconds. Throughput is 1234.3625 records/second. Loss is 0.91674083. Sequential31006cbd's hyper parameters: Current learning rate is 0.009094216078574028. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 3968/60000][Iteration 500][Wall Clock 63.096232996s] Trained 128 records in 0.08538713 seconds. Throughput is 1499.0549 records/second. Loss is 0.93293476. Sequential31006cbd's hyper parameters: Current learning rate is 0.009092562284051645. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:40 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 501][Wall Clock 63.18293757s] Trained 128 records in 0.086704574 seconds. Throughput is 1476.2773 records/second. Loss is 0.86455965. Sequential31006cbd's hyper parameters: Current learning rate is 0.00909090909090909. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4224/60000][Iteration 502][Wall Clock 63.27016776s] Trained 128 records in 0.08723019 seconds. Throughput is 1467.3818 records/second. Loss is 0.9432825. Sequential31006cbd's hyper parameters: Current learning rate is 0.009089256498818397. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 503][Wall Clock 63.363356198s] Trained 128 records in 0.093188438 seconds. Throughput is 1373.561 records/second. Loss is 0.892049. Sequential31006cbd's hyper parameters: Current learning rate is 0.009087604507451835. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4480/60000][Iteration 504][Wall Clock 63.477267854s] Trained 128 records in 0.113911656 seconds. Throughput is 1123.6777 records/second. Loss is 0.910196. Sequential31006cbd's hyper parameters: Current learning rate is 0.009085953116481919. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 505][Wall Clock 63.581488609s] Trained 128 records in 0.104220755 seconds. Throughput is 1228.1622 records/second. Loss is 0.76342714. Sequential31006cbd's hyper parameters: Current learning rate is 0.009084302325581396. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4736/60000][Iteration 506][Wall Clock 63.680185336s] Trained 128 records in 0.098696727 seconds. Throughput is 1296.9022 records/second. Loss is 0.85893846. Sequential31006cbd's hyper parameters: Current learning rate is 0.009082652134423252. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 507][Wall Clock 63.777058718s] Trained 128 records in 0.096873382 seconds. Throughput is 1321.3124 records/second. Loss is 0.81755066. Sequential31006cbd's hyper parameters: Current learning rate is 0.009081002542680712. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 4992/60000][Iteration 508][Wall Clock 63.917338944s] Trained 128 records in 0.140280226 seconds. Throughput is 912.4593 records/second. Loss is 0.743511. Sequential31006cbd's hyper parameters: Current learning rate is 0.009079353550027239. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 509][Wall Clock 64.000619225s] Trained 128 records in 0.083280281 seconds. Throughput is 1536.9785 records/second. Loss is 0.8011997. Sequential31006cbd's hyper parameters: Current learning rate is 0.00907770515613653. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 5248/60000][Iteration 510][Wall Clock 64.095913261s] Trained 128 records in 0.095294036 seconds. Throughput is 1343.211 records/second. Loss is 0.8088795. Sequential31006cbd's hyper parameters: Current learning rate is 0.00907605736068252. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:41 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 511][Wall Clock 64.185665291s] Trained 128 records in 0.08975203 seconds. Throughput is 1426.1515 records/second. Loss is 0.8519662. Sequential31006cbd's hyper parameters: Current learning rate is 0.009074410163339382. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 5504/60000][Iteration 512][Wall Clock 64.284925088s] Trained 128 records in 0.099259797 seconds. Throughput is 1289.5453 records/second. Loss is 0.73880875. Sequential31006cbd's hyper parameters: Current learning rate is 0.009072763563781528. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 513][Wall Clock 64.379249119s] Trained 128 records in 0.094324031 seconds. Throughput is 1357.0243 records/second. Loss is 0.8267284. Sequential31006cbd's hyper parameters: Current learning rate is 0.009071117561683599. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 5760/60000][Iteration 514][Wall Clock 64.495088769s] Trained 128 records in 0.11583965 seconds. Throughput is 1104.9757 records/second. Loss is 0.8064109. Sequential31006cbd's hyper parameters: Current learning rate is 0.009069472156720479. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 515][Wall Clock 64.598321382s] Trained 128 records in 0.103232613 seconds. Throughput is 1239.9182 records/second. Loss is 0.78003. Sequential31006cbd's hyper parameters: Current learning rate is 0.009067827348567283. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 6016/60000][Iteration 516][Wall Clock 64.685481319s] Trained 128 records in 0.087159937 seconds. Throughput is 1468.5646 records/second. Loss is 0.8529606. Sequential31006cbd's hyper parameters: Current learning rate is 0.009066183136899365. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 517][Wall Clock 64.805207462s] Trained 128 records in 0.119726143 seconds. Throughput is 1069.1066 records/second. Loss is 0.8809706. Sequential31006cbd's hyper parameters: Current learning rate is 0.009064539521392313. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 6272/60000][Iteration 518][Wall Clock 64.899393563s] Trained 128 records in 0.094186101 seconds. Throughput is 1359.0116 records/second. Loss is 0.79533064. Sequential31006cbd's hyper parameters: Current learning rate is 0.009062896501721951. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 519][Wall Clock 64.99461644s] Trained 128 records in 0.095222877 seconds. Throughput is 1344.2148 records/second. Loss is 0.84882534. Sequential31006cbd's hyper parameters: Current learning rate is 0.009061254077564336. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 6528/60000][Iteration 520][Wall Clock 65.079558964s] Trained 128 records in 0.084942524 seconds. Throughput is 1506.9012 records/second. Loss is 0.78568536. Sequential31006cbd's hyper parameters: Current learning rate is 0.00905961224859576. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:42 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 521][Wall Clock 65.169591306s] Trained 128 records in 0.090032342 seconds. Throughput is 1421.7114 records/second. Loss is 0.92056066. Sequential31006cbd's hyper parameters: Current learning rate is 0.009057971014492752. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 6784/60000][Iteration 522][Wall Clock 65.258428123s] Trained 128 records in 0.088836817 seconds. Throughput is 1440.844 records/second. Loss is 0.84153926. Sequential31006cbd's hyper parameters: Current learning rate is 0.009056330374932076. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 523][Wall Clock 65.378399041s] Trained 128 records in 0.119970918 seconds. Throughput is 1066.9253 records/second. Loss is 0.9629408. Sequential31006cbd's hyper parameters: Current learning rate is 0.009054690329590729. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7040/60000][Iteration 524][Wall Clock 65.469295511s] Trained 128 records in 0.09089647 seconds. Throughput is 1408.1954 records/second. Loss is 0.80506986. Sequential31006cbd's hyper parameters: Current learning rate is 0.009053050878145934. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 525][Wall Clock 65.568898457s] Trained 128 records in 0.099602946 seconds. Throughput is 1285.1025 records/second. Loss is 0.7618251. Sequential31006cbd's hyper parameters: Current learning rate is 0.009051412020275163. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7296/60000][Iteration 526][Wall Clock 65.662160232s] Trained 128 records in 0.093261775 seconds. Throughput is 1372.4808 records/second. Loss is 0.7434541. Sequential31006cbd's hyper parameters: Current learning rate is 0.00904977375565611. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 527][Wall Clock 65.748814224s] Trained 128 records in 0.086653992 seconds. Throughput is 1477.139 records/second. Loss is 0.75373554. Sequential31006cbd's hyper parameters: Current learning rate is 0.009048136083966703. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7552/60000][Iteration 528][Wall Clock 65.845720856s] Trained 128 records in 0.096906632 seconds. Throughput is 1320.859 records/second. Loss is 0.9862264. Sequential31006cbd's hyper parameters: Current learning rate is 0.009046499004885111. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 529][Wall Clock 65.941788912s] Trained 128 records in 0.096068056 seconds. Throughput is 1332.3888 records/second. Loss is 0.8422193. Sequential31006cbd's hyper parameters: Current learning rate is 0.009044862518089726. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7808/60000][Iteration 530][Wall Clock 66.044945298s] Trained 128 records in 0.103156386 seconds. Throughput is 1240.8345 records/second. Loss is 0.90035236. Sequential31006cbd's hyper parameters: Current learning rate is 0.00904322662325918. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 531][Wall Clock 66.139679953s] Trained 128 records in 0.094734655 seconds. Throughput is 1351.1423 records/second. Loss is 0.8513609. Sequential31006cbd's hyper parameters: Current learning rate is 0.009041591320072331. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:43 INFO  DistriOptimizer$:408 - [Epoch 2 8064/60000][Iteration 532][Wall Clock 66.229014083s] Trained 128 records in 0.08933413 seconds. Throughput is 1432.823 records/second. Loss is 0.8457227. Sequential31006cbd's hyper parameters: Current learning rate is 0.00903995660820828. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 533][Wall Clock 66.339795731s] Trained 128 records in 0.110781648 seconds. Throughput is 1155.426 records/second. Loss is 0.81219745. Sequential31006cbd's hyper parameters: Current learning rate is 0.009038322487346349. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8320/60000][Iteration 534][Wall Clock 66.449668117s] Trained 128 records in 0.109872386 seconds. Throughput is 1164.9879 records/second. Loss is 0.86757. Sequential31006cbd's hyper parameters: Current learning rate is 0.009036688957166094. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 535][Wall Clock 66.540629413s] Trained 128 records in 0.090961296 seconds. Throughput is 1407.192 records/second. Loss is 0.8380041. Sequential31006cbd's hyper parameters: Current learning rate is 0.009035056017347307. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8576/60000][Iteration 536][Wall Clock 66.633253253s] Trained 128 records in 0.09262384 seconds. Throughput is 1381.9337 records/second. Loss is 0.82757074. Sequential31006cbd's hyper parameters: Current learning rate is 0.00903342366757001. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 537][Wall Clock 66.717728783s] Trained 128 records in 0.08447553 seconds. Throughput is 1515.2317 records/second. Loss is 0.7687202. Sequential31006cbd's hyper parameters: Current learning rate is 0.009031791907514452. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8832/60000][Iteration 538][Wall Clock 66.801247414s] Trained 128 records in 0.083518631 seconds. Throughput is 1532.5922 records/second. Loss is 0.67977566. Sequential31006cbd's hyper parameters: Current learning rate is 0.009030160736861116. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 539][Wall Clock 66.929723039s] Trained 128 records in 0.128475625 seconds. Throughput is 996.298 records/second. Loss is 0.8643544. Sequential31006cbd's hyper parameters: Current learning rate is 0.00902853015529072. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 9088/60000][Iteration 540][Wall Clock 67.019286219s] Trained 128 records in 0.08956318 seconds. Throughput is 1429.1587 records/second. Loss is 0.7746237. Sequential31006cbd's hyper parameters: Current learning rate is 0.009026900162484202. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:44 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 541][Wall Clock 67.13477716s] Trained 128 records in 0.115490941 seconds. Throughput is 1108.312 records/second. Loss is 0.8197671. Sequential31006cbd's hyper parameters: Current learning rate is 0.009025270758122744. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 9344/60000][Iteration 542][Wall Clock 67.265489657s] Trained 128 records in 0.130712497 seconds. Throughput is 979.2484 records/second. Loss is 0.79769295. Sequential31006cbd's hyper parameters: Current learning rate is 0.009023641941887746. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 543][Wall Clock 67.364908506s] Trained 128 records in 0.099418849 seconds. Throughput is 1287.4822 records/second. Loss is 0.8454452. Sequential31006cbd's hyper parameters: Current learning rate is 0.009022013713460845. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 9600/60000][Iteration 544][Wall Clock 67.471722838s] Trained 128 records in 0.106814332 seconds. Throughput is 1198.3411 records/second. Loss is 0.8226819. Sequential31006cbd's hyper parameters: Current learning rate is 0.009020386072523904. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 545][Wall Clock 67.565677218s] Trained 128 records in 0.09395438 seconds. Throughput is 1362.3634 records/second. Loss is 0.795263. Sequential31006cbd's hyper parameters: Current learning rate is 0.009018759018759018. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 9856/60000][Iteration 546][Wall Clock 67.669084488s] Trained 128 records in 0.10340727 seconds. Throughput is 1237.824 records/second. Loss is 0.8228894. Sequential31006cbd's hyper parameters: Current learning rate is 0.009017132551848512. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 547][Wall Clock 67.764588519s] Trained 128 records in 0.095504031 seconds. Throughput is 1340.2576 records/second. Loss is 0.8013275. Sequential31006cbd's hyper parameters: Current learning rate is 0.009015506671474938. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 10112/60000][Iteration 548][Wall Clock 67.871784527s] Trained 128 records in 0.107196008 seconds. Throughput is 1194.0743 records/second. Loss is 0.7275945. Sequential31006cbd's hyper parameters: Current learning rate is 0.009013881377321075. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 549][Wall Clock 67.977356241s] Trained 128 records in 0.105571714 seconds. Throughput is 1212.4459 records/second. Loss is 0.7738473. Sequential31006cbd's hyper parameters: Current learning rate is 0.009012256669069936. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 10368/60000][Iteration 550][Wall Clock 68.073257944s] Trained 128 records in 0.095901703 seconds. Throughput is 1334.7 records/second. Loss is 0.84417313. Sequential31006cbd's hyper parameters: Current learning rate is 0.00901063254640476. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:45 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 551][Wall Clock 68.171414573s] Trained 128 records in 0.098156629 seconds. Throughput is 1304.0382 records/second. Loss is 0.7585033. Sequential31006cbd's hyper parameters: Current learning rate is 0.009009009009009009. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 10624/60000][Iteration 552][Wall Clock 68.274471511s] Trained 128 records in 0.103056938 seconds. Throughput is 1242.0319 records/second. Loss is 0.70424455. Sequential31006cbd's hyper parameters: Current learning rate is 0.009007386056566384. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 553][Wall Clock 68.386418324s] Trained 128 records in 0.111946813 seconds. Throughput is 1143.4001 records/second. Loss is 0.81894547. Sequential31006cbd's hyper parameters: Current learning rate is 0.009005763688760807. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 10880/60000][Iteration 554][Wall Clock 68.500968277s] Trained 128 records in 0.114549953 seconds. Throughput is 1117.4165 records/second. Loss is 0.7411508. Sequential31006cbd's hyper parameters: Current learning rate is 0.009004141905276427. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 555][Wall Clock 68.605563627s] Trained 128 records in 0.10459535 seconds. Throughput is 1223.7638 records/second. Loss is 0.6928039. Sequential31006cbd's hyper parameters: Current learning rate is 0.009002520705797623. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11136/60000][Iteration 556][Wall Clock 68.705239297s] Trained 128 records in 0.09967567 seconds. Throughput is 1284.1649 records/second. Loss is 0.7205977. Sequential31006cbd's hyper parameters: Current learning rate is 0.009000900090009001. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 557][Wall Clock 68.79141215s] Trained 128 records in 0.086172853 seconds. Throughput is 1485.3865 records/second. Loss is 0.6972413. Sequential31006cbd's hyper parameters: Current learning rate is 0.008999280057595392. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11392/60000][Iteration 558][Wall Clock 68.885144337s] Trained 128 records in 0.093732187 seconds. Throughput is 1365.5928 records/second. Loss is 0.72030354. Sequential31006cbd's hyper parameters: Current learning rate is 0.008997660608241857. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 559][Wall Clock 68.979017006s] Trained 128 records in 0.093872669 seconds. Throughput is 1363.5492 records/second. Loss is 0.7601727. Sequential31006cbd's hyper parameters: Current learning rate is 0.008996041741633681. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11648/60000][Iteration 560][Wall Clock 69.061153454s] Trained 128 records in 0.082136448 seconds. Throughput is 1558.3826 records/second. Loss is 0.8005854. Sequential31006cbd's hyper parameters: Current learning rate is 0.008994423457456376. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:46 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 561][Wall Clock 69.14662066s] Trained 128 records in 0.085467206 seconds. Throughput is 1497.6505 records/second. Loss is 0.73709154. Sequential31006cbd's hyper parameters: Current learning rate is 0.008992805755395683. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 11904/60000][Iteration 562][Wall Clock 69.234068616s] Trained 128 records in 0.087447956 seconds. Throughput is 1463.7278 records/second. Loss is 0.790787. Sequential31006cbd's hyper parameters: Current learning rate is 0.008991188635137565. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 563][Wall Clock 69.32771889s] Trained 128 records in 0.093650274 seconds. Throughput is 1366.7872 records/second. Loss is 0.7566044. Sequential31006cbd's hyper parameters: Current learning rate is 0.008989572096368213. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12160/60000][Iteration 564][Wall Clock 69.437199535s] Trained 128 records in 0.109480645 seconds. Throughput is 1169.1565 records/second. Loss is 0.85729545. Sequential31006cbd's hyper parameters: Current learning rate is 0.008987956138774043. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 565][Wall Clock 69.54512402s] Trained 128 records in 0.107924485 seconds. Throughput is 1186.0145 records/second. Loss is 0.8004369. Sequential31006cbd's hyper parameters: Current learning rate is 0.008986340762041696. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12416/60000][Iteration 566][Wall Clock 69.667738861s] Trained 128 records in 0.122614841 seconds. Throughput is 1043.9193 records/second. Loss is 0.7379601. Sequential31006cbd's hyper parameters: Current learning rate is 0.008984725965858042. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 567][Wall Clock 69.775083313s] Trained 128 records in 0.107344452 seconds. Throughput is 1192.4231 records/second. Loss is 0.7899022. Sequential31006cbd's hyper parameters: Current learning rate is 0.008983111749910169. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12672/60000][Iteration 568][Wall Clock 69.864727672s] Trained 128 records in 0.089644359 seconds. Throughput is 1427.8645 records/second. Loss is 0.6365818. Sequential31006cbd's hyper parameters: Current learning rate is 0.008981498113885397. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 569][Wall Clock 69.954118514s] Trained 128 records in 0.089390842 seconds. Throughput is 1431.914 records/second. Loss is 0.79771805. Sequential31006cbd's hyper parameters: Current learning rate is 0.008979885057471266. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 12928/60000][Iteration 570][Wall Clock 70.051814231s] Trained 128 records in 0.097695717 seconds. Throughput is 1310.1906 records/second. Loss is 0.75490373. Sequential31006cbd's hyper parameters: Current learning rate is 0.00897827258035554. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:47 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 571][Wall Clock 70.134061627s] Trained 128 records in 0.082247396 seconds. Throughput is 1556.2803 records/second. Loss is 0.74740523. Sequential31006cbd's hyper parameters: Current learning rate is 0.00897666068222621. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13184/60000][Iteration 572][Wall Clock 70.222007525s] Trained 128 records in 0.087945898 seconds. Throughput is 1455.4402 records/second. Loss is 0.72296435. Sequential31006cbd's hyper parameters: Current learning rate is 0.008975049362771494. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 573][Wall Clock 70.318575053s] Trained 128 records in 0.096567528 seconds. Throughput is 1325.4973 records/second. Loss is 0.6564994. Sequential31006cbd's hyper parameters: Current learning rate is 0.008973438621679828. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13440/60000][Iteration 574][Wall Clock 70.409801541s] Trained 128 records in 0.091226488 seconds. Throughput is 1403.1012 records/second. Loss is 0.72236276. Sequential31006cbd's hyper parameters: Current learning rate is 0.00897182845863987. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 575][Wall Clock 70.499517603s] Trained 128 records in 0.089716062 seconds. Throughput is 1426.7234 records/second. Loss is 0.6975077. Sequential31006cbd's hyper parameters: Current learning rate is 0.00897021887334051. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13696/60000][Iteration 576][Wall Clock 70.583212251s] Trained 128 records in 0.083694648 seconds. Throughput is 1529.3689 records/second. Loss is 0.73830485. Sequential31006cbd's hyper parameters: Current learning rate is 0.008968609865470852. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 577][Wall Clock 70.667520052s] Trained 128 records in 0.084307801 seconds. Throughput is 1518.2461 records/second. Loss is 0.8436151. Sequential31006cbd's hyper parameters: Current learning rate is 0.00896700143472023. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 13952/60000][Iteration 578][Wall Clock 70.757190709s] Trained 128 records in 0.089670657 seconds. Throughput is 1427.4458 records/second. Loss is 0.6647239. Sequential31006cbd's hyper parameters: Current learning rate is 0.008965393580778197. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 579][Wall Clock 70.86089251s] Trained 128 records in 0.103701801 seconds. Throughput is 1234.3083 records/second. Loss is 0.7879541. Sequential31006cbd's hyper parameters: Current learning rate is 0.008963786303334529. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 14208/60000][Iteration 580][Wall Clock 70.950581823s] Trained 128 records in 0.089689313 seconds. Throughput is 1427.1488 records/second. Loss is 0.7392455. Sequential31006cbd's hyper parameters: Current learning rate is 0.008962179602079227. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 581][Wall Clock 71.050529268s] Trained 128 records in 0.099947445 seconds. Throughput is 1280.6731 records/second. Loss is 0.73067915. Sequential31006cbd's hyper parameters: Current learning rate is 0.008960573476702509. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:48 INFO  DistriOptimizer$:408 - [Epoch 2 14464/60000][Iteration 582][Wall Clock 71.147036367s] Trained 128 records in 0.096507099 seconds. Throughput is 1326.3273 records/second. Loss is 0.6883773. Sequential31006cbd's hyper parameters: Current learning rate is 0.008958967926894821. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 583][Wall Clock 71.239205256s] Trained 128 records in 0.092168889 seconds. Throughput is 1388.7549 records/second. Loss is 0.62245315. Sequential31006cbd's hyper parameters: Current learning rate is 0.008957362952346828. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 14720/60000][Iteration 584][Wall Clock 71.383241843s] Trained 128 records in 0.144036587 seconds. Throughput is 888.6631 records/second. Loss is 0.7609571. Sequential31006cbd's hyper parameters: Current learning rate is 0.008955758552749419. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 585][Wall Clock 71.495324672s] Trained 128 records in 0.112082829 seconds. Throughput is 1142.0126 records/second. Loss is 0.5867817. Sequential31006cbd's hyper parameters: Current learning rate is 0.008954154727793696. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 14976/60000][Iteration 586][Wall Clock 71.595122568s] Trained 128 records in 0.099797896 seconds. Throughput is 1282.5922 records/second. Loss is 0.6532382. Sequential31006cbd's hyper parameters: Current learning rate is 0.008952551477170993. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 587][Wall Clock 71.689574846s] Trained 128 records in 0.094452278 seconds. Throughput is 1355.1818 records/second. Loss is 0.858385. Sequential31006cbd's hyper parameters: Current learning rate is 0.008950948800572862. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 15232/60000][Iteration 588][Wall Clock 71.78224192s] Trained 128 records in 0.092667074 seconds. Throughput is 1381.289 records/second. Loss is 0.66736156. Sequential31006cbd's hyper parameters: Current learning rate is 0.008949346697691068. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 589][Wall Clock 71.888312201s] Trained 128 records in 0.106070281 seconds. Throughput is 1206.7471 records/second. Loss is 0.8026984. Sequential31006cbd's hyper parameters: Current learning rate is 0.00894774516821761. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 15488/60000][Iteration 590][Wall Clock 71.999575203s] Trained 128 records in 0.111263002 seconds. Throughput is 1150.4274 records/second. Loss is 0.79306567. Sequential31006cbd's hyper parameters: Current learning rate is 0.008946144211844696. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:49 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 591][Wall Clock 72.131369246s] Trained 128 records in 0.131794043 seconds. Throughput is 971.2123 records/second. Loss is 0.73172545. Sequential31006cbd's hyper parameters: Current learning rate is 0.008944543828264758. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 15744/60000][Iteration 592][Wall Clock 72.225663963s] Trained 128 records in 0.094294717 seconds. Throughput is 1357.4462 records/second. Loss is 0.6682263. Sequential31006cbd's hyper parameters: Current learning rate is 0.008942944017170452. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 593][Wall Clock 72.31851978s] Trained 128 records in 0.092855817 seconds. Throughput is 1378.4812 records/second. Loss is 0.7697943. Sequential31006cbd's hyper parameters: Current learning rate is 0.008941344778254649. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16000/60000][Iteration 594][Wall Clock 72.414963228s] Trained 128 records in 0.096443448 seconds. Throughput is 1327.2028 records/second. Loss is 0.84805703. Sequential31006cbd's hyper parameters: Current learning rate is 0.008939746111210442. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 595][Wall Clock 72.511430306s] Trained 128 records in 0.096467078 seconds. Throughput is 1326.8776 records/second. Loss is 0.76936024. Sequential31006cbd's hyper parameters: Current learning rate is 0.00893814801573114. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16256/60000][Iteration 596][Wall Clock 72.611868489s] Trained 128 records in 0.100438183 seconds. Throughput is 1274.4156 records/second. Loss is 0.78326774. Sequential31006cbd's hyper parameters: Current learning rate is 0.008936550491510277. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 597][Wall Clock 72.701061024s] Trained 128 records in 0.089192535 seconds. Throughput is 1435.0978 records/second. Loss is 0.63034874. Sequential31006cbd's hyper parameters: Current learning rate is 0.008934953538241601. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16512/60000][Iteration 598][Wall Clock 72.810852242s] Trained 128 records in 0.109791218 seconds. Throughput is 1165.8491 records/second. Loss is 0.7151183. Sequential31006cbd's hyper parameters: Current learning rate is 0.008933357155619083. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 599][Wall Clock 72.906297967s] Trained 128 records in 0.095445725 seconds. Throughput is 1341.0763 records/second. Loss is 0.7874322. Sequential31006cbd's hyper parameters: Current learning rate is 0.008931761343336907. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16768/60000][Iteration 600][Wall Clock 72.993681137s] Trained 128 records in 0.08738317 seconds. Throughput is 1464.8129 records/second. Loss is 0.6474417. Sequential31006cbd's hyper parameters: Current learning rate is 0.00893016610108948. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 601][Wall Clock 73.079987053s] Trained 128 records in 0.086305916 seconds. Throughput is 1483.0964 records/second. Loss is 0.7487803. Sequential31006cbd's hyper parameters: Current learning rate is 0.008928571428571428. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:50 INFO  DistriOptimizer$:408 - [Epoch 2 17024/60000][Iteration 602][Wall Clock 73.178987485s] Trained 128 records in 0.099000432 seconds. Throughput is 1292.9237 records/second. Loss is 0.70678085. Sequential31006cbd's hyper parameters: Current learning rate is 0.008926977325477594. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 603][Wall Clock 73.276321975s] Trained 128 records in 0.09733449 seconds. Throughput is 1315.0529 records/second. Loss is 0.7182306. Sequential31006cbd's hyper parameters: Current learning rate is 0.008925383791503034. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17280/60000][Iteration 604][Wall Clock 73.40147949s] Trained 128 records in 0.125157515 seconds. Throughput is 1022.71124 records/second. Loss is 0.79894465. Sequential31006cbd's hyper parameters: Current learning rate is 0.00892379082634303. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 605][Wall Clock 73.542005588s] Trained 128 records in 0.140526098 seconds. Throughput is 910.8628 records/second. Loss is 0.8454308. Sequential31006cbd's hyper parameters: Current learning rate is 0.008922198429693077. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17536/60000][Iteration 606][Wall Clock 73.644887483s] Trained 128 records in 0.102881895 seconds. Throughput is 1244.145 records/second. Loss is 0.8167352. Sequential31006cbd's hyper parameters: Current learning rate is 0.008920606601248885. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 607][Wall Clock 73.746638642s] Trained 128 records in 0.101751159 seconds. Throughput is 1257.971 records/second. Loss is 0.77881783. Sequential31006cbd's hyper parameters: Current learning rate is 0.008919015340706386. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17792/60000][Iteration 608][Wall Clock 73.833961322s] Trained 128 records in 0.08732268 seconds. Throughput is 1465.8276 records/second. Loss is 0.82086235. Sequential31006cbd's hyper parameters: Current learning rate is 0.008917424647761726. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 609][Wall Clock 73.934038277s] Trained 128 records in 0.100076955 seconds. Throughput is 1279.0157 records/second. Loss is 0.71482503. Sequential31006cbd's hyper parameters: Current learning rate is 0.00891583452211127. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 18048/60000][Iteration 610][Wall Clock 74.031186143s] Trained 128 records in 0.097147866 seconds. Throughput is 1317.5791 records/second. Loss is 0.74223906. Sequential31006cbd's hyper parameters: Current learning rate is 0.008914244963451596. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:51 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 611][Wall Clock 74.116379626s] Trained 128 records in 0.085193483 seconds. Throughput is 1502.4623 records/second. Loss is 0.70494974. Sequential31006cbd's hyper parameters: Current learning rate is 0.0089126559714795. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 18304/60000][Iteration 612][Wall Clock 74.206662455s] Trained 128 records in 0.090282829 seconds. Throughput is 1417.7668 records/second. Loss is 0.8301238. Sequential31006cbd's hyper parameters: Current learning rate is 0.008911067545891998. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 613][Wall Clock 74.287816573s] Trained 128 records in 0.081154118 seconds. Throughput is 1577.246 records/second. Loss is 0.6159782. Sequential31006cbd's hyper parameters: Current learning rate is 0.008909479686386316. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 18560/60000][Iteration 614][Wall Clock 74.376003838s] Trained 128 records in 0.088187265 seconds. Throughput is 1451.4568 records/second. Loss is 0.7377852. Sequential31006cbd's hyper parameters: Current learning rate is 0.008907892392659897. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 615][Wall Clock 74.480957324s] Trained 128 records in 0.104953486 seconds. Throughput is 1219.5879 records/second. Loss is 0.6940853. Sequential31006cbd's hyper parameters: Current learning rate is 0.008906305664410403. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 18816/60000][Iteration 616][Wall Clock 74.573280809s] Trained 128 records in 0.092323485 seconds. Throughput is 1386.4296 records/second. Loss is 0.7379262. Sequential31006cbd's hyper parameters: Current learning rate is 0.008904719501335707. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 617][Wall Clock 74.663443663s] Trained 128 records in 0.090162854 seconds. Throughput is 1419.6534 records/second. Loss is 0.7059128. Sequential31006cbd's hyper parameters: Current learning rate is 0.008903133903133903. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 19072/60000][Iteration 618][Wall Clock 74.751145565s] Trained 128 records in 0.087701902 seconds. Throughput is 1459.4895 records/second. Loss is 0.67070323. Sequential31006cbd's hyper parameters: Current learning rate is 0.008901548869503294. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 619][Wall Clock 74.834408059s] Trained 128 records in 0.083262494 seconds. Throughput is 1537.3068 records/second. Loss is 0.72710884. Sequential31006cbd's hyper parameters: Current learning rate is 0.0088999644001424. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 19328/60000][Iteration 620][Wall Clock 74.940900267s] Trained 128 records in 0.106492208 seconds. Throughput is 1201.966 records/second. Loss is 0.7001439. Sequential31006cbd's hyper parameters: Current learning rate is 0.008898380494749957. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 621][Wall Clock 75.026882831s] Trained 128 records in 0.085982564 seconds. Throughput is 1488.674 records/second. Loss is 0.6366042. Sequential31006cbd's hyper parameters: Current learning rate is 0.00889679715302491. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:52 INFO  DistriOptimizer$:408 - [Epoch 2 19584/60000][Iteration 622][Wall Clock 75.115201962s] Trained 128 records in 0.088319131 seconds. Throughput is 1449.2897 records/second. Loss is 0.6470853. Sequential31006cbd's hyper parameters: Current learning rate is 0.008895214374666428. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 623][Wall Clock 75.233081402s] Trained 128 records in 0.11787944 seconds. Throughput is 1085.8551 records/second. Loss is 0.6900652. Sequential31006cbd's hyper parameters: Current learning rate is 0.008893632159373888. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 19840/60000][Iteration 624][Wall Clock 75.321590216s] Trained 128 records in 0.088508814 seconds. Throughput is 1446.1836 records/second. Loss is 0.89846164. Sequential31006cbd's hyper parameters: Current learning rate is 0.008892050506846879. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 625][Wall Clock 75.421903809s] Trained 128 records in 0.100313593 seconds. Throughput is 1275.9985 records/second. Loss is 0.79834896. Sequential31006cbd's hyper parameters: Current learning rate is 0.008890469416785207. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20096/60000][Iteration 626][Wall Clock 75.51703893s] Trained 128 records in 0.095135121 seconds. Throughput is 1345.4547 records/second. Loss is 0.7411609. Sequential31006cbd's hyper parameters: Current learning rate is 0.008888888888888889. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 627][Wall Clock 75.622213412s] Trained 128 records in 0.105174482 seconds. Throughput is 1217.0253 records/second. Loss is 0.72981024. Sequential31006cbd's hyper parameters: Current learning rate is 0.00888730892285816. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20352/60000][Iteration 628][Wall Clock 75.738153723s] Trained 128 records in 0.115940311 seconds. Throughput is 1104.0164 records/second. Loss is 0.67101336. Sequential31006cbd's hyper parameters: Current learning rate is 0.00888572951839346. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 629][Wall Clock 75.835202401s] Trained 128 records in 0.097048678 seconds. Throughput is 1318.9258 records/second. Loss is 0.8505408. Sequential31006cbd's hyper parameters: Current learning rate is 0.008884150675195452. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20608/60000][Iteration 630][Wall Clock 75.923195086s] Trained 128 records in 0.087992685 seconds. Throughput is 1454.6664 records/second. Loss is 0.79423714. Sequential31006cbd's hyper parameters: Current learning rate is 0.008882572392965004. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 631][Wall Clock 76.012303271s] Trained 128 records in 0.089108185 seconds. Throughput is 1436.4562 records/second. Loss is 0.6256827. Sequential31006cbd's hyper parameters: Current learning rate is 0.008880994671403198. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:53 INFO  DistriOptimizer$:408 - [Epoch 2 20864/60000][Iteration 632][Wall Clock 76.118171407s] Trained 128 records in 0.105868136 seconds. Throughput is 1209.0511 records/second. Loss is 0.716046. Sequential31006cbd's hyper parameters: Current learning rate is 0.00887941751021133. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 633][Wall Clock 76.221853786s] Trained 128 records in 0.103682379 seconds. Throughput is 1234.5396 records/second. Loss is 0.7437579. Sequential31006cbd's hyper parameters: Current learning rate is 0.008877840909090908. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21120/60000][Iteration 634][Wall Clock 76.314767684s] Trained 128 records in 0.092913898 seconds. Throughput is 1377.6195 records/second. Loss is 0.55518603. Sequential31006cbd's hyper parameters: Current learning rate is 0.008876264867743653. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 635][Wall Clock 76.401420572s] Trained 128 records in 0.086652888 seconds. Throughput is 1477.1578 records/second. Loss is 0.75611806. Sequential31006cbd's hyper parameters: Current learning rate is 0.008874689385871494. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21376/60000][Iteration 636][Wall Clock 76.497692158s] Trained 128 records in 0.096271586 seconds. Throughput is 1329.5719 records/second. Loss is 0.83508694. Sequential31006cbd's hyper parameters: Current learning rate is 0.008873114463176575. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 637][Wall Clock 76.596236149s] Trained 128 records in 0.098543991 seconds. Throughput is 1298.9122 records/second. Loss is 0.75914377. Sequential31006cbd's hyper parameters: Current learning rate is 0.008871540099361249. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21632/60000][Iteration 638][Wall Clock 76.729398598s] Trained 128 records in 0.133162449 seconds. Throughput is 961.23193 records/second. Loss is 0.6816016. Sequential31006cbd's hyper parameters: Current learning rate is 0.008869966294128083. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 639][Wall Clock 76.835583125s] Trained 128 records in 0.106184527 seconds. Throughput is 1205.4487 records/second. Loss is 0.6496067. Sequential31006cbd's hyper parameters: Current learning rate is 0.008868393047179852. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 21888/60000][Iteration 640][Wall Clock 76.962957888s] Trained 128 records in 0.127374763 seconds. Throughput is 1004.90857 records/second. Loss is 0.69947237. Sequential31006cbd's hyper parameters: Current learning rate is 0.008866820358219544. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:54 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 641][Wall Clock 77.087668672s] Trained 128 records in 0.124710784 seconds. Throughput is 1026.3748 records/second. Loss is 0.6864082. Sequential31006cbd's hyper parameters: Current learning rate is 0.008865248226950354. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22144/60000][Iteration 642][Wall Clock 77.197076284s] Trained 128 records in 0.109407612 seconds. Throughput is 1169.9369 records/second. Loss is 0.6986791. Sequential31006cbd's hyper parameters: Current learning rate is 0.008863676653075695. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 643][Wall Clock 77.313578687s] Trained 128 records in 0.116502403 seconds. Throughput is 1098.6898 records/second. Loss is 0.6857028. Sequential31006cbd's hyper parameters: Current learning rate is 0.008862105636299184. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22400/60000][Iteration 644][Wall Clock 77.399869295s] Trained 128 records in 0.086290608 seconds. Throughput is 1483.3596 records/second. Loss is 0.68819433. Sequential31006cbd's hyper parameters: Current learning rate is 0.00886053517632465. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 645][Wall Clock 77.48832617s] Trained 128 records in 0.088456875 seconds. Throughput is 1447.0328 records/second. Loss is 0.71890575. Sequential31006cbd's hyper parameters: Current learning rate is 0.00885896527285613. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22656/60000][Iteration 646][Wall Clock 77.586478339s] Trained 128 records in 0.098152169 seconds. Throughput is 1304.0975 records/second. Loss is 0.6329539. Sequential31006cbd's hyper parameters: Current learning rate is 0.008857395925597875. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 647][Wall Clock 77.681421333s] Trained 128 records in 0.094942994 seconds. Throughput is 1348.1774 records/second. Loss is 0.6337428. Sequential31006cbd's hyper parameters: Current learning rate is 0.00885582713425434. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 22912/60000][Iteration 648][Wall Clock 77.839543289s] Trained 128 records in 0.158121956 seconds. Throughput is 809.5017 records/second. Loss is 0.6112499. Sequential31006cbd's hyper parameters: Current learning rate is 0.008854258898530193. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 649][Wall Clock 77.939957064s] Trained 128 records in 0.100413775 seconds. Throughput is 1274.7255 records/second. Loss is 0.6201937. Sequential31006cbd's hyper parameters: Current learning rate is 0.008852691218130312. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 23168/60000][Iteration 650][Wall Clock 78.039220224s] Trained 128 records in 0.09926316 seconds. Throughput is 1289.5016 records/second. Loss is 0.6731528. Sequential31006cbd's hyper parameters: Current learning rate is 0.008851124092759781. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:55 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 651][Wall Clock 78.135957784s] Trained 128 records in 0.09673756 seconds. Throughput is 1323.1675 records/second. Loss is 0.7875561. Sequential31006cbd's hyper parameters: Current learning rate is 0.008849557522123895. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 23424/60000][Iteration 652][Wall Clock 78.228126327s] Trained 128 records in 0.092168543 seconds. Throughput is 1388.7603 records/second. Loss is 0.68586236. Sequential31006cbd's hyper parameters: Current learning rate is 0.008847991505928153. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 653][Wall Clock 78.330852518s] Trained 128 records in 0.102726191 seconds. Throughput is 1246.0308 records/second. Loss is 0.65208006. Sequential31006cbd's hyper parameters: Current learning rate is 0.008846426043878274. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 23680/60000][Iteration 654][Wall Clock 78.417418714s] Trained 128 records in 0.086566196 seconds. Throughput is 1478.6372 records/second. Loss is 0.81480396. Sequential31006cbd's hyper parameters: Current learning rate is 0.00884486113568017. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 655][Wall Clock 78.512602103s] Trained 128 records in 0.095183389 seconds. Throughput is 1344.7725 records/second. Loss is 0.57315624. Sequential31006cbd's hyper parameters: Current learning rate is 0.008843296781039971. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 23936/60000][Iteration 656][Wall Clock 78.604757293s] Trained 128 records in 0.09215519 seconds. Throughput is 1388.9614 records/second. Loss is 0.7365886. Sequential31006cbd's hyper parameters: Current learning rate is 0.008841732979664015. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 657][Wall Clock 78.708236368s] Trained 128 records in 0.103479075 seconds. Throughput is 1236.9651 records/second. Loss is 0.6351148. Sequential31006cbd's hyper parameters: Current learning rate is 0.00884016973125884. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 24192/60000][Iteration 658][Wall Clock 78.798626437s] Trained 128 records in 0.090390069 seconds. Throughput is 1416.0847 records/second. Loss is 0.6117979. Sequential31006cbd's hyper parameters: Current learning rate is 0.008838607035531201. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 659][Wall Clock 78.885855826s] Trained 128 records in 0.087229389 seconds. Throughput is 1467.3954 records/second. Loss is 0.69109166. Sequential31006cbd's hyper parameters: Current learning rate is 0.008837044892188053. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 24448/60000][Iteration 660][Wall Clock 78.979992527s] Trained 128 records in 0.094136701 seconds. Throughput is 1359.7247 records/second. Loss is 0.57388633. Sequential31006cbd's hyper parameters: Current learning rate is 0.008835483300936562. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:56 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 661][Wall Clock 79.079142998s] Trained 128 records in 0.099150471 seconds. Throughput is 1290.9672 records/second. Loss is 0.6853809. Sequential31006cbd's hyper parameters: Current learning rate is 0.008833922261484098. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 24704/60000][Iteration 662][Wall Clock 79.174261327s] Trained 128 records in 0.095118329 seconds. Throughput is 1345.6923 records/second. Loss is 0.68086785. Sequential31006cbd's hyper parameters: Current learning rate is 0.008832361773538244. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 663][Wall Clock 79.304312142s] Trained 128 records in 0.130050815 seconds. Throughput is 984.2307 records/second. Loss is 0.7047362. Sequential31006cbd's hyper parameters: Current learning rate is 0.008830801836806781. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 24960/60000][Iteration 664][Wall Clock 79.402233018s] Trained 128 records in 0.097920876 seconds. Throughput is 1307.1779 records/second. Loss is 0.68537015. Sequential31006cbd's hyper parameters: Current learning rate is 0.008829242450997704. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 665][Wall Clock 79.505807977s] Trained 128 records in 0.103574959 seconds. Throughput is 1235.82 records/second. Loss is 0.5472973. Sequential31006cbd's hyper parameters: Current learning rate is 0.00882768361581921. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25216/60000][Iteration 666][Wall Clock 79.623827789s] Trained 128 records in 0.118019812 seconds. Throughput is 1084.5637 records/second. Loss is 0.69110954. Sequential31006cbd's hyper parameters: Current learning rate is 0.008826125330979701. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 667][Wall Clock 79.745268022s] Trained 128 records in 0.121440233 seconds. Throughput is 1054.0165 records/second. Loss is 0.71044177. Sequential31006cbd's hyper parameters: Current learning rate is 0.008824567596187787. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25472/60000][Iteration 668][Wall Clock 79.870128066s] Trained 128 records in 0.124860044 seconds. Throughput is 1025.1478 records/second. Loss is 0.5873776. Sequential31006cbd's hyper parameters: Current learning rate is 0.008823010411152285. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 669][Wall Clock 79.973680184s] Trained 128 records in 0.103552118 seconds. Throughput is 1236.0925 records/second. Loss is 0.816477. Sequential31006cbd's hyper parameters: Current learning rate is 0.008821453775582216. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25728/60000][Iteration 670][Wall Clock 80.063842981s] Trained 128 records in 0.090162797 seconds. Throughput is 1419.6543 records/second. Loss is 0.64824986. Sequential31006cbd's hyper parameters: Current learning rate is 0.008819897689186807. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:57 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 671][Wall Clock 80.162066396s] Trained 128 records in 0.098223415 seconds. Throughput is 1303.1516 records/second. Loss is 0.6200368. Sequential31006cbd's hyper parameters: Current learning rate is 0.008818342151675486. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 25984/60000][Iteration 672][Wall Clock 80.293174957s] Trained 128 records in 0.131108561 seconds. Throughput is 976.2901 records/second. Loss is 0.63151187. Sequential31006cbd's hyper parameters: Current learning rate is 0.00881678716275789. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 673][Wall Clock 80.422541782s] Trained 128 records in 0.129366825 seconds. Throughput is 989.43445 records/second. Loss is 0.7707396. Sequential31006cbd's hyper parameters: Current learning rate is 0.008815232722143865. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26240/60000][Iteration 674][Wall Clock 80.548804837s] Trained 128 records in 0.126263055 seconds. Throughput is 1013.7566 records/second. Loss is 0.57952964. Sequential31006cbd's hyper parameters: Current learning rate is 0.008813678829543451. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 675][Wall Clock 80.63746473s] Trained 128 records in 0.088659893 seconds. Throughput is 1443.7194 records/second. Loss is 0.58883923. Sequential31006cbd's hyper parameters: Current learning rate is 0.008812125484666901. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26496/60000][Iteration 676][Wall Clock 80.757847424s] Trained 128 records in 0.120382694 seconds. Throughput is 1063.2758 records/second. Loss is 0.6784228. Sequential31006cbd's hyper parameters: Current learning rate is 0.00881057268722467. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 677][Wall Clock 80.886874867s] Trained 128 records in 0.129027443 seconds. Throughput is 992.03705 records/second. Loss is 0.5845661. Sequential31006cbd's hyper parameters: Current learning rate is 0.008809020436927413. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26752/60000][Iteration 678][Wall Clock 80.990653644s] Trained 128 records in 0.103778777 seconds. Throughput is 1233.3928 records/second. Loss is 0.577233. Sequential31006cbd's hyper parameters: Current learning rate is 0.008807468733485996. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:58 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 679][Wall Clock 81.132507815s] Trained 128 records in 0.141854171 seconds. Throughput is 902.33514 records/second. Loss is 0.586047. Sequential31006cbd's hyper parameters: Current learning rate is 0.008805917576611484. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27008/60000][Iteration 680][Wall Clock 81.243381269s] Trained 128 records in 0.110873454 seconds. Throughput is 1154.4694 records/second. Loss is 0.69453025. Sequential31006cbd's hyper parameters: Current learning rate is 0.008804366966015144. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 681][Wall Clock 81.354144769s] Trained 128 records in 0.1107635 seconds. Throughput is 1155.6154 records/second. Loss is 0.6103262. Sequential31006cbd's hyper parameters: Current learning rate is 0.00880281690140845. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27264/60000][Iteration 682][Wall Clock 81.46166598s] Trained 128 records in 0.107521211 seconds. Throughput is 1190.4628 records/second. Loss is 0.6078185. Sequential31006cbd's hyper parameters: Current learning rate is 0.00880126738250308. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 683][Wall Clock 81.546980149s] Trained 128 records in 0.085314169 seconds. Throughput is 1500.3369 records/second. Loss is 0.5939779. Sequential31006cbd's hyper parameters: Current learning rate is 0.008799718409010912. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27520/60000][Iteration 684][Wall Clock 81.646407073s] Trained 128 records in 0.099426924 seconds. Throughput is 1287.3777 records/second. Loss is 0.76078117. Sequential31006cbd's hyper parameters: Current learning rate is 0.008798169980644026. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 685][Wall Clock 81.760839016s] Trained 128 records in 0.114431943 seconds. Throughput is 1118.5688 records/second. Loss is 0.6623229. Sequential31006cbd's hyper parameters: Current learning rate is 0.008796622097114707. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27776/60000][Iteration 686][Wall Clock 81.872620644s] Trained 128 records in 0.111781628 seconds. Throughput is 1145.0898 records/second. Loss is 0.6718111. Sequential31006cbd's hyper parameters: Current learning rate is 0.008795074758135445. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 687][Wall Clock 81.957347298s] Trained 128 records in 0.084726654 seconds. Throughput is 1510.7406 records/second. Loss is 0.5373616. Sequential31006cbd's hyper parameters: Current learning rate is 0.008793527963418923. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 28032/60000][Iteration 688][Wall Clock 82.044012209s] Trained 128 records in 0.086664911 seconds. Throughput is 1476.953 records/second. Loss is 0.6321327. Sequential31006cbd's hyper parameters: Current learning rate is 0.008791981712678039. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:58:59 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 689][Wall Clock 82.135482178s] Trained 128 records in 0.091469969 seconds. Throughput is 1399.3665 records/second. Loss is 0.5824959. Sequential31006cbd's hyper parameters: Current learning rate is 0.00879043600562588. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 28288/60000][Iteration 690][Wall Clock 82.220014138s] Trained 128 records in 0.08453196 seconds. Throughput is 1514.2201 records/second. Loss is 0.70114034. Sequential31006cbd's hyper parameters: Current learning rate is 0.008788890841975743. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 691][Wall Clock 82.339368223s] Trained 128 records in 0.119354085 seconds. Throughput is 1072.4392 records/second. Loss is 0.56361985. Sequential31006cbd's hyper parameters: Current learning rate is 0.008787346221441126. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 28544/60000][Iteration 692][Wall Clock 82.425002782s] Trained 128 records in 0.085634559 seconds. Throughput is 1494.7236 records/second. Loss is 0.6783905. Sequential31006cbd's hyper parameters: Current learning rate is 0.008785802143735722. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 693][Wall Clock 82.544391871s] Trained 128 records in 0.119389089 seconds. Throughput is 1072.1248 records/second. Loss is 0.6771736. Sequential31006cbd's hyper parameters: Current learning rate is 0.008784258608573436. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 28800/60000][Iteration 694][Wall Clock 82.662898003s] Trained 128 records in 0.118506132 seconds. Throughput is 1080.1129 records/second. Loss is 0.5818097. Sequential31006cbd's hyper parameters: Current learning rate is 0.008782715615668365. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 695][Wall Clock 82.773351886s] Trained 128 records in 0.110453883 seconds. Throughput is 1158.8547 records/second. Loss is 0.73361135. Sequential31006cbd's hyper parameters: Current learning rate is 0.008781173164734809. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 29056/60000][Iteration 696][Wall Clock 82.863559603s] Trained 128 records in 0.090207717 seconds. Throughput is 1418.9473 records/second. Loss is 0.681421. Sequential31006cbd's hyper parameters: Current learning rate is 0.00877963125548727. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 697][Wall Clock 82.953461887s] Trained 128 records in 0.089902284 seconds. Throughput is 1423.7681 records/second. Loss is 0.6815905. Sequential31006cbd's hyper parameters: Current learning rate is 0.00877808988764045. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:00 INFO  DistriOptimizer$:408 - [Epoch 2 29312/60000][Iteration 698][Wall Clock 83.061179218s] Trained 128 records in 0.107717331 seconds. Throughput is 1188.2954 records/second. Loss is 0.6431617. Sequential31006cbd's hyper parameters: Current learning rate is 0.008776549060909251. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 699][Wall Clock 83.215565584s] Trained 128 records in 0.154386366 seconds. Throughput is 829.08875 records/second. Loss is 0.59564203. Sequential31006cbd's hyper parameters: Current learning rate is 0.008775008775008775. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 29568/60000][Iteration 700][Wall Clock 83.335412348s] Trained 128 records in 0.119846764 seconds. Throughput is 1068.0305 records/second. Loss is 0.6320277. Sequential31006cbd's hyper parameters: Current learning rate is 0.008773469029654327. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 701][Wall Clock 83.439902651s] Trained 128 records in 0.104490303 seconds. Throughput is 1224.994 records/second. Loss is 0.6404821. Sequential31006cbd's hyper parameters: Current learning rate is 0.008771929824561403. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 29824/60000][Iteration 702][Wall Clock 83.530088749s] Trained 128 records in 0.090186098 seconds. Throughput is 1419.2875 records/second. Loss is 0.70521. Sequential31006cbd's hyper parameters: Current learning rate is 0.00877039115944571. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 703][Wall Clock 83.630297114s] Trained 128 records in 0.100208365 seconds. Throughput is 1277.3385 records/second. Loss is 0.59704894. Sequential31006cbd's hyper parameters: Current learning rate is 0.008768853034023149. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 30080/60000][Iteration 704][Wall Clock 83.712922734s] Trained 128 records in 0.08262562 seconds. Throughput is 1549.1562 records/second. Loss is 0.6154386. Sequential31006cbd's hyper parameters: Current learning rate is 0.00876731544800982. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 705][Wall Clock 83.797517315s] Trained 128 records in 0.084594581 seconds. Throughput is 1513.0994 records/second. Loss is 0.6546402. Sequential31006cbd's hyper parameters: Current learning rate is 0.00876577840112202. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 30336/60000][Iteration 706][Wall Clock 83.896636913s] Trained 128 records in 0.099119598 seconds. Throughput is 1291.3693 records/second. Loss is 0.6825052. Sequential31006cbd's hyper parameters: Current learning rate is 0.008764241893076249. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 707][Wall Clock 83.989181634s] Trained 128 records in 0.092544721 seconds. Throughput is 1383.1151 records/second. Loss is 0.6339318. Sequential31006cbd's hyper parameters: Current learning rate is 0.008762705923589204. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:01 INFO  DistriOptimizer$:408 - [Epoch 2 30592/60000][Iteration 708][Wall Clock 84.07409102s] Trained 128 records in 0.084909386 seconds. Throughput is 1507.4894 records/second. Loss is 0.7092946. Sequential31006cbd's hyper parameters: Current learning rate is 0.008761170492377781. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 709][Wall Clock 84.166441732s] Trained 128 records in 0.092350712 seconds. Throughput is 1386.0206 records/second. Loss is 0.5974238. Sequential31006cbd's hyper parameters: Current learning rate is 0.008759635599159075. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 30848/60000][Iteration 710][Wall Clock 84.251667391s] Trained 128 records in 0.085225659 seconds. Throughput is 1501.8951 records/second. Loss is 0.6014678. Sequential31006cbd's hyper parameters: Current learning rate is 0.008758101243650377. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 711][Wall Clock 84.342476243s] Trained 128 records in 0.090808852 seconds. Throughput is 1409.5542 records/second. Loss is 0.5867759. Sequential31006cbd's hyper parameters: Current learning rate is 0.008756567425569177. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31104/60000][Iteration 712][Wall Clock 84.467601901s] Trained 128 records in 0.125125658 seconds. Throughput is 1022.9716 records/second. Loss is 0.5538569. Sequential31006cbd's hyper parameters: Current learning rate is 0.008755034144633165. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 713][Wall Clock 84.556964047s] Trained 128 records in 0.089362146 seconds. Throughput is 1432.3739 records/second. Loss is 0.55145943. Sequential31006cbd's hyper parameters: Current learning rate is 0.008753501400560224. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31360/60000][Iteration 714][Wall Clock 84.651617806s] Trained 128 records in 0.094653759 seconds. Throughput is 1352.2971 records/second. Loss is 0.6501711. Sequential31006cbd's hyper parameters: Current learning rate is 0.00875196919306844. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 715][Wall Clock 84.74718486s] Trained 128 records in 0.095567054 seconds. Throughput is 1339.3737 records/second. Loss is 0.6132396. Sequential31006cbd's hyper parameters: Current learning rate is 0.008750437521876094. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31616/60000][Iteration 716][Wall Clock 84.892645135s] Trained 128 records in 0.145460275 seconds. Throughput is 879.96533 records/second. Loss is 0.7510538. Sequential31006cbd's hyper parameters: Current learning rate is 0.008748906386701663. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 717][Wall Clock 85.019959862s] Trained 128 records in 0.127314727 seconds. Throughput is 1005.38245 records/second. Loss is 0.7028872. Sequential31006cbd's hyper parameters: Current learning rate is 0.008747375787263822. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:02 INFO  DistriOptimizer$:408 - [Epoch 2 31872/60000][Iteration 718][Wall Clock 85.138794459s] Trained 128 records in 0.118834597 seconds. Throughput is 1077.1273 records/second. Loss is 0.5774885. Sequential31006cbd's hyper parameters: Current learning rate is 0.008745845723281442. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 719][Wall Clock 85.237902955s] Trained 128 records in 0.099108496 seconds. Throughput is 1291.5139 records/second. Loss is 0.61192375. Sequential31006cbd's hyper parameters: Current learning rate is 0.008744316194473592. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32128/60000][Iteration 720][Wall Clock 85.348627497s] Trained 128 records in 0.110724542 seconds. Throughput is 1156.022 records/second. Loss is 0.55076486. Sequential31006cbd's hyper parameters: Current learning rate is 0.00874278720055954. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 721][Wall Clock 85.452469308s] Trained 128 records in 0.103841811 seconds. Throughput is 1232.6442 records/second. Loss is 0.63550425. Sequential31006cbd's hyper parameters: Current learning rate is 0.00874125874125874. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32384/60000][Iteration 722][Wall Clock 85.560554523s] Trained 128 records in 0.108085215 seconds. Throughput is 1184.2507 records/second. Loss is 0.6307894. Sequential31006cbd's hyper parameters: Current learning rate is 0.008739730816290857. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 723][Wall Clock 85.677406664s] Trained 128 records in 0.116852141 seconds. Throughput is 1095.4014 records/second. Loss is 0.70517606. Sequential31006cbd's hyper parameters: Current learning rate is 0.008738203425375742. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32640/60000][Iteration 724][Wall Clock 85.831817525s] Trained 128 records in 0.154410861 seconds. Throughput is 828.9573 records/second. Loss is 0.67816186. Sequential31006cbd's hyper parameters: Current learning rate is 0.008736676568233443. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 725][Wall Clock 85.975603186s] Trained 128 records in 0.143785661 seconds. Throughput is 890.214 records/second. Loss is 0.5774171. Sequential31006cbd's hyper parameters: Current learning rate is 0.008735150244584206. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:03 INFO  DistriOptimizer$:408 - [Epoch 2 32896/60000][Iteration 726][Wall Clock 86.084408356s] Trained 128 records in 0.10880517 seconds. Throughput is 1176.4147 records/second. Loss is 0.67541265. Sequential31006cbd's hyper parameters: Current learning rate is 0.008733624454148471. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 727][Wall Clock 86.167830307s] Trained 128 records in 0.083421951 seconds. Throughput is 1534.3683 records/second. Loss is 0.6321854. Sequential31006cbd's hyper parameters: Current learning rate is 0.008732099196646874. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33152/60000][Iteration 728][Wall Clock 86.256905311s] Trained 128 records in 0.089075004 seconds. Throughput is 1436.9912 records/second. Loss is 0.69364345. Sequential31006cbd's hyper parameters: Current learning rate is 0.008730574471800244. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 729][Wall Clock 86.336777978s] Trained 128 records in 0.079872667 seconds. Throughput is 1602.5507 records/second. Loss is 0.6420503. Sequential31006cbd's hyper parameters: Current learning rate is 0.00872905027932961. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33408/60000][Iteration 730][Wall Clock 86.420063658s] Trained 128 records in 0.08328568 seconds. Throughput is 1536.8788 records/second. Loss is 0.61072767. Sequential31006cbd's hyper parameters: Current learning rate is 0.008727526618956188. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 731][Wall Clock 86.505885571s] Trained 128 records in 0.085821913 seconds. Throughput is 1491.4606 records/second. Loss is 0.6632535. Sequential31006cbd's hyper parameters: Current learning rate is 0.008726003490401398. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33664/60000][Iteration 732][Wall Clock 86.592647815s] Trained 128 records in 0.086762244 seconds. Throughput is 1475.2961 records/second. Loss is 0.63649654. Sequential31006cbd's hyper parameters: Current learning rate is 0.008724480893386845. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 733][Wall Clock 86.674464619s] Trained 128 records in 0.081816804 seconds. Throughput is 1564.4707 records/second. Loss is 0.55483615. Sequential31006cbd's hyper parameters: Current learning rate is 0.008722958827634334. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 33920/60000][Iteration 734][Wall Clock 86.765706443s] Trained 128 records in 0.091241824 seconds. Throughput is 1402.8655 records/second. Loss is 0.6957719. Sequential31006cbd's hyper parameters: Current learning rate is 0.008721437292865864. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 735][Wall Clock 86.86304946s] Trained 128 records in 0.097343017 seconds. Throughput is 1314.9376 records/second. Loss is 0.69030076. Sequential31006cbd's hyper parameters: Current learning rate is 0.008719916288803628. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 34176/60000][Iteration 736][Wall Clock 86.976839079s] Trained 128 records in 0.113789619 seconds. Throughput is 1124.8829 records/second. Loss is 0.5955069. Sequential31006cbd's hyper parameters: Current learning rate is 0.008718395815170008. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:04 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 737][Wall Clock 87.073223124s] Trained 128 records in 0.096384045 seconds. Throughput is 1328.0206 records/second. Loss is 0.57879555. Sequential31006cbd's hyper parameters: Current learning rate is 0.008716875871687587. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 34432/60000][Iteration 738][Wall Clock 87.159108817s] Trained 128 records in 0.085885693 seconds. Throughput is 1490.3529 records/second. Loss is 0.602989. Sequential31006cbd's hyper parameters: Current learning rate is 0.008715356458079136. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 739][Wall Clock 87.241939317s] Trained 128 records in 0.0828305 seconds. Throughput is 1545.3245 records/second. Loss is 0.6097981. Sequential31006cbd's hyper parameters: Current learning rate is 0.00871383757406762. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 34688/60000][Iteration 740][Wall Clock 87.322407966s] Trained 128 records in 0.080468649 seconds. Throughput is 1590.6816 records/second. Loss is 0.71902734. Sequential31006cbd's hyper parameters: Current learning rate is 0.008712319219376199. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 741][Wall Clock 87.414937331s] Trained 128 records in 0.092529365 seconds. Throughput is 1383.3446 records/second. Loss is 0.61467844. Sequential31006cbd's hyper parameters: Current learning rate is 0.008710801393728223. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 34944/60000][Iteration 742][Wall Clock 87.544980495s] Trained 128 records in 0.130043164 seconds. Throughput is 984.2886 records/second. Loss is 0.72726023. Sequential31006cbd's hyper parameters: Current learning rate is 0.008709284096847238. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 743][Wall Clock 87.63911423s] Trained 128 records in 0.094133735 seconds. Throughput is 1359.7676 records/second. Loss is 0.655738. Sequential31006cbd's hyper parameters: Current learning rate is 0.008707767328456984. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 35200/60000][Iteration 744][Wall Clock 87.76195488s] Trained 128 records in 0.12284065 seconds. Throughput is 1042.0004 records/second. Loss is 0.5933118. Sequential31006cbd's hyper parameters: Current learning rate is 0.008706251088281386. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 745][Wall Clock 87.862643359s] Trained 128 records in 0.100688479 seconds. Throughput is 1271.2477 records/second. Loss is 0.6166645. Sequential31006cbd's hyper parameters: Current learning rate is 0.008704735376044569. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 35456/60000][Iteration 746][Wall Clock 87.968402679s] Trained 128 records in 0.10575932 seconds. Throughput is 1210.2952 records/second. Loss is 0.57696885. Sequential31006cbd's hyper parameters: Current learning rate is 0.008703220191470844. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:05 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 747][Wall Clock 88.067776924s] Trained 128 records in 0.099374245 seconds. Throughput is 1288.0602 records/second. Loss is 0.62030995. Sequential31006cbd's hyper parameters: Current learning rate is 0.00870170553428472. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 35712/60000][Iteration 748][Wall Clock 88.161972698s] Trained 128 records in 0.094195774 seconds. Throughput is 1358.872 records/second. Loss is 0.64950764. Sequential31006cbd's hyper parameters: Current learning rate is 0.008700191404210893. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 749][Wall Clock 88.257954778s] Trained 128 records in 0.09598208 seconds. Throughput is 1333.5823 records/second. Loss is 0.5780875. Sequential31006cbd's hyper parameters: Current learning rate is 0.008698677800974252. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 35968/60000][Iteration 750][Wall Clock 88.380909713s] Trained 128 records in 0.122954935 seconds. Throughput is 1041.0319 records/second. Loss is 0.69685316. Sequential31006cbd's hyper parameters: Current learning rate is 0.008697164724299879. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 751][Wall Clock 88.470721445s] Trained 128 records in 0.089811732 seconds. Throughput is 1425.2035 records/second. Loss is 0.5126826. Sequential31006cbd's hyper parameters: Current learning rate is 0.008695652173913044. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36224/60000][Iteration 752][Wall Clock 88.557900613s] Trained 128 records in 0.087179168 seconds. Throughput is 1468.2406 records/second. Loss is 0.56204975. Sequential31006cbd's hyper parameters: Current learning rate is 0.008694140149539212. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 753][Wall Clock 88.664916364s] Trained 128 records in 0.107015751 seconds. Throughput is 1196.0856 records/second. Loss is 0.5819842. Sequential31006cbd's hyper parameters: Current learning rate is 0.008692628650904033. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36480/60000][Iteration 754][Wall Clock 88.748427805s] Trained 128 records in 0.083511441 seconds. Throughput is 1532.7241 records/second. Loss is 0.64244264. Sequential31006cbd's hyper parameters: Current learning rate is 0.008691117677733355. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 755][Wall Clock 88.855089449s] Trained 128 records in 0.106661644 seconds. Throughput is 1200.0565 records/second. Loss is 0.6712317. Sequential31006cbd's hyper parameters: Current learning rate is 0.008689607229753215. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36736/60000][Iteration 756][Wall Clock 88.951842757s] Trained 128 records in 0.096753308 seconds. Throughput is 1322.9521 records/second. Loss is 0.6079779. Sequential31006cbd's hyper parameters: Current learning rate is 0.008688097306689836. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:06 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 757][Wall Clock 89.045177431s] Trained 128 records in 0.093334674 seconds. Throughput is 1371.4088 records/second. Loss is 0.73383987. Sequential31006cbd's hyper parameters: Current learning rate is 0.008686587908269632. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 36992/60000][Iteration 758][Wall Clock 89.124222872s] Trained 128 records in 0.079045441 seconds. Throughput is 1619.3218 records/second. Loss is 0.5938589. Sequential31006cbd's hyper parameters: Current learning rate is 0.008685079034219213. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 759][Wall Clock 89.213195244s] Trained 128 records in 0.088972372 seconds. Throughput is 1438.6488 records/second. Loss is 0.66473246. Sequential31006cbd's hyper parameters: Current learning rate is 0.00868357068426537. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37248/60000][Iteration 760][Wall Clock 89.301588923s] Trained 128 records in 0.088393679 seconds. Throughput is 1448.0673 records/second. Loss is 0.66520876. Sequential31006cbd's hyper parameters: Current learning rate is 0.008682062858135093. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 761][Wall Clock 89.39075813s] Trained 128 records in 0.089169207 seconds. Throughput is 1435.4731 records/second. Loss is 0.5985812. Sequential31006cbd's hyper parameters: Current learning rate is 0.008680555555555556. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37504/60000][Iteration 762][Wall Clock 89.475920638s] Trained 128 records in 0.085162508 seconds. Throughput is 1503.0089 records/second. Loss is 0.5984184. Sequential31006cbd's hyper parameters: Current learning rate is 0.008679048776254122. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 763][Wall Clock 89.565084184s] Trained 128 records in 0.089163546 seconds. Throughput is 1435.5642 records/second. Loss is 0.68214834. Sequential31006cbd's hyper parameters: Current learning rate is 0.008677542519958347. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37760/60000][Iteration 764][Wall Clock 89.649735784s] Trained 128 records in 0.0846516 seconds. Throughput is 1512.0802 records/second. Loss is 0.5355083. Sequential31006cbd's hyper parameters: Current learning rate is 0.008676036786395974. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 765][Wall Clock 89.735109107s] Trained 128 records in 0.085373323 seconds. Throughput is 1499.2975 records/second. Loss is 0.56689376. Sequential31006cbd's hyper parameters: Current learning rate is 0.008674531575294934. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 38016/60000][Iteration 766][Wall Clock 89.825890514s] Trained 128 records in 0.090781407 seconds. Throughput is 1409.9803 records/second. Loss is 0.6519952. Sequential31006cbd's hyper parameters: Current learning rate is 0.008673026886383347. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 767][Wall Clock 89.939347671s] Trained 128 records in 0.113457157 seconds. Throughput is 1128.1792 records/second. Loss is 0.68772686. Sequential31006cbd's hyper parameters: Current learning rate is 0.008671522719389525. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 38272/60000][Iteration 768][Wall Clock 90.029440732s] Trained 128 records in 0.090093061 seconds. Throughput is 1420.7532 records/second. Loss is 0.6149767. Sequential31006cbd's hyper parameters: Current learning rate is 0.008670019074041963. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:07 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 769][Wall Clock 90.116037151s] Trained 128 records in 0.086596419 seconds. Throughput is 1478.1211 records/second. Loss is 0.6498688. Sequential31006cbd's hyper parameters: Current learning rate is 0.00866851595006935. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 38528/60000][Iteration 770][Wall Clock 90.210753672s] Trained 128 records in 0.094716521 seconds. Throughput is 1351.401 records/second. Loss is 0.63378394. Sequential31006cbd's hyper parameters: Current learning rate is 0.008667013347200556. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 771][Wall Clock 90.303879326s] Trained 128 records in 0.093125654 seconds. Throughput is 1374.4869 records/second. Loss is 0.6185396. Sequential31006cbd's hyper parameters: Current learning rate is 0.008665511265164646. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 38784/60000][Iteration 772][Wall Clock 90.406576838s] Trained 128 records in 0.102697512 seconds. Throughput is 1246.3788 records/second. Loss is 0.5962645. Sequential31006cbd's hyper parameters: Current learning rate is 0.00866400970369087. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 773][Wall Clock 90.513994005s] Trained 128 records in 0.107417167 seconds. Throughput is 1191.6158 records/second. Loss is 0.6886304. Sequential31006cbd's hyper parameters: Current learning rate is 0.008662508662508662. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 39040/60000][Iteration 774][Wall Clock 90.621098277s] Trained 128 records in 0.107104272 seconds. Throughput is 1195.097 records/second. Loss is 0.6166734. Sequential31006cbd's hyper parameters: Current learning rate is 0.008661008141347652. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 775][Wall Clock 90.742077867s] Trained 128 records in 0.12097959 seconds. Throughput is 1058.0297 records/second. Loss is 0.5060307. Sequential31006cbd's hyper parameters: Current learning rate is 0.008659508139937652. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 39296/60000][Iteration 776][Wall Clock 90.843971845s] Trained 128 records in 0.101893978 seconds. Throughput is 1256.2078 records/second. Loss is 0.5488693. Sequential31006cbd's hyper parameters: Current learning rate is 0.008658008658008658. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 777][Wall Clock 90.960046388s] Trained 128 records in 0.116074543 seconds. Throughput is 1102.7396 records/second. Loss is 0.5076029. Sequential31006cbd's hyper parameters: Current learning rate is 0.00865650969529086. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:08 INFO  DistriOptimizer$:408 - [Epoch 2 39552/60000][Iteration 778][Wall Clock 91.048448264s] Trained 128 records in 0.088401876 seconds. Throughput is 1447.9331 records/second. Loss is 0.6162268. Sequential31006cbd's hyper parameters: Current learning rate is 0.008655011251514627. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 779][Wall Clock 91.130859971s] Trained 128 records in 0.082411707 seconds. Throughput is 1553.1774 records/second. Loss is 0.7017266. Sequential31006cbd's hyper parameters: Current learning rate is 0.008653513326410523. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 39808/60000][Iteration 780][Wall Clock 91.211873194s] Trained 128 records in 0.081013223 seconds. Throughput is 1579.9889 records/second. Loss is 0.6885258. Sequential31006cbd's hyper parameters: Current learning rate is 0.008652015919709292. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 781][Wall Clock 91.302107503s] Trained 128 records in 0.090234309 seconds. Throughput is 1418.5292 records/second. Loss is 0.58523035. Sequential31006cbd's hyper parameters: Current learning rate is 0.00865051903114187. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40064/60000][Iteration 782][Wall Clock 91.39736845s] Trained 128 records in 0.095260947 seconds. Throughput is 1343.6776 records/second. Loss is 0.57479846. Sequential31006cbd's hyper parameters: Current learning rate is 0.008649022660439369. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 783][Wall Clock 91.487186403s] Trained 128 records in 0.089817953 seconds. Throughput is 1425.1047 records/second. Loss is 0.61789. Sequential31006cbd's hyper parameters: Current learning rate is 0.008647526807333102. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40320/60000][Iteration 784][Wall Clock 91.568582782s] Trained 128 records in 0.081396379 seconds. Throughput is 1572.5515 records/second. Loss is 0.59138644. Sequential31006cbd's hyper parameters: Current learning rate is 0.008646031471554556. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 785][Wall Clock 91.656880676s] Trained 128 records in 0.088297894 seconds. Throughput is 1449.6382 records/second. Loss is 0.52204114. Sequential31006cbd's hyper parameters: Current learning rate is 0.008644536652835409. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40576/60000][Iteration 786][Wall Clock 91.736855654s] Trained 128 records in 0.079974978 seconds. Throughput is 1600.5006 records/second. Loss is 0.53243357. Sequential31006cbd's hyper parameters: Current learning rate is 0.00864304235090752. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 787][Wall Clock 91.820417586s] Trained 128 records in 0.083561932 seconds. Throughput is 1531.798 records/second. Loss is 0.49103782. Sequential31006cbd's hyper parameters: Current learning rate is 0.008641548565502939. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40832/60000][Iteration 788][Wall Clock 91.9027283s] Trained 128 records in 0.082310714 seconds. Throughput is 1555.0831 records/second. Loss is 0.604892. Sequential31006cbd's hyper parameters: Current learning rate is 0.008640055296353897. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 789][Wall Clock 91.988798569s] Trained 128 records in 0.086070269 seconds. Throughput is 1487.157 records/second. Loss is 0.55680025. Sequential31006cbd's hyper parameters: Current learning rate is 0.008638562543192813. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:09 INFO  DistriOptimizer$:408 - [Epoch 2 41088/60000][Iteration 790][Wall Clock 92.070179191s] Trained 128 records in 0.081380622 seconds. Throughput is 1572.8561 records/second. Loss is 0.5538835. Sequential31006cbd's hyper parameters: Current learning rate is 0.00863707030575229. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 791][Wall Clock 92.158538847s] Trained 128 records in 0.088359656 seconds. Throughput is 1448.625 records/second. Loss is 0.6800778. Sequential31006cbd's hyper parameters: Current learning rate is 0.008635578583765112. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41344/60000][Iteration 792][Wall Clock 92.267714592s] Trained 128 records in 0.109175745 seconds. Throughput is 1172.4216 records/second. Loss is 0.5205922. Sequential31006cbd's hyper parameters: Current learning rate is 0.008634087376964255. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 793][Wall Clock 92.358365206s] Trained 128 records in 0.090650614 seconds. Throughput is 1412.0148 records/second. Loss is 0.6932969. Sequential31006cbd's hyper parameters: Current learning rate is 0.008632596685082872. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41600/60000][Iteration 794][Wall Clock 92.472173347s] Trained 128 records in 0.113808141 seconds. Throughput is 1124.6998 records/second. Loss is 0.52872753. Sequential31006cbd's hyper parameters: Current learning rate is 0.008631106507854307. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 795][Wall Clock 92.596240752s] Trained 128 records in 0.124067405 seconds. Throughput is 1031.6973 records/second. Loss is 0.56327367. Sequential31006cbd's hyper parameters: Current learning rate is 0.00862961684501208. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41856/60000][Iteration 796][Wall Clock 92.692777904s] Trained 128 records in 0.096537152 seconds. Throughput is 1325.9144 records/second. Loss is 0.64114237. Sequential31006cbd's hyper parameters: Current learning rate is 0.008628127696289905. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 797][Wall Clock 92.788281176s] Trained 128 records in 0.095503272 seconds. Throughput is 1340.2682 records/second. Loss is 0.6634237. Sequential31006cbd's hyper parameters: Current learning rate is 0.00862663906142167. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 42112/60000][Iteration 798][Wall Clock 92.895458052s] Trained 128 records in 0.107176876 seconds. Throughput is 1194.2875 records/second. Loss is 0.628062. Sequential31006cbd's hyper parameters: Current learning rate is 0.008625150940141452. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:10 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 799][Wall Clock 93.003547627s] Trained 128 records in 0.108089575 seconds. Throughput is 1184.203 records/second. Loss is 0.6518468. Sequential31006cbd's hyper parameters: Current learning rate is 0.008623663332183512. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 42368/60000][Iteration 800][Wall Clock 93.133528047s] Trained 128 records in 0.12998042 seconds. Throughput is 984.76373 records/second. Loss is 0.7523565. Sequential31006cbd's hyper parameters: Current learning rate is 0.00862217623728229. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 801][Wall Clock 93.241469732s] Trained 128 records in 0.107941685 seconds. Throughput is 1185.8254 records/second. Loss is 0.5664419. Sequential31006cbd's hyper parameters: Current learning rate is 0.008620689655172415. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 42624/60000][Iteration 802][Wall Clock 93.365769107s] Trained 128 records in 0.124299375 seconds. Throughput is 1029.7719 records/second. Loss is 0.6193987. Sequential31006cbd's hyper parameters: Current learning rate is 0.008619203585588691. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 803][Wall Clock 93.479186858s] Trained 128 records in 0.113417751 seconds. Throughput is 1128.5712 records/second. Loss is 0.58915854. Sequential31006cbd's hyper parameters: Current learning rate is 0.008617718028266115. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 42880/60000][Iteration 804][Wall Clock 93.582151239s] Trained 128 records in 0.102964381 seconds. Throughput is 1243.1483 records/second. Loss is 0.43081883. Sequential31006cbd's hyper parameters: Current learning rate is 0.008616232982939858. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 805][Wall Clock 93.687052076s] Trained 128 records in 0.104900837 seconds. Throughput is 1220.2 records/second. Loss is 0.56291837. Sequential31006cbd's hyper parameters: Current learning rate is 0.008614748449345278. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 43136/60000][Iteration 806][Wall Clock 93.790612982s] Trained 128 records in 0.103560906 seconds. Throughput is 1235.9875 records/second. Loss is 0.55994534. Sequential31006cbd's hyper parameters: Current learning rate is 0.008613264427217916. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 807][Wall Clock 93.912226445s] Trained 128 records in 0.121613463 seconds. Throughput is 1052.515 records/second. Loss is 0.47683054. Sequential31006cbd's hyper parameters: Current learning rate is 0.00861178091629349. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:11 INFO  DistriOptimizer$:408 - [Epoch 2 43392/60000][Iteration 808][Wall Clock 94.050176768s] Trained 128 records in 0.137950323 seconds. Throughput is 927.8703 records/second. Loss is 0.6153221. Sequential31006cbd's hyper parameters: Current learning rate is 0.008610297916307904. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 809][Wall Clock 94.157440352s] Trained 128 records in 0.107263584 seconds. Throughput is 1193.322 records/second. Loss is 0.5413517. Sequential31006cbd's hyper parameters: Current learning rate is 0.008608815426997245. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 43648/60000][Iteration 810][Wall Clock 94.248210767s] Trained 128 records in 0.090770415 seconds. Throughput is 1410.1511 records/second. Loss is 0.4931243. Sequential31006cbd's hyper parameters: Current learning rate is 0.00860733344809778. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 811][Wall Clock 94.351688292s] Trained 128 records in 0.103477525 seconds. Throughput is 1236.9836 records/second. Loss is 0.54084826. Sequential31006cbd's hyper parameters: Current learning rate is 0.008605851979345956. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 43904/60000][Iteration 812][Wall Clock 94.439668015s] Trained 128 records in 0.087979723 seconds. Throughput is 1454.8806 records/second. Loss is 0.57414114. Sequential31006cbd's hyper parameters: Current learning rate is 0.008604371020478403. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 813][Wall Clock 94.531368508s] Trained 128 records in 0.091700493 seconds. Throughput is 1395.8485 records/second. Loss is 0.54484874. Sequential31006cbd's hyper parameters: Current learning rate is 0.008602890571231933. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44160/60000][Iteration 814][Wall Clock 94.635082879s] Trained 128 records in 0.103714371 seconds. Throughput is 1234.1588 records/second. Loss is 0.57520366. Sequential31006cbd's hyper parameters: Current learning rate is 0.00860141063134354. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 815][Wall Clock 94.722697205s] Trained 128 records in 0.087614326 seconds. Throughput is 1460.9482 records/second. Loss is 0.6253938. Sequential31006cbd's hyper parameters: Current learning rate is 0.008599931200550396. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44416/60000][Iteration 816][Wall Clock 94.803219448s] Trained 128 records in 0.080522243 seconds. Throughput is 1589.6228 records/second. Loss is 0.513031. Sequential31006cbd's hyper parameters: Current learning rate is 0.008598452278589854. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 817][Wall Clock 94.923771619s] Trained 128 records in 0.120552171 seconds. Throughput is 1061.781 records/second. Loss is 0.6194912. Sequential31006cbd's hyper parameters: Current learning rate is 0.00859697386519945. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44672/60000][Iteration 818][Wall Clock 95.008658415s] Trained 128 records in 0.084886796 seconds. Throughput is 1507.8906 records/second. Loss is 0.53200924. Sequential31006cbd's hyper parameters: Current learning rate is 0.008595495960116899. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:12 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 819][Wall Clock 95.090355292s] Trained 128 records in 0.081696877 seconds. Throughput is 1566.7673 records/second. Loss is 0.62046903. Sequential31006cbd's hyper parameters: Current learning rate is 0.008594018563080097. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 44928/60000][Iteration 820][Wall Clock 95.197452401s] Trained 128 records in 0.107097109 seconds. Throughput is 1195.177 records/second. Loss is 0.5186451. Sequential31006cbd's hyper parameters: Current learning rate is 0.008592541673827118. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 821][Wall Clock 95.292208174s] Trained 128 records in 0.094755773 seconds. Throughput is 1350.8412 records/second. Loss is 0.5277627. Sequential31006cbd's hyper parameters: Current learning rate is 0.00859106529209622. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45184/60000][Iteration 822][Wall Clock 95.43069053s] Trained 128 records in 0.138482356 seconds. Throughput is 924.3054 records/second. Loss is 0.6577206. Sequential31006cbd's hyper parameters: Current learning rate is 0.008589589417625837. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 823][Wall Clock 95.527386552s] Trained 128 records in 0.096696022 seconds. Throughput is 1323.736 records/second. Loss is 0.5190601. Sequential31006cbd's hyper parameters: Current learning rate is 0.008588114050154586. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45440/60000][Iteration 824][Wall Clock 95.623273437s] Trained 128 records in 0.095886885 seconds. Throughput is 1334.9062 records/second. Loss is 0.6476402. Sequential31006cbd's hyper parameters: Current learning rate is 0.00858663918942126. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 825][Wall Clock 95.713000312s] Trained 128 records in 0.089726875 seconds. Throughput is 1426.5514 records/second. Loss is 0.5946021. Sequential31006cbd's hyper parameters: Current learning rate is 0.008585164835164834. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45696/60000][Iteration 826][Wall Clock 95.793320421s] Trained 128 records in 0.080320109 seconds. Throughput is 1593.6233 records/second. Loss is 0.5416102. Sequential31006cbd's hyper parameters: Current learning rate is 0.008583690987124463. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 827][Wall Clock 95.877012433s] Trained 128 records in 0.083692012 seconds. Throughput is 1529.4171 records/second. Loss is 0.54468316. Sequential31006cbd's hyper parameters: Current learning rate is 0.008582217645039478. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 45952/60000][Iteration 828][Wall Clock 95.961903458s] Trained 128 records in 0.084891025 seconds. Throughput is 1507.8154 records/second. Loss is 0.66249126. Sequential31006cbd's hyper parameters: Current learning rate is 0.008580744808649392. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:13 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 829][Wall Clock 96.050876577s] Trained 128 records in 0.088973119 seconds. Throughput is 1438.6367 records/second. Loss is 0.5447109. Sequential31006cbd's hyper parameters: Current learning rate is 0.008579272477693892. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46208/60000][Iteration 830][Wall Clock 96.149637469s] Trained 128 records in 0.098760892 seconds. Throughput is 1296.0596 records/second. Loss is 0.57730496. Sequential31006cbd's hyper parameters: Current learning rate is 0.00857780065191285. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 831][Wall Clock 96.24424706s] Trained 128 records in 0.094609591 seconds. Throughput is 1352.9285 records/second. Loss is 0.5545497. Sequential31006cbd's hyper parameters: Current learning rate is 0.008576329331046312. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46464/60000][Iteration 832][Wall Clock 96.329046734s] Trained 128 records in 0.084799674 seconds. Throughput is 1509.4397 records/second. Loss is 0.47983924. Sequential31006cbd's hyper parameters: Current learning rate is 0.008574858514834506. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 833][Wall Clock 96.43414567s] Trained 128 records in 0.105098936 seconds. Throughput is 1217.9001 records/second. Loss is 0.5445018. Sequential31006cbd's hyper parameters: Current learning rate is 0.008573388203017831. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46720/60000][Iteration 834][Wall Clock 96.528963407s] Trained 128 records in 0.094817737 seconds. Throughput is 1349.9584 records/second. Loss is 0.6473578. Sequential31006cbd's hyper parameters: Current learning rate is 0.008571918395336876. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 835][Wall Clock 96.612812805s] Trained 128 records in 0.083849398 seconds. Throughput is 1526.5464 records/second. Loss is 0.57231146. Sequential31006cbd's hyper parameters: Current learning rate is 0.008570449091532395. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 46976/60000][Iteration 836][Wall Clock 96.707789205s] Trained 128 records in 0.0949764 seconds. Throughput is 1347.7031 records/second. Loss is 0.6344716. Sequential31006cbd's hyper parameters: Current learning rate is 0.00856898029134533. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 837][Wall Clock 96.800601083s] Trained 128 records in 0.092811878 seconds. Throughput is 1379.1339 records/second. Loss is 0.6438743. Sequential31006cbd's hyper parameters: Current learning rate is 0.008567511994516792. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 47232/60000][Iteration 838][Wall Clock 96.881989168s] Trained 128 records in 0.081388085 seconds. Throughput is 1572.7118 records/second. Loss is 0.5217681. Sequential31006cbd's hyper parameters: Current learning rate is 0.008566044200788075. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 839][Wall Clock 96.961562113s] Trained 128 records in 0.079572945 seconds. Throughput is 1608.5869 records/second. Loss is 0.5300233. Sequential31006cbd's hyper parameters: Current learning rate is 0.00856457690990065. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:14 INFO  DistriOptimizer$:408 - [Epoch 2 47488/60000][Iteration 840][Wall Clock 97.045008379s] Trained 128 records in 0.083446266 seconds. Throughput is 1533.9213 records/second. Loss is 0.54493827. Sequential31006cbd's hyper parameters: Current learning rate is 0.008563110121596164. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 841][Wall Clock 97.14628576s] Trained 128 records in 0.101277381 seconds. Throughput is 1263.8557 records/second. Loss is 0.50747997. Sequential31006cbd's hyper parameters: Current learning rate is 0.00856164383561644. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 47744/60000][Iteration 842][Wall Clock 97.261160051s] Trained 128 records in 0.114874291 seconds. Throughput is 1114.2615 records/second. Loss is 0.64330405. Sequential31006cbd's hyper parameters: Current learning rate is 0.008560178051703475. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 843][Wall Clock 97.365308696s] Trained 128 records in 0.104148645 seconds. Throughput is 1229.0126 records/second. Loss is 0.6058934. Sequential31006cbd's hyper parameters: Current learning rate is 0.008558712769599451. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48000/60000][Iteration 844][Wall Clock 97.455520004s] Trained 128 records in 0.090211308 seconds. Throughput is 1418.8909 records/second. Loss is 0.5223145. Sequential31006cbd's hyper parameters: Current learning rate is 0.008557247989046722. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 845][Wall Clock 97.547049549s] Trained 128 records in 0.091529545 seconds. Throughput is 1398.4554 records/second. Loss is 0.49980298. Sequential31006cbd's hyper parameters: Current learning rate is 0.008555783709787816. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48256/60000][Iteration 846][Wall Clock 97.658249497s] Trained 128 records in 0.111199948 seconds. Throughput is 1151.0797 records/second. Loss is 0.63403344. Sequential31006cbd's hyper parameters: Current learning rate is 0.00855431993156544. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 847][Wall Clock 97.764496941s] Trained 128 records in 0.106247444 seconds. Throughput is 1204.7349 records/second. Loss is 0.57193357. Sequential31006cbd's hyper parameters: Current learning rate is 0.008552856654122478. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48512/60000][Iteration 848][Wall Clock 97.862200879s] Trained 128 records in 0.097703938 seconds. Throughput is 1310.0802 records/second. Loss is 0.5493923. Sequential31006cbd's hyper parameters: Current learning rate is 0.008551393877201984. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 849][Wall Clock 97.949858826s] Trained 128 records in 0.087657947 seconds. Throughput is 1460.2213 records/second. Loss is 0.48382002. Sequential31006cbd's hyper parameters: Current learning rate is 0.008549931600547196. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:15 INFO  DistriOptimizer$:408 - [Epoch 2 48768/60000][Iteration 850][Wall Clock 98.036878941s] Trained 128 records in 0.087020115 seconds. Throughput is 1470.9243 records/second. Loss is 0.5614887. Sequential31006cbd's hyper parameters: Current learning rate is 0.008548469823901523. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 851][Wall Clock 98.16105937s] Trained 128 records in 0.124180429 seconds. Throughput is 1030.7582 records/second. Loss is 0.5307588. Sequential31006cbd's hyper parameters: Current learning rate is 0.008547008547008548. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49024/60000][Iteration 852][Wall Clock 98.26994788s] Trained 128 records in 0.10888851 seconds. Throughput is 1175.5143 records/second. Loss is 0.6876138. Sequential31006cbd's hyper parameters: Current learning rate is 0.008545547769612033. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 853][Wall Clock 98.359653875s] Trained 128 records in 0.089705995 seconds. Throughput is 1426.8834 records/second. Loss is 0.55259776. Sequential31006cbd's hyper parameters: Current learning rate is 0.008544087491455913. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49280/60000][Iteration 854][Wall Clock 98.453345724s] Trained 128 records in 0.093691849 seconds. Throughput is 1366.1808 records/second. Loss is 0.5260481. Sequential31006cbd's hyper parameters: Current learning rate is 0.008542627712284298. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 855][Wall Clock 98.557673352s] Trained 128 records in 0.104327628 seconds. Throughput is 1226.9042 records/second. Loss is 0.60135627. Sequential31006cbd's hyper parameters: Current learning rate is 0.008541168431841476. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49536/60000][Iteration 856][Wall Clock 98.647005855s] Trained 128 records in 0.089332503 seconds. Throughput is 1432.8491 records/second. Loss is 0.53489405. Sequential31006cbd's hyper parameters: Current learning rate is 0.008539709649871904. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 857][Wall Clock 98.734030135s] Trained 128 records in 0.08702428 seconds. Throughput is 1470.8539 records/second. Loss is 0.66367036. Sequential31006cbd's hyper parameters: Current learning rate is 0.00853825136612022. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49792/60000][Iteration 858][Wall Clock 98.82037677s] Trained 128 records in 0.086346635 seconds. Throughput is 1482.3971 records/second. Loss is 0.6077933. Sequential31006cbd's hyper parameters: Current learning rate is 0.008536793580331228. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 859][Wall Clock 98.904895701s] Trained 128 records in 0.084518931 seconds. Throughput is 1514.4536 records/second. Loss is 0.53278804. Sequential31006cbd's hyper parameters: Current learning rate is 0.008535336292249915. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:16 INFO  DistriOptimizer$:408 - [Epoch 2 50048/60000][Iteration 860][Wall Clock 98.998031385s] Trained 128 records in 0.093135684 seconds. Throughput is 1374.339 records/second. Loss is 0.5132569. Sequential31006cbd's hyper parameters: Current learning rate is 0.008533879501621438. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 861][Wall Clock 99.100311732s] Trained 128 records in 0.102280347 seconds. Throughput is 1251.4623 records/second. Loss is 0.5902219. Sequential31006cbd's hyper parameters: Current learning rate is 0.008532423208191127. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50304/60000][Iteration 862][Wall Clock 99.186753098s] Trained 128 records in 0.086441366 seconds. Throughput is 1480.7725 records/second. Loss is 0.555783. Sequential31006cbd's hyper parameters: Current learning rate is 0.008530967411704487. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 863][Wall Clock 99.267427072s] Trained 128 records in 0.080673974 seconds. Throughput is 1586.6332 records/second. Loss is 0.5489352. Sequential31006cbd's hyper parameters: Current learning rate is 0.008529512111907198. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50560/60000][Iteration 864][Wall Clock 99.357268024s] Trained 128 records in 0.089840952 seconds. Throughput is 1424.7401 records/second. Loss is 0.6478916. Sequential31006cbd's hyper parameters: Current learning rate is 0.008528057308545113. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 865][Wall Clock 99.438547883s] Trained 128 records in 0.081279859 seconds. Throughput is 1574.8059 records/second. Loss is 0.52992475. Sequential31006cbd's hyper parameters: Current learning rate is 0.008526603001364257. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50816/60000][Iteration 866][Wall Clock 99.520069835s] Trained 128 records in 0.081521952 seconds. Throughput is 1570.1293 records/second. Loss is 0.5839968. Sequential31006cbd's hyper parameters: Current learning rate is 0.008525149190110827. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 867][Wall Clock 99.605717699s] Trained 128 records in 0.085647864 seconds. Throughput is 1494.4915 records/second. Loss is 0.4887979. Sequential31006cbd's hyper parameters: Current learning rate is 0.008523695874531197. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 51072/60000][Iteration 868][Wall Clock 99.703328964s] Trained 128 records in 0.097611265 seconds. Throughput is 1311.3241 records/second. Loss is 0.60884714. Sequential31006cbd's hyper parameters: Current learning rate is 0.00852224305437191. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 869][Wall Clock 99.815693389s] Trained 128 records in 0.112364425 seconds. Throughput is 1139.1505 records/second. Loss is 0.6601708. Sequential31006cbd's hyper parameters: Current learning rate is 0.008520790729379687. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 51328/60000][Iteration 870][Wall Clock 99.903593669s] Trained 128 records in 0.08790028 seconds. Throughput is 1456.1956 records/second. Loss is 0.58442205. Sequential31006cbd's hyper parameters: Current learning rate is 0.008519338899301414. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:17 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 871][Wall Clock 99.994676852s] Trained 128 records in 0.091083183 seconds. Throughput is 1405.3088 records/second. Loss is 0.58584625. Sequential31006cbd's hyper parameters: Current learning rate is 0.008517887563884158. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 51584/60000][Iteration 872][Wall Clock 100.090498383s] Trained 128 records in 0.095821531 seconds. Throughput is 1335.8167 records/second. Loss is 0.50483936. Sequential31006cbd's hyper parameters: Current learning rate is 0.008516436722875149. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 873][Wall Clock 100.184932843s] Trained 128 records in 0.09443446 seconds. Throughput is 1355.4374 records/second. Loss is 0.5895708. Sequential31006cbd's hyper parameters: Current learning rate is 0.0085149863760218. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 51840/60000][Iteration 874][Wall Clock 100.293532253s] Trained 128 records in 0.10859941 seconds. Throughput is 1178.6436 records/second. Loss is 0.755997. Sequential31006cbd's hyper parameters: Current learning rate is 0.008513536523071684. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 875][Wall Clock 100.411092939s] Trained 128 records in 0.117560686 seconds. Throughput is 1088.7993 records/second. Loss is 0.510263. Sequential31006cbd's hyper parameters: Current learning rate is 0.008512087163772556. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 52096/60000][Iteration 876][Wall Clock 100.563765668s] Trained 128 records in 0.152672729 seconds. Throughput is 838.3947 records/second. Loss is 0.56886417. Sequential31006cbd's hyper parameters: Current learning rate is 0.00851063829787234. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 877][Wall Clock 100.667670627s] Trained 128 records in 0.103904959 seconds. Throughput is 1231.895 records/second. Loss is 0.47948128. Sequential31006cbd's hyper parameters: Current learning rate is 0.00850918992511913. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 52352/60000][Iteration 878][Wall Clock 100.749620812s] Trained 128 records in 0.081950185 seconds. Throughput is 1561.9244 records/second. Loss is 0.6063784. Sequential31006cbd's hyper parameters: Current learning rate is 0.008507742045261188. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 879][Wall Clock 100.838765882s] Trained 128 records in 0.08914507 seconds. Throughput is 1435.8618 records/second. Loss is 0.5795056. Sequential31006cbd's hyper parameters: Current learning rate is 0.008506294658046955. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 52608/60000][Iteration 880][Wall Clock 100.940988538s] Trained 128 records in 0.102222656 seconds. Throughput is 1252.1686 records/second. Loss is 0.5390605. Sequential31006cbd's hyper parameters: Current learning rate is 0.008504847763225038. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:18 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 881][Wall Clock 101.03220955s] Trained 128 records in 0.091221012 seconds. Throughput is 1403.1854 records/second. Loss is 0.54003316. Sequential31006cbd's hyper parameters: Current learning rate is 0.008503401360544218. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 52864/60000][Iteration 882][Wall Clock 101.13640828s] Trained 128 records in 0.10419873 seconds. Throughput is 1228.4219 records/second. Loss is 0.59013027. Sequential31006cbd's hyper parameters: Current learning rate is 0.008501955449753445. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 883][Wall Clock 101.255845501s] Trained 128 records in 0.119437221 seconds. Throughput is 1071.6927 records/second. Loss is 0.5024778. Sequential31006cbd's hyper parameters: Current learning rate is 0.008500510030601835. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53120/60000][Iteration 884][Wall Clock 101.382575576s] Trained 128 records in 0.126730075 seconds. Throughput is 1010.02075 records/second. Loss is 0.5667471. Sequential31006cbd's hyper parameters: Current learning rate is 0.008499065102838687. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 885][Wall Clock 101.470752022s] Trained 128 records in 0.088176446 seconds. Throughput is 1451.6349 records/second. Loss is 0.40353793. Sequential31006cbd's hyper parameters: Current learning rate is 0.00849762066621346. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53376/60000][Iteration 886][Wall Clock 101.580330531s] Trained 128 records in 0.109578509 seconds. Throughput is 1168.1122 records/second. Loss is 0.5562516. Sequential31006cbd's hyper parameters: Current learning rate is 0.008496176720475786. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 887][Wall Clock 101.696063695s] Trained 128 records in 0.115733164 seconds. Throughput is 1105.9924 records/second. Loss is 0.5401969. Sequential31006cbd's hyper parameters: Current learning rate is 0.008494733265375467. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53632/60000][Iteration 888][Wall Clock 101.779224618s] Trained 128 records in 0.083160923 seconds. Throughput is 1539.1844 records/second. Loss is 0.58318573. Sequential31006cbd's hyper parameters: Current learning rate is 0.008493290300662476. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 889][Wall Clock 101.860903678s] Trained 128 records in 0.08167906 seconds. Throughput is 1567.1091 records/second. Loss is 0.5680557. Sequential31006cbd's hyper parameters: Current learning rate is 0.008491847826086956. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:19 INFO  DistriOptimizer$:408 - [Epoch 2 53888/60000][Iteration 890][Wall Clock 101.95530326s] Trained 128 records in 0.094399582 seconds. Throughput is 1355.9382 records/second. Loss is 0.652788. Sequential31006cbd's hyper parameters: Current learning rate is 0.008490405841399219. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 891][Wall Clock 102.066606811s] Trained 128 records in 0.111303551 seconds. Throughput is 1150.0082 records/second. Loss is 0.6233927. Sequential31006cbd's hyper parameters: Current learning rate is 0.008488964346349746. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54144/60000][Iteration 892][Wall Clock 102.165505984s] Trained 128 records in 0.098899173 seconds. Throughput is 1294.2474 records/second. Loss is 0.5445949. Sequential31006cbd's hyper parameters: Current learning rate is 0.008487523340689187. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 893][Wall Clock 102.297750043s] Trained 128 records in 0.132244059 seconds. Throughput is 967.90735 records/second. Loss is 0.45257935. Sequential31006cbd's hyper parameters: Current learning rate is 0.008486082824168364. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54400/60000][Iteration 894][Wall Clock 102.422708698s] Trained 128 records in 0.124958655 seconds. Throughput is 1024.3387 records/second. Loss is 0.4885232. Sequential31006cbd's hyper parameters: Current learning rate is 0.008484642796538265. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 895][Wall Clock 102.505919322s] Trained 128 records in 0.083210624 seconds. Throughput is 1538.2651 records/second. Loss is 0.47600305. Sequential31006cbd's hyper parameters: Current learning rate is 0.00848320325755005. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54656/60000][Iteration 896][Wall Clock 102.603480579s] Trained 128 records in 0.097561257 seconds. Throughput is 1311.9962 records/second. Loss is 0.58821106. Sequential31006cbd's hyper parameters: Current learning rate is 0.008481764206955046. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 897][Wall Clock 102.692186019s] Trained 128 records in 0.08870544 seconds. Throughput is 1442.978 records/second. Loss is 0.6054655. Sequential31006cbd's hyper parameters: Current learning rate is 0.008480325644504749. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 54912/60000][Iteration 898][Wall Clock 102.782426528s] Trained 128 records in 0.090240509 seconds. Throughput is 1418.4318 records/second. Loss is 0.53527343. Sequential31006cbd's hyper parameters: Current learning rate is 0.008478887569950822. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 899][Wall Clock 102.878071489s] Trained 128 records in 0.095644961 seconds. Throughput is 1338.2827 records/second. Loss is 0.5156624. Sequential31006cbd's hyper parameters: Current learning rate is 0.0084774499830451. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 55168/60000][Iteration 900][Wall Clock 102.961880514s] Trained 128 records in 0.083809025 seconds. Throughput is 1527.2819 records/second. Loss is 0.54505897. Sequential31006cbd's hyper parameters: Current learning rate is 0.008476012883539583. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:20 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 901][Wall Clock 103.050315515s] Trained 128 records in 0.088435001 seconds. Throughput is 1447.3907 records/second. Loss is 0.56445444. Sequential31006cbd's hyper parameters: Current learning rate is 0.00847457627118644. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 55424/60000][Iteration 902][Wall Clock 103.171881052s] Trained 128 records in 0.121565537 seconds. Throughput is 1052.93 records/second. Loss is 0.49271774. Sequential31006cbd's hyper parameters: Current learning rate is 0.00847314014573801. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 903][Wall Clock 103.264894849s] Trained 128 records in 0.093013797 seconds. Throughput is 1376.1399 records/second. Loss is 0.52336675. Sequential31006cbd's hyper parameters: Current learning rate is 0.008471704506946797. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 55680/60000][Iteration 904][Wall Clock 103.376700816s] Trained 128 records in 0.111805967 seconds. Throughput is 1144.8405 records/second. Loss is 0.5032078. Sequential31006cbd's hyper parameters: Current learning rate is 0.008470269354565475. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 905][Wall Clock 103.480392593s] Trained 128 records in 0.103691777 seconds. Throughput is 1234.4276 records/second. Loss is 0.5820141. Sequential31006cbd's hyper parameters: Current learning rate is 0.008468834688346883. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 55936/60000][Iteration 906][Wall Clock 103.57283191s] Trained 128 records in 0.092439317 seconds. Throughput is 1384.6921 records/second. Loss is 0.5274499. Sequential31006cbd's hyper parameters: Current learning rate is 0.00846740050804403. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 907][Wall Clock 103.695103321s] Trained 128 records in 0.122271411 seconds. Throughput is 1046.8514 records/second. Loss is 0.52130026. Sequential31006cbd's hyper parameters: Current learning rate is 0.008465966813410091. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 56192/60000][Iteration 908][Wall Clock 103.785398492s] Trained 128 records in 0.090295171 seconds. Throughput is 1417.573 records/second. Loss is 0.5400843. Sequential31006cbd's hyper parameters: Current learning rate is 0.008464533604198408. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 909][Wall Clock 103.88169121s] Trained 128 records in 0.096292718 seconds. Throughput is 1329.2802 records/second. Loss is 0.46699202. Sequential31006cbd's hyper parameters: Current learning rate is 0.008463100880162493. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:21 INFO  DistriOptimizer$:408 - [Epoch 2 56448/60000][Iteration 910][Wall Clock 103.985094583s] Trained 128 records in 0.103403373 seconds. Throughput is 1237.8706 records/second. Loss is 0.47721136. Sequential31006cbd's hyper parameters: Current learning rate is 0.008461668641056016. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 911][Wall Clock 104.073319217s] Trained 128 records in 0.088224634 seconds. Throughput is 1450.8419 records/second. Loss is 0.5784453. Sequential31006cbd's hyper parameters: Current learning rate is 0.008460236886632826. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 56704/60000][Iteration 912][Wall Clock 104.158543867s] Trained 128 records in 0.08522465 seconds. Throughput is 1501.9128 records/second. Loss is 0.6411089. Sequential31006cbd's hyper parameters: Current learning rate is 0.00845880561664693. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 913][Wall Clock 104.246578652s] Trained 128 records in 0.088034785 seconds. Throughput is 1453.9707 records/second. Loss is 0.46765667. Sequential31006cbd's hyper parameters: Current learning rate is 0.008457374830852505. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 56960/60000][Iteration 914][Wall Clock 104.333279055s] Trained 128 records in 0.086700403 seconds. Throughput is 1476.3484 records/second. Loss is 0.4477896. Sequential31006cbd's hyper parameters: Current learning rate is 0.00845594452900389. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 915][Wall Clock 104.420036251s] Trained 128 records in 0.086757196 seconds. Throughput is 1475.382 records/second. Loss is 0.54521894. Sequential31006cbd's hyper parameters: Current learning rate is 0.008454514710855596. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57216/60000][Iteration 916][Wall Clock 104.500620644s] Trained 128 records in 0.080584393 seconds. Throughput is 1588.397 records/second. Loss is 0.5779321. Sequential31006cbd's hyper parameters: Current learning rate is 0.008453085376162298. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 917][Wall Clock 104.591255411s] Trained 128 records in 0.090634767 seconds. Throughput is 1412.2615 records/second. Loss is 0.5172079. Sequential31006cbd's hyper parameters: Current learning rate is 0.008451656524678837. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57472/60000][Iteration 918][Wall Clock 104.689029579s] Trained 128 records in 0.097774168 seconds. Throughput is 1309.1392 records/second. Loss is 0.5167491. Sequential31006cbd's hyper parameters: Current learning rate is 0.008450228156160217. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 919][Wall Clock 104.781260199s] Trained 128 records in 0.09223062 seconds. Throughput is 1387.8254 records/second. Loss is 0.59467554. Sequential31006cbd's hyper parameters: Current learning rate is 0.00844880027036161. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57728/60000][Iteration 920][Wall Clock 104.879037523s] Trained 128 records in 0.097777324 seconds. Throughput is 1309.097 records/second. Loss is 0.59696764. Sequential31006cbd's hyper parameters: Current learning rate is 0.00844737286703835. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:22 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 921][Wall Clock 105.002360007s] Trained 128 records in 0.123322484 seconds. Throughput is 1037.9291 records/second. Loss is 0.604143. Sequential31006cbd's hyper parameters: Current learning rate is 0.008445945945945946. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 57984/60000][Iteration 922][Wall Clock 105.097178753s] Trained 128 records in 0.094818746 seconds. Throughput is 1349.944 records/second. Loss is 0.4819862. Sequential31006cbd's hyper parameters: Current learning rate is 0.008444519506840062. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 923][Wall Clock 105.190652088s] Trained 128 records in 0.093473335 seconds. Throughput is 1369.3744 records/second. Loss is 0.408923. Sequential31006cbd's hyper parameters: Current learning rate is 0.008443093549476527. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58240/60000][Iteration 924][Wall Clock 105.282706143s] Trained 128 records in 0.092054055 seconds. Throughput is 1390.4874 records/second. Loss is 0.5303618. Sequential31006cbd's hyper parameters: Current learning rate is 0.008441668073611346. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 925][Wall Clock 105.373134626s] Trained 128 records in 0.090428483 seconds. Throughput is 1415.4832 records/second. Loss is 0.49033284. Sequential31006cbd's hyper parameters: Current learning rate is 0.008440243079000674. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58496/60000][Iteration 926][Wall Clock 105.483335207s] Trained 128 records in 0.110200581 seconds. Throughput is 1161.5183 records/second. Loss is 0.45569715. Sequential31006cbd's hyper parameters: Current learning rate is 0.008438818565400843. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 927][Wall Clock 105.597816668s] Trained 128 records in 0.114481461 seconds. Throughput is 1118.085 records/second. Loss is 0.541838. Sequential31006cbd's hyper parameters: Current learning rate is 0.008437394532568343. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58752/60000][Iteration 928][Wall Clock 105.676585351s] Trained 128 records in 0.078768683 seconds. Throughput is 1625.0112 records/second. Loss is 0.5209545. Sequential31006cbd's hyper parameters: Current learning rate is 0.008435970980259827. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 929][Wall Clock 105.768083226s] Trained 128 records in 0.091497875 seconds. Throughput is 1398.9396 records/second. Loss is 0.5339799. Sequential31006cbd's hyper parameters: Current learning rate is 0.008434547908232119. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 59008/60000][Iteration 930][Wall Clock 105.862398754s] Trained 128 records in 0.094315528 seconds. Throughput is 1357.1466 records/second. Loss is 0.54018277. Sequential31006cbd's hyper parameters: Current learning rate is 0.0084331253162422. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:23 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 931][Wall Clock 105.950941893s] Trained 128 records in 0.088543139 seconds. Throughput is 1445.623 records/second. Loss is 0.4917208. Sequential31006cbd's hyper parameters: Current learning rate is 0.008431703204047219. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 59264/60000][Iteration 932][Wall Clock 106.054095967s] Trained 128 records in 0.103154074 seconds. Throughput is 1240.8623 records/second. Loss is 0.5849364. Sequential31006cbd's hyper parameters: Current learning rate is 0.008430281571404486. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 933][Wall Clock 106.150836633s] Trained 128 records in 0.096740666 seconds. Throughput is 1323.1251 records/second. Loss is 0.45973253. Sequential31006cbd's hyper parameters: Current learning rate is 0.008428860418071478. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 59520/60000][Iteration 934][Wall Clock 106.243346372s] Trained 128 records in 0.092509739 seconds. Throughput is 1383.6381 records/second. Loss is 0.5093649. Sequential31006cbd's hyper parameters: Current learning rate is 0.008427439743805831. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 935][Wall Clock 106.323976367s] Trained 128 records in 0.080629995 seconds. Throughput is 1587.4985 records/second. Loss is 0.5939387. Sequential31006cbd's hyper parameters: Current learning rate is 0.008426019548365351. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 59776/60000][Iteration 936][Wall Clock 106.411251222s] Trained 128 records in 0.087274855 seconds. Throughput is 1466.6309 records/second. Loss is 0.6331227. Sequential31006cbd's hyper parameters: Current learning rate is 0.008424599831508003. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 937][Wall Clock 106.500726833s] Trained 128 records in 0.089475611 seconds. Throughput is 1430.5575 records/second. Loss is 0.515473. Sequential31006cbd's hyper parameters: Current learning rate is 0.008423180592991913. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:408 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 106.589167679s] Trained 128 records in 0.088440846 seconds. Throughput is 1447.2952 records/second. Loss is 0.4296124. Sequential31006cbd's hyper parameters: Current learning rate is 0.008421761832575375. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:24 INFO  DistriOptimizer$:452 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 106.589167679s] Epoch finished. Wall clock time is 108068.465175 ms
2019-10-23 23:59:24 INFO  DistriOptimizer$:111 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 106.589167679s] Validate model...
2019-10-23 23:59:25 INFO  DistriOptimizer$:178 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 106.589167679s] validate model throughput is 11364.617 records/second
2019-10-23 23:59:25 INFO  DistriOptimizer$:181 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 106.589167679s] Top1Accuracy is Accuracy(correct: 8774, count: 10000, accuracy: 0.8774)
2019-10-23 23:59:25 INFO  DistriOptimizer$:221 - [Wall Clock 108.068465175s] Save model to /tmp/lenet5/20191023_235735
2019-10-23 23:59:25 INFO  DistriOptimizer$:226 - [Wall Clock 108.068465175s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-23 23:59:25 INFO  DistriOptimizer$:408 - [Epoch 3 128/60000][Iteration 939][Wall Clock 108.205796264s] Trained 128 records in 0.137331089 seconds. Throughput is 932.0541 records/second. Loss is 0.505259. Sequential31006cbd's hyper parameters: Current learning rate is 0.008420343550016841. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:25 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 940][Wall Clock 108.298303847s] Trained 128 records in 0.092507583 seconds. Throughput is 1383.6703 records/second. Loss is 0.61882776. Sequential31006cbd's hyper parameters: Current learning rate is 0.00841892574507493. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:25 INFO  DistriOptimizer$:408 - [Epoch 3 384/60000][Iteration 941][Wall Clock 108.404308475s] Trained 128 records in 0.106004628 seconds. Throughput is 1207.4945 records/second. Loss is 0.4988287. Sequential31006cbd's hyper parameters: Current learning rate is 0.008417508417508417. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 942][Wall Clock 108.561591172s] Trained 128 records in 0.157282697 seconds. Throughput is 813.8212 records/second. Loss is 0.61353004. Sequential31006cbd's hyper parameters: Current learning rate is 0.008416091567076251. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 640/60000][Iteration 943][Wall Clock 108.675758941s] Trained 128 records in 0.114167769 seconds. Throughput is 1121.157 records/second. Loss is 0.47842088. Sequential31006cbd's hyper parameters: Current learning rate is 0.008414675193537528. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 944][Wall Clock 108.77974877s] Trained 128 records in 0.103989829 seconds. Throughput is 1230.8895 records/second. Loss is 0.48367235. Sequential31006cbd's hyper parameters: Current learning rate is 0.008413259296651522. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 896/60000][Iteration 945][Wall Clock 108.908053255s] Trained 128 records in 0.128304485 seconds. Throughput is 997.6269 records/second. Loss is 0.47402075. Sequential31006cbd's hyper parameters: Current learning rate is 0.008411843876177657. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 946][Wall Clock 109.026892947s] Trained 128 records in 0.118839692 seconds. Throughput is 1077.0813 records/second. Loss is 0.39264894. Sequential31006cbd's hyper parameters: Current learning rate is 0.008410428931875526. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 1152/60000][Iteration 947][Wall Clock 109.135273153s] Trained 128 records in 0.108380206 seconds. Throughput is 1181.0275 records/second. Loss is 0.5392399. Sequential31006cbd's hyper parameters: Current learning rate is 0.008409014463504878. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 948][Wall Clock 109.268733265s] Trained 128 records in 0.133460112 seconds. Throughput is 959.088 records/second. Loss is 0.5755373. Sequential31006cbd's hyper parameters: Current learning rate is 0.008407600470825626. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 1408/60000][Iteration 949][Wall Clock 109.367920796s] Trained 128 records in 0.099187531 seconds. Throughput is 1290.4847 records/second. Loss is 0.48124373. Sequential31006cbd's hyper parameters: Current learning rate is 0.008406186953597848. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:26 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 950][Wall Clock 109.479461355s] Trained 128 records in 0.111540559 seconds. Throughput is 1147.5647 records/second. Loss is 0.54361075. Sequential31006cbd's hyper parameters: Current learning rate is 0.00840477391158178. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 1664/60000][Iteration 951][Wall Clock 109.620426823s] Trained 128 records in 0.140965468 seconds. Throughput is 908.02386 records/second. Loss is 0.43327555. Sequential31006cbd's hyper parameters: Current learning rate is 0.008403361344537816. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 952][Wall Clock 109.718370986s] Trained 128 records in 0.097944163 seconds. Throughput is 1306.8671 records/second. Loss is 0.5239644. Sequential31006cbd's hyper parameters: Current learning rate is 0.008401949252226518. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 1920/60000][Iteration 953][Wall Clock 109.800498124s] Trained 128 records in 0.082127138 seconds. Throughput is 1558.5591 records/second. Loss is 0.40881413. Sequential31006cbd's hyper parameters: Current learning rate is 0.008400537634408603. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 954][Wall Clock 109.883357123s] Trained 128 records in 0.082858999 seconds. Throughput is 1544.793 records/second. Loss is 0.49260777. Sequential31006cbd's hyper parameters: Current learning rate is 0.008399126490844951. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2176/60000][Iteration 955][Wall Clock 109.970694297s] Trained 128 records in 0.087337174 seconds. Throughput is 1465.5844 records/second. Loss is 0.5399804. Sequential31006cbd's hyper parameters: Current learning rate is 0.008397715821296607. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 956][Wall Clock 110.060317235s] Trained 128 records in 0.089622938 seconds. Throughput is 1428.2058 records/second. Loss is 0.67850614. Sequential31006cbd's hyper parameters: Current learning rate is 0.008396305625524769. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2432/60000][Iteration 957][Wall Clock 110.152204535s] Trained 128 records in 0.0918873 seconds. Throughput is 1393.0107 records/second. Loss is 0.46665087. Sequential31006cbd's hyper parameters: Current learning rate is 0.0083948959032908. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 958][Wall Clock 110.2349665s] Trained 128 records in 0.082761965 seconds. Throughput is 1546.6041 records/second. Loss is 0.48942548. Sequential31006cbd's hyper parameters: Current learning rate is 0.008393486654356219. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2688/60000][Iteration 959][Wall Clock 110.320705565s] Trained 128 records in 0.085739065 seconds. Throughput is 1492.9017 records/second. Loss is 0.510167. Sequential31006cbd's hyper parameters: Current learning rate is 0.008392077878482713. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 960][Wall Clock 110.399258567s] Trained 128 records in 0.078553002 seconds. Throughput is 1629.4731 records/second. Loss is 0.54623413. Sequential31006cbd's hyper parameters: Current learning rate is 0.00839066957543212. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:27 INFO  DistriOptimizer$:408 - [Epoch 3 2944/60000][Iteration 961][Wall Clock 110.47473795s] Trained 128 records in 0.075479383 seconds. Throughput is 1695.8274 records/second. Loss is 0.43191746. Sequential31006cbd's hyper parameters: Current learning rate is 0.008389261744966443. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 962][Wall Clock 110.553367881s] Trained 128 records in 0.078629931 seconds. Throughput is 1627.8788 records/second. Loss is 0.50999737. Sequential31006cbd's hyper parameters: Current learning rate is 0.008387854386847846. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3200/60000][Iteration 963][Wall Clock 110.648391453s] Trained 128 records in 0.095023572 seconds. Throughput is 1347.0342 records/second. Loss is 0.41636324. Sequential31006cbd's hyper parameters: Current learning rate is 0.008386447500838645. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 964][Wall Clock 110.733622338s] Trained 128 records in 0.085230885 seconds. Throughput is 1501.803 records/second. Loss is 0.43879896. Sequential31006cbd's hyper parameters: Current learning rate is 0.008385041086701324. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3456/60000][Iteration 965][Wall Clock 110.812853839s] Trained 128 records in 0.079231501 seconds. Throughput is 1615.519 records/second. Loss is 0.6392824. Sequential31006cbd's hyper parameters: Current learning rate is 0.008383635144198523. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 966][Wall Clock 110.931655249s] Trained 128 records in 0.11880141 seconds. Throughput is 1077.4283 records/second. Loss is 0.5529371. Sequential31006cbd's hyper parameters: Current learning rate is 0.008382229673093043. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3712/60000][Iteration 967][Wall Clock 111.030549304s] Trained 128 records in 0.098894055 seconds. Throughput is 1294.3145 records/second. Loss is 0.508858. Sequential31006cbd's hyper parameters: Current learning rate is 0.008380824673147838. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 968][Wall Clock 111.185479603s] Trained 128 records in 0.154930299 seconds. Throughput is 826.178 records/second. Loss is 0.52750707. Sequential31006cbd's hyper parameters: Current learning rate is 0.008379420144126027. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 3968/60000][Iteration 969][Wall Clock 111.300330335s] Trained 128 records in 0.114850732 seconds. Throughput is 1114.4901 records/second. Loss is 0.5301136. Sequential31006cbd's hyper parameters: Current learning rate is 0.008378016085790885. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 970][Wall Clock 111.393121494s] Trained 128 records in 0.092791159 seconds. Throughput is 1379.4418 records/second. Loss is 0.55002326. Sequential31006cbd's hyper parameters: Current learning rate is 0.008376612497905847. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:28 INFO  DistriOptimizer$:408 - [Epoch 3 4224/60000][Iteration 971][Wall Clock 111.496491016s] Trained 128 records in 0.103369522 seconds. Throughput is 1238.276 records/second. Loss is 0.5700751. Sequential31006cbd's hyper parameters: Current learning rate is 0.008375209380234507. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 972][Wall Clock 111.583622372s] Trained 128 records in 0.087131356 seconds. Throughput is 1469.0463 records/second. Loss is 0.486256. Sequential31006cbd's hyper parameters: Current learning rate is 0.008373806732540614. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 4480/60000][Iteration 973][Wall Clock 111.669494104s] Trained 128 records in 0.085871732 seconds. Throughput is 1490.5952 records/second. Loss is 0.44537857. Sequential31006cbd's hyper parameters: Current learning rate is 0.008372404554588079. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 974][Wall Clock 111.74961077s] Trained 128 records in 0.080116666 seconds. Throughput is 1597.67 records/second. Loss is 0.5078747. Sequential31006cbd's hyper parameters: Current learning rate is 0.008371002846140967. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 4736/60000][Iteration 975][Wall Clock 111.848085399s] Trained 128 records in 0.098474629 seconds. Throughput is 1299.8271 records/second. Loss is 0.42802116. Sequential31006cbd's hyper parameters: Current learning rate is 0.008369601606963508. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 976][Wall Clock 111.976993709s] Trained 128 records in 0.12890831 seconds. Throughput is 992.95386 records/second. Loss is 0.53573716. Sequential31006cbd's hyper parameters: Current learning rate is 0.008368200836820083. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 4992/60000][Iteration 977][Wall Clock 112.080194196s] Trained 128 records in 0.103200487 seconds. Throughput is 1240.3042 records/second. Loss is 0.5450937. Sequential31006cbd's hyper parameters: Current learning rate is 0.008366800535475234. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 978][Wall Clock 112.164572243s] Trained 128 records in 0.084378047 seconds. Throughput is 1516.9822 records/second. Loss is 0.56956196. Sequential31006cbd's hyper parameters: Current learning rate is 0.008365400702693659. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 5248/60000][Iteration 979][Wall Clock 112.246000269s] Trained 128 records in 0.081428026 seconds. Throughput is 1571.9403 records/second. Loss is 0.49774596. Sequential31006cbd's hyper parameters: Current learning rate is 0.008364001338240215. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 980][Wall Clock 112.330415753s] Trained 128 records in 0.084415484 seconds. Throughput is 1516.3096 records/second. Loss is 0.44099194. Sequential31006cbd's hyper parameters: Current learning rate is 0.008362602441879913. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 5504/60000][Iteration 981][Wall Clock 112.414993448s] Trained 128 records in 0.084577695 seconds. Throughput is 1513.4014 records/second. Loss is 0.54433906. Sequential31006cbd's hyper parameters: Current learning rate is 0.008361204013377928. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:29 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 982][Wall Clock 112.499699874s] Trained 128 records in 0.084706426 seconds. Throughput is 1511.1014 records/second. Loss is 0.6120211. Sequential31006cbd's hyper parameters: Current learning rate is 0.008359806052499582. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 5760/60000][Iteration 983][Wall Clock 112.588220558s] Trained 128 records in 0.088520684 seconds. Throughput is 1445.9897 records/second. Loss is 0.47974786. Sequential31006cbd's hyper parameters: Current learning rate is 0.008358408559010364. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 984][Wall Clock 112.675990319s] Trained 128 records in 0.087769761 seconds. Throughput is 1458.3611 records/second. Loss is 0.5880457. Sequential31006cbd's hyper parameters: Current learning rate is 0.008357011532675915. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6016/60000][Iteration 985][Wall Clock 112.762958561s] Trained 128 records in 0.086968242 seconds. Throughput is 1471.8016 records/second. Loss is 0.5368153. Sequential31006cbd's hyper parameters: Current learning rate is 0.008355614973262033. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 986][Wall Clock 112.844428636s] Trained 128 records in 0.081470075 seconds. Throughput is 1571.129 records/second. Loss is 0.57357574. Sequential31006cbd's hyper parameters: Current learning rate is 0.00835421888053467. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6272/60000][Iteration 987][Wall Clock 112.939044895s] Trained 128 records in 0.094616259 seconds. Throughput is 1352.833 records/second. Loss is 0.49804497. Sequential31006cbd's hyper parameters: Current learning rate is 0.00835282325425994. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 988][Wall Clock 113.04187644s] Trained 128 records in 0.102831545 seconds. Throughput is 1244.7543 records/second. Loss is 0.54908144. Sequential31006cbd's hyper parameters: Current learning rate is 0.008351428094204109. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6528/60000][Iteration 989][Wall Clock 113.138146545s] Trained 128 records in 0.096270105 seconds. Throughput is 1329.5924 records/second. Loss is 0.4353316. Sequential31006cbd's hyper parameters: Current learning rate is 0.008350033400133601. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 990][Wall Clock 113.236423976s] Trained 128 records in 0.098277431 seconds. Throughput is 1302.4353 records/second. Loss is 0.53237015. Sequential31006cbd's hyper parameters: Current learning rate is 0.008348639171814994. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6784/60000][Iteration 991][Wall Clock 113.339537523s] Trained 128 records in 0.103113547 seconds. Throughput is 1241.35 records/second. Loss is 0.51573676. Sequential31006cbd's hyper parameters: Current learning rate is 0.008347245409015026. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:30 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 992][Wall Clock 113.463955646s] Trained 128 records in 0.124418123 seconds. Throughput is 1028.7891 records/second. Loss is 0.49103. Sequential31006cbd's hyper parameters: Current learning rate is 0.008345852111500586. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7040/60000][Iteration 993][Wall Clock 113.592897761s] Trained 128 records in 0.128942115 seconds. Throughput is 992.6935 records/second. Loss is 0.47511625. Sequential31006cbd's hyper parameters: Current learning rate is 0.00834445927903872. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 994][Wall Clock 113.698443076s] Trained 128 records in 0.105545315 seconds. Throughput is 1212.7493 records/second. Loss is 0.5287916. Sequential31006cbd's hyper parameters: Current learning rate is 0.00834306691139663. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7296/60000][Iteration 995][Wall Clock 113.802165721s] Trained 128 records in 0.103722645 seconds. Throughput is 1234.0603 records/second. Loss is 0.49973622. Sequential31006cbd's hyper parameters: Current learning rate is 0.008341675008341674. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 996][Wall Clock 113.909402107s] Trained 128 records in 0.107236386 seconds. Throughput is 1193.6248 records/second. Loss is 0.529037. Sequential31006cbd's hyper parameters: Current learning rate is 0.008340283569641367. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7552/60000][Iteration 997][Wall Clock 114.011608525s] Trained 128 records in 0.102206418 seconds. Throughput is 1252.3676 records/second. Loss is 0.43347603. Sequential31006cbd's hyper parameters: Current learning rate is 0.008338892595063376. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 998][Wall Clock 114.102769545s] Trained 128 records in 0.09116102 seconds. Throughput is 1404.1089 records/second. Loss is 0.5422515. Sequential31006cbd's hyper parameters: Current learning rate is 0.00833750208437552. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7808/60000][Iteration 999][Wall Clock 114.199949234s] Trained 128 records in 0.097179689 seconds. Throughput is 1317.1477 records/second. Loss is 0.526959. Sequential31006cbd's hyper parameters: Current learning rate is 0.008336112037345782. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 1000][Wall Clock 114.28620655s] Trained 128 records in 0.086257316 seconds. Throughput is 1483.9321 records/second. Loss is 0.45972723. Sequential31006cbd's hyper parameters: Current learning rate is 0.008334722453742291. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 8064/60000][Iteration 1001][Wall Clock 114.386548847s] Trained 128 records in 0.100342297 seconds. Throughput is 1275.6335 records/second. Loss is 0.5948207. Sequential31006cbd's hyper parameters: Current learning rate is 0.008333333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:31 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 1002][Wall Clock 114.48085657s] Trained 128 records in 0.094307723 seconds. Throughput is 1357.2589 records/second. Loss is 0.4324657. Sequential31006cbd's hyper parameters: Current learning rate is 0.008331944675887352. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 8320/60000][Iteration 1003][Wall Clock 114.566038688s] Trained 128 records in 0.085182118 seconds. Throughput is 1502.6628 records/second. Loss is 0.45745537. Sequential31006cbd's hyper parameters: Current learning rate is 0.008330556481172941. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 1004][Wall Clock 114.649926512s] Trained 128 records in 0.083887824 seconds. Throughput is 1525.8472 records/second. Loss is 0.61703265. Sequential31006cbd's hyper parameters: Current learning rate is 0.008329168748958853. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 8576/60000][Iteration 1005][Wall Clock 114.755111522s] Trained 128 records in 0.10518501 seconds. Throughput is 1216.9034 records/second. Loss is 0.44377154. Sequential31006cbd's hyper parameters: Current learning rate is 0.008327781479013991. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 1006][Wall Clock 114.846564484s] Trained 128 records in 0.091452962 seconds. Throughput is 1399.6266 records/second. Loss is 0.44775513. Sequential31006cbd's hyper parameters: Current learning rate is 0.00832639467110741. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 8832/60000][Iteration 1007][Wall Clock 114.94524944s] Trained 128 records in 0.098684956 seconds. Throughput is 1297.0569 records/second. Loss is 0.40749255. Sequential31006cbd's hyper parameters: Current learning rate is 0.008325008325008324. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 1008][Wall Clock 115.035946077s] Trained 128 records in 0.090696637 seconds. Throughput is 1411.2981 records/second. Loss is 0.40665388. Sequential31006cbd's hyper parameters: Current learning rate is 0.0083236224404861. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 9088/60000][Iteration 1009][Wall Clock 115.123654616s] Trained 128 records in 0.087708539 seconds. Throughput is 1459.379 records/second. Loss is 0.5063331. Sequential31006cbd's hyper parameters: Current learning rate is 0.008322237017310254. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 1010][Wall Clock 115.222680811s] Trained 128 records in 0.099026195 seconds. Throughput is 1292.5873 records/second. Loss is 0.55711585. Sequential31006cbd's hyper parameters: Current learning rate is 0.008320852055250457. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 9344/60000][Iteration 1011][Wall Clock 115.31132929s] Trained 128 records in 0.088648479 seconds. Throughput is 1443.9053 records/second. Loss is 0.3981808. Sequential31006cbd's hyper parameters: Current learning rate is 0.00831946755407654. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 1012][Wall Clock 115.400432221s] Trained 128 records in 0.089102931 seconds. Throughput is 1436.5409 records/second. Loss is 0.3910999. Sequential31006cbd's hyper parameters: Current learning rate is 0.008318083513558477. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:32 INFO  DistriOptimizer$:408 - [Epoch 3 9600/60000][Iteration 1013][Wall Clock 115.486540102s] Trained 128 records in 0.086107881 seconds. Throughput is 1486.5074 records/second. Loss is 0.5875115. Sequential31006cbd's hyper parameters: Current learning rate is 0.008316699933466402. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 1014][Wall Clock 115.571606508s] Trained 128 records in 0.085066406 seconds. Throughput is 1504.7068 records/second. Loss is 0.551968. Sequential31006cbd's hyper parameters: Current learning rate is 0.008315316813570598. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 9856/60000][Iteration 1015][Wall Clock 115.658413459s] Trained 128 records in 0.086806951 seconds. Throughput is 1474.5363 records/second. Loss is 0.47135678. Sequential31006cbd's hyper parameters: Current learning rate is 0.008313934153641503. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 1016][Wall Clock 115.760846063s] Trained 128 records in 0.102432604 seconds. Throughput is 1249.6022 records/second. Loss is 0.4880677. Sequential31006cbd's hyper parameters: Current learning rate is 0.00831255195344971. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10112/60000][Iteration 1017][Wall Clock 115.856095121s] Trained 128 records in 0.095249058 seconds. Throughput is 1343.8453 records/second. Loss is 0.45551717. Sequential31006cbd's hyper parameters: Current learning rate is 0.008311170212765957. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 1018][Wall Clock 115.953289862s] Trained 128 records in 0.097194741 seconds. Throughput is 1316.9437 records/second. Loss is 0.4411349. Sequential31006cbd's hyper parameters: Current learning rate is 0.008309788931361143. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10368/60000][Iteration 1019][Wall Clock 116.061701562s] Trained 128 records in 0.1084117 seconds. Throughput is 1180.6843 records/second. Loss is 0.39668438. Sequential31006cbd's hyper parameters: Current learning rate is 0.008308408109006314. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 1020][Wall Clock 116.163236994s] Trained 128 records in 0.101535432 seconds. Throughput is 1260.6437 records/second. Loss is 0.4452763. Sequential31006cbd's hyper parameters: Current learning rate is 0.00830702774547267. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10624/60000][Iteration 1021][Wall Clock 116.252368942s] Trained 128 records in 0.089131948 seconds. Throughput is 1436.0731 records/second. Loss is 0.5595442. Sequential31006cbd's hyper parameters: Current learning rate is 0.008305647840531562. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 1022][Wall Clock 116.343255384s] Trained 128 records in 0.090886442 seconds. Throughput is 1408.3508 records/second. Loss is 0.45182195. Sequential31006cbd's hyper parameters: Current learning rate is 0.008304268393954492. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:33 INFO  DistriOptimizer$:408 - [Epoch 3 10880/60000][Iteration 1023][Wall Clock 116.424275169s] Trained 128 records in 0.081019785 seconds. Throughput is 1579.8611 records/second. Loss is 0.47402725. Sequential31006cbd's hyper parameters: Current learning rate is 0.008302889405513119. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 1024][Wall Clock 116.511205561s] Trained 128 records in 0.086930392 seconds. Throughput is 1472.4424 records/second. Loss is 0.50981116. Sequential31006cbd's hyper parameters: Current learning rate is 0.008301510874979245. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11136/60000][Iteration 1025][Wall Clock 116.596049016s] Trained 128 records in 0.084843455 seconds. Throughput is 1508.6609 records/second. Loss is 0.43804646. Sequential31006cbd's hyper parameters: Current learning rate is 0.008300132802124834. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 1026][Wall Clock 116.692633779s] Trained 128 records in 0.096584763 seconds. Throughput is 1325.2609 records/second. Loss is 0.39988908. Sequential31006cbd's hyper parameters: Current learning rate is 0.008298755186721992. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11392/60000][Iteration 1027][Wall Clock 116.819129126s] Trained 128 records in 0.126495347 seconds. Throughput is 1011.89496 records/second. Loss is 0.4637696. Sequential31006cbd's hyper parameters: Current learning rate is 0.00829737802854298. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 1028][Wall Clock 116.915959035s] Trained 128 records in 0.096829909 seconds. Throughput is 1321.9056 records/second. Loss is 0.5364828. Sequential31006cbd's hyper parameters: Current learning rate is 0.008296001327360213. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11648/60000][Iteration 1029][Wall Clock 117.011359756s] Trained 128 records in 0.095400721 seconds. Throughput is 1341.709 records/second. Loss is 0.4437399. Sequential31006cbd's hyper parameters: Current learning rate is 0.00829462508294625. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 1030][Wall Clock 117.097236342s] Trained 128 records in 0.085876586 seconds. Throughput is 1490.5111 records/second. Loss is 0.4342151. Sequential31006cbd's hyper parameters: Current learning rate is 0.00829324929507381. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 11904/60000][Iteration 1031][Wall Clock 117.195778764s] Trained 128 records in 0.098542422 seconds. Throughput is 1298.933 records/second. Loss is 0.4970504. Sequential31006cbd's hyper parameters: Current learning rate is 0.008291873963515755. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 1032][Wall Clock 117.285060149s] Trained 128 records in 0.089281385 seconds. Throughput is 1433.6694 records/second. Loss is 0.4843468. Sequential31006cbd's hyper parameters: Current learning rate is 0.0082904990880451. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 12160/60000][Iteration 1033][Wall Clock 117.385903626s] Trained 128 records in 0.100843477 seconds. Throughput is 1269.2938 records/second. Loss is 0.4183725. Sequential31006cbd's hyper parameters: Current learning rate is 0.008289124668435014. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:34 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 1034][Wall Clock 117.484748218s] Trained 128 records in 0.098844592 seconds. Throughput is 1294.962 records/second. Loss is 0.49440846. Sequential31006cbd's hyper parameters: Current learning rate is 0.00828775070445881. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 12416/60000][Iteration 1035][Wall Clock 117.586647107s] Trained 128 records in 0.101898889 seconds. Throughput is 1256.1472 records/second. Loss is 0.5407411. Sequential31006cbd's hyper parameters: Current learning rate is 0.008286377195889956. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 1036][Wall Clock 117.685774498s] Trained 128 records in 0.099127391 seconds. Throughput is 1291.2677 records/second. Loss is 0.512701. Sequential31006cbd's hyper parameters: Current learning rate is 0.008285004142502071. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 12672/60000][Iteration 1037][Wall Clock 117.77939805s] Trained 128 records in 0.093623552 seconds. Throughput is 1367.1774 records/second. Loss is 0.3641093. Sequential31006cbd's hyper parameters: Current learning rate is 0.00828363154406892. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 1038][Wall Clock 117.882278463s] Trained 128 records in 0.102880413 seconds. Throughput is 1244.163 records/second. Loss is 0.4800067. Sequential31006cbd's hyper parameters: Current learning rate is 0.008282259400364419. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 12928/60000][Iteration 1039][Wall Clock 117.964824139s] Trained 128 records in 0.082545676 seconds. Throughput is 1550.6566 records/second. Loss is 0.48960716. Sequential31006cbd's hyper parameters: Current learning rate is 0.008280887711162636. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 1040][Wall Clock 118.05684548s] Trained 128 records in 0.092021341 seconds. Throughput is 1390.9817 records/second. Loss is 0.47687182. Sequential31006cbd's hyper parameters: Current learning rate is 0.008279516476237788. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 13184/60000][Iteration 1041][Wall Clock 118.182311949s] Trained 128 records in 0.125466469 seconds. Throughput is 1020.19293 records/second. Loss is 0.39691874. Sequential31006cbd's hyper parameters: Current learning rate is 0.008278145695364239. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 1042][Wall Clock 118.277742196s] Trained 128 records in 0.095430247 seconds. Throughput is 1341.2938 records/second. Loss is 0.46560833. Sequential31006cbd's hyper parameters: Current learning rate is 0.008276775368316504. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 13440/60000][Iteration 1043][Wall Clock 118.367269483s] Trained 128 records in 0.089527287 seconds. Throughput is 1429.7317 records/second. Loss is 0.45248285. Sequential31006cbd's hyper parameters: Current learning rate is 0.00827540549486925. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:35 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 1044][Wall Clock 118.460691783s] Trained 128 records in 0.0934223 seconds. Throughput is 1370.1226 records/second. Loss is 0.40804058. Sequential31006cbd's hyper parameters: Current learning rate is 0.008274036074797285. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 13696/60000][Iteration 1045][Wall Clock 118.548940434s] Trained 128 records in 0.088248651 seconds. Throughput is 1450.4471 records/second. Loss is 0.5220084. Sequential31006cbd's hyper parameters: Current learning rate is 0.00827266710787558. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 1046][Wall Clock 118.648327431s] Trained 128 records in 0.099386997 seconds. Throughput is 1287.8948 records/second. Loss is 0.50545216. Sequential31006cbd's hyper parameters: Current learning rate is 0.008271298593879239. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 13952/60000][Iteration 1047][Wall Clock 118.762953453s] Trained 128 records in 0.114626022 seconds. Throughput is 1116.6749 records/second. Loss is 0.48965833. Sequential31006cbd's hyper parameters: Current learning rate is 0.008269930532583526. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 1048][Wall Clock 118.85269569s] Trained 128 records in 0.089742237 seconds. Throughput is 1426.3073 records/second. Loss is 0.4499138. Sequential31006cbd's hyper parameters: Current learning rate is 0.00826856292376385. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14208/60000][Iteration 1049][Wall Clock 118.933910538s] Trained 128 records in 0.081214848 seconds. Throughput is 1576.0665 records/second. Loss is 0.5121529. Sequential31006cbd's hyper parameters: Current learning rate is 0.008267195767195767. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 1050][Wall Clock 119.016981439s] Trained 128 records in 0.083070901 seconds. Throughput is 1540.8524 records/second. Loss is 0.6626427. Sequential31006cbd's hyper parameters: Current learning rate is 0.008265829062654984. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14464/60000][Iteration 1051][Wall Clock 119.098512397s] Trained 128 records in 0.081530958 seconds. Throughput is 1569.9558 records/second. Loss is 0.50812805. Sequential31006cbd's hyper parameters: Current learning rate is 0.008264462809917356. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 1052][Wall Clock 119.204740006s] Trained 128 records in 0.106227609 seconds. Throughput is 1204.9598 records/second. Loss is 0.5144901. Sequential31006cbd's hyper parameters: Current learning rate is 0.008263097008758883. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14720/60000][Iteration 1053][Wall Clock 119.289657523s] Trained 128 records in 0.084917517 seconds. Throughput is 1507.3451 records/second. Loss is 0.5262262. Sequential31006cbd's hyper parameters: Current learning rate is 0.008261731658955718. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:36 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 1054][Wall Clock 119.386407269s] Trained 128 records in 0.096749746 seconds. Throughput is 1323.0009 records/second. Loss is 0.547201. Sequential31006cbd's hyper parameters: Current learning rate is 0.008260366760284157. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 14976/60000][Iteration 1055][Wall Clock 119.485839973s] Trained 128 records in 0.099432704 seconds. Throughput is 1287.3027 records/second. Loss is 0.3959543. Sequential31006cbd's hyper parameters: Current learning rate is 0.008259002312520646. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 1056][Wall Clock 119.589116977s] Trained 128 records in 0.103277004 seconds. Throughput is 1239.3853 records/second. Loss is 0.5460078. Sequential31006cbd's hyper parameters: Current learning rate is 0.008257638315441783. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15232/60000][Iteration 1057][Wall Clock 119.710183111s] Trained 128 records in 0.121066134 seconds. Throughput is 1057.2734 records/second. Loss is 0.5479501. Sequential31006cbd's hyper parameters: Current learning rate is 0.008256274768824306. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 1058][Wall Clock 119.80439695s] Trained 128 records in 0.094213839 seconds. Throughput is 1358.6115 records/second. Loss is 0.43274868. Sequential31006cbd's hyper parameters: Current learning rate is 0.008254911672445105. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15488/60000][Iteration 1059][Wall Clock 119.91161285s] Trained 128 records in 0.1072159 seconds. Throughput is 1193.8528 records/second. Loss is 0.5112953. Sequential31006cbd's hyper parameters: Current learning rate is 0.008253549026081214. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 1060][Wall Clock 120.002781149s] Trained 128 records in 0.091168299 seconds. Throughput is 1403.9968 records/second. Loss is 0.49699408. Sequential31006cbd's hyper parameters: Current learning rate is 0.00825218682950982. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15744/60000][Iteration 1061][Wall Clock 120.133776566s] Trained 128 records in 0.130995417 seconds. Throughput is 977.13336 records/second. Loss is 0.48694912. Sequential31006cbd's hyper parameters: Current learning rate is 0.008250825082508252. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 1062][Wall Clock 120.2271715s] Trained 128 records in 0.093394934 seconds. Throughput is 1370.524 records/second. Loss is 0.48763. Sequential31006cbd's hyper parameters: Current learning rate is 0.008249463784853986. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 16000/60000][Iteration 1063][Wall Clock 120.318050896s] Trained 128 records in 0.090879396 seconds. Throughput is 1408.4601 records/second. Loss is 0.5057301. Sequential31006cbd's hyper parameters: Current learning rate is 0.008248102936324647. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:37 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 1064][Wall Clock 120.414779354s] Trained 128 records in 0.096728458 seconds. Throughput is 1323.292 records/second. Loss is 0.4200191. Sequential31006cbd's hyper parameters: Current learning rate is 0.008246742536698003. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 16256/60000][Iteration 1065][Wall Clock 120.520256169s] Trained 128 records in 0.105476815 seconds. Throughput is 1213.5369 records/second. Loss is 0.47249296. Sequential31006cbd's hyper parameters: Current learning rate is 0.008245382585751979. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 1066][Wall Clock 120.606203311s] Trained 128 records in 0.085947142 seconds. Throughput is 1489.2875 records/second. Loss is 0.46287838. Sequential31006cbd's hyper parameters: Current learning rate is 0.008244023083264633. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 16512/60000][Iteration 1067][Wall Clock 120.720238227s] Trained 128 records in 0.114034916 seconds. Throughput is 1122.4633 records/second. Loss is 0.4772548. Sequential31006cbd's hyper parameters: Current learning rate is 0.008242664029014177. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 1068][Wall Clock 120.809181578s] Trained 128 records in 0.088943351 seconds. Throughput is 1439.1183 records/second. Loss is 0.43799087. Sequential31006cbd's hyper parameters: Current learning rate is 0.008241305422778969. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 16768/60000][Iteration 1069][Wall Clock 120.955761588s] Trained 128 records in 0.14658001 seconds. Throughput is 873.2432 records/second. Loss is 0.51244634. Sequential31006cbd's hyper parameters: Current learning rate is 0.008239947264337508. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 1070][Wall Clock 121.084629312s] Trained 128 records in 0.128867724 seconds. Throughput is 993.2665 records/second. Loss is 0.40376705. Sequential31006cbd's hyper parameters: Current learning rate is 0.008238589553468446. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 17024/60000][Iteration 1071][Wall Clock 121.228018465s] Trained 128 records in 0.143389153 seconds. Throughput is 892.6756 records/second. Loss is 0.46778917. Sequential31006cbd's hyper parameters: Current learning rate is 0.008237232289950576. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:38 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 1072][Wall Clock 121.361433539s] Trained 128 records in 0.133415074 seconds. Throughput is 959.4118 records/second. Loss is 0.3788491. Sequential31006cbd's hyper parameters: Current learning rate is 0.00823587547356284. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 17280/60000][Iteration 1073][Wall Clock 121.480014534s] Trained 128 records in 0.118580995 seconds. Throughput is 1079.4309 records/second. Loss is 0.5381121. Sequential31006cbd's hyper parameters: Current learning rate is 0.008234519104084322. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 1074][Wall Clock 121.569176671s] Trained 128 records in 0.089162137 seconds. Throughput is 1435.587 records/second. Loss is 0.4394539. Sequential31006cbd's hyper parameters: Current learning rate is 0.008233163181294254. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 17536/60000][Iteration 1075][Wall Clock 121.655235101s] Trained 128 records in 0.08605843 seconds. Throughput is 1487.3616 records/second. Loss is 0.5146384. Sequential31006cbd's hyper parameters: Current learning rate is 0.008231807704972012. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 1076][Wall Clock 121.742208787s] Trained 128 records in 0.086973686 seconds. Throughput is 1471.7095 records/second. Loss is 0.4419069. Sequential31006cbd's hyper parameters: Current learning rate is 0.008230452674897118. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 17792/60000][Iteration 1077][Wall Clock 121.844830054s] Trained 128 records in 0.102621267 seconds. Throughput is 1247.3048 records/second. Loss is 0.40732518. Sequential31006cbd's hyper parameters: Current learning rate is 0.008229098090849242. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 1078][Wall Clock 121.947114471s] Trained 128 records in 0.102284417 seconds. Throughput is 1251.4125 records/second. Loss is 0.44214398. Sequential31006cbd's hyper parameters: Current learning rate is 0.008227743952608195. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 18048/60000][Iteration 1079][Wall Clock 122.029057946s] Trained 128 records in 0.081943475 seconds. Throughput is 1562.0524 records/second. Loss is 0.47063392. Sequential31006cbd's hyper parameters: Current learning rate is 0.008226390259953932. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 1080][Wall Clock 122.123720875s] Trained 128 records in 0.094662929 seconds. Throughput is 1352.1661 records/second. Loss is 0.43846837. Sequential31006cbd's hyper parameters: Current learning rate is 0.008225037012666558. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 18304/60000][Iteration 1081][Wall Clock 122.212478913s] Trained 128 records in 0.088758038 seconds. Throughput is 1442.1229 records/second. Loss is 0.503204. Sequential31006cbd's hyper parameters: Current learning rate is 0.008223684210526315. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 1082][Wall Clock 122.301561003s] Trained 128 records in 0.08908209 seconds. Throughput is 1436.877 records/second. Loss is 0.4071585. Sequential31006cbd's hyper parameters: Current learning rate is 0.0082223318533136. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:39 INFO  DistriOptimizer$:408 - [Epoch 3 18560/60000][Iteration 1083][Wall Clock 122.391981273s] Trained 128 records in 0.09042027 seconds. Throughput is 1415.6118 records/second. Loss is 0.45969403. Sequential31006cbd's hyper parameters: Current learning rate is 0.008220979940808944. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 1084][Wall Clock 122.479861609s] Trained 128 records in 0.087880336 seconds. Throughput is 1456.5261 records/second. Loss is 0.53296757. Sequential31006cbd's hyper parameters: Current learning rate is 0.008219628472793028. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 18816/60000][Iteration 1085][Wall Clock 122.560293437s] Trained 128 records in 0.080431828 seconds. Throughput is 1591.4098 records/second. Loss is 0.43241906. Sequential31006cbd's hyper parameters: Current learning rate is 0.00821827744904668. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 1086][Wall Clock 122.644153473s] Trained 128 records in 0.083860036 seconds. Throughput is 1526.3528 records/second. Loss is 0.38457865. Sequential31006cbd's hyper parameters: Current learning rate is 0.008216926869350863. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19072/60000][Iteration 1087][Wall Clock 122.737652397s] Trained 128 records in 0.093498924 seconds. Throughput is 1368.9998 records/second. Loss is 0.42307776. Sequential31006cbd's hyper parameters: Current learning rate is 0.00821557673348669. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 1088][Wall Clock 122.832939848s] Trained 128 records in 0.095287451 seconds. Throughput is 1343.3038 records/second. Loss is 0.5071402. Sequential31006cbd's hyper parameters: Current learning rate is 0.008214227041235419. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19328/60000][Iteration 1089][Wall Clock 122.934050845s] Trained 128 records in 0.101110997 seconds. Throughput is 1265.9355 records/second. Loss is 0.49609315. Sequential31006cbd's hyper parameters: Current learning rate is 0.00821287779237845. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 1090][Wall Clock 123.038434501s] Trained 128 records in 0.104383656 seconds. Throughput is 1226.2456 records/second. Loss is 0.54617167. Sequential31006cbd's hyper parameters: Current learning rate is 0.008211528986697324. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19584/60000][Iteration 1091][Wall Clock 123.127750845s] Trained 128 records in 0.089316344 seconds. Throughput is 1433.1084 records/second. Loss is 0.36681205. Sequential31006cbd's hyper parameters: Current learning rate is 0.008210180623973728. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 1092][Wall Clock 123.223391493s] Trained 128 records in 0.095640648 seconds. Throughput is 1338.3431 records/second. Loss is 0.5052379. Sequential31006cbd's hyper parameters: Current learning rate is 0.008208832703989493. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19840/60000][Iteration 1093][Wall Clock 123.308967692s] Trained 128 records in 0.085576199 seconds. Throughput is 1495.743 records/second. Loss is 0.44902635. Sequential31006cbd's hyper parameters: Current learning rate is 0.008207485226526593. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:40 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 1094][Wall Clock 123.396350206s] Trained 128 records in 0.087382514 seconds. Throughput is 1464.824 records/second. Loss is 0.5065729. Sequential31006cbd's hyper parameters: Current learning rate is 0.008206138191367143. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20096/60000][Iteration 1095][Wall Clock 123.505080813s] Trained 128 records in 0.108730607 seconds. Throughput is 1177.2214 records/second. Loss is 0.4685144. Sequential31006cbd's hyper parameters: Current learning rate is 0.008204791598293402. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 1096][Wall Clock 123.618581109s] Trained 128 records in 0.113500296 seconds. Throughput is 1127.7504 records/second. Loss is 0.4580197. Sequential31006cbd's hyper parameters: Current learning rate is 0.008203445447087777. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20352/60000][Iteration 1097][Wall Clock 123.698298965s] Trained 128 records in 0.079717856 seconds. Throughput is 1605.6627 records/second. Loss is 0.4347288. Sequential31006cbd's hyper parameters: Current learning rate is 0.008202099737532808. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 1098][Wall Clock 123.786283271s] Trained 128 records in 0.087984306 seconds. Throughput is 1454.8048 records/second. Loss is 0.38592106. Sequential31006cbd's hyper parameters: Current learning rate is 0.008200754469411186. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20608/60000][Iteration 1099][Wall Clock 123.872705073s] Trained 128 records in 0.086421802 seconds. Throughput is 1481.1078 records/second. Loss is 0.38616806. Sequential31006cbd's hyper parameters: Current learning rate is 0.008199409642505739. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 1100][Wall Clock 123.960283532s] Trained 128 records in 0.087578459 seconds. Throughput is 1461.5466 records/second. Loss is 0.447041. Sequential31006cbd's hyper parameters: Current learning rate is 0.008198065256599442. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20864/60000][Iteration 1101][Wall Clock 124.045224407s] Trained 128 records in 0.084940875 seconds. Throughput is 1506.9305 records/second. Loss is 0.51286244. Sequential31006cbd's hyper parameters: Current learning rate is 0.00819672131147541. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 1102][Wall Clock 124.144341106s] Trained 128 records in 0.099116699 seconds. Throughput is 1291.407 records/second. Loss is 0.44843438. Sequential31006cbd's hyper parameters: Current learning rate is 0.0081953778069169. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 21120/60000][Iteration 1103][Wall Clock 124.250132993s] Trained 128 records in 0.105791887 seconds. Throughput is 1209.9226 records/second. Loss is 0.43759167. Sequential31006cbd's hyper parameters: Current learning rate is 0.00819403474270731. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 1104][Wall Clock 124.336873205s] Trained 128 records in 0.086740212 seconds. Throughput is 1475.6709 records/second. Loss is 0.43299946. Sequential31006cbd's hyper parameters: Current learning rate is 0.008192692118630182. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:41 INFO  DistriOptimizer$:408 - [Epoch 3 21376/60000][Iteration 1105][Wall Clock 124.422221206s] Trained 128 records in 0.085348001 seconds. Throughput is 1499.7422 records/second. Loss is 0.46682066. Sequential31006cbd's hyper parameters: Current learning rate is 0.0081913499344692. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 1106][Wall Clock 124.514676208s] Trained 128 records in 0.092455002 seconds. Throughput is 1384.4573 records/second. Loss is 0.39483422. Sequential31006cbd's hyper parameters: Current learning rate is 0.00819000819000819. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 21632/60000][Iteration 1107][Wall Clock 124.600204528s] Trained 128 records in 0.08552832 seconds. Throughput is 1496.5803 records/second. Loss is 0.5309805. Sequential31006cbd's hyper parameters: Current learning rate is 0.008188666885031117. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 1108][Wall Clock 124.687526639s] Trained 128 records in 0.087322111 seconds. Throughput is 1465.8373 records/second. Loss is 0.40855855. Sequential31006cbd's hyper parameters: Current learning rate is 0.008187326019322089. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 21888/60000][Iteration 1109][Wall Clock 124.774741685s] Trained 128 records in 0.087215046 seconds. Throughput is 1467.6367 records/second. Loss is 0.416664. Sequential31006cbd's hyper parameters: Current learning rate is 0.008185985592665358. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 1110][Wall Clock 124.856691166s] Trained 128 records in 0.081949481 seconds. Throughput is 1561.9379 records/second. Loss is 0.43561727. Sequential31006cbd's hyper parameters: Current learning rate is 0.00818464560484531. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22144/60000][Iteration 1111][Wall Clock 124.943172325s] Trained 128 records in 0.086481159 seconds. Throughput is 1480.0912 records/second. Loss is 0.45348918. Sequential31006cbd's hyper parameters: Current learning rate is 0.008183306055646482. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 1112][Wall Clock 125.026744328s] Trained 128 records in 0.083572003 seconds. Throughput is 1531.6134 records/second. Loss is 0.47142774. Sequential31006cbd's hyper parameters: Current learning rate is 0.008181966944853543. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22400/60000][Iteration 1113][Wall Clock 125.118437241s] Trained 128 records in 0.091692913 seconds. Throughput is 1395.964 records/second. Loss is 0.45562473. Sequential31006cbd's hyper parameters: Current learning rate is 0.008180628272251309. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 1114][Wall Clock 125.199189923s] Trained 128 records in 0.080752682 seconds. Throughput is 1585.0865 records/second. Loss is 0.4608092. Sequential31006cbd's hyper parameters: Current learning rate is 0.008179290037624735. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22656/60000][Iteration 1115][Wall Clock 125.285057506s] Trained 128 records in 0.085867583 seconds. Throughput is 1490.6674 records/second. Loss is 0.46029553. Sequential31006cbd's hyper parameters: Current learning rate is 0.008177952240758915. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:42 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 1116][Wall Clock 125.393164912s] Trained 128 records in 0.108107406 seconds. Throughput is 1184.0077 records/second. Loss is 0.47768492. Sequential31006cbd's hyper parameters: Current learning rate is 0.008176614881439084. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 22912/60000][Iteration 1117][Wall Clock 125.50639467s] Trained 128 records in 0.113229758 seconds. Throughput is 1130.4448 records/second. Loss is 0.4437575. Sequential31006cbd's hyper parameters: Current learning rate is 0.008175277959450621. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 1118][Wall Clock 125.607859476s] Trained 128 records in 0.101464806 seconds. Throughput is 1261.5211 records/second. Loss is 0.5211152. Sequential31006cbd's hyper parameters: Current learning rate is 0.008173941474579042. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23168/60000][Iteration 1119][Wall Clock 125.719619264s] Trained 128 records in 0.111759788 seconds. Throughput is 1145.3136 records/second. Loss is 0.478688. Sequential31006cbd's hyper parameters: Current learning rate is 0.008172605426610004. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 1120][Wall Clock 125.846137437s] Trained 128 records in 0.126518173 seconds. Throughput is 1011.71234 records/second. Loss is 0.3963323. Sequential31006cbd's hyper parameters: Current learning rate is 0.008171269815329302. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23424/60000][Iteration 1121][Wall Clock 125.95866966s] Trained 128 records in 0.112532223 seconds. Throughput is 1137.452 records/second. Loss is 0.50856954. Sequential31006cbd's hyper parameters: Current learning rate is 0.008169934640522876. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 1122][Wall Clock 126.073906943s] Trained 128 records in 0.115237283 seconds. Throughput is 1110.7517 records/second. Loss is 0.47969815. Sequential31006cbd's hyper parameters: Current learning rate is 0.008168599901976801. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23680/60000][Iteration 1123][Wall Clock 126.165217643s] Trained 128 records in 0.0913107 seconds. Throughput is 1401.8073 records/second. Loss is 0.44253168. Sequential31006cbd's hyper parameters: Current learning rate is 0.008167265599477296. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 1124][Wall Clock 126.250839715s] Trained 128 records in 0.085622072 seconds. Throughput is 1494.9417 records/second. Loss is 0.43671474. Sequential31006cbd's hyper parameters: Current learning rate is 0.008165931732810713. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 23936/60000][Iteration 1125][Wall Clock 126.336468184s] Trained 128 records in 0.085628469 seconds. Throughput is 1494.8298 records/second. Loss is 0.48253232. Sequential31006cbd's hyper parameters: Current learning rate is 0.008164598301763552. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:43 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 1126][Wall Clock 126.438928789s] Trained 128 records in 0.102460605 seconds. Throughput is 1249.2606 records/second. Loss is 0.38561517. Sequential31006cbd's hyper parameters: Current learning rate is 0.008163265306122448. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24192/60000][Iteration 1127][Wall Clock 126.523016523s] Trained 128 records in 0.084087734 seconds. Throughput is 1522.2196 records/second. Loss is 0.69587374. Sequential31006cbd's hyper parameters: Current learning rate is 0.008161932745674175. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 1128][Wall Clock 126.629167322s] Trained 128 records in 0.106150799 seconds. Throughput is 1205.8317 records/second. Loss is 0.47724992. Sequential31006cbd's hyper parameters: Current learning rate is 0.008160600620205648. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24448/60000][Iteration 1129][Wall Clock 126.714005661s] Trained 128 records in 0.084838339 seconds. Throughput is 1508.7518 records/second. Loss is 0.44733292. Sequential31006cbd's hyper parameters: Current learning rate is 0.008159268929503917. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 1130][Wall Clock 126.81254586s] Trained 128 records in 0.098540199 seconds. Throughput is 1298.9623 records/second. Loss is 0.49778342. Sequential31006cbd's hyper parameters: Current learning rate is 0.008157937673356175. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24704/60000][Iteration 1131][Wall Clock 126.89857015s] Trained 128 records in 0.08602429 seconds. Throughput is 1487.9518 records/second. Loss is 0.49113753. Sequential31006cbd's hyper parameters: Current learning rate is 0.008156606851549756. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 1132][Wall Clock 126.976732451s] Trained 128 records in 0.078162301 seconds. Throughput is 1637.6182 records/second. Loss is 0.43264014. Sequential31006cbd's hyper parameters: Current learning rate is 0.008155276463872126. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 24960/60000][Iteration 1133][Wall Clock 127.061424211s] Trained 128 records in 0.08469176 seconds. Throughput is 1511.363 records/second. Loss is 0.40122464. Sequential31006cbd's hyper parameters: Current learning rate is 0.008153946510110895. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 1134][Wall Clock 127.156402308s] Trained 128 records in 0.094978097 seconds. Throughput is 1347.6792 records/second. Loss is 0.42429945. Sequential31006cbd's hyper parameters: Current learning rate is 0.008152616990053808. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 25216/60000][Iteration 1135][Wall Clock 127.243367315s] Trained 128 records in 0.086965007 seconds. Throughput is 1471.8563 records/second. Loss is 0.5423124. Sequential31006cbd's hyper parameters: Current learning rate is 0.008151287903488753. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 1136][Wall Clock 127.331348321s] Trained 128 records in 0.087981006 seconds. Throughput is 1454.8595 records/second. Loss is 0.446286. Sequential31006cbd's hyper parameters: Current learning rate is 0.008149959250203748. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:44 INFO  DistriOptimizer$:408 - [Epoch 3 25472/60000][Iteration 1137][Wall Clock 127.418115107s] Trained 128 records in 0.086766786 seconds. Throughput is 1475.2189 records/second. Loss is 0.42900845. Sequential31006cbd's hyper parameters: Current learning rate is 0.008148631029986962. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 1138][Wall Clock 127.504636786s] Trained 128 records in 0.086521679 seconds. Throughput is 1479.3981 records/second. Loss is 0.5470036. Sequential31006cbd's hyper parameters: Current learning rate is 0.008147303242626691. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 25728/60000][Iteration 1139][Wall Clock 127.598219035s] Trained 128 records in 0.093582249 seconds. Throughput is 1367.7808 records/second. Loss is 0.36522385. Sequential31006cbd's hyper parameters: Current learning rate is 0.008145975887911373. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 1140][Wall Clock 127.687081936s] Trained 128 records in 0.088862901 seconds. Throughput is 1440.4211 records/second. Loss is 0.46712184. Sequential31006cbd's hyper parameters: Current learning rate is 0.008144648965629582. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 25984/60000][Iteration 1141][Wall Clock 127.771462415s] Trained 128 records in 0.084380479 seconds. Throughput is 1516.9386 records/second. Loss is 0.5250176. Sequential31006cbd's hyper parameters: Current learning rate is 0.008143322475570033. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 1142][Wall Clock 127.867812898s] Trained 128 records in 0.096350483 seconds. Throughput is 1328.4832 records/second. Loss is 0.51827884. Sequential31006cbd's hyper parameters: Current learning rate is 0.008141996417521577. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26240/60000][Iteration 1143][Wall Clock 127.959793855s] Trained 128 records in 0.091980957 seconds. Throughput is 1391.5924 records/second. Loss is 0.371436. Sequential31006cbd's hyper parameters: Current learning rate is 0.008140670791273202. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 1144][Wall Clock 128.059690059s] Trained 128 records in 0.099896204 seconds. Throughput is 1281.33 records/second. Loss is 0.4299718. Sequential31006cbd's hyper parameters: Current learning rate is 0.008139345596614033. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26496/60000][Iteration 1145][Wall Clock 128.15907933s] Trained 128 records in 0.099389271 seconds. Throughput is 1287.8654 records/second. Loss is 0.47460642. Sequential31006cbd's hyper parameters: Current learning rate is 0.008138020833333332. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 1146][Wall Clock 128.248357072s] Trained 128 records in 0.089277742 seconds. Throughput is 1433.728 records/second. Loss is 0.4439344. Sequential31006cbd's hyper parameters: Current learning rate is 0.008136696501220505. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26752/60000][Iteration 1147][Wall Clock 128.329048923s] Trained 128 records in 0.080691851 seconds. Throughput is 1586.2816 records/second. Loss is 0.4128341. Sequential31006cbd's hyper parameters: Current learning rate is 0.008135372600065083. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:45 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 1148][Wall Clock 128.423604126s] Trained 128 records in 0.094555203 seconds. Throughput is 1353.7065 records/second. Loss is 0.5018722. Sequential31006cbd's hyper parameters: Current learning rate is 0.008134049129656743. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27008/60000][Iteration 1149][Wall Clock 128.51185561s] Trained 128 records in 0.088251484 seconds. Throughput is 1450.4005 records/second. Loss is 0.37667894. Sequential31006cbd's hyper parameters: Current learning rate is 0.008132726089785295. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 1150][Wall Clock 128.603442036s] Trained 128 records in 0.091586426 seconds. Throughput is 1397.587 records/second. Loss is 0.4701905. Sequential31006cbd's hyper parameters: Current learning rate is 0.00813140348024069. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27264/60000][Iteration 1151][Wall Clock 128.681799442s] Trained 128 records in 0.078357406 seconds. Throughput is 1633.5405 records/second. Loss is 0.37959367. Sequential31006cbd's hyper parameters: Current learning rate is 0.008130081300813009. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 1152][Wall Clock 128.769833704s] Trained 128 records in 0.088034262 seconds. Throughput is 1453.9794 records/second. Loss is 0.5996684. Sequential31006cbd's hyper parameters: Current learning rate is 0.008128759551292473. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27520/60000][Iteration 1153][Wall Clock 128.879473755s] Trained 128 records in 0.109640051 seconds. Throughput is 1167.4565 records/second. Loss is 0.4615339. Sequential31006cbd's hyper parameters: Current learning rate is 0.008127438231469442. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 1154][Wall Clock 128.962028328s] Trained 128 records in 0.082554573 seconds. Throughput is 1550.4895 records/second. Loss is 0.5615749. Sequential31006cbd's hyper parameters: Current learning rate is 0.008126117341134406. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27776/60000][Iteration 1155][Wall Clock 129.045353851s] Trained 128 records in 0.083325523 seconds. Throughput is 1536.144 records/second. Loss is 0.43309766. Sequential31006cbd's hyper parameters: Current learning rate is 0.008124796880077998. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 1156][Wall Clock 129.137581983s] Trained 128 records in 0.092228132 seconds. Throughput is 1387.8629 records/second. Loss is 0.43524766. Sequential31006cbd's hyper parameters: Current learning rate is 0.008123476848090982. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 28032/60000][Iteration 1157][Wall Clock 129.228755805s] Trained 128 records in 0.091173822 seconds. Throughput is 1403.9117 records/second. Loss is 0.3853078. Sequential31006cbd's hyper parameters: Current learning rate is 0.008122157244964262. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 1158][Wall Clock 129.311681063s] Trained 128 records in 0.082925258 seconds. Throughput is 1543.5586 records/second. Loss is 0.39533353. Sequential31006cbd's hyper parameters: Current learning rate is 0.008120838070488873. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:46 INFO  DistriOptimizer$:408 - [Epoch 3 28288/60000][Iteration 1159][Wall Clock 129.39742843s] Trained 128 records in 0.085747367 seconds. Throughput is 1492.7572 records/second. Loss is 0.40924478. Sequential31006cbd's hyper parameters: Current learning rate is 0.008119519324455992. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 1160][Wall Clock 129.483346626s] Trained 128 records in 0.085918196 seconds. Throughput is 1489.7892 records/second. Loss is 0.45910645. Sequential31006cbd's hyper parameters: Current learning rate is 0.008118201006656925. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 28544/60000][Iteration 1161][Wall Clock 129.591199897s] Trained 128 records in 0.107853271 seconds. Throughput is 1186.7976 records/second. Loss is 0.3928418. Sequential31006cbd's hyper parameters: Current learning rate is 0.008116883116883118. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 1162][Wall Clock 129.691919397s] Trained 128 records in 0.1007195 seconds. Throughput is 1270.8562 records/second. Loss is 0.6597929. Sequential31006cbd's hyper parameters: Current learning rate is 0.008115565654926148. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 28800/60000][Iteration 1163][Wall Clock 129.789143895s] Trained 128 records in 0.097224498 seconds. Throughput is 1316.5406 records/second. Loss is 0.4950475. Sequential31006cbd's hyper parameters: Current learning rate is 0.008114248620577734. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 1164][Wall Clock 129.900992371s] Trained 128 records in 0.111848476 seconds. Throughput is 1144.4054 records/second. Loss is 0.40314662. Sequential31006cbd's hyper parameters: Current learning rate is 0.008112932013629727. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 29056/60000][Iteration 1165][Wall Clock 129.996090699s] Trained 128 records in 0.095098328 seconds. Throughput is 1345.9752 records/second. Loss is 0.4446245. Sequential31006cbd's hyper parameters: Current learning rate is 0.008111615833874108. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 1166][Wall Clock 130.085101626s] Trained 128 records in 0.089010927 seconds. Throughput is 1438.0258 records/second. Loss is 0.46954313. Sequential31006cbd's hyper parameters: Current learning rate is 0.008110300081103. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 29312/60000][Iteration 1167][Wall Clock 130.179865724s] Trained 128 records in 0.094764098 seconds. Throughput is 1350.7225 records/second. Loss is 0.3469662. Sequential31006cbd's hyper parameters: Current learning rate is 0.00810898475510866. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 1168][Wall Clock 130.271606386s] Trained 128 records in 0.091740662 seconds. Throughput is 1395.2374 records/second. Loss is 0.4363888. Sequential31006cbd's hyper parameters: Current learning rate is 0.008107669855683477. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:47 INFO  DistriOptimizer$:408 - [Epoch 3 29568/60000][Iteration 1169][Wall Clock 130.361298983s] Trained 128 records in 0.089692597 seconds. Throughput is 1427.0966 records/second. Loss is 0.3188851. Sequential31006cbd's hyper parameters: Current learning rate is 0.008106355382619975. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 1170][Wall Clock 130.497980745s] Trained 128 records in 0.136681762 seconds. Throughput is 936.48193 records/second. Loss is 0.44838956. Sequential31006cbd's hyper parameters: Current learning rate is 0.008105041335710812. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 29824/60000][Iteration 1171][Wall Clock 130.589387919s] Trained 128 records in 0.091407174 seconds. Throughput is 1400.3278 records/second. Loss is 0.44705948. Sequential31006cbd's hyper parameters: Current learning rate is 0.008103727714748784. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 1172][Wall Clock 130.682521175s] Trained 128 records in 0.093133256 seconds. Throughput is 1374.3748 records/second. Loss is 0.49151027. Sequential31006cbd's hyper parameters: Current learning rate is 0.00810241451952682. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30080/60000][Iteration 1173][Wall Clock 130.766171868s] Trained 128 records in 0.083650693 seconds. Throughput is 1530.1726 records/second. Loss is 0.41665852. Sequential31006cbd's hyper parameters: Current learning rate is 0.00810110174983798. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 1174][Wall Clock 130.848781491s] Trained 128 records in 0.082609623 seconds. Throughput is 1549.4563 records/second. Loss is 0.5484576. Sequential31006cbd's hyper parameters: Current learning rate is 0.008099789405475458. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30336/60000][Iteration 1175][Wall Clock 130.930605232s] Trained 128 records in 0.081823741 seconds. Throughput is 1564.3381 records/second. Loss is 0.47686127. Sequential31006cbd's hyper parameters: Current learning rate is 0.008098477486232589. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 1176][Wall Clock 131.015424972s] Trained 128 records in 0.08481974 seconds. Throughput is 1509.0826 records/second. Loss is 0.48545873. Sequential31006cbd's hyper parameters: Current learning rate is 0.008097165991902834. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30592/60000][Iteration 1177][Wall Clock 131.100945847s] Trained 128 records in 0.085520875 seconds. Throughput is 1496.7106 records/second. Loss is 0.29953203. Sequential31006cbd's hyper parameters: Current learning rate is 0.008095854922279792. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 1178][Wall Clock 131.192899012s] Trained 128 records in 0.091953165 seconds. Throughput is 1392.013 records/second. Loss is 0.41463897. Sequential31006cbd's hyper parameters: Current learning rate is 0.008094544277157195. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30848/60000][Iteration 1179][Wall Clock 131.289116846s] Trained 128 records in 0.096217834 seconds. Throughput is 1330.3147 records/second. Loss is 0.38912308. Sequential31006cbd's hyper parameters: Current learning rate is 0.00809323405632891. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:48 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 1180][Wall Clock 131.372359488s] Trained 128 records in 0.083242642 seconds. Throughput is 1537.6735 records/second. Loss is 0.45931128. Sequential31006cbd's hyper parameters: Current learning rate is 0.00809192425958893. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31104/60000][Iteration 1181][Wall Clock 131.45603618s] Trained 128 records in 0.083676692 seconds. Throughput is 1529.6973 records/second. Loss is 0.46828204. Sequential31006cbd's hyper parameters: Current learning rate is 0.008090614886731393. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 1182][Wall Clock 131.540880212s] Trained 128 records in 0.084844032 seconds. Throughput is 1508.6506 records/second. Loss is 0.4340328. Sequential31006cbd's hyper parameters: Current learning rate is 0.008089305937550558. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31360/60000][Iteration 1183][Wall Clock 131.63258489s] Trained 128 records in 0.091704678 seconds. Throughput is 1395.7848 records/second. Loss is 0.4614352. Sequential31006cbd's hyper parameters: Current learning rate is 0.008087997411840828. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 1184][Wall Clock 131.721870843s] Trained 128 records in 0.089285953 seconds. Throughput is 1433.5962 records/second. Loss is 0.45549417. Sequential31006cbd's hyper parameters: Current learning rate is 0.008086689309396733. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31616/60000][Iteration 1185][Wall Clock 131.797919061s] Trained 128 records in 0.076048218 seconds. Throughput is 1683.1427 records/second. Loss is 0.3567465. Sequential31006cbd's hyper parameters: Current learning rate is 0.008085381630012937. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 1186][Wall Clock 131.890378445s] Trained 128 records in 0.092459384 seconds. Throughput is 1384.3917 records/second. Loss is 0.28869998. Sequential31006cbd's hyper parameters: Current learning rate is 0.008084074373484235. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 31872/60000][Iteration 1187][Wall Clock 131.980831611s] Trained 128 records in 0.090453166 seconds. Throughput is 1415.097 records/second. Loss is 0.42810136. Sequential31006cbd's hyper parameters: Current learning rate is 0.008082767539605561. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 1188][Wall Clock 132.066990322s] Trained 128 records in 0.086158711 seconds. Throughput is 1485.6305 records/second. Loss is 0.47632793. Sequential31006cbd's hyper parameters: Current learning rate is 0.008081461128171973. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 32128/60000][Iteration 1189][Wall Clock 132.154332573s] Trained 128 records in 0.087342251 seconds. Throughput is 1465.4993 records/second. Loss is 0.51987666. Sequential31006cbd's hyper parameters: Current learning rate is 0.00808015513897867. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 1190][Wall Clock 132.245645386s] Trained 128 records in 0.091312813 seconds. Throughput is 1401.7748 records/second. Loss is 0.41927114. Sequential31006cbd's hyper parameters: Current learning rate is 0.008078849571820973. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:49 INFO  DistriOptimizer$:408 - [Epoch 3 32384/60000][Iteration 1191][Wall Clock 132.325574127s] Trained 128 records in 0.079928741 seconds. Throughput is 1601.4265 records/second. Loss is 0.33204168. Sequential31006cbd's hyper parameters: Current learning rate is 0.008077544426494346. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 1192][Wall Clock 132.413961066s] Trained 128 records in 0.088386939 seconds. Throughput is 1448.1777 records/second. Loss is 0.4832373. Sequential31006cbd's hyper parameters: Current learning rate is 0.008076239702794379. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 32640/60000][Iteration 1193][Wall Clock 132.515816157s] Trained 128 records in 0.101855091 seconds. Throughput is 1256.6873 records/second. Loss is 0.44492382. Sequential31006cbd's hyper parameters: Current learning rate is 0.008074935400516797. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 1194][Wall Clock 132.612466985s] Trained 128 records in 0.096650828 seconds. Throughput is 1324.3549 records/second. Loss is 0.44421864. Sequential31006cbd's hyper parameters: Current learning rate is 0.008073631519457452. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 32896/60000][Iteration 1195][Wall Clock 132.716801382s] Trained 128 records in 0.104334397 seconds. Throughput is 1226.8246 records/second. Loss is 0.4023757. Sequential31006cbd's hyper parameters: Current learning rate is 0.008072328059412335. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 1196][Wall Clock 132.826759395s] Trained 128 records in 0.109958013 seconds. Throughput is 1164.0807 records/second. Loss is 0.53870964. Sequential31006cbd's hyper parameters: Current learning rate is 0.008071025020177562. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33152/60000][Iteration 1197][Wall Clock 132.923962554s] Trained 128 records in 0.097203159 seconds. Throughput is 1316.8296 records/second. Loss is 0.3931209. Sequential31006cbd's hyper parameters: Current learning rate is 0.008069722401549387. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 1198][Wall Clock 133.023085429s] Trained 128 records in 0.099122875 seconds. Throughput is 1291.3265 records/second. Loss is 0.3077345. Sequential31006cbd's hyper parameters: Current learning rate is 0.008068420203324189. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33408/60000][Iteration 1199][Wall Clock 133.115942805s] Trained 128 records in 0.092857376 seconds. Throughput is 1378.4581 records/second. Loss is 0.45069855. Sequential31006cbd's hyper parameters: Current learning rate is 0.008067118425298484. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 1200][Wall Clock 133.21270845s] Trained 128 records in 0.096765645 seconds. Throughput is 1322.7836 records/second. Loss is 0.4851431. Sequential31006cbd's hyper parameters: Current learning rate is 0.008065817067268914. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33664/60000][Iteration 1201][Wall Clock 133.298352195s] Trained 128 records in 0.085643745 seconds. Throughput is 1494.5634 records/second. Loss is 0.49138197. Sequential31006cbd's hyper parameters: Current learning rate is 0.008064516129032258. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:50 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 1202][Wall Clock 133.376614542s] Trained 128 records in 0.078262347 seconds. Throughput is 1635.5248 records/second. Loss is 0.48723277. Sequential31006cbd's hyper parameters: Current learning rate is 0.008063215610385421. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 33920/60000][Iteration 1203][Wall Clock 133.463466394s] Trained 128 records in 0.086851852 seconds. Throughput is 1473.774 records/second. Loss is 0.49207315. Sequential31006cbd's hyper parameters: Current learning rate is 0.008061915511125443. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 1204][Wall Clock 133.571418223s] Trained 128 records in 0.107951829 seconds. Throughput is 1185.7141 records/second. Loss is 0.45660952. Sequential31006cbd's hyper parameters: Current learning rate is 0.008060615831049493. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34176/60000][Iteration 1205][Wall Clock 133.659982284s] Trained 128 records in 0.088564061 seconds. Throughput is 1445.2815 records/second. Loss is 0.5512038. Sequential31006cbd's hyper parameters: Current learning rate is 0.008059316569954867. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 1206][Wall Clock 133.752596644s] Trained 128 records in 0.09261436 seconds. Throughput is 1382.0751 records/second. Loss is 0.43153587. Sequential31006cbd's hyper parameters: Current learning rate is 0.008058017727639. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34432/60000][Iteration 1207][Wall Clock 133.834854202s] Trained 128 records in 0.082257558 seconds. Throughput is 1556.0879 records/second. Loss is 0.43719903. Sequential31006cbd's hyper parameters: Current learning rate is 0.008056719303899451. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 1208][Wall Clock 133.916891772s] Trained 128 records in 0.08203757 seconds. Throughput is 1560.2607 records/second. Loss is 0.47486973. Sequential31006cbd's hyper parameters: Current learning rate is 0.008055421298533913. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34688/60000][Iteration 1209][Wall Clock 134.00150803s] Trained 128 records in 0.084616258 seconds. Throughput is 1512.7117 records/second. Loss is 0.4202707. Sequential31006cbd's hyper parameters: Current learning rate is 0.008054123711340205. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 1210][Wall Clock 134.088232505s] Trained 128 records in 0.086724475 seconds. Throughput is 1475.9386 records/second. Loss is 0.50218046. Sequential31006cbd's hyper parameters: Current learning rate is 0.008052826542116283. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 34944/60000][Iteration 1211][Wall Clock 134.175265823s] Trained 128 records in 0.087033318 seconds. Throughput is 1470.7012 records/second. Loss is 0.5063404. Sequential31006cbd's hyper parameters: Current learning rate is 0.008051529790660227. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 1212][Wall Clock 134.274863609s] Trained 128 records in 0.099597786 seconds. Throughput is 1285.1691 records/second. Loss is 0.4398981. Sequential31006cbd's hyper parameters: Current learning rate is 0.008050233456770247. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:51 INFO  DistriOptimizer$:408 - [Epoch 3 35200/60000][Iteration 1213][Wall Clock 134.364293905s] Trained 128 records in 0.089430296 seconds. Throughput is 1431.2823 records/second. Loss is 0.4415718. Sequential31006cbd's hyper parameters: Current learning rate is 0.008048937540244688. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 1214][Wall Clock 134.454733188s] Trained 128 records in 0.090439283 seconds. Throughput is 1415.3142 records/second. Loss is 0.39784884. Sequential31006cbd's hyper parameters: Current learning rate is 0.008047642040882022. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 35456/60000][Iteration 1215][Wall Clock 134.553879129s] Trained 128 records in 0.099145941 seconds. Throughput is 1291.0261 records/second. Loss is 0.41335133. Sequential31006cbd's hyper parameters: Current learning rate is 0.008046346958480851. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 1216][Wall Clock 134.66378955s] Trained 128 records in 0.109910421 seconds. Throughput is 1164.5847 records/second. Loss is 0.41284138. Sequential31006cbd's hyper parameters: Current learning rate is 0.008045052292839902. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 35712/60000][Iteration 1217][Wall Clock 134.762177768s] Trained 128 records in 0.098388218 seconds. Throughput is 1300.9688 records/second. Loss is 0.47461322. Sequential31006cbd's hyper parameters: Current learning rate is 0.008043758043758044. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 1218][Wall Clock 134.851575449s] Trained 128 records in 0.089397681 seconds. Throughput is 1431.8044 records/second. Loss is 0.35942933. Sequential31006cbd's hyper parameters: Current learning rate is 0.00804246421103426. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 35968/60000][Iteration 1219][Wall Clock 134.957610323s] Trained 128 records in 0.106034874 seconds. Throughput is 1207.15 records/second. Loss is 0.5746508. Sequential31006cbd's hyper parameters: Current learning rate is 0.008041170794467674. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 1220][Wall Clock 135.09783977s] Trained 128 records in 0.140229447 seconds. Throughput is 912.78973 records/second. Loss is 0.44602016. Sequential31006cbd's hyper parameters: Current learning rate is 0.008039877793857533. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 36224/60000][Iteration 1221][Wall Clock 135.211691821s] Trained 128 records in 0.113852051 seconds. Throughput is 1124.2661 records/second. Loss is 0.41342428. Sequential31006cbd's hyper parameters: Current learning rate is 0.008038585209003215. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 1222][Wall Clock 135.300222382s] Trained 128 records in 0.088530561 seconds. Throughput is 1445.8284 records/second. Loss is 0.49890375. Sequential31006cbd's hyper parameters: Current learning rate is 0.008037293039704229. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:52 INFO  DistriOptimizer$:408 - [Epoch 3 36480/60000][Iteration 1223][Wall Clock 135.385313759s] Trained 128 records in 0.085091377 seconds. Throughput is 1504.2653 records/second. Loss is 0.4201095. Sequential31006cbd's hyper parameters: Current learning rate is 0.008036001285760206. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 1224][Wall Clock 135.469611286s] Trained 128 records in 0.084297527 seconds. Throughput is 1518.4312 records/second. Loss is 0.5232336. Sequential31006cbd's hyper parameters: Current learning rate is 0.008034709946970914. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 36736/60000][Iteration 1225][Wall Clock 135.548824446s] Trained 128 records in 0.07921316 seconds. Throughput is 1615.8932 records/second. Loss is 0.44853267. Sequential31006cbd's hyper parameters: Current learning rate is 0.008033419023136246. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 1226][Wall Clock 135.629692718s] Trained 128 records in 0.080868272 seconds. Throughput is 1582.8209 records/second. Loss is 0.5568862. Sequential31006cbd's hyper parameters: Current learning rate is 0.008032128514056224. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 36992/60000][Iteration 1227][Wall Clock 135.722502814s] Trained 128 records in 0.092810096 seconds. Throughput is 1379.1603 records/second. Loss is 0.4231627. Sequential31006cbd's hyper parameters: Current learning rate is 0.008030838419530999. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 1228][Wall Clock 135.807932056s] Trained 128 records in 0.085429242 seconds. Throughput is 1498.3159 records/second. Loss is 0.4835803. Sequential31006cbd's hyper parameters: Current learning rate is 0.008029548739360848. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 37248/60000][Iteration 1229][Wall Clock 135.893851916s] Trained 128 records in 0.08591986 seconds. Throughput is 1489.7604 records/second. Loss is 0.3649579. Sequential31006cbd's hyper parameters: Current learning rate is 0.008028259473346178. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 1230][Wall Clock 136.004189704s] Trained 128 records in 0.110337788 seconds. Throughput is 1160.074 records/second. Loss is 0.42197755. Sequential31006cbd's hyper parameters: Current learning rate is 0.008026970621287526. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 37504/60000][Iteration 1231][Wall Clock 136.124151194s] Trained 128 records in 0.11996149 seconds. Throughput is 1067.009 records/second. Loss is 0.35232696. Sequential31006cbd's hyper parameters: Current learning rate is 0.008025682182985555. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 1232][Wall Clock 136.217818384s] Trained 128 records in 0.09366719 seconds. Throughput is 1366.5404 records/second. Loss is 0.43260935. Sequential31006cbd's hyper parameters: Current learning rate is 0.008024394158241053. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:53 INFO  DistriOptimizer$:408 - [Epoch 3 37760/60000][Iteration 1233][Wall Clock 136.305757327s] Trained 128 records in 0.087938943 seconds. Throughput is 1455.5554 records/second. Loss is 0.35227215. Sequential31006cbd's hyper parameters: Current learning rate is 0.008023106546854942. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 1234][Wall Clock 136.397337126s] Trained 128 records in 0.091579799 seconds. Throughput is 1397.6881 records/second. Loss is 0.4618626. Sequential31006cbd's hyper parameters: Current learning rate is 0.00802181934862827. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38016/60000][Iteration 1235][Wall Clock 136.487339956s] Trained 128 records in 0.09000283 seconds. Throughput is 1422.1775 records/second. Loss is 0.49422476. Sequential31006cbd's hyper parameters: Current learning rate is 0.008020532563362208. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 1236][Wall Clock 136.580503409s] Trained 128 records in 0.093163453 seconds. Throughput is 1373.9293 records/second. Loss is 0.42142448. Sequential31006cbd's hyper parameters: Current learning rate is 0.00801924619085806. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38272/60000][Iteration 1237][Wall Clock 136.6899729s] Trained 128 records in 0.109469491 seconds. Throughput is 1169.2756 records/second. Loss is 0.40546703. Sequential31006cbd's hyper parameters: Current learning rate is 0.008017960230917255. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 1238][Wall Clock 136.789921985s] Trained 128 records in 0.099949085 seconds. Throughput is 1280.6521 records/second. Loss is 0.40199825. Sequential31006cbd's hyper parameters: Current learning rate is 0.00801667468334135. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38528/60000][Iteration 1239][Wall Clock 136.894443273s] Trained 128 records in 0.104521288 seconds. Throughput is 1224.6309 records/second. Loss is 0.38694042. Sequential31006cbd's hyper parameters: Current learning rate is 0.008015389547932029. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 1240][Wall Clock 136.998813607s] Trained 128 records in 0.104370334 seconds. Throughput is 1226.4021 records/second. Loss is 0.34667104. Sequential31006cbd's hyper parameters: Current learning rate is 0.008014104824491105. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38784/60000][Iteration 1241][Wall Clock 137.112715565s] Trained 128 records in 0.113901958 seconds. Throughput is 1123.7734 records/second. Loss is 0.33499327. Sequential31006cbd's hyper parameters: Current learning rate is 0.008012820512820514. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 1242][Wall Clock 137.221163466s] Trained 128 records in 0.108447901 seconds. Throughput is 1180.2903 records/second. Loss is 0.3269978. Sequential31006cbd's hyper parameters: Current learning rate is 0.00801153661272232. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:54 INFO  DistriOptimizer$:408 - [Epoch 3 39040/60000][Iteration 1243][Wall Clock 137.30576465s] Trained 128 records in 0.084601184 seconds. Throughput is 1512.9812 records/second. Loss is 0.53399277. Sequential31006cbd's hyper parameters: Current learning rate is 0.00801025312399872. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 1244][Wall Clock 137.417902374s] Trained 128 records in 0.112137724 seconds. Throughput is 1141.4535 records/second. Loss is 0.3691625. Sequential31006cbd's hyper parameters: Current learning rate is 0.008008970046452027. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39296/60000][Iteration 1245][Wall Clock 137.545424381s] Trained 128 records in 0.127522007 seconds. Throughput is 1003.7483 records/second. Loss is 0.42912042. Sequential31006cbd's hyper parameters: Current learning rate is 0.008007687379884689. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 1246][Wall Clock 137.642603294s] Trained 128 records in 0.097178913 seconds. Throughput is 1317.1582 records/second. Loss is 0.3994516. Sequential31006cbd's hyper parameters: Current learning rate is 0.008006405124099279. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39552/60000][Iteration 1247][Wall Clock 137.757981387s] Trained 128 records in 0.115378093 seconds. Throughput is 1109.396 records/second. Loss is 0.38087118. Sequential31006cbd's hyper parameters: Current learning rate is 0.008005123278898494. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 1248][Wall Clock 137.842040561s] Trained 128 records in 0.084059174 seconds. Throughput is 1522.7368 records/second. Loss is 0.4303372. Sequential31006cbd's hyper parameters: Current learning rate is 0.00800384184408516. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39808/60000][Iteration 1249][Wall Clock 137.936637249s] Trained 128 records in 0.094596688 seconds. Throughput is 1353.1129 records/second. Loss is 0.45569882. Sequential31006cbd's hyper parameters: Current learning rate is 0.008002560819462228. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 1250][Wall Clock 138.035035736s] Trained 128 records in 0.098398487 seconds. Throughput is 1300.833 records/second. Loss is 0.3861293. Sequential31006cbd's hyper parameters: Current learning rate is 0.008001280204832774. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 40064/60000][Iteration 1251][Wall Clock 138.144072836s] Trained 128 records in 0.1090371 seconds. Throughput is 1173.9124 records/second. Loss is 0.3325637. Sequential31006cbd's hyper parameters: Current learning rate is 0.008. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 1252][Wall Clock 138.241300289s] Trained 128 records in 0.097227453 seconds. Throughput is 1316.5006 records/second. Loss is 0.35790113. Sequential31006cbd's hyper parameters: Current learning rate is 0.007998720204767237. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:55 INFO  DistriOptimizer$:408 - [Epoch 3 40320/60000][Iteration 1253][Wall Clock 138.327928337s] Trained 128 records in 0.086628048 seconds. Throughput is 1477.5814 records/second. Loss is 0.4844644. Sequential31006cbd's hyper parameters: Current learning rate is 0.00799744081893794. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 1254][Wall Clock 138.431311214s] Trained 128 records in 0.103382877 seconds. Throughput is 1238.1161 records/second. Loss is 0.4354926. Sequential31006cbd's hyper parameters: Current learning rate is 0.00799616184231569. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 40576/60000][Iteration 1255][Wall Clock 138.56462284s] Trained 128 records in 0.133311626 seconds. Throughput is 960.1563 records/second. Loss is 0.4978341. Sequential31006cbd's hyper parameters: Current learning rate is 0.00799488327470419. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 1256][Wall Clock 138.679158402s] Trained 128 records in 0.114535562 seconds. Throughput is 1117.5569 records/second. Loss is 0.4193734. Sequential31006cbd's hyper parameters: Current learning rate is 0.007993605115907274. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 40832/60000][Iteration 1257][Wall Clock 138.782614331s] Trained 128 records in 0.103455929 seconds. Throughput is 1237.2418 records/second. Loss is 0.42012882. Sequential31006cbd's hyper parameters: Current learning rate is 0.007992327365728899. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 1258][Wall Clock 138.89713553s] Trained 128 records in 0.114521199 seconds. Throughput is 1117.697 records/second. Loss is 0.54599607. Sequential31006cbd's hyper parameters: Current learning rate is 0.00799105002397315. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 41088/60000][Iteration 1259][Wall Clock 138.989276337s] Trained 128 records in 0.092140807 seconds. Throughput is 1389.1782 records/second. Loss is 0.35777792. Sequential31006cbd's hyper parameters: Current learning rate is 0.00798977309044423. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 1260][Wall Clock 139.077874703s] Trained 128 records in 0.088598366 seconds. Throughput is 1444.7219 records/second. Loss is 0.37429035. Sequential31006cbd's hyper parameters: Current learning rate is 0.007988496564946478. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 41344/60000][Iteration 1261][Wall Clock 139.17705657s] Trained 128 records in 0.099181867 seconds. Throughput is 1290.5585 records/second. Loss is 0.47762644. Sequential31006cbd's hyper parameters: Current learning rate is 0.007987220447284345. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 1262][Wall Clock 139.266108941s] Trained 128 records in 0.089052371 seconds. Throughput is 1437.3564 records/second. Loss is 0.3820023. Sequential31006cbd's hyper parameters: Current learning rate is 0.007985944737262418. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:56 INFO  DistriOptimizer$:408 - [Epoch 3 41600/60000][Iteration 1263][Wall Clock 139.347083983s] Trained 128 records in 0.080975042 seconds. Throughput is 1580.734 records/second. Loss is 0.4528947. Sequential31006cbd's hyper parameters: Current learning rate is 0.007984669434685404. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 1264][Wall Clock 139.450030258s] Trained 128 records in 0.102946275 seconds. Throughput is 1243.367 records/second. Loss is 0.46726245. Sequential31006cbd's hyper parameters: Current learning rate is 0.007983394539358136. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 41856/60000][Iteration 1265][Wall Clock 139.534719229s] Trained 128 records in 0.084688971 seconds. Throughput is 1511.4128 records/second. Loss is 0.42935035. Sequential31006cbd's hyper parameters: Current learning rate is 0.007982120051085567. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 1266][Wall Clock 139.653807767s] Trained 128 records in 0.119088538 seconds. Throughput is 1074.8306 records/second. Loss is 0.4050487. Sequential31006cbd's hyper parameters: Current learning rate is 0.007980845969672785. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 42112/60000][Iteration 1267][Wall Clock 139.759738256s] Trained 128 records in 0.105930489 seconds. Throughput is 1208.3395 records/second. Loss is 0.57167614. Sequential31006cbd's hyper parameters: Current learning rate is 0.007979572294924991. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 1268][Wall Clock 139.867635413s] Trained 128 records in 0.107897157 seconds. Throughput is 1186.3148 records/second. Loss is 0.45836934. Sequential31006cbd's hyper parameters: Current learning rate is 0.007978299026647519. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 42368/60000][Iteration 1269][Wall Clock 139.964752783s] Trained 128 records in 0.09711737 seconds. Throughput is 1317.9928 records/second. Loss is 0.38136753. Sequential31006cbd's hyper parameters: Current learning rate is 0.00797702616464582. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 1270][Wall Clock 140.091349431s] Trained 128 records in 0.126596648 seconds. Throughput is 1011.08527 records/second. Loss is 0.44573778. Sequential31006cbd's hyper parameters: Current learning rate is 0.007975753708725474. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 42624/60000][Iteration 1271][Wall Clock 140.209897698s] Trained 128 records in 0.118548267 seconds. Throughput is 1079.729 records/second. Loss is 0.47433004. Sequential31006cbd's hyper parameters: Current learning rate is 0.007974481658692184. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:57 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 1272][Wall Clock 140.313484559s] Trained 128 records in 0.103586861 seconds. Throughput is 1235.678 records/second. Loss is 0.4961301. Sequential31006cbd's hyper parameters: Current learning rate is 0.007973210014351778. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 42880/60000][Iteration 1273][Wall Clock 140.476327306s] Trained 128 records in 0.162842747 seconds. Throughput is 786.03436 records/second. Loss is 0.42512524. Sequential31006cbd's hyper parameters: Current learning rate is 0.007971938775510204. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 1274][Wall Clock 140.575498858s] Trained 128 records in 0.099171552 seconds. Throughput is 1290.6927 records/second. Loss is 0.40155566. Sequential31006cbd's hyper parameters: Current learning rate is 0.007970667941973538. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43136/60000][Iteration 1275][Wall Clock 140.686447124s] Trained 128 records in 0.110948266 seconds. Throughput is 1153.6909 records/second. Loss is 0.381035. Sequential31006cbd's hyper parameters: Current learning rate is 0.007969397513547976. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 1276][Wall Clock 140.803617582s] Trained 128 records in 0.117170458 seconds. Throughput is 1092.4255 records/second. Loss is 0.3219633. Sequential31006cbd's hyper parameters: Current learning rate is 0.007968127490039842. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43392/60000][Iteration 1277][Wall Clock 140.902598073s] Trained 128 records in 0.098980491 seconds. Throughput is 1293.1841 records/second. Loss is 0.44306546. Sequential31006cbd's hyper parameters: Current learning rate is 0.007966857871255577. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 1278][Wall Clock 141.017930924s] Trained 128 records in 0.115332851 seconds. Throughput is 1109.8313 records/second. Loss is 0.51863766. Sequential31006cbd's hyper parameters: Current learning rate is 0.007965588657001752. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43648/60000][Iteration 1279][Wall Clock 141.1309971s] Trained 128 records in 0.113066176 seconds. Throughput is 1132.0804 records/second. Loss is 0.43358922. Sequential31006cbd's hyper parameters: Current learning rate is 0.00796431984708506. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:58 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 1280][Wall Clock 141.239319024s] Trained 128 records in 0.108321924 seconds. Throughput is 1181.6628 records/second. Loss is 0.41157112. Sequential31006cbd's hyper parameters: Current learning rate is 0.00796305144131231. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 43904/60000][Iteration 1281][Wall Clock 141.379641183s] Trained 128 records in 0.140322159 seconds. Throughput is 912.18665 records/second. Loss is 0.48542026. Sequential31006cbd's hyper parameters: Current learning rate is 0.007961783439490446. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 1282][Wall Clock 141.489279919s] Trained 128 records in 0.109638736 seconds. Throughput is 1167.4706 records/second. Loss is 0.47289243. Sequential31006cbd's hyper parameters: Current learning rate is 0.007960515841426525. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44160/60000][Iteration 1283][Wall Clock 141.594843807s] Trained 128 records in 0.105563888 seconds. Throughput is 1212.5359 records/second. Loss is 0.46913975. Sequential31006cbd's hyper parameters: Current learning rate is 0.00795924864692773. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 1284][Wall Clock 141.710074555s] Trained 128 records in 0.115230748 seconds. Throughput is 1110.8147 records/second. Loss is 0.38872403. Sequential31006cbd's hyper parameters: Current learning rate is 0.00795798185580137. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44416/60000][Iteration 1285][Wall Clock 141.81322005s] Trained 128 records in 0.103145495 seconds. Throughput is 1240.9655 records/second. Loss is 0.45373338. Sequential31006cbd's hyper parameters: Current learning rate is 0.007956715467854869. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 1286][Wall Clock 141.900610723s] Trained 128 records in 0.087390673 seconds. Throughput is 1464.6871 records/second. Loss is 0.34755516. Sequential31006cbd's hyper parameters: Current learning rate is 0.007955449482895782. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44672/60000][Iteration 1287][Wall Clock 141.996305384s] Trained 128 records in 0.095694661 seconds. Throughput is 1337.5876 records/second. Loss is 0.5264865. Sequential31006cbd's hyper parameters: Current learning rate is 0.007954183900731784. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 1288][Wall Clock 142.099113948s] Trained 128 records in 0.102808564 seconds. Throughput is 1245.0325 records/second. Loss is 0.48825148. Sequential31006cbd's hyper parameters: Current learning rate is 0.00795291872117067. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 44928/60000][Iteration 1289][Wall Clock 142.202075555s] Trained 128 records in 0.102961607 seconds. Throughput is 1243.1819 records/second. Loss is 0.3985412. Sequential31006cbd's hyper parameters: Current learning rate is 0.007951653944020356. Current dampening is 1.7976931348623157E308.  
2019-10-23 23:59:59 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 1290][Wall Clock 142.294578892s] Trained 128 records in 0.092503337 seconds. Throughput is 1383.7339 records/second. Loss is 0.3991273. Sequential31006cbd's hyper parameters: Current learning rate is 0.007950389569088886. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45184/60000][Iteration 1291][Wall Clock 142.422516046s] Trained 128 records in 0.127937154 seconds. Throughput is 1000.4912 records/second. Loss is 0.46022224. Sequential31006cbd's hyper parameters: Current learning rate is 0.00794912559618442. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 1292][Wall Clock 142.51887622s] Trained 128 records in 0.096360174 seconds. Throughput is 1328.3496 records/second. Loss is 0.44489416. Sequential31006cbd's hyper parameters: Current learning rate is 0.007947862025115245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45440/60000][Iteration 1293][Wall Clock 142.612566436s] Trained 128 records in 0.093690216 seconds. Throughput is 1366.2046 records/second. Loss is 0.47687888. Sequential31006cbd's hyper parameters: Current learning rate is 0.007946598855689765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 1294][Wall Clock 142.722911233s] Trained 128 records in 0.110344797 seconds. Throughput is 1160.0004 records/second. Loss is 0.43401742. Sequential31006cbd's hyper parameters: Current learning rate is 0.00794533608771651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45696/60000][Iteration 1295][Wall Clock 142.838262041s] Trained 128 records in 0.115350808 seconds. Throughput is 1109.6584 records/second. Loss is 0.45024154. Sequential31006cbd's hyper parameters: Current learning rate is 0.00794407372100413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 1296][Wall Clock 143.018055494s] Trained 128 records in 0.179793453 seconds. Throughput is 711.92804 records/second. Loss is 0.37670544. Sequential31006cbd's hyper parameters: Current learning rate is 0.0079428117553614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 45952/60000][Iteration 1297][Wall Clock 143.130868957s] Trained 128 records in 0.112813463 seconds. Throughput is 1134.6163 records/second. Loss is 0.37223065. Sequential31006cbd's hyper parameters: Current learning rate is 0.007941550190597205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:00 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 1298][Wall Clock 143.272108497s] Trained 128 records in 0.14123954 seconds. Throughput is 906.2618 records/second. Loss is 0.49092764. Sequential31006cbd's hyper parameters: Current learning rate is 0.007940289026520565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46208/60000][Iteration 1299][Wall Clock 143.381749537s] Trained 128 records in 0.10964104 seconds. Throughput is 1167.446 records/second. Loss is 0.42769942. Sequential31006cbd's hyper parameters: Current learning rate is 0.007939028262940616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 1300][Wall Clock 143.479036519s] Trained 128 records in 0.097286982 seconds. Throughput is 1315.6951 records/second. Loss is 0.490164. Sequential31006cbd's hyper parameters: Current learning rate is 0.007937767899666614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46464/60000][Iteration 1301][Wall Clock 143.596091203s] Trained 128 records in 0.117054684 seconds. Throughput is 1093.506 records/second. Loss is 0.34286514. Sequential31006cbd's hyper parameters: Current learning rate is 0.007936507936507936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 1302][Wall Clock 143.691137589s] Trained 128 records in 0.095046386 seconds. Throughput is 1346.7108 records/second. Loss is 0.2896365. Sequential31006cbd's hyper parameters: Current learning rate is 0.007935248373274084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46720/60000][Iteration 1303][Wall Clock 143.787756685s] Trained 128 records in 0.096619096 seconds. Throughput is 1324.7898 records/second. Loss is 0.4405531. Sequential31006cbd's hyper parameters: Current learning rate is 0.007933989209774676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 1304][Wall Clock 143.875366811s] Trained 128 records in 0.087610126 seconds. Throughput is 1461.0183 records/second. Loss is 0.40573806. Sequential31006cbd's hyper parameters: Current learning rate is 0.007932730445819451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 46976/60000][Iteration 1305][Wall Clock 143.969006365s] Trained 128 records in 0.093639554 seconds. Throughput is 1366.9437 records/second. Loss is 0.44499633. Sequential31006cbd's hyper parameters: Current learning rate is 0.007931472081218274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 1306][Wall Clock 144.096770415s] Trained 128 records in 0.12776405 seconds. Throughput is 1001.8468 records/second. Loss is 0.4971325. Sequential31006cbd's hyper parameters: Current learning rate is 0.007930214115781126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 47232/60000][Iteration 1307][Wall Clock 144.197613846s] Trained 128 records in 0.100843431 seconds. Throughput is 1269.2944 records/second. Loss is 0.4189907. Sequential31006cbd's hyper parameters: Current learning rate is 0.00792895654931811. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:01 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 1308][Wall Clock 144.315588969s] Trained 128 records in 0.117975123 seconds. Throughput is 1084.9745 records/second. Loss is 0.39134157. Sequential31006cbd's hyper parameters: Current learning rate is 0.007927699381639447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 47488/60000][Iteration 1309][Wall Clock 144.412389347s] Trained 128 records in 0.096800378 seconds. Throughput is 1322.3088 records/second. Loss is 0.43657136. Sequential31006cbd's hyper parameters: Current learning rate is 0.007926442612555484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 1310][Wall Clock 144.507762933s] Trained 128 records in 0.095373586 seconds. Throughput is 1342.0907 records/second. Loss is 0.32528606. Sequential31006cbd's hyper parameters: Current learning rate is 0.007925186241876684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 47744/60000][Iteration 1311][Wall Clock 144.606596856s] Trained 128 records in 0.098833923 seconds. Throughput is 1295.1018 records/second. Loss is 0.50404805. Sequential31006cbd's hyper parameters: Current learning rate is 0.00792393026941363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 1312][Wall Clock 144.695446869s] Trained 128 records in 0.088850013 seconds. Throughput is 1440.63 records/second. Loss is 0.423287. Sequential31006cbd's hyper parameters: Current learning rate is 0.007922674694977025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 48000/60000][Iteration 1313][Wall Clock 144.780539574s] Trained 128 records in 0.085092705 seconds. Throughput is 1504.2417 records/second. Loss is 0.47689655. Sequential31006cbd's hyper parameters: Current learning rate is 0.007921419518377694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 1314][Wall Clock 144.872147118s] Trained 128 records in 0.091607544 seconds. Throughput is 1397.2649 records/second. Loss is 0.31835508. Sequential31006cbd's hyper parameters: Current learning rate is 0.007920164739426581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 48256/60000][Iteration 1315][Wall Clock 144.98449938s] Trained 128 records in 0.112352262 seconds. Throughput is 1139.2739 records/second. Loss is 0.3588019. Sequential31006cbd's hyper parameters: Current learning rate is 0.007918910357934749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 1316][Wall Clock 145.092111714s] Trained 128 records in 0.107612334 seconds. Throughput is 1189.4547 records/second. Loss is 0.49744028. Sequential31006cbd's hyper parameters: Current learning rate is 0.007917656373713382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 48512/60000][Iteration 1317][Wall Clock 145.186449254s] Trained 128 records in 0.09433754 seconds. Throughput is 1356.83 records/second. Loss is 0.3032573. Sequential31006cbd's hyper parameters: Current learning rate is 0.007916402786573781. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:02 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 1318][Wall Clock 145.270600881s] Trained 128 records in 0.084151627 seconds. Throughput is 1521.0638 records/second. Loss is 0.4347643. Sequential31006cbd's hyper parameters: Current learning rate is 0.007915149596327371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 48768/60000][Iteration 1319][Wall Clock 145.359089668s] Trained 128 records in 0.088488787 seconds. Throughput is 1446.511 records/second. Loss is 0.30931646. Sequential31006cbd's hyper parameters: Current learning rate is 0.007913896802785692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 1320][Wall Clock 145.460822467s] Trained 128 records in 0.101732799 seconds. Throughput is 1258.198 records/second. Loss is 0.39582694. Sequential31006cbd's hyper parameters: Current learning rate is 0.007912644405760404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49024/60000][Iteration 1321][Wall Clock 145.604073028s] Trained 128 records in 0.143250561 seconds. Throughput is 893.5393 records/second. Loss is 0.41550586. Sequential31006cbd's hyper parameters: Current learning rate is 0.007911392405063292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 1322][Wall Clock 145.703968521s] Trained 128 records in 0.099895493 seconds. Throughput is 1281.3391 records/second. Loss is 0.4081892. Sequential31006cbd's hyper parameters: Current learning rate is 0.00791014080050625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49280/60000][Iteration 1323][Wall Clock 145.791331799s] Trained 128 records in 0.087363278 seconds. Throughput is 1465.1465 records/second. Loss is 0.3941333. Sequential31006cbd's hyper parameters: Current learning rate is 0.007908889591901298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 1324][Wall Clock 145.882995648s] Trained 128 records in 0.091663849 seconds. Throughput is 1396.4065 records/second. Loss is 0.46136302. Sequential31006cbd's hyper parameters: Current learning rate is 0.007907638779060573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49536/60000][Iteration 1325][Wall Clock 145.999890515s] Trained 128 records in 0.116894867 seconds. Throughput is 1095.0011 records/second. Loss is 0.37745893. Sequential31006cbd's hyper parameters: Current learning rate is 0.007906388361796331. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 1326][Wall Clock 146.09106159s] Trained 128 records in 0.091171075 seconds. Throughput is 1403.954 records/second. Loss is 0.42701218. Sequential31006cbd's hyper parameters: Current learning rate is 0.007905138339920948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49792/60000][Iteration 1327][Wall Clock 146.177311134s] Trained 128 records in 0.086249544 seconds. Throughput is 1484.0658 records/second. Loss is 0.46495324. Sequential31006cbd's hyper parameters: Current learning rate is 0.007903888713246918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:03 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 1328][Wall Clock 146.279100578s] Trained 128 records in 0.101789444 seconds. Throughput is 1257.4978 records/second. Loss is 0.38746157. Sequential31006cbd's hyper parameters: Current learning rate is 0.00790263948158685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50048/60000][Iteration 1329][Wall Clock 146.415910279s] Trained 128 records in 0.136809701 seconds. Throughput is 935.60614 records/second. Loss is 0.4933329. Sequential31006cbd's hyper parameters: Current learning rate is 0.007901390644753476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 1330][Wall Clock 146.499370183s] Trained 128 records in 0.083459904 seconds. Throughput is 1533.6705 records/second. Loss is 0.31791034. Sequential31006cbd's hyper parameters: Current learning rate is 0.007900142202559647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50304/60000][Iteration 1331][Wall Clock 146.596414248s] Trained 128 records in 0.097044065 seconds. Throughput is 1318.9884 records/second. Loss is 0.43266785. Sequential31006cbd's hyper parameters: Current learning rate is 0.007898894154818325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 1332][Wall Clock 146.712912851s] Trained 128 records in 0.116498603 seconds. Throughput is 1098.7256 records/second. Loss is 0.45551726. Sequential31006cbd's hyper parameters: Current learning rate is 0.0078976465013426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50560/60000][Iteration 1333][Wall Clock 146.820107166s] Trained 128 records in 0.107194315 seconds. Throughput is 1194.0933 records/second. Loss is 0.4520977. Sequential31006cbd's hyper parameters: Current learning rate is 0.007896399241945674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 1334][Wall Clock 146.942466308s] Trained 128 records in 0.122359142 seconds. Throughput is 1046.1008 records/second. Loss is 0.32932374. Sequential31006cbd's hyper parameters: Current learning rate is 0.007895152376440865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50816/60000][Iteration 1335][Wall Clock 147.059221253s] Trained 128 records in 0.116754945 seconds. Throughput is 1096.3134 records/second. Loss is 0.5714065. Sequential31006cbd's hyper parameters: Current learning rate is 0.007893905904641616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 1336][Wall Clock 147.171004253s] Trained 128 records in 0.111783 seconds. Throughput is 1145.0758 records/second. Loss is 0.409277. Sequential31006cbd's hyper parameters: Current learning rate is 0.007892659826361484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:04 INFO  DistriOptimizer$:408 - [Epoch 3 51072/60000][Iteration 1337][Wall Clock 147.295780824s] Trained 128 records in 0.124776571 seconds. Throughput is 1025.8336 records/second. Loss is 0.41600794. Sequential31006cbd's hyper parameters: Current learning rate is 0.007891414141414142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 1338][Wall Clock 147.39452873s] Trained 128 records in 0.098747906 seconds. Throughput is 1296.23 records/second. Loss is 0.36341318. Sequential31006cbd's hyper parameters: Current learning rate is 0.007890168849613381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51328/60000][Iteration 1339][Wall Clock 147.497819642s] Trained 128 records in 0.103290912 seconds. Throughput is 1239.2184 records/second. Loss is 0.3431066. Sequential31006cbd's hyper parameters: Current learning rate is 0.007888923950773114. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 1340][Wall Clock 147.605539398s] Trained 128 records in 0.107719756 seconds. Throughput is 1188.2686 records/second. Loss is 0.41209874. Sequential31006cbd's hyper parameters: Current learning rate is 0.007887679444707366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51584/60000][Iteration 1341][Wall Clock 147.726562924s] Trained 128 records in 0.121023526 seconds. Throughput is 1057.6456 records/second. Loss is 0.4651038. Sequential31006cbd's hyper parameters: Current learning rate is 0.007886435331230283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 1342][Wall Clock 147.82952032s] Trained 128 records in 0.102957396 seconds. Throughput is 1243.2327 records/second. Loss is 0.34613743. Sequential31006cbd's hyper parameters: Current learning rate is 0.007885191610156127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51840/60000][Iteration 1343][Wall Clock 147.93803377s] Trained 128 records in 0.10851345 seconds. Throughput is 1179.5773 records/second. Loss is 0.3878504. Sequential31006cbd's hyper parameters: Current learning rate is 0.007883948281299276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 1344][Wall Clock 148.037083609s] Trained 128 records in 0.099049839 seconds. Throughput is 1292.2788 records/second. Loss is 0.43964982. Sequential31006cbd's hyper parameters: Current learning rate is 0.007882705344474224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 52096/60000][Iteration 1345][Wall Clock 148.129773968s] Trained 128 records in 0.092690359 seconds. Throughput is 1380.9419 records/second. Loss is 0.46780124. Sequential31006cbd's hyper parameters: Current learning rate is 0.007881462799495585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:05 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 1346][Wall Clock 148.22839628s] Trained 128 records in 0.098622312 seconds. Throughput is 1297.8807 records/second. Loss is 0.44202554. Sequential31006cbd's hyper parameters: Current learning rate is 0.007880220646178092. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 52352/60000][Iteration 1347][Wall Clock 148.329201721s] Trained 128 records in 0.100805441 seconds. Throughput is 1269.7727 records/second. Loss is 0.5637318. Sequential31006cbd's hyper parameters: Current learning rate is 0.00787897888433659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 1348][Wall Clock 148.471688683s] Trained 128 records in 0.142486962 seconds. Throughput is 898.3278 records/second. Loss is 0.4022047. Sequential31006cbd's hyper parameters: Current learning rate is 0.00787773751378604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 52608/60000][Iteration 1349][Wall Clock 148.564527624s] Trained 128 records in 0.092838941 seconds. Throughput is 1378.7318 records/second. Loss is 0.370893. Sequential31006cbd's hyper parameters: Current learning rate is 0.007876496534341524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 1350][Wall Clock 148.658347758s] Trained 128 records in 0.093820134 seconds. Throughput is 1364.3127 records/second. Loss is 0.47867617. Sequential31006cbd's hyper parameters: Current learning rate is 0.007875255945818239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 52864/60000][Iteration 1351][Wall Clock 148.745402987s] Trained 128 records in 0.087055229 seconds. Throughput is 1470.3309 records/second. Loss is 0.4097245. Sequential31006cbd's hyper parameters: Current learning rate is 0.007874015748031496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 1352][Wall Clock 148.832517968s] Trained 128 records in 0.087114981 seconds. Throughput is 1469.3225 records/second. Loss is 0.32132018. Sequential31006cbd's hyper parameters: Current learning rate is 0.007872775940796726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 53120/60000][Iteration 1353][Wall Clock 148.918805987s] Trained 128 records in 0.086288019 seconds. Throughput is 1483.404 records/second. Loss is 0.41571683. Sequential31006cbd's hyper parameters: Current learning rate is 0.007871536523929471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 1354][Wall Clock 149.004300567s] Trained 128 records in 0.08549458 seconds. Throughput is 1497.171 records/second. Loss is 0.32285225. Sequential31006cbd's hyper parameters: Current learning rate is 0.007870297497245396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 53376/60000][Iteration 1355][Wall Clock 149.102361102s] Trained 128 records in 0.098060535 seconds. Throughput is 1305.3162 records/second. Loss is 0.41101265. Sequential31006cbd's hyper parameters: Current learning rate is 0.007869058860560278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 1356][Wall Clock 149.208747985s] Trained 128 records in 0.106386883 seconds. Throughput is 1203.1558 records/second. Loss is 0.43608233. Sequential31006cbd's hyper parameters: Current learning rate is 0.007867820613690008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:06 INFO  DistriOptimizer$:408 - [Epoch 3 53632/60000][Iteration 1357][Wall Clock 149.296166937s] Trained 128 records in 0.087418952 seconds. Throughput is 1464.2134 records/second. Loss is 0.3188669. Sequential31006cbd's hyper parameters: Current learning rate is 0.007866582756450599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 1358][Wall Clock 149.424599151s] Trained 128 records in 0.128432214 seconds. Throughput is 996.6347 records/second. Loss is 0.39174312. Sequential31006cbd's hyper parameters: Current learning rate is 0.007865345288658171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 53888/60000][Iteration 1359][Wall Clock 149.518155705s] Trained 128 records in 0.093556554 seconds. Throughput is 1368.1564 records/second. Loss is 0.354774. Sequential31006cbd's hyper parameters: Current learning rate is 0.007864108210128971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 1360][Wall Clock 149.633275539s] Trained 128 records in 0.115119834 seconds. Throughput is 1111.8848 records/second. Loss is 0.43777347. Sequential31006cbd's hyper parameters: Current learning rate is 0.007862871520679353. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 54144/60000][Iteration 1361][Wall Clock 149.744273536s] Trained 128 records in 0.110997997 seconds. Throughput is 1153.174 records/second. Loss is 0.43831366. Sequential31006cbd's hyper parameters: Current learning rate is 0.007861635220125786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 1362][Wall Clock 149.855205255s] Trained 128 records in 0.110931719 seconds. Throughput is 1153.8629 records/second. Loss is 0.36503226. Sequential31006cbd's hyper parameters: Current learning rate is 0.007860399308284862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 54400/60000][Iteration 1363][Wall Clock 149.982169099s] Trained 128 records in 0.126963844 seconds. Throughput is 1008.1611 records/second. Loss is 0.37372425. Sequential31006cbd's hyper parameters: Current learning rate is 0.00785916378497328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 1364][Wall Clock 150.089755774s] Trained 128 records in 0.107586675 seconds. Throughput is 1189.7384 records/second. Loss is 0.32753196. Sequential31006cbd's hyper parameters: Current learning rate is 0.007857928650007858. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:07 INFO  DistriOptimizer$:408 - [Epoch 3 54656/60000][Iteration 1365][Wall Clock 150.194318691s] Trained 128 records in 0.104562917 seconds. Throughput is 1224.1433 records/second. Loss is 0.39381093. Sequential31006cbd's hyper parameters: Current learning rate is 0.00785669390320553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 1366][Wall Clock 150.312752999s] Trained 128 records in 0.118434308 seconds. Throughput is 1080.768 records/second. Loss is 0.3523238. Sequential31006cbd's hyper parameters: Current learning rate is 0.007855459544383346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 54912/60000][Iteration 1367][Wall Clock 150.396083519s] Trained 128 records in 0.08333052 seconds. Throughput is 1536.0519 records/second. Loss is 0.37318286. Sequential31006cbd's hyper parameters: Current learning rate is 0.007854225573358466. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 1368][Wall Clock 150.489752372s] Trained 128 records in 0.093668853 seconds. Throughput is 1366.5161 records/second. Loss is 0.41898987. Sequential31006cbd's hyper parameters: Current learning rate is 0.00785299198994817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55168/60000][Iteration 1369][Wall Clock 150.567055799s] Trained 128 records in 0.077303427 seconds. Throughput is 1655.8127 records/second. Loss is 0.43989542. Sequential31006cbd's hyper parameters: Current learning rate is 0.007851758793969849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 1370][Wall Clock 150.651867992s] Trained 128 records in 0.084812193 seconds. Throughput is 1509.2169 records/second. Loss is 0.3387334. Sequential31006cbd's hyper parameters: Current learning rate is 0.00785052598524101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55424/60000][Iteration 1371][Wall Clock 150.785154654s] Trained 128 records in 0.133286662 seconds. Throughput is 960.3362 records/second. Loss is 0.35394862. Sequential31006cbd's hyper parameters: Current learning rate is 0.007849293563579277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 1372][Wall Clock 150.865053207s] Trained 128 records in 0.079898553 seconds. Throughput is 1602.0315 records/second. Loss is 0.38801333. Sequential31006cbd's hyper parameters: Current learning rate is 0.007848061528802385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55680/60000][Iteration 1373][Wall Clock 150.953113259s] Trained 128 records in 0.088060052 seconds. Throughput is 1453.5536 records/second. Loss is 0.33860925. Sequential31006cbd's hyper parameters: Current learning rate is 0.007846829880728186. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 1374][Wall Clock 151.063186686s] Trained 128 records in 0.110073427 seconds. Throughput is 1162.8601 records/second. Loss is 0.45485035. Sequential31006cbd's hyper parameters: Current learning rate is 0.007845598619174643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 55936/60000][Iteration 1375][Wall Clock 151.156999377s] Trained 128 records in 0.093812691 seconds. Throughput is 1364.421 records/second. Loss is 0.3921036. Sequential31006cbd's hyper parameters: Current learning rate is 0.007844367743959838. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:08 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 1376][Wall Clock 151.245692681s] Trained 128 records in 0.088693304 seconds. Throughput is 1443.1754 records/second. Loss is 0.400836. Sequential31006cbd's hyper parameters: Current learning rate is 0.00784313725490196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56192/60000][Iteration 1377][Wall Clock 151.342073427s] Trained 128 records in 0.096380746 seconds. Throughput is 1328.066 records/second. Loss is 0.38928276. Sequential31006cbd's hyper parameters: Current learning rate is 0.007841907151819323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 1378][Wall Clock 151.442356904s] Trained 128 records in 0.100283477 seconds. Throughput is 1276.3818 records/second. Loss is 0.32884473. Sequential31006cbd's hyper parameters: Current learning rate is 0.007840677434530343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56448/60000][Iteration 1379][Wall Clock 151.52435411s] Trained 128 records in 0.081997206 seconds. Throughput is 1561.0288 records/second. Loss is 0.4184512. Sequential31006cbd's hyper parameters: Current learning rate is 0.00783944810285356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 1380][Wall Clock 151.602244634s] Trained 128 records in 0.077890524 seconds. Throughput is 1643.3322 records/second. Loss is 0.5089489. Sequential31006cbd's hyper parameters: Current learning rate is 0.007838219156607618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56704/60000][Iteration 1381][Wall Clock 151.687736868s] Trained 128 records in 0.085492234 seconds. Throughput is 1497.212 records/second. Loss is 0.4596716. Sequential31006cbd's hyper parameters: Current learning rate is 0.007836990595611285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 1382][Wall Clock 151.774758615s] Trained 128 records in 0.087021747 seconds. Throughput is 1470.8967 records/second. Loss is 0.3497186. Sequential31006cbd's hyper parameters: Current learning rate is 0.007835762419683435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 56960/60000][Iteration 1383][Wall Clock 151.854141731s] Trained 128 records in 0.079383116 seconds. Throughput is 1612.4336 records/second. Loss is 0.351153. Sequential31006cbd's hyper parameters: Current learning rate is 0.007834534628643058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 1384][Wall Clock 151.949428444s] Trained 128 records in 0.095286713 seconds. Throughput is 1343.3142 records/second. Loss is 0.37356925. Sequential31006cbd's hyper parameters: Current learning rate is 0.007833307222309259. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 57216/60000][Iteration 1385][Wall Clock 152.04002416s] Trained 128 records in 0.090595716 seconds. Throughput is 1412.8704 records/second. Loss is 0.40634766. Sequential31006cbd's hyper parameters: Current learning rate is 0.007832080200501254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 1386][Wall Clock 152.122580353s] Trained 128 records in 0.082556193 seconds. Throughput is 1550.459 records/second. Loss is 0.44896826. Sequential31006cbd's hyper parameters: Current learning rate is 0.00783085356303837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 57472/60000][Iteration 1387][Wall Clock 152.200648041s] Trained 128 records in 0.078067688 seconds. Throughput is 1639.6028 records/second. Loss is 0.32896483. Sequential31006cbd's hyper parameters: Current learning rate is 0.007829627309740055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:09 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 1388][Wall Clock 152.281584357s] Trained 128 records in 0.080936316 seconds. Throughput is 1581.4904 records/second. Loss is 0.37003437. Sequential31006cbd's hyper parameters: Current learning rate is 0.007828401440425865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 57728/60000][Iteration 1389][Wall Clock 152.357842288s] Trained 128 records in 0.076257931 seconds. Throughput is 1678.5139 records/second. Loss is 0.36152494. Sequential31006cbd's hyper parameters: Current learning rate is 0.007827175954915467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 1390][Wall Clock 152.43874155s] Trained 128 records in 0.080899262 seconds. Throughput is 1582.2147 records/second. Loss is 0.368763. Sequential31006cbd's hyper parameters: Current learning rate is 0.007825950853028642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 57984/60000][Iteration 1391][Wall Clock 152.525446653s] Trained 128 records in 0.086705103 seconds. Throughput is 1476.2683 records/second. Loss is 0.37039328. Sequential31006cbd's hyper parameters: Current learning rate is 0.00782472613458529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 1392][Wall Clock 152.603918687s] Trained 128 records in 0.078472034 seconds. Throughput is 1631.1544 records/second. Loss is 0.42466795. Sequential31006cbd's hyper parameters: Current learning rate is 0.007823501799405413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58240/60000][Iteration 1393][Wall Clock 152.682932448s] Trained 128 records in 0.079013761 seconds. Throughput is 1619.9711 records/second. Loss is 0.36382082. Sequential31006cbd's hyper parameters: Current learning rate is 0.007822277847309137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 1394][Wall Clock 152.763031986s] Trained 128 records in 0.080099538 seconds. Throughput is 1598.0117 records/second. Loss is 0.39129293. Sequential31006cbd's hyper parameters: Current learning rate is 0.00782105427811669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58496/60000][Iteration 1395][Wall Clock 152.848828436s] Trained 128 records in 0.08579645 seconds. Throughput is 1491.9032 records/second. Loss is 0.4021993. Sequential31006cbd's hyper parameters: Current learning rate is 0.00781983109164842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 1396][Wall Clock 152.945166909s] Trained 128 records in 0.096338473 seconds. Throughput is 1328.6488 records/second. Loss is 0.40294388. Sequential31006cbd's hyper parameters: Current learning rate is 0.007818608287724786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58752/60000][Iteration 1397][Wall Clock 153.053906899s] Trained 128 records in 0.10873999 seconds. Throughput is 1177.1199 records/second. Loss is 0.45632526. Sequential31006cbd's hyper parameters: Current learning rate is 0.007817385866166355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 1398][Wall Clock 153.147721464s] Trained 128 records in 0.093814565 seconds. Throughput is 1364.3937 records/second. Loss is 0.3721352. Sequential31006cbd's hyper parameters: Current learning rate is 0.00781616382679381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:10 INFO  DistriOptimizer$:408 - [Epoch 3 59008/60000][Iteration 1399][Wall Clock 153.238087667s] Trained 128 records in 0.090366203 seconds. Throughput is 1416.4589 records/second. Loss is 0.3781213. Sequential31006cbd's hyper parameters: Current learning rate is 0.007814942169427946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 1400][Wall Clock 153.324034952s] Trained 128 records in 0.085947285 seconds. Throughput is 1489.285 records/second. Loss is 0.39992067. Sequential31006cbd's hyper parameters: Current learning rate is 0.00781372089388967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59264/60000][Iteration 1401][Wall Clock 153.41528717s] Trained 128 records in 0.091252218 seconds. Throughput is 1402.7057 records/second. Loss is 0.3219639. Sequential31006cbd's hyper parameters: Current learning rate is 0.0078125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 1402][Wall Clock 153.50575722s] Trained 128 records in 0.09047005 seconds. Throughput is 1414.8328 records/second. Loss is 0.40903473. Sequential31006cbd's hyper parameters: Current learning rate is 0.007811279487580066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59520/60000][Iteration 1403][Wall Clock 153.585952045s] Trained 128 records in 0.080194825 seconds. Throughput is 1596.113 records/second. Loss is 0.46337312. Sequential31006cbd's hyper parameters: Current learning rate is 0.007810059356451109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 1404][Wall Clock 153.663980631s] Trained 128 records in 0.078028586 seconds. Throughput is 1640.4243 records/second. Loss is 0.43087944. Sequential31006cbd's hyper parameters: Current learning rate is 0.007808839606434484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59776/60000][Iteration 1405][Wall Clock 153.741349924s] Trained 128 records in 0.077369293 seconds. Throughput is 1654.4031 records/second. Loss is 0.34417033. Sequential31006cbd's hyper parameters: Current learning rate is 0.007807620237351656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 1406][Wall Clock 153.826428904s] Trained 128 records in 0.08507898 seconds. Throughput is 1504.4845 records/second. Loss is 0.4005993. Sequential31006cbd's hyper parameters: Current learning rate is 0.007806401249024199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:408 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 153.91460408s] Trained 128 records in 0.088175176 seconds. Throughput is 1451.6558 records/second. Loss is 0.32748684. Sequential31006cbd's hyper parameters: Current learning rate is 0.007805182641273806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:11 INFO  DistriOptimizer$:452 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 153.91460408s] Epoch finished. Wall clock time is 155145.574481 ms
2019-10-24 00:00:11 INFO  DistriOptimizer$:111 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 153.91460408s] Validate model...
2019-10-24 00:00:12 INFO  DistriOptimizer$:178 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 153.91460408s] validate model throughput is 10097.951 records/second
2019-10-24 00:00:12 INFO  DistriOptimizer$:181 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 153.91460408s] Top1Accuracy is Accuracy(correct: 9032, count: 10000, accuracy: 0.9032)
2019-10-24 00:00:12 INFO  DistriOptimizer$:221 - [Wall Clock 155.145574481s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:00:12 INFO  DistriOptimizer$:226 - [Wall Clock 155.145574481s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:00:12 INFO  DistriOptimizer$:408 - [Epoch 4 128/60000][Iteration 1408][Wall Clock 155.254273199s] Trained 128 records in 0.108698718 seconds. Throughput is 1177.5668 records/second. Loss is 0.577008. Sequential31006cbd's hyper parameters: Current learning rate is 0.007803964413922272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:12 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 1409][Wall Clock 155.335328696s] Trained 128 records in 0.081055497 seconds. Throughput is 1579.1649 records/second. Loss is 0.42821056. Sequential31006cbd's hyper parameters: Current learning rate is 0.007802746566791511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:12 INFO  DistriOptimizer$:408 - [Epoch 4 384/60000][Iteration 1410][Wall Clock 155.420366377s] Trained 128 records in 0.085037681 seconds. Throughput is 1505.2151 records/second. Loss is 0.39977437. Sequential31006cbd's hyper parameters: Current learning rate is 0.007801529099703542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 1411][Wall Clock 155.510116174s] Trained 128 records in 0.089749797 seconds. Throughput is 1426.187 records/second. Loss is 0.38289827. Sequential31006cbd's hyper parameters: Current learning rate is 0.0078003120124804995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 640/60000][Iteration 1412][Wall Clock 155.59640108s] Trained 128 records in 0.086284906 seconds. Throughput is 1483.4576 records/second. Loss is 0.38796625. Sequential31006cbd's hyper parameters: Current learning rate is 0.007799095304944627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 1413][Wall Clock 155.682777272s] Trained 128 records in 0.086376192 seconds. Throughput is 1481.8899 records/second. Loss is 0.36372992. Sequential31006cbd's hyper parameters: Current learning rate is 0.007797878976918278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 896/60000][Iteration 1414][Wall Clock 155.784589706s] Trained 128 records in 0.101812434 seconds. Throughput is 1257.2137 records/second. Loss is 0.38758934. Sequential31006cbd's hyper parameters: Current learning rate is 0.00779666302822392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 1415][Wall Clock 155.874797299s] Trained 128 records in 0.090207593 seconds. Throughput is 1418.9493 records/second. Loss is 0.3807512. Sequential31006cbd's hyper parameters: Current learning rate is 0.007795447458684129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1152/60000][Iteration 1416][Wall Clock 155.959198703s] Trained 128 records in 0.084401404 seconds. Throughput is 1516.5624 records/second. Loss is 0.28408206. Sequential31006cbd's hyper parameters: Current learning rate is 0.007794232268121591. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 1417][Wall Clock 156.043966822s] Trained 128 records in 0.084768119 seconds. Throughput is 1510.0017 records/second. Loss is 0.3912715. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077930174563591035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1408/60000][Iteration 1418][Wall Clock 156.130081563s] Trained 128 records in 0.086114741 seconds. Throughput is 1486.3889 records/second. Loss is 0.3673452. Sequential31006cbd's hyper parameters: Current learning rate is 0.007791803023219573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 1419][Wall Clock 156.209023643s] Trained 128 records in 0.07894208 seconds. Throughput is 1621.4419 records/second. Loss is 0.45797613. Sequential31006cbd's hyper parameters: Current learning rate is 0.00779058896852602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1664/60000][Iteration 1420][Wall Clock 156.306514907s] Trained 128 records in 0.097491264 seconds. Throughput is 1312.9381 records/second. Loss is 0.3849011. Sequential31006cbd's hyper parameters: Current learning rate is 0.007789375292101573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:13 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 1421][Wall Clock 156.401084561s] Trained 128 records in 0.094569654 seconds. Throughput is 1353.4998 records/second. Loss is 0.28200123. Sequential31006cbd's hyper parameters: Current learning rate is 0.00778816199376947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 1920/60000][Iteration 1422][Wall Clock 156.514548224s] Trained 128 records in 0.113463663 seconds. Throughput is 1128.1145 records/second. Loss is 0.45655465. Sequential31006cbd's hyper parameters: Current learning rate is 0.00778694907335306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 1423][Wall Clock 156.595701857s] Trained 128 records in 0.081153633 seconds. Throughput is 1577.2554 records/second. Loss is 0.39265034. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077857365306758025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2176/60000][Iteration 1424][Wall Clock 156.673255203s] Trained 128 records in 0.077553346 seconds. Throughput is 1650.4768 records/second. Loss is 0.29679754. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077845243655612646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 1425][Wall Clock 156.757654237s] Trained 128 records in 0.084399034 seconds. Throughput is 1516.605 records/second. Loss is 0.38001028. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077833125778331265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2432/60000][Iteration 1426][Wall Clock 156.840329778s] Trained 128 records in 0.082675541 seconds. Throughput is 1548.221 records/second. Loss is 0.4201385. Sequential31006cbd's hyper parameters: Current learning rate is 0.007782101167315174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 1427][Wall Clock 156.9182815s] Trained 128 records in 0.077951722 seconds. Throughput is 1642.042 records/second. Loss is 0.35842466. Sequential31006cbd's hyper parameters: Current learning rate is 0.00778089013383131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2688/60000][Iteration 1428][Wall Clock 156.998738209s] Trained 128 records in 0.080456709 seconds. Throughput is 1590.9176 records/second. Loss is 0.4482701. Sequential31006cbd's hyper parameters: Current learning rate is 0.007779679477205538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 1429][Wall Clock 157.081154315s] Trained 128 records in 0.082416106 seconds. Throughput is 1553.0946 records/second. Loss is 0.373618. Sequential31006cbd's hyper parameters: Current learning rate is 0.007778469197261978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 2944/60000][Iteration 1430][Wall Clock 157.165206203s] Trained 128 records in 0.084051888 seconds. Throughput is 1522.8689 records/second. Loss is 0.38389558. Sequential31006cbd's hyper parameters: Current learning rate is 0.007777259293824856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 1431][Wall Clock 157.242808096s] Trained 128 records in 0.077601893 seconds. Throughput is 1649.4442 records/second. Loss is 0.47537714. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077760497667185065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 3200/60000][Iteration 1432][Wall Clock 157.329983509s] Trained 128 records in 0.087175413 seconds. Throughput is 1468.304 records/second. Loss is 0.40753922. Sequential31006cbd's hyper parameters: Current learning rate is 0.007774840615767377. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:14 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 1433][Wall Clock 157.41116736s] Trained 128 records in 0.081183851 seconds. Throughput is 1576.6682 records/second. Loss is 0.35472035. Sequential31006cbd's hyper parameters: Current learning rate is 0.00777363184079602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 3456/60000][Iteration 1434][Wall Clock 157.511791433s] Trained 128 records in 0.100624073 seconds. Throughput is 1272.0614 records/second. Loss is 0.3579184. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077724234416291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 1435][Wall Clock 157.599478565s] Trained 128 records in 0.087687132 seconds. Throughput is 1459.7352 records/second. Loss is 0.31108359. Sequential31006cbd's hyper parameters: Current learning rate is 0.00777121541809139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 3712/60000][Iteration 1436][Wall Clock 157.685591026s] Trained 128 records in 0.086112461 seconds. Throughput is 1486.4283 records/second. Loss is 0.326335. Sequential31006cbd's hyper parameters: Current learning rate is 0.007770007770007771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 1437][Wall Clock 157.774652677s] Trained 128 records in 0.089061651 seconds. Throughput is 1437.2068 records/second. Loss is 0.3241081. Sequential31006cbd's hyper parameters: Current learning rate is 0.007768800497203233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 3968/60000][Iteration 1438][Wall Clock 157.860665619s] Trained 128 records in 0.086012942 seconds. Throughput is 1488.1481 records/second. Loss is 0.31851223. Sequential31006cbd's hyper parameters: Current learning rate is 0.007767593599502875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 1439][Wall Clock 157.944908725s] Trained 128 records in 0.084243106 seconds. Throughput is 1519.4122 records/second. Loss is 0.39023522. Sequential31006cbd's hyper parameters: Current learning rate is 0.007766387076731904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 4224/60000][Iteration 1440][Wall Clock 158.033665386s] Trained 128 records in 0.088756661 seconds. Throughput is 1442.1454 records/second. Loss is 0.34097594. Sequential31006cbd's hyper parameters: Current learning rate is 0.007765180928715639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 1441][Wall Clock 158.118731427s] Trained 128 records in 0.085066041 seconds. Throughput is 1504.7133 records/second. Loss is 0.44920892. Sequential31006cbd's hyper parameters: Current learning rate is 0.007763975155279503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 4480/60000][Iteration 1442][Wall Clock 158.205147061s] Trained 128 records in 0.086415634 seconds. Throughput is 1481.2135 records/second. Loss is 0.4532863. Sequential31006cbd's hyper parameters: Current learning rate is 0.00776276975624903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 1443][Wall Clock 158.286281935s] Trained 128 records in 0.081134874 seconds. Throughput is 1577.6201 records/second. Loss is 0.31680587. Sequential31006cbd's hyper parameters: Current learning rate is 0.00776156473144986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:15 INFO  DistriOptimizer$:408 - [Epoch 4 4736/60000][Iteration 1444][Wall Clock 158.37352239s] Trained 128 records in 0.087240455 seconds. Throughput is 1467.2092 records/second. Loss is 0.38968822. Sequential31006cbd's hyper parameters: Current learning rate is 0.007760360080707745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 1445][Wall Clock 158.474390874s] Trained 128 records in 0.100868484 seconds. Throughput is 1268.9791 records/second. Loss is 0.37237287. Sequential31006cbd's hyper parameters: Current learning rate is 0.007759155803848542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 4992/60000][Iteration 1446][Wall Clock 158.556552414s] Trained 128 records in 0.08216154 seconds. Throughput is 1557.9066 records/second. Loss is 0.5066217. Sequential31006cbd's hyper parameters: Current learning rate is 0.007757951900698215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 1447][Wall Clock 158.633332409s] Trained 128 records in 0.076779995 seconds. Throughput is 1667.101 records/second. Loss is 0.3740704. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077567483710828415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5248/60000][Iteration 1448][Wall Clock 158.71073971s] Trained 128 records in 0.077407301 seconds. Throughput is 1653.5908 records/second. Loss is 0.37430933. Sequential31006cbd's hyper parameters: Current learning rate is 0.007755545214828602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 1449][Wall Clock 158.790261946s] Trained 128 records in 0.079522236 seconds. Throughput is 1609.6127 records/second. Loss is 0.27087116. Sequential31006cbd's hyper parameters: Current learning rate is 0.007754342431761786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5504/60000][Iteration 1450][Wall Clock 158.869349405s] Trained 128 records in 0.079087459 seconds. Throughput is 1618.4614 records/second. Loss is 0.35330927. Sequential31006cbd's hyper parameters: Current learning rate is 0.007753140021708792. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 1451][Wall Clock 158.946200393s] Trained 128 records in 0.076850988 seconds. Throughput is 1665.5609 records/second. Loss is 0.4505934. Sequential31006cbd's hyper parameters: Current learning rate is 0.007751937984496124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5760/60000][Iteration 1452][Wall Clock 159.022116327s] Trained 128 records in 0.075915934 seconds. Throughput is 1686.0756 records/second. Loss is 0.39274764. Sequential31006cbd's hyper parameters: Current learning rate is 0.007750736319950395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 1453][Wall Clock 159.103413626s] Trained 128 records in 0.081297299 seconds. Throughput is 1574.468 records/second. Loss is 0.32330808. Sequential31006cbd's hyper parameters: Current learning rate is 0.007749535027898326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 6016/60000][Iteration 1454][Wall Clock 159.182185817s] Trained 128 records in 0.078772191 seconds. Throughput is 1624.9388 records/second. Loss is 0.36978745. Sequential31006cbd's hyper parameters: Current learning rate is 0.007748334108166745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 1455][Wall Clock 159.264208556s] Trained 128 records in 0.082022739 seconds. Throughput is 1560.5428 records/second. Loss is 0.3665233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077471335605825845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 6272/60000][Iteration 1456][Wall Clock 159.341377788s] Trained 128 records in 0.077169232 seconds. Throughput is 1658.6921 records/second. Loss is 0.34484404. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077459333849728895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:16 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 1457][Wall Clock 159.425686648s] Trained 128 records in 0.08430886 seconds. Throughput is 1518.227 records/second. Loss is 0.35645458. Sequential31006cbd's hyper parameters: Current learning rate is 0.007744733581164808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 6528/60000][Iteration 1458][Wall Clock 159.510238691s] Trained 128 records in 0.084552043 seconds. Throughput is 1513.8606 records/second. Loss is 0.33586016. Sequential31006cbd's hyper parameters: Current learning rate is 0.007743534148985598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 1459][Wall Clock 159.596764461s] Trained 128 records in 0.08652577 seconds. Throughput is 1479.3281 records/second. Loss is 0.33996415. Sequential31006cbd's hyper parameters: Current learning rate is 0.00774233508826262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 6784/60000][Iteration 1460][Wall Clock 159.715081573s] Trained 128 records in 0.118317112 seconds. Throughput is 1081.8384 records/second. Loss is 0.35653967. Sequential31006cbd's hyper parameters: Current learning rate is 0.007741136398823347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 1461][Wall Clock 159.807060157s] Trained 128 records in 0.091978584 seconds. Throughput is 1391.6283 records/second. Loss is 0.36305615. Sequential31006cbd's hyper parameters: Current learning rate is 0.007739938080495356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7040/60000][Iteration 1462][Wall Clock 159.907771478s] Trained 128 records in 0.100711321 seconds. Throughput is 1270.9594 records/second. Loss is 0.32893345. Sequential31006cbd's hyper parameters: Current learning rate is 0.007738740133106331. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 1463][Wall Clock 160.004636845s] Trained 128 records in 0.096865367 seconds. Throughput is 1321.4218 records/second. Loss is 0.28979176. Sequential31006cbd's hyper parameters: Current learning rate is 0.007737542556484061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7296/60000][Iteration 1464][Wall Clock 160.088441143s] Trained 128 records in 0.083804298 seconds. Throughput is 1527.368 records/second. Loss is 0.31997308. Sequential31006cbd's hyper parameters: Current learning rate is 0.007736345350456445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 1465][Wall Clock 160.179661817s] Trained 128 records in 0.091220674 seconds. Throughput is 1403.1907 records/second. Loss is 0.43967983. Sequential31006cbd's hyper parameters: Current learning rate is 0.007735148514851486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7552/60000][Iteration 1466][Wall Clock 160.262631092s] Trained 128 records in 0.082969275 seconds. Throughput is 1542.7397 records/second. Loss is 0.29993892. Sequential31006cbd's hyper parameters: Current learning rate is 0.007733952049497292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 1467][Wall Clock 160.339639259s] Trained 128 records in 0.077008167 seconds. Throughput is 1662.1614 records/second. Loss is 0.37841174. Sequential31006cbd's hyper parameters: Current learning rate is 0.007732755954222084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:17 INFO  DistriOptimizer$:408 - [Epoch 4 7808/60000][Iteration 1468][Wall Clock 160.425605709s] Trained 128 records in 0.08596645 seconds. Throughput is 1488.9529 records/second. Loss is 0.34571326. Sequential31006cbd's hyper parameters: Current learning rate is 0.007731560228854182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 1469][Wall Clock 160.510771592s] Trained 128 records in 0.085165883 seconds. Throughput is 1502.9493 records/second. Loss is 0.38457108. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077303648732220155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8064/60000][Iteration 1470][Wall Clock 160.597197906s] Trained 128 records in 0.086426314 seconds. Throughput is 1481.0304 records/second. Loss is 0.4331318. Sequential31006cbd's hyper parameters: Current learning rate is 0.007729169887154119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 1471][Wall Clock 160.680211408s] Trained 128 records in 0.083013502 seconds. Throughput is 1541.9178 records/second. Loss is 0.42491376. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077279752704791345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8320/60000][Iteration 1472][Wall Clock 160.761216727s] Trained 128 records in 0.081005319 seconds. Throughput is 1580.1432 records/second. Loss is 0.26226974. Sequential31006cbd's hyper parameters: Current learning rate is 0.007726781023025807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 1473][Wall Clock 160.840264718s] Trained 128 records in 0.079047991 seconds. Throughput is 1619.2694 records/second. Loss is 0.34212077. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077255871446229914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8576/60000][Iteration 1474][Wall Clock 160.92299739s] Trained 128 records in 0.082732672 seconds. Throughput is 1547.1519 records/second. Loss is 0.3034582. Sequential31006cbd's hyper parameters: Current learning rate is 0.007724393635099645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 1475][Wall Clock 161.002160098s] Trained 128 records in 0.079162708 seconds. Throughput is 1616.923 records/second. Loss is 0.43272245. Sequential31006cbd's hyper parameters: Current learning rate is 0.007723200494284832. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8832/60000][Iteration 1476][Wall Clock 161.085368378s] Trained 128 records in 0.08320828 seconds. Throughput is 1538.3085 records/second. Loss is 0.3745757. Sequential31006cbd's hyper parameters: Current learning rate is 0.007722007722007722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 1477][Wall Clock 161.167738395s] Trained 128 records in 0.082370017 seconds. Throughput is 1553.9634 records/second. Loss is 0.26018882. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077208153180975915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 9088/60000][Iteration 1478][Wall Clock 161.247403705s] Trained 128 records in 0.07966531 seconds. Throughput is 1606.7219 records/second. Loss is 0.39808723. Sequential31006cbd's hyper parameters: Current learning rate is 0.00771962328238382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 1479][Wall Clock 161.327263988s] Trained 128 records in 0.079860283 seconds. Throughput is 1602.7992 records/second. Loss is 0.42589888. Sequential31006cbd's hyper parameters: Current learning rate is 0.007718431614695894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:18 INFO  DistriOptimizer$:408 - [Epoch 4 9344/60000][Iteration 1480][Wall Clock 161.407292396s] Trained 128 records in 0.080028408 seconds. Throughput is 1599.432 records/second. Loss is 0.4733778. Sequential31006cbd's hyper parameters: Current learning rate is 0.007717240314863405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 1481][Wall Clock 161.506938795s] Trained 128 records in 0.099646399 seconds. Throughput is 1284.5422 records/second. Loss is 0.42845282. Sequential31006cbd's hyper parameters: Current learning rate is 0.007716049382716049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 9600/60000][Iteration 1482][Wall Clock 161.596650952s] Trained 128 records in 0.089712157 seconds. Throughput is 1426.7854 records/second. Loss is 0.38455215. Sequential31006cbd's hyper parameters: Current learning rate is 0.007714858818083629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 1483][Wall Clock 161.679500977s] Trained 128 records in 0.082850025 seconds. Throughput is 1544.9603 records/second. Loss is 0.37123474. Sequential31006cbd's hyper parameters: Current learning rate is 0.007713668620796051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 9856/60000][Iteration 1484][Wall Clock 161.75889318s] Trained 128 records in 0.079392203 seconds. Throughput is 1612.249 records/second. Loss is 0.3818241. Sequential31006cbd's hyper parameters: Current learning rate is 0.007712478790683326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 1485][Wall Clock 161.836819729s] Trained 128 records in 0.077926549 seconds. Throughput is 1642.5725 records/second. Loss is 0.43234634. Sequential31006cbd's hyper parameters: Current learning rate is 0.007711289327575571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 10112/60000][Iteration 1486][Wall Clock 161.924740333s] Trained 128 records in 0.087920604 seconds. Throughput is 1455.8589 records/second. Loss is 0.38022095. Sequential31006cbd's hyper parameters: Current learning rate is 0.007710100231303006. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 1487][Wall Clock 162.006670474s] Trained 128 records in 0.081930141 seconds. Throughput is 1562.3066 records/second. Loss is 0.37876508. Sequential31006cbd's hyper parameters: Current learning rate is 0.00770891150169596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 10368/60000][Iteration 1488][Wall Clock 162.104470858s] Trained 128 records in 0.097800384 seconds. Throughput is 1308.7883 records/second. Loss is 0.354277. Sequential31006cbd's hyper parameters: Current learning rate is 0.007707723138584861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 1489][Wall Clock 162.190101454s] Trained 128 records in 0.085630596 seconds. Throughput is 1494.7928 records/second. Loss is 0.42773628. Sequential31006cbd's hyper parameters: Current learning rate is 0.0077065351418002465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 10624/60000][Iteration 1490][Wall Clock 162.269797576s] Trained 128 records in 0.079696122 seconds. Throughput is 1606.1008 records/second. Loss is 0.30040812. Sequential31006cbd's hyper parameters: Current learning rate is 0.007705347511172754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:19 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 1491][Wall Clock 162.352130933s] Trained 128 records in 0.082333357 seconds. Throughput is 1554.6554 records/second. Loss is 0.39088404. Sequential31006cbd's hyper parameters: Current learning rate is 0.007704160246533128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 10880/60000][Iteration 1492][Wall Clock 162.432012327s] Trained 128 records in 0.079881394 seconds. Throughput is 1602.3757 records/second. Loss is 0.36719283. Sequential31006cbd's hyper parameters: Current learning rate is 0.007702973347712217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 1493][Wall Clock 162.513496825s] Trained 128 records in 0.081484498 seconds. Throughput is 1570.851 records/second. Loss is 0.30942562. Sequential31006cbd's hyper parameters: Current learning rate is 0.007701786814540973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11136/60000][Iteration 1494][Wall Clock 162.600373475s] Trained 128 records in 0.08687665 seconds. Throughput is 1473.3533 records/second. Loss is 0.4113546. Sequential31006cbd's hyper parameters: Current learning rate is 0.007700600646850454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 1495][Wall Clock 162.695401429s] Trained 128 records in 0.095027954 seconds. Throughput is 1346.972 records/second. Loss is 0.40303552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076994148444718205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11392/60000][Iteration 1496][Wall Clock 162.775137047s] Trained 128 records in 0.079735618 seconds. Throughput is 1605.3053 records/second. Loss is 0.32155406. Sequential31006cbd's hyper parameters: Current learning rate is 0.007698229407236336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 1497][Wall Clock 162.849490748s] Trained 128 records in 0.074353701 seconds. Throughput is 1721.5013 records/second. Loss is 0.41110522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076970443349753705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11648/60000][Iteration 1498][Wall Clock 162.929112105s] Trained 128 records in 0.079621357 seconds. Throughput is 1607.6088 records/second. Loss is 0.43667948. Sequential31006cbd's hyper parameters: Current learning rate is 0.007695859627520395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 1499][Wall Clock 163.011357582s] Trained 128 records in 0.082245477 seconds. Throughput is 1556.3167 records/second. Loss is 0.46816245. Sequential31006cbd's hyper parameters: Current learning rate is 0.007694675284702985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 11904/60000][Iteration 1500][Wall Clock 163.093224135s] Trained 128 records in 0.081866553 seconds. Throughput is 1563.52 records/second. Loss is 0.35507455. Sequential31006cbd's hyper parameters: Current learning rate is 0.007693491306354824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 1501][Wall Clock 163.225703027s] Trained 128 records in 0.132478892 seconds. Throughput is 966.19165 records/second. Loss is 0.38071007. Sequential31006cbd's hyper parameters: Current learning rate is 0.007692307692307692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 12160/60000][Iteration 1502][Wall Clock 163.321896609s] Trained 128 records in 0.096193582 seconds. Throughput is 1330.6501 records/second. Loss is 0.34287328. Sequential31006cbd's hyper parameters: Current learning rate is 0.007691124442393478. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:20 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 1503][Wall Clock 163.405089401s] Trained 128 records in 0.083192792 seconds. Throughput is 1538.5947 records/second. Loss is 0.42285514. Sequential31006cbd's hyper parameters: Current learning rate is 0.007689941556444172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 12416/60000][Iteration 1504][Wall Clock 163.491751869s] Trained 128 records in 0.086662468 seconds. Throughput is 1476.9946 records/second. Loss is 0.3601464. Sequential31006cbd's hyper parameters: Current learning rate is 0.007688759034291865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 1505][Wall Clock 163.578013983s] Trained 128 records in 0.086262114 seconds. Throughput is 1483.8496 records/second. Loss is 0.39260504. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076875768757687585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 12672/60000][Iteration 1506][Wall Clock 163.660246812s] Trained 128 records in 0.082232829 seconds. Throughput is 1556.556 records/second. Loss is 0.29612213. Sequential31006cbd's hyper parameters: Current learning rate is 0.007686395080707149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 1507][Wall Clock 163.745531181s] Trained 128 records in 0.085284369 seconds. Throughput is 1500.8612 records/second. Loss is 0.2796139. Sequential31006cbd's hyper parameters: Current learning rate is 0.00768521364893944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 12928/60000][Iteration 1508][Wall Clock 163.826292028s] Trained 128 records in 0.080760847 seconds. Throughput is 1584.9265 records/second. Loss is 0.350252. Sequential31006cbd's hyper parameters: Current learning rate is 0.00768403258029814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 1509][Wall Clock 163.905540288s] Trained 128 records in 0.07924826 seconds. Throughput is 1615.1775 records/second. Loss is 0.39198384. Sequential31006cbd's hyper parameters: Current learning rate is 0.007682851874615857. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 13184/60000][Iteration 1510][Wall Clock 163.986327423s] Trained 128 records in 0.080787135 seconds. Throughput is 1584.4106 records/second. Loss is 0.32012123. Sequential31006cbd's hyper parameters: Current learning rate is 0.007681671531725303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 1511][Wall Clock 164.067590754s] Trained 128 records in 0.081263331 seconds. Throughput is 1575.1261 records/second. Loss is 0.35277274. Sequential31006cbd's hyper parameters: Current learning rate is 0.007680491551459293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 13440/60000][Iteration 1512][Wall Clock 164.154742436s] Trained 128 records in 0.087151682 seconds. Throughput is 1468.7037 records/second. Loss is 0.5065333. Sequential31006cbd's hyper parameters: Current learning rate is 0.007679311933650745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 1513][Wall Clock 164.235004515s] Trained 128 records in 0.080262079 seconds. Throughput is 1594.7755 records/second. Loss is 0.29504114. Sequential31006cbd's hyper parameters: Current learning rate is 0.007678132678132678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:21 INFO  DistriOptimizer$:408 - [Epoch 4 13696/60000][Iteration 1514][Wall Clock 164.320482183s] Trained 128 records in 0.085477668 seconds. Throughput is 1497.4672 records/second. Loss is 0.2848763. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076769537847382165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 1515][Wall Clock 164.425420482s] Trained 128 records in 0.104938299 seconds. Throughput is 1219.7644 records/second. Loss is 0.385927. Sequential31006cbd's hyper parameters: Current learning rate is 0.007675775253300584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 13952/60000][Iteration 1516][Wall Clock 164.505421427s] Trained 128 records in 0.080000945 seconds. Throughput is 1599.9811 records/second. Loss is 0.4638446. Sequential31006cbd's hyper parameters: Current learning rate is 0.007674597083653109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 1517][Wall Clock 164.590232177s] Trained 128 records in 0.08481075 seconds. Throughput is 1509.2427 records/second. Loss is 0.4439406. Sequential31006cbd's hyper parameters: Current learning rate is 0.007673419275629221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14208/60000][Iteration 1518][Wall Clock 164.673016911s] Trained 128 records in 0.082784734 seconds. Throughput is 1546.1788 records/second. Loss is 0.36673456. Sequential31006cbd's hyper parameters: Current learning rate is 0.007672241829062453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 1519][Wall Clock 164.755735073s] Trained 128 records in 0.082718162 seconds. Throughput is 1547.4231 records/second. Loss is 0.36807418. Sequential31006cbd's hyper parameters: Current learning rate is 0.007671064743786437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14464/60000][Iteration 1520][Wall Clock 164.843102353s] Trained 128 records in 0.08736728 seconds. Throughput is 1465.0793 records/second. Loss is 0.48924106. Sequential31006cbd's hyper parameters: Current learning rate is 0.007669888019634913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 1521][Wall Clock 164.929687466s] Trained 128 records in 0.086585113 seconds. Throughput is 1478.3142 records/second. Loss is 0.31528345. Sequential31006cbd's hyper parameters: Current learning rate is 0.007668711656441718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14720/60000][Iteration 1522][Wall Clock 165.025565571s] Trained 128 records in 0.095878105 seconds. Throughput is 1335.0286 records/second. Loss is 0.3689329. Sequential31006cbd's hyper parameters: Current learning rate is 0.007667535654040792. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 1523][Wall Clock 165.105921719s] Trained 128 records in 0.080356148 seconds. Throughput is 1592.9086 records/second. Loss is 0.35340357. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076663600122661765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 14976/60000][Iteration 1524][Wall Clock 165.189282257s] Trained 128 records in 0.083360538 seconds. Throughput is 1535.4988 records/second. Loss is 0.4238208. Sequential31006cbd's hyper parameters: Current learning rate is 0.007665184730952016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 1525][Wall Clock 165.280087286s] Trained 128 records in 0.090805029 seconds. Throughput is 1409.6135 records/second. Loss is 0.35190636. Sequential31006cbd's hyper parameters: Current learning rate is 0.007664009809932557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:22 INFO  DistriOptimizer$:408 - [Epoch 4 15232/60000][Iteration 1526][Wall Clock 165.363560824s] Trained 128 records in 0.083473538 seconds. Throughput is 1533.42 records/second. Loss is 0.2939505. Sequential31006cbd's hyper parameters: Current learning rate is 0.007662835249042146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 1527][Wall Clock 165.440775101s] Trained 128 records in 0.077214277 seconds. Throughput is 1657.7245 records/second. Loss is 0.44070902. Sequential31006cbd's hyper parameters: Current learning rate is 0.007661661048115231. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 15488/60000][Iteration 1528][Wall Clock 165.524647703s] Trained 128 records in 0.083872602 seconds. Throughput is 1526.1241 records/second. Loss is 0.40290332. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076604872069863635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 1529][Wall Clock 165.618540612s] Trained 128 records in 0.093892909 seconds. Throughput is 1363.2552 records/second. Loss is 0.44498166. Sequential31006cbd's hyper parameters: Current learning rate is 0.007659313725490196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 15744/60000][Iteration 1530][Wall Clock 165.703884348s] Trained 128 records in 0.085343736 seconds. Throughput is 1499.8173 records/second. Loss is 0.4299373. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076581406034614795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 1531][Wall Clock 165.78405855s] Trained 128 records in 0.080174202 seconds. Throughput is 1596.5236 records/second. Loss is 0.4432984. Sequential31006cbd's hyper parameters: Current learning rate is 0.007656967840735069. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16000/60000][Iteration 1532][Wall Clock 165.877247635s] Trained 128 records in 0.093189085 seconds. Throughput is 1373.5514 records/second. Loss is 0.40033287. Sequential31006cbd's hyper parameters: Current learning rate is 0.007655795437145919. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 1533][Wall Clock 165.955408318s] Trained 128 records in 0.078160683 seconds. Throughput is 1637.6521 records/second. Loss is 0.32018495. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076546233925290875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16256/60000][Iteration 1534][Wall Clock 166.031767667s] Trained 128 records in 0.076359349 seconds. Throughput is 1676.2847 records/second. Loss is 0.338606. Sequential31006cbd's hyper parameters: Current learning rate is 0.007653451706719731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 1535][Wall Clock 166.112535653s] Trained 128 records in 0.080767986 seconds. Throughput is 1584.7863 records/second. Loss is 0.41380322. Sequential31006cbd's hyper parameters: Current learning rate is 0.007652280379553107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16512/60000][Iteration 1536][Wall Clock 166.195899301s] Trained 128 records in 0.083363648 seconds. Throughput is 1535.4415 records/second. Loss is 0.37950468. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076511094108645756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 1537][Wall Clock 166.289781605s] Trained 128 records in 0.093882304 seconds. Throughput is 1363.4092 records/second. Loss is 0.36781964. Sequential31006cbd's hyper parameters: Current learning rate is 0.007649938800489597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:23 INFO  DistriOptimizer$:408 - [Epoch 4 16768/60000][Iteration 1538][Wall Clock 166.370508998s] Trained 128 records in 0.080727393 seconds. Throughput is 1585.5833 records/second. Loss is 0.44443697. Sequential31006cbd's hyper parameters: Current learning rate is 0.007648768548263731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 1539][Wall Clock 166.451758313s] Trained 128 records in 0.081249315 seconds. Throughput is 1575.398 records/second. Loss is 0.45149297. Sequential31006cbd's hyper parameters: Current learning rate is 0.007647598654022637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17024/60000][Iteration 1540][Wall Clock 166.544374554s] Trained 128 records in 0.092616241 seconds. Throughput is 1382.0471 records/second. Loss is 0.32743356. Sequential31006cbd's hyper parameters: Current learning rate is 0.00764642911760208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 1541][Wall Clock 166.632829658s] Trained 128 records in 0.088455104 seconds. Throughput is 1447.0618 records/second. Loss is 0.30066234. Sequential31006cbd's hyper parameters: Current learning rate is 0.00764525993883792. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17280/60000][Iteration 1542][Wall Clock 166.717353357s] Trained 128 records in 0.084523699 seconds. Throughput is 1514.3682 records/second. Loss is 0.4118161. Sequential31006cbd's hyper parameters: Current learning rate is 0.007644091117566121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 1543][Wall Clock 166.812461374s] Trained 128 records in 0.095108017 seconds. Throughput is 1345.8381 records/second. Loss is 0.4194488. Sequential31006cbd's hyper parameters: Current learning rate is 0.007642922653622745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17536/60000][Iteration 1544][Wall Clock 166.898285667s] Trained 128 records in 0.085824293 seconds. Throughput is 1491.4192 records/second. Loss is 0.40831223. Sequential31006cbd's hyper parameters: Current learning rate is 0.007641754546843955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 1545][Wall Clock 166.98008366s] Trained 128 records in 0.081797993 seconds. Throughput is 1564.8306 records/second. Loss is 0.29447722. Sequential31006cbd's hyper parameters: Current learning rate is 0.007640586797066015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17792/60000][Iteration 1546][Wall Clock 167.06334522s] Trained 128 records in 0.08326156 seconds. Throughput is 1537.3241 records/second. Loss is 0.3813505. Sequential31006cbd's hyper parameters: Current learning rate is 0.007639419404125287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 1547][Wall Clock 167.153122053s] Trained 128 records in 0.089776833 seconds. Throughput is 1425.7576 records/second. Loss is 0.3280828. Sequential31006cbd's hyper parameters: Current learning rate is 0.007638252367858233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 18048/60000][Iteration 1548][Wall Clock 167.229019832s] Trained 128 records in 0.075897779 seconds. Throughput is 1686.4789 records/second. Loss is 0.41170576. Sequential31006cbd's hyper parameters: Current learning rate is 0.00763708568810142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 1549][Wall Clock 167.306094081s] Trained 128 records in 0.077074249 seconds. Throughput is 1660.7362 records/second. Loss is 0.41304773. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076359193646915085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:24 INFO  DistriOptimizer$:408 - [Epoch 4 18304/60000][Iteration 1550][Wall Clock 167.394983308s] Trained 128 records in 0.088889227 seconds. Throughput is 1439.9945 records/second. Loss is 0.4134153. Sequential31006cbd's hyper parameters: Current learning rate is 0.007634753397465261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 1551][Wall Clock 167.471634172s] Trained 128 records in 0.076650864 seconds. Throughput is 1669.9094 records/second. Loss is 0.36263853. Sequential31006cbd's hyper parameters: Current learning rate is 0.007633587786259542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 18560/60000][Iteration 1552][Wall Clock 167.565891613s] Trained 128 records in 0.094257441 seconds. Throughput is 1357.9829 records/second. Loss is 0.44439772. Sequential31006cbd's hyper parameters: Current learning rate is 0.007632422530911311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 1553][Wall Clock 167.648179698s] Trained 128 records in 0.082288085 seconds. Throughput is 1555.5107 records/second. Loss is 0.32048988. Sequential31006cbd's hyper parameters: Current learning rate is 0.007631257631257631. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 18816/60000][Iteration 1554][Wall Clock 167.730936578s] Trained 128 records in 0.08275688 seconds. Throughput is 1546.6992 records/second. Loss is 0.37149203. Sequential31006cbd's hyper parameters: Current learning rate is 0.007630093087135663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 1555][Wall Clock 167.835803855s] Trained 128 records in 0.104867277 seconds. Throughput is 1220.5905 records/second. Loss is 0.36678198. Sequential31006cbd's hyper parameters: Current learning rate is 0.007628928898382668. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 19072/60000][Iteration 1556][Wall Clock 167.91301066s] Trained 128 records in 0.077206805 seconds. Throughput is 1657.8849 records/second. Loss is 0.33252746. Sequential31006cbd's hyper parameters: Current learning rate is 0.007627765064836004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 1557][Wall Clock 168.005832575s] Trained 128 records in 0.092821915 seconds. Throughput is 1378.9846 records/second. Loss is 0.4291063. Sequential31006cbd's hyper parameters: Current learning rate is 0.007626601586333131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 19328/60000][Iteration 1558][Wall Clock 168.088621464s] Trained 128 records in 0.082788889 seconds. Throughput is 1546.1011 records/second. Loss is 0.34032884. Sequential31006cbd's hyper parameters: Current learning rate is 0.007625438462711607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 1559][Wall Clock 168.169766222s] Trained 128 records in 0.081144758 seconds. Throughput is 1577.4279 records/second. Loss is 0.371499. Sequential31006cbd's hyper parameters: Current learning rate is 0.007624275693809089. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 19584/60000][Iteration 1560][Wall Clock 168.245695038s] Trained 128 records in 0.075928816 seconds. Throughput is 1685.7896 records/second. Loss is 0.37306088. Sequential31006cbd's hyper parameters: Current learning rate is 0.007623113279463333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:25 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 1561][Wall Clock 168.329513841s] Trained 128 records in 0.083818803 seconds. Throughput is 1527.1036 records/second. Loss is 0.354661. Sequential31006cbd's hyper parameters: Current learning rate is 0.007621951219512195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 19840/60000][Iteration 1562][Wall Clock 168.421680969s] Trained 128 records in 0.092167128 seconds. Throughput is 1388.7814 records/second. Loss is 0.5283952. Sequential31006cbd's hyper parameters: Current learning rate is 0.007620789513793629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 1563][Wall Clock 168.533684665s] Trained 128 records in 0.112003696 seconds. Throughput is 1142.8195 records/second. Loss is 0.40966514. Sequential31006cbd's hyper parameters: Current learning rate is 0.007619628162145687. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20096/60000][Iteration 1564][Wall Clock 168.633492378s] Trained 128 records in 0.099807713 seconds. Throughput is 1282.4661 records/second. Loss is 0.3644121. Sequential31006cbd's hyper parameters: Current learning rate is 0.007618467164406522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 1565][Wall Clock 168.731254955s] Trained 128 records in 0.097762577 seconds. Throughput is 1309.2944 records/second. Loss is 0.36531463. Sequential31006cbd's hyper parameters: Current learning rate is 0.007617306520414382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20352/60000][Iteration 1566][Wall Clock 168.815423304s] Trained 128 records in 0.084168349 seconds. Throughput is 1520.7616 records/second. Loss is 0.33087134. Sequential31006cbd's hyper parameters: Current learning rate is 0.007616146230007617. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 1567][Wall Clock 168.897820296s] Trained 128 records in 0.082396992 seconds. Throughput is 1553.4548 records/second. Loss is 0.31798834. Sequential31006cbd's hyper parameters: Current learning rate is 0.007614986293024672. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20608/60000][Iteration 1568][Wall Clock 168.988647525s] Trained 128 records in 0.090827229 seconds. Throughput is 1409.269 records/second. Loss is 0.26011044. Sequential31006cbd's hyper parameters: Current learning rate is 0.007613826709304096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 1569][Wall Clock 169.07784438s] Trained 128 records in 0.089196855 seconds. Throughput is 1435.0282 records/second. Loss is 0.32248423. Sequential31006cbd's hyper parameters: Current learning rate is 0.00761266747868453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20864/60000][Iteration 1570][Wall Clock 169.168591026s] Trained 128 records in 0.090746646 seconds. Throughput is 1410.5204 records/second. Loss is 0.34601375. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076115086010047186. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 1571][Wall Clock 169.254642045s] Trained 128 records in 0.086051019 seconds. Throughput is 1487.4896 records/second. Loss is 0.38165966. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076103500761035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:26 INFO  DistriOptimizer$:408 - [Epoch 4 21120/60000][Iteration 1572][Wall Clock 169.34145288s] Trained 128 records in 0.086810835 seconds. Throughput is 1474.4703 records/second. Loss is 0.39954537. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076091919038198145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 1573][Wall Clock 169.431834008s] Trained 128 records in 0.090381128 seconds. Throughput is 1416.2249 records/second. Loss is 0.33180106. Sequential31006cbd's hyper parameters: Current learning rate is 0.007608034083992696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 21376/60000][Iteration 1574][Wall Clock 169.522578857s] Trained 128 records in 0.090744849 seconds. Throughput is 1410.5485 records/second. Loss is 0.3671713. Sequential31006cbd's hyper parameters: Current learning rate is 0.007606876616461282. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 1575][Wall Clock 169.603546278s] Trained 128 records in 0.080967421 seconds. Throughput is 1580.8828 records/second. Loss is 0.39830658. Sequential31006cbd's hyper parameters: Current learning rate is 0.007605719501064801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 21632/60000][Iteration 1576][Wall Clock 169.705506496s] Trained 128 records in 0.101960218 seconds. Throughput is 1255.3916 records/second. Loss is 0.27907544. Sequential31006cbd's hyper parameters: Current learning rate is 0.007604562737642586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 1577][Wall Clock 169.803403356s] Trained 128 records in 0.09789686 seconds. Throughput is 1307.4985 records/second. Loss is 0.3141033. Sequential31006cbd's hyper parameters: Current learning rate is 0.0076034063260340635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 21888/60000][Iteration 1578][Wall Clock 169.907569785s] Trained 128 records in 0.104166429 seconds. Throughput is 1228.8029 records/second. Loss is 0.2648639. Sequential31006cbd's hyper parameters: Current learning rate is 0.00760225026607876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 1579][Wall Clock 169.993062612s] Trained 128 records in 0.085492827 seconds. Throughput is 1497.2017 records/second. Loss is 0.4345465. Sequential31006cbd's hyper parameters: Current learning rate is 0.007601094557616298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 22144/60000][Iteration 1580][Wall Clock 170.075916702s] Trained 128 records in 0.08285409 seconds. Throughput is 1544.8845 records/second. Loss is 0.40986574. Sequential31006cbd's hyper parameters: Current learning rate is 0.007599939200486396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 1581][Wall Clock 170.182243295s] Trained 128 records in 0.106326593 seconds. Throughput is 1203.838 records/second. Loss is 0.41013265. Sequential31006cbd's hyper parameters: Current learning rate is 0.007598784194528876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 22400/60000][Iteration 1582][Wall Clock 170.266464624s] Trained 128 records in 0.084221329 seconds. Throughput is 1519.805 records/second. Loss is 0.39397427. Sequential31006cbd's hyper parameters: Current learning rate is 0.00759762953958365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:27 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 1583][Wall Clock 170.343549892s] Trained 128 records in 0.077085268 seconds. Throughput is 1660.4988 records/second. Loss is 0.40579185. Sequential31006cbd's hyper parameters: Current learning rate is 0.007596475235490732. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 22656/60000][Iteration 1584][Wall Clock 170.465312143s] Trained 128 records in 0.121762251 seconds. Throughput is 1051.2289 records/second. Loss is 0.2798391. Sequential31006cbd's hyper parameters: Current learning rate is 0.007595321282090233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 1585][Wall Clock 170.560552348s] Trained 128 records in 0.095240205 seconds. Throughput is 1343.9702 records/second. Loss is 0.48834237. Sequential31006cbd's hyper parameters: Current learning rate is 0.007594167679222358. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 22912/60000][Iteration 1586][Wall Clock 170.66861793s] Trained 128 records in 0.108065582 seconds. Throughput is 1184.466 records/second. Loss is 0.44791126. Sequential31006cbd's hyper parameters: Current learning rate is 0.007593014426727412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 1587][Wall Clock 170.796034928s] Trained 128 records in 0.127416998 seconds. Throughput is 1004.57556 records/second. Loss is 0.43537983. Sequential31006cbd's hyper parameters: Current learning rate is 0.007591861524445793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 23168/60000][Iteration 1588][Wall Clock 170.884389417s] Trained 128 records in 0.088354489 seconds. Throughput is 1448.7096 records/second. Loss is 0.5023905. Sequential31006cbd's hyper parameters: Current learning rate is 0.007590708972218005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 1589][Wall Clock 171.014151612s] Trained 128 records in 0.129762195 seconds. Throughput is 986.41986 records/second. Loss is 0.29028013. Sequential31006cbd's hyper parameters: Current learning rate is 0.007589556769884639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 23424/60000][Iteration 1590][Wall Clock 171.10954629s] Trained 128 records in 0.095394678 seconds. Throughput is 1341.794 records/second. Loss is 0.2727679. Sequential31006cbd's hyper parameters: Current learning rate is 0.007588404917286386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 1591][Wall Clock 171.231009073s] Trained 128 records in 0.121462783 seconds. Throughput is 1053.8207 records/second. Loss is 0.32831565. Sequential31006cbd's hyper parameters: Current learning rate is 0.007587253414264036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:28 INFO  DistriOptimizer$:408 - [Epoch 4 23680/60000][Iteration 1592][Wall Clock 171.315153566s] Trained 128 records in 0.084144493 seconds. Throughput is 1521.1927 records/second. Loss is 0.4345054. Sequential31006cbd's hyper parameters: Current learning rate is 0.007586102260658474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 1593][Wall Clock 171.421180872s] Trained 128 records in 0.106027306 seconds. Throughput is 1207.2362 records/second. Loss is 0.4887755. Sequential31006cbd's hyper parameters: Current learning rate is 0.00758495145631068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 23936/60000][Iteration 1594][Wall Clock 171.517505203s] Trained 128 records in 0.096324331 seconds. Throughput is 1328.8439 records/second. Loss is 0.43630284. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075838010010617326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 1595][Wall Clock 171.605692769s] Trained 128 records in 0.088187566 seconds. Throughput is 1451.4518 records/second. Loss is 0.42539424. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075826508947528055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24192/60000][Iteration 1596][Wall Clock 171.692137274s] Trained 128 records in 0.086444505 seconds. Throughput is 1480.7188 records/second. Loss is 0.43747523. Sequential31006cbd's hyper parameters: Current learning rate is 0.007581501137225171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 1597][Wall Clock 171.820546065s] Trained 128 records in 0.128408791 seconds. Throughput is 996.8165 records/second. Loss is 0.3952629. Sequential31006cbd's hyper parameters: Current learning rate is 0.007580351728320195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24448/60000][Iteration 1598][Wall Clock 171.9213383s] Trained 128 records in 0.100792235 seconds. Throughput is 1269.9391 records/second. Loss is 0.34586963. Sequential31006cbd's hyper parameters: Current learning rate is 0.00757920266787934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 1599][Wall Clock 172.005167037s] Trained 128 records in 0.083828737 seconds. Throughput is 1526.9226 records/second. Loss is 0.351111. Sequential31006cbd's hyper parameters: Current learning rate is 0.007578053955744166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24704/60000][Iteration 1600][Wall Clock 172.105316276s] Trained 128 records in 0.100149239 seconds. Throughput is 1278.0927 records/second. Loss is 0.34686726. Sequential31006cbd's hyper parameters: Current learning rate is 0.007576905591756326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 1601][Wall Clock 172.208206273s] Trained 128 records in 0.102889997 seconds. Throughput is 1244.047 records/second. Loss is 0.38900298. Sequential31006cbd's hyper parameters: Current learning rate is 0.007575757575757576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:29 INFO  DistriOptimizer$:408 - [Epoch 4 24960/60000][Iteration 1602][Wall Clock 172.309663056s] Trained 128 records in 0.101456783 seconds. Throughput is 1261.621 records/second. Loss is 0.33364463. Sequential31006cbd's hyper parameters: Current learning rate is 0.007574609907589759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 1603][Wall Clock 172.409735359s] Trained 128 records in 0.100072303 seconds. Throughput is 1279.0752 records/second. Loss is 0.30379784. Sequential31006cbd's hyper parameters: Current learning rate is 0.00757346258709482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25216/60000][Iteration 1604][Wall Clock 172.497368676s] Trained 128 records in 0.087633317 seconds. Throughput is 1460.6317 records/second. Loss is 0.25564906. Sequential31006cbd's hyper parameters: Current learning rate is 0.007572315614114797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 1605][Wall Clock 172.590724471s] Trained 128 records in 0.093355795 seconds. Throughput is 1371.0985 records/second. Loss is 0.31806388. Sequential31006cbd's hyper parameters: Current learning rate is 0.007571168988491824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25472/60000][Iteration 1606][Wall Clock 172.680913s] Trained 128 records in 0.090188529 seconds. Throughput is 1419.2493 records/second. Loss is 0.3327408. Sequential31006cbd's hyper parameters: Current learning rate is 0.007570022710068131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 1607][Wall Clock 172.761996715s] Trained 128 records in 0.081083715 seconds. Throughput is 1578.6154 records/second. Loss is 0.44852844. Sequential31006cbd's hyper parameters: Current learning rate is 0.007568876778686042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25728/60000][Iteration 1608][Wall Clock 172.87365536s] Trained 128 records in 0.111658645 seconds. Throughput is 1146.351 records/second. Loss is 0.37433523. Sequential31006cbd's hyper parameters: Current learning rate is 0.007567731194187982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 1609][Wall Clock 172.96343036s] Trained 128 records in 0.089775 seconds. Throughput is 1425.7866 records/second. Loss is 0.36915398. Sequential31006cbd's hyper parameters: Current learning rate is 0.007566585956416464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 25984/60000][Iteration 1610][Wall Clock 173.050471053s] Trained 128 records in 0.087040693 seconds. Throughput is 1470.5765 records/second. Loss is 0.35281682. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075654410652141015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 1611][Wall Clock 173.13230985s] Trained 128 records in 0.081838797 seconds. Throughput is 1564.0504 records/second. Loss is 0.3209598. Sequential31006cbd's hyper parameters: Current learning rate is 0.007564296520423601. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 26240/60000][Iteration 1612][Wall Clock 173.225028365s] Trained 128 records in 0.092718515 seconds. Throughput is 1380.5226 records/second. Loss is 0.3144104. Sequential31006cbd's hyper parameters: Current learning rate is 0.007563152321887763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:30 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 1613][Wall Clock 173.321513197s] Trained 128 records in 0.096484832 seconds. Throughput is 1326.6334 records/second. Loss is 0.32272878. Sequential31006cbd's hyper parameters: Current learning rate is 0.007562008469449486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 26496/60000][Iteration 1614][Wall Clock 173.470524977s] Trained 128 records in 0.14901178 seconds. Throughput is 858.9925 records/second. Loss is 0.28192133. Sequential31006cbd's hyper parameters: Current learning rate is 0.007560864962951762. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 1615][Wall Clock 173.561208538s] Trained 128 records in 0.090683561 seconds. Throughput is 1411.5016 records/second. Loss is 0.4889377. Sequential31006cbd's hyper parameters: Current learning rate is 0.007559721802237678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 26752/60000][Iteration 1616][Wall Clock 173.64493693s] Trained 128 records in 0.083728392 seconds. Throughput is 1528.7526 records/second. Loss is 0.4925285. Sequential31006cbd's hyper parameters: Current learning rate is 0.007558578987150416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 1617][Wall Clock 173.750393162s] Trained 128 records in 0.105456232 seconds. Throughput is 1213.7737 records/second. Loss is 0.32538888. Sequential31006cbd's hyper parameters: Current learning rate is 0.007557436517533253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 27008/60000][Iteration 1618][Wall Clock 173.849599905s] Trained 128 records in 0.099206743 seconds. Throughput is 1290.2349 records/second. Loss is 0.30328238. Sequential31006cbd's hyper parameters: Current learning rate is 0.007556294393229561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 1619][Wall Clock 173.934241845s] Trained 128 records in 0.08464194 seconds. Throughput is 1512.2527 records/second. Loss is 0.26239696. Sequential31006cbd's hyper parameters: Current learning rate is 0.007555152614082805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 27264/60000][Iteration 1620][Wall Clock 174.025877596s] Trained 128 records in 0.091635751 seconds. Throughput is 1396.8347 records/second. Loss is 0.39654037. Sequential31006cbd's hyper parameters: Current learning rate is 0.007554011179936546. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 1621][Wall Clock 174.145595546s] Trained 128 records in 0.11971795 seconds. Throughput is 1069.1797 records/second. Loss is 0.4316116. Sequential31006cbd's hyper parameters: Current learning rate is 0.007552870090634441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:31 INFO  DistriOptimizer$:408 - [Epoch 4 27520/60000][Iteration 1622][Wall Clock 174.289211428s] Trained 128 records in 0.143615882 seconds. Throughput is 891.2663 records/second. Loss is 0.4163291. Sequential31006cbd's hyper parameters: Current learning rate is 0.007551729346020239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 1623][Wall Clock 174.399488516s] Trained 128 records in 0.110277088 seconds. Throughput is 1160.7125 records/second. Loss is 0.33444202. Sequential31006cbd's hyper parameters: Current learning rate is 0.007550588945937783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 27776/60000][Iteration 1624][Wall Clock 174.493480705s] Trained 128 records in 0.093992189 seconds. Throughput is 1361.8153 records/second. Loss is 0.3370419. Sequential31006cbd's hyper parameters: Current learning rate is 0.007549448890231013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 1625][Wall Clock 174.580766651s] Trained 128 records in 0.087285946 seconds. Throughput is 1466.4446 records/second. Loss is 0.45559675. Sequential31006cbd's hyper parameters: Current learning rate is 0.007548309178743962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28032/60000][Iteration 1626][Wall Clock 174.686940341s] Trained 128 records in 0.10617369 seconds. Throughput is 1205.5718 records/second. Loss is 0.3236175. Sequential31006cbd's hyper parameters: Current learning rate is 0.007547169811320755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 1627][Wall Clock 174.777556573s] Trained 128 records in 0.090616232 seconds. Throughput is 1412.5504 records/second. Loss is 0.45732927. Sequential31006cbd's hyper parameters: Current learning rate is 0.007546030787805615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28288/60000][Iteration 1628][Wall Clock 174.868099909s] Trained 128 records in 0.090543336 seconds. Throughput is 1413.6876 records/second. Loss is 0.29895115. Sequential31006cbd's hyper parameters: Current learning rate is 0.007544892108042854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 1629][Wall Clock 174.953237514s] Trained 128 records in 0.085137605 seconds. Throughput is 1503.4485 records/second. Loss is 0.31218335. Sequential31006cbd's hyper parameters: Current learning rate is 0.007543753771876886. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28544/60000][Iteration 1630][Wall Clock 175.048046378s] Trained 128 records in 0.094808864 seconds. Throughput is 1350.0847 records/second. Loss is 0.3567987. Sequential31006cbd's hyper parameters: Current learning rate is 0.00754261577915221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 1631][Wall Clock 175.138955673s] Trained 128 records in 0.090909295 seconds. Throughput is 1407.9968 records/second. Loss is 0.40131778. Sequential31006cbd's hyper parameters: Current learning rate is 0.007541478129713424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28800/60000][Iteration 1632][Wall Clock 175.220261624s] Trained 128 records in 0.081305951 seconds. Throughput is 1574.3005 records/second. Loss is 0.34292763. Sequential31006cbd's hyper parameters: Current learning rate is 0.007540340823405218. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:32 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 1633][Wall Clock 175.322245502s] Trained 128 records in 0.101983878 seconds. Throughput is 1255.1003 records/second. Loss is 0.35737494. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075392038600723766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29056/60000][Iteration 1634][Wall Clock 175.415107918s] Trained 128 records in 0.092862416 seconds. Throughput is 1378.3833 records/second. Loss is 0.30290455. Sequential31006cbd's hyper parameters: Current learning rate is 0.007538067239559777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 1635][Wall Clock 175.513357026s] Trained 128 records in 0.098249108 seconds. Throughput is 1302.8108 records/second. Loss is 0.4751426. Sequential31006cbd's hyper parameters: Current learning rate is 0.007536930961712391. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29312/60000][Iteration 1636][Wall Clock 175.602653016s] Trained 128 records in 0.08929599 seconds. Throughput is 1433.435 records/second. Loss is 0.417214. Sequential31006cbd's hyper parameters: Current learning rate is 0.007535795026375283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 1637][Wall Clock 175.687379189s] Trained 128 records in 0.084726173 seconds. Throughput is 1510.7493 records/second. Loss is 0.45069727. Sequential31006cbd's hyper parameters: Current learning rate is 0.007534659433393611. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29568/60000][Iteration 1638][Wall Clock 175.772166017s] Trained 128 records in 0.084786828 seconds. Throughput is 1509.6685 records/second. Loss is 0.40932783. Sequential31006cbd's hyper parameters: Current learning rate is 0.007533524182612627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 1639][Wall Clock 175.889372227s] Trained 128 records in 0.11720621 seconds. Throughput is 1092.0923 records/second. Loss is 0.37129486. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075323892738776745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29824/60000][Iteration 1640][Wall Clock 176.014845115s] Trained 128 records in 0.125472888 seconds. Throughput is 1020.1407 records/second. Loss is 0.29113394. Sequential31006cbd's hyper parameters: Current learning rate is 0.007531254707034192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 1641][Wall Clock 176.121311346s] Trained 128 records in 0.106466231 seconds. Throughput is 1202.2592 records/second. Loss is 0.33170918. Sequential31006cbd's hyper parameters: Current learning rate is 0.007530120481927711. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 30080/60000][Iteration 1642][Wall Clock 176.22193246s] Trained 128 records in 0.100621114 seconds. Throughput is 1272.0989 records/second. Loss is 0.3707641. Sequential31006cbd's hyper parameters: Current learning rate is 0.007528986598403855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:33 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 1643][Wall Clock 176.343118615s] Trained 128 records in 0.121186155 seconds. Throughput is 1056.2263 records/second. Loss is 0.3688777. Sequential31006cbd's hyper parameters: Current learning rate is 0.007527853056308341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 30336/60000][Iteration 1644][Wall Clock 176.43521718s] Trained 128 records in 0.092098565 seconds. Throughput is 1389.8154 records/second. Loss is 0.29225546. Sequential31006cbd's hyper parameters: Current learning rate is 0.007526719855486979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 1645][Wall Clock 176.517336901s] Trained 128 records in 0.082119721 seconds. Throughput is 1558.7 records/second. Loss is 0.39544886. Sequential31006cbd's hyper parameters: Current learning rate is 0.007525586995785672. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 30592/60000][Iteration 1646][Wall Clock 176.605345089s] Trained 128 records in 0.088008188 seconds. Throughput is 1454.4102 records/second. Loss is 0.2731223. Sequential31006cbd's hyper parameters: Current learning rate is 0.007524454477050415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 1647][Wall Clock 176.687578907s] Trained 128 records in 0.082233818 seconds. Throughput is 1556.5372 records/second. Loss is 0.37820083. Sequential31006cbd's hyper parameters: Current learning rate is 0.007523322299127295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 30848/60000][Iteration 1648][Wall Clock 176.817856455s] Trained 128 records in 0.130277548 seconds. Throughput is 982.51776 records/second. Loss is 0.4830582. Sequential31006cbd's hyper parameters: Current learning rate is 0.007522190461862493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 1649][Wall Clock 176.919959437s] Trained 128 records in 0.102102982 seconds. Throughput is 1253.6362 records/second. Loss is 0.36627448. Sequential31006cbd's hyper parameters: Current learning rate is 0.007521058965102286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 31104/60000][Iteration 1650][Wall Clock 177.004976379s] Trained 128 records in 0.085016942 seconds. Throughput is 1505.5823 records/second. Loss is 0.3895259. Sequential31006cbd's hyper parameters: Current learning rate is 0.007519927808693036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 1651][Wall Clock 177.088185287s] Trained 128 records in 0.083208908 seconds. Throughput is 1538.2968 records/second. Loss is 0.29575473. Sequential31006cbd's hyper parameters: Current learning rate is 0.007518796992481203. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 31360/60000][Iteration 1652][Wall Clock 177.177906972s] Trained 128 records in 0.089721685 seconds. Throughput is 1426.6339 records/second. Loss is 0.32498637. Sequential31006cbd's hyper parameters: Current learning rate is 0.007517666516313336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 1653][Wall Clock 177.264219963s] Trained 128 records in 0.086312991 seconds. Throughput is 1482.9749 records/second. Loss is 0.32775778. Sequential31006cbd's hyper parameters: Current learning rate is 0.00751653638003608. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:34 INFO  DistriOptimizer$:408 - [Epoch 4 31616/60000][Iteration 1654][Wall Clock 177.348994359s] Trained 128 records in 0.084774396 seconds. Throughput is 1509.8898 records/second. Loss is 0.30988878. Sequential31006cbd's hyper parameters: Current learning rate is 0.007515406583496168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 1655][Wall Clock 177.445145412s] Trained 128 records in 0.096151053 seconds. Throughput is 1331.2386 records/second. Loss is 0.30832815. Sequential31006cbd's hyper parameters: Current learning rate is 0.007514277126540427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 31872/60000][Iteration 1656][Wall Clock 177.541107404s] Trained 128 records in 0.095961992 seconds. Throughput is 1333.8613 records/second. Loss is 0.3723663. Sequential31006cbd's hyper parameters: Current learning rate is 0.007513148009015778. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 1657][Wall Clock 177.633627918s] Trained 128 records in 0.092520514 seconds. Throughput is 1383.4769 records/second. Loss is 0.35909602. Sequential31006cbd's hyper parameters: Current learning rate is 0.007512019230769231. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32128/60000][Iteration 1658][Wall Clock 177.720979388s] Trained 128 records in 0.08735147 seconds. Throughput is 1465.3445 records/second. Loss is 0.37255737. Sequential31006cbd's hyper parameters: Current learning rate is 0.00751089079164789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 1659][Wall Clock 177.825911318s] Trained 128 records in 0.10493193 seconds. Throughput is 1219.8385 records/second. Loss is 0.27308887. Sequential31006cbd's hyper parameters: Current learning rate is 0.00750976269149895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32384/60000][Iteration 1660][Wall Clock 177.919052949s] Trained 128 records in 0.093141631 seconds. Throughput is 1374.2512 records/second. Loss is 0.25937378. Sequential31006cbd's hyper parameters: Current learning rate is 0.007508634930169695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 1661][Wall Clock 178.016724824s] Trained 128 records in 0.097671875 seconds. Throughput is 1310.5104 records/second. Loss is 0.39432597. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075075075075075074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32640/60000][Iteration 1662][Wall Clock 178.113309531s] Trained 128 records in 0.096584707 seconds. Throughput is 1325.2616 records/second. Loss is 0.3665715. Sequential31006cbd's hyper parameters: Current learning rate is 0.007506380423359856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 1663][Wall Clock 178.20276367s] Trained 128 records in 0.089454139 seconds. Throughput is 1430.9009 records/second. Loss is 0.3438968. Sequential31006cbd's hyper parameters: Current learning rate is 0.007505253677574302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:35 INFO  DistriOptimizer$:408 - [Epoch 4 32896/60000][Iteration 1664][Wall Clock 178.297510392s] Trained 128 records in 0.094746722 seconds. Throughput is 1350.9702 records/second. Loss is 0.33537734. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075041272699984994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 1665][Wall Clock 178.441661425s] Trained 128 records in 0.144151033 seconds. Throughput is 887.9576 records/second. Loss is 0.28443408. Sequential31006cbd's hyper parameters: Current learning rate is 0.007503001200480192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33152/60000][Iteration 1666][Wall Clock 178.552694327s] Trained 128 records in 0.111032902 seconds. Throughput is 1152.8114 records/second. Loss is 0.33352545. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075018754688672175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 1667][Wall Clock 178.640138142s] Trained 128 records in 0.087443815 seconds. Throughput is 1463.7971 records/second. Loss is 0.38621706. Sequential31006cbd's hyper parameters: Current learning rate is 0.0075007500750075016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33408/60000][Iteration 1668][Wall Clock 178.765071722s] Trained 128 records in 0.12493358 seconds. Throughput is 1024.5444 records/second. Loss is 0.35562563. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074996250187490615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 1669][Wall Clock 178.876863332s] Trained 128 records in 0.11179161 seconds. Throughput is 1144.9875 records/second. Loss is 0.3687098. Sequential31006cbd's hyper parameters: Current learning rate is 0.007498500299940011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33664/60000][Iteration 1670][Wall Clock 178.971572945s] Trained 128 records in 0.094709613 seconds. Throughput is 1351.4995 records/second. Loss is 0.27514127. Sequential31006cbd's hyper parameters: Current learning rate is 0.00749737591842855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 1671][Wall Clock 179.05612326s] Trained 128 records in 0.084550315 seconds. Throughput is 1513.8915 records/second. Loss is 0.4462971. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074962518740629685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 33920/60000][Iteration 1672][Wall Clock 179.140039217s] Trained 128 records in 0.083915957 seconds. Throughput is 1525.3357 records/second. Loss is 0.4167587. Sequential31006cbd's hyper parameters: Current learning rate is 0.00749512816669165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 1673][Wall Clock 179.25633046s] Trained 128 records in 0.116291243 seconds. Throughput is 1100.6848 records/second. Loss is 0.4215482. Sequential31006cbd's hyper parameters: Current learning rate is 0.00749400479616307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:36 INFO  DistriOptimizer$:408 - [Epoch 4 34176/60000][Iteration 1674][Wall Clock 179.334943889s] Trained 128 records in 0.078613429 seconds. Throughput is 1628.2205 records/second. Loss is 0.40552565. Sequential31006cbd's hyper parameters: Current learning rate is 0.007492881762325791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 1675][Wall Clock 179.429366219s] Trained 128 records in 0.09442233 seconds. Throughput is 1355.6115 records/second. Loss is 0.24923038. Sequential31006cbd's hyper parameters: Current learning rate is 0.007491759065028469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 34432/60000][Iteration 1676][Wall Clock 179.53549686s] Trained 128 records in 0.106130641 seconds. Throughput is 1206.0607 records/second. Loss is 0.3136833. Sequential31006cbd's hyper parameters: Current learning rate is 0.00749063670411985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 1677][Wall Clock 179.620413065s] Trained 128 records in 0.084916205 seconds. Throughput is 1507.3684 records/second. Loss is 0.3600027. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074895146794487725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 34688/60000][Iteration 1678][Wall Clock 179.715294976s] Trained 128 records in 0.094881911 seconds. Throughput is 1349.0453 records/second. Loss is 0.35903972. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074883929908641615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 1679][Wall Clock 179.800320752s] Trained 128 records in 0.085025776 seconds. Throughput is 1505.4259 records/second. Loss is 0.33220923. Sequential31006cbd's hyper parameters: Current learning rate is 0.007487271638215035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 34944/60000][Iteration 1680][Wall Clock 179.891105542s] Trained 128 records in 0.09078479 seconds. Throughput is 1409.9279 records/second. Loss is 0.41354486. Sequential31006cbd's hyper parameters: Current learning rate is 0.007486150621350501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 1681][Wall Clock 179.977575692s] Trained 128 records in 0.08647015 seconds. Throughput is 1480.2797 records/second. Loss is 0.47218817. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074850299401197605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 35200/60000][Iteration 1682][Wall Clock 180.071251524s] Trained 128 records in 0.093675832 seconds. Throughput is 1366.4144 records/second. Loss is 0.33623087. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074839095943721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 1683][Wall Clock 180.167760598s] Trained 128 records in 0.096509074 seconds. Throughput is 1326.3002 records/second. Loss is 0.35409683. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074827895839568994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:37 INFO  DistriOptimizer$:408 - [Epoch 4 35456/60000][Iteration 1684][Wall Clock 180.266255132s] Trained 128 records in 0.098494534 seconds. Throughput is 1299.5645 records/second. Loss is 0.31740934. Sequential31006cbd's hyper parameters: Current learning rate is 0.007481669908723627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 1685][Wall Clock 180.352030429s] Trained 128 records in 0.085775297 seconds. Throughput is 1492.2712 records/second. Loss is 0.3977688. Sequential31006cbd's hyper parameters: Current learning rate is 0.007480550568521843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 35712/60000][Iteration 1686][Wall Clock 180.449076838s] Trained 128 records in 0.097046409 seconds. Throughput is 1318.9565 records/second. Loss is 0.27372268. Sequential31006cbd's hyper parameters: Current learning rate is 0.007479431563201197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 1687][Wall Clock 180.545435887s] Trained 128 records in 0.096359049 seconds. Throughput is 1328.3651 records/second. Loss is 0.3228503. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074783128926114275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 35968/60000][Iteration 1688][Wall Clock 180.650489847s] Trained 128 records in 0.10505396 seconds. Throughput is 1218.4215 records/second. Loss is 0.37836704. Sequential31006cbd's hyper parameters: Current learning rate is 0.007477194556602362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 1689][Wall Clock 180.744660509s] Trained 128 records in 0.094170662 seconds. Throughput is 1359.2344 records/second. Loss is 0.32358825. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074760765550239226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 36224/60000][Iteration 1690][Wall Clock 180.84156082s] Trained 128 records in 0.096900311 seconds. Throughput is 1320.9452 records/second. Loss is 0.42891824. Sequential31006cbd's hyper parameters: Current learning rate is 0.007474958887726117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 1691][Wall Clock 180.966057921s] Trained 128 records in 0.124497101 seconds. Throughput is 1028.1364 records/second. Loss is 0.35204917. Sequential31006cbd's hyper parameters: Current learning rate is 0.007473841554559043. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 36480/60000][Iteration 1692][Wall Clock 181.066394381s] Trained 128 records in 0.10033646 seconds. Throughput is 1275.7078 records/second. Loss is 0.2773379. Sequential31006cbd's hyper parameters: Current learning rate is 0.007472724555372889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 1693][Wall Clock 181.174764097s] Trained 128 records in 0.108369716 seconds. Throughput is 1181.1418 records/second. Loss is 0.30401993. Sequential31006cbd's hyper parameters: Current learning rate is 0.007471607890017932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:38 INFO  DistriOptimizer$:408 - [Epoch 4 36736/60000][Iteration 1694][Wall Clock 181.262571828s] Trained 128 records in 0.087807731 seconds. Throughput is 1457.7305 records/second. Loss is 0.3957529. Sequential31006cbd's hyper parameters: Current learning rate is 0.007470491558344539. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 1695][Wall Clock 181.352523919s] Trained 128 records in 0.089952091 seconds. Throughput is 1422.9797 records/second. Loss is 0.4274074. Sequential31006cbd's hyper parameters: Current learning rate is 0.007469375560203167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 36992/60000][Iteration 1696][Wall Clock 181.44070884s] Trained 128 records in 0.088184921 seconds. Throughput is 1451.4952 records/second. Loss is 0.32038862. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074682598954443615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 1697][Wall Clock 181.536926014s] Trained 128 records in 0.096217174 seconds. Throughput is 1330.3239 records/second. Loss is 0.4148882. Sequential31006cbd's hyper parameters: Current learning rate is 0.007467144563918758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37248/60000][Iteration 1698][Wall Clock 181.624484644s] Trained 128 records in 0.08755863 seconds. Throughput is 1461.8777 records/second. Loss is 0.41545832. Sequential31006cbd's hyper parameters: Current learning rate is 0.00746602956547708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 1699][Wall Clock 181.732145651s] Trained 128 records in 0.107661007 seconds. Throughput is 1188.917 records/second. Loss is 0.33105487. Sequential31006cbd's hyper parameters: Current learning rate is 0.007464914899970141. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37504/60000][Iteration 1700][Wall Clock 181.81321096s] Trained 128 records in 0.081065309 seconds. Throughput is 1578.9738 records/second. Loss is 0.4422614. Sequential31006cbd's hyper parameters: Current learning rate is 0.007463800567248844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 1701][Wall Clock 181.910327389s] Trained 128 records in 0.097116429 seconds. Throughput is 1318.0056 records/second. Loss is 0.4085661. Sequential31006cbd's hyper parameters: Current learning rate is 0.007462686567164179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37760/60000][Iteration 1702][Wall Clock 182.019702905s] Trained 128 records in 0.109375516 seconds. Throughput is 1170.2803 records/second. Loss is 0.3372342. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074615728995672285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 1703][Wall Clock 182.101155132s] Trained 128 records in 0.081452227 seconds. Throughput is 1571.4733 records/second. Loss is 0.29874542. Sequential31006cbd's hyper parameters: Current learning rate is 0.007460459564309161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 38016/60000][Iteration 1704][Wall Clock 182.192393597s] Trained 128 records in 0.091238465 seconds. Throughput is 1402.9171 records/second. Loss is 0.3742349. Sequential31006cbd's hyper parameters: Current learning rate is 0.007459346561241235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:39 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 1705][Wall Clock 182.318338795s] Trained 128 records in 0.125945198 seconds. Throughput is 1016.31506 records/second. Loss is 0.41024294. Sequential31006cbd's hyper parameters: Current learning rate is 0.007458233890214798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 38272/60000][Iteration 1706][Wall Clock 182.410111707s] Trained 128 records in 0.091772912 seconds. Throughput is 1394.7471 records/second. Loss is 0.4476402. Sequential31006cbd's hyper parameters: Current learning rate is 0.007457121551081283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 1707][Wall Clock 182.4920229s] Trained 128 records in 0.081911193 seconds. Throughput is 1562.6681 records/second. Loss is 0.44119212. Sequential31006cbd's hyper parameters: Current learning rate is 0.007456009543692217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 38528/60000][Iteration 1708][Wall Clock 182.586474011s] Trained 128 records in 0.094451111 seconds. Throughput is 1355.1984 records/second. Loss is 0.53528154. Sequential31006cbd's hyper parameters: Current learning rate is 0.007454897867899209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 1709][Wall Clock 182.669905411s] Trained 128 records in 0.0834314 seconds. Throughput is 1534.1946 records/second. Loss is 0.3190821. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074537865235539645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 38784/60000][Iteration 1710][Wall Clock 182.770908726s] Trained 128 records in 0.101003315 seconds. Throughput is 1267.2852 records/second. Loss is 0.4624318. Sequential31006cbd's hyper parameters: Current learning rate is 0.007452675510508272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 1711][Wall Clock 182.890739938s] Trained 128 records in 0.119831212 seconds. Throughput is 1068.1691 records/second. Loss is 0.3937899. Sequential31006cbd's hyper parameters: Current learning rate is 0.007451564828614009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 39040/60000][Iteration 1712][Wall Clock 182.973579734s] Trained 128 records in 0.082839796 seconds. Throughput is 1545.1511 records/second. Loss is 0.4224798. Sequential31006cbd's hyper parameters: Current learning rate is 0.007450454477723141. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 1713][Wall Clock 183.074368528s] Trained 128 records in 0.100788794 seconds. Throughput is 1269.9824 records/second. Loss is 0.4299787. Sequential31006cbd's hyper parameters: Current learning rate is 0.007449344457687724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 39296/60000][Iteration 1714][Wall Clock 183.171296901s] Trained 128 records in 0.096928373 seconds. Throughput is 1320.5627 records/second. Loss is 0.31278092. Sequential31006cbd's hyper parameters: Current learning rate is 0.007448234768359899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:40 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 1715][Wall Clock 183.279867707s] Trained 128 records in 0.108570806 seconds. Throughput is 1178.9541 records/second. Loss is 0.36439732. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074471254095918975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 39552/60000][Iteration 1716][Wall Clock 183.399960154s] Trained 128 records in 0.120092447 seconds. Throughput is 1065.8456 records/second. Loss is 0.3752922. Sequential31006cbd's hyper parameters: Current learning rate is 0.007446016381236039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 1717][Wall Clock 183.484280257s] Trained 128 records in 0.084320103 seconds. Throughput is 1518.0247 records/second. Loss is 0.32887796. Sequential31006cbd's hyper parameters: Current learning rate is 0.00744490768314473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 39808/60000][Iteration 1718][Wall Clock 183.577255604s] Trained 128 records in 0.092975347 seconds. Throughput is 1376.709 records/second. Loss is 0.2782872. Sequential31006cbd's hyper parameters: Current learning rate is 0.007443799315170464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 1719][Wall Clock 183.661997703s] Trained 128 records in 0.084742099 seconds. Throughput is 1510.4653 records/second. Loss is 0.3126253. Sequential31006cbd's hyper parameters: Current learning rate is 0.007442691277165824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40064/60000][Iteration 1720][Wall Clock 183.753410128s] Trained 128 records in 0.091412425 seconds. Throughput is 1400.2473 records/second. Loss is 0.43552843. Sequential31006cbd's hyper parameters: Current learning rate is 0.007441583568983481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 1721][Wall Clock 183.840476011s] Trained 128 records in 0.087065883 seconds. Throughput is 1470.151 records/second. Loss is 0.35448188. Sequential31006cbd's hyper parameters: Current learning rate is 0.00744047619047619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40320/60000][Iteration 1722][Wall Clock 183.927930922s] Trained 128 records in 0.087454911 seconds. Throughput is 1463.6115 records/second. Loss is 0.4327336. Sequential31006cbd's hyper parameters: Current learning rate is 0.007439369141496801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 1723][Wall Clock 184.008651877s] Trained 128 records in 0.080720955 seconds. Throughput is 1585.7097 records/second. Loss is 0.28005803. Sequential31006cbd's hyper parameters: Current learning rate is 0.007438262421898245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40576/60000][Iteration 1724][Wall Clock 184.122216468s] Trained 128 records in 0.113564591 seconds. Throughput is 1127.1119 records/second. Loss is 0.2918886. Sequential31006cbd's hyper parameters: Current learning rate is 0.007437156031533542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 1725][Wall Clock 184.239396769s] Trained 128 records in 0.117180301 seconds. Throughput is 1092.3337 records/second. Loss is 0.42201728. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074360499702558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:41 INFO  DistriOptimizer$:408 - [Epoch 4 40832/60000][Iteration 1726][Wall Clock 184.32017224s] Trained 128 records in 0.080775471 seconds. Throughput is 1584.6395 records/second. Loss is 0.35341233. Sequential31006cbd's hyper parameters: Current learning rate is 0.007434944237918216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 1727][Wall Clock 184.407010512s] Trained 128 records in 0.086838272 seconds. Throughput is 1474.0044 records/second. Loss is 0.48401177. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074338388343740715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41088/60000][Iteration 1728][Wall Clock 184.483131612s] Trained 128 records in 0.0761211 seconds. Throughput is 1681.5311 records/second. Loss is 0.32982662. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074327337594767345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 1729][Wall Clock 184.576640681s] Trained 128 records in 0.093509069 seconds. Throughput is 1368.8512 records/second. Loss is 0.2977662. Sequential31006cbd's hyper parameters: Current learning rate is 0.007431629013079666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41344/60000][Iteration 1730][Wall Clock 184.661832642s] Trained 128 records in 0.085191961 seconds. Throughput is 1502.4893 records/second. Loss is 0.25996357. Sequential31006cbd's hyper parameters: Current learning rate is 0.007430524595036409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 1731][Wall Clock 184.748222822s] Trained 128 records in 0.08639018 seconds. Throughput is 1481.6498 records/second. Loss is 0.33048213. Sequential31006cbd's hyper parameters: Current learning rate is 0.007429420505200594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41600/60000][Iteration 1732][Wall Clock 184.828384687s] Trained 128 records in 0.080161865 seconds. Throughput is 1596.7693 records/second. Loss is 0.47703427. Sequential31006cbd's hyper parameters: Current learning rate is 0.00742831674342594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 1733][Wall Clock 184.912320469s] Trained 128 records in 0.083935782 seconds. Throughput is 1524.9753 records/second. Loss is 0.31913912. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074272133095662505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41856/60000][Iteration 1734][Wall Clock 185.005330361s] Trained 128 records in 0.093009892 seconds. Throughput is 1376.1978 records/second. Loss is 0.2868885. Sequential31006cbd's hyper parameters: Current learning rate is 0.007426110203475419. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 1735][Wall Clock 185.088233668s] Trained 128 records in 0.082903307 seconds. Throughput is 1543.9673 records/second. Loss is 0.44324294. Sequential31006cbd's hyper parameters: Current learning rate is 0.007425007425007425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 42112/60000][Iteration 1736][Wall Clock 185.167605491s] Trained 128 records in 0.079371823 seconds. Throughput is 1612.663 records/second. Loss is 0.39530778. Sequential31006cbd's hyper parameters: Current learning rate is 0.007423904974016333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:42 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 1737][Wall Clock 185.25054954s] Trained 128 records in 0.082944049 seconds. Throughput is 1543.209 records/second. Loss is 0.44765645. Sequential31006cbd's hyper parameters: Current learning rate is 0.007422802850356295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 42368/60000][Iteration 1738][Wall Clock 185.336517377s] Trained 128 records in 0.085967837 seconds. Throughput is 1488.929 records/second. Loss is 0.2582852. Sequential31006cbd's hyper parameters: Current learning rate is 0.00742170105388155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 1739][Wall Clock 185.417501956s] Trained 128 records in 0.080984579 seconds. Throughput is 1580.5479 records/second. Loss is 0.43446347. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074205995844464235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 42624/60000][Iteration 1740][Wall Clock 185.494628762s] Trained 128 records in 0.077126806 seconds. Throughput is 1659.6045 records/second. Loss is 0.44182944. Sequential31006cbd's hyper parameters: Current learning rate is 0.007419498441905328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 1741][Wall Clock 185.604329219s] Trained 128 records in 0.109700457 seconds. Throughput is 1166.8137 records/second. Loss is 0.42167205. Sequential31006cbd's hyper parameters: Current learning rate is 0.007418397626112759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 42880/60000][Iteration 1742][Wall Clock 185.729857392s] Trained 128 records in 0.125528173 seconds. Throughput is 1019.6914 records/second. Loss is 0.41339937. Sequential31006cbd's hyper parameters: Current learning rate is 0.007417297136923305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 1743][Wall Clock 185.832325337s] Trained 128 records in 0.102467945 seconds. Throughput is 1249.1711 records/second. Loss is 0.3806828. Sequential31006cbd's hyper parameters: Current learning rate is 0.007416196974191634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 43136/60000][Iteration 1744][Wall Clock 185.937442985s] Trained 128 records in 0.105117648 seconds. Throughput is 1217.6832 records/second. Loss is 0.30348623. Sequential31006cbd's hyper parameters: Current learning rate is 0.007415097137772505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 1745][Wall Clock 186.037109276s] Trained 128 records in 0.099666291 seconds. Throughput is 1284.2858 records/second. Loss is 0.47826484. Sequential31006cbd's hyper parameters: Current learning rate is 0.00741399762752076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 43392/60000][Iteration 1746][Wall Clock 186.120078121s] Trained 128 records in 0.082968845 seconds. Throughput is 1542.7478 records/second. Loss is 0.38332546. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074128984432913275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 1747][Wall Clock 186.215072791s] Trained 128 records in 0.09499467 seconds. Throughput is 1347.444 records/second. Loss is 0.2900812. Sequential31006cbd's hyper parameters: Current learning rate is 0.007411799584939224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:43 INFO  DistriOptimizer$:408 - [Epoch 4 43648/60000][Iteration 1748][Wall Clock 186.309798902s] Trained 128 records in 0.094726111 seconds. Throughput is 1351.2642 records/second. Loss is 0.29178026. Sequential31006cbd's hyper parameters: Current learning rate is 0.0074107010523195484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 1749][Wall Clock 186.39318957s] Trained 128 records in 0.083390668 seconds. Throughput is 1534.944 records/second. Loss is 0.29804406. Sequential31006cbd's hyper parameters: Current learning rate is 0.007409602845287492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 43904/60000][Iteration 1750][Wall Clock 186.495924775s] Trained 128 records in 0.102735205 seconds. Throughput is 1245.9215 records/second. Loss is 0.35965315. Sequential31006cbd's hyper parameters: Current learning rate is 0.007408504963698325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 1751][Wall Clock 186.606113836s] Trained 128 records in 0.110189061 seconds. Throughput is 1161.6399 records/second. Loss is 0.25829932. Sequential31006cbd's hyper parameters: Current learning rate is 0.007407407407407407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44160/60000][Iteration 1752][Wall Clock 186.692251093s] Trained 128 records in 0.086137257 seconds. Throughput is 1486.0004 records/second. Loss is 0.3949817. Sequential31006cbd's hyper parameters: Current learning rate is 0.007406310176270182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 1753][Wall Clock 186.77409006s] Trained 128 records in 0.081838967 seconds. Throughput is 1564.0471 records/second. Loss is 0.387811. Sequential31006cbd's hyper parameters: Current learning rate is 0.00740521327014218. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44416/60000][Iteration 1754][Wall Clock 186.869361679s] Trained 128 records in 0.095271619 seconds. Throughput is 1343.5271 records/second. Loss is 0.35034946. Sequential31006cbd's hyper parameters: Current learning rate is 0.007404116688879017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 1755][Wall Clock 186.958865323s] Trained 128 records in 0.089503644 seconds. Throughput is 1430.1094 records/second. Loss is 0.28422722. Sequential31006cbd's hyper parameters: Current learning rate is 0.007403020432336393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44672/60000][Iteration 1756][Wall Clock 187.03932321s] Trained 128 records in 0.080457887 seconds. Throughput is 1590.8943 records/second. Loss is 0.47674063. Sequential31006cbd's hyper parameters: Current learning rate is 0.007401924500370097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 1757][Wall Clock 187.118260323s] Trained 128 records in 0.078937113 seconds. Throughput is 1621.544 records/second. Loss is 0.2988331. Sequential31006cbd's hyper parameters: Current learning rate is 0.007400828892835998. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:44 INFO  DistriOptimizer$:408 - [Epoch 4 44928/60000][Iteration 1758][Wall Clock 187.223602519s] Trained 128 records in 0.105342196 seconds. Throughput is 1215.0876 records/second. Loss is 0.36039466. Sequential31006cbd's hyper parameters: Current learning rate is 0.007399733609590055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 1759][Wall Clock 187.31734371s] Trained 128 records in 0.093741191 seconds. Throughput is 1365.4615 records/second. Loss is 0.3102969. Sequential31006cbd's hyper parameters: Current learning rate is 0.007398638650488311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45184/60000][Iteration 1760][Wall Clock 187.406817306s] Trained 128 records in 0.089473596 seconds. Throughput is 1430.5896 records/second. Loss is 0.53491044. Sequential31006cbd's hyper parameters: Current learning rate is 0.007397544015386892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 1761][Wall Clock 187.492952921s] Trained 128 records in 0.086135615 seconds. Throughput is 1486.0287 records/second. Loss is 0.39249673. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073964497041420114. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45440/60000][Iteration 1762][Wall Clock 187.584956794s] Trained 128 records in 0.092003873 seconds. Throughput is 1391.2457 records/second. Loss is 0.34329033. Sequential31006cbd's hyper parameters: Current learning rate is 0.007395355716609969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 1763][Wall Clock 187.674891861s] Trained 128 records in 0.089935067 seconds. Throughput is 1423.2491 records/second. Loss is 0.40189058. Sequential31006cbd's hyper parameters: Current learning rate is 0.007394262052647146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45696/60000][Iteration 1764][Wall Clock 187.758510223s] Trained 128 records in 0.083618362 seconds. Throughput is 1530.7642 records/second. Loss is 0.32402456. Sequential31006cbd's hyper parameters: Current learning rate is 0.00739316871211001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 1765][Wall Clock 187.846202445s] Trained 128 records in 0.087692222 seconds. Throughput is 1459.6505 records/second. Loss is 0.37543237. Sequential31006cbd's hyper parameters: Current learning rate is 0.007392075694855116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 45952/60000][Iteration 1766][Wall Clock 187.959861938s] Trained 128 records in 0.113659493 seconds. Throughput is 1126.1708 records/second. Loss is 0.39013365. Sequential31006cbd's hyper parameters: Current learning rate is 0.007390983000739098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 1767][Wall Clock 188.080098914s] Trained 128 records in 0.120236976 seconds. Throughput is 1064.5643 records/second. Loss is 0.45936212. Sequential31006cbd's hyper parameters: Current learning rate is 0.007389890629618682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:45 INFO  DistriOptimizer$:408 - [Epoch 4 46208/60000][Iteration 1768][Wall Clock 188.239122088s] Trained 128 records in 0.159023174 seconds. Throughput is 804.9141 records/second. Loss is 0.38157886. Sequential31006cbd's hyper parameters: Current learning rate is 0.007388798581350673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 1769][Wall Clock 188.35986669s] Trained 128 records in 0.120744602 seconds. Throughput is 1060.0889 records/second. Loss is 0.4617859. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073877068557919616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 46464/60000][Iteration 1770][Wall Clock 188.461823958s] Trained 128 records in 0.101957268 seconds. Throughput is 1255.4279 records/second. Loss is 0.31842902. Sequential31006cbd's hyper parameters: Current learning rate is 0.007386615452799527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 1771][Wall Clock 188.54294947s] Trained 128 records in 0.081125512 seconds. Throughput is 1577.802 records/second. Loss is 0.5296308. Sequential31006cbd's hyper parameters: Current learning rate is 0.007385524372230428. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 46720/60000][Iteration 1772][Wall Clock 188.62501945s] Trained 128 records in 0.08206998 seconds. Throughput is 1559.6447 records/second. Loss is 0.37435383. Sequential31006cbd's hyper parameters: Current learning rate is 0.007384433613941811. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 1773][Wall Clock 188.709986345s] Trained 128 records in 0.084966895 seconds. Throughput is 1506.469 records/second. Loss is 0.327057. Sequential31006cbd's hyper parameters: Current learning rate is 0.007383343177790903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 46976/60000][Iteration 1774][Wall Clock 188.793659606s] Trained 128 records in 0.083673261 seconds. Throughput is 1529.7599 records/second. Loss is 0.27833956. Sequential31006cbd's hyper parameters: Current learning rate is 0.007382253063635022. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 1775][Wall Clock 188.924711713s] Trained 128 records in 0.131052107 seconds. Throughput is 976.71075 records/second. Loss is 0.37506554. Sequential31006cbd's hyper parameters: Current learning rate is 0.007381163271331562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 47232/60000][Iteration 1776][Wall Clock 189.015582756s] Trained 128 records in 0.090871043 seconds. Throughput is 1408.5895 records/second. Loss is 0.32048917. Sequential31006cbd's hyper parameters: Current learning rate is 0.007380073800738008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 1777][Wall Clock 189.102758415s] Trained 128 records in 0.087175659 seconds. Throughput is 1468.2998 records/second. Loss is 0.3131246. Sequential31006cbd's hyper parameters: Current learning rate is 0.007378984651711925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 47488/60000][Iteration 1778][Wall Clock 189.18247007s] Trained 128 records in 0.079711655 seconds. Throughput is 1605.7878 records/second. Loss is 0.27641848. Sequential31006cbd's hyper parameters: Current learning rate is 0.007377895824110964. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:46 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 1779][Wall Clock 189.264605776s] Trained 128 records in 0.082135706 seconds. Throughput is 1558.3965 records/second. Loss is 0.3268324. Sequential31006cbd's hyper parameters: Current learning rate is 0.00737680731779286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 47744/60000][Iteration 1780][Wall Clock 189.347151969s] Trained 128 records in 0.082546193 seconds. Throughput is 1550.647 records/second. Loss is 0.49617088. Sequential31006cbd's hyper parameters: Current learning rate is 0.007375719132615431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 1781][Wall Clock 189.434666306s] Trained 128 records in 0.087514337 seconds. Throughput is 1462.6176 records/second. Loss is 0.342808. Sequential31006cbd's hyper parameters: Current learning rate is 0.007374631268436578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48000/60000][Iteration 1782][Wall Clock 189.523395913s] Trained 128 records in 0.088729607 seconds. Throughput is 1442.5851 records/second. Loss is 0.42595991. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073735437251142896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 1783][Wall Clock 189.610950439s] Trained 128 records in 0.087554526 seconds. Throughput is 1461.946 records/second. Loss is 0.3497821. Sequential31006cbd's hyper parameters: Current learning rate is 0.007372456502506635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48256/60000][Iteration 1784][Wall Clock 189.69754948s] Trained 128 records in 0.086599041 seconds. Throughput is 1478.0763 records/second. Loss is 0.36171526. Sequential31006cbd's hyper parameters: Current learning rate is 0.007371369600471768. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 1785][Wall Clock 189.779201549s] Trained 128 records in 0.081652069 seconds. Throughput is 1567.6272 records/second. Loss is 0.2425383. Sequential31006cbd's hyper parameters: Current learning rate is 0.007370283018867925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48512/60000][Iteration 1786][Wall Clock 189.879804309s] Trained 128 records in 0.10060276 seconds. Throughput is 1272.3309 records/second. Loss is 0.3878662. Sequential31006cbd's hyper parameters: Current learning rate is 0.007369196757553427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 1787][Wall Clock 189.995426293s] Trained 128 records in 0.115621984 seconds. Throughput is 1107.0559 records/second. Loss is 0.23872033. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073681108163866785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48768/60000][Iteration 1788][Wall Clock 190.103908911s] Trained 128 records in 0.108482618 seconds. Throughput is 1179.9125 records/second. Loss is 0.3096957. Sequential31006cbd's hyper parameters: Current learning rate is 0.007367025195226168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 1789][Wall Clock 190.199372381s] Trained 128 records in 0.09546347 seconds. Throughput is 1340.827 records/second. Loss is 0.26336968. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073659398939304645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:47 INFO  DistriOptimizer$:408 - [Epoch 4 49024/60000][Iteration 1790][Wall Clock 190.285833371s] Trained 128 records in 0.08646099 seconds. Throughput is 1480.4364 records/second. Loss is 0.31774095. Sequential31006cbd's hyper parameters: Current learning rate is 0.007364854912358226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 1791][Wall Clock 190.377706542s] Trained 128 records in 0.091873171 seconds. Throughput is 1393.2251 records/second. Loss is 0.4683009. Sequential31006cbd's hyper parameters: Current learning rate is 0.007363770250368188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49280/60000][Iteration 1792][Wall Clock 190.48659625s] Trained 128 records in 0.108889708 seconds. Throughput is 1175.5013 records/second. Loss is 0.4050541. Sequential31006cbd's hyper parameters: Current learning rate is 0.007362685907819172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 1793][Wall Clock 190.626343098s] Trained 128 records in 0.139746848 seconds. Throughput is 915.94196 records/second. Loss is 0.26857376. Sequential31006cbd's hyper parameters: Current learning rate is 0.007361601884570083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49536/60000][Iteration 1794][Wall Clock 190.754065864s] Trained 128 records in 0.127722766 seconds. Throughput is 1002.17053 records/second. Loss is 0.40586847. Sequential31006cbd's hyper parameters: Current learning rate is 0.007360518180479906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 1795][Wall Clock 190.843192928s] Trained 128 records in 0.089127064 seconds. Throughput is 1436.1519 records/second. Loss is 0.38077635. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073594347954077126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49792/60000][Iteration 1796][Wall Clock 190.95147632s] Trained 128 records in 0.108283392 seconds. Throughput is 1182.0834 records/second. Loss is 0.3258156. Sequential31006cbd's hyper parameters: Current learning rate is 0.007358351729212656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 1797][Wall Clock 191.035134509s] Trained 128 records in 0.083658189 seconds. Throughput is 1530.0355 records/second. Loss is 0.2981711. Sequential31006cbd's hyper parameters: Current learning rate is 0.007357268981753973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 50048/60000][Iteration 1798][Wall Clock 191.122754269s] Trained 128 records in 0.08761976 seconds. Throughput is 1460.8577 records/second. Loss is 0.33939058. Sequential31006cbd's hyper parameters: Current learning rate is 0.007356186552890982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:48 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 1799][Wall Clock 191.206215381s] Trained 128 records in 0.083461112 seconds. Throughput is 1533.6483 records/second. Loss is 0.25367367. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073551044424830835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 50304/60000][Iteration 1800][Wall Clock 191.300864718s] Trained 128 records in 0.094649337 seconds. Throughput is 1352.3602 records/second. Loss is 0.3175224. Sequential31006cbd's hyper parameters: Current learning rate is 0.007354022650389764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 1801][Wall Clock 191.447867589s] Trained 128 records in 0.147002871 seconds. Throughput is 870.73126 records/second. Loss is 0.42315748. Sequential31006cbd's hyper parameters: Current learning rate is 0.007352941176470588. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 50560/60000][Iteration 1802][Wall Clock 191.558566494s] Trained 128 records in 0.110698905 seconds. Throughput is 1156.2897 records/second. Loss is 0.26799315. Sequential31006cbd's hyper parameters: Current learning rate is 0.007351860020585208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 1803][Wall Clock 191.649099087s] Trained 128 records in 0.090532593 seconds. Throughput is 1413.8555 records/second. Loss is 0.27876523. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073507791825933545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 50816/60000][Iteration 1804][Wall Clock 191.740189668s] Trained 128 records in 0.091090581 seconds. Throughput is 1405.1947 records/second. Loss is 0.24487095. Sequential31006cbd's hyper parameters: Current learning rate is 0.007349698662354844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 1805][Wall Clock 191.821971085s] Trained 128 records in 0.081781417 seconds. Throughput is 1565.1477 records/second. Loss is 0.31993634. Sequential31006cbd's hyper parameters: Current learning rate is 0.007348618459729571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 51072/60000][Iteration 1806][Wall Clock 191.912491743s] Trained 128 records in 0.090520658 seconds. Throughput is 1414.0419 records/second. Loss is 0.4969139. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073475385745775165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 1807][Wall Clock 191.997597953s] Trained 128 records in 0.08510621 seconds. Throughput is 1504.003 records/second. Loss is 0.42571795. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073464590067587425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 51328/60000][Iteration 1808][Wall Clock 192.096827002s] Trained 128 records in 0.099229049 seconds. Throughput is 1289.9448 records/second. Loss is 0.32538566. Sequential31006cbd's hyper parameters: Current learning rate is 0.007345379756133393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 1809][Wall Clock 192.179296903s] Trained 128 records in 0.082469901 seconds. Throughput is 1552.0814 records/second. Loss is 0.2761735. Sequential31006cbd's hyper parameters: Current learning rate is 0.007344300822561691. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:49 INFO  DistriOptimizer$:408 - [Epoch 4 51584/60000][Iteration 1810][Wall Clock 192.265703438s] Trained 128 records in 0.086406535 seconds. Throughput is 1481.3694 records/second. Loss is 0.36735952. Sequential31006cbd's hyper parameters: Current learning rate is 0.00734322220590395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 1811][Wall Clock 192.347133138s] Trained 128 records in 0.0814297 seconds. Throughput is 1571.9081 records/second. Loss is 0.34827453. Sequential31006cbd's hyper parameters: Current learning rate is 0.007342143906020558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 51840/60000][Iteration 1812][Wall Clock 192.435621685s] Trained 128 records in 0.088488547 seconds. Throughput is 1446.5149 records/second. Loss is 0.3334612. Sequential31006cbd's hyper parameters: Current learning rate is 0.007341065922771986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 1813][Wall Clock 192.521394489s] Trained 128 records in 0.085772804 seconds. Throughput is 1492.3145 records/second. Loss is 0.29625976. Sequential31006cbd's hyper parameters: Current learning rate is 0.00733998825601879. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52096/60000][Iteration 1814][Wall Clock 192.60785636s] Trained 128 records in 0.086461871 seconds. Throughput is 1480.4214 records/second. Loss is 0.26160905. Sequential31006cbd's hyper parameters: Current learning rate is 0.007338910905621606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 1815][Wall Clock 192.684678013s] Trained 128 records in 0.076821653 seconds. Throughput is 1666.1969 records/second. Loss is 0.35057634. Sequential31006cbd's hyper parameters: Current learning rate is 0.00733783387144115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52352/60000][Iteration 1816][Wall Clock 192.768905168s] Trained 128 records in 0.084227155 seconds. Throughput is 1519.7 records/second. Loss is 0.33490038. Sequential31006cbd's hyper parameters: Current learning rate is 0.007336757153338225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 1817][Wall Clock 192.853593479s] Trained 128 records in 0.084688311 seconds. Throughput is 1511.4246 records/second. Loss is 0.25708285. Sequential31006cbd's hyper parameters: Current learning rate is 0.007335680751173709. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52608/60000][Iteration 1818][Wall Clock 192.946622475s] Trained 128 records in 0.093028996 seconds. Throughput is 1375.9152 records/second. Loss is 0.2958172. Sequential31006cbd's hyper parameters: Current learning rate is 0.007334604664808567. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 1819][Wall Clock 193.048090149s] Trained 128 records in 0.101467674 seconds. Throughput is 1261.4855 records/second. Loss is 0.24357468. Sequential31006cbd's hyper parameters: Current learning rate is 0.007333528894103844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52864/60000][Iteration 1820][Wall Clock 193.142443742s] Trained 128 records in 0.094353593 seconds. Throughput is 1356.5991 records/second. Loss is 0.32493475. Sequential31006cbd's hyper parameters: Current learning rate is 0.007332453438920664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:50 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 1821][Wall Clock 193.229150716s] Trained 128 records in 0.086706974 seconds. Throughput is 1476.2365 records/second. Loss is 0.36264008. Sequential31006cbd's hyper parameters: Current learning rate is 0.007331378299120235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53120/60000][Iteration 1822][Wall Clock 193.334127997s] Trained 128 records in 0.104977281 seconds. Throughput is 1219.3114 records/second. Loss is 0.38332778. Sequential31006cbd's hyper parameters: Current learning rate is 0.007330303474563846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 1823][Wall Clock 193.434524471s] Trained 128 records in 0.100396474 seconds. Throughput is 1274.9452 records/second. Loss is 0.37891185. Sequential31006cbd's hyper parameters: Current learning rate is 0.00732922896511287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53376/60000][Iteration 1824][Wall Clock 193.519037241s] Trained 128 records in 0.08451277 seconds. Throughput is 1514.564 records/second. Loss is 0.36203498. Sequential31006cbd's hyper parameters: Current learning rate is 0.007328154770628756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 1825][Wall Clock 193.601734886s] Trained 128 records in 0.082697645 seconds. Throughput is 1547.8071 records/second. Loss is 0.31009722. Sequential31006cbd's hyper parameters: Current learning rate is 0.007327080890973036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53632/60000][Iteration 1826][Wall Clock 193.708664821s] Trained 128 records in 0.106929935 seconds. Throughput is 1197.0455 records/second. Loss is 0.25953606. Sequential31006cbd's hyper parameters: Current learning rate is 0.007326007326007326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 1827][Wall Clock 193.879635785s] Trained 128 records in 0.170970964 seconds. Throughput is 748.66516 records/second. Loss is 0.4173493. Sequential31006cbd's hyper parameters: Current learning rate is 0.00732493407559332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 53888/60000][Iteration 1828][Wall Clock 194.002032154s] Trained 128 records in 0.122396369 seconds. Throughput is 1045.7826 records/second. Loss is 0.30840975. Sequential31006cbd's hyper parameters: Current learning rate is 0.007323861139592794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 1829][Wall Clock 194.096558791s] Trained 128 records in 0.094526637 seconds. Throughput is 1354.1157 records/second. Loss is 0.3339164. Sequential31006cbd's hyper parameters: Current learning rate is 0.007322788517867603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 54144/60000][Iteration 1830][Wall Clock 194.178960525s] Trained 128 records in 0.082401734 seconds. Throughput is 1553.3654 records/second. Loss is 0.3216483. Sequential31006cbd's hyper parameters: Current learning rate is 0.007321716210279689. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:51 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 1831][Wall Clock 194.255484387s] Trained 128 records in 0.076523862 seconds. Throughput is 1672.6809 records/second. Loss is 0.37882334. Sequential31006cbd's hyper parameters: Current learning rate is 0.007320644216691068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 54400/60000][Iteration 1832][Wall Clock 194.335946609s] Trained 128 records in 0.080462222 seconds. Throughput is 1590.8086 records/second. Loss is 0.50170106. Sequential31006cbd's hyper parameters: Current learning rate is 0.007319572536963841. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 1833][Wall Clock 194.421046508s] Trained 128 records in 0.085099899 seconds. Throughput is 1504.1146 records/second. Loss is 0.3261856. Sequential31006cbd's hyper parameters: Current learning rate is 0.007318501170960187. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 54656/60000][Iteration 1834][Wall Clock 194.503228467s] Trained 128 records in 0.082181959 seconds. Throughput is 1557.5194 records/second. Loss is 0.3051159. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073174301185423675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 1835][Wall Clock 194.590207728s] Trained 128 records in 0.086979261 seconds. Throughput is 1471.6151 records/second. Loss is 0.37529987. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073163593795727245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 54912/60000][Iteration 1836][Wall Clock 194.6789139s] Trained 128 records in 0.088706172 seconds. Throughput is 1442.9661 records/second. Loss is 0.30675155. Sequential31006cbd's hyper parameters: Current learning rate is 0.0073152889539136795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 1837][Wall Clock 194.770493965s] Trained 128 records in 0.091580065 seconds. Throughput is 1397.6841 records/second. Loss is 0.29725105. Sequential31006cbd's hyper parameters: Current learning rate is 0.007314218841427736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 55168/60000][Iteration 1838][Wall Clock 194.857361471s] Trained 128 records in 0.086867506 seconds. Throughput is 1473.5084 records/second. Loss is 0.3229518. Sequential31006cbd's hyper parameters: Current learning rate is 0.007313149041977476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 1839][Wall Clock 194.944160722s] Trained 128 records in 0.086799251 seconds. Throughput is 1474.6671 records/second. Loss is 0.3533342. Sequential31006cbd's hyper parameters: Current learning rate is 0.007312079555425563. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 55424/60000][Iteration 1840][Wall Clock 195.029289223s] Trained 128 records in 0.085128501 seconds. Throughput is 1503.6093 records/second. Loss is 0.3077265. Sequential31006cbd's hyper parameters: Current learning rate is 0.007311010381634743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 1841][Wall Clock 195.113683152s] Trained 128 records in 0.084393929 seconds. Throughput is 1516.6968 records/second. Loss is 0.39950132. Sequential31006cbd's hyper parameters: Current learning rate is 0.007309941520467837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:52 INFO  DistriOptimizer$:408 - [Epoch 4 55680/60000][Iteration 1842][Wall Clock 195.206660503s] Trained 128 records in 0.092977351 seconds. Throughput is 1376.6793 records/second. Loss is 0.33488214. Sequential31006cbd's hyper parameters: Current learning rate is 0.00730887297178775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 1843][Wall Clock 195.310787829s] Trained 128 records in 0.104127326 seconds. Throughput is 1229.2643 records/second. Loss is 0.283617. Sequential31006cbd's hyper parameters: Current learning rate is 0.007307804735457469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 55936/60000][Iteration 1844][Wall Clock 195.423227387s] Trained 128 records in 0.112439558 seconds. Throughput is 1138.3894 records/second. Loss is 0.3256703. Sequential31006cbd's hyper parameters: Current learning rate is 0.007306736811340055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 1845][Wall Clock 195.558464601s] Trained 128 records in 0.135237214 seconds. Throughput is 946.48505 records/second. Loss is 0.44781056. Sequential31006cbd's hyper parameters: Current learning rate is 0.007305669199298656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56192/60000][Iteration 1846][Wall Clock 195.646580592s] Trained 128 records in 0.088115991 seconds. Throughput is 1452.6307 records/second. Loss is 0.4692034. Sequential31006cbd's hyper parameters: Current learning rate is 0.007304601899196494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 1847][Wall Clock 195.739031625s] Trained 128 records in 0.092451033 seconds. Throughput is 1384.5167 records/second. Loss is 0.36945516. Sequential31006cbd's hyper parameters: Current learning rate is 0.007303534910896874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56448/60000][Iteration 1848][Wall Clock 195.838101509s] Trained 128 records in 0.099069884 seconds. Throughput is 1292.0172 records/second. Loss is 0.320321. Sequential31006cbd's hyper parameters: Current learning rate is 0.007302468234263181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 1849][Wall Clock 195.921224894s] Trained 128 records in 0.083123385 seconds. Throughput is 1539.8795 records/second. Loss is 0.35641408. Sequential31006cbd's hyper parameters: Current learning rate is 0.007301401869158878. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56704/60000][Iteration 1850][Wall Clock 196.004970685s] Trained 128 records in 0.083745791 seconds. Throughput is 1528.4349 records/second. Loss is 0.3238598. Sequential31006cbd's hyper parameters: Current learning rate is 0.00730033581544751. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 1851][Wall Clock 196.095577869s] Trained 128 records in 0.090607184 seconds. Throughput is 1412.6915 records/second. Loss is 0.33817065. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072992700729927005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:53 INFO  DistriOptimizer$:408 - [Epoch 4 56960/60000][Iteration 1852][Wall Clock 196.202520758s] Trained 128 records in 0.106942889 seconds. Throughput is 1196.9005 records/second. Loss is 0.47931403. Sequential31006cbd's hyper parameters: Current learning rate is 0.007298204641658152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 1853][Wall Clock 196.292162262s] Trained 128 records in 0.089641504 seconds. Throughput is 1427.91 records/second. Loss is 0.31228256. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072971395213076475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57216/60000][Iteration 1854][Wall Clock 196.376277024s] Trained 128 records in 0.084114762 seconds. Throughput is 1521.7306 records/second. Loss is 0.40028456. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072960747118050485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 1855][Wall Clock 196.460768099s] Trained 128 records in 0.084491075 seconds. Throughput is 1514.9529 records/second. Loss is 0.34579003. Sequential31006cbd's hyper parameters: Current learning rate is 0.007295010213014298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57472/60000][Iteration 1856][Wall Clock 196.545951905s] Trained 128 records in 0.085183806 seconds. Throughput is 1502.633 records/second. Loss is 0.412624. Sequential31006cbd's hyper parameters: Current learning rate is 0.007293946024799417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 1857][Wall Clock 196.631842974s] Trained 128 records in 0.085891069 seconds. Throughput is 1490.2598 records/second. Loss is 0.34392706. Sequential31006cbd's hyper parameters: Current learning rate is 0.007292882147024504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57728/60000][Iteration 1858][Wall Clock 196.713378827s] Trained 128 records in 0.081535853 seconds. Throughput is 1569.8616 records/second. Loss is 0.30703095. Sequential31006cbd's hyper parameters: Current learning rate is 0.007291818579553741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 1859][Wall Clock 196.793013948s] Trained 128 records in 0.079635121 seconds. Throughput is 1607.331 records/second. Loss is 0.32102033. Sequential31006cbd's hyper parameters: Current learning rate is 0.007290755322251386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 57984/60000][Iteration 1860][Wall Clock 196.873103468s] Trained 128 records in 0.08008952 seconds. Throughput is 1598.2117 records/second. Loss is 0.33864713. Sequential31006cbd's hyper parameters: Current learning rate is 0.007289692374981776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 1861][Wall Clock 196.964752901s] Trained 128 records in 0.091649433 seconds. Throughput is 1396.6262 records/second. Loss is 0.3745847. Sequential31006cbd's hyper parameters: Current learning rate is 0.00728862973760933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 58240/60000][Iteration 1862][Wall Clock 197.051230273s] Trained 128 records in 0.086477372 seconds. Throughput is 1480.156 records/second. Loss is 0.31061667. Sequential31006cbd's hyper parameters: Current learning rate is 0.007287567409998542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 1863][Wall Clock 197.139920038s] Trained 128 records in 0.088689765 seconds. Throughput is 1443.233 records/second. Loss is 0.3900845. Sequential31006cbd's hyper parameters: Current learning rate is 0.00728650539201399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:54 INFO  DistriOptimizer$:408 - [Epoch 4 58496/60000][Iteration 1864][Wall Clock 197.249983171s] Trained 128 records in 0.110063133 seconds. Throughput is 1162.9689 records/second. Loss is 0.43855473. Sequential31006cbd's hyper parameters: Current learning rate is 0.007285443683520326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 1865][Wall Clock 197.334816971s] Trained 128 records in 0.0848338 seconds. Throughput is 1508.8325 records/second. Loss is 0.33852363. Sequential31006cbd's hyper parameters: Current learning rate is 0.007284382284382284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 58752/60000][Iteration 1866][Wall Clock 197.437653207s] Trained 128 records in 0.102836236 seconds. Throughput is 1244.6974 records/second. Loss is 0.45964265. Sequential31006cbd's hyper parameters: Current learning rate is 0.007283321194464676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 1867][Wall Clock 197.522980305s] Trained 128 records in 0.085327098 seconds. Throughput is 1500.1096 records/second. Loss is 0.3505354. Sequential31006cbd's hyper parameters: Current learning rate is 0.007282260413632392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59008/60000][Iteration 1868][Wall Clock 197.620340237s] Trained 128 records in 0.097359932 seconds. Throughput is 1314.7092 records/second. Loss is 0.291068. Sequential31006cbd's hyper parameters: Current learning rate is 0.007281199941750401. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 1869][Wall Clock 197.729898908s] Trained 128 records in 0.109558671 seconds. Throughput is 1168.3237 records/second. Loss is 0.37027338. Sequential31006cbd's hyper parameters: Current learning rate is 0.00728013977868375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59264/60000][Iteration 1870][Wall Clock 197.827974473s] Trained 128 records in 0.098075565 seconds. Throughput is 1305.1161 records/second. Loss is 0.36596686. Sequential31006cbd's hyper parameters: Current learning rate is 0.007279079924297568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 1871][Wall Clock 197.967292461s] Trained 128 records in 0.139317988 seconds. Throughput is 918.7615 records/second. Loss is 0.34526226. Sequential31006cbd's hyper parameters: Current learning rate is 0.00727802037845706. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59520/60000][Iteration 1872][Wall Clock 198.05909566s] Trained 128 records in 0.091803199 seconds. Throughput is 1394.2869 records/second. Loss is 0.33547568. Sequential31006cbd's hyper parameters: Current learning rate is 0.007276961141027507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 1873][Wall Clock 198.141268764s] Trained 128 records in 0.082173104 seconds. Throughput is 1557.6874 records/second. Loss is 0.346527. Sequential31006cbd's hyper parameters: Current learning rate is 0.007275902211874272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:55 INFO  DistriOptimizer$:408 - [Epoch 4 59776/60000][Iteration 1874][Wall Clock 198.230783473s] Trained 128 records in 0.089514709 seconds. Throughput is 1429.9326 records/second. Loss is 0.50011986. Sequential31006cbd's hyper parameters: Current learning rate is 0.007274843590862797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:56 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 1875][Wall Clock 198.313427243s] Trained 128 records in 0.08264377 seconds. Throughput is 1548.816 records/second. Loss is 0.26445463. Sequential31006cbd's hyper parameters: Current learning rate is 0.007273785277858598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:56 INFO  DistriOptimizer$:408 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 198.40725457s] Trained 128 records in 0.093827327 seconds. Throughput is 1364.208 records/second. Loss is 0.35107288. Sequential31006cbd's hyper parameters: Current learning rate is 0.007272727272727273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:56 INFO  DistriOptimizer$:452 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 198.40725457s] Epoch finished. Wall clock time is 199672.492417 ms
2019-10-24 00:00:56 INFO  DistriOptimizer$:111 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 198.40725457s] Validate model...
2019-10-24 00:00:57 INFO  DistriOptimizer$:178 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 198.40725457s] validate model throughput is 11756.067 records/second
2019-10-24 00:00:57 INFO  DistriOptimizer$:181 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 198.40725457s] Top1Accuracy is Accuracy(correct: 9167, count: 10000, accuracy: 0.9167)
2019-10-24 00:00:57 INFO  DistriOptimizer$:221 - [Wall Clock 199.672492417s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:00:57 INFO  DistriOptimizer$:226 - [Wall Clock 199.672492417s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 128/60000][Iteration 1877][Wall Clock 199.777290885s] Trained 128 records in 0.104798468 seconds. Throughput is 1221.392 records/second. Loss is 0.34641746. Sequential31006cbd's hyper parameters: Current learning rate is 0.007271669575334497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 1878][Wall Clock 199.86968854s] Trained 128 records in 0.092397655 seconds. Throughput is 1385.3165 records/second. Loss is 0.2072897. Sequential31006cbd's hyper parameters: Current learning rate is 0.007270612185546023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 384/60000][Iteration 1879][Wall Clock 199.964465595s] Trained 128 records in 0.094777055 seconds. Throughput is 1350.5378 records/second. Loss is 0.26828018. Sequential31006cbd's hyper parameters: Current learning rate is 0.007269555103227683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 1880][Wall Clock 200.053886586s] Trained 128 records in 0.089420991 seconds. Throughput is 1431.4313 records/second. Loss is 0.23837547. Sequential31006cbd's hyper parameters: Current learning rate is 0.007268498328245385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 640/60000][Iteration 1881][Wall Clock 200.140800911s] Trained 128 records in 0.086914325 seconds. Throughput is 1472.7147 records/second. Loss is 0.33687922. Sequential31006cbd's hyper parameters: Current learning rate is 0.007267441860465117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 1882][Wall Clock 200.231799065s] Trained 128 records in 0.090998154 seconds. Throughput is 1406.622 records/second. Loss is 0.29921544. Sequential31006cbd's hyper parameters: Current learning rate is 0.007266385699752942. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 896/60000][Iteration 1883][Wall Clock 200.321988506s] Trained 128 records in 0.090189441 seconds. Throughput is 1419.2349 records/second. Loss is 0.43614858. Sequential31006cbd's hyper parameters: Current learning rate is 0.007265329845975007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 1884][Wall Clock 200.413078593s] Trained 128 records in 0.091090087 seconds. Throughput is 1405.2023 records/second. Loss is 0.37402377. Sequential31006cbd's hyper parameters: Current learning rate is 0.00726427429899753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:57 INFO  DistriOptimizer$:408 - [Epoch 5 1152/60000][Iteration 1885][Wall Clock 200.490851852s] Trained 128 records in 0.077773259 seconds. Throughput is 1645.8099 records/second. Loss is 0.34093407. Sequential31006cbd's hyper parameters: Current learning rate is 0.00726321905868681. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 1886][Wall Clock 200.580812134s] Trained 128 records in 0.089960282 seconds. Throughput is 1422.8501 records/second. Loss is 0.25915083. Sequential31006cbd's hyper parameters: Current learning rate is 0.007262164124909223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 1408/60000][Iteration 1887][Wall Clock 200.667932927s] Trained 128 records in 0.087120793 seconds. Throughput is 1469.2245 records/second. Loss is 0.32154354. Sequential31006cbd's hyper parameters: Current learning rate is 0.007261109497531223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 1888][Wall Clock 200.748650652s] Trained 128 records in 0.080717725 seconds. Throughput is 1585.7731 records/second. Loss is 0.31903976. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072600551764193414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 1664/60000][Iteration 1889][Wall Clock 200.82931386s] Trained 128 records in 0.080663208 seconds. Throughput is 1586.8448 records/second. Loss is 0.24846072. Sequential31006cbd's hyper parameters: Current learning rate is 0.007259001161440186. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 1890][Wall Clock 200.919557173s] Trained 128 records in 0.090243313 seconds. Throughput is 1418.3877 records/second. Loss is 0.34634307. Sequential31006cbd's hyper parameters: Current learning rate is 0.007257947452460444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 1920/60000][Iteration 1891][Wall Clock 201.039696696s] Trained 128 records in 0.120139523 seconds. Throughput is 1065.4279 records/second. Loss is 0.37012815. Sequential31006cbd's hyper parameters: Current learning rate is 0.007256894049346879. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 1892][Wall Clock 201.164345383s] Trained 128 records in 0.124648687 seconds. Throughput is 1026.886 records/second. Loss is 0.44483343. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072558409519663325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 2176/60000][Iteration 1893][Wall Clock 201.267041797s] Trained 128 records in 0.102696414 seconds. Throughput is 1246.3921 records/second. Loss is 0.3693732. Sequential31006cbd's hyper parameters: Current learning rate is 0.007254788160185722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 1894][Wall Clock 201.363303256s] Trained 128 records in 0.096261459 seconds. Throughput is 1329.7119 records/second. Loss is 0.32250217. Sequential31006cbd's hyper parameters: Current learning rate is 0.007253735673872044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:58 INFO  DistriOptimizer$:408 - [Epoch 5 2432/60000][Iteration 1895][Wall Clock 201.453845861s] Trained 128 records in 0.090542605 seconds. Throughput is 1413.6991 records/second. Loss is 0.2941974. Sequential31006cbd's hyper parameters: Current learning rate is 0.00725268349289237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 1896][Wall Clock 201.554540269s] Trained 128 records in 0.100694408 seconds. Throughput is 1271.1729 records/second. Loss is 0.28195006. Sequential31006cbd's hyper parameters: Current learning rate is 0.007251631617113851. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 2688/60000][Iteration 1897][Wall Clock 201.661428628s] Trained 128 records in 0.106888359 seconds. Throughput is 1197.5111 records/second. Loss is 0.26594472. Sequential31006cbd's hyper parameters: Current learning rate is 0.007250580046403713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 1898][Wall Clock 201.760029889s] Trained 128 records in 0.098601261 seconds. Throughput is 1298.1578 records/second. Loss is 0.2697421. Sequential31006cbd's hyper parameters: Current learning rate is 0.00724952878062926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 2944/60000][Iteration 1899][Wall Clock 201.863124837s] Trained 128 records in 0.103094948 seconds. Throughput is 1241.5739 records/second. Loss is 0.29980776. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072484778196578725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 1900][Wall Clock 201.968594883s] Trained 128 records in 0.105470046 seconds. Throughput is 1213.6147 records/second. Loss is 0.34702045. Sequential31006cbd's hyper parameters: Current learning rate is 0.007247427163357009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 3200/60000][Iteration 1901][Wall Clock 202.090494653s] Trained 128 records in 0.12189977 seconds. Throughput is 1050.043 records/second. Loss is 0.34245008. Sequential31006cbd's hyper parameters: Current learning rate is 0.007246376811594204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 1902][Wall Clock 202.191934269s] Trained 128 records in 0.101439616 seconds. Throughput is 1261.8344 records/second. Loss is 0.3373373. Sequential31006cbd's hyper parameters: Current learning rate is 0.007245326764237067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 3456/60000][Iteration 1903][Wall Clock 202.282687764s] Trained 128 records in 0.090753495 seconds. Throughput is 1410.414 records/second. Loss is 0.27622896. Sequential31006cbd's hyper parameters: Current learning rate is 0.007244277021153289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 1904][Wall Clock 202.388539308s] Trained 128 records in 0.105851544 seconds. Throughput is 1209.2407 records/second. Loss is 0.3250181. Sequential31006cbd's hyper parameters: Current learning rate is 0.007243227582210633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:00:59 INFO  DistriOptimizer$:408 - [Epoch 5 3712/60000][Iteration 1905][Wall Clock 202.469732337s] Trained 128 records in 0.081193029 seconds. Throughput is 1576.49 records/second. Loss is 0.31503347. Sequential31006cbd's hyper parameters: Current learning rate is 0.007242178447276941. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 1906][Wall Clock 202.54872772s] Trained 128 records in 0.078995383 seconds. Throughput is 1620.3478 records/second. Loss is 0.33961943. Sequential31006cbd's hyper parameters: Current learning rate is 0.00724112961622013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 3968/60000][Iteration 1907][Wall Clock 202.631903661s] Trained 128 records in 0.083175941 seconds. Throughput is 1538.9065 records/second. Loss is 0.31091055. Sequential31006cbd's hyper parameters: Current learning rate is 0.007240081088908196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 1908][Wall Clock 202.713376049s] Trained 128 records in 0.081472388 seconds. Throughput is 1571.0844 records/second. Loss is 0.4772872. Sequential31006cbd's hyper parameters: Current learning rate is 0.007239032865209208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4224/60000][Iteration 1909][Wall Clock 202.794967251s] Trained 128 records in 0.081591202 seconds. Throughput is 1568.7965 records/second. Loss is 0.36363307. Sequential31006cbd's hyper parameters: Current learning rate is 0.007237984944991315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 1910][Wall Clock 202.877825259s] Trained 128 records in 0.082858008 seconds. Throughput is 1544.8114 records/second. Loss is 0.29439393. Sequential31006cbd's hyper parameters: Current learning rate is 0.007236937328122738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4480/60000][Iteration 1911][Wall Clock 202.962837391s] Trained 128 records in 0.085012132 seconds. Throughput is 1505.6675 records/second. Loss is 0.35767186. Sequential31006cbd's hyper parameters: Current learning rate is 0.00723589001447178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 1912][Wall Clock 203.056159093s] Trained 128 records in 0.093321702 seconds. Throughput is 1371.5995 records/second. Loss is 0.35108814. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072348430039068145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4736/60000][Iteration 1913][Wall Clock 203.149787611s] Trained 128 records in 0.093628518 seconds. Throughput is 1367.1049 records/second. Loss is 0.27361128. Sequential31006cbd's hyper parameters: Current learning rate is 0.007233796296296296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 1914][Wall Clock 203.231302096s] Trained 128 records in 0.081514485 seconds. Throughput is 1570.2731 records/second. Loss is 0.3662912. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072327498915087515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 4992/60000][Iteration 1915][Wall Clock 203.32057146s] Trained 128 records in 0.089269364 seconds. Throughput is 1433.8625 records/second. Loss is 0.40404126. Sequential31006cbd's hyper parameters: Current learning rate is 0.007231703789412786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:00 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 1916][Wall Clock 203.443254024s] Trained 128 records in 0.122682564 seconds. Throughput is 1043.343 records/second. Loss is 0.287552. Sequential31006cbd's hyper parameters: Current learning rate is 0.007230657989877079. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 5248/60000][Iteration 1917][Wall Clock 203.535636647s] Trained 128 records in 0.092382623 seconds. Throughput is 1385.5419 records/second. Loss is 0.19801623. Sequential31006cbd's hyper parameters: Current learning rate is 0.007229612492770388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 1918][Wall Clock 203.672055376s] Trained 128 records in 0.136418729 seconds. Throughput is 938.2876 records/second. Loss is 0.34963343. Sequential31006cbd's hyper parameters: Current learning rate is 0.007228567297961544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 5504/60000][Iteration 1919][Wall Clock 203.773826147s] Trained 128 records in 0.101770771 seconds. Throughput is 1257.7285 records/second. Loss is 0.34653148. Sequential31006cbd's hyper parameters: Current learning rate is 0.007227522405319457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 1920][Wall Clock 203.874970572s] Trained 128 records in 0.101144425 seconds. Throughput is 1265.5171 records/second. Loss is 0.2533119. Sequential31006cbd's hyper parameters: Current learning rate is 0.00722647781471311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 5760/60000][Iteration 1921][Wall Clock 203.977531114s] Trained 128 records in 0.102560542 seconds. Throughput is 1248.0433 records/second. Loss is 0.32514632. Sequential31006cbd's hyper parameters: Current learning rate is 0.007225433526011561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 1922][Wall Clock 204.096956135s] Trained 128 records in 0.119425021 seconds. Throughput is 1071.8022 records/second. Loss is 0.39021355. Sequential31006cbd's hyper parameters: Current learning rate is 0.007224389539083947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 6016/60000][Iteration 1923][Wall Clock 204.21732019s] Trained 128 records in 0.120364055 seconds. Throughput is 1063.4404 records/second. Loss is 0.34214365. Sequential31006cbd's hyper parameters: Current learning rate is 0.00722334585379948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 1924][Wall Clock 204.328336049s] Trained 128 records in 0.111015859 seconds. Throughput is 1152.9884 records/second. Loss is 0.3381318. Sequential31006cbd's hyper parameters: Current learning rate is 0.007222302470027445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 6272/60000][Iteration 1925][Wall Clock 204.423000259s] Trained 128 records in 0.09466421 seconds. Throughput is 1352.1478 records/second. Loss is 0.35993028. Sequential31006cbd's hyper parameters: Current learning rate is 0.007221259387637204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:01 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 1926][Wall Clock 204.514605388s] Trained 128 records in 0.091605129 seconds. Throughput is 1397.3018 records/second. Loss is 0.23271206. Sequential31006cbd's hyper parameters: Current learning rate is 0.007220216606498195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 6528/60000][Iteration 1927][Wall Clock 204.618627001s] Trained 128 records in 0.104021613 seconds. Throughput is 1230.5134 records/second. Loss is 0.38240406. Sequential31006cbd's hyper parameters: Current learning rate is 0.007219174126479931. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 1928][Wall Clock 204.715851016s] Trained 128 records in 0.097224015 seconds. Throughput is 1316.5472 records/second. Loss is 0.3712248. Sequential31006cbd's hyper parameters: Current learning rate is 0.007218131947452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 6784/60000][Iteration 1929][Wall Clock 204.792931539s] Trained 128 records in 0.077080523 seconds. Throughput is 1660.6011 records/second. Loss is 0.3456641. Sequential31006cbd's hyper parameters: Current learning rate is 0.007217090069284065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 1930][Wall Clock 204.870995027s] Trained 128 records in 0.078063488 seconds. Throughput is 1639.691 records/second. Loss is 0.30159223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072160484918458645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 7040/60000][Iteration 1931][Wall Clock 204.958801337s] Trained 128 records in 0.08780631 seconds. Throughput is 1457.754 records/second. Loss is 0.45375916. Sequential31006cbd's hyper parameters: Current learning rate is 0.007215007215007214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 1932][Wall Clock 205.0526857s] Trained 128 records in 0.093884363 seconds. Throughput is 1363.3793 records/second. Loss is 0.34987926. Sequential31006cbd's hyper parameters: Current learning rate is 0.007213966238638003. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 7296/60000][Iteration 1933][Wall Clock 205.141079703s] Trained 128 records in 0.088394003 seconds. Throughput is 1448.062 records/second. Loss is 0.33126253. Sequential31006cbd's hyper parameters: Current learning rate is 0.007212925562608194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 1934][Wall Clock 205.240638618s] Trained 128 records in 0.099558915 seconds. Throughput is 1285.6709 records/second. Loss is 0.38756365. Sequential31006cbd's hyper parameters: Current learning rate is 0.007211885186787826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 7552/60000][Iteration 1935][Wall Clock 205.331813282s] Trained 128 records in 0.091174664 seconds. Throughput is 1403.8988 records/second. Loss is 0.29767522. Sequential31006cbd's hyper parameters: Current learning rate is 0.007210845111047015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:02 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 1936][Wall Clock 205.45550779s] Trained 128 records in 0.123694508 seconds. Throughput is 1034.8075 records/second. Loss is 0.2532754. Sequential31006cbd's hyper parameters: Current learning rate is 0.0072098053352559486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 7808/60000][Iteration 1937][Wall Clock 205.546780004s] Trained 128 records in 0.091272214 seconds. Throughput is 1402.3983 records/second. Loss is 0.3149085. Sequential31006cbd's hyper parameters: Current learning rate is 0.00720876585928489. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 1938][Wall Clock 205.631819167s] Trained 128 records in 0.085039163 seconds. Throughput is 1505.1888 records/second. Loss is 0.34263012. Sequential31006cbd's hyper parameters: Current learning rate is 0.007207726683004181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8064/60000][Iteration 1939][Wall Clock 205.720448603s] Trained 128 records in 0.088629436 seconds. Throughput is 1444.2153 records/second. Loss is 0.3568059. Sequential31006cbd's hyper parameters: Current learning rate is 0.007206687806284232. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 1940][Wall Clock 205.803832183s] Trained 128 records in 0.08338358 seconds. Throughput is 1535.0743 records/second. Loss is 0.33533555. Sequential31006cbd's hyper parameters: Current learning rate is 0.007205649228995533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8320/60000][Iteration 1941][Wall Clock 205.901877833s] Trained 128 records in 0.09804565 seconds. Throughput is 1305.5144 records/second. Loss is 0.27637148. Sequential31006cbd's hyper parameters: Current learning rate is 0.007204610951008646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 1942][Wall Clock 205.998332537s] Trained 128 records in 0.096454704 seconds. Throughput is 1327.0479 records/second. Loss is 0.32991824. Sequential31006cbd's hyper parameters: Current learning rate is 0.007203572972194208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8576/60000][Iteration 1943][Wall Clock 206.088034582s] Trained 128 records in 0.089702045 seconds. Throughput is 1426.9463 records/second. Loss is 0.25356606. Sequential31006cbd's hyper parameters: Current learning rate is 0.007202535292422933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 1944][Wall Clock 206.178744577s] Trained 128 records in 0.090709995 seconds. Throughput is 1411.0905 records/second. Loss is 0.47027463. Sequential31006cbd's hyper parameters: Current learning rate is 0.007201497911565605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8832/60000][Iteration 1945][Wall Clock 206.272061769s] Trained 128 records in 0.093317192 seconds. Throughput is 1371.6659 records/second. Loss is 0.2969521. Sequential31006cbd's hyper parameters: Current learning rate is 0.007200460829493088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 1946][Wall Clock 206.350850386s] Trained 128 records in 0.078788617 seconds. Throughput is 1624.6002 records/second. Loss is 0.32139364. Sequential31006cbd's hyper parameters: Current learning rate is 0.007199424046076314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:03 INFO  DistriOptimizer$:408 - [Epoch 5 9088/60000][Iteration 1947][Wall Clock 206.445567166s] Trained 128 records in 0.09471678 seconds. Throughput is 1351.3973 records/second. Loss is 0.33336228. Sequential31006cbd's hyper parameters: Current learning rate is 0.007198387561186294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 1948][Wall Clock 206.544787815s] Trained 128 records in 0.099220649 seconds. Throughput is 1290.0541 records/second. Loss is 0.29838467. Sequential31006cbd's hyper parameters: Current learning rate is 0.007197351374694113. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9344/60000][Iteration 1949][Wall Clock 206.634904173s] Trained 128 records in 0.090116358 seconds. Throughput is 1420.3859 records/second. Loss is 0.23404858. Sequential31006cbd's hyper parameters: Current learning rate is 0.007196315486470927. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 1950][Wall Clock 206.745439949s] Trained 128 records in 0.110535776 seconds. Throughput is 1157.9961 records/second. Loss is 0.27692527. Sequential31006cbd's hyper parameters: Current learning rate is 0.007195279896387969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9600/60000][Iteration 1951][Wall Clock 206.831918153s] Trained 128 records in 0.086478204 seconds. Throughput is 1480.1417 records/second. Loss is 0.44124854. Sequential31006cbd's hyper parameters: Current learning rate is 0.007194244604316546. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 1952][Wall Clock 206.917206914s] Trained 128 records in 0.085288761 seconds. Throughput is 1500.7838 records/second. Loss is 0.31818062. Sequential31006cbd's hyper parameters: Current learning rate is 0.007193209610128039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9856/60000][Iteration 1953][Wall Clock 207.016032124s] Trained 128 records in 0.09882521 seconds. Throughput is 1295.2161 records/second. Loss is 0.3347576. Sequential31006cbd's hyper parameters: Current learning rate is 0.007192174913693901. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 1954][Wall Clock 207.121368185s] Trained 128 records in 0.105336061 seconds. Throughput is 1215.1584 records/second. Loss is 0.3271532. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071911405148856605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 10112/60000][Iteration 1955][Wall Clock 207.205930225s] Trained 128 records in 0.08456204 seconds. Throughput is 1513.6815 records/second. Loss is 0.2996901. Sequential31006cbd's hyper parameters: Current learning rate is 0.007190106413574921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 1956][Wall Clock 207.299090746s] Trained 128 records in 0.093160521 seconds. Throughput is 1373.9727 records/second. Loss is 0.3513521. Sequential31006cbd's hyper parameters: Current learning rate is 0.007189072609633357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:04 INFO  DistriOptimizer$:408 - [Epoch 5 10368/60000][Iteration 1957][Wall Clock 207.409367634s] Trained 128 records in 0.110276888 seconds. Throughput is 1160.7147 records/second. Loss is 0.3651828. Sequential31006cbd's hyper parameters: Current learning rate is 0.00718803910293272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 1958][Wall Clock 207.509084898s] Trained 128 records in 0.099717264 seconds. Throughput is 1283.6293 records/second. Loss is 0.28091204. Sequential31006cbd's hyper parameters: Current learning rate is 0.007187005893344833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 10624/60000][Iteration 1959][Wall Clock 207.601056606s] Trained 128 records in 0.091971708 seconds. Throughput is 1391.7323 records/second. Loss is 0.26851273. Sequential31006cbd's hyper parameters: Current learning rate is 0.007185972980741593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 1960][Wall Clock 207.681499553s] Trained 128 records in 0.080442947 seconds. Throughput is 1591.1898 records/second. Loss is 0.30959427. Sequential31006cbd's hyper parameters: Current learning rate is 0.007184940364994971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 10880/60000][Iteration 1961][Wall Clock 207.769522946s] Trained 128 records in 0.088023393 seconds. Throughput is 1454.1588 records/second. Loss is 0.36079976. Sequential31006cbd's hyper parameters: Current learning rate is 0.007183908045977012. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 1962][Wall Clock 207.85450883s] Trained 128 records in 0.084985884 seconds. Throughput is 1506.1326 records/second. Loss is 0.35965285. Sequential31006cbd's hyper parameters: Current learning rate is 0.007182876023559834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11136/60000][Iteration 1963][Wall Clock 207.935175209s] Trained 128 records in 0.080666379 seconds. Throughput is 1586.7826 records/second. Loss is 0.39898756. Sequential31006cbd's hyper parameters: Current learning rate is 0.007181844297615627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 1964][Wall Clock 208.016740311s] Trained 128 records in 0.081565102 seconds. Throughput is 1569.2986 records/second. Loss is 0.34412313. Sequential31006cbd's hyper parameters: Current learning rate is 0.007180812868016659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11392/60000][Iteration 1965][Wall Clock 208.097951589s] Trained 128 records in 0.081211278 seconds. Throughput is 1576.1357 records/second. Loss is 0.37077186. Sequential31006cbd's hyper parameters: Current learning rate is 0.007179781734635267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 1966][Wall Clock 208.181405438s] Trained 128 records in 0.083453849 seconds. Throughput is 1533.7819 records/second. Loss is 0.25301534. Sequential31006cbd's hyper parameters: Current learning rate is 0.007178750897343863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11648/60000][Iteration 1967][Wall Clock 208.268704862s] Trained 128 records in 0.087299424 seconds. Throughput is 1466.2181 records/second. Loss is 0.30529207. Sequential31006cbd's hyper parameters: Current learning rate is 0.00717772035601493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 1968][Wall Clock 208.355756256s] Trained 128 records in 0.087051394 seconds. Throughput is 1470.3958 records/second. Loss is 0.29244557. Sequential31006cbd's hyper parameters: Current learning rate is 0.007176690110521028. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:05 INFO  DistriOptimizer$:408 - [Epoch 5 11904/60000][Iteration 1969][Wall Clock 208.444403334s] Trained 128 records in 0.088647078 seconds. Throughput is 1443.9281 records/second. Loss is 0.3196484. Sequential31006cbd's hyper parameters: Current learning rate is 0.007175660160734788. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 1970][Wall Clock 208.54168305s] Trained 128 records in 0.097279716 seconds. Throughput is 1315.7933 records/second. Loss is 0.25516093. Sequential31006cbd's hyper parameters: Current learning rate is 0.007174630506528913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12160/60000][Iteration 1971][Wall Clock 208.623641672s] Trained 128 records in 0.081958622 seconds. Throughput is 1561.7637 records/second. Loss is 0.3261667. Sequential31006cbd's hyper parameters: Current learning rate is 0.007173601147776183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 1972][Wall Clock 208.709338646s] Trained 128 records in 0.085696974 seconds. Throughput is 1493.635 records/second. Loss is 0.42946047. Sequential31006cbd's hyper parameters: Current learning rate is 0.007172572084349447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12416/60000][Iteration 1973][Wall Clock 208.799597779s] Trained 128 records in 0.090259133 seconds. Throughput is 1418.139 records/second. Loss is 0.45501494. Sequential31006cbd's hyper parameters: Current learning rate is 0.007171543316121629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 1974][Wall Clock 208.886708812s] Trained 128 records in 0.087111033 seconds. Throughput is 1469.389 records/second. Loss is 0.37220582. Sequential31006cbd's hyper parameters: Current learning rate is 0.007170514842965724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12672/60000][Iteration 1975][Wall Clock 208.963897864s] Trained 128 records in 0.077189052 seconds. Throughput is 1658.2662 records/second. Loss is 0.27258444. Sequential31006cbd's hyper parameters: Current learning rate is 0.007169486664754803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 1976][Wall Clock 209.049460916s] Trained 128 records in 0.085563052 seconds. Throughput is 1495.9729 records/second. Loss is 0.26801524. Sequential31006cbd's hyper parameters: Current learning rate is 0.007168458781362007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 12928/60000][Iteration 1977][Wall Clock 209.155827075s] Trained 128 records in 0.106366159 seconds. Throughput is 1203.3903 records/second. Loss is 0.22339427. Sequential31006cbd's hyper parameters: Current learning rate is 0.007167431192660551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 1978][Wall Clock 209.269303504s] Trained 128 records in 0.113476429 seconds. Throughput is 1127.9875 records/second. Loss is 0.20969655. Sequential31006cbd's hyper parameters: Current learning rate is 0.007166403898523721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 13184/60000][Iteration 1979][Wall Clock 209.370348599s] Trained 128 records in 0.101045095 seconds. Throughput is 1266.7611 records/second. Loss is 0.2586667. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071653768988248785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:06 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 1980][Wall Clock 209.467093361s] Trained 128 records in 0.096744762 seconds. Throughput is 1323.0691 records/second. Loss is 0.2749687. Sequential31006cbd's hyper parameters: Current learning rate is 0.007164350193437456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 13440/60000][Iteration 1981][Wall Clock 209.555612692s] Trained 128 records in 0.088519331 seconds. Throughput is 1446.0118 records/second. Loss is 0.35815674. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071633237822349575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 1982][Wall Clock 209.645914268s] Trained 128 records in 0.090301576 seconds. Throughput is 1417.4725 records/second. Loss is 0.4050443. Sequential31006cbd's hyper parameters: Current learning rate is 0.007162297665090962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 13696/60000][Iteration 1983][Wall Clock 209.725234402s] Trained 128 records in 0.079320134 seconds. Throughput is 1613.7139 records/second. Loss is 0.2542512. Sequential31006cbd's hyper parameters: Current learning rate is 0.007161271841879117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 1984][Wall Clock 209.806880612s] Trained 128 records in 0.08164621 seconds. Throughput is 1567.7396 records/second. Loss is 0.37733257. Sequential31006cbd's hyper parameters: Current learning rate is 0.007160246312473149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 13952/60000][Iteration 1985][Wall Clock 209.9018192s] Trained 128 records in 0.094938588 seconds. Throughput is 1348.24 records/second. Loss is 0.27161855. Sequential31006cbd's hyper parameters: Current learning rate is 0.00715922107674685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 1986][Wall Clock 209.983513201s] Trained 128 records in 0.081694001 seconds. Throughput is 1566.8225 records/second. Loss is 0.2899824. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071581961345740875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 14208/60000][Iteration 1987][Wall Clock 210.069517279s] Trained 128 records in 0.086004078 seconds. Throughput is 1488.3015 records/second. Loss is 0.3381837. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071571714858288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 1988][Wall Clock 210.155718894s] Trained 128 records in 0.086201615 seconds. Throughput is 1484.891 records/second. Loss is 0.29327548. Sequential31006cbd's hyper parameters: Current learning rate is 0.007156147130385001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 14464/60000][Iteration 1989][Wall Clock 210.246767822s] Trained 128 records in 0.091048928 seconds. Throughput is 1405.8375 records/second. Loss is 0.27154976. Sequential31006cbd's hyper parameters: Current learning rate is 0.007155123068116772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 1990][Wall Clock 210.360042713s] Trained 128 records in 0.113274891 seconds. Throughput is 1129.9944 records/second. Loss is 0.3493605. Sequential31006cbd's hyper parameters: Current learning rate is 0.007154099298898268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:07 INFO  DistriOptimizer$:408 - [Epoch 5 14720/60000][Iteration 1991][Wall Clock 210.461451967s] Trained 128 records in 0.101409254 seconds. Throughput is 1262.2122 records/second. Loss is 0.38599244. Sequential31006cbd's hyper parameters: Current learning rate is 0.007153075822603719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 1992][Wall Clock 210.605801467s] Trained 128 records in 0.1443495 seconds. Throughput is 886.7367 records/second. Loss is 0.23117982. Sequential31006cbd's hyper parameters: Current learning rate is 0.007152052639107423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 14976/60000][Iteration 1993][Wall Clock 210.705128573s] Trained 128 records in 0.099327106 seconds. Throughput is 1288.6714 records/second. Loss is 0.36286488. Sequential31006cbd's hyper parameters: Current learning rate is 0.007151029748283752. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 1994][Wall Clock 210.808064175s] Trained 128 records in 0.102935602 seconds. Throughput is 1243.4958 records/second. Loss is 0.2769599. Sequential31006cbd's hyper parameters: Current learning rate is 0.00715000715000715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15232/60000][Iteration 1995][Wall Clock 210.914083987s] Trained 128 records in 0.106019812 seconds. Throughput is 1207.3215 records/second. Loss is 0.3422231. Sequential31006cbd's hyper parameters: Current learning rate is 0.007148984844152131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 1996][Wall Clock 211.011247898s] Trained 128 records in 0.097163911 seconds. Throughput is 1317.3616 records/second. Loss is 0.3242944. Sequential31006cbd's hyper parameters: Current learning rate is 0.007147962830593281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15488/60000][Iteration 1997][Wall Clock 211.097229458s] Trained 128 records in 0.08598156 seconds. Throughput is 1488.6913 records/second. Loss is 0.25637862. Sequential31006cbd's hyper parameters: Current learning rate is 0.007146941109205261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 1998][Wall Clock 211.206913288s] Trained 128 records in 0.10968383 seconds. Throughput is 1166.9906 records/second. Loss is 0.2794042. Sequential31006cbd's hyper parameters: Current learning rate is 0.007145919679862799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15744/60000][Iteration 1999][Wall Clock 211.313317808s] Trained 128 records in 0.10640452 seconds. Throughput is 1202.9564 records/second. Loss is 0.33780015. Sequential31006cbd's hyper parameters: Current learning rate is 0.007144898542440698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:08 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 2000][Wall Clock 211.401473982s] Trained 128 records in 0.088156174 seconds. Throughput is 1451.9686 records/second. Loss is 0.28649017. Sequential31006cbd's hyper parameters: Current learning rate is 0.007143877696813831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16000/60000][Iteration 2001][Wall Clock 211.494267564s] Trained 128 records in 0.092793582 seconds. Throughput is 1379.4058 records/second. Loss is 0.37561268. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071428571428571435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 2002][Wall Clock 211.66276648s] Trained 128 records in 0.168498916 seconds. Throughput is 759.6488 records/second. Loss is 0.28846377. Sequential31006cbd's hyper parameters: Current learning rate is 0.007141836880445652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16256/60000][Iteration 2003][Wall Clock 211.753773587s] Trained 128 records in 0.091007107 seconds. Throughput is 1406.4835 records/second. Loss is 0.2539131. Sequential31006cbd's hyper parameters: Current learning rate is 0.007140816909454441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 2004][Wall Clock 211.872229729s] Trained 128 records in 0.118456142 seconds. Throughput is 1080.5687 records/second. Loss is 0.4551922. Sequential31006cbd's hyper parameters: Current learning rate is 0.007139797229758675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16512/60000][Iteration 2005][Wall Clock 211.960349731s] Trained 128 records in 0.088120002 seconds. Throughput is 1452.5647 records/second. Loss is 0.26050425. Sequential31006cbd's hyper parameters: Current learning rate is 0.007138777841233581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 2006][Wall Clock 212.045114011s] Trained 128 records in 0.08476428 seconds. Throughput is 1510.0701 records/second. Loss is 0.39273202. Sequential31006cbd's hyper parameters: Current learning rate is 0.007137758743754461. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16768/60000][Iteration 2007][Wall Clock 212.130908888s] Trained 128 records in 0.085794877 seconds. Throughput is 1491.9307 records/second. Loss is 0.29887757. Sequential31006cbd's hyper parameters: Current learning rate is 0.007136739937196689. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 2008][Wall Clock 212.212568771s] Trained 128 records in 0.081659883 seconds. Throughput is 1567.4772 records/second. Loss is 0.34064212. Sequential31006cbd's hyper parameters: Current learning rate is 0.007135721421435708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 17024/60000][Iteration 2009][Wall Clock 212.302222942s] Trained 128 records in 0.089654171 seconds. Throughput is 1427.7083 records/second. Loss is 0.3146772. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071347031963470324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 2010][Wall Clock 212.388986272s] Trained 128 records in 0.08676333 seconds. Throughput is 1475.2776 records/second. Loss is 0.42787313. Sequential31006cbd's hyper parameters: Current learning rate is 0.007133685261806248. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:09 INFO  DistriOptimizer$:408 - [Epoch 5 17280/60000][Iteration 2011][Wall Clock 212.48003356s] Trained 128 records in 0.091047288 seconds. Throughput is 1405.8629 records/second. Loss is 0.31915554. Sequential31006cbd's hyper parameters: Current learning rate is 0.007132667617689015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 2012][Wall Clock 212.563954366s] Trained 128 records in 0.083920806 seconds. Throughput is 1525.2474 records/second. Loss is 0.28740245. Sequential31006cbd's hyper parameters: Current learning rate is 0.007131650263871059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 17536/60000][Iteration 2013][Wall Clock 212.647463223s] Trained 128 records in 0.083508857 seconds. Throughput is 1532.7716 records/second. Loss is 0.30660713. Sequential31006cbd's hyper parameters: Current learning rate is 0.00713063320022818. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 2014][Wall Clock 212.73044275s] Trained 128 records in 0.082979527 seconds. Throughput is 1542.5491 records/second. Loss is 0.43053252. Sequential31006cbd's hyper parameters: Current learning rate is 0.007129616426636246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 17792/60000][Iteration 2015][Wall Clock 212.809316447s] Trained 128 records in 0.078873697 seconds. Throughput is 1622.8478 records/second. Loss is 0.3909156. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071285999429712005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 2016][Wall Clock 212.908904562s] Trained 128 records in 0.099588115 seconds. Throughput is 1285.294 records/second. Loss is 0.33522278. Sequential31006cbd's hyper parameters: Current learning rate is 0.007127583749109052. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 18048/60000][Iteration 2017][Wall Clock 213.014893381s] Trained 128 records in 0.105988819 seconds. Throughput is 1207.6746 records/second. Loss is 0.2381741. Sequential31006cbd's hyper parameters: Current learning rate is 0.007126567844925884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 2018][Wall Clock 213.0946996s] Trained 128 records in 0.079806219 seconds. Throughput is 1603.8851 records/second. Loss is 0.34556434. Sequential31006cbd's hyper parameters: Current learning rate is 0.007125552230297848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 18304/60000][Iteration 2019][Wall Clock 213.182000904s] Trained 128 records in 0.087301304 seconds. Throughput is 1466.1865 records/second. Loss is 0.30947837. Sequential31006cbd's hyper parameters: Current learning rate is 0.007124536905101168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 2020][Wall Clock 213.282258536s] Trained 128 records in 0.100257632 seconds. Throughput is 1276.7107 records/second. Loss is 0.2911064. Sequential31006cbd's hyper parameters: Current learning rate is 0.007123521869212139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 18560/60000][Iteration 2021][Wall Clock 213.364237828s] Trained 128 records in 0.081979292 seconds. Throughput is 1561.37 records/second. Loss is 0.41321582. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071225071225071235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:10 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 2022][Wall Clock 213.462325166s] Trained 128 records in 0.098087338 seconds. Throughput is 1304.9595 records/second. Loss is 0.34874508. Sequential31006cbd's hyper parameters: Current learning rate is 0.007121492664862556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 18816/60000][Iteration 2023][Wall Clock 213.560318187s] Trained 128 records in 0.097993021 seconds. Throughput is 1306.2155 records/second. Loss is 0.26034078. Sequential31006cbd's hyper parameters: Current learning rate is 0.007120478496154941. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 2024][Wall Clock 213.672377063s] Trained 128 records in 0.112058876 seconds. Throughput is 1142.2567 records/second. Loss is 0.28577328. Sequential31006cbd's hyper parameters: Current learning rate is 0.007119464616260857. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19072/60000][Iteration 2025][Wall Clock 213.773326648s] Trained 128 records in 0.100949585 seconds. Throughput is 1267.9596 records/second. Loss is 0.24868621. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071184510250569474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 2026][Wall Clock 213.874418528s] Trained 128 records in 0.10109188 seconds. Throughput is 1266.1749 records/second. Loss is 0.23726061. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071174377224199285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19328/60000][Iteration 2027][Wall Clock 213.986427883s] Trained 128 records in 0.112009355 seconds. Throughput is 1142.7617 records/second. Loss is 0.31299785. Sequential31006cbd's hyper parameters: Current learning rate is 0.007116424708226587. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 2028][Wall Clock 214.072815706s] Trained 128 records in 0.086387823 seconds. Throughput is 1481.6903 records/second. Loss is 0.2292544. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071154119823537785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19584/60000][Iteration 2029][Wall Clock 214.167771308s] Trained 128 records in 0.094955602 seconds. Throughput is 1347.9984 records/second. Loss is 0.3731466. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071143995446784295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 2030][Wall Clock 214.249160351s] Trained 128 records in 0.081389043 seconds. Throughput is 1572.6934 records/second. Loss is 0.3794888. Sequential31006cbd's hyper parameters: Current learning rate is 0.007113387395077536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19840/60000][Iteration 2031][Wall Clock 214.328568712s] Trained 128 records in 0.079408361 seconds. Throughput is 1611.9209 records/second. Loss is 0.24813673. Sequential31006cbd's hyper parameters: Current learning rate is 0.007112375533428164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:11 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 2032][Wall Clock 214.411807006s] Trained 128 records in 0.083238294 seconds. Throughput is 1537.7538 records/second. Loss is 0.29214618. Sequential31006cbd's hyper parameters: Current learning rate is 0.007111363959607452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20096/60000][Iteration 2033][Wall Clock 214.495451981s] Trained 128 records in 0.083644975 seconds. Throughput is 1530.2771 records/second. Loss is 0.32493314. Sequential31006cbd's hyper parameters: Current learning rate is 0.007110352673492605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 2034][Wall Clock 214.580686269s] Trained 128 records in 0.085234288 seconds. Throughput is 1501.7432 records/second. Loss is 0.26653373. Sequential31006cbd's hyper parameters: Current learning rate is 0.007109341674960899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20352/60000][Iteration 2035][Wall Clock 214.673542118s] Trained 128 records in 0.092855849 seconds. Throughput is 1378.4807 records/second. Loss is 0.28014773. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071083309638896785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 2036][Wall Clock 214.760438315s] Trained 128 records in 0.086896197 seconds. Throughput is 1473.0219 records/second. Loss is 0.35532993. Sequential31006cbd's hyper parameters: Current learning rate is 0.007107320540156361. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20608/60000][Iteration 2037][Wall Clock 214.84204259s] Trained 128 records in 0.081604275 seconds. Throughput is 1568.5453 records/second. Loss is 0.35497326. Sequential31006cbd's hyper parameters: Current learning rate is 0.007106310403638431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 2038][Wall Clock 214.922299251s] Trained 128 records in 0.080256661 seconds. Throughput is 1594.8832 records/second. Loss is 0.35657564. Sequential31006cbd's hyper parameters: Current learning rate is 0.0071053005542134435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20864/60000][Iteration 2039][Wall Clock 215.010407356s] Trained 128 records in 0.088108105 seconds. Throughput is 1452.7607 records/second. Loss is 0.26152793. Sequential31006cbd's hyper parameters: Current learning rate is 0.007104290991759023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 2040][Wall Clock 215.093708534s] Trained 128 records in 0.083301178 seconds. Throughput is 1536.5929 records/second. Loss is 0.30477753. Sequential31006cbd's hyper parameters: Current learning rate is 0.007103281716152863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 21120/60000][Iteration 2041][Wall Clock 215.168283049s] Trained 128 records in 0.074574515 seconds. Throughput is 1716.404 records/second. Loss is 0.33502465. Sequential31006cbd's hyper parameters: Current learning rate is 0.007102272727272728. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 2042][Wall Clock 215.259171938s] Trained 128 records in 0.090888889 seconds. Throughput is 1408.313 records/second. Loss is 0.199384. Sequential31006cbd's hyper parameters: Current learning rate is 0.00710126402499645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 21376/60000][Iteration 2043][Wall Clock 215.367700941s] Trained 128 records in 0.108529003 seconds. Throughput is 1179.4082 records/second. Loss is 0.3058495. Sequential31006cbd's hyper parameters: Current learning rate is 0.007100255609201931. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:12 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 2044][Wall Clock 215.455836879s] Trained 128 records in 0.088135938 seconds. Throughput is 1452.302 records/second. Loss is 0.3082583. Sequential31006cbd's hyper parameters: Current learning rate is 0.007099247479767145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 21632/60000][Iteration 2045][Wall Clock 215.548343268s] Trained 128 records in 0.092506389 seconds. Throughput is 1383.6882 records/second. Loss is 0.42833987. Sequential31006cbd's hyper parameters: Current learning rate is 0.007098239636570131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 2046][Wall Clock 215.644353421s] Trained 128 records in 0.096010153 seconds. Throughput is 1333.1923 records/second. Loss is 0.38683927. Sequential31006cbd's hyper parameters: Current learning rate is 0.007097232079488999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 21888/60000][Iteration 2047][Wall Clock 215.730992411s] Trained 128 records in 0.08663899 seconds. Throughput is 1477.3949 records/second. Loss is 0.28499606. Sequential31006cbd's hyper parameters: Current learning rate is 0.00709622480840193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 2048][Wall Clock 215.811010586s] Trained 128 records in 0.080018175 seconds. Throughput is 1599.6365 records/second. Loss is 0.36919346. Sequential31006cbd's hyper parameters: Current learning rate is 0.007095217823187172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22144/60000][Iteration 2049][Wall Clock 215.89035672s] Trained 128 records in 0.079346134 seconds. Throughput is 1613.185 records/second. Loss is 0.2066035. Sequential31006cbd's hyper parameters: Current learning rate is 0.007094211123723043. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 2050][Wall Clock 215.982170754s] Trained 128 records in 0.091814034 seconds. Throughput is 1394.1224 records/second. Loss is 0.3075441. Sequential31006cbd's hyper parameters: Current learning rate is 0.007093204709887928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22400/60000][Iteration 2051][Wall Clock 216.06984408s] Trained 128 records in 0.087673326 seconds. Throughput is 1459.9651 records/second. Loss is 0.3209877. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070921985815602835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 2052][Wall Clock 216.148601996s] Trained 128 records in 0.078757916 seconds. Throughput is 1625.2334 records/second. Loss is 0.2682198. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070911927386186355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22656/60000][Iteration 2053][Wall Clock 216.244258474s] Trained 128 records in 0.095656478 seconds. Throughput is 1338.1216 records/second. Loss is 0.21922137. Sequential31006cbd's hyper parameters: Current learning rate is 0.007090187180941576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:13 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 2054][Wall Clock 216.333063664s] Trained 128 records in 0.08880519 seconds. Throughput is 1441.3572 records/second. Loss is 0.31357485. Sequential31006cbd's hyper parameters: Current learning rate is 0.007089181908407769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 22912/60000][Iteration 2055][Wall Clock 216.475571894s] Trained 128 records in 0.14250823 seconds. Throughput is 898.1938 records/second. Loss is 0.28460407. Sequential31006cbd's hyper parameters: Current learning rate is 0.007088176920895945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 2056][Wall Clock 216.569975467s] Trained 128 records in 0.094403573 seconds. Throughput is 1355.8809 records/second. Loss is 0.3160862. Sequential31006cbd's hyper parameters: Current learning rate is 0.007087172218284904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23168/60000][Iteration 2057][Wall Clock 216.689977188s] Trained 128 records in 0.120001721 seconds. Throughput is 1066.6514 records/second. Loss is 0.37717924. Sequential31006cbd's hyper parameters: Current learning rate is 0.007086167800453515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 2058][Wall Clock 216.795895651s] Trained 128 records in 0.105918463 seconds. Throughput is 1208.4768 records/second. Loss is 0.2509851. Sequential31006cbd's hyper parameters: Current learning rate is 0.007085163667280714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23424/60000][Iteration 2059][Wall Clock 216.89183748s] Trained 128 records in 0.095941829 seconds. Throughput is 1334.1418 records/second. Loss is 0.41724813. Sequential31006cbd's hyper parameters: Current learning rate is 0.007084159818645509. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 2060][Wall Clock 216.980178894s] Trained 128 records in 0.088341414 seconds. Throughput is 1448.9241 records/second. Loss is 0.22841856. Sequential31006cbd's hyper parameters: Current learning rate is 0.007083156254426973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23680/60000][Iteration 2061][Wall Clock 217.076794859s] Trained 128 records in 0.096615965 seconds. Throughput is 1324.8329 records/second. Loss is 0.27089682. Sequential31006cbd's hyper parameters: Current learning rate is 0.007082152974504249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 2062][Wall Clock 217.156671799s] Trained 128 records in 0.07987694 seconds. Throughput is 1602.4651 records/second. Loss is 0.31762534. Sequential31006cbd's hyper parameters: Current learning rate is 0.007081149978756551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 23936/60000][Iteration 2063][Wall Clock 217.241881384s] Trained 128 records in 0.085209585 seconds. Throughput is 1502.1785 records/second. Loss is 0.28073198. Sequential31006cbd's hyper parameters: Current learning rate is 0.007080147267063155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 2064][Wall Clock 217.3304547s] Trained 128 records in 0.088573316 seconds. Throughput is 1445.1305 records/second. Loss is 0.26910707. Sequential31006cbd's hyper parameters: Current learning rate is 0.007079144839303412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:14 INFO  DistriOptimizer$:408 - [Epoch 5 24192/60000][Iteration 2065][Wall Clock 217.431589811s] Trained 128 records in 0.101135111 seconds. Throughput is 1265.6337 records/second. Loss is 0.34077248. Sequential31006cbd's hyper parameters: Current learning rate is 0.007078142695356738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 2066][Wall Clock 217.57181806s] Trained 128 records in 0.140228249 seconds. Throughput is 912.7976 records/second. Loss is 0.3284714. Sequential31006cbd's hyper parameters: Current learning rate is 0.007077140835102618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 24448/60000][Iteration 2067][Wall Clock 217.673670461s] Trained 128 records in 0.101852401 seconds. Throughput is 1256.7205 records/second. Loss is 0.3515287. Sequential31006cbd's hyper parameters: Current learning rate is 0.007076139258420606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 2068][Wall Clock 217.783174791s] Trained 128 records in 0.10950433 seconds. Throughput is 1168.9036 records/second. Loss is 0.35201627. Sequential31006cbd's hyper parameters: Current learning rate is 0.007075137965190321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 24704/60000][Iteration 2069][Wall Clock 217.880987706s] Trained 128 records in 0.097812915 seconds. Throughput is 1308.6207 records/second. Loss is 0.3390234. Sequential31006cbd's hyper parameters: Current learning rate is 0.007074136955291454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 2070][Wall Clock 217.980137706s] Trained 128 records in 0.09915 seconds. Throughput is 1290.9733 records/second. Loss is 0.23301572. Sequential31006cbd's hyper parameters: Current learning rate is 0.007073136228603763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 24960/60000][Iteration 2071][Wall Clock 218.090612759s] Trained 128 records in 0.110475053 seconds. Throughput is 1158.6326 records/second. Loss is 0.34067923. Sequential31006cbd's hyper parameters: Current learning rate is 0.007072135785007072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 2072][Wall Clock 218.178696526s] Trained 128 records in 0.088083767 seconds. Throughput is 1453.1622 records/second. Loss is 0.32126653. Sequential31006cbd's hyper parameters: Current learning rate is 0.007071135624381275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 25216/60000][Iteration 2073][Wall Clock 218.25700917s] Trained 128 records in 0.078312644 seconds. Throughput is 1634.4742 records/second. Loss is 0.37195086. Sequential31006cbd's hyper parameters: Current learning rate is 0.007070135746606335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 2074][Wall Clock 218.33924085s] Trained 128 records in 0.08223168 seconds. Throughput is 1556.5778 records/second. Loss is 0.26894096. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070691361515622785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:15 INFO  DistriOptimizer$:408 - [Epoch 5 25472/60000][Iteration 2075][Wall Clock 218.422452498s] Trained 128 records in 0.083211648 seconds. Throughput is 1538.2462 records/second. Loss is 0.29817718. Sequential31006cbd's hyper parameters: Current learning rate is 0.007068136839129205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 2076][Wall Clock 218.510513643s] Trained 128 records in 0.088061145 seconds. Throughput is 1453.5355 records/second. Loss is 0.30312786. Sequential31006cbd's hyper parameters: Current learning rate is 0.007067137809187279. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 25728/60000][Iteration 2077][Wall Clock 218.59110652s] Trained 128 records in 0.080592877 seconds. Throughput is 1588.2296 records/second. Loss is 0.25149268. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070661390616167325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 2078][Wall Clock 218.671514281s] Trained 128 records in 0.080407761 seconds. Throughput is 1591.8861 records/second. Loss is 0.44711366. Sequential31006cbd's hyper parameters: Current learning rate is 0.007065140596297866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 25984/60000][Iteration 2079][Wall Clock 218.757725971s] Trained 128 records in 0.08621169 seconds. Throughput is 1484.7174 records/second. Loss is 0.27998266. Sequential31006cbd's hyper parameters: Current learning rate is 0.007064142413111049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 2080][Wall Clock 218.84581112s] Trained 128 records in 0.088085149 seconds. Throughput is 1453.1393 records/second. Loss is 0.21718766. Sequential31006cbd's hyper parameters: Current learning rate is 0.007063144511936715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26240/60000][Iteration 2081][Wall Clock 218.96173079s] Trained 128 records in 0.11591967 seconds. Throughput is 1104.2129 records/second. Loss is 0.3088869. Sequential31006cbd's hyper parameters: Current learning rate is 0.007062146892655368. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 2082][Wall Clock 219.078701345s] Trained 128 records in 0.116970555 seconds. Throughput is 1094.2925 records/second. Loss is 0.4376696. Sequential31006cbd's hyper parameters: Current learning rate is 0.007061149555147579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26496/60000][Iteration 2083][Wall Clock 219.177013636s] Trained 128 records in 0.098312291 seconds. Throughput is 1301.9735 records/second. Loss is 0.3277364. Sequential31006cbd's hyper parameters: Current learning rate is 0.007060152499293986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 2084][Wall Clock 219.27478082s] Trained 128 records in 0.097767184 seconds. Throughput is 1309.2328 records/second. Loss is 0.32809797. Sequential31006cbd's hyper parameters: Current learning rate is 0.007059155724975293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26752/60000][Iteration 2085][Wall Clock 219.362714536s] Trained 128 records in 0.087933716 seconds. Throughput is 1455.6418 records/second. Loss is 0.25453618. Sequential31006cbd's hyper parameters: Current learning rate is 0.007058159232072275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:16 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 2086][Wall Clock 219.446814356s] Trained 128 records in 0.08409982 seconds. Throughput is 1522.0009 records/second. Loss is 0.3542797. Sequential31006cbd's hyper parameters: Current learning rate is 0.007057163020465773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27008/60000][Iteration 2087][Wall Clock 219.539678172s] Trained 128 records in 0.092863816 seconds. Throughput is 1378.3625 records/second. Loss is 0.29229352. Sequential31006cbd's hyper parameters: Current learning rate is 0.007056167090036692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 2088][Wall Clock 219.622430349s] Trained 128 records in 0.082752177 seconds. Throughput is 1546.7871 records/second. Loss is 0.24758658. Sequential31006cbd's hyper parameters: Current learning rate is 0.007055171440666009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27264/60000][Iteration 2089][Wall Clock 219.707035562s] Trained 128 records in 0.084605213 seconds. Throughput is 1512.9092 records/second. Loss is 0.2914946. Sequential31006cbd's hyper parameters: Current learning rate is 0.007054176072234763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 2090][Wall Clock 219.790125725s] Trained 128 records in 0.083090163 seconds. Throughput is 1540.4952 records/second. Loss is 0.29502526. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070531809846240655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27520/60000][Iteration 2091][Wall Clock 219.878370733s] Trained 128 records in 0.088245008 seconds. Throughput is 1450.5071 records/second. Loss is 0.3335318. Sequential31006cbd's hyper parameters: Current learning rate is 0.007052186177715091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 2092][Wall Clock 219.990670555s] Trained 128 records in 0.112299822 seconds. Throughput is 1139.8059 records/second. Loss is 0.30596483. Sequential31006cbd's hyper parameters: Current learning rate is 0.007051191651389084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27776/60000][Iteration 2093][Wall Clock 220.085612109s] Trained 128 records in 0.094941554 seconds. Throughput is 1348.1979 records/second. Loss is 0.37336755. Sequential31006cbd's hyper parameters: Current learning rate is 0.007050197405527354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 2094][Wall Clock 220.171096767s] Trained 128 records in 0.085484658 seconds. Throughput is 1497.3446 records/second. Loss is 0.41581908. Sequential31006cbd's hyper parameters: Current learning rate is 0.007049203440011279. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 28032/60000][Iteration 2095][Wall Clock 220.262843845s] Trained 128 records in 0.091747078 seconds. Throughput is 1395.1399 records/second. Loss is 0.32716838. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070482097547223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 2096][Wall Clock 220.345826621s] Trained 128 records in 0.082982776 seconds. Throughput is 1542.4888 records/second. Loss is 0.19808766. Sequential31006cbd's hyper parameters: Current learning rate is 0.007047216349541931. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:17 INFO  DistriOptimizer$:408 - [Epoch 5 28288/60000][Iteration 2097][Wall Clock 220.427023405s] Trained 128 records in 0.081196784 seconds. Throughput is 1576.4171 records/second. Loss is 0.36638364. Sequential31006cbd's hyper parameters: Current learning rate is 0.007046223224351747. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 2098][Wall Clock 220.517068287s] Trained 128 records in 0.090044882 seconds. Throughput is 1421.5134 records/second. Loss is 0.3516544. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070452303790333945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 28544/60000][Iteration 2099][Wall Clock 220.612701637s] Trained 128 records in 0.09563335 seconds. Throughput is 1338.4452 records/second. Loss is 0.44332522. Sequential31006cbd's hyper parameters: Current learning rate is 0.007044237813468583. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 2100][Wall Clock 220.701817985s] Trained 128 records in 0.089116348 seconds. Throughput is 1436.3246 records/second. Loss is 0.37008312. Sequential31006cbd's hyper parameters: Current learning rate is 0.007043245527539091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 28800/60000][Iteration 2101][Wall Clock 220.788342043s] Trained 128 records in 0.086524058 seconds. Throughput is 1479.3574 records/second. Loss is 0.40292457. Sequential31006cbd's hyper parameters: Current learning rate is 0.007042253521126761. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 2102][Wall Clock 220.881808334s] Trained 128 records in 0.093466291 seconds. Throughput is 1369.4777 records/second. Loss is 0.29324028. Sequential31006cbd's hyper parameters: Current learning rate is 0.007041261794113506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 29056/60000][Iteration 2103][Wall Clock 220.968041362s] Trained 128 records in 0.086233028 seconds. Throughput is 1484.3501 records/second. Loss is 0.36046797. Sequential31006cbd's hyper parameters: Current learning rate is 0.007040270346381302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 2104][Wall Clock 221.046640017s] Trained 128 records in 0.078598655 seconds. Throughput is 1628.5266 records/second. Loss is 0.35452378. Sequential31006cbd's hyper parameters: Current learning rate is 0.007039279177812192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 29312/60000][Iteration 2105][Wall Clock 221.133023177s] Trained 128 records in 0.08638316 seconds. Throughput is 1481.7704 records/second. Loss is 0.4719683. Sequential31006cbd's hyper parameters: Current learning rate is 0.007038288288288288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 2106][Wall Clock 221.219924565s] Trained 128 records in 0.086901388 seconds. Throughput is 1472.9338 records/second. Loss is 0.3078556. Sequential31006cbd's hyper parameters: Current learning rate is 0.007037297677691766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 29568/60000][Iteration 2107][Wall Clock 221.32489281s] Trained 128 records in 0.104968245 seconds. Throughput is 1219.4164 records/second. Loss is 0.3173699. Sequential31006cbd's hyper parameters: Current learning rate is 0.007036307345904869. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:18 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 2108][Wall Clock 221.415353056s] Trained 128 records in 0.090460246 seconds. Throughput is 1414.9862 records/second. Loss is 0.3591197. Sequential31006cbd's hyper parameters: Current learning rate is 0.007035317292809906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 29824/60000][Iteration 2109][Wall Clock 221.498903564s] Trained 128 records in 0.083550508 seconds. Throughput is 1532.0074 records/second. Loss is 0.2892218. Sequential31006cbd's hyper parameters: Current learning rate is 0.007034327518289252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 2110][Wall Clock 221.614553681s] Trained 128 records in 0.115650117 seconds. Throughput is 1106.7866 records/second. Loss is 0.27459717. Sequential31006cbd's hyper parameters: Current learning rate is 0.007033338022225348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30080/60000][Iteration 2111][Wall Clock 221.704711222s] Trained 128 records in 0.090157541 seconds. Throughput is 1419.737 records/second. Loss is 0.34296176. Sequential31006cbd's hyper parameters: Current learning rate is 0.007032348804500703. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 2112][Wall Clock 221.783481415s] Trained 128 records in 0.078770193 seconds. Throughput is 1624.9802 records/second. Loss is 0.31274506. Sequential31006cbd's hyper parameters: Current learning rate is 0.00703135986499789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30336/60000][Iteration 2113][Wall Clock 221.863822363s] Trained 128 records in 0.080340948 seconds. Throughput is 1593.21 records/second. Loss is 0.3951211. Sequential31006cbd's hyper parameters: Current learning rate is 0.00703037120359955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 2114][Wall Clock 221.948113116s] Trained 128 records in 0.084290753 seconds. Throughput is 1518.5533 records/second. Loss is 0.29411605. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070293828201883875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30592/60000][Iteration 2115][Wall Clock 222.026385514s] Trained 128 records in 0.078272398 seconds. Throughput is 1635.3147 records/second. Loss is 0.2913006. Sequential31006cbd's hyper parameters: Current learning rate is 0.007028394714647174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 2116][Wall Clock 222.116819311s] Trained 128 records in 0.090433797 seconds. Throughput is 1415.4 records/second. Loss is 0.26202574. Sequential31006cbd's hyper parameters: Current learning rate is 0.007027406886858749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30848/60000][Iteration 2117][Wall Clock 222.200723909s] Trained 128 records in 0.083904598 seconds. Throughput is 1525.5421 records/second. Loss is 0.37178233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070264193367060145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 2118][Wall Clock 222.29720531s] Trained 128 records in 0.096481401 seconds. Throughput is 1326.6807 records/second. Loss is 0.29027072. Sequential31006cbd's hyper parameters: Current learning rate is 0.00702543206407194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:19 INFO  DistriOptimizer$:408 - [Epoch 5 31104/60000][Iteration 2119][Wall Clock 222.374055435s] Trained 128 records in 0.076850125 seconds. Throughput is 1665.5796 records/second. Loss is 0.33223298. Sequential31006cbd's hyper parameters: Current learning rate is 0.007024445068839562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 2120][Wall Clock 222.469184863s] Trained 128 records in 0.095129428 seconds. Throughput is 1345.5353 records/second. Loss is 0.4094678. Sequential31006cbd's hyper parameters: Current learning rate is 0.007023458350891979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 31360/60000][Iteration 2121][Wall Clock 222.564769756s] Trained 128 records in 0.095584893 seconds. Throughput is 1339.1238 records/second. Loss is 0.41261688. Sequential31006cbd's hyper parameters: Current learning rate is 0.00702247191011236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 2122][Wall Clock 222.66811608s] Trained 128 records in 0.103346324 seconds. Throughput is 1238.554 records/second. Loss is 0.26404142. Sequential31006cbd's hyper parameters: Current learning rate is 0.007021485746383936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 31616/60000][Iteration 2123][Wall Clock 222.759330981s] Trained 128 records in 0.091214901 seconds. Throughput is 1403.2794 records/second. Loss is 0.28218955. Sequential31006cbd's hyper parameters: Current learning rate is 0.007020499859590004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 2124][Wall Clock 222.841390316s] Trained 128 records in 0.082059335 seconds. Throughput is 1559.8468 records/second. Loss is 0.3465905. Sequential31006cbd's hyper parameters: Current learning rate is 0.007019514249613926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 31872/60000][Iteration 2125][Wall Clock 222.937847325s] Trained 128 records in 0.096457009 seconds. Throughput is 1327.016 records/second. Loss is 0.3412114. Sequential31006cbd's hyper parameters: Current learning rate is 0.007018528916339135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 2126][Wall Clock 223.01441883s] Trained 128 records in 0.076571505 seconds. Throughput is 1671.6401 records/second. Loss is 0.3864119. Sequential31006cbd's hyper parameters: Current learning rate is 0.007017543859649123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 32128/60000][Iteration 2127][Wall Clock 223.098413086s] Trained 128 records in 0.083994256 seconds. Throughput is 1523.9138 records/second. Loss is 0.3029963. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070165590794274485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 2128][Wall Clock 223.19708751s] Trained 128 records in 0.098674424 seconds. Throughput is 1297.1953 records/second. Loss is 0.35021165. Sequential31006cbd's hyper parameters: Current learning rate is 0.007015574575557739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 32384/60000][Iteration 2129][Wall Clock 223.28741935s] Trained 128 records in 0.09033184 seconds. Throughput is 1416.9977 records/second. Loss is 0.31240442. Sequential31006cbd's hyper parameters: Current learning rate is 0.007014590347923681. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:20 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 2130][Wall Clock 223.374323687s] Trained 128 records in 0.086904337 seconds. Throughput is 1472.8839 records/second. Loss is 0.32572976. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070136063964090336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 32640/60000][Iteration 2131][Wall Clock 223.456580333s] Trained 128 records in 0.082256646 seconds. Throughput is 1556.1052 records/second. Loss is 0.35318542. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070126227208976155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 2132][Wall Clock 223.544965199s] Trained 128 records in 0.088384866 seconds. Throughput is 1448.2117 records/second. Loss is 0.18545856. Sequential31006cbd's hyper parameters: Current learning rate is 0.007011639321273314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 32896/60000][Iteration 2133][Wall Clock 223.66675989s] Trained 128 records in 0.121794691 seconds. Throughput is 1050.9489 records/second. Loss is 0.28534296. Sequential31006cbd's hyper parameters: Current learning rate is 0.007010656197420078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 2134][Wall Clock 223.77714103s] Trained 128 records in 0.11038114 seconds. Throughput is 1159.6184 records/second. Loss is 0.26869804. Sequential31006cbd's hyper parameters: Current learning rate is 0.007009673349221926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33152/60000][Iteration 2135][Wall Clock 223.881939136s] Trained 128 records in 0.104798106 seconds. Throughput is 1221.3961 records/second. Loss is 0.36163628. Sequential31006cbd's hyper parameters: Current learning rate is 0.007008690776562938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 2136][Wall Clock 223.982317601s] Trained 128 records in 0.100378465 seconds. Throughput is 1275.1738 records/second. Loss is 0.34736758. Sequential31006cbd's hyper parameters: Current learning rate is 0.00700770847932726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33408/60000][Iteration 2137][Wall Clock 224.061572488s] Trained 128 records in 0.079254887 seconds. Throughput is 1615.0424 records/second. Loss is 0.26693207. Sequential31006cbd's hyper parameters: Current learning rate is 0.007006726457399103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 2138][Wall Clock 224.14384392s] Trained 128 records in 0.082271432 seconds. Throughput is 1555.8256 records/second. Loss is 0.22217882. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070057447106627434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33664/60000][Iteration 2139][Wall Clock 224.225839618s] Trained 128 records in 0.081995698 seconds. Throughput is 1561.0575 records/second. Loss is 0.39891708. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070047632390025216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 2140][Wall Clock 224.307175613s] Trained 128 records in 0.081335995 seconds. Throughput is 1573.7191 records/second. Loss is 0.28806484. Sequential31006cbd's hyper parameters: Current learning rate is 0.007003782042302844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:21 INFO  DistriOptimizer$:408 - [Epoch 5 33920/60000][Iteration 2141][Wall Clock 224.381520841s] Trained 128 records in 0.074345228 seconds. Throughput is 1721.6975 records/second. Loss is 0.24234831. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070028011204481795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 2142][Wall Clock 224.466578048s] Trained 128 records in 0.085057207 seconds. Throughput is 1504.8695 records/second. Loss is 0.1936738. Sequential31006cbd's hyper parameters: Current learning rate is 0.0070018204733230645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34176/60000][Iteration 2143][Wall Clock 224.57798983s] Trained 128 records in 0.111411782 seconds. Throughput is 1148.8911 records/second. Loss is 0.25244552. Sequential31006cbd's hyper parameters: Current learning rate is 0.007000840100812098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 2144][Wall Clock 224.663248954s] Trained 128 records in 0.085259124 seconds. Throughput is 1501.3055 records/second. Loss is 0.4083851. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069998600027999435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34432/60000][Iteration 2145][Wall Clock 224.76403437s] Trained 128 records in 0.100785416 seconds. Throughput is 1270.025 records/second. Loss is 0.33917153. Sequential31006cbd's hyper parameters: Current learning rate is 0.006998880179171332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 2146][Wall Clock 224.850199862s] Trained 128 records in 0.086165492 seconds. Throughput is 1485.5134 records/second. Loss is 0.42210364. Sequential31006cbd's hyper parameters: Current learning rate is 0.006997900629811056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34688/60000][Iteration 2147][Wall Clock 224.942238065s] Trained 128 records in 0.092038203 seconds. Throughput is 1390.7269 records/second. Loss is 0.2476084. Sequential31006cbd's hyper parameters: Current learning rate is 0.006996921354603974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 2148][Wall Clock 225.034611804s] Trained 128 records in 0.092373739 seconds. Throughput is 1385.6753 records/second. Loss is 0.340167. Sequential31006cbd's hyper parameters: Current learning rate is 0.006995942353435008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 34944/60000][Iteration 2149][Wall Clock 225.116083026s] Trained 128 records in 0.081471222 seconds. Throughput is 1571.1069 records/second. Loss is 0.38014948. Sequential31006cbd's hyper parameters: Current learning rate is 0.006994963626189144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 2150][Wall Clock 225.197972327s] Trained 128 records in 0.081889301 seconds. Throughput is 1563.0857 records/second. Loss is 0.2670043. Sequential31006cbd's hyper parameters: Current learning rate is 0.006993985172751434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 35200/60000][Iteration 2151][Wall Clock 225.287980088s] Trained 128 records in 0.090007761 seconds. Throughput is 1422.0996 records/second. Loss is 0.28174838. Sequential31006cbd's hyper parameters: Current learning rate is 0.006993006993006994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:22 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 2152][Wall Clock 225.373329024s] Trained 128 records in 0.085348936 seconds. Throughput is 1499.7258 records/second. Loss is 0.2924142. Sequential31006cbd's hyper parameters: Current learning rate is 0.006992029086841001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 35456/60000][Iteration 2153][Wall Clock 225.453957595s] Trained 128 records in 0.080628571 seconds. Throughput is 1587.5265 records/second. Loss is 0.33913836. Sequential31006cbd's hyper parameters: Current learning rate is 0.006991051454138702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 2154][Wall Clock 225.551474417s] Trained 128 records in 0.097516822 seconds. Throughput is 1312.5941 records/second. Loss is 0.28672767. Sequential31006cbd's hyper parameters: Current learning rate is 0.006990074094785404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 35712/60000][Iteration 2155][Wall Clock 225.650760039s] Trained 128 records in 0.099285622 seconds. Throughput is 1289.2098 records/second. Loss is 0.34356818. Sequential31006cbd's hyper parameters: Current learning rate is 0.00698909700866648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 2156][Wall Clock 225.740610968s] Trained 128 records in 0.089850929 seconds. Throughput is 1424.5818 records/second. Loss is 0.30911928. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069881201956673656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 35968/60000][Iteration 2157][Wall Clock 225.830168463s] Trained 128 records in 0.089557495 seconds. Throughput is 1429.2494 records/second. Loss is 0.3603816. Sequential31006cbd's hyper parameters: Current learning rate is 0.006987143655673561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 2158][Wall Clock 225.909595251s] Trained 128 records in 0.079426788 seconds. Throughput is 1611.547 records/second. Loss is 0.26211488. Sequential31006cbd's hyper parameters: Current learning rate is 0.00698616738857063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 36224/60000][Iteration 2159][Wall Clock 226.016806589s] Trained 128 records in 0.107211338 seconds. Throughput is 1193.9036 records/second. Loss is 0.2641925. Sequential31006cbd's hyper parameters: Current learning rate is 0.006985191394244202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 2160][Wall Clock 226.118504472s] Trained 128 records in 0.101697883 seconds. Throughput is 1258.6299 records/second. Loss is 0.23961121. Sequential31006cbd's hyper parameters: Current learning rate is 0.006984215672579969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 36480/60000][Iteration 2161][Wall Clock 226.204910531s] Trained 128 records in 0.086406059 seconds. Throughput is 1481.3776 records/second. Loss is 0.27330825. Sequential31006cbd's hyper parameters: Current learning rate is 0.006983240223463688. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 2162][Wall Clock 226.305839203s] Trained 128 records in 0.100928672 seconds. Throughput is 1268.2224 records/second. Loss is 0.33477584. Sequential31006cbd's hyper parameters: Current learning rate is 0.006982265046781177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:23 INFO  DistriOptimizer$:408 - [Epoch 5 36736/60000][Iteration 2163][Wall Clock 226.396375207s] Trained 128 records in 0.090536004 seconds. Throughput is 1413.8021 records/second. Loss is 0.2722859. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069812901424183196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 2164][Wall Clock 226.480576901s] Trained 128 records in 0.084201694 seconds. Throughput is 1520.1594 records/second. Loss is 0.3006632. Sequential31006cbd's hyper parameters: Current learning rate is 0.006980315510261063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 36992/60000][Iteration 2165][Wall Clock 226.566754066s] Trained 128 records in 0.086177165 seconds. Throughput is 1485.3123 records/second. Loss is 0.34504455. Sequential31006cbd's hyper parameters: Current learning rate is 0.006979341150195421. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 2166][Wall Clock 226.648204974s] Trained 128 records in 0.081450908 seconds. Throughput is 1571.4988 records/second. Loss is 0.30305305. Sequential31006cbd's hyper parameters: Current learning rate is 0.006978367062107467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37248/60000][Iteration 2167][Wall Clock 226.744996164s] Trained 128 records in 0.09679119 seconds. Throughput is 1322.4343 records/second. Loss is 0.35729206. Sequential31006cbd's hyper parameters: Current learning rate is 0.006977393245883338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 2168][Wall Clock 226.863470905s] Trained 128 records in 0.118474741 seconds. Throughput is 1080.399 records/second. Loss is 0.20030203. Sequential31006cbd's hyper parameters: Current learning rate is 0.006976419701409237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37504/60000][Iteration 2169][Wall Clock 226.948340802s] Trained 128 records in 0.084869897 seconds. Throughput is 1508.1908 records/second. Loss is 0.29349574. Sequential31006cbd's hyper parameters: Current learning rate is 0.006975446428571429. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 2170][Wall Clock 227.041092739s] Trained 128 records in 0.092751937 seconds. Throughput is 1380.0251 records/second. Loss is 0.26893085. Sequential31006cbd's hyper parameters: Current learning rate is 0.006974473427256243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37760/60000][Iteration 2171][Wall Clock 227.13799607s] Trained 128 records in 0.096903331 seconds. Throughput is 1320.904 records/second. Loss is 0.27013183. Sequential31006cbd's hyper parameters: Current learning rate is 0.006973500697350071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 2172][Wall Clock 227.220793237s] Trained 128 records in 0.082797167 seconds. Throughput is 1545.9465 records/second. Loss is 0.3633252. Sequential31006cbd's hyper parameters: Current learning rate is 0.006972528238739366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 38016/60000][Iteration 2173][Wall Clock 227.296887629s] Trained 128 records in 0.076094392 seconds. Throughput is 1682.1213 records/second. Loss is 0.2946887. Sequential31006cbd's hyper parameters: Current learning rate is 0.006971556051310652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:24 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 2174][Wall Clock 227.38306936s] Trained 128 records in 0.086181731 seconds. Throughput is 1485.2336 records/second. Loss is 0.3368436. Sequential31006cbd's hyper parameters: Current learning rate is 0.006970584134950508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 38272/60000][Iteration 2175][Wall Clock 227.469532176s] Trained 128 records in 0.086462816 seconds. Throughput is 1480.4052 records/second. Loss is 0.22894067. Sequential31006cbd's hyper parameters: Current learning rate is 0.006969612489545581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 2176][Wall Clock 227.552272321s] Trained 128 records in 0.082740145 seconds. Throughput is 1547.0121 records/second. Loss is 0.27914694. Sequential31006cbd's hyper parameters: Current learning rate is 0.006968641114982578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 38528/60000][Iteration 2177][Wall Clock 227.635499456s] Trained 128 records in 0.083227135 seconds. Throughput is 1537.96 records/second. Loss is 0.3269053. Sequential31006cbd's hyper parameters: Current learning rate is 0.006967670011148272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 2178][Wall Clock 227.720952765s] Trained 128 records in 0.085453309 seconds. Throughput is 1497.894 records/second. Loss is 0.24927132. Sequential31006cbd's hyper parameters: Current learning rate is 0.006966699177929497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 38784/60000][Iteration 2179][Wall Clock 227.821857166s] Trained 128 records in 0.100904401 seconds. Throughput is 1268.5275 records/second. Loss is 0.31990808. Sequential31006cbd's hyper parameters: Current learning rate is 0.006965728615213151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 2180][Wall Clock 227.907750892s] Trained 128 records in 0.085893726 seconds. Throughput is 1490.2136 records/second. Loss is 0.2984258. Sequential31006cbd's hyper parameters: Current learning rate is 0.006964758322886196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 39040/60000][Iteration 2181][Wall Clock 228.003534052s] Trained 128 records in 0.09578316 seconds. Throughput is 1336.3518 records/second. Loss is 0.33430296. Sequential31006cbd's hyper parameters: Current learning rate is 0.006963788300835655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 2182][Wall Clock 228.089362087s] Trained 128 records in 0.085828035 seconds. Throughput is 1491.3541 records/second. Loss is 0.22516228. Sequential31006cbd's hyper parameters: Current learning rate is 0.006962818548948615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 39296/60000][Iteration 2183][Wall Clock 228.17033473s] Trained 128 records in 0.080972643 seconds. Throughput is 1580.7809 records/second. Loss is 0.40062052. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069618490671122255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 2184][Wall Clock 228.24297833s] Trained 128 records in 0.0726436 seconds. Throughput is 1762.0272 records/second. Loss is 0.2677256. Sequential31006cbd's hyper parameters: Current learning rate is 0.006960879855213699. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:25 INFO  DistriOptimizer$:408 - [Epoch 5 39552/60000][Iteration 2185][Wall Clock 228.338113171s] Trained 128 records in 0.095134841 seconds. Throughput is 1345.4587 records/second. Loss is 0.39766705. Sequential31006cbd's hyper parameters: Current learning rate is 0.006959910913140311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 2186][Wall Clock 228.422010566s] Trained 128 records in 0.083897395 seconds. Throughput is 1525.6731 records/second. Loss is 0.42569238. Sequential31006cbd's hyper parameters: Current learning rate is 0.006958942240779402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 39808/60000][Iteration 2187][Wall Clock 228.511752212s] Trained 128 records in 0.089741646 seconds. Throughput is 1426.3165 records/second. Loss is 0.39636442. Sequential31006cbd's hyper parameters: Current learning rate is 0.006957973838018369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 2188][Wall Clock 228.607144838s] Trained 128 records in 0.095392626 seconds. Throughput is 1341.8228 records/second. Loss is 0.3799633. Sequential31006cbd's hyper parameters: Current learning rate is 0.006957005704744678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40064/60000][Iteration 2189][Wall Clock 228.704802904s] Trained 128 records in 0.097658066 seconds. Throughput is 1310.6956 records/second. Loss is 0.3215589. Sequential31006cbd's hyper parameters: Current learning rate is 0.006956037840845855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 2190][Wall Clock 228.798329224s] Trained 128 records in 0.09352632 seconds. Throughput is 1368.5988 records/second. Loss is 0.27698898. Sequential31006cbd's hyper parameters: Current learning rate is 0.006955070246209487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40320/60000][Iteration 2191][Wall Clock 228.881551098s] Trained 128 records in 0.083221874 seconds. Throughput is 1538.0571 records/second. Loss is 0.35410577. Sequential31006cbd's hyper parameters: Current learning rate is 0.006954102920723227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 2192][Wall Clock 228.956838373s] Trained 128 records in 0.075287275 seconds. Throughput is 1700.1545 records/second. Loss is 0.30096537. Sequential31006cbd's hyper parameters: Current learning rate is 0.006953135864274787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40576/60000][Iteration 2193][Wall Clock 229.058931268s] Trained 128 records in 0.102092895 seconds. Throughput is 1253.7601 records/second. Loss is 0.3071621. Sequential31006cbd's hyper parameters: Current learning rate is 0.006952169076751946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 2194][Wall Clock 229.142632665s] Trained 128 records in 0.083701397 seconds. Throughput is 1529.2457 records/second. Loss is 0.2550459. Sequential31006cbd's hyper parameters: Current learning rate is 0.006951202558042541. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40832/60000][Iteration 2195][Wall Clock 229.22172214s] Trained 128 records in 0.079089475 seconds. Throughput is 1618.42 records/second. Loss is 0.4341789. Sequential31006cbd's hyper parameters: Current learning rate is 0.006950236308034473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 2196][Wall Clock 229.302559116s] Trained 128 records in 0.080836976 seconds. Throughput is 1583.4338 records/second. Loss is 0.43263552. Sequential31006cbd's hyper parameters: Current learning rate is 0.006949270326615705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:26 INFO  DistriOptimizer$:408 - [Epoch 5 41088/60000][Iteration 2197][Wall Clock 229.393340829s] Trained 128 records in 0.090781713 seconds. Throughput is 1409.9756 records/second. Loss is 0.3489594. Sequential31006cbd's hyper parameters: Current learning rate is 0.006948304613674263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 2198][Wall Clock 229.482799749s] Trained 128 records in 0.08945892 seconds. Throughput is 1430.8243 records/second. Loss is 0.268775. Sequential31006cbd's hyper parameters: Current learning rate is 0.006947339169098236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41344/60000][Iteration 2199][Wall Clock 229.560386906s] Trained 128 records in 0.077587157 seconds. Throughput is 1649.7576 records/second. Loss is 0.27562574. Sequential31006cbd's hyper parameters: Current learning rate is 0.006946373992775771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 2200][Wall Clock 229.645822757s] Trained 128 records in 0.085435851 seconds. Throughput is 1498.2001 records/second. Loss is 0.349683. Sequential31006cbd's hyper parameters: Current learning rate is 0.006945409084595083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41600/60000][Iteration 2201][Wall Clock 229.742171547s] Trained 128 records in 0.09634879 seconds. Throughput is 1328.5066 records/second. Loss is 0.25902528. Sequential31006cbd's hyper parameters: Current learning rate is 0.006944444444444445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 2202][Wall Clock 229.833767751s] Trained 128 records in 0.091596204 seconds. Throughput is 1397.4379 records/second. Loss is 0.31437925. Sequential31006cbd's hyper parameters: Current learning rate is 0.006943480072212193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41856/60000][Iteration 2203][Wall Clock 229.919878145s] Trained 128 records in 0.086110394 seconds. Throughput is 1486.464 records/second. Loss is 0.17019254. Sequential31006cbd's hyper parameters: Current learning rate is 0.006942515967786726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 2204][Wall Clock 230.003381105s] Trained 128 records in 0.08350296 seconds. Throughput is 1532.8798 records/second. Loss is 0.47660065. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069415521310565035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 42112/60000][Iteration 2205][Wall Clock 230.08613481s] Trained 128 records in 0.082753705 seconds. Throughput is 1546.7585 records/second. Loss is 0.2730929. Sequential31006cbd's hyper parameters: Current learning rate is 0.00694058856191005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 2206][Wall Clock 230.17340524s] Trained 128 records in 0.08727043 seconds. Throughput is 1466.7052 records/second. Loss is 0.29761747. Sequential31006cbd's hyper parameters: Current learning rate is 0.006939625260235947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 42368/60000][Iteration 2207][Wall Clock 230.255083746s] Trained 128 records in 0.081678506 seconds. Throughput is 1567.1196 records/second. Loss is 0.29424757. Sequential31006cbd's hyper parameters: Current learning rate is 0.006938662225922842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:27 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 2208][Wall Clock 230.342650365s] Trained 128 records in 0.087566619 seconds. Throughput is 1461.7441 records/second. Loss is 0.32605025. Sequential31006cbd's hyper parameters: Current learning rate is 0.006937699458859442. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 42624/60000][Iteration 2209][Wall Clock 230.423924749s] Trained 128 records in 0.081274384 seconds. Throughput is 1574.912 records/second. Loss is 0.38638708. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069367369589345175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 2210][Wall Clock 230.508751223s] Trained 128 records in 0.084826474 seconds. Throughput is 1508.9628 records/second. Loss is 0.26117358. Sequential31006cbd's hyper parameters: Current learning rate is 0.006935774726036899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 42880/60000][Iteration 2211][Wall Clock 230.626739318s] Trained 128 records in 0.117988095 seconds. Throughput is 1084.8552 records/second. Loss is 0.29670113. Sequential31006cbd's hyper parameters: Current learning rate is 0.006934812760055479. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 2212][Wall Clock 230.728043232s] Trained 128 records in 0.101303914 seconds. Throughput is 1263.5248 records/second. Loss is 0.40088838. Sequential31006cbd's hyper parameters: Current learning rate is 0.006933851060879212. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43136/60000][Iteration 2213][Wall Clock 230.828255154s] Trained 128 records in 0.100211922 seconds. Throughput is 1277.2932 records/second. Loss is 0.26395315. Sequential31006cbd's hyper parameters: Current learning rate is 0.006932889628397116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 2214][Wall Clock 230.94369651s] Trained 128 records in 0.115441356 seconds. Throughput is 1108.7881 records/second. Loss is 0.32921728. Sequential31006cbd's hyper parameters: Current learning rate is 0.006931928462498267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43392/60000][Iteration 2215][Wall Clock 231.048091677s] Trained 128 records in 0.104395167 seconds. Throughput is 1226.1104 records/second. Loss is 0.35809693. Sequential31006cbd's hyper parameters: Current learning rate is 0.006930967563071804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 2216][Wall Clock 231.142361477s] Trained 128 records in 0.0942698 seconds. Throughput is 1357.8049 records/second. Loss is 0.2866476. Sequential31006cbd's hyper parameters: Current learning rate is 0.00693000693000693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43648/60000][Iteration 2217][Wall Clock 231.240388623s] Trained 128 records in 0.098027146 seconds. Throughput is 1305.7607 records/second. Loss is 0.29274878. Sequential31006cbd's hyper parameters: Current learning rate is 0.006929046563192905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:28 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 2218][Wall Clock 231.324697039s] Trained 128 records in 0.084308416 seconds. Throughput is 1518.2351 records/second. Loss is 0.23165278. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069280864625190525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 43904/60000][Iteration 2219][Wall Clock 231.410269954s] Trained 128 records in 0.085572915 seconds. Throughput is 1495.8004 records/second. Loss is 0.26517767. Sequential31006cbd's hyper parameters: Current learning rate is 0.006927126627874758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 2220][Wall Clock 231.494873457s] Trained 128 records in 0.084603503 seconds. Throughput is 1512.9397 records/second. Loss is 0.24367715. Sequential31006cbd's hyper parameters: Current learning rate is 0.006926167059149467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44160/60000][Iteration 2221][Wall Clock 231.578898177s] Trained 128 records in 0.08402472 seconds. Throughput is 1523.3612 records/second. Loss is 0.27162686. Sequential31006cbd's hyper parameters: Current learning rate is 0.006925207756232688. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 2222][Wall Clock 231.659838237s] Trained 128 records in 0.08094006 seconds. Throughput is 1581.4171 records/second. Loss is 0.31178898. Sequential31006cbd's hyper parameters: Current learning rate is 0.006924248719013987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44416/60000][Iteration 2223][Wall Clock 231.754939186s] Trained 128 records in 0.095100949 seconds. Throughput is 1345.9382 records/second. Loss is 0.2468673. Sequential31006cbd's hyper parameters: Current learning rate is 0.006923289947382997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 2224][Wall Clock 231.843756625s] Trained 128 records in 0.088817439 seconds. Throughput is 1441.1584 records/second. Loss is 0.3220546. Sequential31006cbd's hyper parameters: Current learning rate is 0.006922331441229407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44672/60000][Iteration 2225][Wall Clock 231.923428323s] Trained 128 records in 0.079671698 seconds. Throughput is 1606.5931 records/second. Loss is 0.31947258. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069213732004429675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 2226][Wall Clock 232.002124724s] Trained 128 records in 0.078696401 seconds. Throughput is 1626.5039 records/second. Loss is 0.26330292. Sequential31006cbd's hyper parameters: Current learning rate is 0.006920415224913495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 44928/60000][Iteration 2227][Wall Clock 232.078103161s] Trained 128 records in 0.075978437 seconds. Throughput is 1684.6886 records/second. Loss is 0.38663465. Sequential31006cbd's hyper parameters: Current learning rate is 0.006919457514530861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 2228][Wall Clock 232.161632997s] Trained 128 records in 0.083529836 seconds. Throughput is 1532.3866 records/second. Loss is 0.27894905. Sequential31006cbd's hyper parameters: Current learning rate is 0.006918500069185001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 45184/60000][Iteration 2229][Wall Clock 232.243432658s] Trained 128 records in 0.081799661 seconds. Throughput is 1564.7986 records/second. Loss is 0.30270785. Sequential31006cbd's hyper parameters: Current learning rate is 0.00691754288876591. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:29 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 2230][Wall Clock 232.339438748s] Trained 128 records in 0.09600609 seconds. Throughput is 1333.2488 records/second. Loss is 0.25743335. Sequential31006cbd's hyper parameters: Current learning rate is 0.006916585973163646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 45440/60000][Iteration 2231][Wall Clock 232.42420439s] Trained 128 records in 0.084765642 seconds. Throughput is 1510.0458 records/second. Loss is 0.27905402. Sequential31006cbd's hyper parameters: Current learning rate is 0.006915629322268327. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 2232][Wall Clock 232.512204571s] Trained 128 records in 0.088000181 seconds. Throughput is 1454.5425 records/second. Loss is 0.24351904. Sequential31006cbd's hyper parameters: Current learning rate is 0.006914672935970128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 45696/60000][Iteration 2233][Wall Clock 232.595523271s] Trained 128 records in 0.0833187 seconds. Throughput is 1536.2698 records/second. Loss is 0.4347814. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069137168141592915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 2234][Wall Clock 232.675115868s] Trained 128 records in 0.079592597 seconds. Throughput is 1608.1897 records/second. Loss is 0.26052487. Sequential31006cbd's hyper parameters: Current learning rate is 0.006912760956726116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 45952/60000][Iteration 2235][Wall Clock 232.768533635s] Trained 128 records in 0.093417767 seconds. Throughput is 1370.1891 records/second. Loss is 0.34081146. Sequential31006cbd's hyper parameters: Current learning rate is 0.006911805363560962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 2236][Wall Clock 232.864877609s] Trained 128 records in 0.096343974 seconds. Throughput is 1328.573 records/second. Loss is 0.3231142. Sequential31006cbd's hyper parameters: Current learning rate is 0.00691085003455425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46208/60000][Iteration 2237][Wall Clock 232.950433958s] Trained 128 records in 0.085556349 seconds. Throughput is 1496.09 records/second. Loss is 0.32281318. Sequential31006cbd's hyper parameters: Current learning rate is 0.006909894969596462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 2238][Wall Clock 233.029762368s] Trained 128 records in 0.07932841 seconds. Throughput is 1613.5455 records/second. Loss is 0.25618228. Sequential31006cbd's hyper parameters: Current learning rate is 0.00690894016857814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46464/60000][Iteration 2239][Wall Clock 233.113441108s] Trained 128 records in 0.08367874 seconds. Throughput is 1529.6598 records/second. Loss is 0.3626978. Sequential31006cbd's hyper parameters: Current learning rate is 0.006907985631389887. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 2240][Wall Clock 233.197551151s] Trained 128 records in 0.084110043 seconds. Throughput is 1521.8159 records/second. Loss is 0.35156155. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069070313579223655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46720/60000][Iteration 2241][Wall Clock 233.279965209s] Trained 128 records in 0.082414058 seconds. Throughput is 1553.133 records/second. Loss is 0.32266766. Sequential31006cbd's hyper parameters: Current learning rate is 0.006906077348066299. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:30 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 2242][Wall Clock 233.372305224s] Trained 128 records in 0.092340015 seconds. Throughput is 1386.1813 records/second. Loss is 0.3550959. Sequential31006cbd's hyper parameters: Current learning rate is 0.0069051236017124715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 46976/60000][Iteration 2243][Wall Clock 233.464676319s] Trained 128 records in 0.092371095 seconds. Throughput is 1385.7148 records/second. Loss is 0.31000608. Sequential31006cbd's hyper parameters: Current learning rate is 0.006904170118751727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 2244][Wall Clock 233.568035452s] Trained 128 records in 0.103359133 seconds. Throughput is 1238.4005 records/second. Loss is 0.32337683. Sequential31006cbd's hyper parameters: Current learning rate is 0.006903216899074969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47232/60000][Iteration 2245][Wall Clock 233.647456949s] Trained 128 records in 0.079421497 seconds. Throughput is 1611.6543 records/second. Loss is 0.3311721. Sequential31006cbd's hyper parameters: Current learning rate is 0.006902263942573164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 2246][Wall Clock 233.72795981s] Trained 128 records in 0.080502861 seconds. Throughput is 1590.0056 records/second. Loss is 0.28775656. Sequential31006cbd's hyper parameters: Current learning rate is 0.006901311249137336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47488/60000][Iteration 2247][Wall Clock 233.808235602s] Trained 128 records in 0.080275792 seconds. Throughput is 1594.5032 records/second. Loss is 0.29737887. Sequential31006cbd's hyper parameters: Current learning rate is 0.00690035881865857. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 2248][Wall Clock 233.888031152s] Trained 128 records in 0.07979555 seconds. Throughput is 1604.0995 records/second. Loss is 0.30390674. Sequential31006cbd's hyper parameters: Current learning rate is 0.006899406651028011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47744/60000][Iteration 2249][Wall Clock 233.975277652s] Trained 128 records in 0.0872465 seconds. Throughput is 1467.1075 records/second. Loss is 0.26130822. Sequential31006cbd's hyper parameters: Current learning rate is 0.006898454746136866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 2250][Wall Clock 234.076939486s] Trained 128 records in 0.101661834 seconds. Throughput is 1259.0763 records/second. Loss is 0.29582274. Sequential31006cbd's hyper parameters: Current learning rate is 0.006897503103876397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 48000/60000][Iteration 2251][Wall Clock 234.182316045s] Trained 128 records in 0.105376559 seconds. Throughput is 1214.6914 records/second. Loss is 0.28674418. Sequential31006cbd's hyper parameters: Current learning rate is 0.006896551724137932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:31 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 2252][Wall Clock 234.304506728s] Trained 128 records in 0.122190683 seconds. Throughput is 1047.5431 records/second. Loss is 0.28503317. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068956006068128526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 48256/60000][Iteration 2253][Wall Clock 234.390133369s] Trained 128 records in 0.085626641 seconds. Throughput is 1494.8619 records/second. Loss is 0.30672398. Sequential31006cbd's hyper parameters: Current learning rate is 0.006894649751792608. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 2254][Wall Clock 234.469089506s] Trained 128 records in 0.078956137 seconds. Throughput is 1621.1533 records/second. Loss is 0.22121233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068936991589687024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 48512/60000][Iteration 2255][Wall Clock 234.561063463s] Trained 128 records in 0.091973957 seconds. Throughput is 1391.6982 records/second. Loss is 0.37135532. Sequential31006cbd's hyper parameters: Current learning rate is 0.006892748828232699. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 2256][Wall Clock 234.640053344s] Trained 128 records in 0.078989881 seconds. Throughput is 1620.4608 records/second. Loss is 0.31918475. Sequential31006cbd's hyper parameters: Current learning rate is 0.006891798759476223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 48768/60000][Iteration 2257][Wall Clock 234.72275017s] Trained 128 records in 0.082696826 seconds. Throughput is 1547.8224 records/second. Loss is 0.25799978. Sequential31006cbd's hyper parameters: Current learning rate is 0.006890848952590959. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 2258][Wall Clock 234.801727669s] Trained 128 records in 0.078977499 seconds. Throughput is 1620.7148 records/second. Loss is 0.33620587. Sequential31006cbd's hyper parameters: Current learning rate is 0.006889899407468651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 49024/60000][Iteration 2259][Wall Clock 234.889466468s] Trained 128 records in 0.087738799 seconds. Throughput is 1458.8757 records/second. Loss is 0.26349178. Sequential31006cbd's hyper parameters: Current learning rate is 0.006888950124001102. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 2260][Wall Clock 234.970079431s] Trained 128 records in 0.080612963 seconds. Throughput is 1587.8339 records/second. Loss is 0.26221776. Sequential31006cbd's hyper parameters: Current learning rate is 0.006888001102080176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 49280/60000][Iteration 2261][Wall Clock 235.051153889s] Trained 128 records in 0.081074458 seconds. Throughput is 1578.7955 records/second. Loss is 0.21727717. Sequential31006cbd's hyper parameters: Current learning rate is 0.006887052341597796. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 2262][Wall Clock 235.16923526s] Trained 128 records in 0.118081371 seconds. Throughput is 1083.9983 records/second. Loss is 0.284073. Sequential31006cbd's hyper parameters: Current learning rate is 0.006886103842445945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:32 INFO  DistriOptimizer$:408 - [Epoch 5 49536/60000][Iteration 2263][Wall Clock 235.292671377s] Trained 128 records in 0.123436117 seconds. Throughput is 1036.9736 records/second. Loss is 0.26678982. Sequential31006cbd's hyper parameters: Current learning rate is 0.006885155604516663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 2264][Wall Clock 235.372875709s] Trained 128 records in 0.080204332 seconds. Throughput is 1595.9238 records/second. Loss is 0.29852152. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068842076277020525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 49792/60000][Iteration 2265][Wall Clock 235.483696176s] Trained 128 records in 0.110820467 seconds. Throughput is 1155.0214 records/second. Loss is 0.26023865. Sequential31006cbd's hyper parameters: Current learning rate is 0.006883259911894273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 2266][Wall Clock 235.571815542s] Trained 128 records in 0.088119366 seconds. Throughput is 1452.5752 records/second. Loss is 0.2798592. Sequential31006cbd's hyper parameters: Current learning rate is 0.006882312456985547. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50048/60000][Iteration 2267][Wall Clock 235.658332809s] Trained 128 records in 0.086517267 seconds. Throughput is 1479.4735 records/second. Loss is 0.45222124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006881365262868153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 2268][Wall Clock 235.746827396s] Trained 128 records in 0.088494587 seconds. Throughput is 1446.4163 records/second. Loss is 0.39632306. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068804183294344295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50304/60000][Iteration 2269][Wall Clock 235.827908034s] Trained 128 records in 0.081080638 seconds. Throughput is 1578.6753 records/second. Loss is 0.18429923. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068794716565767754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 2270][Wall Clock 235.914017343s] Trained 128 records in 0.086109309 seconds. Throughput is 1486.4827 records/second. Loss is 0.30593264. Sequential31006cbd's hyper parameters: Current learning rate is 0.006878525244187647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50560/60000][Iteration 2271][Wall Clock 236.001090532s] Trained 128 records in 0.087073189 seconds. Throughput is 1470.0277 records/second. Loss is 0.301421. Sequential31006cbd's hyper parameters: Current learning rate is 0.00687757909215956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 2272][Wall Clock 236.115805566s] Trained 128 records in 0.114715034 seconds. Throughput is 1115.8085 records/second. Loss is 0.294233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068766332003850905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50816/60000][Iteration 2273][Wall Clock 236.212220799s] Trained 128 records in 0.096415233 seconds. Throughput is 1327.591 records/second. Loss is 0.33585954. Sequential31006cbd's hyper parameters: Current learning rate is 0.006875687568756875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:33 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 2274][Wall Clock 236.29911681s] Trained 128 records in 0.086896011 seconds. Throughput is 1473.025 records/second. Loss is 0.30464247. Sequential31006cbd's hyper parameters: Current learning rate is 0.006874742197167606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51072/60000][Iteration 2275][Wall Clock 236.381807138s] Trained 128 records in 0.082690328 seconds. Throughput is 1547.944 records/second. Loss is 0.3572613. Sequential31006cbd's hyper parameters: Current learning rate is 0.006873797085510036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 2276][Wall Clock 236.460693789s] Trained 128 records in 0.078886651 seconds. Throughput is 1622.5813 records/second. Loss is 0.32394734. Sequential31006cbd's hyper parameters: Current learning rate is 0.006872852233676976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51328/60000][Iteration 2277][Wall Clock 236.543572695s] Trained 128 records in 0.082878906 seconds. Throughput is 1544.422 records/second. Loss is 0.26366892. Sequential31006cbd's hyper parameters: Current learning rate is 0.006871907641561297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 2278][Wall Clock 236.627217832s] Trained 128 records in 0.083645137 seconds. Throughput is 1530.2743 records/second. Loss is 0.26915273. Sequential31006cbd's hyper parameters: Current learning rate is 0.00687096330905593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51584/60000][Iteration 2279][Wall Clock 236.708928142s] Trained 128 records in 0.08171031 seconds. Throughput is 1566.5098 records/second. Loss is 0.34482738. Sequential31006cbd's hyper parameters: Current learning rate is 0.006870019236053861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 2280][Wall Clock 236.785744227s] Trained 128 records in 0.076816085 seconds. Throughput is 1666.3177 records/second. Loss is 0.27526894. Sequential31006cbd's hyper parameters: Current learning rate is 0.006869075422448139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51840/60000][Iteration 2281][Wall Clock 236.866112064s] Trained 128 records in 0.080367837 seconds. Throughput is 1592.677 records/second. Loss is 0.27336022. Sequential31006cbd's hyper parameters: Current learning rate is 0.006868131868131869. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 2282][Wall Clock 236.94888114s] Trained 128 records in 0.082769076 seconds. Throughput is 1546.4713 records/second. Loss is 0.3220546. Sequential31006cbd's hyper parameters: Current learning rate is 0.006867188572998215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 52096/60000][Iteration 2283][Wall Clock 237.027916111s] Trained 128 records in 0.079034971 seconds. Throughput is 1619.5363 records/second. Loss is 0.3265463. Sequential31006cbd's hyper parameters: Current learning rate is 0.006866245536940402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 2284][Wall Clock 237.125267303s] Trained 128 records in 0.097351192 seconds. Throughput is 1314.8273 records/second. Loss is 0.34915316. Sequential31006cbd's hyper parameters: Current learning rate is 0.00686530275985171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 52352/60000][Iteration 2285][Wall Clock 237.211607671s] Trained 128 records in 0.086340368 seconds. Throughput is 1482.5046 records/second. Loss is 0.25469476. Sequential31006cbd's hyper parameters: Current learning rate is 0.00686436024162548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:34 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 2286][Wall Clock 237.290567966s] Trained 128 records in 0.078960295 seconds. Throughput is 1621.068 records/second. Loss is 0.30167645. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068634179821551134. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 52608/60000][Iteration 2287][Wall Clock 237.373297042s] Trained 128 records in 0.082729076 seconds. Throughput is 1547.219 records/second. Loss is 0.2617721. Sequential31006cbd's hyper parameters: Current learning rate is 0.006862475981334065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 2288][Wall Clock 237.476544959s] Trained 128 records in 0.103247917 seconds. Throughput is 1239.7345 records/second. Loss is 0.40915847. Sequential31006cbd's hyper parameters: Current learning rate is 0.006861534239055853. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 52864/60000][Iteration 2289][Wall Clock 237.565235665s] Trained 128 records in 0.088690706 seconds. Throughput is 1443.2178 records/second. Loss is 0.31410602. Sequential31006cbd's hyper parameters: Current learning rate is 0.006860592755214051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 2290][Wall Clock 237.656521363s] Trained 128 records in 0.091285698 seconds. Throughput is 1402.1912 records/second. Loss is 0.35399204. Sequential31006cbd's hyper parameters: Current learning rate is 0.006859651529702291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53120/60000][Iteration 2291][Wall Clock 237.748517116s] Trained 128 records in 0.091995753 seconds. Throughput is 1391.3685 records/second. Loss is 0.25415856. Sequential31006cbd's hyper parameters: Current learning rate is 0.006858710562414267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 2292][Wall Clock 237.837179563s] Trained 128 records in 0.088662447 seconds. Throughput is 1443.6777 records/second. Loss is 0.27580062. Sequential31006cbd's hyper parameters: Current learning rate is 0.006857769853243725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53376/60000][Iteration 2293][Wall Clock 237.926752174s] Trained 128 records in 0.089572611 seconds. Throughput is 1429.0083 records/second. Loss is 0.3107547. Sequential31006cbd's hyper parameters: Current learning rate is 0.006856829402084476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 2294][Wall Clock 238.016031794s] Trained 128 records in 0.08927962 seconds. Throughput is 1433.6979 records/second. Loss is 0.24722059. Sequential31006cbd's hyper parameters: Current learning rate is 0.006855889208830385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53632/60000][Iteration 2295][Wall Clock 238.100985565s] Trained 128 records in 0.084953771 seconds. Throughput is 1506.7018 records/second. Loss is 0.29020074. Sequential31006cbd's hyper parameters: Current learning rate is 0.006854949273375377. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 2296][Wall Clock 238.186215957s] Trained 128 records in 0.085230392 seconds. Throughput is 1501.8116 records/second. Loss is 0.27084583. Sequential31006cbd's hyper parameters: Current learning rate is 0.006854009595613434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 53888/60000][Iteration 2297][Wall Clock 238.264213729s] Trained 128 records in 0.077997772 seconds. Throughput is 1641.0725 records/second. Loss is 0.256254. Sequential31006cbd's hyper parameters: Current learning rate is 0.006853070175438596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:35 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 2298][Wall Clock 238.345131839s] Trained 128 records in 0.08091811 seconds. Throughput is 1581.8461 records/second. Loss is 0.32429034. Sequential31006cbd's hyper parameters: Current learning rate is 0.006852131012744964. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54144/60000][Iteration 2299][Wall Clock 238.442266955s] Trained 128 records in 0.097135116 seconds. Throughput is 1317.7521 records/second. Loss is 0.3321805. Sequential31006cbd's hyper parameters: Current learning rate is 0.006851192107426692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 2300][Wall Clock 238.524688319s] Trained 128 records in 0.082421364 seconds. Throughput is 1552.9955 records/second. Loss is 0.30637306. Sequential31006cbd's hyper parameters: Current learning rate is 0.006850253459377997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54400/60000][Iteration 2301][Wall Clock 238.60152659s] Trained 128 records in 0.076838271 seconds. Throughput is 1665.8365 records/second. Loss is 0.2925215. Sequential31006cbd's hyper parameters: Current learning rate is 0.006849315068493151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 2302][Wall Clock 238.684189205s] Trained 128 records in 0.082662615 seconds. Throughput is 1548.463 records/second. Loss is 0.26135594. Sequential31006cbd's hyper parameters: Current learning rate is 0.006848376934666485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54656/60000][Iteration 2303][Wall Clock 238.776056782s] Trained 128 records in 0.091867577 seconds. Throughput is 1393.3099 records/second. Loss is 0.34321943. Sequential31006cbd's hyper parameters: Current learning rate is 0.006847439057792386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 2304][Wall Clock 238.858565549s] Trained 128 records in 0.082508767 seconds. Throughput is 1551.3503 records/second. Loss is 0.24504036. Sequential31006cbd's hyper parameters: Current learning rate is 0.006846501437765303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 54912/60000][Iteration 2305][Wall Clock 238.953814517s] Trained 128 records in 0.095248968 seconds. Throughput is 1343.8466 records/second. Loss is 0.29730102. Sequential31006cbd's hyper parameters: Current learning rate is 0.006845564074479737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 2306][Wall Clock 239.045167732s] Trained 128 records in 0.091353215 seconds. Throughput is 1401.1548 records/second. Loss is 0.31311628. Sequential31006cbd's hyper parameters: Current learning rate is 0.006844626967830253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 55168/60000][Iteration 2307][Wall Clock 239.136335446s] Trained 128 records in 0.091167714 seconds. Throughput is 1404.0059 records/second. Loss is 0.24548371. Sequential31006cbd's hyper parameters: Current learning rate is 0.00684369011771147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 2308][Wall Clock 239.2178854s] Trained 128 records in 0.081549954 seconds. Throughput is 1569.5901 records/second. Loss is 0.2608664. Sequential31006cbd's hyper parameters: Current learning rate is 0.006842753524018065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:36 INFO  DistriOptimizer$:408 - [Epoch 5 55424/60000][Iteration 2309][Wall Clock 239.295742038s] Trained 128 records in 0.077856638 seconds. Throughput is 1644.0474 records/second. Loss is 0.25099683. Sequential31006cbd's hyper parameters: Current learning rate is 0.006841817186644773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 2310][Wall Clock 239.379622341s] Trained 128 records in 0.083880303 seconds. Throughput is 1525.984 records/second. Loss is 0.25005746. Sequential31006cbd's hyper parameters: Current learning rate is 0.006840881105486387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 55680/60000][Iteration 2311][Wall Clock 239.459119068s] Trained 128 records in 0.079496727 seconds. Throughput is 1610.1292 records/second. Loss is 0.28880644. Sequential31006cbd's hyper parameters: Current learning rate is 0.006839945280437756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 2312][Wall Clock 239.534960273s] Trained 128 records in 0.075841205 seconds. Throughput is 1687.7369 records/second. Loss is 0.2768677. Sequential31006cbd's hyper parameters: Current learning rate is 0.00683900971139379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 55936/60000][Iteration 2313][Wall Clock 239.63838931s] Trained 128 records in 0.103429037 seconds. Throughput is 1237.5635 records/second. Loss is 0.24777626. Sequential31006cbd's hyper parameters: Current learning rate is 0.006838074398249452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 2314][Wall Clock 239.7351676s] Trained 128 records in 0.09677829 seconds. Throughput is 1322.6107 records/second. Loss is 0.29091498. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068371393408997675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56192/60000][Iteration 2315][Wall Clock 239.821232995s] Trained 128 records in 0.086065395 seconds. Throughput is 1487.2412 records/second. Loss is 0.3376741. Sequential31006cbd's hyper parameters: Current learning rate is 0.006836204539239814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 2316][Wall Clock 239.917324244s] Trained 128 records in 0.096091249 seconds. Throughput is 1332.0673 records/second. Loss is 0.3294297. Sequential31006cbd's hyper parameters: Current learning rate is 0.00683526999316473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56448/60000][Iteration 2317][Wall Clock 240.005986679s] Trained 128 records in 0.088662435 seconds. Throughput is 1443.6779 records/second. Loss is 0.2403687. Sequential31006cbd's hyper parameters: Current learning rate is 0.00683433570256971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 2318][Wall Clock 240.088715422s] Trained 128 records in 0.082728743 seconds. Throughput is 1547.2252 records/second. Loss is 0.36551028. Sequential31006cbd's hyper parameters: Current learning rate is 0.006833401667350007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56704/60000][Iteration 2319][Wall Clock 240.163482355s] Trained 128 records in 0.074766933 seconds. Throughput is 1711.9867 records/second. Loss is 0.26035994. Sequential31006cbd's hyper parameters: Current learning rate is 0.00683246788740093. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 2320][Wall Clock 240.240397486s] Trained 128 records in 0.076915131 seconds. Throughput is 1664.1719 records/second. Loss is 0.32386675. Sequential31006cbd's hyper parameters: Current learning rate is 0.006831534362617844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:37 INFO  DistriOptimizer$:408 - [Epoch 5 56960/60000][Iteration 2321][Wall Clock 240.318793421s] Trained 128 records in 0.078395935 seconds. Throughput is 1632.7378 records/second. Loss is 0.28829768. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068306010928961755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 2322][Wall Clock 240.396953698s] Trained 128 records in 0.078160277 seconds. Throughput is 1637.6605 records/second. Loss is 0.24879295. Sequential31006cbd's hyper parameters: Current learning rate is 0.006829668078131403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57216/60000][Iteration 2323][Wall Clock 240.474489961s] Trained 128 records in 0.077536263 seconds. Throughput is 1650.8405 records/second. Loss is 0.26926553. Sequential31006cbd's hyper parameters: Current learning rate is 0.006828735318219066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 2324][Wall Clock 240.552311177s] Trained 128 records in 0.077821216 seconds. Throughput is 1644.7957 records/second. Loss is 0.29670334. Sequential31006cbd's hyper parameters: Current learning rate is 0.00682780281305476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57472/60000][Iteration 2325][Wall Clock 240.64204033s] Trained 128 records in 0.089729153 seconds. Throughput is 1426.5153 records/second. Loss is 0.29398343. Sequential31006cbd's hyper parameters: Current learning rate is 0.006826870562534134. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 2326][Wall Clock 240.727208156s] Trained 128 records in 0.085167826 seconds. Throughput is 1502.9149 records/second. Loss is 0.2307609. Sequential31006cbd's hyper parameters: Current learning rate is 0.006825938566552901. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57728/60000][Iteration 2327][Wall Clock 240.81075637s] Trained 128 records in 0.083548214 seconds. Throughput is 1532.0496 records/second. Loss is 0.2916105. Sequential31006cbd's hyper parameters: Current learning rate is 0.006825006825006825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 2328][Wall Clock 240.891102813s] Trained 128 records in 0.080346443 seconds. Throughput is 1593.1011 records/second. Loss is 0.24789013. Sequential31006cbd's hyper parameters: Current learning rate is 0.006824075337791729. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 57984/60000][Iteration 2329][Wall Clock 240.982043575s] Trained 128 records in 0.090940762 seconds. Throughput is 1407.5096 records/second. Loss is 0.4719288. Sequential31006cbd's hyper parameters: Current learning rate is 0.006823144104803494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 2330][Wall Clock 241.065598367s] Trained 128 records in 0.083554792 seconds. Throughput is 1531.929 records/second. Loss is 0.4254171. Sequential31006cbd's hyper parameters: Current learning rate is 0.006822213125938055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 58240/60000][Iteration 2331][Wall Clock 241.146963875s] Trained 128 records in 0.081365508 seconds. Throughput is 1573.1481 records/second. Loss is 0.32816112. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068212824010914054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 2332][Wall Clock 241.228568367s] Trained 128 records in 0.081604492 seconds. Throughput is 1568.541 records/second. Loss is 0.22948442. Sequential31006cbd's hyper parameters: Current learning rate is 0.006820351930159597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:38 INFO  DistriOptimizer$:408 - [Epoch 5 58496/60000][Iteration 2333][Wall Clock 241.311172528s] Trained 128 records in 0.082604161 seconds. Throughput is 1549.5587 records/second. Loss is 0.35692585. Sequential31006cbd's hyper parameters: Current learning rate is 0.006819421713038734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 2334][Wall Clock 241.396269617s] Trained 128 records in 0.085097089 seconds. Throughput is 1504.1643 records/second. Loss is 0.3121089. Sequential31006cbd's hyper parameters: Current learning rate is 0.006818491749624982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 58752/60000][Iteration 2335][Wall Clock 241.482631082s] Trained 128 records in 0.086361465 seconds. Throughput is 1482.1425 records/second. Loss is 0.34388924. Sequential31006cbd's hyper parameters: Current learning rate is 0.006817562039814562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 2336][Wall Clock 241.563347765s] Trained 128 records in 0.080716683 seconds. Throughput is 1585.7936 records/second. Loss is 0.26607153. Sequential31006cbd's hyper parameters: Current learning rate is 0.006816632583503749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59008/60000][Iteration 2337][Wall Clock 241.643537232s] Trained 128 records in 0.080189467 seconds. Throughput is 1596.2196 records/second. Loss is 0.29047215. Sequential31006cbd's hyper parameters: Current learning rate is 0.006815703380588877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 2338][Wall Clock 241.749426364s] Trained 128 records in 0.105889132 seconds. Throughput is 1208.8115 records/second. Loss is 0.4045708. Sequential31006cbd's hyper parameters: Current learning rate is 0.006814774430966335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59264/60000][Iteration 2339][Wall Clock 241.86441336s] Trained 128 records in 0.114986996 seconds. Throughput is 1113.1694 records/second. Loss is 0.32276794. Sequential31006cbd's hyper parameters: Current learning rate is 0.00681384573453257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 2340][Wall Clock 241.96477276s] Trained 128 records in 0.1003594 seconds. Throughput is 1275.4161 records/second. Loss is 0.3784855. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068129172911840855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59520/60000][Iteration 2341][Wall Clock 242.048916378s] Trained 128 records in 0.084143618 seconds. Throughput is 1521.2087 records/second. Loss is 0.46743447. Sequential31006cbd's hyper parameters: Current learning rate is 0.006811989100817439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 2342][Wall Clock 242.14192108s] Trained 128 records in 0.093004702 seconds. Throughput is 1376.2745 records/second. Loss is 0.3110541. Sequential31006cbd's hyper parameters: Current learning rate is 0.006811061163329247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59776/60000][Iteration 2343][Wall Clock 242.232500961s] Trained 128 records in 0.090579881 seconds. Throughput is 1413.1173 records/second. Loss is 0.33362466. Sequential31006cbd's hyper parameters: Current learning rate is 0.006810133478616182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:39 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 2344][Wall Clock 242.321739989s] Trained 128 records in 0.089239028 seconds. Throughput is 1434.35 records/second. Loss is 0.298454. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068092060465749695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:40 INFO  DistriOptimizer$:408 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 242.405699136s] Trained 128 records in 0.083959147 seconds. Throughput is 1524.551 records/second. Loss is 0.24396971. Sequential31006cbd's hyper parameters: Current learning rate is 0.006808278867102396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:40 INFO  DistriOptimizer$:452 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 242.405699136s] Epoch finished. Wall clock time is 243596.285639 ms
2019-10-24 00:01:40 INFO  DistriOptimizer$:111 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 242.405699136s] Validate model...
2019-10-24 00:01:41 INFO  DistriOptimizer$:178 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 242.405699136s] validate model throughput is 9835.75 records/second
2019-10-24 00:01:41 INFO  DistriOptimizer$:181 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 242.405699136s] Top1Accuracy is Accuracy(correct: 9245, count: 10000, accuracy: 0.9245)
2019-10-24 00:01:41 INFO  DistriOptimizer$:221 - [Wall Clock 243.596285639s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:01:41 INFO  DistriOptimizer$:226 - [Wall Clock 243.596285639s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 128/60000][Iteration 2346][Wall Clock 243.69835544s] Trained 128 records in 0.102069801 seconds. Throughput is 1254.0438 records/second. Loss is 0.28611606. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068073519400953025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 256/60000][Iteration 2347][Wall Clock 243.784627351s] Trained 128 records in 0.086271911 seconds. Throughput is 1483.681 records/second. Loss is 0.2647878. Sequential31006cbd's hyper parameters: Current learning rate is 0.006806425265450586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 384/60000][Iteration 2348][Wall Clock 243.870224216s] Trained 128 records in 0.085596865 seconds. Throughput is 1495.3818 records/second. Loss is 0.33720866. Sequential31006cbd's hyper parameters: Current learning rate is 0.006805498843065197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 512/60000][Iteration 2349][Wall Clock 243.953415063s] Trained 128 records in 0.083190847 seconds. Throughput is 1538.6309 records/second. Loss is 0.30108202. Sequential31006cbd's hyper parameters: Current learning rate is 0.006804572672836146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 640/60000][Iteration 2350][Wall Clock 244.031544996s] Trained 128 records in 0.078129933 seconds. Throughput is 1638.2965 records/second. Loss is 0.25842407. Sequential31006cbd's hyper parameters: Current learning rate is 0.006803646754660498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 768/60000][Iteration 2351][Wall Clock 244.124299492s] Trained 128 records in 0.092754496 seconds. Throughput is 1379.9869 records/second. Loss is 0.26123327. Sequential31006cbd's hyper parameters: Current learning rate is 0.006802721088435375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 896/60000][Iteration 2352][Wall Clock 244.211060304s] Trained 128 records in 0.086760812 seconds. Throughput is 1475.3204 records/second. Loss is 0.24434496. Sequential31006cbd's hyper parameters: Current learning rate is 0.006801795674057952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 1024/60000][Iteration 2353][Wall Clock 244.291537931s] Trained 128 records in 0.080477627 seconds. Throughput is 1590.5042 records/second. Loss is 0.25303996. Sequential31006cbd's hyper parameters: Current learning rate is 0.0068008705114254615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:41 INFO  DistriOptimizer$:408 - [Epoch 6 1152/60000][Iteration 2354][Wall Clock 244.372061141s] Trained 128 records in 0.08052321 seconds. Throughput is 1589.6039 records/second. Loss is 0.27865404. Sequential31006cbd's hyper parameters: Current learning rate is 0.006799945600435196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 1280/60000][Iteration 2355][Wall Clock 244.465223934s] Trained 128 records in 0.093162793 seconds. Throughput is 1373.9391 records/second. Loss is 0.26610392. Sequential31006cbd's hyper parameters: Current learning rate is 0.006799020940984498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 1408/60000][Iteration 2356][Wall Clock 244.557485983s] Trained 128 records in 0.092262049 seconds. Throughput is 1387.3527 records/second. Loss is 0.26773164. Sequential31006cbd's hyper parameters: Current learning rate is 0.006798096532970768. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 1536/60000][Iteration 2357][Wall Clock 244.642282321s] Trained 128 records in 0.084796338 seconds. Throughput is 1509.4991 records/second. Loss is 0.31753007. Sequential31006cbd's hyper parameters: Current learning rate is 0.006797172376291463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 1664/60000][Iteration 2358][Wall Clock 244.724008233s] Trained 128 records in 0.081725912 seconds. Throughput is 1566.2108 records/second. Loss is 0.2317621. Sequential31006cbd's hyper parameters: Current learning rate is 0.006796248470844094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 1792/60000][Iteration 2359][Wall Clock 244.807667022s] Trained 128 records in 0.083658789 seconds. Throughput is 1530.0245 records/second. Loss is 0.24585551. Sequential31006cbd's hyper parameters: Current learning rate is 0.00679532481652623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 1920/60000][Iteration 2360][Wall Clock 244.903591963s] Trained 128 records in 0.095924941 seconds. Throughput is 1334.3766 records/second. Loss is 0.36184186. Sequential31006cbd's hyper parameters: Current learning rate is 0.006794401413235494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 2048/60000][Iteration 2361][Wall Clock 244.981189028s] Trained 128 records in 0.077597065 seconds. Throughput is 1649.5469 records/second. Loss is 0.31862563. Sequential31006cbd's hyper parameters: Current learning rate is 0.006793478260869566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 2176/60000][Iteration 2362][Wall Clock 245.060535824s] Trained 128 records in 0.079346796 seconds. Throughput is 1613.1716 records/second. Loss is 0.24836196. Sequential31006cbd's hyper parameters: Current learning rate is 0.006792555359326179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 2304/60000][Iteration 2363][Wall Clock 245.171737788s] Trained 128 records in 0.111201964 seconds. Throughput is 1151.0588 records/second. Loss is 0.33364475. Sequential31006cbd's hyper parameters: Current learning rate is 0.006791632708503125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 2432/60000][Iteration 2364][Wall Clock 245.272093311s] Trained 128 records in 0.100355523 seconds. Throughput is 1275.4655 records/second. Loss is 0.30176276. Sequential31006cbd's hyper parameters: Current learning rate is 0.006790710308298248. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:42 INFO  DistriOptimizer$:408 - [Epoch 6 2560/60000][Iteration 2365][Wall Clock 245.361056296s] Trained 128 records in 0.088962985 seconds. Throughput is 1438.8007 records/second. Loss is 0.2657417. Sequential31006cbd's hyper parameters: Current learning rate is 0.006789788158609452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 2688/60000][Iteration 2366][Wall Clock 245.453866237s] Trained 128 records in 0.092809941 seconds. Throughput is 1379.1626 records/second. Loss is 0.27862427. Sequential31006cbd's hyper parameters: Current learning rate is 0.006788866259334691. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 2816/60000][Iteration 2367][Wall Clock 245.528233149s] Trained 128 records in 0.074366912 seconds. Throughput is 1721.1956 records/second. Loss is 0.41225624. Sequential31006cbd's hyper parameters: Current learning rate is 0.006787944610371979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 2944/60000][Iteration 2368][Wall Clock 245.620939774s] Trained 128 records in 0.092706625 seconds. Throughput is 1380.6996 records/second. Loss is 0.26643485. Sequential31006cbd's hyper parameters: Current learning rate is 0.006787023211619384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3072/60000][Iteration 2369][Wall Clock 245.700727083s] Trained 128 records in 0.079787309 seconds. Throughput is 1604.2653 records/second. Loss is 0.3383314. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067861020629750276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3200/60000][Iteration 2370][Wall Clock 245.783364554s] Trained 128 records in 0.082637471 seconds. Throughput is 1548.9341 records/second. Loss is 0.24915454. Sequential31006cbd's hyper parameters: Current learning rate is 0.006785181164337088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3328/60000][Iteration 2371][Wall Clock 245.872514805s] Trained 128 records in 0.089150251 seconds. Throughput is 1435.7783 records/second. Loss is 0.30084997. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067842605156037995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3456/60000][Iteration 2372][Wall Clock 245.959370903s] Trained 128 records in 0.086856098 seconds. Throughput is 1473.7019 records/second. Loss is 0.28612122. Sequential31006cbd's hyper parameters: Current learning rate is 0.00678334011667345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3584/60000][Iteration 2373][Wall Clock 246.039387549s] Trained 128 records in 0.080016646 seconds. Throughput is 1599.6672 records/second. Loss is 0.30557448. Sequential31006cbd's hyper parameters: Current learning rate is 0.006782419967444384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3712/60000][Iteration 2374][Wall Clock 246.117716465s] Trained 128 records in 0.078328916 seconds. Throughput is 1634.1348 records/second. Loss is 0.29250336. Sequential31006cbd's hyper parameters: Current learning rate is 0.006781500067815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3840/60000][Iteration 2375][Wall Clock 246.205290202s] Trained 128 records in 0.087573737 seconds. Throughput is 1461.6254 records/second. Loss is 0.29592192. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067805804176837535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 3968/60000][Iteration 2376][Wall Clock 246.294702603s] Trained 128 records in 0.089412401 seconds. Throughput is 1431.5688 records/second. Loss is 0.23914072. Sequential31006cbd's hyper parameters: Current learning rate is 0.006779661016949152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:43 INFO  DistriOptimizer$:408 - [Epoch 6 4096/60000][Iteration 2377][Wall Clock 246.387436732s] Trained 128 records in 0.092734129 seconds. Throughput is 1380.2902 records/second. Loss is 0.25012028. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067787418655097615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4224/60000][Iteration 2378][Wall Clock 246.466259974s] Trained 128 records in 0.078823242 seconds. Throughput is 1623.8866 records/second. Loss is 0.35363588. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067778229632641995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4352/60000][Iteration 2379][Wall Clock 246.549106996s] Trained 128 records in 0.082847022 seconds. Throughput is 1545.0164 records/second. Loss is 0.38826242. Sequential31006cbd's hyper parameters: Current learning rate is 0.006776904310111141. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4480/60000][Iteration 2380][Wall Clock 246.62812602s] Trained 128 records in 0.079019024 seconds. Throughput is 1619.863 records/second. Loss is 0.31867552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067759859059493156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4608/60000][Iteration 2381][Wall Clock 246.724541984s] Trained 128 records in 0.096415964 seconds. Throughput is 1327.5809 records/second. Loss is 0.22513929. Sequential31006cbd's hyper parameters: Current learning rate is 0.006775067750677507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4736/60000][Iteration 2382][Wall Clock 246.803632487s] Trained 128 records in 0.079090503 seconds. Throughput is 1618.399 records/second. Loss is 0.2321942. Sequential31006cbd's hyper parameters: Current learning rate is 0.006774149844194554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4864/60000][Iteration 2383][Wall Clock 246.903804908s] Trained 128 records in 0.100172421 seconds. Throughput is 1277.7968 records/second. Loss is 0.30165708. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067732321863993505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 4992/60000][Iteration 2384][Wall Clock 246.986242388s] Trained 128 records in 0.08243748 seconds. Throughput is 1552.6919 records/second. Loss is 0.27792844. Sequential31006cbd's hyper parameters: Current learning rate is 0.006772314777190844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 5120/60000][Iteration 2385][Wall Clock 247.062213156s] Trained 128 records in 0.075970768 seconds. Throughput is 1684.8585 records/second. Loss is 0.21875572. Sequential31006cbd's hyper parameters: Current learning rate is 0.00677139761646804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 5248/60000][Iteration 2386][Wall Clock 247.1376918s] Trained 128 records in 0.075478644 seconds. Throughput is 1695.844 records/second. Loss is 0.32887828. Sequential31006cbd's hyper parameters: Current learning rate is 0.006770480704129993. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 5376/60000][Iteration 2387][Wall Clock 247.22263229s] Trained 128 records in 0.08494049 seconds. Throughput is 1506.9374 records/second. Loss is 0.2355679. Sequential31006cbd's hyper parameters: Current learning rate is 0.006769564040075819. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:44 INFO  DistriOptimizer$:408 - [Epoch 6 5504/60000][Iteration 2388][Wall Clock 247.305857174s] Trained 128 records in 0.083224884 seconds. Throughput is 1538.0015 records/second. Loss is 0.24668893. Sequential31006cbd's hyper parameters: Current learning rate is 0.006768647624204684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 5632/60000][Iteration 2389][Wall Clock 247.439148628s] Trained 128 records in 0.133291454 seconds. Throughput is 960.30164 records/second. Loss is 0.26950002. Sequential31006cbd's hyper parameters: Current learning rate is 0.00676773145641581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 5760/60000][Iteration 2390][Wall Clock 247.524159857s] Trained 128 records in 0.085011229 seconds. Throughput is 1505.6835 records/second. Loss is 0.25663468. Sequential31006cbd's hyper parameters: Current learning rate is 0.006766815536608472. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 5888/60000][Iteration 2391][Wall Clock 247.608203303s] Trained 128 records in 0.084043446 seconds. Throughput is 1523.0219 records/second. Loss is 0.20586908. Sequential31006cbd's hyper parameters: Current learning rate is 0.006765899864682003. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6016/60000][Iteration 2392][Wall Clock 247.686766815s] Trained 128 records in 0.078563512 seconds. Throughput is 1629.2551 records/second. Loss is 0.1633255. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067649844405357875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6144/60000][Iteration 2393][Wall Clock 247.785982074s] Trained 128 records in 0.099215259 seconds. Throughput is 1290.1241 records/second. Loss is 0.25148094. Sequential31006cbd's hyper parameters: Current learning rate is 0.006764069264069263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6272/60000][Iteration 2394][Wall Clock 247.874458698s] Trained 128 records in 0.088476624 seconds. Throughput is 1446.7098 records/second. Loss is 0.23385608. Sequential31006cbd's hyper parameters: Current learning rate is 0.006763154335181929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6400/60000][Iteration 2395][Wall Clock 247.954304838s] Trained 128 records in 0.07984614 seconds. Throughput is 1603.083 records/second. Loss is 0.37262002. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067622396537733295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6528/60000][Iteration 2396][Wall Clock 248.049855116s] Trained 128 records in 0.095550278 seconds. Throughput is 1339.6089 records/second. Loss is 0.21335617. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067613252197430695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6656/60000][Iteration 2397][Wall Clock 248.14797195s] Trained 128 records in 0.098116834 seconds. Throughput is 1304.5671 records/second. Loss is 0.2007067. Sequential31006cbd's hyper parameters: Current learning rate is 0.006760411032990805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6784/60000][Iteration 2398][Wall Clock 248.239689671s] Trained 128 records in 0.091717721 seconds. Throughput is 1395.5864 records/second. Loss is 0.19143008. Sequential31006cbd's hyper parameters: Current learning rate is 0.00675949709341625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:45 INFO  DistriOptimizer$:408 - [Epoch 6 6912/60000][Iteration 2399][Wall Clock 248.333401564s] Trained 128 records in 0.093711893 seconds. Throughput is 1365.8885 records/second. Loss is 0.2795439. Sequential31006cbd's hyper parameters: Current learning rate is 0.006758583400919167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7040/60000][Iteration 2400][Wall Clock 248.419964948s] Trained 128 records in 0.086563384 seconds. Throughput is 1478.6852 records/second. Loss is 0.2804759. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067576699553993785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7168/60000][Iteration 2401][Wall Clock 248.49953744s] Trained 128 records in 0.079572492 seconds. Throughput is 1608.5961 records/second. Loss is 0.28909883. Sequential31006cbd's hyper parameters: Current learning rate is 0.006756756756756757. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7296/60000][Iteration 2402][Wall Clock 248.577829929s] Trained 128 records in 0.078292489 seconds. Throughput is 1634.895 records/second. Loss is 0.22986634. Sequential31006cbd's hyper parameters: Current learning rate is 0.006755843804891231. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7424/60000][Iteration 2403][Wall Clock 248.654794635s] Trained 128 records in 0.076964706 seconds. Throughput is 1663.1 records/second. Loss is 0.2765638. Sequential31006cbd's hyper parameters: Current learning rate is 0.006754931099702784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7552/60000][Iteration 2404][Wall Clock 248.734930798s] Trained 128 records in 0.080136163 seconds. Throughput is 1597.2814 records/second. Loss is 0.2919186. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067540186410914495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7680/60000][Iteration 2405][Wall Clock 248.813530873s] Trained 128 records in 0.078600075 seconds. Throughput is 1628.4972 records/second. Loss is 0.44261247. Sequential31006cbd's hyper parameters: Current learning rate is 0.006753106428957321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7808/60000][Iteration 2406][Wall Clock 248.894964634s] Trained 128 records in 0.081433761 seconds. Throughput is 1571.8297 records/second. Loss is 0.22087371. Sequential31006cbd's hyper parameters: Current learning rate is 0.00675219446320054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 7936/60000][Iteration 2407][Wall Clock 248.972502733s] Trained 128 records in 0.077538099 seconds. Throughput is 1650.8014 records/second. Loss is 0.2993974. Sequential31006cbd's hyper parameters: Current learning rate is 0.006751282743721307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 8064/60000][Iteration 2408][Wall Clock 249.053023047s] Trained 128 records in 0.080520314 seconds. Throughput is 1589.6609 records/second. Loss is 0.33011743. Sequential31006cbd's hyper parameters: Current learning rate is 0.006750371270419873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 8192/60000][Iteration 2409][Wall Clock 249.135504027s] Trained 128 records in 0.08248098 seconds. Throughput is 1551.8729 records/second. Loss is 0.28554887. Sequential31006cbd's hyper parameters: Current learning rate is 0.006749460043196544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 8320/60000][Iteration 2410][Wall Clock 249.214797394s] Trained 128 records in 0.079293367 seconds. Throughput is 1614.2585 records/second. Loss is 0.32707688. Sequential31006cbd's hyper parameters: Current learning rate is 0.00674854906195168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 8448/60000][Iteration 2411][Wall Clock 249.295700519s] Trained 128 records in 0.080903125 seconds. Throughput is 1582.139 records/second. Loss is 0.3988883. Sequential31006cbd's hyper parameters: Current learning rate is 0.006747638326585695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:46 INFO  DistriOptimizer$:408 - [Epoch 6 8576/60000][Iteration 2412][Wall Clock 249.384672714s] Trained 128 records in 0.088972195 seconds. Throughput is 1438.6517 records/second. Loss is 0.27792555. Sequential31006cbd's hyper parameters: Current learning rate is 0.006746727836999056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 8704/60000][Iteration 2413][Wall Clock 249.489352508s] Trained 128 records in 0.104679794 seconds. Throughput is 1222.7766 records/second. Loss is 0.29263073. Sequential31006cbd's hyper parameters: Current learning rate is 0.006745817593092283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 8832/60000][Iteration 2414][Wall Clock 249.591666684s] Trained 128 records in 0.102314176 seconds. Throughput is 1251.0486 records/second. Loss is 0.38922974. Sequential31006cbd's hyper parameters: Current learning rate is 0.006744907594765951. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 8960/60000][Iteration 2415][Wall Clock 249.69023983s] Trained 128 records in 0.098573146 seconds. Throughput is 1298.5281 records/second. Loss is 0.3167042. Sequential31006cbd's hyper parameters: Current learning rate is 0.00674399784192069. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9088/60000][Iteration 2416][Wall Clock 249.783983936s] Trained 128 records in 0.093744106 seconds. Throughput is 1365.4192 records/second. Loss is 0.18248296. Sequential31006cbd's hyper parameters: Current learning rate is 0.006743088334457181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9216/60000][Iteration 2417][Wall Clock 249.874362039s] Trained 128 records in 0.090378103 seconds. Throughput is 1416.2722 records/second. Loss is 0.27716222. Sequential31006cbd's hyper parameters: Current learning rate is 0.006742179072276159. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9344/60000][Iteration 2418][Wall Clock 249.956793634s] Trained 128 records in 0.082431595 seconds. Throughput is 1552.8027 records/second. Loss is 0.19349883. Sequential31006cbd's hyper parameters: Current learning rate is 0.006741270055278414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9472/60000][Iteration 2419][Wall Clock 250.048809004s] Trained 128 records in 0.09201537 seconds. Throughput is 1391.0719 records/second. Loss is 0.23870936. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067403612833647885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9600/60000][Iteration 2420][Wall Clock 250.139679894s] Trained 128 records in 0.09087089 seconds. Throughput is 1408.5919 records/second. Loss is 0.24974476. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067394527564361775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9728/60000][Iteration 2421][Wall Clock 250.221397737s] Trained 128 records in 0.081717843 seconds. Throughput is 1566.3654 records/second. Loss is 0.3211755. Sequential31006cbd's hyper parameters: Current learning rate is 0.006738544474393531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:47 INFO  DistriOptimizer$:408 - [Epoch 6 9856/60000][Iteration 2422][Wall Clock 250.306828564s] Trained 128 records in 0.085430827 seconds. Throughput is 1498.2881 records/second. Loss is 0.3350103. Sequential31006cbd's hyper parameters: Current learning rate is 0.006737636437137852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 9984/60000][Iteration 2423][Wall Clock 250.382013784s] Trained 128 records in 0.07518522 seconds. Throughput is 1702.4623 records/second. Loss is 0.42806014. Sequential31006cbd's hyper parameters: Current learning rate is 0.006736728644570197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10112/60000][Iteration 2424][Wall Clock 250.46597657s] Trained 128 records in 0.083962786 seconds. Throughput is 1524.485 records/second. Loss is 0.21085668. Sequential31006cbd's hyper parameters: Current learning rate is 0.006735821096591675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10240/60000][Iteration 2425][Wall Clock 250.550636629s] Trained 128 records in 0.084660059 seconds. Throughput is 1511.929 records/second. Loss is 0.33081907. Sequential31006cbd's hyper parameters: Current learning rate is 0.006734913793103449. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10368/60000][Iteration 2426][Wall Clock 250.655615013s] Trained 128 records in 0.104978384 seconds. Throughput is 1219.2987 records/second. Loss is 0.29773104. Sequential31006cbd's hyper parameters: Current learning rate is 0.006734006734006734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10496/60000][Iteration 2427][Wall Clock 250.750424973s] Trained 128 records in 0.09480996 seconds. Throughput is 1350.0692 records/second. Loss is 0.32612652. Sequential31006cbd's hyper parameters: Current learning rate is 0.006733099919202801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10624/60000][Iteration 2428][Wall Clock 250.839897892s] Trained 128 records in 0.089472919 seconds. Throughput is 1430.6005 records/second. Loss is 0.3168509. Sequential31006cbd's hyper parameters: Current learning rate is 0.006732193348592971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10752/60000][Iteration 2429][Wall Clock 250.923615784s] Trained 128 records in 0.083717892 seconds. Throughput is 1528.9445 records/second. Loss is 0.27315262. Sequential31006cbd's hyper parameters: Current learning rate is 0.006731287022078622. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 10880/60000][Iteration 2430][Wall Clock 251.014692579s] Trained 128 records in 0.091076795 seconds. Throughput is 1405.4075 records/second. Loss is 0.33777732. Sequential31006cbd's hyper parameters: Current learning rate is 0.006730380939561179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 11008/60000][Iteration 2431][Wall Clock 251.102634304s] Trained 128 records in 0.087941725 seconds. Throughput is 1455.5093 records/second. Loss is 0.272105. Sequential31006cbd's hyper parameters: Current learning rate is 0.006729475100942127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 11136/60000][Iteration 2432][Wall Clock 251.191461645s] Trained 128 records in 0.088827341 seconds. Throughput is 1440.9978 records/second. Loss is 0.33031863. Sequential31006cbd's hyper parameters: Current learning rate is 0.006728569506122999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 11264/60000][Iteration 2433][Wall Clock 251.273719269s] Trained 128 records in 0.082257624 seconds. Throughput is 1556.0868 records/second. Loss is 0.32660976. Sequential31006cbd's hyper parameters: Current learning rate is 0.006727664155005382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:48 INFO  DistriOptimizer$:408 - [Epoch 6 11392/60000][Iteration 2434][Wall Clock 251.37332944s] Trained 128 records in 0.099610171 seconds. Throughput is 1285.0093 records/second. Loss is 0.28401226. Sequential31006cbd's hyper parameters: Current learning rate is 0.006726759047490918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 11520/60000][Iteration 2435][Wall Clock 251.462208132s] Trained 128 records in 0.088878692 seconds. Throughput is 1440.1652 records/second. Loss is 0.29802164. Sequential31006cbd's hyper parameters: Current learning rate is 0.006725854183481302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 11648/60000][Iteration 2436][Wall Clock 251.547151995s] Trained 128 records in 0.084943863 seconds. Throughput is 1506.8776 records/second. Loss is 0.26951656. Sequential31006cbd's hyper parameters: Current learning rate is 0.006724949562878278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 11776/60000][Iteration 2437][Wall Clock 251.635423133s] Trained 128 records in 0.088271138 seconds. Throughput is 1450.0775 records/second. Loss is 0.2940887. Sequential31006cbd's hyper parameters: Current learning rate is 0.006724045185583647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 11904/60000][Iteration 2438][Wall Clock 251.724946687s] Trained 128 records in 0.089523554 seconds. Throughput is 1429.7913 records/second. Loss is 0.29062372. Sequential31006cbd's hyper parameters: Current learning rate is 0.006723141051499261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12032/60000][Iteration 2439][Wall Clock 251.852833491s] Trained 128 records in 0.127886804 seconds. Throughput is 1000.88513 records/second. Loss is 0.5170756. Sequential31006cbd's hyper parameters: Current learning rate is 0.006722237160527024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12160/60000][Iteration 2440][Wall Clock 251.94810467s] Trained 128 records in 0.095271179 seconds. Throughput is 1343.5333 records/second. Loss is 0.24183224. Sequential31006cbd's hyper parameters: Current learning rate is 0.006721333512568894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12288/60000][Iteration 2441][Wall Clock 252.044995268s] Trained 128 records in 0.096890598 seconds. Throughput is 1321.0776 records/second. Loss is 0.19988403. Sequential31006cbd's hyper parameters: Current learning rate is 0.006720430107526882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12416/60000][Iteration 2442][Wall Clock 252.133287742s] Trained 128 records in 0.088292474 seconds. Throughput is 1449.7272 records/second. Loss is 0.25183296. Sequential31006cbd's hyper parameters: Current learning rate is 0.006719526945303051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12544/60000][Iteration 2443][Wall Clock 252.209393748s] Trained 128 records in 0.076106006 seconds. Throughput is 1681.8646 records/second. Loss is 0.23342167. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067186240257995165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12672/60000][Iteration 2444][Wall Clock 252.286472481s] Trained 128 records in 0.077078733 seconds. Throughput is 1660.6398 records/second. Loss is 0.21065551. Sequential31006cbd's hyper parameters: Current learning rate is 0.006717721348918447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:49 INFO  DistriOptimizer$:408 - [Epoch 6 12800/60000][Iteration 2445][Wall Clock 252.36503574s] Trained 128 records in 0.078563259 seconds. Throughput is 1629.2604 records/second. Loss is 0.23825558. Sequential31006cbd's hyper parameters: Current learning rate is 0.006716818914562064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 12928/60000][Iteration 2446][Wall Clock 252.455689073s] Trained 128 records in 0.090653333 seconds. Throughput is 1411.9724 records/second. Loss is 0.31222403. Sequential31006cbd's hyper parameters: Current learning rate is 0.006715916722632639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13056/60000][Iteration 2447][Wall Clock 252.53724506s] Trained 128 records in 0.081555987 seconds. Throughput is 1569.474 records/second. Loss is 0.22481138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067150147730325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13184/60000][Iteration 2448][Wall Clock 252.652213505s] Trained 128 records in 0.114968445 seconds. Throughput is 1113.349 records/second. Loss is 0.3394126. Sequential31006cbd's hyper parameters: Current learning rate is 0.006714113065664025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13312/60000][Iteration 2449][Wall Clock 252.73743202s] Trained 128 records in 0.085218515 seconds. Throughput is 1502.0211 records/second. Loss is 0.29325157. Sequential31006cbd's hyper parameters: Current learning rate is 0.006713211600429645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13440/60000][Iteration 2450][Wall Clock 252.824329879s] Trained 128 records in 0.086897859 seconds. Throughput is 1472.9938 records/second. Loss is 0.25495002. Sequential31006cbd's hyper parameters: Current learning rate is 0.006712310377231843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13568/60000][Iteration 2451][Wall Clock 252.907969081s] Trained 128 records in 0.083639202 seconds. Throughput is 1530.3828 records/second. Loss is 0.35818207. Sequential31006cbd's hyper parameters: Current learning rate is 0.006711409395973154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13696/60000][Iteration 2452][Wall Clock 252.988200886s] Trained 128 records in 0.080231805 seconds. Throughput is 1595.3772 records/second. Loss is 0.2195212. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067105086565561675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13824/60000][Iteration 2453][Wall Clock 253.08292227s] Trained 128 records in 0.094721384 seconds. Throughput is 1351.3315 records/second. Loss is 0.305413. Sequential31006cbd's hyper parameters: Current learning rate is 0.0067096081588835215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 13952/60000][Iteration 2454][Wall Clock 253.191127974s] Trained 128 records in 0.108205704 seconds. Throughput is 1182.9321 records/second. Loss is 0.24184383. Sequential31006cbd's hyper parameters: Current learning rate is 0.006708707902857909. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 14080/60000][Iteration 2455][Wall Clock 253.272846607s] Trained 128 records in 0.081718633 seconds. Throughput is 1566.3502 records/second. Loss is 0.20451544. Sequential31006cbd's hyper parameters: Current learning rate is 0.006707807888382076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:50 INFO  DistriOptimizer$:408 - [Epoch 6 14208/60000][Iteration 2456][Wall Clock 253.363023282s] Trained 128 records in 0.090176675 seconds. Throughput is 1419.4358 records/second. Loss is 0.2935846. Sequential31006cbd's hyper parameters: Current learning rate is 0.006706908115358819. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 14336/60000][Iteration 2457][Wall Clock 253.448924452s] Trained 128 records in 0.08590117 seconds. Throughput is 1490.0845 records/second. Loss is 0.3093302. Sequential31006cbd's hyper parameters: Current learning rate is 0.006706008583690987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 14464/60000][Iteration 2458][Wall Clock 253.555917846s] Trained 128 records in 0.106993394 seconds. Throughput is 1196.3356 records/second. Loss is 0.25819048. Sequential31006cbd's hyper parameters: Current learning rate is 0.006705109293281481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 14592/60000][Iteration 2459][Wall Clock 253.66751433s] Trained 128 records in 0.111596484 seconds. Throughput is 1146.9895 records/second. Loss is 0.3012841. Sequential31006cbd's hyper parameters: Current learning rate is 0.006704210244033253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 14720/60000][Iteration 2460][Wall Clock 253.754323661s] Trained 128 records in 0.086809331 seconds. Throughput is 1474.4958 records/second. Loss is 0.3203309. Sequential31006cbd's hyper parameters: Current learning rate is 0.00670331143584931. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 14848/60000][Iteration 2461][Wall Clock 253.841571663s] Trained 128 records in 0.087248002 seconds. Throughput is 1467.0823 records/second. Loss is 0.1889896. Sequential31006cbd's hyper parameters: Current learning rate is 0.006702412868632708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 14976/60000][Iteration 2462][Wall Clock 253.925934187s] Trained 128 records in 0.084362524 seconds. Throughput is 1517.2615 records/second. Loss is 0.21754143. Sequential31006cbd's hyper parameters: Current learning rate is 0.006701514542286557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 15104/60000][Iteration 2463][Wall Clock 254.003048598s] Trained 128 records in 0.077114411 seconds. Throughput is 1659.8713 records/second. Loss is 0.23271206. Sequential31006cbd's hyper parameters: Current learning rate is 0.006700616456714018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 15232/60000][Iteration 2464][Wall Clock 254.094550427s] Trained 128 records in 0.091501829 seconds. Throughput is 1398.8792 records/second. Loss is 0.2461085. Sequential31006cbd's hyper parameters: Current learning rate is 0.006699718611818304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 15360/60000][Iteration 2465][Wall Clock 254.189120477s] Trained 128 records in 0.09457005 seconds. Throughput is 1353.494 records/second. Loss is 0.3299675. Sequential31006cbd's hyper parameters: Current learning rate is 0.00669882100750268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 15488/60000][Iteration 2466][Wall Clock 254.276100942s] Trained 128 records in 0.086980465 seconds. Throughput is 1471.5948 records/second. Loss is 0.37690613. Sequential31006cbd's hyper parameters: Current learning rate is 0.006697923643670462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:51 INFO  DistriOptimizer$:408 - [Epoch 6 15616/60000][Iteration 2467][Wall Clock 254.36107279s] Trained 128 records in 0.084971848 seconds. Throughput is 1506.3813 records/second. Loss is 0.42995548. Sequential31006cbd's hyper parameters: Current learning rate is 0.00669702652022502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 15744/60000][Iteration 2468][Wall Clock 254.44601972s] Trained 128 records in 0.08494693 seconds. Throughput is 1506.8231 records/second. Loss is 0.30901375. Sequential31006cbd's hyper parameters: Current learning rate is 0.006696129637069773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 15872/60000][Iteration 2469][Wall Clock 254.5318419s] Trained 128 records in 0.08582218 seconds. Throughput is 1491.4559 records/second. Loss is 0.31833085. Sequential31006cbd's hyper parameters: Current learning rate is 0.006695232994108195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16000/60000][Iteration 2470][Wall Clock 254.616630316s] Trained 128 records in 0.084788416 seconds. Throughput is 1509.6401 records/second. Loss is 0.30889353. Sequential31006cbd's hyper parameters: Current learning rate is 0.006694336591243808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16128/60000][Iteration 2471][Wall Clock 254.698254709s] Trained 128 records in 0.081624393 seconds. Throughput is 1568.1586 records/second. Loss is 0.25969902. Sequential31006cbd's hyper parameters: Current learning rate is 0.006693440428380187. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16256/60000][Iteration 2472][Wall Clock 254.776592302s] Trained 128 records in 0.078337593 seconds. Throughput is 1633.9536 records/second. Loss is 0.31144238. Sequential31006cbd's hyper parameters: Current learning rate is 0.006692544505420961. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16384/60000][Iteration 2473][Wall Clock 254.872744057s] Trained 128 records in 0.096151755 seconds. Throughput is 1331.229 records/second. Loss is 0.50504756. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066916488222698075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16512/60000][Iteration 2474][Wall Clock 254.960800465s] Trained 128 records in 0.088056408 seconds. Throughput is 1453.6136 records/second. Loss is 0.28478223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066907533788304555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16640/60000][Iteration 2475][Wall Clock 255.047878951s] Trained 128 records in 0.087078486 seconds. Throughput is 1469.9382 records/second. Loss is 0.24110839. Sequential31006cbd's hyper parameters: Current learning rate is 0.00668985817500669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16768/60000][Iteration 2476][Wall Clock 255.141404244s] Trained 128 records in 0.093525293 seconds. Throughput is 1368.6138 records/second. Loss is 0.30558708. Sequential31006cbd's hyper parameters: Current learning rate is 0.006688963210702341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 16896/60000][Iteration 2477][Wall Clock 255.233096459s] Trained 128 records in 0.091692215 seconds. Throughput is 1395.9745 records/second. Loss is 0.36107612. Sequential31006cbd's hyper parameters: Current learning rate is 0.006688068485821295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:52 INFO  DistriOptimizer$:408 - [Epoch 6 17024/60000][Iteration 2478][Wall Clock 255.332884986s] Trained 128 records in 0.099788527 seconds. Throughput is 1282.7126 records/second. Loss is 0.3260539. Sequential31006cbd's hyper parameters: Current learning rate is 0.006687174000267487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17152/60000][Iteration 2479][Wall Clock 255.419933165s] Trained 128 records in 0.087048179 seconds. Throughput is 1470.4501 records/second. Loss is 0.28256255. Sequential31006cbd's hyper parameters: Current learning rate is 0.006686279753944905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17280/60000][Iteration 2480][Wall Clock 255.506059603s] Trained 128 records in 0.086126438 seconds. Throughput is 1486.187 records/second. Loss is 0.25364068. Sequential31006cbd's hyper parameters: Current learning rate is 0.006685385746757588. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17408/60000][Iteration 2481][Wall Clock 255.598694734s] Trained 128 records in 0.092635131 seconds. Throughput is 1381.7651 records/second. Loss is 0.37017652. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066844919786096255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17536/60000][Iteration 2482][Wall Clock 255.699854492s] Trained 128 records in 0.101159758 seconds. Throughput is 1265.3253 records/second. Loss is 0.3211865. Sequential31006cbd's hyper parameters: Current learning rate is 0.00668359844940516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17664/60000][Iteration 2483][Wall Clock 255.775855688s] Trained 128 records in 0.076001196 seconds. Throughput is 1684.184 records/second. Loss is 0.4121744. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066827051590483836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17792/60000][Iteration 2484][Wall Clock 255.864019411s] Trained 128 records in 0.088163723 seconds. Throughput is 1451.8442 records/second. Loss is 0.29932052. Sequential31006cbd's hyper parameters: Current learning rate is 0.006681812107443539. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 17920/60000][Iteration 2485][Wall Clock 255.963959872s] Trained 128 records in 0.099940461 seconds. Throughput is 1280.7626 records/second. Loss is 0.32549995. Sequential31006cbd's hyper parameters: Current learning rate is 0.006680919294494923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 18048/60000][Iteration 2486][Wall Clock 256.051772353s] Trained 128 records in 0.087812481 seconds. Throughput is 1457.6515 records/second. Loss is 0.244719. Sequential31006cbd's hyper parameters: Current learning rate is 0.006680026720106881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 18176/60000][Iteration 2487][Wall Clock 256.134922868s] Trained 128 records in 0.083150515 seconds. Throughput is 1539.3772 records/second. Loss is 0.23131818. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066791343841838095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 18304/60000][Iteration 2488][Wall Clock 256.221776388s] Trained 128 records in 0.08685352 seconds. Throughput is 1473.7457 records/second. Loss is 0.21750161. Sequential31006cbd's hyper parameters: Current learning rate is 0.006678242286630159. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:53 INFO  DistriOptimizer$:408 - [Epoch 6 18432/60000][Iteration 2489][Wall Clock 256.309848648s] Trained 128 records in 0.08807226 seconds. Throughput is 1453.352 records/second. Loss is 0.26009583. Sequential31006cbd's hyper parameters: Current learning rate is 0.006677350427350427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 18560/60000][Iteration 2490][Wall Clock 256.433867948s] Trained 128 records in 0.1240193 seconds. Throughput is 1032.0974 records/second. Loss is 0.2255024. Sequential31006cbd's hyper parameters: Current learning rate is 0.006676458806249165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 18688/60000][Iteration 2491][Wall Clock 256.524593514s] Trained 128 records in 0.090725566 seconds. Throughput is 1410.8483 records/second. Loss is 0.33148158. Sequential31006cbd's hyper parameters: Current learning rate is 0.006675567423230975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 18816/60000][Iteration 2492][Wall Clock 256.625417269s] Trained 128 records in 0.100823755 seconds. Throughput is 1269.5421 records/second. Loss is 0.39728767. Sequential31006cbd's hyper parameters: Current learning rate is 0.006674676278200508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 18944/60000][Iteration 2493][Wall Clock 256.709083478s] Trained 128 records in 0.083666209 seconds. Throughput is 1529.8889 records/second. Loss is 0.20182574. Sequential31006cbd's hyper parameters: Current learning rate is 0.006673785371062467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 19072/60000][Iteration 2494][Wall Clock 256.789481348s] Trained 128 records in 0.08039787 seconds. Throughput is 1592.082 records/second. Loss is 0.26205522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066728947017216066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 19200/60000][Iteration 2495][Wall Clock 256.866634022s] Trained 128 records in 0.077152674 seconds. Throughput is 1659.0481 records/second. Loss is 0.402609. Sequential31006cbd's hyper parameters: Current learning rate is 0.006672004270082733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 19328/60000][Iteration 2496][Wall Clock 256.953756671s] Trained 128 records in 0.087122649 seconds. Throughput is 1469.1931 records/second. Loss is 0.21923567. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066711140760507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 19456/60000][Iteration 2497][Wall Clock 257.038418787s] Trained 128 records in 0.084662116 seconds. Throughput is 1511.8922 records/second. Loss is 0.23100446. Sequential31006cbd's hyper parameters: Current learning rate is 0.006670224119530416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:54 INFO  DistriOptimizer$:408 - [Epoch 6 19584/60000][Iteration 2498][Wall Clock 257.112397739s] Trained 128 records in 0.073978952 seconds. Throughput is 1730.2218 records/second. Loss is 0.21757029. Sequential31006cbd's hyper parameters: Current learning rate is 0.006669334400426837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 19712/60000][Iteration 2499][Wall Clock 257.457292897s] Trained 128 records in 0.344895158 seconds. Throughput is 371.1273 records/second. Loss is 0.43058932. Sequential31006cbd's hyper parameters: Current learning rate is 0.006668444918644972. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 19840/60000][Iteration 2500][Wall Clock 257.545110554s] Trained 128 records in 0.087817657 seconds. Throughput is 1457.5657 records/second. Loss is 0.25642645. Sequential31006cbd's hyper parameters: Current learning rate is 0.006667555674089879. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 19968/60000][Iteration 2501][Wall Clock 257.627801581s] Trained 128 records in 0.082691027 seconds. Throughput is 1547.9309 records/second. Loss is 0.22771476. Sequential31006cbd's hyper parameters: Current learning rate is 0.006666666666666667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20096/60000][Iteration 2502][Wall Clock 257.718527611s] Trained 128 records in 0.09072603 seconds. Throughput is 1410.841 records/second. Loss is 0.3221377. Sequential31006cbd's hyper parameters: Current learning rate is 0.006665777896280496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20224/60000][Iteration 2503][Wall Clock 257.798958942s] Trained 128 records in 0.080431331 seconds. Throughput is 1591.4196 records/second. Loss is 0.2584396. Sequential31006cbd's hyper parameters: Current learning rate is 0.006664889362836577. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20352/60000][Iteration 2504][Wall Clock 257.878392997s] Trained 128 records in 0.079434055 seconds. Throughput is 1611.3997 records/second. Loss is 0.26583377. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066640010662401715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20480/60000][Iteration 2505][Wall Clock 257.966769188s] Trained 128 records in 0.088376191 seconds. Throughput is 1448.3539 records/second. Loss is 0.26895863. Sequential31006cbd's hyper parameters: Current learning rate is 0.006663113006396589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20608/60000][Iteration 2506][Wall Clock 258.053969959s] Trained 128 records in 0.087200771 seconds. Throughput is 1467.877 records/second. Loss is 0.21278267. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066622251832111935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20736/60000][Iteration 2507][Wall Clock 258.133237698s] Trained 128 records in 0.079267739 seconds. Throughput is 1614.7805 records/second. Loss is 0.24881151. Sequential31006cbd's hyper parameters: Current learning rate is 0.006661337596589396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20864/60000][Iteration 2508][Wall Clock 258.216942831s] Trained 128 records in 0.083705133 seconds. Throughput is 1529.1774 records/second. Loss is 0.2735414. Sequential31006cbd's hyper parameters: Current learning rate is 0.006660450246436659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:55 INFO  DistriOptimizer$:408 - [Epoch 6 20992/60000][Iteration 2509][Wall Clock 258.298476664s] Trained 128 records in 0.081533833 seconds. Throughput is 1569.9004 records/second. Loss is 0.33616617. Sequential31006cbd's hyper parameters: Current learning rate is 0.006659563132658497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21120/60000][Iteration 2510][Wall Clock 258.379562981s] Trained 128 records in 0.081086317 seconds. Throughput is 1578.5648 records/second. Loss is 0.31131294. Sequential31006cbd's hyper parameters: Current learning rate is 0.006658676255160474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21248/60000][Iteration 2511][Wall Clock 258.453877655s] Trained 128 records in 0.074314674 seconds. Throughput is 1722.4054 records/second. Loss is 0.26467222. Sequential31006cbd's hyper parameters: Current learning rate is 0.006657789613848202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21376/60000][Iteration 2512][Wall Clock 258.53719133s] Trained 128 records in 0.083313675 seconds. Throughput is 1536.3624 records/second. Loss is 0.26779082. Sequential31006cbd's hyper parameters: Current learning rate is 0.006656903208627347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21504/60000][Iteration 2513][Wall Clock 258.643114322s] Trained 128 records in 0.105922992 seconds. Throughput is 1208.425 records/second. Loss is 0.28170222. Sequential31006cbd's hyper parameters: Current learning rate is 0.00665601703940362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21632/60000][Iteration 2514][Wall Clock 258.760296902s] Trained 128 records in 0.11718258 seconds. Throughput is 1092.3125 records/second. Loss is 0.2024717. Sequential31006cbd's hyper parameters: Current learning rate is 0.006655131106082789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21760/60000][Iteration 2515][Wall Clock 258.870345684s] Trained 128 records in 0.110048782 seconds. Throughput is 1163.1206 records/second. Loss is 0.25094038. Sequential31006cbd's hyper parameters: Current learning rate is 0.006654245408570667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 21888/60000][Iteration 2516][Wall Clock 258.952276494s] Trained 128 records in 0.08193081 seconds. Throughput is 1562.2938 records/second. Loss is 0.30440837. Sequential31006cbd's hyper parameters: Current learning rate is 0.00665335994677312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 22016/60000][Iteration 2517][Wall Clock 259.040499747s] Trained 128 records in 0.088223253 seconds. Throughput is 1450.8646 records/second. Loss is 0.3205042. Sequential31006cbd's hyper parameters: Current learning rate is 0.006652474720596061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 22144/60000][Iteration 2518][Wall Clock 259.122922904s] Trained 128 records in 0.082423157 seconds. Throughput is 1552.9615 records/second. Loss is 0.33791536. Sequential31006cbd's hyper parameters: Current learning rate is 0.006651589729945457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 22272/60000][Iteration 2519][Wall Clock 259.200454145s] Trained 128 records in 0.077531241 seconds. Throughput is 1650.9474 records/second. Loss is 0.28689876. Sequential31006cbd's hyper parameters: Current learning rate is 0.006650704974727321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:56 INFO  DistriOptimizer$:408 - [Epoch 6 22400/60000][Iteration 2520][Wall Clock 259.292527903s] Trained 128 records in 0.092073758 seconds. Throughput is 1390.1898 records/second. Loss is 0.27378255. Sequential31006cbd's hyper parameters: Current learning rate is 0.006649820454847719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 22528/60000][Iteration 2521][Wall Clock 259.389846152s] Trained 128 records in 0.097318249 seconds. Throughput is 1315.2723 records/second. Loss is 0.29053983. Sequential31006cbd's hyper parameters: Current learning rate is 0.006648936170212766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 22656/60000][Iteration 2522][Wall Clock 259.468635356s] Trained 128 records in 0.078789204 seconds. Throughput is 1624.588 records/second. Loss is 0.30592388. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066480521207286265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 22784/60000][Iteration 2523][Wall Clock 259.557447649s] Trained 128 records in 0.088812293 seconds. Throughput is 1441.242 records/second. Loss is 0.41157174. Sequential31006cbd's hyper parameters: Current learning rate is 0.006647168306301516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 22912/60000][Iteration 2524][Wall Clock 259.660351198s] Trained 128 records in 0.102903549 seconds. Throughput is 1243.8832 records/second. Loss is 0.22370146. Sequential31006cbd's hyper parameters: Current learning rate is 0.006646284726837698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23040/60000][Iteration 2525][Wall Clock 259.775345851s] Trained 128 records in 0.114994653 seconds. Throughput is 1113.0952 records/second. Loss is 0.38275188. Sequential31006cbd's hyper parameters: Current learning rate is 0.006645401382243488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23168/60000][Iteration 2526][Wall Clock 259.859343274s] Trained 128 records in 0.083997423 seconds. Throughput is 1523.8563 records/second. Loss is 0.20961821. Sequential31006cbd's hyper parameters: Current learning rate is 0.00664451827242525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23296/60000][Iteration 2527][Wall Clock 259.934102013s] Trained 128 records in 0.074758739 seconds. Throughput is 1712.1744 records/second. Loss is 0.29200676. Sequential31006cbd's hyper parameters: Current learning rate is 0.006643635397289398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23424/60000][Iteration 2528][Wall Clock 260.013365565s] Trained 128 records in 0.079263552 seconds. Throughput is 1614.8658 records/second. Loss is 0.22314362. Sequential31006cbd's hyper parameters: Current learning rate is 0.006642752756742394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23552/60000][Iteration 2529][Wall Clock 260.094758128s] Trained 128 records in 0.081392563 seconds. Throughput is 1572.6252 records/second. Loss is 0.2634475. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066418703506907545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23680/60000][Iteration 2530][Wall Clock 260.174346667s] Trained 128 records in 0.079588539 seconds. Throughput is 1608.2717 records/second. Loss is 0.3144506. Sequential31006cbd's hyper parameters: Current learning rate is 0.006640988179041041. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:57 INFO  DistriOptimizer$:408 - [Epoch 6 23808/60000][Iteration 2531][Wall Clock 260.25779747s] Trained 128 records in 0.083450803 seconds. Throughput is 1533.8379 records/second. Loss is 0.28404284. Sequential31006cbd's hyper parameters: Current learning rate is 0.006640106241699867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 23936/60000][Iteration 2532][Wall Clock 260.354376408s] Trained 128 records in 0.096578938 seconds. Throughput is 1325.3407 records/second. Loss is 0.251873. Sequential31006cbd's hyper parameters: Current learning rate is 0.006639224538573895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24064/60000][Iteration 2533][Wall Clock 260.433391623s] Trained 128 records in 0.079015215 seconds. Throughput is 1619.9412 records/second. Loss is 0.32517606. Sequential31006cbd's hyper parameters: Current learning rate is 0.006638343069569835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24192/60000][Iteration 2534][Wall Clock 260.51871468s] Trained 128 records in 0.085323057 seconds. Throughput is 1500.1807 records/second. Loss is 0.31539962. Sequential31006cbd's hyper parameters: Current learning rate is 0.006637461834594451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24320/60000][Iteration 2535][Wall Clock 260.607425099s] Trained 128 records in 0.088710419 seconds. Throughput is 1442.897 records/second. Loss is 0.24041279. Sequential31006cbd's hyper parameters: Current learning rate is 0.006636580833554552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24448/60000][Iteration 2536][Wall Clock 260.704399345s] Trained 128 records in 0.096974246 seconds. Throughput is 1319.9381 records/second. Loss is 0.33340538. Sequential31006cbd's hyper parameters: Current learning rate is 0.006635700066357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24576/60000][Iteration 2537][Wall Clock 260.828490316s] Trained 128 records in 0.124090971 seconds. Throughput is 1031.5013 records/second. Loss is 0.27544382. Sequential31006cbd's hyper parameters: Current learning rate is 0.006634819532908704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24704/60000][Iteration 2538][Wall Clock 260.920947955s] Trained 128 records in 0.092457639 seconds. Throughput is 1384.4178 records/second. Loss is 0.30106738. Sequential31006cbd's hyper parameters: Current learning rate is 0.006633939233116624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24832/60000][Iteration 2539][Wall Clock 261.036537326s] Trained 128 records in 0.115589371 seconds. Throughput is 1107.3683 records/second. Loss is 0.3427988. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066330591668877685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 24960/60000][Iteration 2540][Wall Clock 261.137641299s] Trained 128 records in 0.101103973 seconds. Throughput is 1266.0234 records/second. Loss is 0.18352076. Sequential31006cbd's hyper parameters: Current learning rate is 0.006632179334129195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:58 INFO  DistriOptimizer$:408 - [Epoch 6 25088/60000][Iteration 2541][Wall Clock 261.22800721s] Trained 128 records in 0.090365911 seconds. Throughput is 1416.4634 records/second. Loss is 0.3036116. Sequential31006cbd's hyper parameters: Current learning rate is 0.006631299734748011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25216/60000][Iteration 2542][Wall Clock 261.339645802s] Trained 128 records in 0.111638592 seconds. Throughput is 1146.5569 records/second. Loss is 0.34735185. Sequential31006cbd's hyper parameters: Current learning rate is 0.006630420368651373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25344/60000][Iteration 2543][Wall Clock 261.442617422s] Trained 128 records in 0.10297162 seconds. Throughput is 1243.0609 records/second. Loss is 0.30852073. Sequential31006cbd's hyper parameters: Current learning rate is 0.006629541235746487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25472/60000][Iteration 2544][Wall Clock 261.530422757s] Trained 128 records in 0.087805335 seconds. Throughput is 1457.7701 records/second. Loss is 0.3238088. Sequential31006cbd's hyper parameters: Current learning rate is 0.006628662335940607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25600/60000][Iteration 2545][Wall Clock 261.613755754s] Trained 128 records in 0.083332997 seconds. Throughput is 1536.0061 records/second. Loss is 0.2586773. Sequential31006cbd's hyper parameters: Current learning rate is 0.006627783669141039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25728/60000][Iteration 2546][Wall Clock 261.695616557s] Trained 128 records in 0.081860803 seconds. Throughput is 1563.6299 records/second. Loss is 0.24461062. Sequential31006cbd's hyper parameters: Current learning rate is 0.006626905235255136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25856/60000][Iteration 2547][Wall Clock 261.78727457s] Trained 128 records in 0.091658013 seconds. Throughput is 1396.4955 records/second. Loss is 0.19367363. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066260270341903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 25984/60000][Iteration 2548][Wall Clock 261.896240755s] Trained 128 records in 0.108966185 seconds. Throughput is 1174.6763 records/second. Loss is 0.29927945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066251490658539814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 26112/60000][Iteration 2549][Wall Clock 261.982146355s] Trained 128 records in 0.0859056 seconds. Throughput is 1490.0077 records/second. Loss is 0.21420538. Sequential31006cbd's hyper parameters: Current learning rate is 0.006624271330153683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 26240/60000][Iteration 2550][Wall Clock 262.081643583s] Trained 128 records in 0.099497228 seconds. Throughput is 1286.468 records/second. Loss is 0.23206855. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066233938269969535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 26368/60000][Iteration 2551][Wall Clock 262.178250323s] Trained 128 records in 0.09660674 seconds. Throughput is 1324.9594 records/second. Loss is 0.40624702. Sequential31006cbd's hyper parameters: Current learning rate is 0.006622516556291391. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:01:59 INFO  DistriOptimizer$:408 - [Epoch 6 26496/60000][Iteration 2552][Wall Clock 262.260896724s] Trained 128 records in 0.082646401 seconds. Throughput is 1548.7668 records/second. Loss is 0.2965058. Sequential31006cbd's hyper parameters: Current learning rate is 0.006621639517944643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 26624/60000][Iteration 2553][Wall Clock 262.339292502s] Trained 128 records in 0.078395778 seconds. Throughput is 1632.741 records/second. Loss is 0.25992247. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066207627118644065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 26752/60000][Iteration 2554][Wall Clock 262.437825068s] Trained 128 records in 0.098532566 seconds. Throughput is 1299.0629 records/second. Loss is 0.18850209. Sequential31006cbd's hyper parameters: Current learning rate is 0.006619886137958426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 26880/60000][Iteration 2555][Wall Clock 262.52235565s] Trained 128 records in 0.084530582 seconds. Throughput is 1514.2449 records/second. Loss is 0.22200419. Sequential31006cbd's hyper parameters: Current learning rate is 0.006619009796134498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27008/60000][Iteration 2556][Wall Clock 262.618922098s] Trained 128 records in 0.096566448 seconds. Throughput is 1325.5122 records/second. Loss is 0.32082435. Sequential31006cbd's hyper parameters: Current learning rate is 0.006618133686300463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27136/60000][Iteration 2557][Wall Clock 262.713294719s] Trained 128 records in 0.094372621 seconds. Throughput is 1356.3256 records/second. Loss is 0.19451457. Sequential31006cbd's hyper parameters: Current learning rate is 0.006617257808364214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27264/60000][Iteration 2558][Wall Clock 262.806976408s] Trained 128 records in 0.093681689 seconds. Throughput is 1366.329 records/second. Loss is 0.22881934. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066163821622336905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27392/60000][Iteration 2559][Wall Clock 262.909042623s] Trained 128 records in 0.102066215 seconds. Throughput is 1254.0879 records/second. Loss is 0.25307515. Sequential31006cbd's hyper parameters: Current learning rate is 0.006615506747816882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27520/60000][Iteration 2560][Wall Clock 262.989216733s] Trained 128 records in 0.08017411 seconds. Throughput is 1596.5254 records/second. Loss is 0.29506132. Sequential31006cbd's hyper parameters: Current learning rate is 0.006614631565021828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27648/60000][Iteration 2561][Wall Clock 263.071952317s] Trained 128 records in 0.082735584 seconds. Throughput is 1547.0973 records/second. Loss is 0.25298372. Sequential31006cbd's hyper parameters: Current learning rate is 0.006613756613756614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27776/60000][Iteration 2562][Wall Clock 263.161967477s] Trained 128 records in 0.09001516 seconds. Throughput is 1421.9828 records/second. Loss is 0.22856528. Sequential31006cbd's hyper parameters: Current learning rate is 0.006612881893929374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:00 INFO  DistriOptimizer$:408 - [Epoch 6 27904/60000][Iteration 2563][Wall Clock 263.240044665s] Trained 128 records in 0.078077188 seconds. Throughput is 1639.4033 records/second. Loss is 0.24025506. Sequential31006cbd's hyper parameters: Current learning rate is 0.006612007405448294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28032/60000][Iteration 2564][Wall Clock 263.349382973s] Trained 128 records in 0.109338308 seconds. Throughput is 1170.6785 records/second. Loss is 0.23417392. Sequential31006cbd's hyper parameters: Current learning rate is 0.006611133148221606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28160/60000][Iteration 2565][Wall Clock 263.450196462s] Trained 128 records in 0.100813489 seconds. Throughput is 1269.6714 records/second. Loss is 0.3326202. Sequential31006cbd's hyper parameters: Current learning rate is 0.006610259122157589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28288/60000][Iteration 2566][Wall Clock 263.534448968s] Trained 128 records in 0.084252506 seconds. Throughput is 1519.2427 records/second. Loss is 0.2635428. Sequential31006cbd's hyper parameters: Current learning rate is 0.006609385327164575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28416/60000][Iteration 2567][Wall Clock 263.618238481s] Trained 128 records in 0.083789513 seconds. Throughput is 1527.6375 records/second. Loss is 0.26135233. Sequential31006cbd's hyper parameters: Current learning rate is 0.006608511763150939. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28544/60000][Iteration 2568][Wall Clock 263.698373153s] Trained 128 records in 0.080134672 seconds. Throughput is 1597.311 records/second. Loss is 0.28362292. Sequential31006cbd's hyper parameters: Current learning rate is 0.006607638430025109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28672/60000][Iteration 2569][Wall Clock 263.786553046s] Trained 128 records in 0.088179893 seconds. Throughput is 1451.5781 records/second. Loss is 0.21367286. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066067653276955605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28800/60000][Iteration 2570][Wall Clock 263.87775003s] Trained 128 records in 0.091196984 seconds. Throughput is 1403.5552 records/second. Loss is 0.28397685. Sequential31006cbd's hyper parameters: Current learning rate is 0.006605892456070815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 28928/60000][Iteration 2571][Wall Clock 263.975425388s] Trained 128 records in 0.097675358 seconds. Throughput is 1310.4635 records/second. Loss is 0.30368006. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066050198150594455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 29056/60000][Iteration 2572][Wall Clock 264.062525142s] Trained 128 records in 0.087099754 seconds. Throughput is 1469.5793 records/second. Loss is 0.25607425. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066041474045700705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 29184/60000][Iteration 2573][Wall Clock 264.150301407s] Trained 128 records in 0.087776265 seconds. Throughput is 1458.2529 records/second. Loss is 0.35995066. Sequential31006cbd's hyper parameters: Current learning rate is 0.006603275224511357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:01 INFO  DistriOptimizer$:408 - [Epoch 6 29312/60000][Iteration 2574][Wall Clock 264.237115063s] Trained 128 records in 0.086813656 seconds. Throughput is 1474.4224 records/second. Loss is 0.2817243. Sequential31006cbd's hyper parameters: Current learning rate is 0.006602403274792024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 29440/60000][Iteration 2575][Wall Clock 264.330058303s] Trained 128 records in 0.09294324 seconds. Throughput is 1377.1846 records/second. Loss is 0.2369523. Sequential31006cbd's hyper parameters: Current learning rate is 0.006601531555320834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 29568/60000][Iteration 2576][Wall Clock 264.452374971s] Trained 128 records in 0.122316668 seconds. Throughput is 1046.4641 records/second. Loss is 0.22208402. Sequential31006cbd's hyper parameters: Current learning rate is 0.0066006600660066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 29696/60000][Iteration 2577][Wall Clock 264.547180061s] Trained 128 records in 0.09480509 seconds. Throughput is 1350.1384 records/second. Loss is 0.2633389. Sequential31006cbd's hyper parameters: Current learning rate is 0.006599788806758183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 29824/60000][Iteration 2578][Wall Clock 264.627986609s] Trained 128 records in 0.080806548 seconds. Throughput is 1584.03 records/second. Loss is 0.28385156. Sequential31006cbd's hyper parameters: Current learning rate is 0.006598917777484493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 29952/60000][Iteration 2579][Wall Clock 264.71589173s] Trained 128 records in 0.087905121 seconds. Throughput is 1456.1154 records/second. Loss is 0.27924362. Sequential31006cbd's hyper parameters: Current learning rate is 0.006598046978094484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 30080/60000][Iteration 2580][Wall Clock 264.834470833s] Trained 128 records in 0.118579103 seconds. Throughput is 1079.4482 records/second. Loss is 0.22148797. Sequential31006cbd's hyper parameters: Current learning rate is 0.006597176408497163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 30208/60000][Iteration 2581][Wall Clock 264.931589534s] Trained 128 records in 0.097118701 seconds. Throughput is 1317.9749 records/second. Loss is 0.19946316. Sequential31006cbd's hyper parameters: Current learning rate is 0.006596306068601583. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 30336/60000][Iteration 2582][Wall Clock 265.022379368s] Trained 128 records in 0.090789834 seconds. Throughput is 1409.8495 records/second. Loss is 0.28819942. Sequential31006cbd's hyper parameters: Current learning rate is 0.006595435958316845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 30464/60000][Iteration 2583][Wall Clock 265.112384176s] Trained 128 records in 0.090004808 seconds. Throughput is 1422.1462 records/second. Loss is 0.24443755. Sequential31006cbd's hyper parameters: Current learning rate is 0.006594566077552097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 30592/60000][Iteration 2584][Wall Clock 265.202058161s] Trained 128 records in 0.089673985 seconds. Throughput is 1427.3927 records/second. Loss is 0.22752029. Sequential31006cbd's hyper parameters: Current learning rate is 0.006593696426216537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:02 INFO  DistriOptimizer$:408 - [Epoch 6 30720/60000][Iteration 2585][Wall Clock 265.281266599s] Trained 128 records in 0.079208438 seconds. Throughput is 1615.9894 records/second. Loss is 0.28036508. Sequential31006cbd's hyper parameters: Current learning rate is 0.006592827004219409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 30848/60000][Iteration 2586][Wall Clock 265.377878591s] Trained 128 records in 0.096611992 seconds. Throughput is 1324.8873 records/second. Loss is 0.24546003. Sequential31006cbd's hyper parameters: Current learning rate is 0.006591957811470007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 30976/60000][Iteration 2587][Wall Clock 265.462770339s] Trained 128 records in 0.084891748 seconds. Throughput is 1507.8026 records/second. Loss is 0.2649271. Sequential31006cbd's hyper parameters: Current learning rate is 0.00659108884787767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31104/60000][Iteration 2588][Wall Clock 265.560394973s] Trained 128 records in 0.097624634 seconds. Throughput is 1311.1444 records/second. Loss is 0.25876832. Sequential31006cbd's hyper parameters: Current learning rate is 0.006590220113351787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31232/60000][Iteration 2589][Wall Clock 265.662170922s] Trained 128 records in 0.101775949 seconds. Throughput is 1257.6644 records/second. Loss is 0.26930594. Sequential31006cbd's hyper parameters: Current learning rate is 0.006589351607801792. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31360/60000][Iteration 2590][Wall Clock 265.750471884s] Trained 128 records in 0.088300962 seconds. Throughput is 1449.5879 records/second. Loss is 0.20842624. Sequential31006cbd's hyper parameters: Current learning rate is 0.006588483331137172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31488/60000][Iteration 2591][Wall Clock 265.865164437s] Trained 128 records in 0.114692553 seconds. Throughput is 1116.0271 records/second. Loss is 0.24422692. Sequential31006cbd's hyper parameters: Current learning rate is 0.006587615283267457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31616/60000][Iteration 2592][Wall Clock 265.95284429s] Trained 128 records in 0.087679853 seconds. Throughput is 1459.8564 records/second. Loss is 0.19103505. Sequential31006cbd's hyper parameters: Current learning rate is 0.006586747464102227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31744/60000][Iteration 2593][Wall Clock 266.03490345s] Trained 128 records in 0.08205916 seconds. Throughput is 1559.8502 records/second. Loss is 0.2983866. Sequential31006cbd's hyper parameters: Current learning rate is 0.006585879873551107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 31872/60000][Iteration 2594][Wall Clock 266.133906839s] Trained 128 records in 0.099003389 seconds. Throughput is 1292.885 records/second. Loss is 0.31823164. Sequential31006cbd's hyper parameters: Current learning rate is 0.006585012511523772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:03 INFO  DistriOptimizer$:408 - [Epoch 6 32000/60000][Iteration 2595][Wall Clock 266.227510627s] Trained 128 records in 0.093603788 seconds. Throughput is 1367.466 records/second. Loss is 0.28257582. Sequential31006cbd's hyper parameters: Current learning rate is 0.006584145377929944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32128/60000][Iteration 2596][Wall Clock 266.315399397s] Trained 128 records in 0.08788877 seconds. Throughput is 1456.3864 records/second. Loss is 0.2962361. Sequential31006cbd's hyper parameters: Current learning rate is 0.006583278472679394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32256/60000][Iteration 2597][Wall Clock 266.403869562s] Trained 128 records in 0.088470165 seconds. Throughput is 1446.8154 records/second. Loss is 0.27807084. Sequential31006cbd's hyper parameters: Current learning rate is 0.006582411795681938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32384/60000][Iteration 2598][Wall Clock 266.503696475s] Trained 128 records in 0.099826913 seconds. Throughput is 1282.2194 records/second. Loss is 0.27409562. Sequential31006cbd's hyper parameters: Current learning rate is 0.00658154534684744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32512/60000][Iteration 2599][Wall Clock 266.611568763s] Trained 128 records in 0.107872288 seconds. Throughput is 1186.5884 records/second. Loss is 0.39129588. Sequential31006cbd's hyper parameters: Current learning rate is 0.006580679126085812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32640/60000][Iteration 2600][Wall Clock 266.719266134s] Trained 128 records in 0.107697371 seconds. Throughput is 1188.5156 records/second. Loss is 0.3736245. Sequential31006cbd's hyper parameters: Current learning rate is 0.006579813133307014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32768/60000][Iteration 2601][Wall Clock 266.825733816s] Trained 128 records in 0.106467682 seconds. Throughput is 1202.2428 records/second. Loss is 0.42057148. Sequential31006cbd's hyper parameters: Current learning rate is 0.006578947368421052. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 32896/60000][Iteration 2602][Wall Clock 266.955899479s] Trained 128 records in 0.130165663 seconds. Throughput is 983.36224 records/second. Loss is 0.33265945. Sequential31006cbd's hyper parameters: Current learning rate is 0.006578081831337982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 33024/60000][Iteration 2603][Wall Clock 267.079327138s] Trained 128 records in 0.123427659 seconds. Throughput is 1037.0447 records/second. Loss is 0.2749138. Sequential31006cbd's hyper parameters: Current learning rate is 0.006577216521967903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:04 INFO  DistriOptimizer$:408 - [Epoch 6 33152/60000][Iteration 2604][Wall Clock 267.178980538s] Trained 128 records in 0.0996534 seconds. Throughput is 1284.4519 records/second. Loss is 0.29159588. Sequential31006cbd's hyper parameters: Current learning rate is 0.006576351440220966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 33280/60000][Iteration 2605][Wall Clock 267.283359895s] Trained 128 records in 0.104379357 seconds. Throughput is 1226.2961 records/second. Loss is 0.21460997. Sequential31006cbd's hyper parameters: Current learning rate is 0.006575486586007365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 33408/60000][Iteration 2606][Wall Clock 267.387027354s] Trained 128 records in 0.103667459 seconds. Throughput is 1234.7173 records/second. Loss is 0.31231913. Sequential31006cbd's hyper parameters: Current learning rate is 0.006574621959237344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 33536/60000][Iteration 2607][Wall Clock 267.465045977s] Trained 128 records in 0.078018623 seconds. Throughput is 1640.634 records/second. Loss is 0.1784448. Sequential31006cbd's hyper parameters: Current learning rate is 0.006573757559821194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 33664/60000][Iteration 2608][Wall Clock 267.546567182s] Trained 128 records in 0.081521205 seconds. Throughput is 1570.1436 records/second. Loss is 0.3277265. Sequential31006cbd's hyper parameters: Current learning rate is 0.006572893387669252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 33792/60000][Iteration 2609][Wall Clock 267.625014329s] Trained 128 records in 0.078447147 seconds. Throughput is 1631.6718 records/second. Loss is 0.24913616. Sequential31006cbd's hyper parameters: Current learning rate is 0.006572029442691903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 33920/60000][Iteration 2610][Wall Clock 267.707913224s] Trained 128 records in 0.082898895 seconds. Throughput is 1544.0496 records/second. Loss is 0.34643105. Sequential31006cbd's hyper parameters: Current learning rate is 0.006571165724799579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 34048/60000][Iteration 2611][Wall Clock 267.79357347s] Trained 128 records in 0.085660246 seconds. Throughput is 1494.2754 records/second. Loss is 0.32652515. Sequential31006cbd's hyper parameters: Current learning rate is 0.006570302233902759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 34176/60000][Iteration 2612][Wall Clock 267.875335652s] Trained 128 records in 0.081762182 seconds. Throughput is 1565.516 records/second. Loss is 0.36568764. Sequential31006cbd's hyper parameters: Current learning rate is 0.00656943896991197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 34304/60000][Iteration 2613][Wall Clock 267.962805117s] Trained 128 records in 0.087469465 seconds. Throughput is 1463.3678 records/second. Loss is 0.38759544. Sequential31006cbd's hyper parameters: Current learning rate is 0.006568575932737783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 34432/60000][Iteration 2614][Wall Clock 268.055352489s] Trained 128 records in 0.092547372 seconds. Throughput is 1383.0754 records/second. Loss is 0.26718813. Sequential31006cbd's hyper parameters: Current learning rate is 0.006567713122290817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 34560/60000][Iteration 2615][Wall Clock 268.157564876s] Trained 128 records in 0.102212387 seconds. Throughput is 1252.2944 records/second. Loss is 0.30272582. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065668505384817435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:05 INFO  DistriOptimizer$:408 - [Epoch 6 34688/60000][Iteration 2616][Wall Clock 268.251280918s] Trained 128 records in 0.093716042 seconds. Throughput is 1365.8281 records/second. Loss is 0.18885368. Sequential31006cbd's hyper parameters: Current learning rate is 0.006565988181221273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 34816/60000][Iteration 2617][Wall Clock 268.333033941s] Trained 128 records in 0.081753023 seconds. Throughput is 1565.6913 records/second. Loss is 0.20526542. Sequential31006cbd's hyper parameters: Current learning rate is 0.006565126050420168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 34944/60000][Iteration 2618][Wall Clock 268.411408696s] Trained 128 records in 0.078374755 seconds. Throughput is 1633.1788 records/second. Loss is 0.31320882. Sequential31006cbd's hyper parameters: Current learning rate is 0.006564264145989235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35072/60000][Iteration 2619][Wall Clock 268.506057913s] Trained 128 records in 0.094649217 seconds. Throughput is 1352.3619 records/second. Loss is 0.42791256. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065634024678393275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35200/60000][Iteration 2620][Wall Clock 268.608859248s] Trained 128 records in 0.102801335 seconds. Throughput is 1245.12 records/second. Loss is 0.26644182. Sequential31006cbd's hyper parameters: Current learning rate is 0.006562541015881349. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35328/60000][Iteration 2621][Wall Clock 268.705757856s] Trained 128 records in 0.096898608 seconds. Throughput is 1320.9684 records/second. Loss is 0.3559782. Sequential31006cbd's hyper parameters: Current learning rate is 0.006561679790026247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35456/60000][Iteration 2622][Wall Clock 268.829684168s] Trained 128 records in 0.123926312 seconds. Throughput is 1032.8718 records/second. Loss is 0.2563479. Sequential31006cbd's hyper parameters: Current learning rate is 0.006560818790185015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35584/60000][Iteration 2623][Wall Clock 268.919240704s] Trained 128 records in 0.089556536 seconds. Throughput is 1429.2648 records/second. Loss is 0.32009858. Sequential31006cbd's hyper parameters: Current learning rate is 0.006559958016268696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35712/60000][Iteration 2624][Wall Clock 269.0008297s] Trained 128 records in 0.081588996 seconds. Throughput is 1568.839 records/second. Loss is 0.3386319. Sequential31006cbd's hyper parameters: Current learning rate is 0.006559097468188378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35840/60000][Iteration 2625][Wall Clock 269.083216977s] Trained 128 records in 0.082387277 seconds. Throughput is 1553.638 records/second. Loss is 0.36752263. Sequential31006cbd's hyper parameters: Current learning rate is 0.006558237145855195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 35968/60000][Iteration 2626][Wall Clock 269.169502181s] Trained 128 records in 0.086285204 seconds. Throughput is 1483.4525 records/second. Loss is 0.2745341. Sequential31006cbd's hyper parameters: Current learning rate is 0.006557377049180329. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:06 INFO  DistriOptimizer$:408 - [Epoch 6 36096/60000][Iteration 2627][Wall Clock 269.258604767s] Trained 128 records in 0.089102586 seconds. Throughput is 1436.5464 records/second. Loss is 0.32005972. Sequential31006cbd's hyper parameters: Current learning rate is 0.006556517178075007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36224/60000][Iteration 2628][Wall Clock 269.345574304s] Trained 128 records in 0.086969537 seconds. Throughput is 1471.7797 records/second. Loss is 0.3373364. Sequential31006cbd's hyper parameters: Current learning rate is 0.006555657532450506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36352/60000][Iteration 2629][Wall Clock 269.422511357s] Trained 128 records in 0.076937053 seconds. Throughput is 1663.6978 records/second. Loss is 0.33768797. Sequential31006cbd's hyper parameters: Current learning rate is 0.006554798112218143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36480/60000][Iteration 2630][Wall Clock 269.513634758s] Trained 128 records in 0.091123401 seconds. Throughput is 1404.6886 records/second. Loss is 0.3143124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006553938917289291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36608/60000][Iteration 2631][Wall Clock 269.596309129s] Trained 128 records in 0.082674371 seconds. Throughput is 1548.2428 records/second. Loss is 0.17064059. Sequential31006cbd's hyper parameters: Current learning rate is 0.00655307994757536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36736/60000][Iteration 2632][Wall Clock 269.674919638s] Trained 128 records in 0.078610509 seconds. Throughput is 1628.281 records/second. Loss is 0.30286932. Sequential31006cbd's hyper parameters: Current learning rate is 0.006552221202987813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36864/60000][Iteration 2633][Wall Clock 269.757857515s] Trained 128 records in 0.082937877 seconds. Throughput is 1543.3239 records/second. Loss is 0.25172672. Sequential31006cbd's hyper parameters: Current learning rate is 0.006551362683438156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 36992/60000][Iteration 2634][Wall Clock 269.849614436s] Trained 128 records in 0.091756921 seconds. Throughput is 1394.9902 records/second. Loss is 0.2621874. Sequential31006cbd's hyper parameters: Current learning rate is 0.00655050438883794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 37120/60000][Iteration 2635][Wall Clock 269.926262344s] Trained 128 records in 0.076647908 seconds. Throughput is 1669.9739 records/second. Loss is 0.32222697. Sequential31006cbd's hyper parameters: Current learning rate is 0.006549646319098768. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 37248/60000][Iteration 2636][Wall Clock 270.008437184s] Trained 128 records in 0.08217484 seconds. Throughput is 1557.6544 records/second. Loss is 0.33637875. Sequential31006cbd's hyper parameters: Current learning rate is 0.006548788474132285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 37376/60000][Iteration 2637][Wall Clock 270.096439669s] Trained 128 records in 0.088002485 seconds. Throughput is 1454.5043 records/second. Loss is 0.21993633. Sequential31006cbd's hyper parameters: Current learning rate is 0.006547930853850183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:07 INFO  DistriOptimizer$:408 - [Epoch 6 37504/60000][Iteration 2638][Wall Clock 270.189902498s] Trained 128 records in 0.093462829 seconds. Throughput is 1369.5283 records/second. Loss is 0.26027647. Sequential31006cbd's hyper parameters: Current learning rate is 0.006547073458164201. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 37632/60000][Iteration 2639][Wall Clock 270.28224294s] Trained 128 records in 0.092340442 seconds. Throughput is 1386.1749 records/second. Loss is 0.2126055. Sequential31006cbd's hyper parameters: Current learning rate is 0.006546216286986122. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 37760/60000][Iteration 2640][Wall Clock 270.387138769s] Trained 128 records in 0.104895829 seconds. Throughput is 1220.2582 records/second. Loss is 0.31011894. Sequential31006cbd's hyper parameters: Current learning rate is 0.006545359340227779. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 37888/60000][Iteration 2641][Wall Clock 270.473457901s] Trained 128 records in 0.086319132 seconds. Throughput is 1482.8694 records/second. Loss is 0.2747762. Sequential31006cbd's hyper parameters: Current learning rate is 0.006544502617801047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38016/60000][Iteration 2642][Wall Clock 270.561590441s] Trained 128 records in 0.08813254 seconds. Throughput is 1452.358 records/second. Loss is 0.23456986. Sequential31006cbd's hyper parameters: Current learning rate is 0.006543646119617851. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38144/60000][Iteration 2643][Wall Clock 270.662694036s] Trained 128 records in 0.101103595 seconds. Throughput is 1266.0282 records/second. Loss is 0.21019262. Sequential31006cbd's hyper parameters: Current learning rate is 0.00654278984559016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38272/60000][Iteration 2644][Wall Clock 270.740074733s] Trained 128 records in 0.077380697 seconds. Throughput is 1654.1593 records/second. Loss is 0.3525039. Sequential31006cbd's hyper parameters: Current learning rate is 0.006541933795629989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38400/60000][Iteration 2645][Wall Clock 270.821098437s] Trained 128 records in 0.081023704 seconds. Throughput is 1579.7847 records/second. Loss is 0.3012614. Sequential31006cbd's hyper parameters: Current learning rate is 0.006541077969649398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38528/60000][Iteration 2646][Wall Clock 270.906274925s] Trained 128 records in 0.085176488 seconds. Throughput is 1502.7621 records/second. Loss is 0.22174391. Sequential31006cbd's hyper parameters: Current learning rate is 0.006540222367560498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38656/60000][Iteration 2647][Wall Clock 270.991009458s] Trained 128 records in 0.084734533 seconds. Throughput is 1510.6001 records/second. Loss is 0.21038124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006539366989275439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38784/60000][Iteration 2648][Wall Clock 271.069931799s] Trained 128 records in 0.078922341 seconds. Throughput is 1621.8475 records/second. Loss is 0.27682337. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065385118347064215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 38912/60000][Iteration 2649][Wall Clock 271.147444166s] Trained 128 records in 0.077512367 seconds. Throughput is 1651.3494 records/second. Loss is 0.232283. Sequential31006cbd's hyper parameters: Current learning rate is 0.00653765690376569. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:08 INFO  DistriOptimizer$:408 - [Epoch 6 39040/60000][Iteration 2650][Wall Clock 271.226889475s] Trained 128 records in 0.079445309 seconds. Throughput is 1611.1713 records/second. Loss is 0.29447314. Sequential31006cbd's hyper parameters: Current learning rate is 0.006536802196365538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39168/60000][Iteration 2651][Wall Clock 271.332892794s] Trained 128 records in 0.106003319 seconds. Throughput is 1207.5093 records/second. Loss is 0.29411635. Sequential31006cbd's hyper parameters: Current learning rate is 0.006535947712418301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39296/60000][Iteration 2652][Wall Clock 271.4258261s] Trained 128 records in 0.092933306 seconds. Throughput is 1377.3318 records/second. Loss is 0.3383611. Sequential31006cbd's hyper parameters: Current learning rate is 0.006535093451836361. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39424/60000][Iteration 2653][Wall Clock 271.520198084s] Trained 128 records in 0.094371984 seconds. Throughput is 1356.3347 records/second. Loss is 0.315114. Sequential31006cbd's hyper parameters: Current learning rate is 0.006534239414532149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39552/60000][Iteration 2654][Wall Clock 271.624796953s] Trained 128 records in 0.104598869 seconds. Throughput is 1223.7225 records/second. Loss is 0.24267025. Sequential31006cbd's hyper parameters: Current learning rate is 0.006533385600418136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39680/60000][Iteration 2655][Wall Clock 271.741464294s] Trained 128 records in 0.116667341 seconds. Throughput is 1097.1366 records/second. Loss is 0.28624937. Sequential31006cbd's hyper parameters: Current learning rate is 0.006532532009406846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39808/60000][Iteration 2656][Wall Clock 271.824675798s] Trained 128 records in 0.083211504 seconds. Throughput is 1538.2489 records/second. Loss is 0.245946. Sequential31006cbd's hyper parameters: Current learning rate is 0.006531678641410842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 39936/60000][Iteration 2657][Wall Clock 271.913287095s] Trained 128 records in 0.088611297 seconds. Throughput is 1444.5111 records/second. Loss is 0.3008466. Sequential31006cbd's hyper parameters: Current learning rate is 0.006530825496342737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 40064/60000][Iteration 2658][Wall Clock 272.004898502s] Trained 128 records in 0.091611407 seconds. Throughput is 1397.2059 records/second. Loss is 0.32763758. Sequential31006cbd's hyper parameters: Current learning rate is 0.006529972574115189. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 40192/60000][Iteration 2659][Wall Clock 272.087652392s] Trained 128 records in 0.08275389 seconds. Throughput is 1546.7551 records/second. Loss is 0.21093318. Sequential31006cbd's hyper parameters: Current learning rate is 0.006529119874640899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:09 INFO  DistriOptimizer$:408 - [Epoch 6 40320/60000][Iteration 2660][Wall Clock 272.171257223s] Trained 128 records in 0.083604831 seconds. Throughput is 1531.0121 records/second. Loss is 0.2886363. Sequential31006cbd's hyper parameters: Current learning rate is 0.006528267397832615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 40448/60000][Iteration 2661][Wall Clock 272.25721153s] Trained 128 records in 0.085954307 seconds. Throughput is 1489.1633 records/second. Loss is 0.30564126. Sequential31006cbd's hyper parameters: Current learning rate is 0.006527415143603133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 40576/60000][Iteration 2662][Wall Clock 272.345578015s] Trained 128 records in 0.088366485 seconds. Throughput is 1448.513 records/second. Loss is 0.243345. Sequential31006cbd's hyper parameters: Current learning rate is 0.006526563111865292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 40704/60000][Iteration 2663][Wall Clock 272.475086014s] Trained 128 records in 0.129507999 seconds. Throughput is 988.3559 records/second. Loss is 0.27202058. Sequential31006cbd's hyper parameters: Current learning rate is 0.006525711302531976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 40832/60000][Iteration 2664][Wall Clock 272.590926151s] Trained 128 records in 0.115840137 seconds. Throughput is 1104.9711 records/second. Loss is 0.30628654. Sequential31006cbd's hyper parameters: Current learning rate is 0.006524859715516117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 40960/60000][Iteration 2665][Wall Clock 272.689336499s] Trained 128 records in 0.098410348 seconds. Throughput is 1300.6763 records/second. Loss is 0.19779503. Sequential31006cbd's hyper parameters: Current learning rate is 0.00652400835073069. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 41088/60000][Iteration 2666][Wall Clock 272.81658543s] Trained 128 records in 0.127248931 seconds. Throughput is 1005.9024 records/second. Loss is 0.17106603. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065231572080887154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 41216/60000][Iteration 2667][Wall Clock 272.926133299s] Trained 128 records in 0.109547869 seconds. Throughput is 1168.439 records/second. Loss is 0.23811989. Sequential31006cbd's hyper parameters: Current learning rate is 0.006522306287503262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 41344/60000][Iteration 2668][Wall Clock 273.013215877s] Trained 128 records in 0.087082578 seconds. Throughput is 1469.8691 records/second. Loss is 0.14347446. Sequential31006cbd's hyper parameters: Current learning rate is 0.00652145558888744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 41472/60000][Iteration 2669][Wall Clock 273.107257595s] Trained 128 records in 0.094041718 seconds. Throughput is 1361.098 records/second. Loss is 0.30104813. Sequential31006cbd's hyper parameters: Current learning rate is 0.006520605112154408. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:10 INFO  DistriOptimizer$:408 - [Epoch 6 41600/60000][Iteration 2670][Wall Clock 273.1935756s] Trained 128 records in 0.086318005 seconds. Throughput is 1482.8887 records/second. Loss is 0.20506714. Sequential31006cbd's hyper parameters: Current learning rate is 0.006519754857217368. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 41728/60000][Iteration 2671][Wall Clock 273.302433788s] Trained 128 records in 0.108858188 seconds. Throughput is 1175.8417 records/second. Loss is 0.2907254. Sequential31006cbd's hyper parameters: Current learning rate is 0.00651890482398957. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 41856/60000][Iteration 2672][Wall Clock 273.388250359s] Trained 128 records in 0.085816571 seconds. Throughput is 1491.5535 records/second. Loss is 0.17693047. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065180550123843045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 41984/60000][Iteration 2673][Wall Clock 273.478991722s] Trained 128 records in 0.090741363 seconds. Throughput is 1410.6025 records/second. Loss is 0.2523697. Sequential31006cbd's hyper parameters: Current learning rate is 0.006517205422314911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42112/60000][Iteration 2674][Wall Clock 273.58243832s] Trained 128 records in 0.103446598 seconds. Throughput is 1237.3534 records/second. Loss is 0.26092544. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065163560536947735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42240/60000][Iteration 2675][Wall Clock 273.675350524s] Trained 128 records in 0.092912204 seconds. Throughput is 1377.6447 records/second. Loss is 0.37054873. Sequential31006cbd's hyper parameters: Current learning rate is 0.00651550690643732. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42368/60000][Iteration 2676][Wall Clock 273.774028234s] Trained 128 records in 0.09867771 seconds. Throughput is 1297.1521 records/second. Loss is 0.3012741. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065146579804560255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42496/60000][Iteration 2677][Wall Clock 273.867179454s] Trained 128 records in 0.09315122 seconds. Throughput is 1374.1097 records/second. Loss is 0.25457692. Sequential31006cbd's hyper parameters: Current learning rate is 0.006513809275664409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42624/60000][Iteration 2678][Wall Clock 273.961511688s] Trained 128 records in 0.094332234 seconds. Throughput is 1356.9062 records/second. Loss is 0.20938241. Sequential31006cbd's hyper parameters: Current learning rate is 0.006512960791976032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42752/60000][Iteration 2679][Wall Clock 274.045336072s] Trained 128 records in 0.083824384 seconds. Throughput is 1527.0021 records/second. Loss is 0.18239348. Sequential31006cbd's hyper parameters: Current learning rate is 0.006512112529304506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:11 INFO  DistriOptimizer$:408 - [Epoch 6 42880/60000][Iteration 2680][Wall Clock 274.179303704s] Trained 128 records in 0.133967632 seconds. Throughput is 955.45465 records/second. Loss is 0.302671. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065112644875634845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43008/60000][Iteration 2681][Wall Clock 274.270035382s] Trained 128 records in 0.090731678 seconds. Throughput is 1410.753 records/second. Loss is 0.31227356. Sequential31006cbd's hyper parameters: Current learning rate is 0.006510416666666667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43136/60000][Iteration 2682][Wall Clock 274.411518764s] Trained 128 records in 0.141483382 seconds. Throughput is 904.6999 records/second. Loss is 0.2005826. Sequential31006cbd's hyper parameters: Current learning rate is 0.006509569066527796. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43264/60000][Iteration 2683][Wall Clock 274.505932415s] Trained 128 records in 0.094413651 seconds. Throughput is 1355.7361 records/second. Loss is 0.22960804. Sequential31006cbd's hyper parameters: Current learning rate is 0.006508721687060661. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43392/60000][Iteration 2684][Wall Clock 274.595222628s] Trained 128 records in 0.089290213 seconds. Throughput is 1433.5277 records/second. Loss is 0.1940354. Sequential31006cbd's hyper parameters: Current learning rate is 0.006507874528179097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43520/60000][Iteration 2685][Wall Clock 274.684160077s] Trained 128 records in 0.088937449 seconds. Throughput is 1439.2137 records/second. Loss is 0.2569516. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065070275897969815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43648/60000][Iteration 2686][Wall Clock 274.771328482s] Trained 128 records in 0.087168405 seconds. Throughput is 1468.422 records/second. Loss is 0.23909432. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065061808718282375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43776/60000][Iteration 2687][Wall Clock 274.864926599s] Trained 128 records in 0.093598117 seconds. Throughput is 1367.5488 records/second. Loss is 0.21875763. Sequential31006cbd's hyper parameters: Current learning rate is 0.006505334374186834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 43904/60000][Iteration 2688][Wall Clock 274.967058767s] Trained 128 records in 0.102132168 seconds. Throughput is 1253.278 records/second. Loss is 0.26761836. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065044880967867836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 44032/60000][Iteration 2689][Wall Clock 275.069348731s] Trained 128 records in 0.102289964 seconds. Throughput is 1251.3446 records/second. Loss is 0.20006204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065036420395421434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:12 INFO  DistriOptimizer$:408 - [Epoch 6 44160/60000][Iteration 2690][Wall Clock 275.168943253s] Trained 128 records in 0.099594522 seconds. Throughput is 1285.2113 records/second. Loss is 0.3152455. Sequential31006cbd's hyper parameters: Current learning rate is 0.006502796202367018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 44288/60000][Iteration 2691][Wall Clock 275.298810043s] Trained 128 records in 0.12986679 seconds. Throughput is 985.6253 records/second. Loss is 0.2920077. Sequential31006cbd's hyper parameters: Current learning rate is 0.006501950585175552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 44416/60000][Iteration 2692][Wall Clock 275.421308073s] Trained 128 records in 0.12249803 seconds. Throughput is 1044.9148 records/second. Loss is 0.3050915. Sequential31006cbd's hyper parameters: Current learning rate is 0.00650110518788194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 44544/60000][Iteration 2693][Wall Clock 275.522414162s] Trained 128 records in 0.101106089 seconds. Throughput is 1265.997 records/second. Loss is 0.29655558. Sequential31006cbd's hyper parameters: Current learning rate is 0.0065002600104004165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 44672/60000][Iteration 2694][Wall Clock 275.622417332s] Trained 128 records in 0.10000317 seconds. Throughput is 1279.9595 records/second. Loss is 0.33267504. Sequential31006cbd's hyper parameters: Current learning rate is 0.006499415052645261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 44800/60000][Iteration 2695][Wall Clock 275.722058949s] Trained 128 records in 0.099641617 seconds. Throughput is 1284.6039 records/second. Loss is 0.34701845. Sequential31006cbd's hyper parameters: Current learning rate is 0.006498570314530803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 44928/60000][Iteration 2696][Wall Clock 275.830258358s] Trained 128 records in 0.108199409 seconds. Throughput is 1183.0009 records/second. Loss is 0.27176628. Sequential31006cbd's hyper parameters: Current learning rate is 0.00649772579597141. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 45056/60000][Iteration 2697][Wall Clock 275.946005667s] Trained 128 records in 0.115747309 seconds. Throughput is 1105.8572 records/second. Loss is 0.37155414. Sequential31006cbd's hyper parameters: Current learning rate is 0.006496881496881496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 45184/60000][Iteration 2698][Wall Clock 276.057962187s] Trained 128 records in 0.11195652 seconds. Throughput is 1143.301 records/second. Loss is 0.19383636. Sequential31006cbd's hyper parameters: Current learning rate is 0.006496037417175523. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:13 INFO  DistriOptimizer$:408 - [Epoch 6 45312/60000][Iteration 2699][Wall Clock 276.192912996s] Trained 128 records in 0.134950809 seconds. Throughput is 948.49384 records/second. Loss is 0.24276996. Sequential31006cbd's hyper parameters: Current learning rate is 0.006495193556767992. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 45440/60000][Iteration 2700][Wall Clock 276.272408674s] Trained 128 records in 0.079495678 seconds. Throughput is 1610.1505 records/second. Loss is 0.20483884. Sequential31006cbd's hyper parameters: Current learning rate is 0.006494349915573451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 45568/60000][Iteration 2701][Wall Clock 276.354034413s] Trained 128 records in 0.081625739 seconds. Throughput is 1568.1328 records/second. Loss is 0.36306733. Sequential31006cbd's hyper parameters: Current learning rate is 0.006493506493506493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 45696/60000][Iteration 2702][Wall Clock 276.433626352s] Trained 128 records in 0.079591939 seconds. Throughput is 1608.2031 records/second. Loss is 0.31361043. Sequential31006cbd's hyper parameters: Current learning rate is 0.006492663290481756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 45824/60000][Iteration 2703][Wall Clock 276.518619238s] Trained 128 records in 0.084992886 seconds. Throughput is 1506.0084 records/second. Loss is 0.43164504. Sequential31006cbd's hyper parameters: Current learning rate is 0.006491820306413918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 45952/60000][Iteration 2704][Wall Clock 276.607253161s] Trained 128 records in 0.088633923 seconds. Throughput is 1444.1423 records/second. Loss is 0.41260162. Sequential31006cbd's hyper parameters: Current learning rate is 0.006490977541217708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46080/60000][Iteration 2705][Wall Clock 276.686606066s] Trained 128 records in 0.079352905 seconds. Throughput is 1613.0474 records/second. Loss is 0.26969287. Sequential31006cbd's hyper parameters: Current learning rate is 0.006490134994807892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46208/60000][Iteration 2706][Wall Clock 276.796397629s] Trained 128 records in 0.109791563 seconds. Throughput is 1165.8455 records/second. Loss is 0.21568593. Sequential31006cbd's hyper parameters: Current learning rate is 0.006489292667099286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46336/60000][Iteration 2707][Wall Clock 276.876881261s] Trained 128 records in 0.080483632 seconds. Throughput is 1590.3855 records/second. Loss is 0.2857826. Sequential31006cbd's hyper parameters: Current learning rate is 0.006488450558006748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46464/60000][Iteration 2708][Wall Clock 276.957304788s] Trained 128 records in 0.080423527 seconds. Throughput is 1591.5741 records/second. Loss is 0.20474678. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064876086674451805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46592/60000][Iteration 2709][Wall Clock 277.037349137s] Trained 128 records in 0.080044349 seconds. Throughput is 1599.1134 records/second. Loss is 0.29659724. Sequential31006cbd's hyper parameters: Current learning rate is 0.006486766995329528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46720/60000][Iteration 2710][Wall Clock 277.129958443s] Trained 128 records in 0.092609306 seconds. Throughput is 1382.1505 records/second. Loss is 0.38737532. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064859255415747824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:14 INFO  DistriOptimizer$:408 - [Epoch 6 46848/60000][Iteration 2711][Wall Clock 277.218060061s] Trained 128 records in 0.088101618 seconds. Throughput is 1452.8678 records/second. Loss is 0.30187172. Sequential31006cbd's hyper parameters: Current learning rate is 0.00648508430609598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 46976/60000][Iteration 2712][Wall Clock 277.311567519s] Trained 128 records in 0.093507458 seconds. Throughput is 1368.8748 records/second. Loss is 0.26763678. Sequential31006cbd's hyper parameters: Current learning rate is 0.006484243288808196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47104/60000][Iteration 2713][Wall Clock 277.393362247s] Trained 128 records in 0.081794728 seconds. Throughput is 1564.893 records/second. Loss is 0.33748916. Sequential31006cbd's hyper parameters: Current learning rate is 0.006483402489626556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47232/60000][Iteration 2714][Wall Clock 277.482717823s] Trained 128 records in 0.089355576 seconds. Throughput is 1432.4792 records/second. Loss is 0.3176086. Sequential31006cbd's hyper parameters: Current learning rate is 0.006482561908466226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47360/60000][Iteration 2715][Wall Clock 277.582701998s] Trained 128 records in 0.099984175 seconds. Throughput is 1280.2025 records/second. Loss is 0.20247841. Sequential31006cbd's hyper parameters: Current learning rate is 0.006481721545242416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47488/60000][Iteration 2716][Wall Clock 277.679593261s] Trained 128 records in 0.096891263 seconds. Throughput is 1321.0686 records/second. Loss is 0.2081284. Sequential31006cbd's hyper parameters: Current learning rate is 0.006480881399870382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47616/60000][Iteration 2717][Wall Clock 277.77389028s] Trained 128 records in 0.094297019 seconds. Throughput is 1357.413 records/second. Loss is 0.26589656. Sequential31006cbd's hyper parameters: Current learning rate is 0.006480041472265422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47744/60000][Iteration 2718][Wall Clock 277.861614251s] Trained 128 records in 0.087723971 seconds. Throughput is 1459.1223 records/second. Loss is 0.27828583. Sequential31006cbd's hyper parameters: Current learning rate is 0.006479201762342879. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 47872/60000][Iteration 2719][Wall Clock 277.949192957s] Trained 128 records in 0.087578706 seconds. Throughput is 1461.5425 records/second. Loss is 0.21589677. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064783622700181395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 48000/60000][Iteration 2720][Wall Clock 278.041236182s] Trained 128 records in 0.092043225 seconds. Throughput is 1390.6509 records/second. Loss is 0.29071254. Sequential31006cbd's hyper parameters: Current learning rate is 0.006477522995206633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 48128/60000][Iteration 2721][Wall Clock 278.122664521s] Trained 128 records in 0.081428339 seconds. Throughput is 1571.9342 records/second. Loss is 0.31838295. Sequential31006cbd's hyper parameters: Current learning rate is 0.006476683937823834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:15 INFO  DistriOptimizer$:408 - [Epoch 6 48256/60000][Iteration 2722][Wall Clock 278.223067597s] Trained 128 records in 0.100403076 seconds. Throughput is 1274.8613 records/second. Loss is 0.2562019. Sequential31006cbd's hyper parameters: Current learning rate is 0.006475845097785261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 48384/60000][Iteration 2723][Wall Clock 278.318773973s] Trained 128 records in 0.095706376 seconds. Throughput is 1337.424 records/second. Loss is 0.24699655. Sequential31006cbd's hyper parameters: Current learning rate is 0.006475006475006475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 48512/60000][Iteration 2724][Wall Clock 278.403672598s] Trained 128 records in 0.084898625 seconds. Throughput is 1507.6804 records/second. Loss is 0.34683895. Sequential31006cbd's hyper parameters: Current learning rate is 0.006474168069403082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 48640/60000][Iteration 2725][Wall Clock 278.503175901s] Trained 128 records in 0.099503303 seconds. Throughput is 1286.3895 records/second. Loss is 0.17928073. Sequential31006cbd's hyper parameters: Current learning rate is 0.006473329880890731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 48768/60000][Iteration 2726][Wall Clock 278.588569459s] Trained 128 records in 0.085393558 seconds. Throughput is 1498.9421 records/second. Loss is 0.32266486. Sequential31006cbd's hyper parameters: Current learning rate is 0.006472491909385114. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 48896/60000][Iteration 2727][Wall Clock 278.669702402s] Trained 128 records in 0.081132943 seconds. Throughput is 1577.6576 records/second. Loss is 0.29896203. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064716541548019675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 49024/60000][Iteration 2728][Wall Clock 278.748727573s] Trained 128 records in 0.079025171 seconds. Throughput is 1619.737 records/second. Loss is 0.29036605. Sequential31006cbd's hyper parameters: Current learning rate is 0.006470816617057073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 49152/60000][Iteration 2729][Wall Clock 278.829638508s] Trained 128 records in 0.080910935 seconds. Throughput is 1581.9865 records/second. Loss is 0.18331717. Sequential31006cbd's hyper parameters: Current learning rate is 0.006469979296066253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 49280/60000][Iteration 2730][Wall Clock 278.911057548s] Trained 128 records in 0.08141904 seconds. Throughput is 1572.1138 records/second. Loss is 0.24810857. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064691421917453746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 49408/60000][Iteration 2731][Wall Clock 278.995453909s] Trained 128 records in 0.084396361 seconds. Throughput is 1516.6531 records/second. Loss is 0.21829972. Sequential31006cbd's hyper parameters: Current learning rate is 0.00646830530401035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 49536/60000][Iteration 2732][Wall Clock 279.095185051s] Trained 128 records in 0.099731142 seconds. Throughput is 1283.4507 records/second. Loss is 0.2766377. Sequential31006cbd's hyper parameters: Current learning rate is 0.006467468632777131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:16 INFO  DistriOptimizer$:408 - [Epoch 6 49664/60000][Iteration 2733][Wall Clock 279.20444132s] Trained 128 records in 0.109256269 seconds. Throughput is 1171.5575 records/second. Loss is 0.22313847. Sequential31006cbd's hyper parameters: Current learning rate is 0.006466632177961717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 49792/60000][Iteration 2734][Wall Clock 279.301419733s] Trained 128 records in 0.096978413 seconds. Throughput is 1319.8813 records/second. Loss is 0.36684364. Sequential31006cbd's hyper parameters: Current learning rate is 0.006465795939480151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 49920/60000][Iteration 2735][Wall Clock 279.394627395s] Trained 128 records in 0.093207662 seconds. Throughput is 1373.2776 records/second. Loss is 0.263397. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064649599172485125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50048/60000][Iteration 2736][Wall Clock 279.492591356s] Trained 128 records in 0.097963961 seconds. Throughput is 1306.603 records/second. Loss is 0.3436371. Sequential31006cbd's hyper parameters: Current learning rate is 0.006464124111182934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50176/60000][Iteration 2737][Wall Clock 279.601222971s] Trained 128 records in 0.108631615 seconds. Throughput is 1178.2942 records/second. Loss is 0.33544114. Sequential31006cbd's hyper parameters: Current learning rate is 0.006463288521199586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50304/60000][Iteration 2738][Wall Clock 279.718492125s] Trained 128 records in 0.117269154 seconds. Throughput is 1091.5061 records/second. Loss is 0.20571704. Sequential31006cbd's hyper parameters: Current learning rate is 0.006462453147214682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50432/60000][Iteration 2739][Wall Clock 279.830395539s] Trained 128 records in 0.111903414 seconds. Throughput is 1143.8435 records/second. Loss is 0.24861364. Sequential31006cbd's hyper parameters: Current learning rate is 0.006461617989144482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50560/60000][Iteration 2740][Wall Clock 279.938418092s] Trained 128 records in 0.108022553 seconds. Throughput is 1184.9377 records/second. Loss is 0.18212533. Sequential31006cbd's hyper parameters: Current learning rate is 0.006460783046905285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50688/60000][Iteration 2741][Wall Clock 280.050867072s] Trained 128 records in 0.11244898 seconds. Throughput is 1138.294 records/second. Loss is 0.2468406. Sequential31006cbd's hyper parameters: Current learning rate is 0.006459948320413436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:17 INFO  DistriOptimizer$:408 - [Epoch 6 50816/60000][Iteration 2742][Wall Clock 280.168944143s] Trained 128 records in 0.118077071 seconds. Throughput is 1084.0377 records/second. Loss is 0.4017653. Sequential31006cbd's hyper parameters: Current learning rate is 0.006459113809585325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 50944/60000][Iteration 2743][Wall Clock 280.286347156s] Trained 128 records in 0.117403013 seconds. Throughput is 1090.2616 records/second. Loss is 0.21728228. Sequential31006cbd's hyper parameters: Current learning rate is 0.006458279514337381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51072/60000][Iteration 2744][Wall Clock 280.368636762s] Trained 128 records in 0.082289606 seconds. Throughput is 1555.4819 records/second. Loss is 0.27648893. Sequential31006cbd's hyper parameters: Current learning rate is 0.006457445434586078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51200/60000][Iteration 2745][Wall Clock 280.450282861s] Trained 128 records in 0.081646099 seconds. Throughput is 1567.7417 records/second. Loss is 0.38112548. Sequential31006cbd's hyper parameters: Current learning rate is 0.006456611570247934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51328/60000][Iteration 2746][Wall Clock 280.535867509s] Trained 128 records in 0.085584648 seconds. Throughput is 1495.5953 records/second. Loss is 0.20797531. Sequential31006cbd's hyper parameters: Current learning rate is 0.006455777921239509. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51456/60000][Iteration 2747][Wall Clock 280.618970527s] Trained 128 records in 0.083103018 seconds. Throughput is 1540.257 records/second. Loss is 0.26476985. Sequential31006cbd's hyper parameters: Current learning rate is 0.006454944487477408. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51584/60000][Iteration 2748][Wall Clock 280.696827274s] Trained 128 records in 0.077856747 seconds. Throughput is 1644.045 records/second. Loss is 0.24835655. Sequential31006cbd's hyper parameters: Current learning rate is 0.006454111268878276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51712/60000][Iteration 2749][Wall Clock 280.781929505s] Trained 128 records in 0.085102231 seconds. Throughput is 1504.0734 records/second. Loss is 0.31115454. Sequential31006cbd's hyper parameters: Current learning rate is 0.006453278265358803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51840/60000][Iteration 2750][Wall Clock 280.884348387s] Trained 128 records in 0.102418882 seconds. Throughput is 1249.7695 records/second. Loss is 0.25067875. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064524454768357204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 51968/60000][Iteration 2751][Wall Clock 280.964303628s] Trained 128 records in 0.079955241 seconds. Throughput is 1600.8956 records/second. Loss is 0.25768363. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064516129032258064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 52096/60000][Iteration 2752][Wall Clock 281.08102581s] Trained 128 records in 0.116722182 seconds. Throughput is 1096.6211 records/second. Loss is 0.28775263. Sequential31006cbd's hyper parameters: Current learning rate is 0.006450780544445878. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:18 INFO  DistriOptimizer$:408 - [Epoch 6 52224/60000][Iteration 2753][Wall Clock 281.169662353s] Trained 128 records in 0.088636543 seconds. Throughput is 1444.0997 records/second. Loss is 0.30004635. Sequential31006cbd's hyper parameters: Current learning rate is 0.006449948400412797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 52352/60000][Iteration 2754][Wall Clock 281.253457051s] Trained 128 records in 0.083794698 seconds. Throughput is 1527.543 records/second. Loss is 0.2355277. Sequential31006cbd's hyper parameters: Current learning rate is 0.006449116471043468. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 52480/60000][Iteration 2755][Wall Clock 281.335574571s] Trained 128 records in 0.08211752 seconds. Throughput is 1558.7417 records/second. Loss is 0.22598523. Sequential31006cbd's hyper parameters: Current learning rate is 0.006448284756254836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 52608/60000][Iteration 2756][Wall Clock 281.424152909s] Trained 128 records in 0.088578338 seconds. Throughput is 1445.0486 records/second. Loss is 0.27011162. Sequential31006cbd's hyper parameters: Current learning rate is 0.006447453255963894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 52736/60000][Iteration 2757][Wall Clock 281.510095453s] Trained 128 records in 0.085942544 seconds. Throughput is 1489.3672 records/second. Loss is 0.20486279. Sequential31006cbd's hyper parameters: Current learning rate is 0.006446621970087674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 52864/60000][Iteration 2758][Wall Clock 281.607675138s] Trained 128 records in 0.097579685 seconds. Throughput is 1311.7484 records/second. Loss is 0.25758347. Sequential31006cbd's hyper parameters: Current learning rate is 0.006445790898543251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 52992/60000][Iteration 2759][Wall Clock 281.707569914s] Trained 128 records in 0.099894776 seconds. Throughput is 1281.3483 records/second. Loss is 0.3435668. Sequential31006cbd's hyper parameters: Current learning rate is 0.006444960041247744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 53120/60000][Iteration 2760][Wall Clock 281.792289729s] Trained 128 records in 0.084719815 seconds. Throughput is 1510.8627 records/second. Loss is 0.18909039. Sequential31006cbd's hyper parameters: Current learning rate is 0.006444129398118314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 53248/60000][Iteration 2761][Wall Clock 281.886332002s] Trained 128 records in 0.094042273 seconds. Throughput is 1361.0901 records/second. Loss is 0.29997063. Sequential31006cbd's hyper parameters: Current learning rate is 0.006443298969072165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 53376/60000][Iteration 2762][Wall Clock 281.978967501s] Trained 128 records in 0.092635499 seconds. Throughput is 1381.7598 records/second. Loss is 0.29404384. Sequential31006cbd's hyper parameters: Current learning rate is 0.006442468754026543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 53504/60000][Iteration 2763][Wall Clock 282.063117231s] Trained 128 records in 0.08414973 seconds. Throughput is 1521.0981 records/second. Loss is 0.31404757. Sequential31006cbd's hyper parameters: Current learning rate is 0.006441638752898738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:19 INFO  DistriOptimizer$:408 - [Epoch 6 53632/60000][Iteration 2764][Wall Clock 282.143287532s] Trained 128 records in 0.080170301 seconds. Throughput is 1596.6012 records/second. Loss is 0.28526816. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064408089656060805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 53760/60000][Iteration 2765][Wall Clock 282.227758683s] Trained 128 records in 0.084471151 seconds. Throughput is 1515.3102 records/second. Loss is 0.18447956. Sequential31006cbd's hyper parameters: Current learning rate is 0.006439979392065946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 53888/60000][Iteration 2766][Wall Clock 282.315808502s] Trained 128 records in 0.088049819 seconds. Throughput is 1453.7224 records/second. Loss is 0.26103324. Sequential31006cbd's hyper parameters: Current learning rate is 0.006439150032195751. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54016/60000][Iteration 2767][Wall Clock 282.403495306s] Trained 128 records in 0.087686804 seconds. Throughput is 1459.7407 records/second. Loss is 0.20642444. Sequential31006cbd's hyper parameters: Current learning rate is 0.006438320885912954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54144/60000][Iteration 2768][Wall Clock 282.497543405s] Trained 128 records in 0.094048099 seconds. Throughput is 1361.0057 records/second. Loss is 0.15804887. Sequential31006cbd's hyper parameters: Current learning rate is 0.006437491953135059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54272/60000][Iteration 2769][Wall Clock 282.590307227s] Trained 128 records in 0.092763822 seconds. Throughput is 1379.8483 records/second. Loss is 0.3696058. Sequential31006cbd's hyper parameters: Current learning rate is 0.006436663233779609. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54400/60000][Iteration 2770][Wall Clock 282.685921746s] Trained 128 records in 0.095614519 seconds. Throughput is 1338.7087 records/second. Loss is 0.22988194. Sequential31006cbd's hyper parameters: Current learning rate is 0.006435834727764191. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54528/60000][Iteration 2771][Wall Clock 282.776929698s] Trained 128 records in 0.091007952 seconds. Throughput is 1406.4705 records/second. Loss is 0.20390594. Sequential31006cbd's hyper parameters: Current learning rate is 0.006435006435006435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54656/60000][Iteration 2772][Wall Clock 282.870304095s] Trained 128 records in 0.093374397 seconds. Throughput is 1370.8254 records/second. Loss is 0.31410408. Sequential31006cbd's hyper parameters: Current learning rate is 0.006434178355424013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54784/60000][Iteration 2773][Wall Clock 282.967702799s] Trained 128 records in 0.097398704 seconds. Throughput is 1314.1858 records/second. Loss is 0.30676067. Sequential31006cbd's hyper parameters: Current learning rate is 0.006433350488934638. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 54912/60000][Iteration 2774][Wall Clock 283.046682791s] Trained 128 records in 0.078979992 seconds. Throughput is 1620.6637 records/second. Loss is 0.18878484. Sequential31006cbd's hyper parameters: Current learning rate is 0.006432522835456066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 55040/60000][Iteration 2775][Wall Clock 283.122956217s] Trained 128 records in 0.076273426 seconds. Throughput is 1678.173 records/second. Loss is 0.31991813. Sequential31006cbd's hyper parameters: Current learning rate is 0.006431695394906097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:20 INFO  DistriOptimizer$:408 - [Epoch 6 55168/60000][Iteration 2776][Wall Clock 283.201978214s] Trained 128 records in 0.079021997 seconds. Throughput is 1619.8021 records/second. Loss is 0.2913259. Sequential31006cbd's hyper parameters: Current learning rate is 0.006430868167202571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 55296/60000][Iteration 2777][Wall Clock 283.286273316s] Trained 128 records in 0.084295102 seconds. Throughput is 1518.475 records/second. Loss is 0.14491454. Sequential31006cbd's hyper parameters: Current learning rate is 0.006430041152263374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 55424/60000][Iteration 2778][Wall Clock 283.380653571s] Trained 128 records in 0.094380255 seconds. Throughput is 1356.216 records/second. Loss is 0.2798018. Sequential31006cbd's hyper parameters: Current learning rate is 0.006429214350006429. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 55552/60000][Iteration 2779][Wall Clock 283.471845955s] Trained 128 records in 0.091192384 seconds. Throughput is 1403.626 records/second. Loss is 0.30888712. Sequential31006cbd's hyper parameters: Current learning rate is 0.006428387760349704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 55680/60000][Iteration 2780][Wall Clock 283.55967715s] Trained 128 records in 0.087831195 seconds. Throughput is 1457.3411 records/second. Loss is 0.22876377. Sequential31006cbd's hyper parameters: Current learning rate is 0.006427561383211209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 55808/60000][Iteration 2781][Wall Clock 283.651373677s] Trained 128 records in 0.091696527 seconds. Throughput is 1395.9088 records/second. Loss is 0.27888146. Sequential31006cbd's hyper parameters: Current learning rate is 0.006426735218508998. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 55936/60000][Iteration 2782][Wall Clock 283.755746959s] Trained 128 records in 0.104373282 seconds. Throughput is 1226.3674 records/second. Loss is 0.2509505. Sequential31006cbd's hyper parameters: Current learning rate is 0.006425909266161162. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 56064/60000][Iteration 2783][Wall Clock 283.835486646s] Trained 128 records in 0.079739687 seconds. Throughput is 1605.2231 records/second. Loss is 0.26909897. Sequential31006cbd's hyper parameters: Current learning rate is 0.00642508352608584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 56192/60000][Iteration 2784][Wall Clock 283.948391701s] Trained 128 records in 0.112905055 seconds. Throughput is 1133.6959 records/second. Loss is 0.22561018. Sequential31006cbd's hyper parameters: Current learning rate is 0.006424257998201208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 56320/60000][Iteration 2785][Wall Clock 284.033060078s] Trained 128 records in 0.084668377 seconds. Throughput is 1511.7805 records/second. Loss is 0.26175326. Sequential31006cbd's hyper parameters: Current learning rate is 0.006423432682425488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:21 INFO  DistriOptimizer$:408 - [Epoch 6 56448/60000][Iteration 2786][Wall Clock 284.111498314s] Trained 128 records in 0.078438236 seconds. Throughput is 1631.8572 records/second. Loss is 0.24920513. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064226075786769435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 56576/60000][Iteration 2787][Wall Clock 284.20125731s] Trained 128 records in 0.089758996 seconds. Throughput is 1426.0409 records/second. Loss is 0.23827717. Sequential31006cbd's hyper parameters: Current learning rate is 0.006421782686873876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 56704/60000][Iteration 2788][Wall Clock 284.289116305s] Trained 128 records in 0.087858995 seconds. Throughput is 1456.8798 records/second. Loss is 0.19114368. Sequential31006cbd's hyper parameters: Current learning rate is 0.006420958006934635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 56832/60000][Iteration 2789][Wall Clock 284.373796125s] Trained 128 records in 0.08467982 seconds. Throughput is 1511.5762 records/second. Loss is 0.2843336. Sequential31006cbd's hyper parameters: Current learning rate is 0.006420133538777607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 56960/60000][Iteration 2790][Wall Clock 284.456557152s] Trained 128 records in 0.082761027 seconds. Throughput is 1546.6217 records/second. Loss is 0.336572. Sequential31006cbd's hyper parameters: Current learning rate is 0.006419309282321222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57088/60000][Iteration 2791][Wall Clock 284.537494674s] Trained 128 records in 0.080937522 seconds. Throughput is 1581.4668 records/second. Loss is 0.311397. Sequential31006cbd's hyper parameters: Current learning rate is 0.006418485237483953. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57216/60000][Iteration 2792][Wall Clock 284.629580455s] Trained 128 records in 0.092085781 seconds. Throughput is 1390.0083 records/second. Loss is 0.20641124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006417661404184315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57344/60000][Iteration 2793][Wall Clock 284.739264177s] Trained 128 records in 0.109683722 seconds. Throughput is 1166.9917 records/second. Loss is 0.27521867. Sequential31006cbd's hyper parameters: Current learning rate is 0.006416837782340862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57472/60000][Iteration 2794][Wall Clock 284.821026481s] Trained 128 records in 0.081762304 seconds. Throughput is 1565.5135 records/second. Loss is 0.23781714. Sequential31006cbd's hyper parameters: Current learning rate is 0.006416014371872193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57600/60000][Iteration 2795][Wall Clock 284.927239781s] Trained 128 records in 0.1062133 seconds. Throughput is 1205.1221 records/second. Loss is 0.19896996. Sequential31006cbd's hyper parameters: Current learning rate is 0.006415191172696946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57728/60000][Iteration 2796][Wall Clock 285.008639305s] Trained 128 records in 0.081399524 seconds. Throughput is 1572.4908 records/second. Loss is 0.2979143. Sequential31006cbd's hyper parameters: Current learning rate is 0.006414368184733803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57856/60000][Iteration 2797][Wall Clock 285.090832536s] Trained 128 records in 0.082193231 seconds. Throughput is 1557.3058 records/second. Loss is 0.3001723. Sequential31006cbd's hyper parameters: Current learning rate is 0.006413545407901487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:22 INFO  DistriOptimizer$:408 - [Epoch 6 57984/60000][Iteration 2798][Wall Clock 285.16625676s] Trained 128 records in 0.075424224 seconds. Throughput is 1697.0675 records/second. Loss is 0.2286471. Sequential31006cbd's hyper parameters: Current learning rate is 0.006412722842118764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58112/60000][Iteration 2799][Wall Clock 285.245420814s] Trained 128 records in 0.079164054 seconds. Throughput is 1616.8955 records/second. Loss is 0.25441533. Sequential31006cbd's hyper parameters: Current learning rate is 0.006411900487304437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58240/60000][Iteration 2800][Wall Clock 285.345740972s] Trained 128 records in 0.100320158 seconds. Throughput is 1275.915 records/second. Loss is 0.24268189. Sequential31006cbd's hyper parameters: Current learning rate is 0.006411078343377356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58368/60000][Iteration 2801][Wall Clock 285.42933513s] Trained 128 records in 0.083594158 seconds. Throughput is 1531.2075 records/second. Loss is 0.27254945. Sequential31006cbd's hyper parameters: Current learning rate is 0.00641025641025641. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58496/60000][Iteration 2802][Wall Clock 285.55163026s] Trained 128 records in 0.12229513 seconds. Throughput is 1046.6484 records/second. Loss is 0.29030895. Sequential31006cbd's hyper parameters: Current learning rate is 0.006409434687860531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58624/60000][Iteration 2803][Wall Clock 285.627555166s] Trained 128 records in 0.075924906 seconds. Throughput is 1685.8763 records/second. Loss is 0.3538129. Sequential31006cbd's hyper parameters: Current learning rate is 0.00640861317610869. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58752/60000][Iteration 2804][Wall Clock 285.720683019s] Trained 128 records in 0.093127853 seconds. Throughput is 1374.4545 records/second. Loss is 0.27659956. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064077918749199025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 58880/60000][Iteration 2805][Wall Clock 285.82675493s] Trained 128 records in 0.106071911 seconds. Throughput is 1206.7285 records/second. Loss is 0.19685404. Sequential31006cbd's hyper parameters: Current learning rate is 0.006406970784213224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 59008/60000][Iteration 2806][Wall Clock 285.919324593s] Trained 128 records in 0.092569663 seconds. Throughput is 1382.7424 records/second. Loss is 0.2782743. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064061499039077515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 59136/60000][Iteration 2807][Wall Clock 286.00685791s] Trained 128 records in 0.087533317 seconds. Throughput is 1462.3003 records/second. Loss is 0.43586573. Sequential31006cbd's hyper parameters: Current learning rate is 0.006405329233922624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 59264/60000][Iteration 2808][Wall Clock 286.082921562s] Trained 128 records in 0.076063652 seconds. Throughput is 1682.801 records/second. Loss is 0.2708879. Sequential31006cbd's hyper parameters: Current learning rate is 0.006404508774177021. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:23 INFO  DistriOptimizer$:408 - [Epoch 6 59392/60000][Iteration 2809][Wall Clock 286.160676274s] Trained 128 records in 0.077754712 seconds. Throughput is 1646.2024 records/second. Loss is 0.22718352. Sequential31006cbd's hyper parameters: Current learning rate is 0.006403688524590165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:24 INFO  DistriOptimizer$:408 - [Epoch 6 59520/60000][Iteration 2810][Wall Clock 286.258878458s] Trained 128 records in 0.098202184 seconds. Throughput is 1303.4333 records/second. Loss is 0.24699828. Sequential31006cbd's hyper parameters: Current learning rate is 0.006402868485081316. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:24 INFO  DistriOptimizer$:408 - [Epoch 6 59648/60000][Iteration 2811][Wall Clock 286.350240504s] Trained 128 records in 0.091362046 seconds. Throughput is 1401.0194 records/second. Loss is 0.27383482. Sequential31006cbd's hyper parameters: Current learning rate is 0.006402048655569782. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:24 INFO  DistriOptimizer$:408 - [Epoch 6 59776/60000][Iteration 2812][Wall Clock 286.442278528s] Trained 128 records in 0.092038024 seconds. Throughput is 1390.7296 records/second. Loss is 0.3476188. Sequential31006cbd's hyper parameters: Current learning rate is 0.0064012290359749075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:24 INFO  DistriOptimizer$:408 - [Epoch 6 59904/60000][Iteration 2813][Wall Clock 286.525037625s] Trained 128 records in 0.082759097 seconds. Throughput is 1546.6577 records/second. Loss is 0.26836753. Sequential31006cbd's hyper parameters: Current learning rate is 0.006400409626216078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:24 INFO  DistriOptimizer$:408 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 286.607931828s] Trained 128 records in 0.082894203 seconds. Throughput is 1544.1368 records/second. Loss is 0.15812983. Sequential31006cbd's hyper parameters: Current learning rate is 0.006399590426212722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:24 INFO  DistriOptimizer$:452 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 286.607931828s] Epoch finished. Wall clock time is 287943.526816 ms
2019-10-24 00:02:24 INFO  DistriOptimizer$:111 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 286.607931828s] Validate model...
2019-10-24 00:02:25 INFO  DistriOptimizer$:178 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 286.607931828s] validate model throughput is 11905.766 records/second
2019-10-24 00:02:25 INFO  DistriOptimizer$:181 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 286.607931828s] Top1Accuracy is Accuracy(correct: 9312, count: 10000, accuracy: 0.9312)
2019-10-24 00:02:25 INFO  DistriOptimizer$:221 - [Wall Clock 287.943526816s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:02:25 INFO  DistriOptimizer$:226 - [Wall Clock 287.943526816s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 128/60000][Iteration 2815][Wall Clock 288.03442637s] Trained 128 records in 0.090899554 seconds. Throughput is 1408.1477 records/second. Loss is 0.20585977. Sequential31006cbd's hyper parameters: Current learning rate is 0.00639877143588431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 256/60000][Iteration 2816][Wall Clock 288.125978184s] Trained 128 records in 0.091551814 seconds. Throughput is 1398.1155 records/second. Loss is 0.39412048. Sequential31006cbd's hyper parameters: Current learning rate is 0.006397952655150352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 384/60000][Iteration 2817][Wall Clock 288.204511245s] Trained 128 records in 0.078533061 seconds. Throughput is 1629.8868 records/second. Loss is 0.29402572. Sequential31006cbd's hyper parameters: Current learning rate is 0.006397134083930399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 512/60000][Iteration 2818][Wall Clock 288.280407012s] Trained 128 records in 0.075895767 seconds. Throughput is 1686.5237 records/second. Loss is 0.27417576. Sequential31006cbd's hyper parameters: Current learning rate is 0.006396315722144045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 640/60000][Iteration 2819][Wall Clock 288.35641576s] Trained 128 records in 0.076008748 seconds. Throughput is 1684.0167 records/second. Loss is 0.28177983. Sequential31006cbd's hyper parameters: Current learning rate is 0.006395497569710923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 768/60000][Iteration 2820][Wall Clock 288.440141936s] Trained 128 records in 0.083726176 seconds. Throughput is 1528.7931 records/second. Loss is 0.26180816. Sequential31006cbd's hyper parameters: Current learning rate is 0.006394679626550709. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:25 INFO  DistriOptimizer$:408 - [Epoch 7 896/60000][Iteration 2821][Wall Clock 288.518022003s] Trained 128 records in 0.077880067 seconds. Throughput is 1643.5527 records/second. Loss is 0.313267. Sequential31006cbd's hyper parameters: Current learning rate is 0.00639386189258312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1024/60000][Iteration 2822][Wall Clock 288.594115083s] Trained 128 records in 0.07609308 seconds. Throughput is 1682.1504 records/second. Loss is 0.2612236. Sequential31006cbd's hyper parameters: Current learning rate is 0.006393044367727912. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1152/60000][Iteration 2823][Wall Clock 288.668267159s] Trained 128 records in 0.074152076 seconds. Throughput is 1726.1824 records/second. Loss is 0.2611382. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063922270519048835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1280/60000][Iteration 2824][Wall Clock 288.749362734s] Trained 128 records in 0.081095575 seconds. Throughput is 1578.3845 records/second. Loss is 0.33785105. Sequential31006cbd's hyper parameters: Current learning rate is 0.006391409945033875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1408/60000][Iteration 2825][Wall Clock 288.83258284s] Trained 128 records in 0.083220106 seconds. Throughput is 1538.0898 records/second. Loss is 0.28616357. Sequential31006cbd's hyper parameters: Current learning rate is 0.006390593047034765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1536/60000][Iteration 2826][Wall Clock 288.919237098s] Trained 128 records in 0.086654258 seconds. Throughput is 1477.1345 records/second. Loss is 0.24522558. Sequential31006cbd's hyper parameters: Current learning rate is 0.006389776357827477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1664/60000][Iteration 2827][Wall Clock 289.002326731s] Trained 128 records in 0.083089633 seconds. Throughput is 1540.505 records/second. Loss is 0.24363647. Sequential31006cbd's hyper parameters: Current learning rate is 0.006388959877331971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1792/60000][Iteration 2828][Wall Clock 289.113151096s] Trained 128 records in 0.110824365 seconds. Throughput is 1154.9807 records/second. Loss is 0.2714091. Sequential31006cbd's hyper parameters: Current learning rate is 0.006388143605468252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 1920/60000][Iteration 2829][Wall Clock 289.195166537s] Trained 128 records in 0.082015441 seconds. Throughput is 1560.6818 records/second. Loss is 0.32507974. Sequential31006cbd's hyper parameters: Current learning rate is 0.006387327542156362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 2048/60000][Iteration 2830][Wall Clock 289.285464472s] Trained 128 records in 0.090297935 seconds. Throughput is 1417.5297 records/second. Loss is 0.23782687. Sequential31006cbd's hyper parameters: Current learning rate is 0.006386511687316388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 2176/60000][Iteration 2831][Wall Clock 289.362933647s] Trained 128 records in 0.077469175 seconds. Throughput is 1652.27 records/second. Loss is 0.2626524. Sequential31006cbd's hyper parameters: Current learning rate is 0.006385696040868454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 2304/60000][Iteration 2832][Wall Clock 289.4715332s] Trained 128 records in 0.108599553 seconds. Throughput is 1178.6421 records/second. Loss is 0.39196756. Sequential31006cbd's hyper parameters: Current learning rate is 0.006384880602732729. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:26 INFO  DistriOptimizer$:408 - [Epoch 7 2432/60000][Iteration 2833][Wall Clock 289.562556196s] Trained 128 records in 0.091022996 seconds. Throughput is 1406.238 records/second. Loss is 0.2331465. Sequential31006cbd's hyper parameters: Current learning rate is 0.006384065372829418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 2560/60000][Iteration 2834][Wall Clock 289.680881854s] Trained 128 records in 0.118325658 seconds. Throughput is 1081.7603 records/second. Loss is 0.26025558. Sequential31006cbd's hyper parameters: Current learning rate is 0.006383250351078769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 2688/60000][Iteration 2835][Wall Clock 289.775642106s] Trained 128 records in 0.094760252 seconds. Throughput is 1350.7773 records/second. Loss is 0.39202613. Sequential31006cbd's hyper parameters: Current learning rate is 0.006382435537401071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 2816/60000][Iteration 2836][Wall Clock 289.871962451s] Trained 128 records in 0.096320345 seconds. Throughput is 1328.8989 records/second. Loss is 0.33753812. Sequential31006cbd's hyper parameters: Current learning rate is 0.006381620931716655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 2944/60000][Iteration 2837][Wall Clock 289.955351679s] Trained 128 records in 0.083389228 seconds. Throughput is 1534.9705 records/second. Loss is 0.2346642. Sequential31006cbd's hyper parameters: Current learning rate is 0.00638080653394589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 3072/60000][Iteration 2838][Wall Clock 290.043106855s] Trained 128 records in 0.087755176 seconds. Throughput is 1458.6035 records/second. Loss is 0.2849972. Sequential31006cbd's hyper parameters: Current learning rate is 0.006379992344009187. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 3200/60000][Iteration 2839][Wall Clock 290.131071262s] Trained 128 records in 0.087964407 seconds. Throughput is 1455.134 records/second. Loss is 0.25915048. Sequential31006cbd's hyper parameters: Current learning rate is 0.006379178361826996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 3328/60000][Iteration 2840][Wall Clock 290.220744s] Trained 128 records in 0.089672738 seconds. Throughput is 1427.4127 records/second. Loss is 0.2835452. Sequential31006cbd's hyper parameters: Current learning rate is 0.006378364587319811. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 3456/60000][Iteration 2841][Wall Clock 290.301703982s] Trained 128 records in 0.080959982 seconds. Throughput is 1581.028 records/second. Loss is 0.3382812. Sequential31006cbd's hyper parameters: Current learning rate is 0.006377551020408163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 3584/60000][Iteration 2842][Wall Clock 290.384792644s] Trained 128 records in 0.083088662 seconds. Throughput is 1540.5231 records/second. Loss is 0.26806927. Sequential31006cbd's hyper parameters: Current learning rate is 0.006376737661012626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:27 INFO  DistriOptimizer$:408 - [Epoch 7 3712/60000][Iteration 2843][Wall Clock 290.492872638s] Trained 128 records in 0.108079994 seconds. Throughput is 1184.308 records/second. Loss is 0.28344917. Sequential31006cbd's hyper parameters: Current learning rate is 0.006375924509053813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 3840/60000][Iteration 2844][Wall Clock 290.57783943s] Trained 128 records in 0.084966792 seconds. Throughput is 1506.4708 records/second. Loss is 0.23384705. Sequential31006cbd's hyper parameters: Current learning rate is 0.006375111564452378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 3968/60000][Iteration 2845][Wall Clock 290.664209435s] Trained 128 records in 0.086370005 seconds. Throughput is 1481.996 records/second. Loss is 0.21880957. Sequential31006cbd's hyper parameters: Current learning rate is 0.006374298827129016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4096/60000][Iteration 2846][Wall Clock 290.755941235s] Trained 128 records in 0.0917318 seconds. Throughput is 1395.3722 records/second. Loss is 0.21258537. Sequential31006cbd's hyper parameters: Current learning rate is 0.006373486297004462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4224/60000][Iteration 2847][Wall Clock 290.836042394s] Trained 128 records in 0.080101159 seconds. Throughput is 1597.9794 records/second. Loss is 0.32570392. Sequential31006cbd's hyper parameters: Current learning rate is 0.006372673973999491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4352/60000][Iteration 2848][Wall Clock 290.931389689s] Trained 128 records in 0.095347295 seconds. Throughput is 1342.4608 records/second. Loss is 0.3892496. Sequential31006cbd's hyper parameters: Current learning rate is 0.006371861858034919. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4480/60000][Iteration 2849][Wall Clock 291.023895219s] Trained 128 records in 0.09250553 seconds. Throughput is 1383.701 records/second. Loss is 0.28036106. Sequential31006cbd's hyper parameters: Current learning rate is 0.006371049949031601. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4608/60000][Iteration 2850][Wall Clock 291.110185497s] Trained 128 records in 0.086290278 seconds. Throughput is 1483.3652 records/second. Loss is 0.17280518. Sequential31006cbd's hyper parameters: Current learning rate is 0.006370238246910435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4736/60000][Iteration 2851][Wall Clock 291.193607149s] Trained 128 records in 0.083421652 seconds. Throughput is 1534.3738 records/second. Loss is 0.39171264. Sequential31006cbd's hyper parameters: Current learning rate is 0.006369426751592356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4864/60000][Iteration 2852][Wall Clock 291.275985776s] Trained 128 records in 0.082378627 seconds. Throughput is 1553.8011 records/second. Loss is 0.31931126. Sequential31006cbd's hyper parameters: Current learning rate is 0.006368615462998344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 4992/60000][Iteration 2853][Wall Clock 291.363430205s] Trained 128 records in 0.087444429 seconds. Throughput is 1463.7867 records/second. Loss is 0.26725632. Sequential31006cbd's hyper parameters: Current learning rate is 0.006367804381049415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 5120/60000][Iteration 2854][Wall Clock 291.453654231s] Trained 128 records in 0.090224026 seconds. Throughput is 1418.6908 records/second. Loss is 0.26361126. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063669935056666245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:28 INFO  DistriOptimizer$:408 - [Epoch 7 5248/60000][Iteration 2855][Wall Clock 291.551048304s] Trained 128 records in 0.097394073 seconds. Throughput is 1314.2484 records/second. Loss is 0.2483603. Sequential31006cbd's hyper parameters: Current learning rate is 0.006366182836771072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 5376/60000][Iteration 2856][Wall Clock 291.632362791s] Trained 128 records in 0.081314487 seconds. Throughput is 1574.1353 records/second. Loss is 0.23133847. Sequential31006cbd's hyper parameters: Current learning rate is 0.006365372374283895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 5504/60000][Iteration 2857][Wall Clock 291.71293049s] Trained 128 records in 0.080567699 seconds. Throughput is 1588.726 records/second. Loss is 0.33012828. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063645621181262725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 5632/60000][Iteration 2858][Wall Clock 291.806955804s] Trained 128 records in 0.094025314 seconds. Throughput is 1361.3356 records/second. Loss is 0.27887604. Sequential31006cbd's hyper parameters: Current learning rate is 0.006363752068219422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 5760/60000][Iteration 2859][Wall Clock 291.88910839s] Trained 128 records in 0.082152586 seconds. Throughput is 1558.0764 records/second. Loss is 0.28189537. Sequential31006cbd's hyper parameters: Current learning rate is 0.006362942224484601. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 5888/60000][Iteration 2860][Wall Clock 291.991765565s] Trained 128 records in 0.102657175 seconds. Throughput is 1246.8685 records/second. Loss is 0.27847776. Sequential31006cbd's hyper parameters: Current learning rate is 0.006362132586843109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 6016/60000][Iteration 2861][Wall Clock 292.081229053s] Trained 128 records in 0.089463488 seconds. Throughput is 1430.7513 records/second. Loss is 0.2709006. Sequential31006cbd's hyper parameters: Current learning rate is 0.006361323155216285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 6144/60000][Iteration 2862][Wall Clock 292.171047373s] Trained 128 records in 0.08981832 seconds. Throughput is 1425.099 records/second. Loss is 0.21489617. Sequential31006cbd's hyper parameters: Current learning rate is 0.006360513929525506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 6272/60000][Iteration 2863][Wall Clock 292.255668915s] Trained 128 records in 0.084621542 seconds. Throughput is 1512.6172 records/second. Loss is 0.25026467. Sequential31006cbd's hyper parameters: Current learning rate is 0.00635970490969219. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 6400/60000][Iteration 2864][Wall Clock 292.342268636s] Trained 128 records in 0.086599721 seconds. Throughput is 1478.0648 records/second. Loss is 0.32125372. Sequential31006cbd's hyper parameters: Current learning rate is 0.006358896095637797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 6528/60000][Iteration 2865][Wall Clock 292.421978811s] Trained 128 records in 0.079710175 seconds. Throughput is 1605.8175 records/second. Loss is 0.2227186. Sequential31006cbd's hyper parameters: Current learning rate is 0.006358087487283825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:29 INFO  DistriOptimizer$:408 - [Epoch 7 6656/60000][Iteration 2866][Wall Clock 292.498610192s] Trained 128 records in 0.076631381 seconds. Throughput is 1670.334 records/second. Loss is 0.2713078. Sequential31006cbd's hyper parameters: Current learning rate is 0.006357279084551812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 6784/60000][Iteration 2867][Wall Clock 292.58851777s] Trained 128 records in 0.089907578 seconds. Throughput is 1423.6842 records/second. Loss is 0.3466402. Sequential31006cbd's hyper parameters: Current learning rate is 0.006356470887363336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 6912/60000][Iteration 2868][Wall Clock 292.709128335s] Trained 128 records in 0.120610565 seconds. Throughput is 1061.2668 records/second. Loss is 0.3824934. Sequential31006cbd's hyper parameters: Current learning rate is 0.006355662895640016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7040/60000][Iteration 2869][Wall Clock 292.805073984s] Trained 128 records in 0.095945649 seconds. Throughput is 1334.0886 records/second. Loss is 0.2326377. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063548551093035085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7168/60000][Iteration 2870][Wall Clock 292.892698174s] Trained 128 records in 0.08762419 seconds. Throughput is 1460.7838 records/second. Loss is 0.19306894. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063540475282755126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7296/60000][Iteration 2871][Wall Clock 292.974127819s] Trained 128 records in 0.081429645 seconds. Throughput is 1571.909 records/second. Loss is 0.27663904. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063532401524777635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7424/60000][Iteration 2872][Wall Clock 293.082921601s] Trained 128 records in 0.108793782 seconds. Throughput is 1176.5378 records/second. Loss is 0.23943841. Sequential31006cbd's hyper parameters: Current learning rate is 0.006352432981832042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7552/60000][Iteration 2873][Wall Clock 293.163298409s] Trained 128 records in 0.080376808 seconds. Throughput is 1592.4991 records/second. Loss is 0.2208856. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063516260162601625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7680/60000][Iteration 2874][Wall Clock 293.243898556s] Trained 128 records in 0.080600147 seconds. Throughput is 1588.0864 records/second. Loss is 0.23443581. Sequential31006cbd's hyper parameters: Current learning rate is 0.006350819255683983. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7808/60000][Iteration 2875][Wall Clock 293.346720904s] Trained 128 records in 0.102822348 seconds. Throughput is 1244.8656 records/second. Loss is 0.2820506. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063500127000254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 7936/60000][Iteration 2876][Wall Clock 293.445630743s] Trained 128 records in 0.098909839 seconds. Throughput is 1294.1078 records/second. Loss is 0.16683736. Sequential31006cbd's hyper parameters: Current learning rate is 0.006349206349206348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:30 INFO  DistriOptimizer$:408 - [Epoch 7 8064/60000][Iteration 2877][Wall Clock 293.530859564s] Trained 128 records in 0.085228821 seconds. Throughput is 1501.8394 records/second. Loss is 0.20915407. Sequential31006cbd's hyper parameters: Current learning rate is 0.006348400203148806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8192/60000][Iteration 2878][Wall Clock 293.634194364s] Trained 128 records in 0.1033348 seconds. Throughput is 1238.6921 records/second. Loss is 0.14545847. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063475942617747865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8320/60000][Iteration 2879][Wall Clock 293.728195251s] Trained 128 records in 0.094000887 seconds. Throughput is 1361.6893 records/second. Loss is 0.30040583. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063467885250063465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8448/60000][Iteration 2880][Wall Clock 293.806252643s] Trained 128 records in 0.078057392 seconds. Throughput is 1639.8191 records/second. Loss is 0.266515. Sequential31006cbd's hyper parameters: Current learning rate is 0.006345982992765579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8576/60000][Iteration 2881][Wall Clock 293.884322924s] Trained 128 records in 0.078070281 seconds. Throughput is 1639.5483 records/second. Loss is 0.17686348. Sequential31006cbd's hyper parameters: Current learning rate is 0.006345177664974619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8704/60000][Iteration 2882][Wall Clock 293.973328228s] Trained 128 records in 0.089005304 seconds. Throughput is 1438.1165 records/second. Loss is 0.26686788. Sequential31006cbd's hyper parameters: Current learning rate is 0.00634437254155564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8832/60000][Iteration 2883][Wall Clock 294.055938701s] Trained 128 records in 0.082610473 seconds. Throughput is 1549.4403 records/second. Loss is 0.2231124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006343567622430855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 8960/60000][Iteration 2884][Wall Clock 294.142948965s] Trained 128 records in 0.087010264 seconds. Throughput is 1471.0908 records/second. Loss is 0.15958346. Sequential31006cbd's hyper parameters: Current learning rate is 0.006342762907522517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 9088/60000][Iteration 2885][Wall Clock 294.235550199s] Trained 128 records in 0.092601234 seconds. Throughput is 1382.271 records/second. Loss is 0.32922333. Sequential31006cbd's hyper parameters: Current learning rate is 0.006341958396752918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 9216/60000][Iteration 2886][Wall Clock 294.318993104s] Trained 128 records in 0.083442905 seconds. Throughput is 1533.983 records/second. Loss is 0.35255033. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063411540900443885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 9344/60000][Iteration 2887][Wall Clock 294.40095715s] Trained 128 records in 0.081964046 seconds. Throughput is 1561.6604 records/second. Loss is 0.21147564. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063403499873193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:31 INFO  DistriOptimizer$:408 - [Epoch 7 9472/60000][Iteration 2888][Wall Clock 294.501638015s] Trained 128 records in 0.100680865 seconds. Throughput is 1271.3439 records/second. Loss is 0.30465087. Sequential31006cbd's hyper parameters: Current learning rate is 0.006339546088500064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 9600/60000][Iteration 2889][Wall Clock 294.592378615s] Trained 128 records in 0.0907406 seconds. Throughput is 1410.6145 records/second. Loss is 0.281867. Sequential31006cbd's hyper parameters: Current learning rate is 0.006338742393509129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 9728/60000][Iteration 2890][Wall Clock 294.682829681s] Trained 128 records in 0.090451066 seconds. Throughput is 1415.1298 records/second. Loss is 0.22572151. Sequential31006cbd's hyper parameters: Current learning rate is 0.006337938902268983. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 9856/60000][Iteration 2891][Wall Clock 294.769676697s] Trained 128 records in 0.086847016 seconds. Throughput is 1473.8561 records/second. Loss is 0.17166385. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063371356147021544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 9984/60000][Iteration 2892][Wall Clock 294.865677918s] Trained 128 records in 0.096001221 seconds. Throughput is 1333.3164 records/second. Loss is 0.25689015. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063363325307312125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10112/60000][Iteration 2893][Wall Clock 294.971449352s] Trained 128 records in 0.105771434 seconds. Throughput is 1210.1566 records/second. Loss is 0.22731535. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063355296502787635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10240/60000][Iteration 2894][Wall Clock 295.066807813s] Trained 128 records in 0.095358461 seconds. Throughput is 1342.3036 records/second. Loss is 0.309972. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063347269732674525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10368/60000][Iteration 2895][Wall Clock 295.167435824s] Trained 128 records in 0.100628011 seconds. Throughput is 1272.0116 records/second. Loss is 0.20096084. Sequential31006cbd's hyper parameters: Current learning rate is 0.006333924499619965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10496/60000][Iteration 2896][Wall Clock 295.253279277s] Trained 128 records in 0.085843453 seconds. Throughput is 1491.0864 records/second. Loss is 0.22928964. Sequential31006cbd's hyper parameters: Current learning rate is 0.006333122229259024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10624/60000][Iteration 2897][Wall Clock 295.354279384s] Trained 128 records in 0.101000107 seconds. Throughput is 1267.3254 records/second. Loss is 0.37056676. Sequential31006cbd's hyper parameters: Current learning rate is 0.006332320162107396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10752/60000][Iteration 2898][Wall Clock 295.432435098s] Trained 128 records in 0.078155714 seconds. Throughput is 1637.7562 records/second. Loss is 0.24061784. Sequential31006cbd's hyper parameters: Current learning rate is 0.006331518298087881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:32 INFO  DistriOptimizer$:408 - [Epoch 7 10880/60000][Iteration 2899][Wall Clock 295.51148173s] Trained 128 records in 0.079046632 seconds. Throughput is 1619.2974 records/second. Loss is 0.24128771. Sequential31006cbd's hyper parameters: Current learning rate is 0.006330716637123322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11008/60000][Iteration 2900][Wall Clock 295.589736166s] Trained 128 records in 0.078254436 seconds. Throughput is 1635.69 records/second. Loss is 0.23889673. Sequential31006cbd's hyper parameters: Current learning rate is 0.006329915179136599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11136/60000][Iteration 2901][Wall Clock 295.6697727s] Trained 128 records in 0.080036534 seconds. Throughput is 1599.2697 records/second. Loss is 0.28108674. Sequential31006cbd's hyper parameters: Current learning rate is 0.006329113924050633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11264/60000][Iteration 2902][Wall Clock 295.755413756s] Trained 128 records in 0.085641056 seconds. Throughput is 1494.6102 records/second. Loss is 0.17699528. Sequential31006cbd's hyper parameters: Current learning rate is 0.006328312871788381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11392/60000][Iteration 2903][Wall Clock 295.837727203s] Trained 128 records in 0.082313447 seconds. Throughput is 1555.0315 records/second. Loss is 0.26764598. Sequential31006cbd's hyper parameters: Current learning rate is 0.006327512022272842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11520/60000][Iteration 2904][Wall Clock 295.916622924s] Trained 128 records in 0.078895721 seconds. Throughput is 1622.3948 records/second. Loss is 0.27802277. Sequential31006cbd's hyper parameters: Current learning rate is 0.006326711375427053. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11648/60000][Iteration 2905][Wall Clock 296.006677476s] Trained 128 records in 0.090054552 seconds. Throughput is 1421.3607 records/second. Loss is 0.18037736. Sequential31006cbd's hyper parameters: Current learning rate is 0.006325910931174089. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11776/60000][Iteration 2906][Wall Clock 296.086819919s] Trained 128 records in 0.080142443 seconds. Throughput is 1597.1561 records/second. Loss is 0.26917413. Sequential31006cbd's hyper parameters: Current learning rate is 0.006325110689437066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 11904/60000][Iteration 2907][Wall Clock 296.168162495s] Trained 128 records in 0.081342576 seconds. Throughput is 1573.5917 records/second. Loss is 0.28831816. Sequential31006cbd's hyper parameters: Current learning rate is 0.006324310650139135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 12032/60000][Iteration 2908][Wall Clock 296.268085785s] Trained 128 records in 0.09992329 seconds. Throughput is 1280.9827 records/second. Loss is 0.28888875. Sequential31006cbd's hyper parameters: Current learning rate is 0.006323510813203491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 12160/60000][Iteration 2909][Wall Clock 296.353610679s] Trained 128 records in 0.085524894 seconds. Throughput is 1496.6403 records/second. Loss is 0.22882518. Sequential31006cbd's hyper parameters: Current learning rate is 0.006322711178553364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 12288/60000][Iteration 2910][Wall Clock 296.435273325s] Trained 128 records in 0.081662646 seconds. Throughput is 1567.4241 records/second. Loss is 0.272376. Sequential31006cbd's hyper parameters: Current learning rate is 0.006321911746112025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:33 INFO  DistriOptimizer$:408 - [Epoch 7 12416/60000][Iteration 2911][Wall Clock 296.536663467s] Trained 128 records in 0.101390142 seconds. Throughput is 1262.4501 records/second. Loss is 0.2760571. Sequential31006cbd's hyper parameters: Current learning rate is 0.006321112515802781. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 12544/60000][Iteration 2912][Wall Clock 296.614089828s] Trained 128 records in 0.077426361 seconds. Throughput is 1653.1837 records/second. Loss is 0.22839639. Sequential31006cbd's hyper parameters: Current learning rate is 0.006320313487548982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 12672/60000][Iteration 2913][Wall Clock 296.699084851s] Trained 128 records in 0.084995023 seconds. Throughput is 1505.9705 records/second. Loss is 0.2030837. Sequential31006cbd's hyper parameters: Current learning rate is 0.006319514661274014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 12800/60000][Iteration 2914][Wall Clock 296.792940997s] Trained 128 records in 0.093856146 seconds. Throughput is 1363.7892 records/second. Loss is 0.26918173. Sequential31006cbd's hyper parameters: Current learning rate is 0.006318716036901302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 12928/60000][Iteration 2915][Wall Clock 296.871697791s] Trained 128 records in 0.078756794 seconds. Throughput is 1625.2566 records/second. Loss is 0.25306815. Sequential31006cbd's hyper parameters: Current learning rate is 0.006317917614354309. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13056/60000][Iteration 2916][Wall Clock 296.955287839s] Trained 128 records in 0.083590048 seconds. Throughput is 1531.2828 records/second. Loss is 0.35774457. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063171193935565376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13184/60000][Iteration 2917][Wall Clock 297.038855656s] Trained 128 records in 0.083567817 seconds. Throughput is 1531.6901 records/second. Loss is 0.28104845. Sequential31006cbd's hyper parameters: Current learning rate is 0.006316321374431531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13312/60000][Iteration 2918][Wall Clock 297.125086118s] Trained 128 records in 0.086230462 seconds. Throughput is 1484.3942 records/second. Loss is 0.20419693. Sequential31006cbd's hyper parameters: Current learning rate is 0.006315523556902867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13440/60000][Iteration 2919][Wall Clock 297.211231253s] Trained 128 records in 0.086145135 seconds. Throughput is 1485.8645 records/second. Loss is 0.2936629. Sequential31006cbd's hyper parameters: Current learning rate is 0.006314725940894165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13568/60000][Iteration 2920][Wall Clock 297.283971296s] Trained 128 records in 0.072740043 seconds. Throughput is 1759.691 records/second. Loss is 0.2720954. Sequential31006cbd's hyper parameters: Current learning rate is 0.006313928526329082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13696/60000][Iteration 2921][Wall Clock 297.35997527s] Trained 128 records in 0.076003974 seconds. Throughput is 1684.1224 records/second. Loss is 0.2762535. Sequential31006cbd's hyper parameters: Current learning rate is 0.006313131313131313. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13824/60000][Iteration 2922][Wall Clock 297.439603369s] Trained 128 records in 0.079628099 seconds. Throughput is 1607.4727 records/second. Loss is 0.22046071. Sequential31006cbd's hyper parameters: Current learning rate is 0.006312334301224593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:34 INFO  DistriOptimizer$:408 - [Epoch 7 13952/60000][Iteration 2923][Wall Clock 297.518968787s] Trained 128 records in 0.079365418 seconds. Throughput is 1612.7931 records/second. Loss is 0.2908698. Sequential31006cbd's hyper parameters: Current learning rate is 0.006311537490532694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14080/60000][Iteration 2924][Wall Clock 297.605811734s] Trained 128 records in 0.086842947 seconds. Throughput is 1473.9252 records/second. Loss is 0.32833245. Sequential31006cbd's hyper parameters: Current learning rate is 0.006310740880979427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14208/60000][Iteration 2925][Wall Clock 297.701070586s] Trained 128 records in 0.095258852 seconds. Throughput is 1343.7072 records/second. Loss is 0.23119955. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063099444724886425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14336/60000][Iteration 2926][Wall Clock 297.781269442s] Trained 128 records in 0.080198856 seconds. Throughput is 1596.0328 records/second. Loss is 0.35035753. Sequential31006cbd's hyper parameters: Current learning rate is 0.006309148264984228. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14464/60000][Iteration 2927][Wall Clock 297.867644641s] Trained 128 records in 0.086375199 seconds. Throughput is 1481.9069 records/second. Loss is 0.341702. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063083522583901085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14592/60000][Iteration 2928][Wall Clock 297.955054781s] Trained 128 records in 0.08741014 seconds. Throughput is 1464.3611 records/second. Loss is 0.18366656. Sequential31006cbd's hyper parameters: Current learning rate is 0.006307556452630252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14720/60000][Iteration 2929][Wall Clock 298.03880477s] Trained 128 records in 0.083749989 seconds. Throughput is 1528.3584 records/second. Loss is 0.2852121. Sequential31006cbd's hyper parameters: Current learning rate is 0.006306760847628658. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14848/60000][Iteration 2930][Wall Clock 298.121877566s] Trained 128 records in 0.083072796 seconds. Throughput is 1540.8173 records/second. Loss is 0.28035265. Sequential31006cbd's hyper parameters: Current learning rate is 0.006305965443309371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 14976/60000][Iteration 2931][Wall Clock 298.20574591s] Trained 128 records in 0.083868344 seconds. Throughput is 1526.2015 records/second. Loss is 0.3290124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006305170239596469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 15104/60000][Iteration 2932][Wall Clock 298.294825781s] Trained 128 records in 0.089079871 seconds. Throughput is 1436.9127 records/second. Loss is 0.23107475. Sequential31006cbd's hyper parameters: Current learning rate is 0.0063043752364140716. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 15232/60000][Iteration 2933][Wall Clock 298.378123157s] Trained 128 records in 0.083297376 seconds. Throughput is 1536.663 records/second. Loss is 0.23417369. Sequential31006cbd's hyper parameters: Current learning rate is 0.006303580433686334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:35 INFO  DistriOptimizer$:408 - [Epoch 7 15360/60000][Iteration 2934][Wall Clock 298.468719202s] Trained 128 records in 0.090596045 seconds. Throughput is 1412.8652 records/second. Loss is 0.3078072. Sequential31006cbd's hyper parameters: Current learning rate is 0.006302785831337451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 15488/60000][Iteration 2935][Wall Clock 298.552065827s] Trained 128 records in 0.083346625 seconds. Throughput is 1535.755 records/second. Loss is 0.24021736. Sequential31006cbd's hyper parameters: Current learning rate is 0.006301991429291657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 15616/60000][Iteration 2936][Wall Clock 298.624294783s] Trained 128 records in 0.072228956 seconds. Throughput is 1772.1426 records/second. Loss is 0.23369744. Sequential31006cbd's hyper parameters: Current learning rate is 0.00630119722747322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 15744/60000][Iteration 2937][Wall Clock 298.72282374s] Trained 128 records in 0.098528957 seconds. Throughput is 1299.1105 records/second. Loss is 0.24592416. Sequential31006cbd's hyper parameters: Current learning rate is 0.006300403225806451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 15872/60000][Iteration 2938][Wall Clock 298.830038253s] Trained 128 records in 0.107214513 seconds. Throughput is 1193.8683 records/second. Loss is 0.22390272. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062996094242156984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16000/60000][Iteration 2939][Wall Clock 298.908689223s] Trained 128 records in 0.07865097 seconds. Throughput is 1627.4435 records/second. Loss is 0.28179955. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062988158226253465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16128/60000][Iteration 2940][Wall Clock 298.992267426s] Trained 128 records in 0.083578203 seconds. Throughput is 1531.4998 records/second. Loss is 0.20957965. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062980224209598186. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16256/60000][Iteration 2941][Wall Clock 299.073267869s] Trained 128 records in 0.081000443 seconds. Throughput is 1580.2383 records/second. Loss is 0.23234941. Sequential31006cbd's hyper parameters: Current learning rate is 0.006297229219143576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16384/60000][Iteration 2942][Wall Clock 299.156084249s] Trained 128 records in 0.08281638 seconds. Throughput is 1545.588 records/second. Loss is 0.18906665. Sequential31006cbd's hyper parameters: Current learning rate is 0.006296436217101121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16512/60000][Iteration 2943][Wall Clock 299.236804s] Trained 128 records in 0.080719751 seconds. Throughput is 1585.7333 records/second. Loss is 0.41335386. Sequential31006cbd's hyper parameters: Current learning rate is 0.006295643414756988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16640/60000][Iteration 2944][Wall Clock 299.320831585s] Trained 128 records in 0.084027585 seconds. Throughput is 1523.3092 records/second. Loss is 0.2258102. Sequential31006cbd's hyper parameters: Current learning rate is 0.006294850812035755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16768/60000][Iteration 2945][Wall Clock 299.411817527s] Trained 128 records in 0.090985942 seconds. Throughput is 1406.8108 records/second. Loss is 0.19232696. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062940584088620345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:36 INFO  DistriOptimizer$:408 - [Epoch 7 16896/60000][Iteration 2946][Wall Clock 299.504056288s] Trained 128 records in 0.092238761 seconds. Throughput is 1387.7029 records/second. Loss is 0.3291856. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062932662051604785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17024/60000][Iteration 2947][Wall Clock 299.601748602s] Trained 128 records in 0.097692314 seconds. Throughput is 1310.2362 records/second. Loss is 0.24040341. Sequential31006cbd's hyper parameters: Current learning rate is 0.006292474200855777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17152/60000][Iteration 2948][Wall Clock 299.684338498s] Trained 128 records in 0.082589896 seconds. Throughput is 1549.8264 records/second. Loss is 0.19275424. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062916823958726565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17280/60000][Iteration 2949][Wall Clock 299.773862703s] Trained 128 records in 0.089524205 seconds. Throughput is 1429.781 records/second. Loss is 0.20999263. Sequential31006cbd's hyper parameters: Current learning rate is 0.006290890790135884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17408/60000][Iteration 2950][Wall Clock 299.880011738s] Trained 128 records in 0.106149035 seconds. Throughput is 1205.8518 records/second. Loss is 0.27942532. Sequential31006cbd's hyper parameters: Current learning rate is 0.006290099383570261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17536/60000][Iteration 2951][Wall Clock 299.966054706s] Trained 128 records in 0.086042968 seconds. Throughput is 1487.6288 records/second. Loss is 0.25342733. Sequential31006cbd's hyper parameters: Current learning rate is 0.006289308176100628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17664/60000][Iteration 2952][Wall Clock 300.047709804s] Trained 128 records in 0.081655098 seconds. Throughput is 1567.569 records/second. Loss is 0.28738075. Sequential31006cbd's hyper parameters: Current learning rate is 0.006288517167651868. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17792/60000][Iteration 2953][Wall Clock 300.124492809s] Trained 128 records in 0.076783005 seconds. Throughput is 1667.0356 records/second. Loss is 0.32026505. Sequential31006cbd's hyper parameters: Current learning rate is 0.006287726358148894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 17920/60000][Iteration 2954][Wall Clock 300.209318498s] Trained 128 records in 0.084825689 seconds. Throughput is 1508.9769 records/second. Loss is 0.2665901. Sequential31006cbd's hyper parameters: Current learning rate is 0.00628693574751666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 18048/60000][Iteration 2955][Wall Clock 300.297769594s] Trained 128 records in 0.088451096 seconds. Throughput is 1447.1273 records/second. Loss is 0.17442642. Sequential31006cbd's hyper parameters: Current learning rate is 0.006286145335680161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 18176/60000][Iteration 2956][Wall Clock 300.376707836s] Trained 128 records in 0.078938242 seconds. Throughput is 1621.5209 records/second. Loss is 0.31440747. Sequential31006cbd's hyper parameters: Current learning rate is 0.006285355122564424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:37 INFO  DistriOptimizer$:408 - [Epoch 7 18304/60000][Iteration 2957][Wall Clock 300.463721014s] Trained 128 records in 0.087013178 seconds. Throughput is 1471.0415 records/second. Loss is 0.25045574. Sequential31006cbd's hyper parameters: Current learning rate is 0.006284565108094519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 18432/60000][Iteration 2958][Wall Clock 300.542580232s] Trained 128 records in 0.078859218 seconds. Throughput is 1623.1458 records/second. Loss is 0.19725955. Sequential31006cbd's hyper parameters: Current learning rate is 0.006283775292195551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 18560/60000][Iteration 2959][Wall Clock 300.62698124s] Trained 128 records in 0.084401008 seconds. Throughput is 1516.5695 records/second. Loss is 0.27135345. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062829856747926615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 18688/60000][Iteration 2960][Wall Clock 300.709446425s] Trained 128 records in 0.082465185 seconds. Throughput is 1552.1702 records/second. Loss is 0.23512697. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062821962558110315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 18816/60000][Iteration 2961][Wall Clock 300.785597887s] Trained 128 records in 0.076151462 seconds. Throughput is 1680.8607 records/second. Loss is 0.3104937. Sequential31006cbd's hyper parameters: Current learning rate is 0.006281407035175879. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 18944/60000][Iteration 2962][Wall Clock 300.882394454s] Trained 128 records in 0.096796567 seconds. Throughput is 1322.361 records/second. Loss is 0.16368389. Sequential31006cbd's hyper parameters: Current learning rate is 0.00628061801281246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19072/60000][Iteration 2963][Wall Clock 300.977577019s] Trained 128 records in 0.095182565 seconds. Throughput is 1344.784 records/second. Loss is 0.2740458. Sequential31006cbd's hyper parameters: Current learning rate is 0.006279829188646069. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19200/60000][Iteration 2964][Wall Clock 301.070849579s] Trained 128 records in 0.09327256 seconds. Throughput is 1372.3221 records/second. Loss is 0.33995223. Sequential31006cbd's hyper parameters: Current learning rate is 0.006279040562602035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19328/60000][Iteration 2965][Wall Clock 301.150006515s] Trained 128 records in 0.079156936 seconds. Throughput is 1617.0409 records/second. Loss is 0.23456056. Sequential31006cbd's hyper parameters: Current learning rate is 0.006278252134605726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19456/60000][Iteration 2966][Wall Clock 301.228615813s] Trained 128 records in 0.078609298 seconds. Throughput is 1628.3062 records/second. Loss is 0.23901585. Sequential31006cbd's hyper parameters: Current learning rate is 0.006277463904582549. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19584/60000][Iteration 2967][Wall Clock 301.321185761s] Trained 128 records in 0.092569948 seconds. Throughput is 1382.7382 records/second. Loss is 0.24154213. Sequential31006cbd's hyper parameters: Current learning rate is 0.006276675872457947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19712/60000][Iteration 2968][Wall Clock 301.397989991s] Trained 128 records in 0.07680423 seconds. Throughput is 1666.575 records/second. Loss is 0.27712363. Sequential31006cbd's hyper parameters: Current learning rate is 0.006275888038157399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:38 INFO  DistriOptimizer$:408 - [Epoch 7 19840/60000][Iteration 2969][Wall Clock 301.471044045s] Trained 128 records in 0.073054054 seconds. Throughput is 1752.1273 records/second. Loss is 0.21614231. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062751004016064265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 19968/60000][Iteration 2970][Wall Clock 301.568897602s] Trained 128 records in 0.097853557 seconds. Throughput is 1308.0771 records/second. Loss is 0.25945327. Sequential31006cbd's hyper parameters: Current learning rate is 0.006274312962730582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20096/60000][Iteration 2971][Wall Clock 301.669771336s] Trained 128 records in 0.100873734 seconds. Throughput is 1268.9131 records/second. Loss is 0.23577707. Sequential31006cbd's hyper parameters: Current learning rate is 0.006273525721455458. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20224/60000][Iteration 2972][Wall Clock 301.762626133s] Trained 128 records in 0.092854797 seconds. Throughput is 1378.4963 records/second. Loss is 0.29032642. Sequential31006cbd's hyper parameters: Current learning rate is 0.006272738677706687. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20352/60000][Iteration 2973][Wall Clock 301.843345378s] Trained 128 records in 0.080719245 seconds. Throughput is 1585.7433 records/second. Loss is 0.21394701. Sequential31006cbd's hyper parameters: Current learning rate is 0.006271951831409934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20480/60000][Iteration 2974][Wall Clock 301.925399587s] Trained 128 records in 0.082054209 seconds. Throughput is 1559.9443 records/second. Loss is 0.2325255. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062711651824909065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20608/60000][Iteration 2975][Wall Clock 302.009856036s] Trained 128 records in 0.084456449 seconds. Throughput is 1515.574 records/second. Loss is 0.32919458. Sequential31006cbd's hyper parameters: Current learning rate is 0.006270378730875345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20736/60000][Iteration 2976][Wall Clock 302.089833756s] Trained 128 records in 0.07997772 seconds. Throughput is 1600.4457 records/second. Loss is 0.28531826. Sequential31006cbd's hyper parameters: Current learning rate is 0.006269592476489029. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20864/60000][Iteration 2977][Wall Clock 302.168656711s] Trained 128 records in 0.078822955 seconds. Throughput is 1623.8925 records/second. Loss is 0.22834322. Sequential31006cbd's hyper parameters: Current learning rate is 0.006268806419257773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 20992/60000][Iteration 2978][Wall Clock 302.259001275s] Trained 128 records in 0.090344564 seconds. Throughput is 1416.7981 records/second. Loss is 0.24680102. Sequential31006cbd's hyper parameters: Current learning rate is 0.006268020559107433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 21120/60000][Iteration 2979][Wall Clock 302.342875893s] Trained 128 records in 0.083874618 seconds. Throughput is 1526.0874 records/second. Loss is 0.26356748. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062672348959639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 21248/60000][Iteration 2980][Wall Clock 302.418052558s] Trained 128 records in 0.075176665 seconds. Throughput is 1702.656 records/second. Loss is 0.31974298. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062664494297531015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:39 INFO  DistriOptimizer$:408 - [Epoch 7 21376/60000][Iteration 2981][Wall Clock 302.505461097s] Trained 128 records in 0.087408539 seconds. Throughput is 1464.3878 records/second. Loss is 0.2037472. Sequential31006cbd's hyper parameters: Current learning rate is 0.006265664160401002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 21504/60000][Iteration 2982][Wall Clock 302.595402266s] Trained 128 records in 0.089941169 seconds. Throughput is 1423.1526 records/second. Loss is 0.28319713. Sequential31006cbd's hyper parameters: Current learning rate is 0.006264879087833605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 21632/60000][Iteration 2983][Wall Clock 302.705734534s] Trained 128 records in 0.110332268 seconds. Throughput is 1160.1321 records/second. Loss is 0.26570943. Sequential31006cbd's hyper parameters: Current learning rate is 0.006264094211976948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 21760/60000][Iteration 2984][Wall Clock 302.799179119s] Trained 128 records in 0.093444585 seconds. Throughput is 1369.7958 records/second. Loss is 0.14589332. Sequential31006cbd's hyper parameters: Current learning rate is 0.006263309532757109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 21888/60000][Iteration 2985][Wall Clock 302.884987579s] Trained 128 records in 0.08580846 seconds. Throughput is 1491.6943 records/second. Loss is 0.2712537. Sequential31006cbd's hyper parameters: Current learning rate is 0.006262525050100201. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 22016/60000][Iteration 2986][Wall Clock 302.966970086s] Trained 128 records in 0.081982507 seconds. Throughput is 1561.3087 records/second. Loss is 0.19619805. Sequential31006cbd's hyper parameters: Current learning rate is 0.006261740763932373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 22144/60000][Iteration 2987][Wall Clock 303.048295183s] Trained 128 records in 0.081325097 seconds. Throughput is 1573.9298 records/second. Loss is 0.18151936. Sequential31006cbd's hyper parameters: Current learning rate is 0.006260956674179815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 22272/60000][Iteration 2988][Wall Clock 303.141442433s] Trained 128 records in 0.09314725 seconds. Throughput is 1374.1683 records/second. Loss is 0.2652387. Sequential31006cbd's hyper parameters: Current learning rate is 0.00626017278076875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 22400/60000][Iteration 2989][Wall Clock 303.245367009s] Trained 128 records in 0.103924576 seconds. Throughput is 1231.6625 records/second. Loss is 0.24675289. Sequential31006cbd's hyper parameters: Current learning rate is 0.006259389083625439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 22528/60000][Iteration 2990][Wall Clock 303.336831551s] Trained 128 records in 0.091464542 seconds. Throughput is 1399.4495 records/second. Loss is 0.21721604. Sequential31006cbd's hyper parameters: Current learning rate is 0.00625860558267618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:40 INFO  DistriOptimizer$:408 - [Epoch 7 22656/60000][Iteration 2991][Wall Clock 303.431763081s] Trained 128 records in 0.09493153 seconds. Throughput is 1348.3402 records/second. Loss is 0.16866045. Sequential31006cbd's hyper parameters: Current learning rate is 0.00625782227784731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 22784/60000][Iteration 2992][Wall Clock 303.517356211s] Trained 128 records in 0.08559313 seconds. Throughput is 1495.4471 records/second. Loss is 0.2783323. Sequential31006cbd's hyper parameters: Current learning rate is 0.006257039169065198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 22912/60000][Iteration 2993][Wall Clock 303.599290007s] Trained 128 records in 0.081933796 seconds. Throughput is 1562.2369 records/second. Loss is 0.18640682. Sequential31006cbd's hyper parameters: Current learning rate is 0.006256256256256257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23040/60000][Iteration 2994][Wall Clock 303.680335128s] Trained 128 records in 0.081045121 seconds. Throughput is 1579.3672 records/second. Loss is 0.23047829. Sequential31006cbd's hyper parameters: Current learning rate is 0.006255473539346928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23168/60000][Iteration 2995][Wall Clock 303.758477319s] Trained 128 records in 0.078142191 seconds. Throughput is 1638.0396 records/second. Loss is 0.18462345. Sequential31006cbd's hyper parameters: Current learning rate is 0.006254691018263698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23296/60000][Iteration 2996][Wall Clock 303.836821297s] Trained 128 records in 0.078343978 seconds. Throughput is 1633.8204 records/second. Loss is 0.24738392. Sequential31006cbd's hyper parameters: Current learning rate is 0.006253908692933083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23424/60000][Iteration 2997][Wall Clock 303.924316433s] Trained 128 records in 0.087495136 seconds. Throughput is 1462.9385 records/second. Loss is 0.22720277. Sequential31006cbd's hyper parameters: Current learning rate is 0.00625312656328164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23552/60000][Iteration 2998][Wall Clock 304.006844281s] Trained 128 records in 0.082527848 seconds. Throughput is 1550.9917 records/second. Loss is 0.20343013. Sequential31006cbd's hyper parameters: Current learning rate is 0.006252344629235963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23680/60000][Iteration 2999][Wall Clock 304.084743343s] Trained 128 records in 0.077899062 seconds. Throughput is 1643.152 records/second. Loss is 0.1741962. Sequential31006cbd's hyper parameters: Current learning rate is 0.00625156289072268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23808/60000][Iteration 3000][Wall Clock 304.166075384s] Trained 128 records in 0.081332041 seconds. Throughput is 1573.7954 records/second. Loss is 0.2894608. Sequential31006cbd's hyper parameters: Current learning rate is 0.006250781347668459. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 23936/60000][Iteration 3001][Wall Clock 304.247732935s] Trained 128 records in 0.081657551 seconds. Throughput is 1567.5219 records/second. Loss is 0.19719677. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062499999999999995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 24064/60000][Iteration 3002][Wall Clock 304.32849128s] Trained 128 records in 0.080758345 seconds. Throughput is 1584.9755 records/second. Loss is 0.2866339. Sequential31006cbd's hyper parameters: Current learning rate is 0.006249218847644044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 24192/60000][Iteration 3003][Wall Clock 304.411688173s] Trained 128 records in 0.083196893 seconds. Throughput is 1538.519 records/second. Loss is 0.25515336. Sequential31006cbd's hyper parameters: Current learning rate is 0.006248437890527368. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:41 INFO  DistriOptimizer$:408 - [Epoch 7 24320/60000][Iteration 3004][Wall Clock 304.497787362s] Trained 128 records in 0.086099189 seconds. Throughput is 1486.6573 records/second. Loss is 0.26389527. Sequential31006cbd's hyper parameters: Current learning rate is 0.006247657128576784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 24448/60000][Iteration 3005][Wall Clock 304.576112994s] Trained 128 records in 0.078325632 seconds. Throughput is 1634.2032 records/second. Loss is 0.31896782. Sequential31006cbd's hyper parameters: Current learning rate is 0.006246876561719141. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 24576/60000][Iteration 3006][Wall Clock 304.659250578s] Trained 128 records in 0.083137584 seconds. Throughput is 1539.6165 records/second. Loss is 0.24665412. Sequential31006cbd's hyper parameters: Current learning rate is 0.006246096189881325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 24704/60000][Iteration 3007][Wall Clock 304.744925885s] Trained 128 records in 0.085675307 seconds. Throughput is 1494.0127 records/second. Loss is 0.27967235. Sequential31006cbd's hyper parameters: Current learning rate is 0.006245316012990257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 24832/60000][Iteration 3008][Wall Clock 304.826576503s] Trained 128 records in 0.081650618 seconds. Throughput is 1567.655 records/second. Loss is 0.28008723. Sequential31006cbd's hyper parameters: Current learning rate is 0.006244536030972899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 24960/60000][Iteration 3009][Wall Clock 304.912624901s] Trained 128 records in 0.086048398 seconds. Throughput is 1487.535 records/second. Loss is 0.18023667. Sequential31006cbd's hyper parameters: Current learning rate is 0.006243756243756244. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 25088/60000][Iteration 3010][Wall Clock 304.991850628s] Trained 128 records in 0.079225727 seconds. Throughput is 1615.6368 records/second. Loss is 0.2137382. Sequential31006cbd's hyper parameters: Current learning rate is 0.006242976651267325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 25216/60000][Iteration 3011][Wall Clock 305.070836593s] Trained 128 records in 0.078985965 seconds. Throughput is 1620.541 records/second. Loss is 0.34543258. Sequential31006cbd's hyper parameters: Current learning rate is 0.006242197253433209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 25344/60000][Iteration 3012][Wall Clock 305.17226338s] Trained 128 records in 0.101426787 seconds. Throughput is 1261.994 records/second. Loss is 0.2696603. Sequential31006cbd's hyper parameters: Current learning rate is 0.006241418050181001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 25472/60000][Iteration 3013][Wall Clock 305.300417386s] Trained 128 records in 0.128154006 seconds. Throughput is 998.7982 records/second. Loss is 0.30533773. Sequential31006cbd's hyper parameters: Current learning rate is 0.006240639041437843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:42 INFO  DistriOptimizer$:408 - [Epoch 7 25600/60000][Iteration 3014][Wall Clock 305.405846812s] Trained 128 records in 0.105429426 seconds. Throughput is 1214.0823 records/second. Loss is 0.19623694. Sequential31006cbd's hyper parameters: Current learning rate is 0.006239860227130912. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 25728/60000][Iteration 3015][Wall Clock 305.500244268s] Trained 128 records in 0.094397456 seconds. Throughput is 1355.9688 records/second. Loss is 0.19130898. Sequential31006cbd's hyper parameters: Current learning rate is 0.006239081607187422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 25856/60000][Iteration 3016][Wall Clock 305.579577177s] Trained 128 records in 0.079332909 seconds. Throughput is 1613.454 records/second. Loss is 0.247724. Sequential31006cbd's hyper parameters: Current learning rate is 0.006238303181534623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 25984/60000][Iteration 3017][Wall Clock 305.661123074s] Trained 128 records in 0.081545897 seconds. Throughput is 1569.6682 records/second. Loss is 0.14347954. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062375249500997995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26112/60000][Iteration 3018][Wall Clock 305.740469758s] Trained 128 records in 0.079346684 seconds. Throughput is 1613.1738 records/second. Loss is 0.24630117. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062367469128102775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26240/60000][Iteration 3019][Wall Clock 305.823079793s] Trained 128 records in 0.082610035 seconds. Throughput is 1549.4486 records/second. Loss is 0.22964165. Sequential31006cbd's hyper parameters: Current learning rate is 0.006235969069593414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26368/60000][Iteration 3020][Wall Clock 305.900351461s] Trained 128 records in 0.077271668 seconds. Throughput is 1656.4933 records/second. Loss is 0.37761378. Sequential31006cbd's hyper parameters: Current learning rate is 0.006235191420376605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26496/60000][Iteration 3021][Wall Clock 305.99063738s] Trained 128 records in 0.090285919 seconds. Throughput is 1417.7183 records/second. Loss is 0.18344058. Sequential31006cbd's hyper parameters: Current learning rate is 0.006234413965087281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26624/60000][Iteration 3022][Wall Clock 306.072022272s] Trained 128 records in 0.081384892 seconds. Throughput is 1572.7736 records/second. Loss is 0.31274348. Sequential31006cbd's hyper parameters: Current learning rate is 0.006233636703652911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26752/60000][Iteration 3023][Wall Clock 306.15401917s] Trained 128 records in 0.081996898 seconds. Throughput is 1561.0347 records/second. Loss is 0.24291557. Sequential31006cbd's hyper parameters: Current learning rate is 0.006232859636000997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 26880/60000][Iteration 3024][Wall Clock 306.239207832s] Trained 128 records in 0.085188662 seconds. Throughput is 1502.5474 records/second. Loss is 0.31507248. Sequential31006cbd's hyper parameters: Current learning rate is 0.00623208276205908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 27008/60000][Iteration 3025][Wall Clock 306.320295357s] Trained 128 records in 0.081087525 seconds. Throughput is 1578.5413 records/second. Loss is 0.2420881. Sequential31006cbd's hyper parameters: Current learning rate is 0.006231306081754736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 27136/60000][Iteration 3026][Wall Clock 306.397967615s] Trained 128 records in 0.077672258 seconds. Throughput is 1647.9501 records/second. Loss is 0.23147364. Sequential31006cbd's hyper parameters: Current learning rate is 0.006230529595015576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:43 INFO  DistriOptimizer$:408 - [Epoch 7 27264/60000][Iteration 3027][Wall Clock 306.481858591s] Trained 128 records in 0.083890976 seconds. Throughput is 1525.7899 records/second. Loss is 0.27683684. Sequential31006cbd's hyper parameters: Current learning rate is 0.00622975330176925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 27392/60000][Iteration 3028][Wall Clock 306.561037757s] Trained 128 records in 0.079179166 seconds. Throughput is 1616.5868 records/second. Loss is 0.18853295. Sequential31006cbd's hyper parameters: Current learning rate is 0.006228977201943441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 27520/60000][Iteration 3029][Wall Clock 306.652213168s] Trained 128 records in 0.091175411 seconds. Throughput is 1403.8872 records/second. Loss is 0.21439809. Sequential31006cbd's hyper parameters: Current learning rate is 0.00622820129546587. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 27648/60000][Iteration 3030][Wall Clock 306.737379101s] Trained 128 records in 0.085165933 seconds. Throughput is 1502.9484 records/second. Loss is 0.29017547. Sequential31006cbd's hyper parameters: Current learning rate is 0.006227425582264292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 27776/60000][Iteration 3031][Wall Clock 306.820025604s] Trained 128 records in 0.082646503 seconds. Throughput is 1548.7649 records/second. Loss is 0.23647375. Sequential31006cbd's hyper parameters: Current learning rate is 0.006226650062266501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 27904/60000][Iteration 3032][Wall Clock 306.895192797s] Trained 128 records in 0.075167193 seconds. Throughput is 1702.8705 records/second. Loss is 0.2788513. Sequential31006cbd's hyper parameters: Current learning rate is 0.006225874735400323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 28032/60000][Iteration 3033][Wall Clock 306.977409465s] Trained 128 records in 0.082216668 seconds. Throughput is 1556.8619 records/second. Loss is 0.17037287. Sequential31006cbd's hyper parameters: Current learning rate is 0.006225099601593625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 28160/60000][Iteration 3034][Wall Clock 307.07145594s] Trained 128 records in 0.094046475 seconds. Throughput is 1361.0293 records/second. Loss is 0.29713178. Sequential31006cbd's hyper parameters: Current learning rate is 0.006224324660774306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 28288/60000][Iteration 3035][Wall Clock 307.150936213s] Trained 128 records in 0.079480273 seconds. Throughput is 1610.4624 records/second. Loss is 0.31084707. Sequential31006cbd's hyper parameters: Current learning rate is 0.006223549912870301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 28416/60000][Iteration 3036][Wall Clock 307.237816101s] Trained 128 records in 0.086879888 seconds. Throughput is 1473.2985 records/second. Loss is 0.20098321. Sequential31006cbd's hyper parameters: Current learning rate is 0.006222775357809583. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 28544/60000][Iteration 3037][Wall Clock 307.318241355s] Trained 128 records in 0.080425254 seconds. Throughput is 1591.5399 records/second. Loss is 0.2521027. Sequential31006cbd's hyper parameters: Current learning rate is 0.006222000995520159. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:44 INFO  DistriOptimizer$:408 - [Epoch 7 28672/60000][Iteration 3038][Wall Clock 307.40373158s] Trained 128 records in 0.085490225 seconds. Throughput is 1497.2472 records/second. Loss is 0.24725936. Sequential31006cbd's hyper parameters: Current learning rate is 0.006221226825930073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 28800/60000][Iteration 3039][Wall Clock 307.496583433s] Trained 128 records in 0.092851853 seconds. Throughput is 1378.54 records/second. Loss is 0.2939847. Sequential31006cbd's hyper parameters: Current learning rate is 0.006220452848967405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 28928/60000][Iteration 3040][Wall Clock 307.574461126s] Trained 128 records in 0.077877693 seconds. Throughput is 1643.6029 records/second. Loss is 0.24795179. Sequential31006cbd's hyper parameters: Current learning rate is 0.006219679064560268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29056/60000][Iteration 3041][Wall Clock 307.64959922s] Trained 128 records in 0.075138094 seconds. Throughput is 1703.53 records/second. Loss is 0.29547077. Sequential31006cbd's hyper parameters: Current learning rate is 0.006218905472636815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29184/60000][Iteration 3042][Wall Clock 307.72874602s] Trained 128 records in 0.0791468 seconds. Throughput is 1617.2479 records/second. Loss is 0.27900136. Sequential31006cbd's hyper parameters: Current learning rate is 0.006218132073125233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29312/60000][Iteration 3043][Wall Clock 307.813142882s] Trained 128 records in 0.084396862 seconds. Throughput is 1516.644 records/second. Loss is 0.15828124. Sequential31006cbd's hyper parameters: Current learning rate is 0.006217358865953743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29440/60000][Iteration 3044][Wall Clock 307.89877218s] Trained 128 records in 0.085629298 seconds. Throughput is 1494.8154 records/second. Loss is 0.28642282. Sequential31006cbd's hyper parameters: Current learning rate is 0.006216585851050603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29568/60000][Iteration 3045][Wall Clock 307.977652985s] Trained 128 records in 0.078880805 seconds. Throughput is 1622.7015 records/second. Loss is 0.2240276. Sequential31006cbd's hyper parameters: Current learning rate is 0.006215813028344107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29696/60000][Iteration 3046][Wall Clock 308.06707856s] Trained 128 records in 0.089425575 seconds. Throughput is 1431.3578 records/second. Loss is 0.2819699. Sequential31006cbd's hyper parameters: Current learning rate is 0.006215040397762586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29824/60000][Iteration 3047][Wall Clock 308.159462021s] Trained 128 records in 0.092383461 seconds. Throughput is 1385.5294 records/second. Loss is 0.29579535. Sequential31006cbd's hyper parameters: Current learning rate is 0.006214267959234403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 29952/60000][Iteration 3048][Wall Clock 308.252337627s] Trained 128 records in 0.092875606 seconds. Throughput is 1378.1875 records/second. Loss is 0.2732244. Sequential31006cbd's hyper parameters: Current learning rate is 0.006213495712687958. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 30080/60000][Iteration 3049][Wall Clock 308.339944051s] Trained 128 records in 0.087606424 seconds. Throughput is 1461.0801 records/second. Loss is 0.17976135. Sequential31006cbd's hyper parameters: Current learning rate is 0.00621272365805169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:45 INFO  DistriOptimizer$:408 - [Epoch 7 30208/60000][Iteration 3050][Wall Clock 308.422514795s] Trained 128 records in 0.082570744 seconds. Throughput is 1550.1858 records/second. Loss is 0.24748525. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062119517952540695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 30336/60000][Iteration 3051][Wall Clock 308.504414504s] Trained 128 records in 0.081899709 seconds. Throughput is 1562.8871 records/second. Loss is 0.32710534. Sequential31006cbd's hyper parameters: Current learning rate is 0.006211180124223603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 30464/60000][Iteration 3052][Wall Clock 308.585822989s] Trained 128 records in 0.081408485 seconds. Throughput is 1572.3176 records/second. Loss is 0.27250704. Sequential31006cbd's hyper parameters: Current learning rate is 0.006210408644888834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 30592/60000][Iteration 3053][Wall Clock 308.664525335s] Trained 128 records in 0.078702346 seconds. Throughput is 1626.381 records/second. Loss is 0.23069723. Sequential31006cbd's hyper parameters: Current learning rate is 0.00620963735717834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 30720/60000][Iteration 3054][Wall Clock 308.748941956s] Trained 128 records in 0.084416621 seconds. Throughput is 1516.2891 records/second. Loss is 0.19942488. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062088662610207375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 30848/60000][Iteration 3055][Wall Clock 308.829915911s] Trained 128 records in 0.080973955 seconds. Throughput is 1580.7552 records/second. Loss is 0.3285477. Sequential31006cbd's hyper parameters: Current learning rate is 0.006208095356344674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 30976/60000][Iteration 3056][Wall Clock 308.916196648s] Trained 128 records in 0.086280737 seconds. Throughput is 1483.5293 records/second. Loss is 0.3099023. Sequential31006cbd's hyper parameters: Current learning rate is 0.006207324643078833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 31104/60000][Iteration 3057][Wall Clock 308.996930311s] Trained 128 records in 0.080733663 seconds. Throughput is 1585.4601 records/second. Loss is 0.27627525. Sequential31006cbd's hyper parameters: Current learning rate is 0.006206554121151936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 31232/60000][Iteration 3058][Wall Clock 309.085897503s] Trained 128 records in 0.088967192 seconds. Throughput is 1438.7327 records/second. Loss is 0.18062073. Sequential31006cbd's hyper parameters: Current learning rate is 0.006205783790492738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 31360/60000][Iteration 3059][Wall Clock 309.163799513s] Trained 128 records in 0.07790201 seconds. Throughput is 1643.0898 records/second. Loss is 0.20602344. Sequential31006cbd's hyper parameters: Current learning rate is 0.006205013651030032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 31488/60000][Iteration 3060][Wall Clock 309.239745235s] Trained 128 records in 0.075945722 seconds. Throughput is 1685.4143 records/second. Loss is 0.222565. Sequential31006cbd's hyper parameters: Current learning rate is 0.006204243702692642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 31616/60000][Iteration 3061][Wall Clock 309.332348073s] Trained 128 records in 0.092602838 seconds. Throughput is 1382.247 records/second. Loss is 0.22461331. Sequential31006cbd's hyper parameters: Current learning rate is 0.006203473945409429. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:46 INFO  DistriOptimizer$:408 - [Epoch 7 31744/60000][Iteration 3062][Wall Clock 309.414759311s] Trained 128 records in 0.082411238 seconds. Throughput is 1553.1863 records/second. Loss is 0.32228035. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062027043791092916. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 31872/60000][Iteration 3063][Wall Clock 309.500481155s] Trained 128 records in 0.085721844 seconds. Throughput is 1493.2017 records/second. Loss is 0.180559. Sequential31006cbd's hyper parameters: Current learning rate is 0.006201935003721161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32000/60000][Iteration 3064][Wall Clock 309.602199281s] Trained 128 records in 0.101718126 seconds. Throughput is 1258.3794 records/second. Loss is 0.1873348. Sequential31006cbd's hyper parameters: Current learning rate is 0.0062011658191740045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32128/60000][Iteration 3065][Wall Clock 309.681751639s] Trained 128 records in 0.079552358 seconds. Throughput is 1609.0032 records/second. Loss is 0.1980151. Sequential31006cbd's hyper parameters: Current learning rate is 0.006200396825396825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32256/60000][Iteration 3066][Wall Clock 309.765160732s] Trained 128 records in 0.083409093 seconds. Throughput is 1534.6049 records/second. Loss is 0.31396624. Sequential31006cbd's hyper parameters: Current learning rate is 0.006199628022318661. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32384/60000][Iteration 3067][Wall Clock 309.854634087s] Trained 128 records in 0.089473355 seconds. Throughput is 1430.5935 records/second. Loss is 0.19021976. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061988594098685845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32512/60000][Iteration 3068][Wall Clock 309.934663816s] Trained 128 records in 0.080029729 seconds. Throughput is 1599.4056 records/second. Loss is 0.24831411. Sequential31006cbd's hyper parameters: Current learning rate is 0.006198090987975704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32640/60000][Iteration 3069][Wall Clock 310.015511423s] Trained 128 records in 0.080847607 seconds. Throughput is 1583.2256 records/second. Loss is 0.19841613. Sequential31006cbd's hyper parameters: Current learning rate is 0.006197322756569162. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32768/60000][Iteration 3070][Wall Clock 310.102040726s] Trained 128 records in 0.086529303 seconds. Throughput is 1479.2677 records/second. Loss is 0.22873323. Sequential31006cbd's hyper parameters: Current learning rate is 0.006196554715578139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 32896/60000][Iteration 3071][Wall Clock 310.186942063s] Trained 128 records in 0.084901337 seconds. Throughput is 1507.6323 records/second. Loss is 0.22099505. Sequential31006cbd's hyper parameters: Current learning rate is 0.006195786864931847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 33024/60000][Iteration 3072][Wall Clock 310.303184647s] Trained 128 records in 0.116242584 seconds. Throughput is 1101.1455 records/second. Loss is 0.34779987. Sequential31006cbd's hyper parameters: Current learning rate is 0.006195019204559534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:47 INFO  DistriOptimizer$:408 - [Epoch 7 33152/60000][Iteration 3073][Wall Clock 310.396350497s] Trained 128 records in 0.09316585 seconds. Throughput is 1373.8939 records/second. Loss is 0.19208008. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061942517343904855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 33280/60000][Iteration 3074][Wall Clock 310.48107549s] Trained 128 records in 0.084724993 seconds. Throughput is 1510.7703 records/second. Loss is 0.23793781. Sequential31006cbd's hyper parameters: Current learning rate is 0.00619348445435402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 33408/60000][Iteration 3075][Wall Clock 310.567077112s] Trained 128 records in 0.086001622 seconds. Throughput is 1488.3441 records/second. Loss is 0.19539736. Sequential31006cbd's hyper parameters: Current learning rate is 0.00619271736437949. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 33536/60000][Iteration 3076][Wall Clock 310.642568264s] Trained 128 records in 0.075491152 seconds. Throughput is 1695.563 records/second. Loss is 0.18552467. Sequential31006cbd's hyper parameters: Current learning rate is 0.006191950464396285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 33664/60000][Iteration 3077][Wall Clock 310.715939024s] Trained 128 records in 0.07337076 seconds. Throughput is 1744.5641 records/second. Loss is 0.31102926. Sequential31006cbd's hyper parameters: Current learning rate is 0.006191183754333828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 33792/60000][Iteration 3078][Wall Clock 310.799124661s] Trained 128 records in 0.083185637 seconds. Throughput is 1538.7272 records/second. Loss is 0.29716957. Sequential31006cbd's hyper parameters: Current learning rate is 0.006190417234121579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 33920/60000][Iteration 3079][Wall Clock 310.889093672s] Trained 128 records in 0.089969011 seconds. Throughput is 1422.7122 records/second. Loss is 0.24646862. Sequential31006cbd's hyper parameters: Current learning rate is 0.006189650903689031. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 34048/60000][Iteration 3080][Wall Clock 310.972964696s] Trained 128 records in 0.083871024 seconds. Throughput is 1526.1528 records/second. Loss is 0.32109448. Sequential31006cbd's hyper parameters: Current learning rate is 0.006188884762965714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 34176/60000][Iteration 3081][Wall Clock 311.058203841s] Trained 128 records in 0.085239145 seconds. Throughput is 1501.6576 records/second. Loss is 0.1820197. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061881188118811875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 34304/60000][Iteration 3082][Wall Clock 311.14316591s] Trained 128 records in 0.084962069 seconds. Throughput is 1506.5547 records/second. Loss is 0.25732824. Sequential31006cbd's hyper parameters: Current learning rate is 0.006187353050365054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 34432/60000][Iteration 3083][Wall Clock 311.227735395s] Trained 128 records in 0.084569485 seconds. Throughput is 1513.5483 records/second. Loss is 0.1260815. Sequential31006cbd's hyper parameters: Current learning rate is 0.006186587478346944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 34560/60000][Iteration 3084][Wall Clock 311.30198791s] Trained 128 records in 0.074252515 seconds. Throughput is 1723.8473 records/second. Loss is 0.29602623. Sequential31006cbd's hyper parameters: Current learning rate is 0.006185822095756526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:48 INFO  DistriOptimizer$:408 - [Epoch 7 34688/60000][Iteration 3085][Wall Clock 311.376941606s] Trained 128 records in 0.074953696 seconds. Throughput is 1707.721 records/second. Loss is 0.23544674. Sequential31006cbd's hyper parameters: Current learning rate is 0.006185056902523503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 34816/60000][Iteration 3086][Wall Clock 311.480513648s] Trained 128 records in 0.103572042 seconds. Throughput is 1235.8547 records/second. Loss is 0.25522417. Sequential31006cbd's hyper parameters: Current learning rate is 0.006184291898577613. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 34944/60000][Iteration 3087][Wall Clock 311.574816447s] Trained 128 records in 0.094302799 seconds. Throughput is 1357.3298 records/second. Loss is 0.27635565. Sequential31006cbd's hyper parameters: Current learning rate is 0.006183527083848627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35072/60000][Iteration 3088][Wall Clock 311.673769195s] Trained 128 records in 0.098952748 seconds. Throughput is 1293.5468 records/second. Loss is 0.2465286. Sequential31006cbd's hyper parameters: Current learning rate is 0.006182762458266353. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35200/60000][Iteration 3089][Wall Clock 311.755696145s] Trained 128 records in 0.08192695 seconds. Throughput is 1562.3674 records/second. Loss is 0.23626849. Sequential31006cbd's hyper parameters: Current learning rate is 0.006181998021760633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35328/60000][Iteration 3090][Wall Clock 311.855327055s] Trained 128 records in 0.09963091 seconds. Throughput is 1284.742 records/second. Loss is 0.38754553. Sequential31006cbd's hyper parameters: Current learning rate is 0.006181233774261343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35456/60000][Iteration 3091][Wall Clock 311.944626169s] Trained 128 records in 0.089299114 seconds. Throughput is 1433.3849 records/second. Loss is 0.41825742. Sequential31006cbd's hyper parameters: Current learning rate is 0.006180469715698394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35584/60000][Iteration 3092][Wall Clock 312.01919343s] Trained 128 records in 0.074567261 seconds. Throughput is 1716.571 records/second. Loss is 0.25568447. Sequential31006cbd's hyper parameters: Current learning rate is 0.00617970584600173. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35712/60000][Iteration 3093][Wall Clock 312.102062567s] Trained 128 records in 0.082869137 seconds. Throughput is 1544.604 records/second. Loss is 0.24365957. Sequential31006cbd's hyper parameters: Current learning rate is 0.006178942165101334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35840/60000][Iteration 3094][Wall Clock 312.185888661s] Trained 128 records in 0.083826094 seconds. Throughput is 1526.9708 records/second. Loss is 0.19396085. Sequential31006cbd's hyper parameters: Current learning rate is 0.006178178672927221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 35968/60000][Iteration 3095][Wall Clock 312.282043615s] Trained 128 records in 0.096154954 seconds. Throughput is 1331.1847 records/second. Loss is 0.20649064. Sequential31006cbd's hyper parameters: Current learning rate is 0.006177415369409439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:49 INFO  DistriOptimizer$:408 - [Epoch 7 36096/60000][Iteration 3096][Wall Clock 312.382733438s] Trained 128 records in 0.100689823 seconds. Throughput is 1271.2308 records/second. Loss is 0.23841423. Sequential31006cbd's hyper parameters: Current learning rate is 0.006176652254478073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36224/60000][Iteration 3097][Wall Clock 312.46120512s] Trained 128 records in 0.078471682 seconds. Throughput is 1631.1616 records/second. Loss is 0.25455508. Sequential31006cbd's hyper parameters: Current learning rate is 0.00617588932806324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36352/60000][Iteration 3098][Wall Clock 312.548554414s] Trained 128 records in 0.087349294 seconds. Throughput is 1465.381 records/second. Loss is 0.26135266. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061751265900950965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36480/60000][Iteration 3099][Wall Clock 312.647033046s] Trained 128 records in 0.098478632 seconds. Throughput is 1299.7744 records/second. Loss is 0.22618107. Sequential31006cbd's hyper parameters: Current learning rate is 0.006174364040503828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36608/60000][Iteration 3100][Wall Clock 312.72951957s] Trained 128 records in 0.082486524 seconds. Throughput is 1551.7686 records/second. Loss is 0.18627536. Sequential31006cbd's hyper parameters: Current learning rate is 0.006173601679219656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36736/60000][Iteration 3101][Wall Clock 312.804423713s] Trained 128 records in 0.074904143 seconds. Throughput is 1708.8507 records/second. Loss is 0.18820126. Sequential31006cbd's hyper parameters: Current learning rate is 0.006172839506172839. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36864/60000][Iteration 3102][Wall Clock 312.88281522s] Trained 128 records in 0.078391507 seconds. Throughput is 1632.83 records/second. Loss is 0.3195811. Sequential31006cbd's hyper parameters: Current learning rate is 0.006172077521293667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 36992/60000][Iteration 3103][Wall Clock 312.974130617s] Trained 128 records in 0.091315397 seconds. Throughput is 1401.7351 records/second. Loss is 0.28325617. Sequential31006cbd's hyper parameters: Current learning rate is 0.006171315724512466. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 37120/60000][Iteration 3104][Wall Clock 313.056660301s] Trained 128 records in 0.082529684 seconds. Throughput is 1550.957 records/second. Loss is 0.26824078. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061705541157595955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 37248/60000][Iteration 3105][Wall Clock 313.134363355s] Trained 128 records in 0.077703054 seconds. Throughput is 1647.297 records/second. Loss is 0.3756097. Sequential31006cbd's hyper parameters: Current learning rate is 0.006169792694965449. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 37376/60000][Iteration 3106][Wall Clock 313.215139078s] Trained 128 records in 0.080775723 seconds. Throughput is 1584.6345 records/second. Loss is 0.21152613. Sequential31006cbd's hyper parameters: Current learning rate is 0.006169031462060457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 37504/60000][Iteration 3107][Wall Clock 313.296918214s] Trained 128 records in 0.081779136 seconds. Throughput is 1565.1914 records/second. Loss is 0.25405154. Sequential31006cbd's hyper parameters: Current learning rate is 0.00616827041697508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:50 INFO  DistriOptimizer$:408 - [Epoch 7 37632/60000][Iteration 3108][Wall Clock 313.378830536s] Trained 128 records in 0.081912322 seconds. Throughput is 1562.6465 records/second. Loss is 0.23273145. Sequential31006cbd's hyper parameters: Current learning rate is 0.006167509559639818. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 37760/60000][Iteration 3109][Wall Clock 313.455847096s] Trained 128 records in 0.07701656 seconds. Throughput is 1661.9802 records/second. Loss is 0.27346426. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061667488899852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 37888/60000][Iteration 3110][Wall Clock 313.532875788s] Trained 128 records in 0.077028692 seconds. Throughput is 1661.7185 records/second. Loss is 0.18565035. Sequential31006cbd's hyper parameters: Current learning rate is 0.006165988407941794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38016/60000][Iteration 3111][Wall Clock 313.610583188s] Trained 128 records in 0.0777074 seconds. Throughput is 1647.2047 records/second. Loss is 0.23756298. Sequential31006cbd's hyper parameters: Current learning rate is 0.006165228113440198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38144/60000][Iteration 3112][Wall Clock 313.688942632s] Trained 128 records in 0.078359444 seconds. Throughput is 1633.498 records/second. Loss is 0.24193901. Sequential31006cbd's hyper parameters: Current learning rate is 0.006164468006411047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38272/60000][Iteration 3113][Wall Clock 313.77792259s] Trained 128 records in 0.088979958 seconds. Throughput is 1438.5261 records/second. Loss is 0.23036003. Sequential31006cbd's hyper parameters: Current learning rate is 0.00616370808678501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38400/60000][Iteration 3114][Wall Clock 313.885416864s] Trained 128 records in 0.107494274 seconds. Throughput is 1190.7611 records/second. Loss is 0.25800908. Sequential31006cbd's hyper parameters: Current learning rate is 0.006162948354492789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38528/60000][Iteration 3115][Wall Clock 314.026590041s] Trained 128 records in 0.141173177 seconds. Throughput is 906.6878 records/second. Loss is 0.26721603. Sequential31006cbd's hyper parameters: Current learning rate is 0.006162188809465122. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38656/60000][Iteration 3116][Wall Clock 314.12445885s] Trained 128 records in 0.097868809 seconds. Throughput is 1307.8733 records/second. Loss is 0.29415715. Sequential31006cbd's hyper parameters: Current learning rate is 0.006161429451632779. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38784/60000][Iteration 3117][Wall Clock 314.213494276s] Trained 128 records in 0.089035426 seconds. Throughput is 1437.63 records/second. Loss is 0.30903134. Sequential31006cbd's hyper parameters: Current learning rate is 0.006160670280926565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 38912/60000][Iteration 3118][Wall Clock 314.299046646s] Trained 128 records in 0.08555237 seconds. Throughput is 1496.1595 records/second. Loss is 0.2645872. Sequential31006cbd's hyper parameters: Current learning rate is 0.006159911297277319. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:51 INFO  DistriOptimizer$:408 - [Epoch 7 39040/60000][Iteration 3119][Wall Clock 314.378876185s] Trained 128 records in 0.079829539 seconds. Throughput is 1603.4165 records/second. Loss is 0.32021886. Sequential31006cbd's hyper parameters: Current learning rate is 0.006159152500615914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39168/60000][Iteration 3120][Wall Clock 314.460324543s] Trained 128 records in 0.081448358 seconds. Throughput is 1571.5479 records/second. Loss is 0.25859421. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061583938908732596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39296/60000][Iteration 3121][Wall Clock 314.545276127s] Trained 128 records in 0.084951584 seconds. Throughput is 1506.7405 records/second. Loss is 0.22349444. Sequential31006cbd's hyper parameters: Current learning rate is 0.006157635467980295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39424/60000][Iteration 3122][Wall Clock 314.64723348s] Trained 128 records in 0.101957353 seconds. Throughput is 1255.4269 records/second. Loss is 0.26621142. Sequential31006cbd's hyper parameters: Current learning rate is 0.006156877231867996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39552/60000][Iteration 3123][Wall Clock 314.747855251s] Trained 128 records in 0.100621771 seconds. Throughput is 1272.0906 records/second. Loss is 0.28285155. Sequential31006cbd's hyper parameters: Current learning rate is 0.006156119182467373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39680/60000][Iteration 3124][Wall Clock 314.828869773s] Trained 128 records in 0.081014522 seconds. Throughput is 1579.9636 records/second. Loss is 0.23425484. Sequential31006cbd's hyper parameters: Current learning rate is 0.006155361319709467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39808/60000][Iteration 3125][Wall Clock 314.917547333s] Trained 128 records in 0.08867756 seconds. Throughput is 1443.4316 records/second. Loss is 0.17966662. Sequential31006cbd's hyper parameters: Current learning rate is 0.006154603643525357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 39936/60000][Iteration 3126][Wall Clock 314.997312489s] Trained 128 records in 0.079765156 seconds. Throughput is 1604.7107 records/second. Loss is 0.33556587. Sequential31006cbd's hyper parameters: Current learning rate is 0.006153846153846154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 40064/60000][Iteration 3127][Wall Clock 315.074564649s] Trained 128 records in 0.07725216 seconds. Throughput is 1656.9116 records/second. Loss is 0.2654985. Sequential31006cbd's hyper parameters: Current learning rate is 0.006153088850603003. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 40192/60000][Iteration 3128][Wall Clock 315.164022945s] Trained 128 records in 0.089458296 seconds. Throughput is 1430.8344 records/second. Loss is 0.17707375. Sequential31006cbd's hyper parameters: Current learning rate is 0.006152331733727083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 40320/60000][Iteration 3129][Wall Clock 315.255476096s] Trained 128 records in 0.091453151 seconds. Throughput is 1399.6238 records/second. Loss is 0.19231164. Sequential31006cbd's hyper parameters: Current learning rate is 0.006151574803149607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 40448/60000][Iteration 3130][Wall Clock 315.337022023s] Trained 128 records in 0.081545927 seconds. Throughput is 1569.6676 records/second. Loss is 0.28844312. Sequential31006cbd's hyper parameters: Current learning rate is 0.006150818058801821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:52 INFO  DistriOptimizer$:408 - [Epoch 7 40576/60000][Iteration 3131][Wall Clock 315.408563659s] Trained 128 records in 0.071541636 seconds. Throughput is 1789.1678 records/second. Loss is 0.30357188. Sequential31006cbd's hyper parameters: Current learning rate is 0.006150061500615007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 40704/60000][Iteration 3132][Wall Clock 315.485707052s] Trained 128 records in 0.077143393 seconds. Throughput is 1659.2477 records/second. Loss is 0.21856616. Sequential31006cbd's hyper parameters: Current learning rate is 0.006149305128520478. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 40832/60000][Iteration 3133][Wall Clock 315.565379302s] Trained 128 records in 0.07967225 seconds. Throughput is 1606.582 records/second. Loss is 0.26967043. Sequential31006cbd's hyper parameters: Current learning rate is 0.006148548942449582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 40960/60000][Iteration 3134][Wall Clock 315.647539096s] Trained 128 records in 0.082159794 seconds. Throughput is 1557.9396 records/second. Loss is 0.288579. Sequential31006cbd's hyper parameters: Current learning rate is 0.006147792942333702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41088/60000][Iteration 3135][Wall Clock 315.732612363s] Trained 128 records in 0.085073267 seconds. Throughput is 1504.5854 records/second. Loss is 0.30051172. Sequential31006cbd's hyper parameters: Current learning rate is 0.006147037128104254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41216/60000][Iteration 3136][Wall Clock 315.82705181s] Trained 128 records in 0.094439447 seconds. Throughput is 1355.3658 records/second. Loss is 0.24375266. Sequential31006cbd's hyper parameters: Current learning rate is 0.006146281499692686. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41344/60000][Iteration 3137][Wall Clock 315.907904673s] Trained 128 records in 0.080852863 seconds. Throughput is 1583.1226 records/second. Loss is 0.21795866. Sequential31006cbd's hyper parameters: Current learning rate is 0.006145526057030482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41472/60000][Iteration 3138][Wall Clock 316.015507245s] Trained 128 records in 0.107602572 seconds. Throughput is 1189.5626 records/second. Loss is 0.21894693. Sequential31006cbd's hyper parameters: Current learning rate is 0.006144770800049158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41600/60000][Iteration 3139][Wall Clock 316.099804609s] Trained 128 records in 0.084297364 seconds. Throughput is 1518.4342 records/second. Loss is 0.19529277. Sequential31006cbd's hyper parameters: Current learning rate is 0.006144015728680265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41728/60000][Iteration 3140][Wall Clock 316.181586088s] Trained 128 records in 0.081781479 seconds. Throughput is 1565.1466 records/second. Loss is 0.28325355. Sequential31006cbd's hyper parameters: Current learning rate is 0.006143260842855387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41856/60000][Iteration 3141][Wall Clock 316.272035662s] Trained 128 records in 0.090449574 seconds. Throughput is 1415.1532 records/second. Loss is 0.2796986. Sequential31006cbd's hyper parameters: Current learning rate is 0.006142506142506142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:53 INFO  DistriOptimizer$:408 - [Epoch 7 41984/60000][Iteration 3142][Wall Clock 316.362538789s] Trained 128 records in 0.090503127 seconds. Throughput is 1414.3158 records/second. Loss is 0.3100546. Sequential31006cbd's hyper parameters: Current learning rate is 0.006141751627564181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42112/60000][Iteration 3143][Wall Clock 316.444440038s] Trained 128 records in 0.081901249 seconds. Throughput is 1562.8577 records/second. Loss is 0.1848778. Sequential31006cbd's hyper parameters: Current learning rate is 0.006140997297961189. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42240/60000][Iteration 3144][Wall Clock 316.5224774s] Trained 128 records in 0.078037362 seconds. Throughput is 1640.24 records/second. Loss is 0.1883285. Sequential31006cbd's hyper parameters: Current learning rate is 0.006140243153628884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42368/60000][Iteration 3145][Wall Clock 316.606264193s] Trained 128 records in 0.083786793 seconds. Throughput is 1527.687 records/second. Loss is 0.28134343. Sequential31006cbd's hyper parameters: Current learning rate is 0.006139489194499017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42496/60000][Iteration 3146][Wall Clock 316.693422125s] Trained 128 records in 0.087157932 seconds. Throughput is 1468.5984 records/second. Loss is 0.27390772. Sequential31006cbd's hyper parameters: Current learning rate is 0.006138735420503376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42624/60000][Iteration 3147][Wall Clock 316.786711498s] Trained 128 records in 0.093289373 seconds. Throughput is 1372.0748 records/second. Loss is 0.2391305. Sequential31006cbd's hyper parameters: Current learning rate is 0.006137981831573778. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42752/60000][Iteration 3148][Wall Clock 316.893179352s] Trained 128 records in 0.106467854 seconds. Throughput is 1202.2408 records/second. Loss is 0.33455423. Sequential31006cbd's hyper parameters: Current learning rate is 0.006137228427642077. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 42880/60000][Iteration 3149][Wall Clock 317.010981757s] Trained 128 records in 0.117802405 seconds. Throughput is 1086.5653 records/second. Loss is 0.22154409. Sequential31006cbd's hyper parameters: Current learning rate is 0.006136475208640158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 43008/60000][Iteration 3150][Wall Clock 317.102786864s] Trained 128 records in 0.091805107 seconds. Throughput is 1394.2579 records/second. Loss is 0.2616419. Sequential31006cbd's hyper parameters: Current learning rate is 0.006135722174499939. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 43136/60000][Iteration 3151][Wall Clock 317.183524182s] Trained 128 records in 0.080737318 seconds. Throughput is 1585.3883 records/second. Loss is 0.2714859. Sequential31006cbd's hyper parameters: Current learning rate is 0.006134969325153374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 43264/60000][Iteration 3152][Wall Clock 317.263068169s] Trained 128 records in 0.079543987 seconds. Throughput is 1609.1726 records/second. Loss is 0.2888789. Sequential31006cbd's hyper parameters: Current learning rate is 0.00613421666053245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 43392/60000][Iteration 3153][Wall Clock 317.343837184s] Trained 128 records in 0.080769015 seconds. Throughput is 1584.7661 records/second. Loss is 0.22789955. Sequential31006cbd's hyper parameters: Current learning rate is 0.006133464180569185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:54 INFO  DistriOptimizer$:408 - [Epoch 7 43520/60000][Iteration 3154][Wall Clock 317.420299767s] Trained 128 records in 0.076462583 seconds. Throughput is 1674.0215 records/second. Loss is 0.19593742. Sequential31006cbd's hyper parameters: Current learning rate is 0.006132711885195634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 43648/60000][Iteration 3155][Wall Clock 317.498537827s] Trained 128 records in 0.07823806 seconds. Throughput is 1636.0323 records/second. Loss is 0.25463474. Sequential31006cbd's hyper parameters: Current learning rate is 0.00613195977434388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 43776/60000][Iteration 3156][Wall Clock 317.577299392s] Trained 128 records in 0.078761565 seconds. Throughput is 1625.1582 records/second. Loss is 0.19724773. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061312078479460455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 43904/60000][Iteration 3157][Wall Clock 317.675611147s] Trained 128 records in 0.098311755 seconds. Throughput is 1301.9807 records/second. Loss is 0.285589. Sequential31006cbd's hyper parameters: Current learning rate is 0.006130456105934282. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44032/60000][Iteration 3158][Wall Clock 317.75689796s] Trained 128 records in 0.081286813 seconds. Throughput is 1574.6713 records/second. Loss is 0.3469909. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061297045482407745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44160/60000][Iteration 3159][Wall Clock 317.83640433s] Trained 128 records in 0.07950637 seconds. Throughput is 1609.934 records/second. Loss is 0.1729866. Sequential31006cbd's hyper parameters: Current learning rate is 0.006128953174797744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44288/60000][Iteration 3160][Wall Clock 317.911145405s] Trained 128 records in 0.074741075 seconds. Throughput is 1712.5791 records/second. Loss is 0.26768857. Sequential31006cbd's hyper parameters: Current learning rate is 0.006128201985537443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44416/60000][Iteration 3161][Wall Clock 317.98659713s] Trained 128 records in 0.075451725 seconds. Throughput is 1696.449 records/second. Loss is 0.34798273. Sequential31006cbd's hyper parameters: Current learning rate is 0.006127450980392157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44544/60000][Iteration 3162][Wall Clock 318.06269542s] Trained 128 records in 0.07609829 seconds. Throughput is 1682.0352 records/second. Loss is 0.22059846. Sequential31006cbd's hyper parameters: Current learning rate is 0.006126700159294204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44672/60000][Iteration 3163][Wall Clock 318.150589572s] Trained 128 records in 0.087894152 seconds. Throughput is 1456.2971 records/second. Loss is 0.25397596. Sequential31006cbd's hyper parameters: Current learning rate is 0.006125949522175937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44800/60000][Iteration 3164][Wall Clock 318.229065974s] Trained 128 records in 0.078476402 seconds. Throughput is 1631.0636 records/second. Loss is 0.32564682. Sequential31006cbd's hyper parameters: Current learning rate is 0.006125199068969742. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 44928/60000][Iteration 3165][Wall Clock 318.315613067s] Trained 128 records in 0.086547093 seconds. Throughput is 1478.9636 records/second. Loss is 0.23135674. Sequential31006cbd's hyper parameters: Current learning rate is 0.006124448799608035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:55 INFO  DistriOptimizer$:408 - [Epoch 7 45056/60000][Iteration 3166][Wall Clock 318.392224146s] Trained 128 records in 0.076611079 seconds. Throughput is 1670.7766 records/second. Loss is 0.20173195. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061236987140232705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45184/60000][Iteration 3167][Wall Clock 318.468800155s] Trained 128 records in 0.076576009 seconds. Throughput is 1671.5417 records/second. Loss is 0.26913393. Sequential31006cbd's hyper parameters: Current learning rate is 0.006122948812147931. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45312/60000][Iteration 3168][Wall Clock 318.548676438s] Trained 128 records in 0.079876283 seconds. Throughput is 1602.4781 records/second. Loss is 0.27036524. Sequential31006cbd's hyper parameters: Current learning rate is 0.006122199093914534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45440/60000][Iteration 3169][Wall Clock 318.633487229s] Trained 128 records in 0.084810791 seconds. Throughput is 1509.2418 records/second. Loss is 0.22932504. Sequential31006cbd's hyper parameters: Current learning rate is 0.006121449559255632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45568/60000][Iteration 3170][Wall Clock 318.71466341s] Trained 128 records in 0.081176181 seconds. Throughput is 1576.8171 records/second. Loss is 0.34835202. Sequential31006cbd's hyper parameters: Current learning rate is 0.006120700208103807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45696/60000][Iteration 3171][Wall Clock 318.803028832s] Trained 128 records in 0.088365422 seconds. Throughput is 1448.5304 records/second. Loss is 0.24571729. Sequential31006cbd's hyper parameters: Current learning rate is 0.006119951040391677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45824/60000][Iteration 3172][Wall Clock 318.879866741s] Trained 128 records in 0.076837909 seconds. Throughput is 1665.8444 records/second. Loss is 0.2949855. Sequential31006cbd's hyper parameters: Current learning rate is 0.006119202056051891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 45952/60000][Iteration 3173][Wall Clock 318.957292936s] Trained 128 records in 0.077426195 seconds. Throughput is 1653.1873 records/second. Loss is 0.23490131. Sequential31006cbd's hyper parameters: Current learning rate is 0.006118453255017132. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 46080/60000][Iteration 3174][Wall Clock 319.037844731s] Trained 128 records in 0.080551795 seconds. Throughput is 1589.0397 records/second. Loss is 0.17247374. Sequential31006cbd's hyper parameters: Current learning rate is 0.006117704637220115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 46208/60000][Iteration 3175][Wall Clock 319.133741543s] Trained 128 records in 0.095896812 seconds. Throughput is 1334.7681 records/second. Loss is 0.30789262. Sequential31006cbd's hyper parameters: Current learning rate is 0.006116956202593589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 46336/60000][Iteration 3176][Wall Clock 319.223879292s] Trained 128 records in 0.090137749 seconds. Throughput is 1420.0487 records/second. Loss is 0.35236323. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061162079510703364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:56 INFO  DistriOptimizer$:408 - [Epoch 7 46464/60000][Iteration 3177][Wall Clock 319.330383325s] Trained 128 records in 0.106504033 seconds. Throughput is 1201.8324 records/second. Loss is 0.25030273. Sequential31006cbd's hyper parameters: Current learning rate is 0.006115459882583171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 46592/60000][Iteration 3178][Wall Clock 319.451060568s] Trained 128 records in 0.120677243 seconds. Throughput is 1060.6805 records/second. Loss is 0.20260279. Sequential31006cbd's hyper parameters: Current learning rate is 0.006114711997064938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 46720/60000][Iteration 3179][Wall Clock 319.577250104s] Trained 128 records in 0.126189536 seconds. Throughput is 1014.3472 records/second. Loss is 0.24130177. Sequential31006cbd's hyper parameters: Current learning rate is 0.00611396429444852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 46848/60000][Iteration 3180][Wall Clock 319.703440762s] Trained 128 records in 0.126190658 seconds. Throughput is 1014.33813 records/second. Loss is 0.22783956. Sequential31006cbd's hyper parameters: Current learning rate is 0.006113216774666829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 46976/60000][Iteration 3181][Wall Clock 319.791918798s] Trained 128 records in 0.088478036 seconds. Throughput is 1446.6868 records/second. Loss is 0.2570556. Sequential31006cbd's hyper parameters: Current learning rate is 0.006112469437652811. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 47104/60000][Iteration 3182][Wall Clock 319.897603013s] Trained 128 records in 0.105684215 seconds. Throughput is 1211.1554 records/second. Loss is 0.22580436. Sequential31006cbd's hyper parameters: Current learning rate is 0.006111722283339445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 47232/60000][Iteration 3183][Wall Clock 319.976180215s] Trained 128 records in 0.078577202 seconds. Throughput is 1628.9712 records/second. Loss is 0.3229288. Sequential31006cbd's hyper parameters: Current learning rate is 0.006110975311659741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 47360/60000][Iteration 3184][Wall Clock 320.082607806s] Trained 128 records in 0.106427591 seconds. Throughput is 1202.6957 records/second. Loss is 0.2420431. Sequential31006cbd's hyper parameters: Current learning rate is 0.006110228522546743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 47488/60000][Iteration 3185][Wall Clock 320.1996905s] Trained 128 records in 0.117082694 seconds. Throughput is 1093.2444 records/second. Loss is 0.18878764. Sequential31006cbd's hyper parameters: Current learning rate is 0.006109481915933529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 47616/60000][Iteration 3186][Wall Clock 320.306415752s] Trained 128 records in 0.106725252 seconds. Throughput is 1199.3413 records/second. Loss is 0.2650494. Sequential31006cbd's hyper parameters: Current learning rate is 0.006108735491753207. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:57 INFO  DistriOptimizer$:408 - [Epoch 7 47744/60000][Iteration 3187][Wall Clock 320.413099081s] Trained 128 records in 0.106683329 seconds. Throughput is 1199.8126 records/second. Loss is 0.24755098. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061079892499389206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 47872/60000][Iteration 3188][Wall Clock 320.520331677s] Trained 128 records in 0.107232596 seconds. Throughput is 1193.6669 records/second. Loss is 0.27762312. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061072431904238425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48000/60000][Iteration 3189][Wall Clock 320.66977088s] Trained 128 records in 0.149439203 seconds. Throughput is 856.53564 records/second. Loss is 0.30637687. Sequential31006cbd's hyper parameters: Current learning rate is 0.006106497313141183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48128/60000][Iteration 3190][Wall Clock 320.784974201s] Trained 128 records in 0.115203321 seconds. Throughput is 1111.0791 records/second. Loss is 0.2942518. Sequential31006cbd's hyper parameters: Current learning rate is 0.006105751618024179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48256/60000][Iteration 3191][Wall Clock 320.897926975s] Trained 128 records in 0.112952774 seconds. Throughput is 1133.2169 records/second. Loss is 0.22130816. Sequential31006cbd's hyper parameters: Current learning rate is 0.006105006105006106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48384/60000][Iteration 3192][Wall Clock 320.999991572s] Trained 128 records in 0.102064597 seconds. Throughput is 1254.1078 records/second. Loss is 0.23181526. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061042607740202665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48512/60000][Iteration 3193][Wall Clock 321.077837963s] Trained 128 records in 0.077846391 seconds. Throughput is 1644.2637 records/second. Loss is 0.2072972. Sequential31006cbd's hyper parameters: Current learning rate is 0.006103515625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48640/60000][Iteration 3194][Wall Clock 321.170578971s] Trained 128 records in 0.092741008 seconds. Throughput is 1380.1877 records/second. Loss is 0.26783603. Sequential31006cbd's hyper parameters: Current learning rate is 0.006102770657878676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48768/60000][Iteration 3195][Wall Clock 321.253545899s] Trained 128 records in 0.082966928 seconds. Throughput is 1542.7833 records/second. Loss is 0.24295288. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061020258725897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:58 INFO  DistriOptimizer$:408 - [Epoch 7 48896/60000][Iteration 3196][Wall Clock 321.334994567s] Trained 128 records in 0.081448668 seconds. Throughput is 1571.542 records/second. Loss is 0.25047308. Sequential31006cbd's hyper parameters: Current learning rate is 0.006101281269066504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49024/60000][Iteration 3197][Wall Clock 321.443276347s] Trained 128 records in 0.10828178 seconds. Throughput is 1182.1011 records/second. Loss is 0.23042734. Sequential31006cbd's hyper parameters: Current learning rate is 0.0061005368472425575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49152/60000][Iteration 3198][Wall Clock 321.529182199s] Trained 128 records in 0.085905852 seconds. Throughput is 1490.0033 records/second. Loss is 0.19570434. Sequential31006cbd's hyper parameters: Current learning rate is 0.006099792607051359. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49280/60000][Iteration 3199][Wall Clock 321.623008355s] Trained 128 records in 0.093826156 seconds. Throughput is 1364.2252 records/second. Loss is 0.18332516. Sequential31006cbd's hyper parameters: Current learning rate is 0.006099048548426445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49408/60000][Iteration 3200][Wall Clock 321.756420434s] Trained 128 records in 0.133412079 seconds. Throughput is 959.43335 records/second. Loss is 0.18515228. Sequential31006cbd's hyper parameters: Current learning rate is 0.006098304671301378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49536/60000][Iteration 3201][Wall Clock 321.83770759s] Trained 128 records in 0.081287156 seconds. Throughput is 1574.6646 records/second. Loss is 0.30919138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060975609756097554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49664/60000][Iteration 3202][Wall Clock 321.926377967s] Trained 128 records in 0.088670377 seconds. Throughput is 1443.5486 records/second. Loss is 0.23552443. Sequential31006cbd's hyper parameters: Current learning rate is 0.006096817461285209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49792/60000][Iteration 3203][Wall Clock 322.008865146s] Trained 128 records in 0.082487179 seconds. Throughput is 1551.7562 records/second. Loss is 0.2679911. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060960741282614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 49920/60000][Iteration 3204][Wall Clock 322.090192948s] Trained 128 records in 0.081327802 seconds. Throughput is 1573.8774 records/second. Loss is 0.2688859. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060953309764720225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 50048/60000][Iteration 3205][Wall Clock 322.170690356s] Trained 128 records in 0.080497408 seconds. Throughput is 1590.1134 records/second. Loss is 0.218135. Sequential31006cbd's hyper parameters: Current learning rate is 0.006094588005850805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 50176/60000][Iteration 3206][Wall Clock 322.250611202s] Trained 128 records in 0.079920846 seconds. Throughput is 1601.5847 records/second. Loss is 0.20824407. Sequential31006cbd's hyper parameters: Current learning rate is 0.006093845216331505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 50304/60000][Iteration 3207][Wall Clock 322.334899153s] Trained 128 records in 0.084287951 seconds. Throughput is 1518.6038 records/second. Loss is 0.1886591. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060931026078479165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:02:59 INFO  DistriOptimizer$:408 - [Epoch 7 50432/60000][Iteration 3208][Wall Clock 322.417564979s] Trained 128 records in 0.082665826 seconds. Throughput is 1548.4028 records/second. Loss is 0.23436962. Sequential31006cbd's hyper parameters: Current learning rate is 0.006092360180333861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 50560/60000][Iteration 3209][Wall Clock 322.506561329s] Trained 128 records in 0.08899635 seconds. Throughput is 1438.2612 records/second. Loss is 0.17621896. Sequential31006cbd's hyper parameters: Current learning rate is 0.006091617933723197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 50688/60000][Iteration 3210][Wall Clock 322.585019187s] Trained 128 records in 0.078457858 seconds. Throughput is 1631.4491 records/second. Loss is 0.24625376. Sequential31006cbd's hyper parameters: Current learning rate is 0.006090875867949812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 50816/60000][Iteration 3211][Wall Clock 322.667417508s] Trained 128 records in 0.082398321 seconds. Throughput is 1553.4298 records/second. Loss is 0.32565603. Sequential31006cbd's hyper parameters: Current learning rate is 0.006090133982947625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 50944/60000][Iteration 3212][Wall Clock 322.749267023s] Trained 128 records in 0.081849515 seconds. Throughput is 1563.8456 records/second. Loss is 0.25452408. Sequential31006cbd's hyper parameters: Current learning rate is 0.006089392278650591. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51072/60000][Iteration 3213][Wall Clock 322.829438153s] Trained 128 records in 0.08017113 seconds. Throughput is 1596.5847 records/second. Loss is 0.19627136. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060886507549926935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51200/60000][Iteration 3214][Wall Clock 322.929260722s] Trained 128 records in 0.099822569 seconds. Throughput is 1282.2751 records/second. Loss is 0.3462955. Sequential31006cbd's hyper parameters: Current learning rate is 0.00608790941190795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51328/60000][Iteration 3215][Wall Clock 323.005687254s] Trained 128 records in 0.076426532 seconds. Throughput is 1674.8112 records/second. Loss is 0.24881592. Sequential31006cbd's hyper parameters: Current learning rate is 0.006087168249330412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51456/60000][Iteration 3216][Wall Clock 323.08664768s] Trained 128 records in 0.080960426 seconds. Throughput is 1581.0194 records/second. Loss is 0.25010484. Sequential31006cbd's hyper parameters: Current learning rate is 0.006086427267194157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51584/60000][Iteration 3217][Wall Clock 323.17167946s] Trained 128 records in 0.08503178 seconds. Throughput is 1505.3196 records/second. Loss is 0.28174534. Sequential31006cbd's hyper parameters: Current learning rate is 0.006085686465433301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51712/60000][Iteration 3218][Wall Clock 323.263779555s] Trained 128 records in 0.092100095 seconds. Throughput is 1389.7924 records/second. Loss is 0.21670052. Sequential31006cbd's hyper parameters: Current learning rate is 0.006084945843981988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:00 INFO  DistriOptimizer$:408 - [Epoch 7 51840/60000][Iteration 3219][Wall Clock 323.346356778s] Trained 128 records in 0.082577223 seconds. Throughput is 1550.0643 records/second. Loss is 0.29867393. Sequential31006cbd's hyper parameters: Current learning rate is 0.006084205402774397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 51968/60000][Iteration 3220][Wall Clock 323.427788668s] Trained 128 records in 0.08143189 seconds. Throughput is 1571.8658 records/second. Loss is 0.19239055. Sequential31006cbd's hyper parameters: Current learning rate is 0.006083465141744737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52096/60000][Iteration 3221][Wall Clock 323.503865756s] Trained 128 records in 0.076077088 seconds. Throughput is 1682.5039 records/second. Loss is 0.3527995. Sequential31006cbd's hyper parameters: Current learning rate is 0.00608272506082725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52224/60000][Iteration 3222][Wall Clock 323.581948944s] Trained 128 records in 0.078083188 seconds. Throughput is 1639.2773 records/second. Loss is 0.23320891. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060819851599562096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52352/60000][Iteration 3223][Wall Clock 323.656286075s] Trained 128 records in 0.074337131 seconds. Throughput is 1721.8851 records/second. Loss is 0.21878175. Sequential31006cbd's hyper parameters: Current learning rate is 0.006081245439065921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52480/60000][Iteration 3224][Wall Clock 323.738018552s] Trained 128 records in 0.081732477 seconds. Throughput is 1566.085 records/second. Loss is 0.28370947. Sequential31006cbd's hyper parameters: Current learning rate is 0.006080505898090721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52608/60000][Iteration 3225][Wall Clock 323.835919916s] Trained 128 records in 0.097901364 seconds. Throughput is 1307.4384 records/second. Loss is 0.26096144. Sequential31006cbd's hyper parameters: Current learning rate is 0.006079766536964981. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52736/60000][Iteration 3226][Wall Clock 323.935802875s] Trained 128 records in 0.099882959 seconds. Throughput is 1281.4999 records/second. Loss is 0.23311894. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060790273556231. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52864/60000][Iteration 3227][Wall Clock 324.024161418s] Trained 128 records in 0.088358543 seconds. Throughput is 1448.6432 records/second. Loss is 0.16797072. Sequential31006cbd's hyper parameters: Current learning rate is 0.006078288353999514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 52992/60000][Iteration 3228][Wall Clock 324.115490394s] Trained 128 records in 0.091328976 seconds. Throughput is 1401.5267 records/second. Loss is 0.25474107. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060775495320286865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 53120/60000][Iteration 3229][Wall Clock 324.209581463s] Trained 128 records in 0.094091069 seconds. Throughput is 1360.3842 records/second. Loss is 0.20523748. Sequential31006cbd's hyper parameters: Current learning rate is 0.006076810889645115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 53248/60000][Iteration 3230][Wall Clock 324.30223681s] Trained 128 records in 0.092655347 seconds. Throughput is 1381.4637 records/second. Loss is 0.23295382. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060760724267833275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:01 INFO  DistriOptimizer$:408 - [Epoch 7 53376/60000][Iteration 3231][Wall Clock 324.383323777s] Trained 128 records in 0.081086967 seconds. Throughput is 1578.5521 records/second. Loss is 0.23044029. Sequential31006cbd's hyper parameters: Current learning rate is 0.006075334143377886. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 53504/60000][Iteration 3232][Wall Clock 324.457599923s] Trained 128 records in 0.074276146 seconds. Throughput is 1723.2988 records/second. Loss is 0.31582144. Sequential31006cbd's hyper parameters: Current learning rate is 0.006074596039363383. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 53632/60000][Iteration 3233][Wall Clock 324.537492382s] Trained 128 records in 0.079892459 seconds. Throughput is 1602.1538 records/second. Loss is 0.2185132. Sequential31006cbd's hyper parameters: Current learning rate is 0.006073858114674441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 53760/60000][Iteration 3234][Wall Clock 324.619613844s] Trained 128 records in 0.082121462 seconds. Throughput is 1558.6669 records/second. Loss is 0.17918572. Sequential31006cbd's hyper parameters: Current learning rate is 0.006073120369245719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 53888/60000][Iteration 3235][Wall Clock 324.6971026s] Trained 128 records in 0.077488756 seconds. Throughput is 1651.8525 records/second. Loss is 0.26851696. Sequential31006cbd's hyper parameters: Current learning rate is 0.006072382803011902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54016/60000][Iteration 3236][Wall Clock 324.776341049s] Trained 128 records in 0.079238449 seconds. Throughput is 1615.3773 records/second. Loss is 0.19029729. Sequential31006cbd's hyper parameters: Current learning rate is 0.006071645415907711. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54144/60000][Iteration 3237][Wall Clock 324.866745799s] Trained 128 records in 0.09040475 seconds. Throughput is 1415.8549 records/second. Loss is 0.15458621. Sequential31006cbd's hyper parameters: Current learning rate is 0.006070908207867897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54272/60000][Iteration 3238][Wall Clock 324.983588761s] Trained 128 records in 0.116842962 seconds. Throughput is 1095.4874 records/second. Loss is 0.22870436. Sequential31006cbd's hyper parameters: Current learning rate is 0.006070171178827242. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54400/60000][Iteration 3239][Wall Clock 325.090030249s] Trained 128 records in 0.106441488 seconds. Throughput is 1202.5386 records/second. Loss is 0.2314522. Sequential31006cbd's hyper parameters: Current learning rate is 0.006069434328720562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54528/60000][Iteration 3240][Wall Clock 325.181989158s] Trained 128 records in 0.091958909 seconds. Throughput is 1391.926 records/second. Loss is 0.28259826. Sequential31006cbd's hyper parameters: Current learning rate is 0.006068697657482704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54656/60000][Iteration 3241][Wall Clock 325.302974782s] Trained 128 records in 0.120985624 seconds. Throughput is 1057.9769 records/second. Loss is 0.2581091. Sequential31006cbd's hyper parameters: Current learning rate is 0.006067961165048544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:02 INFO  DistriOptimizer$:408 - [Epoch 7 54784/60000][Iteration 3242][Wall Clock 325.391512906s] Trained 128 records in 0.088538124 seconds. Throughput is 1445.7048 records/second. Loss is 0.18421584. Sequential31006cbd's hyper parameters: Current learning rate is 0.006067224851352991. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 54912/60000][Iteration 3243][Wall Clock 325.471166025s] Trained 128 records in 0.079653119 seconds. Throughput is 1606.9678 records/second. Loss is 0.23142031. Sequential31006cbd's hyper parameters: Current learning rate is 0.006066488716330988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55040/60000][Iteration 3244][Wall Clock 325.556293782s] Trained 128 records in 0.085127757 seconds. Throughput is 1503.6224 records/second. Loss is 0.15440801. Sequential31006cbd's hyper parameters: Current learning rate is 0.006065752759917505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55168/60000][Iteration 3245][Wall Clock 325.630784354s] Trained 128 records in 0.074490572 seconds. Throughput is 1718.3384 records/second. Loss is 0.2709935. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060650169820475495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55296/60000][Iteration 3246][Wall Clock 325.715554533s] Trained 128 records in 0.084770179 seconds. Throughput is 1509.965 records/second. Loss is 0.18697688. Sequential31006cbd's hyper parameters: Current learning rate is 0.006064281382656155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55424/60000][Iteration 3247][Wall Clock 325.796997805s] Trained 128 records in 0.081443272 seconds. Throughput is 1571.6461 records/second. Loss is 0.17803699. Sequential31006cbd's hyper parameters: Current learning rate is 0.00606354596167839. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55552/60000][Iteration 3248][Wall Clock 325.891880641s] Trained 128 records in 0.094882836 seconds. Throughput is 1349.0321 records/second. Loss is 0.22899507. Sequential31006cbd's hyper parameters: Current learning rate is 0.006062810719049351. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55680/60000][Iteration 3249][Wall Clock 325.991259255s] Trained 128 records in 0.099378614 seconds. Throughput is 1288.0034 records/second. Loss is 0.23487605. Sequential31006cbd's hyper parameters: Current learning rate is 0.006062075654704171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55808/60000][Iteration 3250][Wall Clock 326.096855392s] Trained 128 records in 0.105596137 seconds. Throughput is 1212.1655 records/second. Loss is 0.32185534. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060613407685780095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 55936/60000][Iteration 3251][Wall Clock 326.216922128s] Trained 128 records in 0.120066736 seconds. Throughput is 1066.0737 records/second. Loss is 0.21822046. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060606060606060615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:03 INFO  DistriOptimizer$:408 - [Epoch 7 56064/60000][Iteration 3252][Wall Clock 326.355624216s] Trained 128 records in 0.138702088 seconds. Throughput is 922.8411 records/second. Loss is 0.22384018. Sequential31006cbd's hyper parameters: Current learning rate is 0.006059871530723549. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56192/60000][Iteration 3253][Wall Clock 326.486480147s] Trained 128 records in 0.130855931 seconds. Throughput is 978.175 records/second. Loss is 0.24016756. Sequential31006cbd's hyper parameters: Current learning rate is 0.00605913717886573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56320/60000][Iteration 3254][Wall Clock 326.631034197s] Trained 128 records in 0.14455405 seconds. Throughput is 885.48193 records/second. Loss is 0.31595346. Sequential31006cbd's hyper parameters: Current learning rate is 0.00605840300496789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56448/60000][Iteration 3255][Wall Clock 326.740630052s] Trained 128 records in 0.109595855 seconds. Throughput is 1167.9274 records/second. Loss is 0.2839218. Sequential31006cbd's hyper parameters: Current learning rate is 0.00605766900896535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56576/60000][Iteration 3256][Wall Clock 326.850473232s] Trained 128 records in 0.10984318 seconds. Throughput is 1165.2976 records/second. Loss is 0.294435. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060569351907934586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56704/60000][Iteration 3257][Wall Clock 326.970177828s] Trained 128 records in 0.119704596 seconds. Throughput is 1069.299 records/second. Loss is 0.27523038. Sequential31006cbd's hyper parameters: Current learning rate is 0.006056201550387597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56832/60000][Iteration 3258][Wall Clock 327.090111005s] Trained 128 records in 0.119933177 seconds. Throughput is 1067.261 records/second. Loss is 0.23964825. Sequential31006cbd's hyper parameters: Current learning rate is 0.006055468087683178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 56960/60000][Iteration 3259][Wall Clock 327.192752034s] Trained 128 records in 0.102641029 seconds. Throughput is 1247.0646 records/second. Loss is 0.26825726. Sequential31006cbd's hyper parameters: Current learning rate is 0.006054734802615645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 57088/60000][Iteration 3260][Wall Clock 327.28241846s] Trained 128 records in 0.089666426 seconds. Throughput is 1427.5131 records/second. Loss is 0.21089795. Sequential31006cbd's hyper parameters: Current learning rate is 0.006054001695120474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:04 INFO  DistriOptimizer$:408 - [Epoch 7 57216/60000][Iteration 3261][Wall Clock 327.374502174s] Trained 128 records in 0.092083714 seconds. Throughput is 1390.0394 records/second. Loss is 0.20512268. Sequential31006cbd's hyper parameters: Current learning rate is 0.006053268765133172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 57344/60000][Iteration 3262][Wall Clock 327.463335945s] Trained 128 records in 0.088833771 seconds. Throughput is 1440.8934 records/second. Loss is 0.38753664. Sequential31006cbd's hyper parameters: Current learning rate is 0.006052536012589275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 57472/60000][Iteration 3263][Wall Clock 327.55730007s] Trained 128 records in 0.093964125 seconds. Throughput is 1362.222 records/second. Loss is 0.22678415. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060518034374243525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 57600/60000][Iteration 3264][Wall Clock 327.647221688s] Trained 128 records in 0.089921618 seconds. Throughput is 1423.4619 records/second. Loss is 0.16869085. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060510710395740045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 57728/60000][Iteration 3265][Wall Clock 327.736023566s] Trained 128 records in 0.088801878 seconds. Throughput is 1441.411 records/second. Loss is 0.30342636. Sequential31006cbd's hyper parameters: Current learning rate is 0.006050338818973862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 57856/60000][Iteration 3266][Wall Clock 327.834247705s] Trained 128 records in 0.098224139 seconds. Throughput is 1303.142 records/second. Loss is 0.20455673. Sequential31006cbd's hyper parameters: Current learning rate is 0.006049606775559589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 57984/60000][Iteration 3267][Wall Clock 327.925089948s] Trained 128 records in 0.090842243 seconds. Throughput is 1409.0361 records/second. Loss is 0.30026272. Sequential31006cbd's hyper parameters: Current learning rate is 0.006048874909266876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 58112/60000][Iteration 3268][Wall Clock 328.015097325s] Trained 128 records in 0.090007377 seconds. Throughput is 1422.1056 records/second. Loss is 0.22454312. Sequential31006cbd's hyper parameters: Current learning rate is 0.00604814322003145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 58240/60000][Iteration 3269][Wall Clock 328.09572246s] Trained 128 records in 0.080625135 seconds. Throughput is 1587.5944 records/second. Loss is 0.29946506. Sequential31006cbd's hyper parameters: Current learning rate is 0.006047411707789067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 58368/60000][Iteration 3270][Wall Clock 328.170226754s] Trained 128 records in 0.074504294 seconds. Throughput is 1718.0219 records/second. Loss is 0.1752125. Sequential31006cbd's hyper parameters: Current learning rate is 0.006046680372475511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 58496/60000][Iteration 3271][Wall Clock 328.248097146s] Trained 128 records in 0.077870392 seconds. Throughput is 1643.757 records/second. Loss is 0.25246894. Sequential31006cbd's hyper parameters: Current learning rate is 0.006045949214026603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:05 INFO  DistriOptimizer$:408 - [Epoch 7 58624/60000][Iteration 3272][Wall Clock 328.325379287s] Trained 128 records in 0.077282141 seconds. Throughput is 1656.2689 records/second. Loss is 0.28119802. Sequential31006cbd's hyper parameters: Current learning rate is 0.006045218232378189. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 58752/60000][Iteration 3273][Wall Clock 328.405574713s] Trained 128 records in 0.080195426 seconds. Throughput is 1596.101 records/second. Loss is 0.16565728. Sequential31006cbd's hyper parameters: Current learning rate is 0.006044487427466151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 58880/60000][Iteration 3274][Wall Clock 328.490619405s] Trained 128 records in 0.085044692 seconds. Throughput is 1505.0911 records/second. Loss is 0.31402117. Sequential31006cbd's hyper parameters: Current learning rate is 0.006043756799226399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59008/60000][Iteration 3275][Wall Clock 328.576595827s] Trained 128 records in 0.085976422 seconds. Throughput is 1488.7803 records/second. Loss is 0.2740586. Sequential31006cbd's hyper parameters: Current learning rate is 0.006043026347594876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59136/60000][Iteration 3276][Wall Clock 328.6551396s] Trained 128 records in 0.078543773 seconds. Throughput is 1629.6644 records/second. Loss is 0.30627576. Sequential31006cbd's hyper parameters: Current learning rate is 0.006042296072507553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59264/60000][Iteration 3277][Wall Clock 328.732444916s] Trained 128 records in 0.077305316 seconds. Throughput is 1655.7722 records/second. Loss is 0.3206265. Sequential31006cbd's hyper parameters: Current learning rate is 0.006041565973900435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59392/60000][Iteration 3278][Wall Clock 328.852348003s] Trained 128 records in 0.119903087 seconds. Throughput is 1067.5288 records/second. Loss is 0.22409433. Sequential31006cbd's hyper parameters: Current learning rate is 0.006040836051709557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59520/60000][Iteration 3279][Wall Clock 328.958056196s] Trained 128 records in 0.105708193 seconds. Throughput is 1210.8806 records/second. Loss is 0.24812496. Sequential31006cbd's hyper parameters: Current learning rate is 0.006040106305870983. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59648/60000][Iteration 3280][Wall Clock 329.04573347s] Trained 128 records in 0.087677274 seconds. Throughput is 1459.8993 records/second. Loss is 0.25017306. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060393767363208116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59776/60000][Iteration 3281][Wall Clock 329.134871279s] Trained 128 records in 0.089137809 seconds. Throughput is 1435.9788 records/second. Loss is 0.338379. Sequential31006cbd's hyper parameters: Current learning rate is 0.006038647342995169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 59904/60000][Iteration 3282][Wall Clock 329.210997615s] Trained 128 records in 0.076126336 seconds. Throughput is 1681.4154 records/second. Loss is 0.22934021. Sequential31006cbd's hyper parameters: Current learning rate is 0.006037918125830213. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:408 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 329.291968923s] Trained 128 records in 0.080971308 seconds. Throughput is 1580.8069 records/second. Loss is 0.39986587. Sequential31006cbd's hyper parameters: Current learning rate is 0.006037189084762135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:06 INFO  DistriOptimizer$:452 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 329.291968923s] Epoch finished. Wall clock time is 330433.296368 ms
2019-10-24 00:03:06 INFO  DistriOptimizer$:111 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 329.291968923s] Validate model...
2019-10-24 00:03:07 INFO  DistriOptimizer$:178 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 329.291968923s] validate model throughput is 11981.0 records/second
2019-10-24 00:03:07 INFO  DistriOptimizer$:181 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 329.291968923s] Top1Accuracy is Accuracy(correct: 9362, count: 10000, accuracy: 0.9362)
2019-10-24 00:03:07 INFO  DistriOptimizer$:221 - [Wall Clock 330.433296368s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:03:07 INFO  DistriOptimizer$:226 - [Wall Clock 330.433296368s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:03:07 INFO  DistriOptimizer$:408 - [Epoch 8 128/60000][Iteration 3284][Wall Clock 330.514925878s] Trained 128 records in 0.08162951 seconds. Throughput is 1568.0604 records/second. Loss is 0.16802625. Sequential31006cbd's hyper parameters: Current learning rate is 0.006036460219727152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:07 INFO  DistriOptimizer$:408 - [Epoch 8 256/60000][Iteration 3285][Wall Clock 330.599975177s] Trained 128 records in 0.085049299 seconds. Throughput is 1505.0094 records/second. Loss is 0.19195001. Sequential31006cbd's hyper parameters: Current learning rate is 0.006035731530661516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 384/60000][Iteration 3286][Wall Clock 330.689991931s] Trained 128 records in 0.090016754 seconds. Throughput is 1421.9575 records/second. Loss is 0.23040712. Sequential31006cbd's hyper parameters: Current learning rate is 0.006035003017501509. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 512/60000][Iteration 3287][Wall Clock 330.821554648s] Trained 128 records in 0.131562717 seconds. Throughput is 972.92004 records/second. Loss is 0.201808. Sequential31006cbd's hyper parameters: Current learning rate is 0.006034274680183442. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 640/60000][Iteration 3288][Wall Clock 330.922435851s] Trained 128 records in 0.100881203 seconds. Throughput is 1268.8191 records/second. Loss is 0.3178977. Sequential31006cbd's hyper parameters: Current learning rate is 0.006033546518643659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 768/60000][Iteration 3289][Wall Clock 331.01291442s] Trained 128 records in 0.090478569 seconds. Throughput is 1414.6997 records/second. Loss is 0.2355603. Sequential31006cbd's hyper parameters: Current learning rate is 0.006032818532818533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 896/60000][Iteration 3290][Wall Clock 331.09257228s] Trained 128 records in 0.07965786 seconds. Throughput is 1606.8722 records/second. Loss is 0.28344506. Sequential31006cbd's hyper parameters: Current learning rate is 0.006032090722644469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 1024/60000][Iteration 3291][Wall Clock 331.176965543s] Trained 128 records in 0.084393263 seconds. Throughput is 1516.7087 records/second. Loss is 0.2352025. Sequential31006cbd's hyper parameters: Current learning rate is 0.006031363088057902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 1152/60000][Iteration 3292][Wall Clock 331.254306481s] Trained 128 records in 0.077340938 seconds. Throughput is 1655.0096 records/second. Loss is 0.33721343. Sequential31006cbd's hyper parameters: Current learning rate is 0.006030635628995296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 1280/60000][Iteration 3293][Wall Clock 331.332850418s] Trained 128 records in 0.078543937 seconds. Throughput is 1629.6611 records/second. Loss is 0.24278252. Sequential31006cbd's hyper parameters: Current learning rate is 0.00602990834539315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 1408/60000][Iteration 3294][Wall Clock 331.412476187s] Trained 128 records in 0.079625769 seconds. Throughput is 1607.5198 records/second. Loss is 0.31949955. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060291812371879895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 1536/60000][Iteration 3295][Wall Clock 331.489500642s] Trained 128 records in 0.077024455 seconds. Throughput is 1661.8099 records/second. Loss is 0.25604406. Sequential31006cbd's hyper parameters: Current learning rate is 0.006028454304316373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:08 INFO  DistriOptimizer$:408 - [Epoch 8 1664/60000][Iteration 3296][Wall Clock 331.568718374s] Trained 128 records in 0.079217732 seconds. Throughput is 1615.7998 records/second. Loss is 0.27951774. Sequential31006cbd's hyper parameters: Current learning rate is 0.006027727546714889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 1792/60000][Iteration 3297][Wall Clock 331.651737004s] Trained 128 records in 0.08301863 seconds. Throughput is 1541.8226 records/second. Loss is 0.24300407. Sequential31006cbd's hyper parameters: Current learning rate is 0.006027000964320154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 1920/60000][Iteration 3298][Wall Clock 331.730471825s] Trained 128 records in 0.078734821 seconds. Throughput is 1625.7102 records/second. Loss is 0.32570326. Sequential31006cbd's hyper parameters: Current learning rate is 0.006026274557068821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2048/60000][Iteration 3299][Wall Clock 331.820295938s] Trained 128 records in 0.089824113 seconds. Throughput is 1425.0072 records/second. Loss is 0.15889284. Sequential31006cbd's hyper parameters: Current learning rate is 0.006025548324897565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2176/60000][Iteration 3300][Wall Clock 331.92088041s] Trained 128 records in 0.100584472 seconds. Throughput is 1272.5623 records/second. Loss is 0.25793833. Sequential31006cbd's hyper parameters: Current learning rate is 0.006024822267743101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2304/60000][Iteration 3301][Wall Clock 332.004863083s] Trained 128 records in 0.083982673 seconds. Throughput is 1524.1239 records/second. Loss is 0.17727748. Sequential31006cbd's hyper parameters: Current learning rate is 0.006024096385542168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2432/60000][Iteration 3302][Wall Clock 332.097791368s] Trained 128 records in 0.092928285 seconds. Throughput is 1377.4062 records/second. Loss is 0.25381947. Sequential31006cbd's hyper parameters: Current learning rate is 0.006023370678231538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2560/60000][Iteration 3303][Wall Clock 332.203779406s] Trained 128 records in 0.105988038 seconds. Throughput is 1207.6835 records/second. Loss is 0.26095438. Sequential31006cbd's hyper parameters: Current learning rate is 0.006022645145748013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2688/60000][Iteration 3304][Wall Clock 332.295405587s] Trained 128 records in 0.091626181 seconds. Throughput is 1396.9806 records/second. Loss is 0.23836197. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060219197880284235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2816/60000][Iteration 3305][Wall Clock 332.390229733s] Trained 128 records in 0.094824146 seconds. Throughput is 1349.8672 records/second. Loss is 0.39781144. Sequential31006cbd's hyper parameters: Current learning rate is 0.006021194605009634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 2944/60000][Iteration 3306][Wall Clock 332.468884239s] Trained 128 records in 0.078654506 seconds. Throughput is 1627.3702 records/second. Loss is 0.21587072. Sequential31006cbd's hyper parameters: Current learning rate is 0.006020469596628537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:09 INFO  DistriOptimizer$:408 - [Epoch 8 3072/60000][Iteration 3307][Wall Clock 332.547539974s] Trained 128 records in 0.078655735 seconds. Throughput is 1627.3448 records/second. Loss is 0.22334674. Sequential31006cbd's hyper parameters: Current learning rate is 0.006019744762822056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3200/60000][Iteration 3308][Wall Clock 332.629891386s] Trained 128 records in 0.082351412 seconds. Throughput is 1554.3146 records/second. Loss is 0.23870352. Sequential31006cbd's hyper parameters: Current learning rate is 0.006019020103527146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3328/60000][Iteration 3309][Wall Clock 332.723067193s] Trained 128 records in 0.093175807 seconds. Throughput is 1373.7472 records/second. Loss is 0.24670982. Sequential31006cbd's hyper parameters: Current learning rate is 0.00601829561868079. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3456/60000][Iteration 3310][Wall Clock 332.805298311s] Trained 128 records in 0.082231118 seconds. Throughput is 1556.5884 records/second. Loss is 0.2616052. Sequential31006cbd's hyper parameters: Current learning rate is 0.006017571308220003. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3584/60000][Iteration 3311][Wall Clock 332.897203945s] Trained 128 records in 0.091905634 seconds. Throughput is 1392.7329 records/second. Loss is 0.27010435. Sequential31006cbd's hyper parameters: Current learning rate is 0.006016847172081829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3712/60000][Iteration 3312][Wall Clock 332.99487119s] Trained 128 records in 0.097667245 seconds. Throughput is 1310.5724 records/second. Loss is 0.2236601. Sequential31006cbd's hyper parameters: Current learning rate is 0.006016123210203345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3840/60000][Iteration 3313][Wall Clock 333.089064886s] Trained 128 records in 0.094193696 seconds. Throughput is 1358.902 records/second. Loss is 0.24144584. Sequential31006cbd's hyper parameters: Current learning rate is 0.006015399422521656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 3968/60000][Iteration 3314][Wall Clock 333.18108652s] Trained 128 records in 0.092021634 seconds. Throughput is 1390.9772 records/second. Loss is 0.3709331. Sequential31006cbd's hyper parameters: Current learning rate is 0.006014675808973896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 4096/60000][Iteration 3315][Wall Clock 333.274487415s] Trained 128 records in 0.093400895 seconds. Throughput is 1370.4365 records/second. Loss is 0.2589622. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060139523694972335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 4224/60000][Iteration 3316][Wall Clock 333.360393985s] Trained 128 records in 0.08590657 seconds. Throughput is 1489.9907 records/second. Loss is 0.24677685. Sequential31006cbd's hyper parameters: Current learning rate is 0.006013229104028864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 4352/60000][Iteration 3317][Wall Clock 333.440341432s] Trained 128 records in 0.079947447 seconds. Throughput is 1601.0518 records/second. Loss is 0.2869311. Sequential31006cbd's hyper parameters: Current learning rate is 0.006012506012506013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:10 INFO  DistriOptimizer$:408 - [Epoch 8 4480/60000][Iteration 3318][Wall Clock 333.518688482s] Trained 128 records in 0.07834705 seconds. Throughput is 1633.7565 records/second. Loss is 0.274187. Sequential31006cbd's hyper parameters: Current learning rate is 0.006011783094865938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 4608/60000][Iteration 3319][Wall Clock 333.612046409s] Trained 128 records in 0.093357927 seconds. Throughput is 1371.0673 records/second. Loss is 0.27344933. Sequential31006cbd's hyper parameters: Current learning rate is 0.006011060351045924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 4736/60000][Iteration 3320][Wall Clock 333.699346848s] Trained 128 records in 0.087300439 seconds. Throughput is 1466.201 records/second. Loss is 0.2942207. Sequential31006cbd's hyper parameters: Current learning rate is 0.006010337780983291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 4864/60000][Iteration 3321][Wall Clock 333.782809133s] Trained 128 records in 0.083462285 seconds. Throughput is 1533.6268 records/second. Loss is 0.16228169. Sequential31006cbd's hyper parameters: Current learning rate is 0.006009615384615384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 4992/60000][Iteration 3322][Wall Clock 333.864290473s] Trained 128 records in 0.08148134 seconds. Throughput is 1570.9119 records/second. Loss is 0.27038628. Sequential31006cbd's hyper parameters: Current learning rate is 0.006008893161879581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5120/60000][Iteration 3323][Wall Clock 333.945265649s] Trained 128 records in 0.080975176 seconds. Throughput is 1580.7313 records/second. Loss is 0.19909936. Sequential31006cbd's hyper parameters: Current learning rate is 0.00600817111271329. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5248/60000][Iteration 3324][Wall Clock 334.023474549s] Trained 128 records in 0.0782089 seconds. Throughput is 1636.6423 records/second. Loss is 0.21466765. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060074492370539466. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5376/60000][Iteration 3325][Wall Clock 334.102425386s] Trained 128 records in 0.078950837 seconds. Throughput is 1621.2621 records/second. Loss is 0.18467803. Sequential31006cbd's hyper parameters: Current learning rate is 0.006006727534839019. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5504/60000][Iteration 3326][Wall Clock 334.174883742s] Trained 128 records in 0.072458356 seconds. Throughput is 1766.532 records/second. Loss is 0.34705314. Sequential31006cbd's hyper parameters: Current learning rate is 0.006006006006006006. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5632/60000][Iteration 3327][Wall Clock 334.253092423s] Trained 128 records in 0.078208681 seconds. Throughput is 1636.6471 records/second. Loss is 0.3336701. Sequential31006cbd's hyper parameters: Current learning rate is 0.006005284650492434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5760/60000][Iteration 3328][Wall Clock 334.337193317s] Trained 128 records in 0.084100894 seconds. Throughput is 1521.9814 records/second. Loss is 0.17070208. Sequential31006cbd's hyper parameters: Current learning rate is 0.006004563468235859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 5888/60000][Iteration 3329][Wall Clock 334.438686316s] Trained 128 records in 0.101492999 seconds. Throughput is 1261.1707 records/second. Loss is 0.22514684. Sequential31006cbd's hyper parameters: Current learning rate is 0.006003842459173871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:11 INFO  DistriOptimizer$:408 - [Epoch 8 6016/60000][Iteration 3330][Wall Clock 334.536094584s] Trained 128 records in 0.097408268 seconds. Throughput is 1314.0569 records/second. Loss is 0.42078334. Sequential31006cbd's hyper parameters: Current learning rate is 0.006003121623244088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6144/60000][Iteration 3331][Wall Clock 334.64344802s] Trained 128 records in 0.107353436 seconds. Throughput is 1192.3232 records/second. Loss is 0.16951588. Sequential31006cbd's hyper parameters: Current learning rate is 0.006002400960384154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6272/60000][Iteration 3332][Wall Clock 334.740371985s] Trained 128 records in 0.096923965 seconds. Throughput is 1320.6228 records/second. Loss is 0.278696. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060016804705317495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6400/60000][Iteration 3333][Wall Clock 334.828628329s] Trained 128 records in 0.088256344 seconds. Throughput is 1450.3207 records/second. Loss is 0.20660385. Sequential31006cbd's hyper parameters: Current learning rate is 0.0060009601536245806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6528/60000][Iteration 3334][Wall Clock 334.90742561s] Trained 128 records in 0.078797281 seconds. Throughput is 1624.4215 records/second. Loss is 0.2750981. Sequential31006cbd's hyper parameters: Current learning rate is 0.006000240009600383. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6656/60000][Iteration 3335][Wall Clock 334.986159066s] Trained 128 records in 0.078733456 seconds. Throughput is 1625.7383 records/second. Loss is 0.26654285. Sequential31006cbd's hyper parameters: Current learning rate is 0.005999520038396928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6784/60000][Iteration 3336][Wall Clock 335.065844313s] Trained 128 records in 0.079685247 seconds. Throughput is 1606.32 records/second. Loss is 0.3064616. Sequential31006cbd's hyper parameters: Current learning rate is 0.00599880023995201. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 6912/60000][Iteration 3337][Wall Clock 335.152355717s] Trained 128 records in 0.086511404 seconds. Throughput is 1479.5737 records/second. Loss is 0.22502673. Sequential31006cbd's hyper parameters: Current learning rate is 0.005998080614203455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 7040/60000][Iteration 3338][Wall Clock 335.230702735s] Trained 128 records in 0.078347018 seconds. Throughput is 1633.7571 records/second. Loss is 0.26639438. Sequential31006cbd's hyper parameters: Current learning rate is 0.005997361161089121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 7168/60000][Iteration 3339][Wall Clock 335.317994492s] Trained 128 records in 0.087291757 seconds. Throughput is 1466.3469 records/second. Loss is 0.2849247. Sequential31006cbd's hyper parameters: Current learning rate is 0.005996641880546893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 7296/60000][Iteration 3340][Wall Clock 335.408142458s] Trained 128 records in 0.090147966 seconds. Throughput is 1419.8878 records/second. Loss is 0.2414397. Sequential31006cbd's hyper parameters: Current learning rate is 0.005995922772514689. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 7424/60000][Iteration 3341][Wall Clock 335.499497108s] Trained 128 records in 0.09135465 seconds. Throughput is 1401.1328 records/second. Loss is 0.35676655. Sequential31006cbd's hyper parameters: Current learning rate is 0.005995203836930455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:12 INFO  DistriOptimizer$:408 - [Epoch 8 7552/60000][Iteration 3342][Wall Clock 335.584951408s] Trained 128 records in 0.0854543 seconds. Throughput is 1497.8766 records/second. Loss is 0.26339275. Sequential31006cbd's hyper parameters: Current learning rate is 0.005994485073732166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 7680/60000][Iteration 3343][Wall Clock 335.677000609s] Trained 128 records in 0.092049201 seconds. Throughput is 1390.5607 records/second. Loss is 0.24166425. Sequential31006cbd's hyper parameters: Current learning rate is 0.005993766482857828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 7808/60000][Iteration 3344][Wall Clock 335.767665534s] Trained 128 records in 0.090664925 seconds. Throughput is 1411.7919 records/second. Loss is 0.2540194. Sequential31006cbd's hyper parameters: Current learning rate is 0.005993048064245475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 7936/60000][Iteration 3345][Wall Clock 335.852576788s] Trained 128 records in 0.084911254 seconds. Throughput is 1507.4562 records/second. Loss is 0.20947719. Sequential31006cbd's hyper parameters: Current learning rate is 0.005992329817833174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8064/60000][Iteration 3346][Wall Clock 335.931042387s] Trained 128 records in 0.078465599 seconds. Throughput is 1631.2882 records/second. Loss is 0.17959434. Sequential31006cbd's hyper parameters: Current learning rate is 0.005991611743559017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8192/60000][Iteration 3347][Wall Clock 336.00930973s] Trained 128 records in 0.078267343 seconds. Throughput is 1635.4203 records/second. Loss is 0.2652405. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059908938413611315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8320/60000][Iteration 3348][Wall Clock 336.096768571s] Trained 128 records in 0.087458841 seconds. Throughput is 1463.5455 records/second. Loss is 0.23544842. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059901761111776685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8448/60000][Iteration 3349][Wall Clock 336.176076036s] Trained 128 records in 0.079307465 seconds. Throughput is 1613.9716 records/second. Loss is 0.20181504. Sequential31006cbd's hyper parameters: Current learning rate is 0.005989458552946814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8576/60000][Iteration 3350][Wall Clock 336.254039219s] Trained 128 records in 0.077963183 seconds. Throughput is 1641.8007 records/second. Loss is 0.23998383. Sequential31006cbd's hyper parameters: Current learning rate is 0.005988741166606779. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8704/60000][Iteration 3351][Wall Clock 336.355315951s] Trained 128 records in 0.101276732 seconds. Throughput is 1263.8639 records/second. Loss is 0.27426645. Sequential31006cbd's hyper parameters: Current learning rate is 0.005988023952095809. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8832/60000][Iteration 3352][Wall Clock 336.436738461s] Trained 128 records in 0.08142251 seconds. Throughput is 1572.0469 records/second. Loss is 0.24512717. Sequential31006cbd's hyper parameters: Current learning rate is 0.005987306909352174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:13 INFO  DistriOptimizer$:408 - [Epoch 8 8960/60000][Iteration 3353][Wall Clock 336.516673688s] Trained 128 records in 0.079935227 seconds. Throughput is 1601.2964 records/second. Loss is 0.28720295. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059865900383141765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9088/60000][Iteration 3354][Wall Clock 336.589333486s] Trained 128 records in 0.072659798 seconds. Throughput is 1761.6344 records/second. Loss is 0.1973965. Sequential31006cbd's hyper parameters: Current learning rate is 0.005985873338920148. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9216/60000][Iteration 3355][Wall Clock 336.676528783s] Trained 128 records in 0.087195297 seconds. Throughput is 1467.969 records/second. Loss is 0.23105833. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059851568111084505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9344/60000][Iteration 3356][Wall Clock 336.76165998s] Trained 128 records in 0.085131197 seconds. Throughput is 1503.5616 records/second. Loss is 0.34048715. Sequential31006cbd's hyper parameters: Current learning rate is 0.005984440454817474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9472/60000][Iteration 3357][Wall Clock 336.847210345s] Trained 128 records in 0.085550365 seconds. Throughput is 1496.1946 records/second. Loss is 0.32832682. Sequential31006cbd's hyper parameters: Current learning rate is 0.005983724269985639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9600/60000][Iteration 3358][Wall Clock 336.92858912s] Trained 128 records in 0.081378775 seconds. Throughput is 1572.8917 records/second. Loss is 0.38088673. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059830082565513944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9728/60000][Iteration 3359][Wall Clock 337.005562253s] Trained 128 records in 0.076973133 seconds. Throughput is 1662.9178 records/second. Loss is 0.34600252. Sequential31006cbd's hyper parameters: Current learning rate is 0.005982292414453218. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9856/60000][Iteration 3360][Wall Clock 337.087596955s] Trained 128 records in 0.082034702 seconds. Throughput is 1560.3153 records/second. Loss is 0.40468255. Sequential31006cbd's hyper parameters: Current learning rate is 0.00598157674362962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 9984/60000][Iteration 3361][Wall Clock 337.161775518s] Trained 128 records in 0.074178563 seconds. Throughput is 1725.5659 records/second. Loss is 0.21977347. Sequential31006cbd's hyper parameters: Current learning rate is 0.005980861244019139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 10112/60000][Iteration 3362][Wall Clock 337.240347755s] Trained 128 records in 0.078572237 seconds. Throughput is 1629.0742 records/second. Loss is 0.22550373. Sequential31006cbd's hyper parameters: Current learning rate is 0.005980145915560339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 10240/60000][Iteration 3363][Wall Clock 337.340206544s] Trained 128 records in 0.099858789 seconds. Throughput is 1281.81 records/second. Loss is 0.341082. Sequential31006cbd's hyper parameters: Current learning rate is 0.00597943075819182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 10368/60000][Iteration 3364][Wall Clock 337.474585044s] Trained 128 records in 0.1343785 seconds. Throughput is 952.5334 records/second. Loss is 0.29293376. Sequential31006cbd's hyper parameters: Current learning rate is 0.005978715771852206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:14 INFO  DistriOptimizer$:408 - [Epoch 8 10496/60000][Iteration 3365][Wall Clock 337.571411703s] Trained 128 records in 0.096826659 seconds. Throughput is 1321.95 records/second. Loss is 0.32662722. Sequential31006cbd's hyper parameters: Current learning rate is 0.005978000956480153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 10624/60000][Iteration 3366][Wall Clock 337.663507749s] Trained 128 records in 0.092096046 seconds. Throughput is 1389.8534 records/second. Loss is 0.21939619. Sequential31006cbd's hyper parameters: Current learning rate is 0.005977286312014346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 10752/60000][Iteration 3367][Wall Clock 337.753037994s] Trained 128 records in 0.089530245 seconds. Throughput is 1429.6844 records/second. Loss is 0.2589124. Sequential31006cbd's hyper parameters: Current learning rate is 0.005976571838393498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 10880/60000][Iteration 3368][Wall Clock 337.83464307s] Trained 128 records in 0.081605076 seconds. Throughput is 1568.5299 records/second. Loss is 0.13478053. Sequential31006cbd's hyper parameters: Current learning rate is 0.005975857535556352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11008/60000][Iteration 3369][Wall Clock 337.909669567s] Trained 128 records in 0.075026497 seconds. Throughput is 1706.064 records/second. Loss is 0.20058528. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059751434034416824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11136/60000][Iteration 3370][Wall Clock 337.982341547s] Trained 128 records in 0.07267198 seconds. Throughput is 1761.3391 records/second. Loss is 0.30668095. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059744294419882904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11264/60000][Iteration 3371][Wall Clock 338.06382977s] Trained 128 records in 0.081488223 seconds. Throughput is 1570.7792 records/second. Loss is 0.175531. Sequential31006cbd's hyper parameters: Current learning rate is 0.005973715651135006. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11392/60000][Iteration 3372][Wall Clock 338.154985731s] Trained 128 records in 0.091155961 seconds. Throughput is 1404.1868 records/second. Loss is 0.25488657. Sequential31006cbd's hyper parameters: Current learning rate is 0.005973002030820691. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11520/60000][Iteration 3373][Wall Clock 338.233457806s] Trained 128 records in 0.078472075 seconds. Throughput is 1631.1534 records/second. Loss is 0.22545716. Sequential31006cbd's hyper parameters: Current learning rate is 0.005972288580984234. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11648/60000][Iteration 3374][Wall Clock 338.309573548s] Trained 128 records in 0.076115742 seconds. Throughput is 1681.6495 records/second. Loss is 0.24614349. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059715753015645535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11776/60000][Iteration 3375][Wall Clock 338.389050768s] Trained 128 records in 0.07947722 seconds. Throughput is 1610.5244 records/second. Loss is 0.21508099. Sequential31006cbd's hyper parameters: Current learning rate is 0.005970862192500597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 11904/60000][Iteration 3376][Wall Clock 338.472937207s] Trained 128 records in 0.083886439 seconds. Throughput is 1525.8724 records/second. Loss is 0.20802715. Sequential31006cbd's hyper parameters: Current learning rate is 0.005970149253731343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:15 INFO  DistriOptimizer$:408 - [Epoch 8 12032/60000][Iteration 3377][Wall Clock 338.553346148s] Trained 128 records in 0.080408941 seconds. Throughput is 1591.8628 records/second. Loss is 0.23488346. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059694364851957974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12160/60000][Iteration 3378][Wall Clock 338.63199181s] Trained 128 records in 0.078645662 seconds. Throughput is 1627.5532 records/second. Loss is 0.23001479. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059687238868329955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12288/60000][Iteration 3379][Wall Clock 338.715000499s] Trained 128 records in 0.083008689 seconds. Throughput is 1542.0072 records/second. Loss is 0.17105575. Sequential31006cbd's hyper parameters: Current learning rate is 0.005968011458582001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12416/60000][Iteration 3380][Wall Clock 338.794837725s] Trained 128 records in 0.079837226 seconds. Throughput is 1603.2621 records/second. Loss is 0.17950824. Sequential31006cbd's hyper parameters: Current learning rate is 0.005967299200381907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12544/60000][Iteration 3381][Wall Clock 338.886809608s] Trained 128 records in 0.091971883 seconds. Throughput is 1391.7297 records/second. Loss is 0.2565163. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059665871121718375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12672/60000][Iteration 3382][Wall Clock 338.971876219s] Trained 128 records in 0.085066611 seconds. Throughput is 1504.7032 records/second. Loss is 0.32483327. Sequential31006cbd's hyper parameters: Current learning rate is 0.005965875193890943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12800/60000][Iteration 3383][Wall Clock 339.04704819s] Trained 128 records in 0.075171971 seconds. Throughput is 1702.7623 records/second. Loss is 0.27498174. Sequential31006cbd's hyper parameters: Current learning rate is 0.005965163445478406. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 12928/60000][Iteration 3384][Wall Clock 339.121599778s] Trained 128 records in 0.074551588 seconds. Throughput is 1716.9319 records/second. Loss is 0.22719195. Sequential31006cbd's hyper parameters: Current learning rate is 0.005964451866873434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 13056/60000][Iteration 3385][Wall Clock 339.221874989s] Trained 128 records in 0.100275211 seconds. Throughput is 1276.4869 records/second. Loss is 0.26208177. Sequential31006cbd's hyper parameters: Current learning rate is 0.005963740458015267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 13184/60000][Iteration 3386][Wall Clock 339.320257956s] Trained 128 records in 0.098382967 seconds. Throughput is 1301.0382 records/second. Loss is 0.24231276. Sequential31006cbd's hyper parameters: Current learning rate is 0.005963029218843173. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 13312/60000][Iteration 3387][Wall Clock 339.423821743s] Trained 128 records in 0.103563787 seconds. Throughput is 1235.9532 records/second. Loss is 0.22520673. Sequential31006cbd's hyper parameters: Current learning rate is 0.005962318149296446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:16 INFO  DistriOptimizer$:408 - [Epoch 8 13440/60000][Iteration 3388][Wall Clock 339.507904435s] Trained 128 records in 0.084082692 seconds. Throughput is 1522.3109 records/second. Loss is 0.26584512. Sequential31006cbd's hyper parameters: Current learning rate is 0.005961607249314415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 13568/60000][Iteration 3389][Wall Clock 339.601558351s] Trained 128 records in 0.093653916 seconds. Throughput is 1366.7341 records/second. Loss is 0.23718627. Sequential31006cbd's hyper parameters: Current learning rate is 0.005960896518836433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 13696/60000][Iteration 3390][Wall Clock 339.683883885s] Trained 128 records in 0.082325534 seconds. Throughput is 1554.8032 records/second. Loss is 0.2841041. Sequential31006cbd's hyper parameters: Current learning rate is 0.005960185957801884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 13824/60000][Iteration 3391][Wall Clock 339.761632866s] Trained 128 records in 0.077748981 seconds. Throughput is 1646.3237 records/second. Loss is 0.30707192. Sequential31006cbd's hyper parameters: Current learning rate is 0.005959475566150179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 13952/60000][Iteration 3392][Wall Clock 339.852359141s] Trained 128 records in 0.090726275 seconds. Throughput is 1410.8372 records/second. Loss is 0.17850843. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059587653438207605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14080/60000][Iteration 3393][Wall Clock 339.93900132s] Trained 128 records in 0.086642179 seconds. Throughput is 1477.3406 records/second. Loss is 0.19885623. Sequential31006cbd's hyper parameters: Current learning rate is 0.005958055290753099. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14208/60000][Iteration 3394][Wall Clock 340.018910278s] Trained 128 records in 0.079908958 seconds. Throughput is 1601.8229 records/second. Loss is 0.36677372. Sequential31006cbd's hyper parameters: Current learning rate is 0.005957345406886692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14336/60000][Iteration 3395][Wall Clock 340.097344639s] Trained 128 records in 0.078434361 seconds. Throughput is 1631.9377 records/second. Loss is 0.3671675. Sequential31006cbd's hyper parameters: Current learning rate is 0.005956635692161067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14464/60000][Iteration 3396][Wall Clock 340.178007577s] Trained 128 records in 0.080662938 seconds. Throughput is 1586.8502 records/second. Loss is 0.23364845. Sequential31006cbd's hyper parameters: Current learning rate is 0.005955926146515783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14592/60000][Iteration 3397][Wall Clock 340.256661637s] Trained 128 records in 0.07865406 seconds. Throughput is 1627.3795 records/second. Loss is 0.17352274. Sequential31006cbd's hyper parameters: Current learning rate is 0.005955216769890424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14720/60000][Iteration 3398][Wall Clock 340.351711059s] Trained 128 records in 0.095049422 seconds. Throughput is 1346.6678 records/second. Loss is 0.3045731. Sequential31006cbd's hyper parameters: Current learning rate is 0.005954507562224604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14848/60000][Iteration 3399][Wall Clock 340.430721842s] Trained 128 records in 0.079010783 seconds. Throughput is 1620.032 records/second. Loss is 0.2312319. Sequential31006cbd's hyper parameters: Current learning rate is 0.005953798523457966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:17 INFO  DistriOptimizer$:408 - [Epoch 8 14976/60000][Iteration 3400][Wall Clock 340.51461899s] Trained 128 records in 0.083897148 seconds. Throughput is 1525.6776 records/second. Loss is 0.2753899. Sequential31006cbd's hyper parameters: Current learning rate is 0.005953089653530181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15104/60000][Iteration 3401][Wall Clock 340.594279595s] Trained 128 records in 0.079660605 seconds. Throughput is 1606.8169 records/second. Loss is 0.20604765. Sequential31006cbd's hyper parameters: Current learning rate is 0.005952380952380952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15232/60000][Iteration 3402][Wall Clock 340.673882446s] Trained 128 records in 0.079602851 seconds. Throughput is 1607.9825 records/second. Loss is 0.23165837. Sequential31006cbd's hyper parameters: Current learning rate is 0.005951672419950005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15360/60000][Iteration 3403][Wall Clock 340.75192897s] Trained 128 records in 0.078046524 seconds. Throughput is 1640.0475 records/second. Loss is 0.19224003. Sequential31006cbd's hyper parameters: Current learning rate is 0.005950964056177101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15488/60000][Iteration 3404][Wall Clock 340.834245722s] Trained 128 records in 0.082316752 seconds. Throughput is 1554.9691 records/second. Loss is 0.23306662. Sequential31006cbd's hyper parameters: Current learning rate is 0.005950255861002023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15616/60000][Iteration 3405][Wall Clock 340.91352367s] Trained 128 records in 0.079277948 seconds. Throughput is 1614.5726 records/second. Loss is 0.15044019. Sequential31006cbd's hyper parameters: Current learning rate is 0.005949547834364588. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15744/60000][Iteration 3406][Wall Clock 341.013805679s] Trained 128 records in 0.100282009 seconds. Throughput is 1276.4005 records/second. Loss is 0.24219221. Sequential31006cbd's hyper parameters: Current learning rate is 0.00594883997620464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 15872/60000][Iteration 3407][Wall Clock 341.09870179s] Trained 128 records in 0.084896111 seconds. Throughput is 1507.7251 records/second. Loss is 0.17808636. Sequential31006cbd's hyper parameters: Current learning rate is 0.005948132286462051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 16000/60000][Iteration 3408][Wall Clock 341.194355001s] Trained 128 records in 0.095653211 seconds. Throughput is 1338.1672 records/second. Loss is 0.30038565. Sequential31006cbd's hyper parameters: Current learning rate is 0.005947424765076722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 16128/60000][Iteration 3409][Wall Clock 341.277025636s] Trained 128 records in 0.082670635 seconds. Throughput is 1548.3127 records/second. Loss is 0.23513329. Sequential31006cbd's hyper parameters: Current learning rate is 0.005946717411988583. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 16256/60000][Iteration 3410][Wall Clock 341.352370519s] Trained 128 records in 0.075344883 seconds. Throughput is 1698.8546 records/second. Loss is 0.24454647. Sequential31006cbd's hyper parameters: Current learning rate is 0.005946010227137591. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 16384/60000][Iteration 3411][Wall Clock 341.457346433s] Trained 128 records in 0.104975914 seconds. Throughput is 1219.3273 records/second. Loss is 0.18765461. Sequential31006cbd's hyper parameters: Current learning rate is 0.005945303210463734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:18 INFO  DistriOptimizer$:408 - [Epoch 8 16512/60000][Iteration 3412][Wall Clock 341.551942553s] Trained 128 records in 0.09459612 seconds. Throughput is 1353.1211 records/second. Loss is 0.25837147. Sequential31006cbd's hyper parameters: Current learning rate is 0.005944596361907027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 16640/60000][Iteration 3413][Wall Clock 341.631901534s] Trained 128 records in 0.079958981 seconds. Throughput is 1600.8208 records/second. Loss is 0.26741806. Sequential31006cbd's hyper parameters: Current learning rate is 0.005943889681407514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 16768/60000][Iteration 3414][Wall Clock 341.748907455s] Trained 128 records in 0.117005921 seconds. Throughput is 1093.9617 records/second. Loss is 0.23612058. Sequential31006cbd's hyper parameters: Current learning rate is 0.005943183168905266. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 16896/60000][Iteration 3415][Wall Clock 341.834175188s] Trained 128 records in 0.085267733 seconds. Throughput is 1501.154 records/second. Loss is 0.2731488. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059424768243403845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17024/60000][Iteration 3416][Wall Clock 341.933427404s] Trained 128 records in 0.099252216 seconds. Throughput is 1289.6438 records/second. Loss is 0.22704966. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059417706476530005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17152/60000][Iteration 3417][Wall Clock 342.015711856s] Trained 128 records in 0.082284452 seconds. Throughput is 1555.5795 records/second. Loss is 0.2603258. Sequential31006cbd's hyper parameters: Current learning rate is 0.00594106463878327. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17280/60000][Iteration 3418][Wall Clock 342.102510314s] Trained 128 records in 0.086798458 seconds. Throughput is 1474.6805 records/second. Loss is 0.27086332. Sequential31006cbd's hyper parameters: Current learning rate is 0.005940358797671379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17408/60000][Iteration 3419][Wall Clock 342.203964496s] Trained 128 records in 0.101454182 seconds. Throughput is 1261.6532 records/second. Loss is 0.3049711. Sequential31006cbd's hyper parameters: Current learning rate is 0.005939653124257544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17536/60000][Iteration 3420][Wall Clock 342.296224414s] Trained 128 records in 0.092259918 seconds. Throughput is 1387.3846 records/second. Loss is 0.27825308. Sequential31006cbd's hyper parameters: Current learning rate is 0.005938947618482004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17664/60000][Iteration 3421][Wall Clock 342.391669965s] Trained 128 records in 0.095445551 seconds. Throughput is 1341.0787 records/second. Loss is 0.23777176. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059382422802850355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17792/60000][Iteration 3422][Wall Clock 342.473035161s] Trained 128 records in 0.081365196 seconds. Throughput is 1573.1542 records/second. Loss is 0.23419371. Sequential31006cbd's hyper parameters: Current learning rate is 0.005937537109606934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:19 INFO  DistriOptimizer$:408 - [Epoch 8 17920/60000][Iteration 3423][Wall Clock 342.556606639s] Trained 128 records in 0.083571478 seconds. Throughput is 1531.623 records/second. Loss is 0.23981449. Sequential31006cbd's hyper parameters: Current learning rate is 0.005936832106388031. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18048/60000][Iteration 3424][Wall Clock 342.635856453s] Trained 128 records in 0.079249814 seconds. Throughput is 1615.1458 records/second. Loss is 0.18182942. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059361272705686806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18176/60000][Iteration 3425][Wall Clock 342.716950251s] Trained 128 records in 0.081093798 seconds. Throughput is 1578.4192 records/second. Loss is 0.18787241. Sequential31006cbd's hyper parameters: Current learning rate is 0.005935422602089268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18304/60000][Iteration 3426][Wall Clock 342.796427301s] Trained 128 records in 0.07947705 seconds. Throughput is 1610.5278 records/second. Loss is 0.21733195. Sequential31006cbd's hyper parameters: Current learning rate is 0.005934718100890208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18432/60000][Iteration 3427][Wall Clock 342.877841505s] Trained 128 records in 0.081414204 seconds. Throughput is 1572.2073 records/second. Loss is 0.29013965. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059340137669119395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18560/60000][Iteration 3428][Wall Clock 342.961955881s] Trained 128 records in 0.084114376 seconds. Throughput is 1521.7375 records/second. Loss is 0.14860559. Sequential31006cbd's hyper parameters: Current learning rate is 0.005933309600094933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18688/60000][Iteration 3429][Wall Clock 343.061485825s] Trained 128 records in 0.099529944 seconds. Throughput is 1286.0452 records/second. Loss is 0.23791943. Sequential31006cbd's hyper parameters: Current learning rate is 0.005932605600379687. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18816/60000][Iteration 3430][Wall Clock 343.143980313s] Trained 128 records in 0.082494488 seconds. Throughput is 1551.6188 records/second. Loss is 0.2378818. Sequential31006cbd's hyper parameters: Current learning rate is 0.005931901767706727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 18944/60000][Iteration 3431][Wall Clock 343.236245365s] Trained 128 records in 0.092265052 seconds. Throughput is 1387.3075 records/second. Loss is 0.2769805. Sequential31006cbd's hyper parameters: Current learning rate is 0.005931198102016607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 19072/60000][Iteration 3432][Wall Clock 343.337524805s] Trained 128 records in 0.10127944 seconds. Throughput is 1263.8301 records/second. Loss is 0.13507685. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059304946032499115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 19200/60000][Iteration 3433][Wall Clock 343.413333372s] Trained 128 records in 0.075808567 seconds. Throughput is 1688.4635 records/second. Loss is 0.22180101. Sequential31006cbd's hyper parameters: Current learning rate is 0.005929791271347249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:20 INFO  DistriOptimizer$:408 - [Epoch 8 19328/60000][Iteration 3434][Wall Clock 343.49266547s] Trained 128 records in 0.079332098 seconds. Throughput is 1613.4705 records/second. Loss is 0.29270336. Sequential31006cbd's hyper parameters: Current learning rate is 0.005929088106249259. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 19456/60000][Iteration 3435][Wall Clock 343.577059686s] Trained 128 records in 0.084394216 seconds. Throughput is 1516.6917 records/second. Loss is 0.2530237. Sequential31006cbd's hyper parameters: Current learning rate is 0.005928385107896609. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 19584/60000][Iteration 3436][Wall Clock 343.666241305s] Trained 128 records in 0.089181619 seconds. Throughput is 1435.2733 records/second. Loss is 0.24330658. Sequential31006cbd's hyper parameters: Current learning rate is 0.005927682276229994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 19712/60000][Iteration 3437][Wall Clock 343.752587081s] Trained 128 records in 0.086345776 seconds. Throughput is 1482.4119 records/second. Loss is 0.18444747. Sequential31006cbd's hyper parameters: Current learning rate is 0.005926979611190137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 19840/60000][Iteration 3438][Wall Clock 343.838683059s] Trained 128 records in 0.086095978 seconds. Throughput is 1486.7129 records/second. Loss is 0.12747912. Sequential31006cbd's hyper parameters: Current learning rate is 0.005926277112717791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 19968/60000][Iteration 3439][Wall Clock 343.921167553s] Trained 128 records in 0.082484494 seconds. Throughput is 1551.8069 records/second. Loss is 0.25402898. Sequential31006cbd's hyper parameters: Current learning rate is 0.005925574780753734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20096/60000][Iteration 3440][Wall Clock 344.021210571s] Trained 128 records in 0.100043018 seconds. Throughput is 1279.4496 records/second. Loss is 0.18450503. Sequential31006cbd's hyper parameters: Current learning rate is 0.005924872615238772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20224/60000][Iteration 3441][Wall Clock 344.109626123s] Trained 128 records in 0.088415552 seconds. Throughput is 1447.7091 records/second. Loss is 0.18656756. Sequential31006cbd's hyper parameters: Current learning rate is 0.005924170616113744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20352/60000][Iteration 3442][Wall Clock 344.189476593s] Trained 128 records in 0.07985047 seconds. Throughput is 1602.9961 records/second. Loss is 0.21935992. Sequential31006cbd's hyper parameters: Current learning rate is 0.005923468783319511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20480/60000][Iteration 3443][Wall Clock 344.271713263s] Trained 128 records in 0.08223667 seconds. Throughput is 1556.4833 records/second. Loss is 0.17297538. Sequential31006cbd's hyper parameters: Current learning rate is 0.005922767116796967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20608/60000][Iteration 3444][Wall Clock 344.353384559s] Trained 128 records in 0.081671296 seconds. Throughput is 1567.258 records/second. Loss is 0.15278393. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059220656164870305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20736/60000][Iteration 3445][Wall Clock 344.428714158s] Trained 128 records in 0.075329599 seconds. Throughput is 1699.1992 records/second. Loss is 0.22680527. Sequential31006cbd's hyper parameters: Current learning rate is 0.005921364282330649. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:21 INFO  DistriOptimizer$:408 - [Epoch 8 20864/60000][Iteration 3446][Wall Clock 344.521202572s] Trained 128 records in 0.092488414 seconds. Throughput is 1383.9572 records/second. Loss is 0.25176224. Sequential31006cbd's hyper parameters: Current learning rate is 0.005920663114268798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 20992/60000][Iteration 3447][Wall Clock 344.606383952s] Trained 128 records in 0.08518138 seconds. Throughput is 1502.6759 records/second. Loss is 0.22146389. Sequential31006cbd's hyper parameters: Current learning rate is 0.005919962112242482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21120/60000][Iteration 3448][Wall Clock 344.689518076s] Trained 128 records in 0.083134124 seconds. Throughput is 1539.6807 records/second. Loss is 0.26173663. Sequential31006cbd's hyper parameters: Current learning rate is 0.005919261276192731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21248/60000][Iteration 3449][Wall Clock 344.769599064s] Trained 128 records in 0.080080988 seconds. Throughput is 1598.382 records/second. Loss is 0.35991648. Sequential31006cbd's hyper parameters: Current learning rate is 0.005918560606060606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21376/60000][Iteration 3450][Wall Clock 344.858433629s] Trained 128 records in 0.088834565 seconds. Throughput is 1440.8806 records/second. Loss is 0.2758686. Sequential31006cbd's hyper parameters: Current learning rate is 0.005917860101787194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21504/60000][Iteration 3451][Wall Clock 344.952052138s] Trained 128 records in 0.093618509 seconds. Throughput is 1367.251 records/second. Loss is 0.22444274. Sequential31006cbd's hyper parameters: Current learning rate is 0.00591715976331361. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21632/60000][Iteration 3452][Wall Clock 345.035600065s] Trained 128 records in 0.083547927 seconds. Throughput is 1532.0548 records/second. Loss is 0.25740984. Sequential31006cbd's hyper parameters: Current learning rate is 0.005916459590580997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21760/60000][Iteration 3453][Wall Clock 345.115737512s] Trained 128 records in 0.080137447 seconds. Throughput is 1597.2557 records/second. Loss is 0.27844024. Sequential31006cbd's hyper parameters: Current learning rate is 0.005915759583530526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 21888/60000][Iteration 3454][Wall Clock 345.194019159s] Trained 128 records in 0.078281647 seconds. Throughput is 1635.1215 records/second. Loss is 0.17808819. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059150597421033955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 22016/60000][Iteration 3455][Wall Clock 345.271490681s] Trained 128 records in 0.077471522 seconds. Throughput is 1652.22 records/second. Loss is 0.19911842. Sequential31006cbd's hyper parameters: Current learning rate is 0.005914360066240833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 22144/60000][Iteration 3456][Wall Clock 345.353400204s] Trained 128 records in 0.081909523 seconds. Throughput is 1562.6998 records/second. Loss is 0.22268572. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059136605558840925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 22272/60000][Iteration 3457][Wall Clock 345.433266868s] Trained 128 records in 0.079866664 seconds. Throughput is 1602.6711 records/second. Loss is 0.15032028. Sequential31006cbd's hyper parameters: Current learning rate is 0.005912961210974456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:22 INFO  DistriOptimizer$:408 - [Epoch 8 22400/60000][Iteration 3458][Wall Clock 345.519284117s] Trained 128 records in 0.086017249 seconds. Throughput is 1488.0736 records/second. Loss is 0.22219323. Sequential31006cbd's hyper parameters: Current learning rate is 0.005912262031453234. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 22528/60000][Iteration 3459][Wall Clock 345.614979361s] Trained 128 records in 0.095695244 seconds. Throughput is 1337.5796 records/second. Loss is 0.24515346. Sequential31006cbd's hyper parameters: Current learning rate is 0.005911563017261764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 22656/60000][Iteration 3460][Wall Clock 345.704489929s] Trained 128 records in 0.089510568 seconds. Throughput is 1429.9988 records/second. Loss is 0.23996581. Sequential31006cbd's hyper parameters: Current learning rate is 0.005910864168341411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 22784/60000][Iteration 3461][Wall Clock 345.788505407s] Trained 128 records in 0.084015478 seconds. Throughput is 1523.5287 records/second. Loss is 0.18494254. Sequential31006cbd's hyper parameters: Current learning rate is 0.00591016548463357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 22912/60000][Iteration 3462][Wall Clock 345.8789252s] Trained 128 records in 0.090419793 seconds. Throughput is 1415.6193 records/second. Loss is 0.2094155. Sequential31006cbd's hyper parameters: Current learning rate is 0.005909466966079659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 23040/60000][Iteration 3463][Wall Clock 345.970936233s] Trained 128 records in 0.092011033 seconds. Throughput is 1391.1375 records/second. Loss is 0.20367266. Sequential31006cbd's hyper parameters: Current learning rate is 0.005908768612621129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 23168/60000][Iteration 3464][Wall Clock 346.056292746s] Trained 128 records in 0.085356513 seconds. Throughput is 1499.5927 records/second. Loss is 0.2385945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059080704241994565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 23296/60000][Iteration 3465][Wall Clock 346.163667917s] Trained 128 records in 0.107375171 seconds. Throughput is 1192.0819 records/second. Loss is 0.30869478. Sequential31006cbd's hyper parameters: Current learning rate is 0.005907372400756144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 23424/60000][Iteration 3466][Wall Clock 346.277811609s] Trained 128 records in 0.114143692 seconds. Throughput is 1121.3936 records/second. Loss is 0.19271767. Sequential31006cbd's hyper parameters: Current learning rate is 0.005906674542232723. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 23552/60000][Iteration 3467][Wall Clock 346.390672725s] Trained 128 records in 0.112861116 seconds. Throughput is 1134.1372 records/second. Loss is 0.1653596. Sequential31006cbd's hyper parameters: Current learning rate is 0.005905976848570754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:23 INFO  DistriOptimizer$:408 - [Epoch 8 23680/60000][Iteration 3468][Wall Clock 346.477332771s] Trained 128 records in 0.086660046 seconds. Throughput is 1477.036 records/second. Loss is 0.20696934. Sequential31006cbd's hyper parameters: Current learning rate is 0.005905279319711822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 23808/60000][Iteration 3469][Wall Clock 346.555620003s] Trained 128 records in 0.078287232 seconds. Throughput is 1635.0049 records/second. Loss is 0.28969753. Sequential31006cbd's hyper parameters: Current learning rate is 0.005904581955597544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 23936/60000][Iteration 3470][Wall Clock 346.637370837s] Trained 128 records in 0.081750834 seconds. Throughput is 1565.7333 records/second. Loss is 0.24767567. Sequential31006cbd's hyper parameters: Current learning rate is 0.00590388475616956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24064/60000][Iteration 3471][Wall Clock 346.716901999s] Trained 128 records in 0.079531162 seconds. Throughput is 1609.432 records/second. Loss is 0.1368368. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059031877213695395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24192/60000][Iteration 3472][Wall Clock 346.795602844s] Trained 128 records in 0.078700845 seconds. Throughput is 1626.412 records/second. Loss is 0.2980114. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059024908511391815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24320/60000][Iteration 3473][Wall Clock 346.878731888s] Trained 128 records in 0.083129044 seconds. Throughput is 1539.7748 records/second. Loss is 0.280882. Sequential31006cbd's hyper parameters: Current learning rate is 0.005901794145420208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24448/60000][Iteration 3474][Wall Clock 346.958629223s] Trained 128 records in 0.079897335 seconds. Throughput is 1602.0559 records/second. Loss is 0.23983607. Sequential31006cbd's hyper parameters: Current learning rate is 0.005901097604154373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24576/60000][Iteration 3475][Wall Clock 347.037918462s] Trained 128 records in 0.079289239 seconds. Throughput is 1614.3425 records/second. Loss is 0.18843041. Sequential31006cbd's hyper parameters: Current learning rate is 0.0059004012272834555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24704/60000][Iteration 3476][Wall Clock 347.122799203s] Trained 128 records in 0.084880741 seconds. Throughput is 1507.9982 records/second. Loss is 0.23801664. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058997050147492625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24832/60000][Iteration 3477][Wall Clock 347.203630659s] Trained 128 records in 0.080831456 seconds. Throughput is 1583.542 records/second. Loss is 0.26015761. Sequential31006cbd's hyper parameters: Current learning rate is 0.005899008966493629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 24960/60000][Iteration 3478][Wall Clock 347.277660614s] Trained 128 records in 0.074029955 seconds. Throughput is 1729.0299 records/second. Loss is 0.17208798. Sequential31006cbd's hyper parameters: Current learning rate is 0.005898313082458417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 25088/60000][Iteration 3479][Wall Clock 347.357651937s] Trained 128 records in 0.079991323 seconds. Throughput is 1600.1735 records/second. Loss is 0.18372484. Sequential31006cbd's hyper parameters: Current learning rate is 0.005897617362585515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:24 INFO  DistriOptimizer$:408 - [Epoch 8 25216/60000][Iteration 3480][Wall Clock 347.437701739s] Trained 128 records in 0.080049802 seconds. Throughput is 1599.0045 records/second. Loss is 0.19096391. Sequential31006cbd's hyper parameters: Current learning rate is 0.005896921806816841. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 25344/60000][Iteration 3481][Wall Clock 347.531311088s] Trained 128 records in 0.093609349 seconds. Throughput is 1367.3848 records/second. Loss is 0.18820724. Sequential31006cbd's hyper parameters: Current learning rate is 0.005896226415094339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 25472/60000][Iteration 3482][Wall Clock 347.643716461s] Trained 128 records in 0.112405373 seconds. Throughput is 1138.7356 records/second. Loss is 0.23208693. Sequential31006cbd's hyper parameters: Current learning rate is 0.005895531187359981. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 25600/60000][Iteration 3483][Wall Clock 347.737050648s] Trained 128 records in 0.093334187 seconds. Throughput is 1371.416 records/second. Loss is 0.27358186. Sequential31006cbd's hyper parameters: Current learning rate is 0.005894836123555765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 25728/60000][Iteration 3484][Wall Clock 347.82289165s] Trained 128 records in 0.085841002 seconds. Throughput is 1491.1289 records/second. Loss is 0.24311697. Sequential31006cbd's hyper parameters: Current learning rate is 0.005894141223623718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 25856/60000][Iteration 3485][Wall Clock 347.903212311s] Trained 128 records in 0.080320661 seconds. Throughput is 1593.6123 records/second. Loss is 0.23172092. Sequential31006cbd's hyper parameters: Current learning rate is 0.005893446487505893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 25984/60000][Iteration 3486][Wall Clock 347.980781283s] Trained 128 records in 0.077568972 seconds. Throughput is 1650.1444 records/second. Loss is 0.20004514. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058927519151443725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 26112/60000][Iteration 3487][Wall Clock 348.076541792s] Trained 128 records in 0.095760509 seconds. Throughput is 1336.668 records/second. Loss is 0.20445512. Sequential31006cbd's hyper parameters: Current learning rate is 0.005892057506481263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 26240/60000][Iteration 3488][Wall Clock 348.157923641s] Trained 128 records in 0.081381849 seconds. Throughput is 1572.8323 records/second. Loss is 0.1678598. Sequential31006cbd's hyper parameters: Current learning rate is 0.005891363261458701. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 26368/60000][Iteration 3489][Wall Clock 348.23226919s] Trained 128 records in 0.074345549 seconds. Throughput is 1721.6901 records/second. Loss is 0.20155482. Sequential31006cbd's hyper parameters: Current learning rate is 0.00589066918001885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 26496/60000][Iteration 3490][Wall Clock 348.309491149s] Trained 128 records in 0.077221959 seconds. Throughput is 1657.5596 records/second. Loss is 0.18736243. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058899752621039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 26624/60000][Iteration 3491][Wall Clock 348.406932089s] Trained 128 records in 0.09744094 seconds. Throughput is 1313.6162 records/second. Loss is 0.23698682. Sequential31006cbd's hyper parameters: Current learning rate is 0.005889281507656066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:25 INFO  DistriOptimizer$:408 - [Epoch 8 26752/60000][Iteration 3492][Wall Clock 348.501638749s] Trained 128 records in 0.09470666 seconds. Throughput is 1351.5416 records/second. Loss is 0.24767412. Sequential31006cbd's hyper parameters: Current learning rate is 0.005888587916617596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 26880/60000][Iteration 3493][Wall Clock 348.575523794s] Trained 128 records in 0.073885045 seconds. Throughput is 1732.4209 records/second. Loss is 0.27123582. Sequential31006cbd's hyper parameters: Current learning rate is 0.005887894488930759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27008/60000][Iteration 3494][Wall Clock 348.654070854s] Trained 128 records in 0.07854706 seconds. Throughput is 1629.5963 records/second. Loss is 0.20921588. Sequential31006cbd's hyper parameters: Current learning rate is 0.005887201224537855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27136/60000][Iteration 3495][Wall Clock 348.736483726s] Trained 128 records in 0.082412872 seconds. Throughput is 1553.1555 records/second. Loss is 0.16777922. Sequential31006cbd's hyper parameters: Current learning rate is 0.00588650812338121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27264/60000][Iteration 3496][Wall Clock 348.819228106s] Trained 128 records in 0.08274438 seconds. Throughput is 1546.9329 records/second. Loss is 0.17264003. Sequential31006cbd's hyper parameters: Current learning rate is 0.005885815185403178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27392/60000][Iteration 3497][Wall Clock 348.917151174s] Trained 128 records in 0.097923068 seconds. Throughput is 1307.1486 records/second. Loss is 0.20519829. Sequential31006cbd's hyper parameters: Current learning rate is 0.005885122410546139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27520/60000][Iteration 3498][Wall Clock 349.019379493s] Trained 128 records in 0.102228319 seconds. Throughput is 1252.0992 records/second. Loss is 0.23354797. Sequential31006cbd's hyper parameters: Current learning rate is 0.005884429798752501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27648/60000][Iteration 3499][Wall Clock 349.104489525s] Trained 128 records in 0.085110032 seconds. Throughput is 1503.9355 records/second. Loss is 0.19963254. Sequential31006cbd's hyper parameters: Current learning rate is 0.005883737349964698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27776/60000][Iteration 3500][Wall Clock 349.189615777s] Trained 128 records in 0.085126252 seconds. Throughput is 1503.6489 records/second. Loss is 0.19976635. Sequential31006cbd's hyper parameters: Current learning rate is 0.00588304506412519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 27904/60000][Iteration 3501][Wall Clock 349.269264592s] Trained 128 records in 0.079648815 seconds. Throughput is 1607.0547 records/second. Loss is 0.19329092. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058823529411764705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 28032/60000][Iteration 3502][Wall Clock 349.339938712s] Trained 128 records in 0.07067412 seconds. Throughput is 1811.1296 records/second. Loss is 0.18816528. Sequential31006cbd's hyper parameters: Current learning rate is 0.005881660981061051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 28160/60000][Iteration 3503][Wall Clock 349.417912732s] Trained 128 records in 0.07797402 seconds. Throughput is 1641.5724 records/second. Loss is 0.23328261. Sequential31006cbd's hyper parameters: Current learning rate is 0.005880969183721477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:26 INFO  DistriOptimizer$:408 - [Epoch 8 28288/60000][Iteration 3504][Wall Clock 349.496508733s] Trained 128 records in 0.078596001 seconds. Throughput is 1628.5815 records/second. Loss is 0.23069358. Sequential31006cbd's hyper parameters: Current learning rate is 0.005880277549100317. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 28416/60000][Iteration 3505][Wall Clock 349.578059173s] Trained 128 records in 0.08155044 seconds. Throughput is 1569.5807 records/second. Loss is 0.2084549. Sequential31006cbd's hyper parameters: Current learning rate is 0.005879586077140169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 28544/60000][Iteration 3506][Wall Clock 349.659497556s] Trained 128 records in 0.081438383 seconds. Throughput is 1571.7404 records/second. Loss is 0.21485095. Sequential31006cbd's hyper parameters: Current learning rate is 0.005878894767783657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 28672/60000][Iteration 3507][Wall Clock 349.73730698s] Trained 128 records in 0.077809424 seconds. Throughput is 1645.0449 records/second. Loss is 0.3041085. Sequential31006cbd's hyper parameters: Current learning rate is 0.005878203620973431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 28800/60000][Iteration 3508][Wall Clock 349.817572844s] Trained 128 records in 0.080265864 seconds. Throughput is 1594.7003 records/second. Loss is 0.1585268. Sequential31006cbd's hyper parameters: Current learning rate is 0.005877512636652169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 28928/60000][Iteration 3509][Wall Clock 349.905154721s] Trained 128 records in 0.087581877 seconds. Throughput is 1461.4895 records/second. Loss is 0.20509818. Sequential31006cbd's hyper parameters: Current learning rate is 0.005876821814762577. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29056/60000][Iteration 3510][Wall Clock 349.979522687s] Trained 128 records in 0.074367966 seconds. Throughput is 1721.1713 records/second. Loss is 0.24999475. Sequential31006cbd's hyper parameters: Current learning rate is 0.005876131155247385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29184/60000][Iteration 3511][Wall Clock 350.073767533s] Trained 128 records in 0.094244846 seconds. Throughput is 1358.1644 records/second. Loss is 0.20900422. Sequential31006cbd's hyper parameters: Current learning rate is 0.005875440658049354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29312/60000][Iteration 3512][Wall Clock 350.165368525s] Trained 128 records in 0.091600992 seconds. Throughput is 1397.3647 records/second. Loss is 0.24251218. Sequential31006cbd's hyper parameters: Current learning rate is 0.005874750323111268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29440/60000][Iteration 3513][Wall Clock 350.24450237s] Trained 128 records in 0.079133845 seconds. Throughput is 1617.5127 records/second. Loss is 0.2679158. Sequential31006cbd's hyper parameters: Current learning rate is 0.00587406015037594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29568/60000][Iteration 3514][Wall Clock 350.32251626s] Trained 128 records in 0.07801389 seconds. Throughput is 1640.7335 records/second. Loss is 0.28413042. Sequential31006cbd's hyper parameters: Current learning rate is 0.00587337013978621. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29696/60000][Iteration 3515][Wall Clock 350.404956078s] Trained 128 records in 0.082439818 seconds. Throughput is 1552.6478 records/second. Loss is 0.18310222. Sequential31006cbd's hyper parameters: Current learning rate is 0.005872680291284943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:27 INFO  DistriOptimizer$:408 - [Epoch 8 29824/60000][Iteration 3516][Wall Clock 350.485614922s] Trained 128 records in 0.080658844 seconds. Throughput is 1586.9307 records/second. Loss is 0.24489172. Sequential31006cbd's hyper parameters: Current learning rate is 0.005871990604815032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 29952/60000][Iteration 3517][Wall Clock 350.577378749s] Trained 128 records in 0.091763827 seconds. Throughput is 1394.8853 records/second. Loss is 0.22691119. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058713010803193985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30080/60000][Iteration 3518][Wall Clock 350.65243332s] Trained 128 records in 0.075054571 seconds. Throughput is 1705.4258 records/second. Loss is 0.15535574. Sequential31006cbd's hyper parameters: Current learning rate is 0.005870611717740989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30208/60000][Iteration 3519][Wall Clock 350.746025878s] Trained 128 records in 0.093592558 seconds. Throughput is 1367.6301 records/second. Loss is 0.26072922. Sequential31006cbd's hyper parameters: Current learning rate is 0.005869922517022776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30336/60000][Iteration 3520][Wall Clock 350.836064728s] Trained 128 records in 0.09003885 seconds. Throughput is 1421.6085 records/second. Loss is 0.20559333. Sequential31006cbd's hyper parameters: Current learning rate is 0.00586923347810776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30464/60000][Iteration 3521][Wall Clock 350.921006151s] Trained 128 records in 0.084941423 seconds. Throughput is 1506.9208 records/second. Loss is 0.28789952. Sequential31006cbd's hyper parameters: Current learning rate is 0.005868544600938967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30592/60000][Iteration 3522][Wall Clock 351.008592827s] Trained 128 records in 0.087586676 seconds. Throughput is 1461.4094 records/second. Loss is 0.2030605. Sequential31006cbd's hyper parameters: Current learning rate is 0.005867855885459453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30720/60000][Iteration 3523][Wall Clock 351.084746999s] Trained 128 records in 0.076154172 seconds. Throughput is 1680.8009 records/second. Loss is 0.24204351. Sequential31006cbd's hyper parameters: Current learning rate is 0.005867167331612297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30848/60000][Iteration 3524][Wall Clock 351.165324419s] Trained 128 records in 0.08057742 seconds. Throughput is 1588.5344 records/second. Loss is 0.27315697. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058664789393406075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 30976/60000][Iteration 3525][Wall Clock 351.248141141s] Trained 128 records in 0.082816722 seconds. Throughput is 1545.5817 records/second. Loss is 0.20236066. Sequential31006cbd's hyper parameters: Current learning rate is 0.005865790708587518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 31104/60000][Iteration 3526][Wall Clock 351.32636252s] Trained 128 records in 0.078221379 seconds. Throughput is 1636.3812 records/second. Loss is 0.23863067. Sequential31006cbd's hyper parameters: Current learning rate is 0.005865102639296188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 31232/60000][Iteration 3527][Wall Clock 351.397857622s] Trained 128 records in 0.071495102 seconds. Throughput is 1790.3325 records/second. Loss is 0.24946678. Sequential31006cbd's hyper parameters: Current learning rate is 0.005864414731409805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:28 INFO  DistriOptimizer$:408 - [Epoch 8 31360/60000][Iteration 3528][Wall Clock 351.478254441s] Trained 128 records in 0.080396819 seconds. Throughput is 1592.1029 records/second. Loss is 0.14427328. Sequential31006cbd's hyper parameters: Current learning rate is 0.005863726984871584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 31488/60000][Iteration 3529][Wall Clock 351.555037911s] Trained 128 records in 0.07678347 seconds. Throughput is 1667.0254 records/second. Loss is 0.22317162. Sequential31006cbd's hyper parameters: Current learning rate is 0.005863039399624766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 31616/60000][Iteration 3530][Wall Clock 351.629361158s] Trained 128 records in 0.074323247 seconds. Throughput is 1722.2068 records/second. Loss is 0.21459094. Sequential31006cbd's hyper parameters: Current learning rate is 0.005862351975612616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 31744/60000][Iteration 3531][Wall Clock 351.704523686s] Trained 128 records in 0.075162528 seconds. Throughput is 1702.9762 records/second. Loss is 0.18506306. Sequential31006cbd's hyper parameters: Current learning rate is 0.005861664712778429. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 31872/60000][Iteration 3532][Wall Clock 351.785495647s] Trained 128 records in 0.080971961 seconds. Throughput is 1580.7941 records/second. Loss is 0.16033183. Sequential31006cbd's hyper parameters: Current learning rate is 0.005860977611065526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32000/60000][Iteration 3533][Wall Clock 351.863135609s] Trained 128 records in 0.077639962 seconds. Throughput is 1648.6356 records/second. Loss is 0.1581862. Sequential31006cbd's hyper parameters: Current learning rate is 0.005860290670417253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32128/60000][Iteration 3534][Wall Clock 351.938559457s] Trained 128 records in 0.075423848 seconds. Throughput is 1697.0759 records/second. Loss is 0.26519528. Sequential31006cbd's hyper parameters: Current learning rate is 0.005859603890776984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32256/60000][Iteration 3535][Wall Clock 352.035974547s] Trained 128 records in 0.09741509 seconds. Throughput is 1313.9648 records/second. Loss is 0.25005445. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058589172720881185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32384/60000][Iteration 3536][Wall Clock 352.127470398s] Trained 128 records in 0.091495851 seconds. Throughput is 1398.9706 records/second. Loss is 0.28348628. Sequential31006cbd's hyper parameters: Current learning rate is 0.005858230814294083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32512/60000][Iteration 3537][Wall Clock 352.231981424s] Trained 128 records in 0.104511026 seconds. Throughput is 1224.7512 records/second. Loss is 0.22516146. Sequential31006cbd's hyper parameters: Current learning rate is 0.005857544517338332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32640/60000][Iteration 3538][Wall Clock 352.312440808s] Trained 128 records in 0.080459384 seconds. Throughput is 1590.8647 records/second. Loss is 0.2519086. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058568583811643435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32768/60000][Iteration 3539][Wall Clock 352.395087888s] Trained 128 records in 0.08264708 seconds. Throughput is 1548.7542 records/second. Loss is 0.33314124. Sequential31006cbd's hyper parameters: Current learning rate is 0.005856172405715624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:29 INFO  DistriOptimizer$:408 - [Epoch 8 32896/60000][Iteration 3540][Wall Clock 352.484045697s] Trained 128 records in 0.088957809 seconds. Throughput is 1438.8844 records/second. Loss is 0.21819401. Sequential31006cbd's hyper parameters: Current learning rate is 0.005855486590935707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33024/60000][Iteration 3541][Wall Clock 352.572439604s] Trained 128 records in 0.088393907 seconds. Throughput is 1448.0636 records/second. Loss is 0.2421188. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058548009367681494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33152/60000][Iteration 3542][Wall Clock 352.66653056s] Trained 128 records in 0.094090956 seconds. Throughput is 1360.3859 records/second. Loss is 0.23691657. Sequential31006cbd's hyper parameters: Current learning rate is 0.005854115443156538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33280/60000][Iteration 3543][Wall Clock 352.809573081s] Trained 128 records in 0.143042521 seconds. Throughput is 894.8388 records/second. Loss is 0.22447391. Sequential31006cbd's hyper parameters: Current learning rate is 0.005853430110044485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33408/60000][Iteration 3544][Wall Clock 352.898164399s] Trained 128 records in 0.088591318 seconds. Throughput is 1444.8369 records/second. Loss is 0.30410516. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058527449373756285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33536/60000][Iteration 3545][Wall Clock 352.990838943s] Trained 128 records in 0.092674544 seconds. Throughput is 1381.1775 records/second. Loss is 0.23804939. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058520599250936325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33664/60000][Iteration 3546][Wall Clock 353.065530912s] Trained 128 records in 0.074691969 seconds. Throughput is 1713.7051 records/second. Loss is 0.22854866. Sequential31006cbd's hyper parameters: Current learning rate is 0.005851375073142188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33792/60000][Iteration 3547][Wall Clock 353.144032297s] Trained 128 records in 0.078501385 seconds. Throughput is 1630.5444 records/second. Loss is 0.23223048. Sequential31006cbd's hyper parameters: Current learning rate is 0.005850690381465013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 33920/60000][Iteration 3548][Wall Clock 353.226223505s] Trained 128 records in 0.082191208 seconds. Throughput is 1557.3442 records/second. Loss is 0.19995546. Sequential31006cbd's hyper parameters: Current learning rate is 0.00585000585000585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 34048/60000][Iteration 3549][Wall Clock 353.305133319s] Trained 128 records in 0.078909814 seconds. Throughput is 1622.105 records/second. Loss is 0.24850366. Sequential31006cbd's hyper parameters: Current learning rate is 0.00584932147870847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 34176/60000][Iteration 3550][Wall Clock 353.380183431s] Trained 128 records in 0.075050112 seconds. Throughput is 1705.527 records/second. Loss is 0.2577756. Sequential31006cbd's hyper parameters: Current learning rate is 0.005848637267516669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:30 INFO  DistriOptimizer$:408 - [Epoch 8 34304/60000][Iteration 3551][Wall Clock 353.456826458s] Trained 128 records in 0.076643027 seconds. Throughput is 1670.0802 records/second. Loss is 0.19383045. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058479532163742695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 34432/60000][Iteration 3552][Wall Clock 353.539680057s] Trained 128 records in 0.082853599 seconds. Throughput is 1544.8937 records/second. Loss is 0.3264448. Sequential31006cbd's hyper parameters: Current learning rate is 0.00584726932522512. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 34560/60000][Iteration 3553][Wall Clock 353.622576086s] Trained 128 records in 0.082896029 seconds. Throughput is 1544.1029 records/second. Loss is 0.24913274. Sequential31006cbd's hyper parameters: Current learning rate is 0.005846585594013097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 34688/60000][Iteration 3554][Wall Clock 353.697975479s] Trained 128 records in 0.075399393 seconds. Throughput is 1697.6265 records/second. Loss is 0.2444533. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058459020226821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 34816/60000][Iteration 3555][Wall Clock 353.779705826s] Trained 128 records in 0.081730347 seconds. Throughput is 1566.1259 records/second. Loss is 0.18305075. Sequential31006cbd's hyper parameters: Current learning rate is 0.005845218611176059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 34944/60000][Iteration 3556][Wall Clock 353.879392224s] Trained 128 records in 0.099686398 seconds. Throughput is 1284.0267 records/second. Loss is 0.2272774. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058445353594389245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35072/60000][Iteration 3557][Wall Clock 353.965946112s] Trained 128 records in 0.086553888 seconds. Throughput is 1478.8475 records/second. Loss is 0.13644993. Sequential31006cbd's hyper parameters: Current learning rate is 0.00584385226741468. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35200/60000][Iteration 3558][Wall Clock 354.052511881s] Trained 128 records in 0.086565769 seconds. Throughput is 1478.6445 records/second. Loss is 0.21126279. Sequential31006cbd's hyper parameters: Current learning rate is 0.00584316933504733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35328/60000][Iteration 3559][Wall Clock 354.13056736s] Trained 128 records in 0.078055479 seconds. Throughput is 1639.8593 records/second. Loss is 0.38858277. Sequential31006cbd's hyper parameters: Current learning rate is 0.005842486562280907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35456/60000][Iteration 3560][Wall Clock 354.2219928s] Trained 128 records in 0.09142544 seconds. Throughput is 1400.048 records/second. Loss is 0.29515356. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058418039490594695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35584/60000][Iteration 3561][Wall Clock 354.317193215s] Trained 128 records in 0.095200415 seconds. Throughput is 1344.532 records/second. Loss is 0.19731688. Sequential31006cbd's hyper parameters: Current learning rate is 0.005841121495327103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35712/60000][Iteration 3562][Wall Clock 354.403577706s] Trained 128 records in 0.086384491 seconds. Throughput is 1481.7474 records/second. Loss is 0.21013665. Sequential31006cbd's hyper parameters: Current learning rate is 0.005840439201027917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:31 INFO  DistriOptimizer$:408 - [Epoch 8 35840/60000][Iteration 3563][Wall Clock 354.481870953s] Trained 128 records in 0.078293247 seconds. Throughput is 1634.8792 records/second. Loss is 0.25205454. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058397570661060496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 35968/60000][Iteration 3564][Wall Clock 354.583659698s] Trained 128 records in 0.101788745 seconds. Throughput is 1257.5065 records/second. Loss is 0.28966007. Sequential31006cbd's hyper parameters: Current learning rate is 0.005839075090505664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36096/60000][Iteration 3565][Wall Clock 354.660622406s] Trained 128 records in 0.076962708 seconds. Throughput is 1663.1431 records/second. Loss is 0.25405264. Sequential31006cbd's hyper parameters: Current learning rate is 0.005838393274170948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36224/60000][Iteration 3566][Wall Clock 354.744406164s] Trained 128 records in 0.083783758 seconds. Throughput is 1527.7423 records/second. Loss is 0.2102773. Sequential31006cbd's hyper parameters: Current learning rate is 0.005837711617046118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36352/60000][Iteration 3567][Wall Clock 354.829808459s] Trained 128 records in 0.085402295 seconds. Throughput is 1498.7888 records/second. Loss is 0.26471296. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058370301190754145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36480/60000][Iteration 3568][Wall Clock 354.945926734s] Trained 128 records in 0.116118275 seconds. Throughput is 1102.3243 records/second. Loss is 0.28078508. Sequential31006cbd's hyper parameters: Current learning rate is 0.005836348780203105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36608/60000][Iteration 3569][Wall Clock 355.034537767s] Trained 128 records in 0.088611033 seconds. Throughput is 1444.5154 records/second. Loss is 0.24682467. Sequential31006cbd's hyper parameters: Current learning rate is 0.005835667600373483. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36736/60000][Iteration 3570][Wall Clock 355.132824922s] Trained 128 records in 0.098287155 seconds. Throughput is 1302.3064 records/second. Loss is 0.1875864. Sequential31006cbd's hyper parameters: Current learning rate is 0.005834986579530867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36864/60000][Iteration 3571][Wall Clock 355.214157919s] Trained 128 records in 0.081332997 seconds. Throughput is 1573.777 records/second. Loss is 0.1687333. Sequential31006cbd's hyper parameters: Current learning rate is 0.005834305717619603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 36992/60000][Iteration 3572][Wall Clock 355.294738982s] Trained 128 records in 0.080581063 seconds. Throughput is 1588.4625 records/second. Loss is 0.18522623. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058336250145840625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 37120/60000][Iteration 3573][Wall Clock 355.377971088s] Trained 128 records in 0.083232106 seconds. Throughput is 1537.8682 records/second. Loss is 0.39284155. Sequential31006cbd's hyper parameters: Current learning rate is 0.005832944470368642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:32 INFO  DistriOptimizer$:408 - [Epoch 8 37248/60000][Iteration 3574][Wall Clock 355.461067153s] Trained 128 records in 0.083096065 seconds. Throughput is 1540.3859 records/second. Loss is 0.19138683. Sequential31006cbd's hyper parameters: Current learning rate is 0.005832264084917766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 37376/60000][Iteration 3575][Wall Clock 355.5430554s] Trained 128 records in 0.081988247 seconds. Throughput is 1561.1995 records/second. Loss is 0.20098305. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058315838581758815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 37504/60000][Iteration 3576][Wall Clock 355.627148887s] Trained 128 records in 0.084093487 seconds. Throughput is 1522.1155 records/second. Loss is 0.2916115. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058309037900874635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 37632/60000][Iteration 3577][Wall Clock 355.712382767s] Trained 128 records in 0.08523388 seconds. Throughput is 1501.7502 records/second. Loss is 0.25094533. Sequential31006cbd's hyper parameters: Current learning rate is 0.005830223880597015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 37760/60000][Iteration 3578][Wall Clock 355.816069796s] Trained 128 records in 0.103687029 seconds. Throughput is 1234.4843 records/second. Loss is 0.20554575. Sequential31006cbd's hyper parameters: Current learning rate is 0.005829544129649061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 37888/60000][Iteration 3579][Wall Clock 355.906868408s] Trained 128 records in 0.090798612 seconds. Throughput is 1409.7133 records/second. Loss is 0.23423606. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058288645371881555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 38016/60000][Iteration 3580][Wall Clock 355.987929627s] Trained 128 records in 0.081061219 seconds. Throughput is 1579.0535 records/second. Loss is 0.17948866. Sequential31006cbd's hyper parameters: Current learning rate is 0.005828185103158877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 38144/60000][Iteration 3581][Wall Clock 356.070049603s] Trained 128 records in 0.082119976 seconds. Throughput is 1558.695 records/second. Loss is 0.22437648. Sequential31006cbd's hyper parameters: Current learning rate is 0.005827505827505827. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 38272/60000][Iteration 3582][Wall Clock 356.150618643s] Trained 128 records in 0.08056904 seconds. Throughput is 1588.6997 records/second. Loss is 0.26993835. Sequential31006cbd's hyper parameters: Current learning rate is 0.005826826710173639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 38400/60000][Iteration 3583][Wall Clock 356.23338982s] Trained 128 records in 0.082771177 seconds. Throughput is 1546.4321 records/second. Loss is 0.16403994. Sequential31006cbd's hyper parameters: Current learning rate is 0.005826147751106968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 38528/60000][Iteration 3584][Wall Clock 356.320074052s] Trained 128 records in 0.086684232 seconds. Throughput is 1476.6238 records/second. Loss is 0.18777639. Sequential31006cbd's hyper parameters: Current learning rate is 0.005825468950250495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:33 INFO  DistriOptimizer$:408 - [Epoch 8 38656/60000][Iteration 3585][Wall Clock 356.413011575s] Trained 128 records in 0.092937523 seconds. Throughput is 1377.2694 records/second. Loss is 0.24805543. Sequential31006cbd's hyper parameters: Current learning rate is 0.005824790307548928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 38784/60000][Iteration 3586][Wall Clock 356.524962673s] Trained 128 records in 0.111951098 seconds. Throughput is 1143.3563 records/second. Loss is 0.23364621. Sequential31006cbd's hyper parameters: Current learning rate is 0.005824111822947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 38912/60000][Iteration 3587][Wall Clock 356.610077381s] Trained 128 records in 0.085114708 seconds. Throughput is 1503.8529 records/second. Loss is 0.25260872. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058234334963894714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39040/60000][Iteration 3588][Wall Clock 356.68987532s] Trained 128 records in 0.079797939 seconds. Throughput is 1604.0515 records/second. Loss is 0.18010285. Sequential31006cbd's hyper parameters: Current learning rate is 0.005822755327821125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39168/60000][Iteration 3589][Wall Clock 356.764019918s] Trained 128 records in 0.074144598 seconds. Throughput is 1726.3564 records/second. Loss is 0.24706803. Sequential31006cbd's hyper parameters: Current learning rate is 0.005822077317186773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39296/60000][Iteration 3590][Wall Clock 356.861149755s] Trained 128 records in 0.097129837 seconds. Throughput is 1317.8237 records/second. Loss is 0.27544302. Sequential31006cbd's hyper parameters: Current learning rate is 0.005821399464431249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39424/60000][Iteration 3591][Wall Clock 356.944808652s] Trained 128 records in 0.083658897 seconds. Throughput is 1530.0226 records/second. Loss is 0.25173354. Sequential31006cbd's hyper parameters: Current learning rate is 0.005820721769499418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39552/60000][Iteration 3592][Wall Clock 357.024245361s] Trained 128 records in 0.079436709 seconds. Throughput is 1611.3457 records/second. Loss is 0.16428113. Sequential31006cbd's hyper parameters: Current learning rate is 0.005820044232336166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39680/60000][Iteration 3593][Wall Clock 357.116098039s] Trained 128 records in 0.091852678 seconds. Throughput is 1393.5358 records/second. Loss is 0.22466485. Sequential31006cbd's hyper parameters: Current learning rate is 0.005819366852886406. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39808/60000][Iteration 3594][Wall Clock 357.223005141s] Trained 128 records in 0.106907102 seconds. Throughput is 1197.3013 records/second. Loss is 0.13518226. Sequential31006cbd's hyper parameters: Current learning rate is 0.005818689631095078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 39936/60000][Iteration 3595][Wall Clock 357.317830164s] Trained 128 records in 0.094825023 seconds. Throughput is 1349.8547 records/second. Loss is 0.17704739. Sequential31006cbd's hyper parameters: Current learning rate is 0.005818012566907145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:34 INFO  DistriOptimizer$:408 - [Epoch 8 40064/60000][Iteration 3596][Wall Clock 357.409587713s] Trained 128 records in 0.091757549 seconds. Throughput is 1394.9806 records/second. Loss is 0.24205211. Sequential31006cbd's hyper parameters: Current learning rate is 0.005817335660267597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40192/60000][Iteration 3597][Wall Clock 357.494276102s] Trained 128 records in 0.084688389 seconds. Throughput is 1511.4232 records/second. Loss is 0.20604572. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058166589111214514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40320/60000][Iteration 3598][Wall Clock 357.592139084s] Trained 128 records in 0.097862982 seconds. Throughput is 1307.9512 records/second. Loss is 0.23242584. Sequential31006cbd's hyper parameters: Current learning rate is 0.005815982319413749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40448/60000][Iteration 3599][Wall Clock 357.682432497s] Trained 128 records in 0.090293413 seconds. Throughput is 1417.6006 records/second. Loss is 0.24755287. Sequential31006cbd's hyper parameters: Current learning rate is 0.005815305885089556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40576/60000][Iteration 3600][Wall Clock 357.76315107s] Trained 128 records in 0.080718573 seconds. Throughput is 1585.7566 records/second. Loss is 0.22100607. Sequential31006cbd's hyper parameters: Current learning rate is 0.005814629608093965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40704/60000][Iteration 3601][Wall Clock 357.850590593s] Trained 128 records in 0.087439523 seconds. Throughput is 1463.8689 records/second. Loss is 0.3144582. Sequential31006cbd's hyper parameters: Current learning rate is 0.005813953488372092. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40832/60000][Iteration 3602][Wall Clock 357.954420378s] Trained 128 records in 0.103829785 seconds. Throughput is 1232.7869 records/second. Loss is 0.19840857. Sequential31006cbd's hyper parameters: Current learning rate is 0.005813277525869085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 40960/60000][Iteration 3603][Wall Clock 358.037751064s] Trained 128 records in 0.083330686 seconds. Throughput is 1536.0488 records/second. Loss is 0.21032533. Sequential31006cbd's hyper parameters: Current learning rate is 0.005812601720530109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 41088/60000][Iteration 3604][Wall Clock 358.126114594s] Trained 128 records in 0.08836353 seconds. Throughput is 1448.5614 records/second. Loss is 0.27310446. Sequential31006cbd's hyper parameters: Current learning rate is 0.00581192607230036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 41216/60000][Iteration 3605][Wall Clock 358.215149229s] Trained 128 records in 0.089034635 seconds. Throughput is 1437.6428 records/second. Loss is 0.25523055. Sequential31006cbd's hyper parameters: Current learning rate is 0.005811250581125058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 41344/60000][Iteration 3606][Wall Clock 358.293144164s] Trained 128 records in 0.077994935 seconds. Throughput is 1641.1322 records/second. Loss is 0.31809273. Sequential31006cbd's hyper parameters: Current learning rate is 0.005810575246949448. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 41472/60000][Iteration 3607][Wall Clock 358.376007203s] Trained 128 records in 0.082863039 seconds. Throughput is 1544.7177 records/second. Loss is 0.23639347. Sequential31006cbd's hyper parameters: Current learning rate is 0.005809900069718801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:35 INFO  DistriOptimizer$:408 - [Epoch 8 41600/60000][Iteration 3608][Wall Clock 358.457529398s] Trained 128 records in 0.081522195 seconds. Throughput is 1570.1245 records/second. Loss is 0.2264821. Sequential31006cbd's hyper parameters: Current learning rate is 0.005809225049378413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 41728/60000][Iteration 3609][Wall Clock 358.543967706s] Trained 128 records in 0.086438308 seconds. Throughput is 1480.825 records/second. Loss is 0.1753137. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058085501858736064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 41856/60000][Iteration 3610][Wall Clock 358.628986233s] Trained 128 records in 0.085018527 seconds. Throughput is 1505.5541 records/second. Loss is 0.30276352. Sequential31006cbd's hyper parameters: Current learning rate is 0.005807875479149727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 41984/60000][Iteration 3611][Wall Clock 358.71636271s] Trained 128 records in 0.087376477 seconds. Throughput is 1464.9252 records/second. Loss is 0.21237981. Sequential31006cbd's hyper parameters: Current learning rate is 0.005807200929152149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42112/60000][Iteration 3612][Wall Clock 358.80279165s] Trained 128 records in 0.08642894 seconds. Throughput is 1480.9855 records/second. Loss is 0.14191218. Sequential31006cbd's hyper parameters: Current learning rate is 0.005806526535826269. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42240/60000][Iteration 3613][Wall Clock 358.889140656s] Trained 128 records in 0.086349006 seconds. Throughput is 1482.3564 records/second. Loss is 0.2589574. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058058522991175105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42368/60000][Iteration 3614][Wall Clock 358.968585532s] Trained 128 records in 0.079444876 seconds. Throughput is 1611.18 records/second. Loss is 0.22695893. Sequential31006cbd's hyper parameters: Current learning rate is 0.005805178218971323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42496/60000][Iteration 3615][Wall Clock 359.047666315s] Trained 128 records in 0.079080783 seconds. Throughput is 1618.598 records/second. Loss is 0.24668883. Sequential31006cbd's hyper parameters: Current learning rate is 0.005804504295333179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42624/60000][Iteration 3616][Wall Clock 359.127436391s] Trained 128 records in 0.079770076 seconds. Throughput is 1604.6118 records/second. Loss is 0.19495751. Sequential31006cbd's hyper parameters: Current learning rate is 0.005803830528148578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42752/60000][Iteration 3617][Wall Clock 359.208698421s] Trained 128 records in 0.08126203 seconds. Throughput is 1575.1514 records/second. Loss is 0.27115065. Sequential31006cbd's hyper parameters: Current learning rate is 0.005803156917363045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 42880/60000][Iteration 3618][Wall Clock 359.294019537s] Trained 128 records in 0.085321116 seconds. Throughput is 1500.2148 records/second. Loss is 0.29980275. Sequential31006cbd's hyper parameters: Current learning rate is 0.005802483462922131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:36 INFO  DistriOptimizer$:408 - [Epoch 8 43008/60000][Iteration 3619][Wall Clock 359.41248696s] Trained 128 records in 0.118467423 seconds. Throughput is 1080.4658 records/second. Loss is 0.22751576. Sequential31006cbd's hyper parameters: Current learning rate is 0.0058018101647714084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43136/60000][Iteration 3620][Wall Clock 359.524540453s] Trained 128 records in 0.112053493 seconds. Throughput is 1142.3115 records/second. Loss is 0.2720849. Sequential31006cbd's hyper parameters: Current learning rate is 0.00580113702285648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43264/60000][Iteration 3621][Wall Clock 359.606055641s] Trained 128 records in 0.081515188 seconds. Throughput is 1570.2595 records/second. Loss is 0.16712573. Sequential31006cbd's hyper parameters: Current learning rate is 0.00580046403712297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43392/60000][Iteration 3622][Wall Clock 359.69177455s] Trained 128 records in 0.085718909 seconds. Throughput is 1493.2528 records/second. Loss is 0.26294518. Sequential31006cbd's hyper parameters: Current learning rate is 0.005799791207516529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43520/60000][Iteration 3623][Wall Clock 359.778538648s] Trained 128 records in 0.086764098 seconds. Throughput is 1475.2645 records/second. Loss is 0.24198942. Sequential31006cbd's hyper parameters: Current learning rate is 0.005799118533982834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43648/60000][Iteration 3624][Wall Clock 359.860558881s] Trained 128 records in 0.082020233 seconds. Throughput is 1560.5906 records/second. Loss is 0.1691974. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057984460164675865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43776/60000][Iteration 3625][Wall Clock 359.947905512s] Trained 128 records in 0.087346631 seconds. Throughput is 1465.4258 records/second. Loss is 0.20945694. Sequential31006cbd's hyper parameters: Current learning rate is 0.005797773654916512. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 43904/60000][Iteration 3626][Wall Clock 360.033467929s] Trained 128 records in 0.085562417 seconds. Throughput is 1495.9839 records/second. Loss is 0.32954454. Sequential31006cbd's hyper parameters: Current learning rate is 0.005797101449275362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 44032/60000][Iteration 3627][Wall Clock 360.112265233s] Trained 128 records in 0.078797304 seconds. Throughput is 1624.421 records/second. Loss is 0.18994199. Sequential31006cbd's hyper parameters: Current learning rate is 0.005796429399489914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 44160/60000][Iteration 3628][Wall Clock 360.203966585s] Trained 128 records in 0.091701352 seconds. Throughput is 1395.8354 records/second. Loss is 0.19387242. Sequential31006cbd's hyper parameters: Current learning rate is 0.00579575750550597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 44288/60000][Iteration 3629][Wall Clock 360.289852061s] Trained 128 records in 0.085885476 seconds. Throughput is 1490.3568 records/second. Loss is 0.26085573. Sequential31006cbd's hyper parameters: Current learning rate is 0.005795085767269356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 44416/60000][Iteration 3630][Wall Clock 360.369519017s] Trained 128 records in 0.079666956 seconds. Throughput is 1606.6887 records/second. Loss is 0.2864848. Sequential31006cbd's hyper parameters: Current learning rate is 0.005794414184725924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:37 INFO  DistriOptimizer$:408 - [Epoch 8 44544/60000][Iteration 3631][Wall Clock 360.454870482s] Trained 128 records in 0.085351465 seconds. Throughput is 1499.6813 records/second. Loss is 0.27106115. Sequential31006cbd's hyper parameters: Current learning rate is 0.005793742757821553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 44672/60000][Iteration 3632][Wall Clock 360.538201386s] Trained 128 records in 0.083330904 seconds. Throughput is 1536.0447 records/second. Loss is 0.25777435. Sequential31006cbd's hyper parameters: Current learning rate is 0.005793071486502144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 44800/60000][Iteration 3633][Wall Clock 360.615349904s] Trained 128 records in 0.077148518 seconds. Throughput is 1659.1375 records/second. Loss is 0.203756. Sequential31006cbd's hyper parameters: Current learning rate is 0.005792400370713624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 44928/60000][Iteration 3634][Wall Clock 360.694527997s] Trained 128 records in 0.079178093 seconds. Throughput is 1616.6088 records/second. Loss is 0.24509704. Sequential31006cbd's hyper parameters: Current learning rate is 0.005791729410401947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45056/60000][Iteration 3635][Wall Clock 360.772567169s] Trained 128 records in 0.078039172 seconds. Throughput is 1640.202 records/second. Loss is 0.22034594. Sequential31006cbd's hyper parameters: Current learning rate is 0.005791058605513088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45184/60000][Iteration 3636][Wall Clock 360.855113568s] Trained 128 records in 0.082546399 seconds. Throughput is 1550.6431 records/second. Loss is 0.20970261. Sequential31006cbd's hyper parameters: Current learning rate is 0.005790387955993052. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45312/60000][Iteration 3637][Wall Clock 360.929979465s] Trained 128 records in 0.074865897 seconds. Throughput is 1709.7236 records/second. Loss is 0.20042004. Sequential31006cbd's hyper parameters: Current learning rate is 0.005789717461787865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45440/60000][Iteration 3638][Wall Clock 361.009621844s] Trained 128 records in 0.079642379 seconds. Throughput is 1607.1846 records/second. Loss is 0.29508084. Sequential31006cbd's hyper parameters: Current learning rate is 0.00578904712284358. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45568/60000][Iteration 3639][Wall Clock 361.090503869s] Trained 128 records in 0.080882025 seconds. Throughput is 1582.5518 records/second. Loss is 0.28302506. Sequential31006cbd's hyper parameters: Current learning rate is 0.005788376939106275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45696/60000][Iteration 3640][Wall Clock 361.176504572s] Trained 128 records in 0.086000703 seconds. Throughput is 1488.3599 records/second. Loss is 0.18376368. Sequential31006cbd's hyper parameters: Current learning rate is 0.005787706910522051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45824/60000][Iteration 3641][Wall Clock 361.262544369s] Trained 128 records in 0.086039797 seconds. Throughput is 1487.6837 records/second. Loss is 0.20163506. Sequential31006cbd's hyper parameters: Current learning rate is 0.005787037037037038. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 45952/60000][Iteration 3642][Wall Clock 361.339063299s] Trained 128 records in 0.07651893 seconds. Throughput is 1672.7887 records/second. Loss is 0.24285069. Sequential31006cbd's hyper parameters: Current learning rate is 0.005786367318597384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:38 INFO  DistriOptimizer$:408 - [Epoch 8 46080/60000][Iteration 3643][Wall Clock 361.41168361s] Trained 128 records in 0.072620311 seconds. Throughput is 1762.5923 records/second. Loss is 0.25417507. Sequential31006cbd's hyper parameters: Current learning rate is 0.005785697755149271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46208/60000][Iteration 3644][Wall Clock 361.486121734s] Trained 128 records in 0.074438124 seconds. Throughput is 1719.549 records/second. Loss is 0.22846285. Sequential31006cbd's hyper parameters: Current learning rate is 0.005785028346638898. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46336/60000][Iteration 3645][Wall Clock 361.580293317s] Trained 128 records in 0.094171583 seconds. Throughput is 1359.2211 records/second. Loss is 0.26842847. Sequential31006cbd's hyper parameters: Current learning rate is 0.005784359093012494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46464/60000][Iteration 3646][Wall Clock 361.664648662s] Trained 128 records in 0.084355345 seconds. Throughput is 1517.3905 records/second. Loss is 0.27466682. Sequential31006cbd's hyper parameters: Current learning rate is 0.00578368999421631. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46592/60000][Iteration 3647][Wall Clock 361.741943178s] Trained 128 records in 0.077294516 seconds. Throughput is 1656.0037 records/second. Loss is 0.23715644. Sequential31006cbd's hyper parameters: Current learning rate is 0.005783021050196622. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46720/60000][Iteration 3648][Wall Clock 361.838137926s] Trained 128 records in 0.096194748 seconds. Throughput is 1330.6339 records/second. Loss is 0.18875325. Sequential31006cbd's hyper parameters: Current learning rate is 0.005782352260899734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46848/60000][Iteration 3649][Wall Clock 361.923814728s] Trained 128 records in 0.085676802 seconds. Throughput is 1493.9866 records/second. Loss is 0.20964634. Sequential31006cbd's hyper parameters: Current learning rate is 0.00578168362627197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 46976/60000][Iteration 3650][Wall Clock 362.004303011s] Trained 128 records in 0.080488283 seconds. Throughput is 1590.2937 records/second. Loss is 0.17739165. Sequential31006cbd's hyper parameters: Current learning rate is 0.005781015146259684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 47104/60000][Iteration 3651][Wall Clock 362.081855027s] Trained 128 records in 0.077552016 seconds. Throughput is 1650.5052 records/second. Loss is 0.20552123. Sequential31006cbd's hyper parameters: Current learning rate is 0.005780346820809249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 47232/60000][Iteration 3652][Wall Clock 362.161320444s] Trained 128 records in 0.079465417 seconds. Throughput is 1610.7635 records/second. Loss is 0.23206855. Sequential31006cbd's hyper parameters: Current learning rate is 0.005779678649867068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 47360/60000][Iteration 3653][Wall Clock 362.244859353s] Trained 128 records in 0.083538909 seconds. Throughput is 1532.2201 records/second. Loss is 0.22036165. Sequential31006cbd's hyper parameters: Current learning rate is 0.005779010633379566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 47488/60000][Iteration 3654][Wall Clock 362.331393618s] Trained 128 records in 0.086534265 seconds. Throughput is 1479.1829 records/second. Loss is 0.26635394. Sequential31006cbd's hyper parameters: Current learning rate is 0.005778342771293194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:39 INFO  DistriOptimizer$:408 - [Epoch 8 47616/60000][Iteration 3655][Wall Clock 362.417576724s] Trained 128 records in 0.086183106 seconds. Throughput is 1485.2098 records/second. Loss is 0.26097524. Sequential31006cbd's hyper parameters: Current learning rate is 0.005777675063554426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 47744/60000][Iteration 3656][Wall Clock 362.498290359s] Trained 128 records in 0.080713635 seconds. Throughput is 1585.8534 records/second. Loss is 0.15712847. Sequential31006cbd's hyper parameters: Current learning rate is 0.005777007510109763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 47872/60000][Iteration 3657][Wall Clock 362.579656898s] Trained 128 records in 0.081366539 seconds. Throughput is 1573.1283 records/second. Loss is 0.24831972. Sequential31006cbd's hyper parameters: Current learning rate is 0.00577634011090573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48000/60000][Iteration 3658][Wall Clock 362.659907833s] Trained 128 records in 0.080250935 seconds. Throughput is 1594.9971 records/second. Loss is 0.26237285. Sequential31006cbd's hyper parameters: Current learning rate is 0.005775672865888876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48128/60000][Iteration 3659][Wall Clock 362.747573646s] Trained 128 records in 0.087665813 seconds. Throughput is 1460.0903 records/second. Loss is 0.16157545. Sequential31006cbd's hyper parameters: Current learning rate is 0.005775005775005775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48256/60000][Iteration 3660][Wall Clock 362.832198621s] Trained 128 records in 0.084624975 seconds. Throughput is 1512.5558 records/second. Loss is 0.29900765. Sequential31006cbd's hyper parameters: Current learning rate is 0.005774338838203026. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48384/60000][Iteration 3661][Wall Clock 362.932670151s] Trained 128 records in 0.10047153 seconds. Throughput is 1273.9928 records/second. Loss is 0.14990062. Sequential31006cbd's hyper parameters: Current learning rate is 0.005773672055427252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48512/60000][Iteration 3662][Wall Clock 363.012848061s] Trained 128 records in 0.08017791 seconds. Throughput is 1596.4497 records/second. Loss is 0.255003. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057730054266251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48640/60000][Iteration 3663][Wall Clock 363.103807986s] Trained 128 records in 0.090959925 seconds. Throughput is 1407.2131 records/second. Loss is 0.17210652. Sequential31006cbd's hyper parameters: Current learning rate is 0.005772338951743246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48768/60000][Iteration 3664][Wall Clock 363.19790581s] Trained 128 records in 0.094097824 seconds. Throughput is 1360.2865 records/second. Loss is 0.25224054. Sequential31006cbd's hyper parameters: Current learning rate is 0.005771672630728385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 48896/60000][Iteration 3665][Wall Clock 363.276535513s] Trained 128 records in 0.078629703 seconds. Throughput is 1627.8835 records/second. Loss is 0.24818043. Sequential31006cbd's hyper parameters: Current learning rate is 0.005771006463527239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 49024/60000][Iteration 3666][Wall Clock 363.349683662s] Trained 128 records in 0.073148149 seconds. Throughput is 1749.8734 records/second. Loss is 0.25848544. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057703404500865545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:40 INFO  DistriOptimizer$:408 - [Epoch 8 49152/60000][Iteration 3667][Wall Clock 363.445976309s] Trained 128 records in 0.096292647 seconds. Throughput is 1329.2811 records/second. Loss is 0.23104. Sequential31006cbd's hyper parameters: Current learning rate is 0.005769674590353104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 49280/60000][Iteration 3668][Wall Clock 363.534272706s] Trained 128 records in 0.088296397 seconds. Throughput is 1449.6627 records/second. Loss is 0.2199201. Sequential31006cbd's hyper parameters: Current learning rate is 0.005769008884273682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 49408/60000][Iteration 3669][Wall Clock 363.619089735s] Trained 128 records in 0.084817029 seconds. Throughput is 1509.1309 records/second. Loss is 0.20553584. Sequential31006cbd's hyper parameters: Current learning rate is 0.005768343331795108. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 49536/60000][Iteration 3670][Wall Clock 363.696224054s] Trained 128 records in 0.077134319 seconds. Throughput is 1659.443 records/second. Loss is 0.300055. Sequential31006cbd's hyper parameters: Current learning rate is 0.005767677932864229. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 49664/60000][Iteration 3671][Wall Clock 363.783809153s] Trained 128 records in 0.087585099 seconds. Throughput is 1461.4358 records/second. Loss is 0.21493344. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057670126874279125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 49792/60000][Iteration 3672][Wall Clock 363.860954246s] Trained 128 records in 0.077145093 seconds. Throughput is 1659.2112 records/second. Loss is 0.19151402. Sequential31006cbd's hyper parameters: Current learning rate is 0.005766347595433053. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 49920/60000][Iteration 3673][Wall Clock 363.941298482s] Trained 128 records in 0.080344236 seconds. Throughput is 1593.1448 records/second. Loss is 0.22617492. Sequential31006cbd's hyper parameters: Current learning rate is 0.005765682656826568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 50048/60000][Iteration 3674][Wall Clock 364.027005002s] Trained 128 records in 0.08570652 seconds. Throughput is 1493.4688 records/second. Loss is 0.25568467. Sequential31006cbd's hyper parameters: Current learning rate is 0.005765017871555402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 50176/60000][Iteration 3675][Wall Clock 364.11446204s] Trained 128 records in 0.087457038 seconds. Throughput is 1463.5757 records/second. Loss is 0.23269394. Sequential31006cbd's hyper parameters: Current learning rate is 0.005764353239566521. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 50304/60000][Iteration 3676][Wall Clock 364.194759465s] Trained 128 records in 0.080297425 seconds. Throughput is 1594.0735 records/second. Loss is 0.14833198. Sequential31006cbd's hyper parameters: Current learning rate is 0.005763688760806917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 50432/60000][Iteration 3677][Wall Clock 364.272722568s] Trained 128 records in 0.077963103 seconds. Throughput is 1641.8022 records/second. Loss is 0.21369013. Sequential31006cbd's hyper parameters: Current learning rate is 0.005763024435223605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 50560/60000][Iteration 3678][Wall Clock 364.352301174s] Trained 128 records in 0.079578606 seconds. Throughput is 1608.4724 records/second. Loss is 0.26366642. Sequential31006cbd's hyper parameters: Current learning rate is 0.005762360262763628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:41 INFO  DistriOptimizer$:408 - [Epoch 8 50688/60000][Iteration 3679][Wall Clock 364.432448291s] Trained 128 records in 0.080147117 seconds. Throughput is 1597.0631 records/second. Loss is 0.18676665. Sequential31006cbd's hyper parameters: Current learning rate is 0.005761696243374049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 50816/60000][Iteration 3680][Wall Clock 364.520478808s] Trained 128 records in 0.088030517 seconds. Throughput is 1454.0413 records/second. Loss is 0.22586745. Sequential31006cbd's hyper parameters: Current learning rate is 0.005761032377001958. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 50944/60000][Iteration 3681][Wall Clock 364.601986629s] Trained 128 records in 0.081507821 seconds. Throughput is 1570.4014 records/second. Loss is 0.19237325. Sequential31006cbd's hyper parameters: Current learning rate is 0.00576036866359447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51072/60000][Iteration 3682][Wall Clock 364.684464844s] Trained 128 records in 0.082478215 seconds. Throughput is 1551.9249 records/second. Loss is 0.23688284. Sequential31006cbd's hyper parameters: Current learning rate is 0.005759705103098721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51200/60000][Iteration 3683][Wall Clock 364.769421048s] Trained 128 records in 0.084956204 seconds. Throughput is 1506.6586 records/second. Loss is 0.19035643. Sequential31006cbd's hyper parameters: Current learning rate is 0.005759041695461875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51328/60000][Iteration 3684][Wall Clock 364.852147659s] Trained 128 records in 0.082726611 seconds. Throughput is 1547.2651 records/second. Loss is 0.18879066. Sequential31006cbd's hyper parameters: Current learning rate is 0.005758378440631118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51456/60000][Iteration 3685][Wall Clock 364.933966954s] Trained 128 records in 0.081819295 seconds. Throughput is 1564.4231 records/second. Loss is 0.3217128. Sequential31006cbd's hyper parameters: Current learning rate is 0.005757715338553662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51584/60000][Iteration 3686][Wall Clock 365.028671319s] Trained 128 records in 0.094704365 seconds. Throughput is 1351.5745 records/second. Loss is 0.25720835. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057570523891767415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51712/60000][Iteration 3687][Wall Clock 365.14203435s] Trained 128 records in 0.113363031 seconds. Throughput is 1129.116 records/second. Loss is 0.14687045. Sequential31006cbd's hyper parameters: Current learning rate is 0.005756389592447617. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51840/60000][Iteration 3688][Wall Clock 365.236158542s] Trained 128 records in 0.094124192 seconds. Throughput is 1359.9054 records/second. Loss is 0.22195806. Sequential31006cbd's hyper parameters: Current learning rate is 0.005755726948313572. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 51968/60000][Iteration 3689][Wall Clock 365.341415313s] Trained 128 records in 0.105256771 seconds. Throughput is 1216.0737 records/second. Loss is 0.22917704. Sequential31006cbd's hyper parameters: Current learning rate is 0.005755064456721915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:42 INFO  DistriOptimizer$:408 - [Epoch 8 52096/60000][Iteration 3690][Wall Clock 365.417383627s] Trained 128 records in 0.075968314 seconds. Throughput is 1684.913 records/second. Loss is 0.27649304. Sequential31006cbd's hyper parameters: Current learning rate is 0.005754402117619979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52224/60000][Iteration 3691][Wall Clock 365.493054074s] Trained 128 records in 0.075670447 seconds. Throughput is 1691.5455 records/second. Loss is 0.23535666. Sequential31006cbd's hyper parameters: Current learning rate is 0.005753739930955121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52352/60000][Iteration 3692][Wall Clock 365.572942471s] Trained 128 records in 0.079888397 seconds. Throughput is 1602.2352 records/second. Loss is 0.19629541. Sequential31006cbd's hyper parameters: Current learning rate is 0.005753077896674721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52480/60000][Iteration 3693][Wall Clock 365.668522364s] Trained 128 records in 0.095579893 seconds. Throughput is 1339.1938 records/second. Loss is 0.18010555. Sequential31006cbd's hyper parameters: Current learning rate is 0.005752416014726185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52608/60000][Iteration 3694][Wall Clock 365.747863282s] Trained 128 records in 0.079340918 seconds. Throughput is 1613.2911 records/second. Loss is 0.17414962. Sequential31006cbd's hyper parameters: Current learning rate is 0.005751754285056943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52736/60000][Iteration 3695][Wall Clock 365.82797295s] Trained 128 records in 0.080109668 seconds. Throughput is 1597.8096 records/second. Loss is 0.26248947. Sequential31006cbd's hyper parameters: Current learning rate is 0.005751092707614447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52864/60000][Iteration 3696][Wall Clock 365.928626896s] Trained 128 records in 0.100653946 seconds. Throughput is 1271.6838 records/second. Loss is 0.18782252. Sequential31006cbd's hyper parameters: Current learning rate is 0.005750431282346176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 52992/60000][Iteration 3697][Wall Clock 366.036637932s] Trained 128 records in 0.108011036 seconds. Throughput is 1185.0641 records/second. Loss is 0.25933093. Sequential31006cbd's hyper parameters: Current learning rate is 0.005749770009199632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 53120/60000][Iteration 3698][Wall Clock 366.130640854s] Trained 128 records in 0.094002922 seconds. Throughput is 1361.6598 records/second. Loss is 0.25333768. Sequential31006cbd's hyper parameters: Current learning rate is 0.005749108888122341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 53248/60000][Iteration 3699][Wall Clock 366.221756249s] Trained 128 records in 0.091115395 seconds. Throughput is 1404.812 records/second. Loss is 0.2151403. Sequential31006cbd's hyper parameters: Current learning rate is 0.005748447919061853. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 53376/60000][Iteration 3700][Wall Clock 366.307748318s] Trained 128 records in 0.085992069 seconds. Throughput is 1488.5094 records/second. Loss is 0.19522052. Sequential31006cbd's hyper parameters: Current learning rate is 0.005747787101965743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:43 INFO  DistriOptimizer$:408 - [Epoch 8 53504/60000][Iteration 3701][Wall Clock 366.385716191s] Trained 128 records in 0.077967873 seconds. Throughput is 1641.7018 records/second. Loss is 0.34108084. Sequential31006cbd's hyper parameters: Current learning rate is 0.005747126436781609. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 53632/60000][Iteration 3702][Wall Clock 366.461313074s] Trained 128 records in 0.075596883 seconds. Throughput is 1693.1915 records/second. Loss is 0.1921777. Sequential31006cbd's hyper parameters: Current learning rate is 0.005746465923457073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 53760/60000][Iteration 3703][Wall Clock 366.550530502s] Trained 128 records in 0.089217428 seconds. Throughput is 1434.6973 records/second. Loss is 0.2019202. Sequential31006cbd's hyper parameters: Current learning rate is 0.005745805561939783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 53888/60000][Iteration 3704][Wall Clock 366.641688763s] Trained 128 records in 0.091158261 seconds. Throughput is 1404.1514 records/second. Loss is 0.20815976. Sequential31006cbd's hyper parameters: Current learning rate is 0.00574514535217741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54016/60000][Iteration 3705][Wall Clock 366.717792481s] Trained 128 records in 0.076103718 seconds. Throughput is 1681.9152 records/second. Loss is 0.14586927. Sequential31006cbd's hyper parameters: Current learning rate is 0.005744485294117647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54144/60000][Iteration 3706][Wall Clock 366.795337878s] Trained 128 records in 0.077545397 seconds. Throughput is 1650.646 records/second. Loss is 0.2852672. Sequential31006cbd's hyper parameters: Current learning rate is 0.005743825387708214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54272/60000][Iteration 3707][Wall Clock 366.869530182s] Trained 128 records in 0.074192304 seconds. Throughput is 1725.2465 records/second. Loss is 0.20102762. Sequential31006cbd's hyper parameters: Current learning rate is 0.005743165632896853. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54400/60000][Iteration 3708][Wall Clock 366.945090861s] Trained 128 records in 0.075560679 seconds. Throughput is 1694.0027 records/second. Loss is 0.2574073. Sequential31006cbd's hyper parameters: Current learning rate is 0.005742506029631331. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54528/60000][Iteration 3709][Wall Clock 367.020614313s] Trained 128 records in 0.075523452 seconds. Throughput is 1694.8378 records/second. Loss is 0.22312132. Sequential31006cbd's hyper parameters: Current learning rate is 0.005741846577859439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54656/60000][Iteration 3710][Wall Clock 367.094297189s] Trained 128 records in 0.073682876 seconds. Throughput is 1737.1743 records/second. Loss is 0.24886854. Sequential31006cbd's hyper parameters: Current learning rate is 0.005741187277528993. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54784/60000][Iteration 3711][Wall Clock 367.182831238s] Trained 128 records in 0.088534049 seconds. Throughput is 1445.7715 records/second. Loss is 0.1960001. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057405281285878304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 54912/60000][Iteration 3712][Wall Clock 367.281861194s] Trained 128 records in 0.099029956 seconds. Throughput is 1292.5382 records/second. Loss is 0.23523334. Sequential31006cbd's hyper parameters: Current learning rate is 0.005739869130983814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:44 INFO  DistriOptimizer$:408 - [Epoch 8 55040/60000][Iteration 3713][Wall Clock 367.358337553s] Trained 128 records in 0.076476359 seconds. Throughput is 1673.7198 records/second. Loss is 0.21154022. Sequential31006cbd's hyper parameters: Current learning rate is 0.005739210284664831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55168/60000][Iteration 3714][Wall Clock 367.448519557s] Trained 128 records in 0.090182004 seconds. Throughput is 1419.3519 records/second. Loss is 0.22496451. Sequential31006cbd's hyper parameters: Current learning rate is 0.005738551589578791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55296/60000][Iteration 3715][Wall Clock 367.525447721s] Trained 128 records in 0.076928164 seconds. Throughput is 1663.89 records/second. Loss is 0.20981574. Sequential31006cbd's hyper parameters: Current learning rate is 0.005737893045673629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55424/60000][Iteration 3716][Wall Clock 367.603067443s] Trained 128 records in 0.077619722 seconds. Throughput is 1649.0654 records/second. Loss is 0.19413832. Sequential31006cbd's hyper parameters: Current learning rate is 0.005737234652897304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55552/60000][Iteration 3717][Wall Clock 367.680079917s] Trained 128 records in 0.077012474 seconds. Throughput is 1662.0685 records/second. Loss is 0.33305648. Sequential31006cbd's hyper parameters: Current learning rate is 0.005736576411197797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55680/60000][Iteration 3718][Wall Clock 367.756528351s] Trained 128 records in 0.076448434 seconds. Throughput is 1674.3313 records/second. Loss is 0.22365406. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057359183205231154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55808/60000][Iteration 3719][Wall Clock 367.854890024s] Trained 128 records in 0.098361673 seconds. Throughput is 1301.32 records/second. Loss is 0.22785866. Sequential31006cbd's hyper parameters: Current learning rate is 0.005735260380821289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 55936/60000][Iteration 3720][Wall Clock 367.946224203s] Trained 128 records in 0.091334179 seconds. Throughput is 1401.4469 records/second. Loss is 0.20884548. Sequential31006cbd's hyper parameters: Current learning rate is 0.005734602592040372. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 56064/60000][Iteration 3721][Wall Clock 368.03849006s] Trained 128 records in 0.092265857 seconds. Throughput is 1387.2954 records/second. Loss is 0.26098722. Sequential31006cbd's hyper parameters: Current learning rate is 0.005733944954128441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 56192/60000][Iteration 3722][Wall Clock 368.116343214s] Trained 128 records in 0.077853154 seconds. Throughput is 1644.121 records/second. Loss is 0.19551715. Sequential31006cbd's hyper parameters: Current learning rate is 0.005733287467033597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 56320/60000][Iteration 3723][Wall Clock 368.217322386s] Trained 128 records in 0.100979172 seconds. Throughput is 1267.5881 records/second. Loss is 0.21766844. Sequential31006cbd's hyper parameters: Current learning rate is 0.005732630130703967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 56448/60000][Iteration 3724][Wall Clock 368.30363691s] Trained 128 records in 0.086314524 seconds. Throughput is 1482.9486 records/second. Loss is 0.24000555. Sequential31006cbd's hyper parameters: Current learning rate is 0.005731972945087699. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:45 INFO  DistriOptimizer$:408 - [Epoch 8 56576/60000][Iteration 3725][Wall Clock 368.39408992s] Trained 128 records in 0.09045301 seconds. Throughput is 1415.0995 records/second. Loss is 0.27794158. Sequential31006cbd's hyper parameters: Current learning rate is 0.005731315910132966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 56704/60000][Iteration 3726][Wall Clock 368.485956421s] Trained 128 records in 0.091866501 seconds. Throughput is 1393.3262 records/second. Loss is 0.24105066. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057306590257879654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 56832/60000][Iteration 3727][Wall Clock 368.568681082s] Trained 128 records in 0.082724661 seconds. Throughput is 1547.3016 records/second. Loss is 0.2859463. Sequential31006cbd's hyper parameters: Current learning rate is 0.005730002292000917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 56960/60000][Iteration 3728][Wall Clock 368.650222479s] Trained 128 records in 0.081541397 seconds. Throughput is 1569.7548 records/second. Loss is 0.26126215. Sequential31006cbd's hyper parameters: Current learning rate is 0.005729345708720064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57088/60000][Iteration 3729][Wall Clock 368.725652384s] Trained 128 records in 0.075429905 seconds. Throughput is 1696.9398 records/second. Loss is 0.20866491. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057286892758936754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57216/60000][Iteration 3730][Wall Clock 368.804627843s] Trained 128 records in 0.078975459 seconds. Throughput is 1620.7566 records/second. Loss is 0.21240643. Sequential31006cbd's hyper parameters: Current learning rate is 0.005728032993470042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57344/60000][Iteration 3731][Wall Clock 368.887404652s] Trained 128 records in 0.082776809 seconds. Throughput is 1546.3269 records/second. Loss is 0.32924253. Sequential31006cbd's hyper parameters: Current learning rate is 0.00572737686139748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57472/60000][Iteration 3732][Wall Clock 368.969691108s] Trained 128 records in 0.082286456 seconds. Throughput is 1555.5415 records/second. Loss is 0.16742975. Sequential31006cbd's hyper parameters: Current learning rate is 0.005726720879624328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57600/60000][Iteration 3733][Wall Clock 369.056272082s] Trained 128 records in 0.086580974 seconds. Throughput is 1478.3848 records/second. Loss is 0.30611616. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057260650480989465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57728/60000][Iteration 3734][Wall Clock 369.133395186s] Trained 128 records in 0.077123104 seconds. Throughput is 1659.6842 records/second. Loss is 0.18937859. Sequential31006cbd's hyper parameters: Current learning rate is 0.005725409366769725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57856/60000][Iteration 3735][Wall Clock 369.210354136s] Trained 128 records in 0.07695895 seconds. Throughput is 1663.2244 records/second. Loss is 0.22636291. Sequential31006cbd's hyper parameters: Current learning rate is 0.00572475383558507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 57984/60000][Iteration 3736][Wall Clock 369.304735349s] Trained 128 records in 0.094381213 seconds. Throughput is 1356.2021 records/second. Loss is 0.20555001. Sequential31006cbd's hyper parameters: Current learning rate is 0.005724098454493418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:46 INFO  DistriOptimizer$:408 - [Epoch 8 58112/60000][Iteration 3737][Wall Clock 369.388126982s] Trained 128 records in 0.083391633 seconds. Throughput is 1534.9261 records/second. Loss is 0.19965869. Sequential31006cbd's hyper parameters: Current learning rate is 0.005723443223443223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 58240/60000][Iteration 3738][Wall Clock 369.486775283s] Trained 128 records in 0.098648301 seconds. Throughput is 1297.5388 records/second. Loss is 0.3225815. Sequential31006cbd's hyper parameters: Current learning rate is 0.005722788142382969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 58368/60000][Iteration 3739][Wall Clock 369.563418519s] Trained 128 records in 0.076643236 seconds. Throughput is 1670.0756 records/second. Loss is 0.2033643. Sequential31006cbd's hyper parameters: Current learning rate is 0.005722133211261158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 58496/60000][Iteration 3740][Wall Clock 369.653392671s] Trained 128 records in 0.089974152 seconds. Throughput is 1422.6309 records/second. Loss is 0.2486603. Sequential31006cbd's hyper parameters: Current learning rate is 0.005721478430026319. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 58624/60000][Iteration 3741][Wall Clock 369.73653212s] Trained 128 records in 0.083139449 seconds. Throughput is 1539.582 records/second. Loss is 0.24282469. Sequential31006cbd's hyper parameters: Current learning rate is 0.005720823798627002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 58752/60000][Iteration 3742][Wall Clock 369.814178209s] Trained 128 records in 0.077646089 seconds. Throughput is 1648.5054 records/second. Loss is 0.13480723. Sequential31006cbd's hyper parameters: Current learning rate is 0.005720169317011783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 58880/60000][Iteration 3743][Wall Clock 369.889464155s] Trained 128 records in 0.075285946 seconds. Throughput is 1700.1844 records/second. Loss is 0.17782038. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057195149851292605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 59008/60000][Iteration 3744][Wall Clock 369.965570004s] Trained 128 records in 0.076105849 seconds. Throughput is 1681.8682 records/second. Loss is 0.17916825. Sequential31006cbd's hyper parameters: Current learning rate is 0.005718860802928057. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 59136/60000][Iteration 3745][Wall Clock 370.041675363s] Trained 128 records in 0.076105359 seconds. Throughput is 1681.879 records/second. Loss is 0.29206803. Sequential31006cbd's hyper parameters: Current learning rate is 0.005718206770356816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 59264/60000][Iteration 3746][Wall Clock 370.126654329s] Trained 128 records in 0.084978966 seconds. Throughput is 1506.255 records/second. Loss is 0.19508848. Sequential31006cbd's hyper parameters: Current learning rate is 0.005717552887364208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 59392/60000][Iteration 3747][Wall Clock 370.203534647s] Trained 128 records in 0.076880318 seconds. Throughput is 1664.9254 records/second. Loss is 0.28710836. Sequential31006cbd's hyper parameters: Current learning rate is 0.005716899153898925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 59520/60000][Iteration 3748][Wall Clock 370.281634727s] Trained 128 records in 0.07810008 seconds. Throughput is 1638.9229 records/second. Loss is 0.26231626. Sequential31006cbd's hyper parameters: Current learning rate is 0.005716245569909683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:47 INFO  DistriOptimizer$:408 - [Epoch 8 59648/60000][Iteration 3749][Wall Clock 370.374414462s] Trained 128 records in 0.092779735 seconds. Throughput is 1379.6117 records/second. Loss is 0.23421623. Sequential31006cbd's hyper parameters: Current learning rate is 0.005715592135345221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:48 INFO  DistriOptimizer$:408 - [Epoch 8 59776/60000][Iteration 3750][Wall Clock 370.483232558s] Trained 128 records in 0.108818096 seconds. Throughput is 1176.2749 records/second. Loss is 0.27756143. Sequential31006cbd's hyper parameters: Current learning rate is 0.005714938850154303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:48 INFO  DistriOptimizer$:408 - [Epoch 8 59904/60000][Iteration 3751][Wall Clock 370.563858705s] Trained 128 records in 0.080626147 seconds. Throughput is 1587.5743 records/second. Loss is 0.21638234. Sequential31006cbd's hyper parameters: Current learning rate is 0.005714285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:48 INFO  DistriOptimizer$:408 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 370.642019737s] Trained 128 records in 0.078161032 seconds. Throughput is 1637.6448 records/second. Loss is 0.24280217. Sequential31006cbd's hyper parameters: Current learning rate is 0.005713632727688264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:48 INFO  DistriOptimizer$:452 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 370.642019737s] Epoch finished. Wall clock time is 371741.675925 ms
2019-10-24 00:03:48 INFO  DistriOptimizer$:111 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 370.642019737s] Validate model...
2019-10-24 00:03:49 INFO  DistriOptimizer$:178 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 370.642019737s] validate model throughput is 11838.703 records/second
2019-10-24 00:03:49 INFO  DistriOptimizer$:181 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 370.642019737s] Top1Accuracy is Accuracy(correct: 9398, count: 10000, accuracy: 0.9398)
2019-10-24 00:03:49 INFO  DistriOptimizer$:221 - [Wall Clock 371.741675925s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:03:49 INFO  DistriOptimizer$:226 - [Wall Clock 371.741675925s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 128/60000][Iteration 3753][Wall Clock 371.841006039s] Trained 128 records in 0.099330114 seconds. Throughput is 1288.6324 records/second. Loss is 0.2445816. Sequential31006cbd's hyper parameters: Current learning rate is 0.005712979890310786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 256/60000][Iteration 3754][Wall Clock 371.920455558s] Trained 128 records in 0.079449519 seconds. Throughput is 1611.0859 records/second. Loss is 0.20199198. Sequential31006cbd's hyper parameters: Current learning rate is 0.005712327202102137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 384/60000][Iteration 3755][Wall Clock 372.003039569s] Trained 128 records in 0.082584011 seconds. Throughput is 1549.9369 records/second. Loss is 0.20731865. Sequential31006cbd's hyper parameters: Current learning rate is 0.005711674663011195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 512/60000][Iteration 3756][Wall Clock 372.085244706s] Trained 128 records in 0.082205137 seconds. Throughput is 1557.0803 records/second. Loss is 0.20774913. Sequential31006cbd's hyper parameters: Current learning rate is 0.005711022272986865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 640/60000][Iteration 3757][Wall Clock 372.173659168s] Trained 128 records in 0.088414462 seconds. Throughput is 1447.7269 records/second. Loss is 0.20286414. Sequential31006cbd's hyper parameters: Current learning rate is 0.005710370031978072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 768/60000][Iteration 3758][Wall Clock 372.257445335s] Trained 128 records in 0.083786167 seconds. Throughput is 1527.6985 records/second. Loss is 0.2643413. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057097179399337675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 896/60000][Iteration 3759][Wall Clock 372.338512913s] Trained 128 records in 0.081067578 seconds. Throughput is 1578.9297 records/second. Loss is 0.19379261. Sequential31006cbd's hyper parameters: Current learning rate is 0.005709065996802923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:49 INFO  DistriOptimizer$:408 - [Epoch 9 1024/60000][Iteration 3760][Wall Clock 372.47225427s] Trained 128 records in 0.133741357 seconds. Throughput is 957.07117 records/second. Loss is 0.17492098. Sequential31006cbd's hyper parameters: Current learning rate is 0.005708414202534536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1152/60000][Iteration 3761][Wall Clock 372.579219654s] Trained 128 records in 0.106965384 seconds. Throughput is 1196.6488 records/second. Loss is 0.30649024. Sequential31006cbd's hyper parameters: Current learning rate is 0.005707762557077625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1280/60000][Iteration 3762][Wall Clock 372.691933142s] Trained 128 records in 0.112713488 seconds. Throughput is 1135.6228 records/second. Loss is 0.17489403. Sequential31006cbd's hyper parameters: Current learning rate is 0.005707111060381235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1408/60000][Iteration 3763][Wall Clock 372.791916499s] Trained 128 records in 0.099983357 seconds. Throughput is 1280.213 records/second. Loss is 0.2995374. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057064597123944304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1536/60000][Iteration 3764][Wall Clock 372.892264602s] Trained 128 records in 0.100348103 seconds. Throughput is 1275.5598 records/second. Loss is 0.1961909. Sequential31006cbd's hyper parameters: Current learning rate is 0.005705808513066301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1664/60000][Iteration 3765][Wall Clock 372.995173318s] Trained 128 records in 0.102908716 seconds. Throughput is 1243.8208 records/second. Loss is 0.13752386. Sequential31006cbd's hyper parameters: Current learning rate is 0.005705157462345961. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1792/60000][Iteration 3766][Wall Clock 373.070574171s] Trained 128 records in 0.075400853 seconds. Throughput is 1697.5935 records/second. Loss is 0.22944832. Sequential31006cbd's hyper parameters: Current learning rate is 0.005704506560182544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 1920/60000][Iteration 3767][Wall Clock 373.150547062s] Trained 128 records in 0.079972891 seconds. Throughput is 1600.5424 records/second. Loss is 0.24618998. Sequential31006cbd's hyper parameters: Current learning rate is 0.005703855806525211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 2048/60000][Iteration 3768][Wall Clock 373.240263526s] Trained 128 records in 0.089716464 seconds. Throughput is 1426.7169 records/second. Loss is 0.16381592. Sequential31006cbd's hyper parameters: Current learning rate is 0.005703205201323143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 2176/60000][Iteration 3769][Wall Clock 373.331034382s] Trained 128 records in 0.090770856 seconds. Throughput is 1410.1443 records/second. Loss is 0.24341303. Sequential31006cbd's hyper parameters: Current learning rate is 0.005702554744525547. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 2304/60000][Iteration 3770][Wall Clock 373.429169478s] Trained 128 records in 0.098135096 seconds. Throughput is 1304.3243 records/second. Loss is 0.19183122. Sequential31006cbd's hyper parameters: Current learning rate is 0.0057019044360816515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:50 INFO  DistriOptimizer$:408 - [Epoch 9 2432/60000][Iteration 3771][Wall Clock 373.515739766s] Trained 128 records in 0.086570288 seconds. Throughput is 1478.5674 records/second. Loss is 0.20363614. Sequential31006cbd's hyper parameters: Current learning rate is 0.005701254275940707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 2560/60000][Iteration 3772][Wall Clock 373.614246906s] Trained 128 records in 0.09850714 seconds. Throughput is 1299.3982 records/second. Loss is 0.22542286. Sequential31006cbd's hyper parameters: Current learning rate is 0.00570060426405199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 2688/60000][Iteration 3773][Wall Clock 373.700277398s] Trained 128 records in 0.086030492 seconds. Throughput is 1487.8446 records/second. Loss is 0.19458999. Sequential31006cbd's hyper parameters: Current learning rate is 0.005699954400364797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 2816/60000][Iteration 3774][Wall Clock 373.79337733s] Trained 128 records in 0.093099932 seconds. Throughput is 1374.8668 records/second. Loss is 0.22256397. Sequential31006cbd's hyper parameters: Current learning rate is 0.005699304684828451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 2944/60000][Iteration 3775][Wall Clock 373.872949524s] Trained 128 records in 0.079572194 seconds. Throughput is 1608.6022 records/second. Loss is 0.33043817. Sequential31006cbd's hyper parameters: Current learning rate is 0.005698655117392296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3072/60000][Iteration 3776][Wall Clock 373.958986117s] Trained 128 records in 0.086036593 seconds. Throughput is 1487.739 records/second. Loss is 0.2036398. Sequential31006cbd's hyper parameters: Current learning rate is 0.005698005698005698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3200/60000][Iteration 3777][Wall Clock 374.051921501s] Trained 128 records in 0.092935384 seconds. Throughput is 1377.301 records/second. Loss is 0.3986409. Sequential31006cbd's hyper parameters: Current learning rate is 0.00569735642661805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3328/60000][Iteration 3778][Wall Clock 374.133603005s] Trained 128 records in 0.081681504 seconds. Throughput is 1567.0623 records/second. Loss is 0.19829483. Sequential31006cbd's hyper parameters: Current learning rate is 0.005696707303178763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3456/60000][Iteration 3779][Wall Clock 374.218109585s] Trained 128 records in 0.08450658 seconds. Throughput is 1514.6749 records/second. Loss is 0.2572739. Sequential31006cbd's hyper parameters: Current learning rate is 0.005696058327637275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3584/60000][Iteration 3780][Wall Clock 374.298123973s] Trained 128 records in 0.080014388 seconds. Throughput is 1599.7124 records/second. Loss is 0.17854714. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056954094999430455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3712/60000][Iteration 3781][Wall Clock 374.379427152s] Trained 128 records in 0.081303179 seconds. Throughput is 1574.3541 records/second. Loss is 0.18414673. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056947608200455585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:51 INFO  DistriOptimizer$:408 - [Epoch 9 3840/60000][Iteration 3782][Wall Clock 374.455220844s] Trained 128 records in 0.075793692 seconds. Throughput is 1688.7949 records/second. Loss is 0.1506724. Sequential31006cbd's hyper parameters: Current learning rate is 0.005694112287894317. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 3968/60000][Iteration 3783][Wall Clock 374.539083834s] Trained 128 records in 0.08386299 seconds. Throughput is 1526.2991 records/second. Loss is 0.16951862. Sequential31006cbd's hyper parameters: Current learning rate is 0.005693463903438852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4096/60000][Iteration 3784][Wall Clock 374.621472902s] Trained 128 records in 0.082389068 seconds. Throughput is 1553.6041 records/second. Loss is 0.27878746. Sequential31006cbd's hyper parameters: Current learning rate is 0.005692815666628714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4224/60000][Iteration 3785][Wall Clock 374.714755185s] Trained 128 records in 0.093282283 seconds. Throughput is 1372.1791 records/second. Loss is 0.1521656. Sequential31006cbd's hyper parameters: Current learning rate is 0.005692167577413479. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4352/60000][Iteration 3786][Wall Clock 374.79671882s] Trained 128 records in 0.081963635 seconds. Throughput is 1561.6682 records/second. Loss is 0.22723508. Sequential31006cbd's hyper parameters: Current learning rate is 0.005691519635742743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4480/60000][Iteration 3787][Wall Clock 374.879200909s] Trained 128 records in 0.082482089 seconds. Throughput is 1551.852 records/second. Loss is 0.29014894. Sequential31006cbd's hyper parameters: Current learning rate is 0.005690871841566128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4608/60000][Iteration 3788][Wall Clock 374.959946286s] Trained 128 records in 0.080745377 seconds. Throughput is 1585.2301 records/second. Loss is 0.27258167. Sequential31006cbd's hyper parameters: Current learning rate is 0.005690224194833276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4736/60000][Iteration 3789][Wall Clock 375.040425213s] Trained 128 records in 0.080478927 seconds. Throughput is 1590.4784 records/second. Loss is 0.176368. Sequential31006cbd's hyper parameters: Current learning rate is 0.005689576695493855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4864/60000][Iteration 3790][Wall Clock 375.126868698s] Trained 128 records in 0.086443485 seconds. Throughput is 1480.7362 records/second. Loss is 0.2912228. Sequential31006cbd's hyper parameters: Current learning rate is 0.005688929343497554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 4992/60000][Iteration 3791][Wall Clock 375.206444507s] Trained 128 records in 0.079575809 seconds. Throughput is 1608.529 records/second. Loss is 0.20548132. Sequential31006cbd's hyper parameters: Current learning rate is 0.005688282138794084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 5120/60000][Iteration 3792][Wall Clock 375.289753942s] Trained 128 records in 0.083309435 seconds. Throughput is 1536.4407 records/second. Loss is 0.15849385. Sequential31006cbd's hyper parameters: Current learning rate is 0.005687635081333181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 5248/60000][Iteration 3793][Wall Clock 375.368246493s] Trained 128 records in 0.078492551 seconds. Throughput is 1630.728 records/second. Loss is 0.24430373. Sequential31006cbd's hyper parameters: Current learning rate is 0.005686988171064605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:52 INFO  DistriOptimizer$:408 - [Epoch 9 5376/60000][Iteration 3794][Wall Clock 375.444696666s] Trained 128 records in 0.076450173 seconds. Throughput is 1674.2931 records/second. Loss is 0.1864777. Sequential31006cbd's hyper parameters: Current learning rate is 0.005686341407938133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 5504/60000][Iteration 3795][Wall Clock 375.52548504s] Trained 128 records in 0.080788374 seconds. Throughput is 1584.3864 records/second. Loss is 0.22797862. Sequential31006cbd's hyper parameters: Current learning rate is 0.005685694791903571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 5632/60000][Iteration 3796][Wall Clock 375.618852453s] Trained 128 records in 0.093367413 seconds. Throughput is 1370.928 records/second. Loss is 0.23045972. Sequential31006cbd's hyper parameters: Current learning rate is 0.005685048322910745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 5760/60000][Iteration 3797][Wall Clock 375.71514794s] Trained 128 records in 0.096295487 seconds. Throughput is 1329.242 records/second. Loss is 0.24936758. Sequential31006cbd's hyper parameters: Current learning rate is 0.005684402000909505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 5888/60000][Iteration 3798][Wall Clock 375.803402154s] Trained 128 records in 0.088254214 seconds. Throughput is 1450.3557 records/second. Loss is 0.26074204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056837558258497215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6016/60000][Iteration 3799][Wall Clock 375.888203876s] Trained 128 records in 0.084801722 seconds. Throughput is 1509.4033 records/second. Loss is 0.2619924. Sequential31006cbd's hyper parameters: Current learning rate is 0.005683109797681291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6144/60000][Iteration 3800][Wall Clock 375.986617611s] Trained 128 records in 0.098413735 seconds. Throughput is 1300.6315 records/second. Loss is 0.23093775. Sequential31006cbd's hyper parameters: Current learning rate is 0.005682463916354131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6272/60000][Iteration 3801][Wall Clock 376.069177084s] Trained 128 records in 0.082559473 seconds. Throughput is 1550.3975 records/second. Loss is 0.2818019. Sequential31006cbd's hyper parameters: Current learning rate is 0.005681818181818182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6400/60000][Iteration 3802][Wall Clock 376.146914836s] Trained 128 records in 0.077737752 seconds. Throughput is 1646.5616 records/second. Loss is 0.18879394. Sequential31006cbd's hyper parameters: Current learning rate is 0.005681172594023407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6528/60000][Iteration 3803][Wall Clock 376.237314672s] Trained 128 records in 0.090399836 seconds. Throughput is 1415.9318 records/second. Loss is 0.28131387. Sequential31006cbd's hyper parameters: Current learning rate is 0.005680527152919791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6656/60000][Iteration 3804][Wall Clock 376.317128191s] Trained 128 records in 0.079813519 seconds. Throughput is 1603.7384 records/second. Loss is 0.428055. Sequential31006cbd's hyper parameters: Current learning rate is 0.005679881858457344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6784/60000][Iteration 3805][Wall Clock 376.396041545s] Trained 128 records in 0.078913354 seconds. Throughput is 1622.0322 records/second. Loss is 0.20018229. Sequential31006cbd's hyper parameters: Current learning rate is 0.005679236710586097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:53 INFO  DistriOptimizer$:408 - [Epoch 9 6912/60000][Iteration 3806][Wall Clock 376.472387842s] Trained 128 records in 0.076346297 seconds. Throughput is 1676.571 records/second. Loss is 0.17668499. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056785917092561046. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7040/60000][Iteration 3807][Wall Clock 376.548166163s] Trained 128 records in 0.075778321 seconds. Throughput is 1689.1375 records/second. Loss is 0.20376362. Sequential31006cbd's hyper parameters: Current learning rate is 0.005677946854417443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7168/60000][Iteration 3808][Wall Clock 376.627524848s] Trained 128 records in 0.079358685 seconds. Throughput is 1612.93 records/second. Loss is 0.2080837. Sequential31006cbd's hyper parameters: Current learning rate is 0.005677302146020211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7296/60000][Iteration 3809][Wall Clock 376.713254493s] Trained 128 records in 0.085729645 seconds. Throughput is 1493.0658 records/second. Loss is 0.21515468. Sequential31006cbd's hyper parameters: Current learning rate is 0.005676657584014532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7424/60000][Iteration 3810][Wall Clock 376.799028836s] Trained 128 records in 0.085774343 seconds. Throughput is 1492.2878 records/second. Loss is 0.13102125. Sequential31006cbd's hyper parameters: Current learning rate is 0.00567601316835055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7552/60000][Iteration 3811][Wall Clock 376.912285723s] Trained 128 records in 0.113256887 seconds. Throughput is 1130.1741 records/second. Loss is 0.18937367. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056753688989784334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7680/60000][Iteration 3812][Wall Clock 377.025401646s] Trained 128 records in 0.113115923 seconds. Throughput is 1131.5825 records/second. Loss is 0.31177792. Sequential31006cbd's hyper parameters: Current learning rate is 0.005674724775848372. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7808/60000][Iteration 3813][Wall Clock 377.136325967s] Trained 128 records in 0.110924321 seconds. Throughput is 1153.94 records/second. Loss is 0.20405735. Sequential31006cbd's hyper parameters: Current learning rate is 0.005674080798910576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 7936/60000][Iteration 3814][Wall Clock 377.234165871s] Trained 128 records in 0.097839904 seconds. Throughput is 1308.2596 records/second. Loss is 0.29779387. Sequential31006cbd's hyper parameters: Current learning rate is 0.005673436968115285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 8064/60000][Iteration 3815][Wall Clock 377.341429136s] Trained 128 records in 0.107263265 seconds. Throughput is 1193.3256 records/second. Loss is 0.2100116. Sequential31006cbd's hyper parameters: Current learning rate is 0.005672793283412753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:54 INFO  DistriOptimizer$:408 - [Epoch 9 8192/60000][Iteration 3816][Wall Clock 377.44188404s] Trained 128 records in 0.100454904 seconds. Throughput is 1274.2036 records/second. Loss is 0.19306491. Sequential31006cbd's hyper parameters: Current learning rate is 0.005672149744753262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 8320/60000][Iteration 3817][Wall Clock 377.523180646s] Trained 128 records in 0.081296606 seconds. Throughput is 1574.4814 records/second. Loss is 0.17761308. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056715063520871144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 8448/60000][Iteration 3818][Wall Clock 377.615885945s] Trained 128 records in 0.092705299 seconds. Throughput is 1380.7194 records/second. Loss is 0.18026961. Sequential31006cbd's hyper parameters: Current learning rate is 0.005670863105364636. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 8576/60000][Iteration 3819][Wall Clock 377.696732538s] Trained 128 records in 0.080846593 seconds. Throughput is 1583.2455 records/second. Loss is 0.16199079. Sequential31006cbd's hyper parameters: Current learning rate is 0.005670220004536176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 8704/60000][Iteration 3820][Wall Clock 377.776333795s] Trained 128 records in 0.079601257 seconds. Throughput is 1608.0148 records/second. Loss is 0.20893303. Sequential31006cbd's hyper parameters: Current learning rate is 0.005669577049552103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 8832/60000][Iteration 3821][Wall Clock 377.855884362s] Trained 128 records in 0.079550567 seconds. Throughput is 1609.0396 records/second. Loss is 0.3026253. Sequential31006cbd's hyper parameters: Current learning rate is 0.005668934240362812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 8960/60000][Iteration 3822][Wall Clock 377.938815101s] Trained 128 records in 0.082930739 seconds. Throughput is 1543.4567 records/second. Loss is 0.21290144. Sequential31006cbd's hyper parameters: Current learning rate is 0.005668291576918717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 9088/60000][Iteration 3823][Wall Clock 378.01763896s] Trained 128 records in 0.078823859 seconds. Throughput is 1623.8739 records/second. Loss is 0.2776211. Sequential31006cbd's hyper parameters: Current learning rate is 0.005667649059170256. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 9216/60000][Iteration 3824][Wall Clock 378.1086313s] Trained 128 records in 0.09099234 seconds. Throughput is 1406.7118 records/second. Loss is 0.30197644. Sequential31006cbd's hyper parameters: Current learning rate is 0.00566700668706789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 9344/60000][Iteration 3825][Wall Clock 378.187353006s] Trained 128 records in 0.078721706 seconds. Throughput is 1625.981 records/second. Loss is 0.22761756. Sequential31006cbd's hyper parameters: Current learning rate is 0.005666364460562103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 9472/60000][Iteration 3826][Wall Clock 378.278918166s] Trained 128 records in 0.09156516 seconds. Throughput is 1397.9116 records/second. Loss is 0.18884772. Sequential31006cbd's hyper parameters: Current learning rate is 0.005665722379603399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 9600/60000][Iteration 3827][Wall Clock 378.359825112s] Trained 128 records in 0.080906946 seconds. Throughput is 1582.0645 records/second. Loss is 0.33047935. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056650804441423066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:55 INFO  DistriOptimizer$:408 - [Epoch 9 9728/60000][Iteration 3828][Wall Clock 378.432932151s] Trained 128 records in 0.073107039 seconds. Throughput is 1750.8573 records/second. Loss is 0.262805. Sequential31006cbd's hyper parameters: Current learning rate is 0.005664438654129376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 9856/60000][Iteration 3829][Wall Clock 378.509351304s] Trained 128 records in 0.076419153 seconds. Throughput is 1674.9728 records/second. Loss is 0.17897035. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056637970095151785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 9984/60000][Iteration 3830][Wall Clock 378.598440379s] Trained 128 records in 0.089089075 seconds. Throughput is 1436.7643 records/second. Loss is 0.2525976. Sequential31006cbd's hyper parameters: Current learning rate is 0.005663155510250311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10112/60000][Iteration 3831][Wall Clock 378.682146735s] Trained 128 records in 0.083706356 seconds. Throughput is 1529.155 records/second. Loss is 0.2000185. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056625141562853904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10240/60000][Iteration 3832][Wall Clock 378.776294238s] Trained 128 records in 0.094147503 seconds. Throughput is 1359.5687 records/second. Loss is 0.18279216. Sequential31006cbd's hyper parameters: Current learning rate is 0.005661872947571056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10368/60000][Iteration 3833][Wall Clock 378.873797165s] Trained 128 records in 0.097502927 seconds. Throughput is 1312.7811 records/second. Loss is 0.20865053. Sequential31006cbd's hyper parameters: Current learning rate is 0.005661231884057971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10496/60000][Iteration 3834][Wall Clock 378.95721257s] Trained 128 records in 0.083415405 seconds. Throughput is 1534.4888 records/second. Loss is 0.26155093. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056605909656968195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10624/60000][Iteration 3835][Wall Clock 379.040208616s] Trained 128 records in 0.082996046 seconds. Throughput is 1542.2421 records/second. Loss is 0.2689827. Sequential31006cbd's hyper parameters: Current learning rate is 0.005659950192438307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10752/60000][Iteration 3836][Wall Clock 379.143218093s] Trained 128 records in 0.103009477 seconds. Throughput is 1242.6041 records/second. Loss is 0.24716221. Sequential31006cbd's hyper parameters: Current learning rate is 0.005659309564233164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 10880/60000][Iteration 3837][Wall Clock 379.224949821s] Trained 128 records in 0.081731728 seconds. Throughput is 1566.0992 records/second. Loss is 0.20763835. Sequential31006cbd's hyper parameters: Current learning rate is 0.005658669081032142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 11008/60000][Iteration 3838][Wall Clock 379.316768727s] Trained 128 records in 0.091818906 seconds. Throughput is 1394.0485 records/second. Loss is 0.24487616. Sequential31006cbd's hyper parameters: Current learning rate is 0.005658028742786013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 11136/60000][Iteration 3839][Wall Clock 379.401740816s] Trained 128 records in 0.084972089 seconds. Throughput is 1506.377 records/second. Loss is 0.18989506. Sequential31006cbd's hyper parameters: Current learning rate is 0.005657388549445576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:56 INFO  DistriOptimizer$:408 - [Epoch 9 11264/60000][Iteration 3840][Wall Clock 379.479285324s] Trained 128 records in 0.077544508 seconds. Throughput is 1650.6649 records/second. Loss is 0.18696158. Sequential31006cbd's hyper parameters: Current learning rate is 0.005656748500961648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 11392/60000][Iteration 3841][Wall Clock 379.56198724s] Trained 128 records in 0.082701916 seconds. Throughput is 1547.7272 records/second. Loss is 0.23307095. Sequential31006cbd's hyper parameters: Current learning rate is 0.005656108597285068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 11520/60000][Iteration 3842][Wall Clock 379.643734193s] Trained 128 records in 0.081746953 seconds. Throughput is 1565.8076 records/second. Loss is 0.25524157. Sequential31006cbd's hyper parameters: Current learning rate is 0.005655468838366701. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 11648/60000][Iteration 3843][Wall Clock 379.722928794s] Trained 128 records in 0.079194601 seconds. Throughput is 1616.2719 records/second. Loss is 0.32317153. Sequential31006cbd's hyper parameters: Current learning rate is 0.00565482922415743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 11776/60000][Iteration 3844][Wall Clock 379.802057708s] Trained 128 records in 0.079128914 seconds. Throughput is 1617.6135 records/second. Loss is 0.22595672. Sequential31006cbd's hyper parameters: Current learning rate is 0.005654189754608165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 11904/60000][Iteration 3845][Wall Clock 379.900576985s] Trained 128 records in 0.098519277 seconds. Throughput is 1299.238 records/second. Loss is 0.18035987. Sequential31006cbd's hyper parameters: Current learning rate is 0.005653550429669832. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12032/60000][Iteration 3846][Wall Clock 379.983711589s] Trained 128 records in 0.083134604 seconds. Throughput is 1539.6716 records/second. Loss is 0.24663651. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056529112492933855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12160/60000][Iteration 3847][Wall Clock 380.062148959s] Trained 128 records in 0.07843737 seconds. Throughput is 1631.8751 records/second. Loss is 0.2030536. Sequential31006cbd's hyper parameters: Current learning rate is 0.005652272213429799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12288/60000][Iteration 3848][Wall Clock 380.141184566s] Trained 128 records in 0.079035607 seconds. Throughput is 1619.5232 records/second. Loss is 0.25930142. Sequential31006cbd's hyper parameters: Current learning rate is 0.005651633322030066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12416/60000][Iteration 3849][Wall Clock 380.219351277s] Trained 128 records in 0.078166711 seconds. Throughput is 1637.5258 records/second. Loss is 0.19560975. Sequential31006cbd's hyper parameters: Current learning rate is 0.005650994575045208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12544/60000][Iteration 3850][Wall Clock 380.301177247s] Trained 128 records in 0.08182597 seconds. Throughput is 1564.2955 records/second. Loss is 0.37579745. Sequential31006cbd's hyper parameters: Current learning rate is 0.005650355972426263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12672/60000][Iteration 3851][Wall Clock 380.381252373s] Trained 128 records in 0.080075126 seconds. Throughput is 1598.4989 records/second. Loss is 0.25797653. Sequential31006cbd's hyper parameters: Current learning rate is 0.005649717514124294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:57 INFO  DistriOptimizer$:408 - [Epoch 9 12800/60000][Iteration 3852][Wall Clock 380.477393098s] Trained 128 records in 0.096140725 seconds. Throughput is 1331.3816 records/second. Loss is 0.24367829. Sequential31006cbd's hyper parameters: Current learning rate is 0.005649079200090386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 12928/60000][Iteration 3853][Wall Clock 380.567727564s] Trained 128 records in 0.090334466 seconds. Throughput is 1416.9564 records/second. Loss is 0.18910491. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056484410302756445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13056/60000][Iteration 3854][Wall Clock 380.651625551s] Trained 128 records in 0.083897987 seconds. Throughput is 1525.6624 records/second. Loss is 0.20413838. Sequential31006cbd's hyper parameters: Current learning rate is 0.005647803004631199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13184/60000][Iteration 3855][Wall Clock 380.731301239s] Trained 128 records in 0.079675688 seconds. Throughput is 1606.5126 records/second. Loss is 0.15565182. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056471651231082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13312/60000][Iteration 3856][Wall Clock 380.819875228s] Trained 128 records in 0.088573989 seconds. Throughput is 1445.1195 records/second. Loss is 0.17458862. Sequential31006cbd's hyper parameters: Current learning rate is 0.005646527385657821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13440/60000][Iteration 3857][Wall Clock 380.902393604s] Trained 128 records in 0.082518376 seconds. Throughput is 1551.1697 records/second. Loss is 0.24014904. Sequential31006cbd's hyper parameters: Current learning rate is 0.005645889792231256. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13568/60000][Iteration 3858][Wall Clock 380.976939076s] Trained 128 records in 0.074545472 seconds. Throughput is 1717.0728 records/second. Loss is 0.23840961. Sequential31006cbd's hyper parameters: Current learning rate is 0.005645252342779722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13696/60000][Iteration 3859][Wall Clock 381.058547866s] Trained 128 records in 0.08160879 seconds. Throughput is 1568.4585 records/second. Loss is 0.22707924. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056446150372544595. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13824/60000][Iteration 3860][Wall Clock 381.143859599s] Trained 128 records in 0.085311733 seconds. Throughput is 1500.3798 records/second. Loss is 0.3135093. Sequential31006cbd's hyper parameters: Current learning rate is 0.005643977875606727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 13952/60000][Iteration 3861][Wall Clock 381.239418038s] Trained 128 records in 0.095558439 seconds. Throughput is 1339.4944 records/second. Loss is 0.21808217. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056433408577878106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 14080/60000][Iteration 3862][Wall Clock 381.31597769s] Trained 128 records in 0.076559652 seconds. Throughput is 1671.8988 records/second. Loss is 0.2274602. Sequential31006cbd's hyper parameters: Current learning rate is 0.005642703983749013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 14208/60000][Iteration 3863][Wall Clock 381.393281131s] Trained 128 records in 0.077303441 seconds. Throughput is 1655.8125 records/second. Loss is 0.20597419. Sequential31006cbd's hyper parameters: Current learning rate is 0.005642067253441661. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:58 INFO  DistriOptimizer$:408 - [Epoch 9 14336/60000][Iteration 3864][Wall Clock 381.476901341s] Trained 128 records in 0.08362021 seconds. Throughput is 1530.7303 records/second. Loss is 0.20084652. Sequential31006cbd's hyper parameters: Current learning rate is 0.005641430666817104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 14464/60000][Iteration 3865][Wall Clock 381.552761178s] Trained 128 records in 0.075859837 seconds. Throughput is 1687.3224 records/second. Loss is 0.31171572. Sequential31006cbd's hyper parameters: Current learning rate is 0.005640794223826714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 14592/60000][Iteration 3866][Wall Clock 381.629236175s] Trained 128 records in 0.076474997 seconds. Throughput is 1673.7498 records/second. Loss is 0.30520988. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056401579244218835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 14720/60000][Iteration 3867][Wall Clock 381.712193695s] Trained 128 records in 0.08295752 seconds. Throughput is 1542.9584 records/second. Loss is 0.29221442. Sequential31006cbd's hyper parameters: Current learning rate is 0.005639521768554027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 14848/60000][Iteration 3868][Wall Clock 381.806004114s] Trained 128 records in 0.093810419 seconds. Throughput is 1364.454 records/second. Loss is 0.21426982. Sequential31006cbd's hyper parameters: Current learning rate is 0.00563888575617458. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 14976/60000][Iteration 3869][Wall Clock 381.894693964s] Trained 128 records in 0.08868985 seconds. Throughput is 1443.2317 records/second. Loss is 0.15980348. Sequential31006cbd's hyper parameters: Current learning rate is 0.005638249887235002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15104/60000][Iteration 3870][Wall Clock 381.977712958s] Trained 128 records in 0.083018994 seconds. Throughput is 1541.8158 records/second. Loss is 0.17808221. Sequential31006cbd's hyper parameters: Current learning rate is 0.005637614161686774. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15232/60000][Iteration 3871][Wall Clock 382.054984987s] Trained 128 records in 0.077272029 seconds. Throughput is 1656.4856 records/second. Loss is 0.26304507. Sequential31006cbd's hyper parameters: Current learning rate is 0.005636978579481398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15360/60000][Iteration 3872][Wall Clock 382.137289945s] Trained 128 records in 0.082304958 seconds. Throughput is 1555.1919 records/second. Loss is 0.21858683. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056363431405703985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15488/60000][Iteration 3873][Wall Clock 382.222756863s] Trained 128 records in 0.085466918 seconds. Throughput is 1497.6554 records/second. Loss is 0.24102119. Sequential31006cbd's hyper parameters: Current learning rate is 0.00563570784490532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15616/60000][Iteration 3874][Wall Clock 382.306959732s] Trained 128 records in 0.084202869 seconds. Throughput is 1520.1382 records/second. Loss is 0.19284038. Sequential31006cbd's hyper parameters: Current learning rate is 0.005635072692437733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15744/60000][Iteration 3875][Wall Clock 382.395810227s] Trained 128 records in 0.088850495 seconds. Throughput is 1440.6222 records/second. Loss is 0.14036432. Sequential31006cbd's hyper parameters: Current learning rate is 0.005634437683119225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:03:59 INFO  DistriOptimizer$:408 - [Epoch 9 15872/60000][Iteration 3876][Wall Clock 382.479062919s] Trained 128 records in 0.083252692 seconds. Throughput is 1537.4878 records/second. Loss is 0.1767539. Sequential31006cbd's hyper parameters: Current learning rate is 0.005633802816901409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16000/60000][Iteration 3877][Wall Clock 382.563027956s] Trained 128 records in 0.083965037 seconds. Throughput is 1524.4441 records/second. Loss is 0.26019412. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056331680937359175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16128/60000][Iteration 3878][Wall Clock 382.661204371s] Trained 128 records in 0.098176415 seconds. Throughput is 1303.7755 records/second. Loss is 0.21082889. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056325335135744056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16256/60000][Iteration 3879][Wall Clock 382.741783725s] Trained 128 records in 0.080579354 seconds. Throughput is 1588.4962 records/second. Loss is 0.20407473. Sequential31006cbd's hyper parameters: Current learning rate is 0.005631899076368551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16384/60000][Iteration 3880][Wall Clock 382.816216007s] Trained 128 records in 0.074432282 seconds. Throughput is 1719.684 records/second. Loss is 0.2985797. Sequential31006cbd's hyper parameters: Current learning rate is 0.005631264782070053. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16512/60000][Iteration 3881][Wall Clock 382.908859392s] Trained 128 records in 0.092643385 seconds. Throughput is 1381.6421 records/second. Loss is 0.24208377. Sequential31006cbd's hyper parameters: Current learning rate is 0.00563063063063063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16640/60000][Iteration 3882][Wall Clock 382.993174412s] Trained 128 records in 0.08431502 seconds. Throughput is 1518.1163 records/second. Loss is 0.24017465. Sequential31006cbd's hyper parameters: Current learning rate is 0.005629996622002027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16768/60000][Iteration 3883][Wall Clock 383.068292646s] Trained 128 records in 0.075118234 seconds. Throughput is 1703.9803 records/second. Loss is 0.23611869. Sequential31006cbd's hyper parameters: Current learning rate is 0.005629362756136005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 16896/60000][Iteration 3884][Wall Clock 383.143072127s] Trained 128 records in 0.074779481 seconds. Throughput is 1711.6995 records/second. Loss is 0.35313374. Sequential31006cbd's hyper parameters: Current learning rate is 0.005628729032984352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 17024/60000][Iteration 3885][Wall Clock 383.238975956s] Trained 128 records in 0.095903829 seconds. Throughput is 1334.6704 records/second. Loss is 0.32412785. Sequential31006cbd's hyper parameters: Current learning rate is 0.005628095452498874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 17152/60000][Iteration 3886][Wall Clock 383.325898539s] Trained 128 records in 0.086922583 seconds. Throughput is 1472.5747 records/second. Loss is 0.16725232. Sequential31006cbd's hyper parameters: Current learning rate is 0.005627462014631401. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:00 INFO  DistriOptimizer$:408 - [Epoch 9 17280/60000][Iteration 3887][Wall Clock 383.402594431s] Trained 128 records in 0.076695892 seconds. Throughput is 1668.9291 records/second. Loss is 0.23024769. Sequential31006cbd's hyper parameters: Current learning rate is 0.005626828719333783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 17408/60000][Iteration 3888][Wall Clock 383.490360931s] Trained 128 records in 0.0877665 seconds. Throughput is 1458.4153 records/second. Loss is 0.31135958. Sequential31006cbd's hyper parameters: Current learning rate is 0.005626195566557893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 17536/60000][Iteration 3889][Wall Clock 383.575554682s] Trained 128 records in 0.085193751 seconds. Throughput is 1502.4575 records/second. Loss is 0.23561542. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056255625562556255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 17664/60000][Iteration 3890][Wall Clock 383.666001253s] Trained 128 records in 0.090446571 seconds. Throughput is 1415.2002 records/second. Loss is 0.20771363. Sequential31006cbd's hyper parameters: Current learning rate is 0.005624929688378895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 17792/60000][Iteration 3891][Wall Clock 383.749110448s] Trained 128 records in 0.083109195 seconds. Throughput is 1540.1425 records/second. Loss is 0.18502708. Sequential31006cbd's hyper parameters: Current learning rate is 0.00562429696287964. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 17920/60000][Iteration 3892][Wall Clock 383.83321473s] Trained 128 records in 0.084104282 seconds. Throughput is 1521.92 records/second. Loss is 0.2718143. Sequential31006cbd's hyper parameters: Current learning rate is 0.005623664379709819. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18048/60000][Iteration 3893][Wall Clock 383.912928016s] Trained 128 records in 0.079713286 seconds. Throughput is 1605.7549 records/second. Loss is 0.19221188. Sequential31006cbd's hyper parameters: Current learning rate is 0.005623031938821413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18176/60000][Iteration 3894][Wall Clock 383.99161294s] Trained 128 records in 0.078684924 seconds. Throughput is 1626.7411 records/second. Loss is 0.23574963. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056223996401664235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18304/60000][Iteration 3895][Wall Clock 384.078414868s] Trained 128 records in 0.086801928 seconds. Throughput is 1474.6216 records/second. Loss is 0.24714695. Sequential31006cbd's hyper parameters: Current learning rate is 0.005621767483696875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18432/60000][Iteration 3896][Wall Clock 384.164248356s] Trained 128 records in 0.085833488 seconds. Throughput is 1491.2594 records/second. Loss is 0.25400746. Sequential31006cbd's hyper parameters: Current learning rate is 0.005621135469364812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18560/60000][Iteration 3897][Wall Clock 384.256354314s] Trained 128 records in 0.092105958 seconds. Throughput is 1389.7039 records/second. Loss is 0.31513536. Sequential31006cbd's hyper parameters: Current learning rate is 0.005620503597122303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18688/60000][Iteration 3898][Wall Clock 384.344912743s] Trained 128 records in 0.088558429 seconds. Throughput is 1445.3734 records/second. Loss is 0.15528192. Sequential31006cbd's hyper parameters: Current learning rate is 0.005619871866921434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:01 INFO  DistriOptimizer$:408 - [Epoch 9 18816/60000][Iteration 3899][Wall Clock 384.431550928s] Trained 128 records in 0.086638185 seconds. Throughput is 1477.4087 records/second. Loss is 0.13489401. Sequential31006cbd's hyper parameters: Current learning rate is 0.005619240278714317. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 18944/60000][Iteration 3900][Wall Clock 384.514521588s] Trained 128 records in 0.08297066 seconds. Throughput is 1542.7141 records/second. Loss is 0.20309925. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056186088324530845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19072/60000][Iteration 3901][Wall Clock 384.593183062s] Trained 128 records in 0.078661474 seconds. Throughput is 1627.2261 records/second. Loss is 0.2677143. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056179775280898875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19200/60000][Iteration 3902][Wall Clock 384.673762532s] Trained 128 records in 0.08057947 seconds. Throughput is 1588.494 records/second. Loss is 0.24498746. Sequential31006cbd's hyper parameters: Current learning rate is 0.005617346365576902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19328/60000][Iteration 3903][Wall Clock 384.758175079s] Trained 128 records in 0.084412547 seconds. Throughput is 1516.3623 records/second. Loss is 0.16912606. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056167153448663226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19456/60000][Iteration 3904][Wall Clock 384.85561863s] Trained 128 records in 0.097443551 seconds. Throughput is 1313.581 records/second. Loss is 0.19500077. Sequential31006cbd's hyper parameters: Current learning rate is 0.005616084465910367. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19584/60000][Iteration 3905][Wall Clock 384.935057865s] Trained 128 records in 0.079439235 seconds. Throughput is 1611.2944 records/second. Loss is 0.21629962. Sequential31006cbd's hyper parameters: Current learning rate is 0.005615453728661276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19712/60000][Iteration 3906][Wall Clock 385.015757661s] Trained 128 records in 0.080699796 seconds. Throughput is 1586.1255 records/second. Loss is 0.3457606. Sequential31006cbd's hyper parameters: Current learning rate is 0.005614823133071308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19840/60000][Iteration 3907][Wall Clock 385.09300503s] Trained 128 records in 0.077247369 seconds. Throughput is 1657.0144 records/second. Loss is 0.2027531. Sequential31006cbd's hyper parameters: Current learning rate is 0.005614192679092746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 19968/60000][Iteration 3908][Wall Clock 385.173819586s] Trained 128 records in 0.080814556 seconds. Throughput is 1583.873 records/second. Loss is 0.19418445. Sequential31006cbd's hyper parameters: Current learning rate is 0.005613562366677894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 20096/60000][Iteration 3909][Wall Clock 385.25187461s] Trained 128 records in 0.078055024 seconds. Throughput is 1639.8688 records/second. Loss is 0.23925304. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056129321957790745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 20224/60000][Iteration 3910][Wall Clock 385.33497207s] Trained 128 records in 0.08309746 seconds. Throughput is 1540.36 records/second. Loss is 0.2689421. Sequential31006cbd's hyper parameters: Current learning rate is 0.005612302166348636. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:02 INFO  DistriOptimizer$:408 - [Epoch 9 20352/60000][Iteration 3911][Wall Clock 385.424815059s] Trained 128 records in 0.089842989 seconds. Throughput is 1424.7078 records/second. Loss is 0.23916402. Sequential31006cbd's hyper parameters: Current learning rate is 0.005611672278338945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 20480/60000][Iteration 3912][Wall Clock 385.532524493s] Trained 128 records in 0.107709434 seconds. Throughput is 1188.3824 records/second. Loss is 0.30015576. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056110425317023906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 20608/60000][Iteration 3913][Wall Clock 385.626625907s] Trained 128 records in 0.094101414 seconds. Throughput is 1360.2346 records/second. Loss is 0.23430671. Sequential31006cbd's hyper parameters: Current learning rate is 0.005610412926391382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 20736/60000][Iteration 3914][Wall Clock 385.71170415s] Trained 128 records in 0.085078243 seconds. Throughput is 1504.4976 records/second. Loss is 0.24816237. Sequential31006cbd's hyper parameters: Current learning rate is 0.005609783462358353. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 20864/60000][Iteration 3915][Wall Clock 385.79534645s] Trained 128 records in 0.0836423 seconds. Throughput is 1530.3262 records/second. Loss is 0.23280936. Sequential31006cbd's hyper parameters: Current learning rate is 0.005609154139555756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 20992/60000][Iteration 3916][Wall Clock 385.876683718s] Trained 128 records in 0.081337268 seconds. Throughput is 1573.6945 records/second. Loss is 0.14050527. Sequential31006cbd's hyper parameters: Current learning rate is 0.005608524957936063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 21120/60000][Iteration 3917][Wall Clock 385.956366871s] Trained 128 records in 0.079683153 seconds. Throughput is 1606.362 records/second. Loss is 0.18726856. Sequential31006cbd's hyper parameters: Current learning rate is 0.005607895917451772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 21248/60000][Iteration 3918][Wall Clock 386.044177639s] Trained 128 records in 0.087810768 seconds. Throughput is 1457.6799 records/second. Loss is 0.1695982. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056072670180554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 21376/60000][Iteration 3919][Wall Clock 386.126521925s] Trained 128 records in 0.082344286 seconds. Throughput is 1554.4491 records/second. Loss is 0.19484651. Sequential31006cbd's hyper parameters: Current learning rate is 0.005606638259699484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 21504/60000][Iteration 3920][Wall Clock 386.217029379s] Trained 128 records in 0.090507454 seconds. Throughput is 1414.2482 records/second. Loss is 0.16994184. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056060096423365844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 21632/60000][Iteration 3921][Wall Clock 386.30612447s] Trained 128 records in 0.089095091 seconds. Throughput is 1436.6672 records/second. Loss is 0.29256094. Sequential31006cbd's hyper parameters: Current learning rate is 0.005605381165919282. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:03 INFO  DistriOptimizer$:408 - [Epoch 9 21760/60000][Iteration 3922][Wall Clock 386.396928611s] Trained 128 records in 0.090804141 seconds. Throughput is 1409.6274 records/second. Loss is 0.16860624. Sequential31006cbd's hyper parameters: Current learning rate is 0.005604752830400179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 21888/60000][Iteration 3923][Wall Clock 386.479229294s] Trained 128 records in 0.082300683 seconds. Throughput is 1555.2726 records/second. Loss is 0.13908948. Sequential31006cbd's hyper parameters: Current learning rate is 0.005604124635731899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22016/60000][Iteration 3924][Wall Clock 386.558284954s] Trained 128 records in 0.07905566 seconds. Throughput is 1619.1124 records/second. Loss is 0.18200393. Sequential31006cbd's hyper parameters: Current learning rate is 0.005603496581867084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22144/60000][Iteration 3925][Wall Clock 386.638165709s] Trained 128 records in 0.079880755 seconds. Throughput is 1602.3885 records/second. Loss is 0.25358915. Sequential31006cbd's hyper parameters: Current learning rate is 0.005602868668758404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22272/60000][Iteration 3926][Wall Clock 386.718999528s] Trained 128 records in 0.080833819 seconds. Throughput is 1583.4956 records/second. Loss is 0.30046934. Sequential31006cbd's hyper parameters: Current learning rate is 0.0056022408963585435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22400/60000][Iteration 3927][Wall Clock 386.79591595s] Trained 128 records in 0.076916422 seconds. Throughput is 1664.144 records/second. Loss is 0.24792509. Sequential31006cbd's hyper parameters: Current learning rate is 0.00560161326462021. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22528/60000][Iteration 3928][Wall Clock 386.882322124s] Trained 128 records in 0.086406174 seconds. Throughput is 1481.3756 records/second. Loss is 0.22214228. Sequential31006cbd's hyper parameters: Current learning rate is 0.005600985773496135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22656/60000][Iteration 3929][Wall Clock 386.984660894s] Trained 128 records in 0.10233877 seconds. Throughput is 1250.7479 records/second. Loss is 0.2204119. Sequential31006cbd's hyper parameters: Current learning rate is 0.005600358422939068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22784/60000][Iteration 3930][Wall Clock 387.063186475s] Trained 128 records in 0.078525581 seconds. Throughput is 1630.0421 records/second. Loss is 0.2108717. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055997312129017806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 22912/60000][Iteration 3931][Wall Clock 387.148114782s] Trained 128 records in 0.084928307 seconds. Throughput is 1507.1536 records/second. Loss is 0.12989117. Sequential31006cbd's hyper parameters: Current learning rate is 0.005599104143337066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 23040/60000][Iteration 3932][Wall Clock 387.22151673s] Trained 128 records in 0.073401948 seconds. Throughput is 1743.8229 records/second. Loss is 0.28870884. Sequential31006cbd's hyper parameters: Current learning rate is 0.005598477214197739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 23168/60000][Iteration 3933][Wall Clock 387.314408879s] Trained 128 records in 0.092892149 seconds. Throughput is 1377.9421 records/second. Loss is 0.1850007. Sequential31006cbd's hyper parameters: Current learning rate is 0.005597850425436633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:04 INFO  DistriOptimizer$:408 - [Epoch 9 23296/60000][Iteration 3934][Wall Clock 387.407304732s] Trained 128 records in 0.092895853 seconds. Throughput is 1377.8872 records/second. Loss is 0.13248716. Sequential31006cbd's hyper parameters: Current learning rate is 0.005597223777006605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 23424/60000][Iteration 3935][Wall Clock 387.484781071s] Trained 128 records in 0.077476339 seconds. Throughput is 1652.1173 records/second. Loss is 0.4179715. Sequential31006cbd's hyper parameters: Current learning rate is 0.005596597268860533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 23552/60000][Iteration 3936][Wall Clock 387.571324999s] Trained 128 records in 0.086543928 seconds. Throughput is 1479.0177 records/second. Loss is 0.11851676. Sequential31006cbd's hyper parameters: Current learning rate is 0.005595970900951316. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 23680/60000][Iteration 3937][Wall Clock 387.65767662s] Trained 128 records in 0.086351621 seconds. Throughput is 1482.3115 records/second. Loss is 0.25421524. Sequential31006cbd's hyper parameters: Current learning rate is 0.005595344673231872. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 23808/60000][Iteration 3938][Wall Clock 387.746949414s] Trained 128 records in 0.089272794 seconds. Throughput is 1433.8074 records/second. Loss is 0.21783504. Sequential31006cbd's hyper parameters: Current learning rate is 0.005594718585655142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 23936/60000][Iteration 3939][Wall Clock 387.83347635s] Trained 128 records in 0.086526936 seconds. Throughput is 1479.3081 records/second. Loss is 0.1982917. Sequential31006cbd's hyper parameters: Current learning rate is 0.005594092638174088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24064/60000][Iteration 3940][Wall Clock 387.912077045s] Trained 128 records in 0.078600695 seconds. Throughput is 1628.4843 records/second. Loss is 0.21519025. Sequential31006cbd's hyper parameters: Current learning rate is 0.005593466830741693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24192/60000][Iteration 3941][Wall Clock 387.992671951s] Trained 128 records in 0.080594906 seconds. Throughput is 1588.1897 records/second. Loss is 0.1768437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005592841163310962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24320/60000][Iteration 3942][Wall Clock 388.075317513s] Trained 128 records in 0.082645562 seconds. Throughput is 1548.7825 records/second. Loss is 0.2588241. Sequential31006cbd's hyper parameters: Current learning rate is 0.005592215635834918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24448/60000][Iteration 3943][Wall Clock 388.154816235s] Trained 128 records in 0.079498722 seconds. Throughput is 1610.0887 records/second. Loss is 0.25210592. Sequential31006cbd's hyper parameters: Current learning rate is 0.005591590248266607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24576/60000][Iteration 3944][Wall Clock 388.235091327s] Trained 128 records in 0.080275092 seconds. Throughput is 1594.5171 records/second. Loss is 0.21609879. Sequential31006cbd's hyper parameters: Current learning rate is 0.005590965000559096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24704/60000][Iteration 3945][Wall Clock 388.3196382s] Trained 128 records in 0.084546873 seconds. Throughput is 1513.9531 records/second. Loss is 0.32196715. Sequential31006cbd's hyper parameters: Current learning rate is 0.005590339892665473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:05 INFO  DistriOptimizer$:408 - [Epoch 9 24832/60000][Iteration 3946][Wall Clock 388.400223842s] Trained 128 records in 0.080585642 seconds. Throughput is 1588.3722 records/second. Loss is 0.21779862. Sequential31006cbd's hyper parameters: Current learning rate is 0.005589714924538848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 24960/60000][Iteration 3947][Wall Clock 388.484312256s] Trained 128 records in 0.084088414 seconds. Throughput is 1522.2073 records/second. Loss is 0.18193474. Sequential31006cbd's hyper parameters: Current learning rate is 0.005589090096132349. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25088/60000][Iteration 3948][Wall Clock 388.569350651s] Trained 128 records in 0.085038395 seconds. Throughput is 1505.2025 records/second. Loss is 0.20167664. Sequential31006cbd's hyper parameters: Current learning rate is 0.005588465407399128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25216/60000][Iteration 3949][Wall Clock 388.655177609s] Trained 128 records in 0.085826958 seconds. Throughput is 1491.3729 records/second. Loss is 0.35813984. Sequential31006cbd's hyper parameters: Current learning rate is 0.005587840858292356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25344/60000][Iteration 3950][Wall Clock 388.734671903s] Trained 128 records in 0.079494294 seconds. Throughput is 1610.1783 records/second. Loss is 0.17305958. Sequential31006cbd's hyper parameters: Current learning rate is 0.005587216448765225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25472/60000][Iteration 3951][Wall Clock 388.806254344s] Trained 128 records in 0.071582441 seconds. Throughput is 1788.148 records/second. Loss is 0.23347905. Sequential31006cbd's hyper parameters: Current learning rate is 0.00558659217877095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25600/60000][Iteration 3952][Wall Clock 388.881343813s] Trained 128 records in 0.075089469 seconds. Throughput is 1704.6332 records/second. Loss is 0.22733274. Sequential31006cbd's hyper parameters: Current learning rate is 0.005585968048262764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25728/60000][Iteration 3953][Wall Clock 388.96390705s] Trained 128 records in 0.082563237 seconds. Throughput is 1550.3268 records/second. Loss is 0.23574658. Sequential31006cbd's hyper parameters: Current learning rate is 0.005585344057193923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25856/60000][Iteration 3954][Wall Clock 389.042052678s] Trained 128 records in 0.078145628 seconds. Throughput is 1637.9674 records/second. Loss is 0.2127915. Sequential31006cbd's hyper parameters: Current learning rate is 0.005584720205517704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 25984/60000][Iteration 3955][Wall Clock 389.177761411s] Trained 128 records in 0.135708733 seconds. Throughput is 943.1965 records/second. Loss is 0.19565722. Sequential31006cbd's hyper parameters: Current learning rate is 0.005584096493187403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 26112/60000][Iteration 3956][Wall Clock 389.260798467s] Trained 128 records in 0.083037056 seconds. Throughput is 1541.4805 records/second. Loss is 0.16967976. Sequential31006cbd's hyper parameters: Current learning rate is 0.005583472920156337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 26240/60000][Iteration 3957][Wall Clock 389.338309643s] Trained 128 records in 0.077511176 seconds. Throughput is 1651.3748 records/second. Loss is 0.17181389. Sequential31006cbd's hyper parameters: Current learning rate is 0.005582849486377848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:06 INFO  DistriOptimizer$:408 - [Epoch 9 26368/60000][Iteration 3958][Wall Clock 389.428048815s] Trained 128 records in 0.089739172 seconds. Throughput is 1426.356 records/second. Loss is 0.2825699. Sequential31006cbd's hyper parameters: Current learning rate is 0.005582226191805292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 26496/60000][Iteration 3959][Wall Clock 389.511173593s] Trained 128 records in 0.083124778 seconds. Throughput is 1539.8538 records/second. Loss is 0.30628905. Sequential31006cbd's hyper parameters: Current learning rate is 0.005581603036392052. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 26624/60000][Iteration 3960][Wall Clock 389.601407969s] Trained 128 records in 0.090234376 seconds. Throughput is 1418.5281 records/second. Loss is 0.19687489. Sequential31006cbd's hyper parameters: Current learning rate is 0.005580980020091528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 26752/60000][Iteration 3961][Wall Clock 389.684956554s] Trained 128 records in 0.083548585 seconds. Throughput is 1532.0427 records/second. Loss is 0.23848712. Sequential31006cbd's hyper parameters: Current learning rate is 0.005580357142857143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 26880/60000][Iteration 3962][Wall Clock 389.762618922s] Trained 128 records in 0.077662368 seconds. Throughput is 1648.1598 records/second. Loss is 0.2049518. Sequential31006cbd's hyper parameters: Current learning rate is 0.005579734404642339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27008/60000][Iteration 3963][Wall Clock 389.839986609s] Trained 128 records in 0.077367687 seconds. Throughput is 1654.4375 records/second. Loss is 0.39420828. Sequential31006cbd's hyper parameters: Current learning rate is 0.005579111805400581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27136/60000][Iteration 3964][Wall Clock 389.916736104s] Trained 128 records in 0.076749495 seconds. Throughput is 1667.7634 records/second. Loss is 0.21598111. Sequential31006cbd's hyper parameters: Current learning rate is 0.005578489345085351. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27264/60000][Iteration 3965][Wall Clock 389.996700565s] Trained 128 records in 0.079964461 seconds. Throughput is 1600.7112 records/second. Loss is 0.24442871. Sequential31006cbd's hyper parameters: Current learning rate is 0.005577867023650156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27392/60000][Iteration 3966][Wall Clock 390.074148549s] Trained 128 records in 0.077447984 seconds. Throughput is 1652.7223 records/second. Loss is 0.21968204. Sequential31006cbd's hyper parameters: Current learning rate is 0.005577244841048522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27520/60000][Iteration 3967][Wall Clock 390.151547245s] Trained 128 records in 0.077398696 seconds. Throughput is 1653.7747 records/second. Loss is 0.2156165. Sequential31006cbd's hyper parameters: Current learning rate is 0.005576622797233995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27648/60000][Iteration 3968][Wall Clock 390.240772553s] Trained 128 records in 0.089225308 seconds. Throughput is 1434.5706 records/second. Loss is 0.18582256. Sequential31006cbd's hyper parameters: Current learning rate is 0.005576000892160143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27776/60000][Iteration 3969][Wall Clock 390.321563124s] Trained 128 records in 0.080790571 seconds. Throughput is 1584.3433 records/second. Loss is 0.27740094. Sequential31006cbd's hyper parameters: Current learning rate is 0.005575379125780553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:07 INFO  DistriOptimizer$:408 - [Epoch 9 27904/60000][Iteration 3970][Wall Clock 390.398907765s] Trained 128 records in 0.077344641 seconds. Throughput is 1654.9304 records/second. Loss is 0.26703802. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055747574980488344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28032/60000][Iteration 3971][Wall Clock 390.478387241s] Trained 128 records in 0.079479476 seconds. Throughput is 1610.4786 records/second. Loss is 0.16022581. Sequential31006cbd's hyper parameters: Current learning rate is 0.005574136008918618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28160/60000][Iteration 3972][Wall Clock 390.553767942s] Trained 128 records in 0.075380701 seconds. Throughput is 1698.0475 records/second. Loss is 0.19370006. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055735146583435514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28288/60000][Iteration 3973][Wall Clock 390.628592506s] Trained 128 records in 0.074824564 seconds. Throughput is 1710.6682 records/second. Loss is 0.15816645. Sequential31006cbd's hyper parameters: Current learning rate is 0.005572893446277307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28416/60000][Iteration 3974][Wall Clock 390.711885096s] Trained 128 records in 0.08329259 seconds. Throughput is 1536.7513 records/second. Loss is 0.3240002. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055722723726735765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28544/60000][Iteration 3975][Wall Clock 390.810858652s] Trained 128 records in 0.098973556 seconds. Throughput is 1293.2748 records/second. Loss is 0.24320841. Sequential31006cbd's hyper parameters: Current learning rate is 0.005571651437486071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28672/60000][Iteration 3976][Wall Clock 390.893734331s] Trained 128 records in 0.082875679 seconds. Throughput is 1544.482 records/second. Loss is 0.19761705. Sequential31006cbd's hyper parameters: Current learning rate is 0.005571030640668524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28800/60000][Iteration 3977][Wall Clock 390.996741077s] Trained 128 records in 0.103006746 seconds. Throughput is 1242.6371 records/second. Loss is 0.23798384. Sequential31006cbd's hyper parameters: Current learning rate is 0.005570409982174688. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 28928/60000][Iteration 3978][Wall Clock 391.083634883s] Trained 128 records in 0.086893806 seconds. Throughput is 1473.0625 records/second. Loss is 0.15336694. Sequential31006cbd's hyper parameters: Current learning rate is 0.005569789461958338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 29056/60000][Iteration 3979][Wall Clock 391.168514089s] Trained 128 records in 0.084879206 seconds. Throughput is 1508.0254 records/second. Loss is 0.2520664. Sequential31006cbd's hyper parameters: Current learning rate is 0.005569169079973268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 29184/60000][Iteration 3980][Wall Clock 391.25898089s] Trained 128 records in 0.090466801 seconds. Throughput is 1414.8838 records/second. Loss is 0.1899055. Sequential31006cbd's hyper parameters: Current learning rate is 0.005568548836173293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:08 INFO  DistriOptimizer$:408 - [Epoch 9 29312/60000][Iteration 3981][Wall Clock 391.369425961s] Trained 128 records in 0.110445071 seconds. Throughput is 1158.9471 records/second. Loss is 0.19842203. Sequential31006cbd's hyper parameters: Current learning rate is 0.005567928730512249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 29440/60000][Iteration 3982][Wall Clock 391.458833909s] Trained 128 records in 0.089407948 seconds. Throughput is 1431.64 records/second. Loss is 0.19425592. Sequential31006cbd's hyper parameters: Current learning rate is 0.005567308762943993. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 29568/60000][Iteration 3983][Wall Clock 391.546366354s] Trained 128 records in 0.087532445 seconds. Throughput is 1462.315 records/second. Loss is 0.15713903. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055666889334224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 29696/60000][Iteration 3984][Wall Clock 391.62545688s] Trained 128 records in 0.079090526 seconds. Throughput is 1618.3986 records/second. Loss is 0.33753124. Sequential31006cbd's hyper parameters: Current learning rate is 0.005566069241901369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 29824/60000][Iteration 3985][Wall Clock 391.713105806s] Trained 128 records in 0.087648926 seconds. Throughput is 1460.3716 records/second. Loss is 0.19441205. Sequential31006cbd's hyper parameters: Current learning rate is 0.005565449688334817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 29952/60000][Iteration 3986][Wall Clock 391.808014794s] Trained 128 records in 0.094908988 seconds. Throughput is 1348.6604 records/second. Loss is 0.2153587. Sequential31006cbd's hyper parameters: Current learning rate is 0.005564830272676683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30080/60000][Iteration 3987][Wall Clock 391.884838545s] Trained 128 records in 0.076823751 seconds. Throughput is 1666.1515 records/second. Loss is 0.20099677. Sequential31006cbd's hyper parameters: Current learning rate is 0.005564210994880926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30208/60000][Iteration 3988][Wall Clock 391.962604338s] Trained 128 records in 0.077765793 seconds. Throughput is 1645.9679 records/second. Loss is 0.3141563. Sequential31006cbd's hyper parameters: Current learning rate is 0.005563591854901524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30336/60000][Iteration 3989][Wall Clock 392.047892362s] Trained 128 records in 0.085288024 seconds. Throughput is 1500.7969 records/second. Loss is 0.2326725. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055629728526924785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30464/60000][Iteration 3990][Wall Clock 392.12426101s] Trained 128 records in 0.076368648 seconds. Throughput is 1676.0806 records/second. Loss is 0.1923781. Sequential31006cbd's hyper parameters: Current learning rate is 0.00556235398820781. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30592/60000][Iteration 3991][Wall Clock 392.198470663s] Trained 128 records in 0.074209653 seconds. Throughput is 1724.843 records/second. Loss is 0.19933066. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055617352614015575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30720/60000][Iteration 3992][Wall Clock 392.276436448s] Trained 128 records in 0.077965785 seconds. Throughput is 1641.7457 records/second. Loss is 0.22701971. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055611166722277835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30848/60000][Iteration 3993][Wall Clock 392.354424546s] Trained 128 records in 0.077988098 seconds. Throughput is 1641.2761 records/second. Loss is 0.17563693. Sequential31006cbd's hyper parameters: Current learning rate is 0.00556049822064057. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:09 INFO  DistriOptimizer$:408 - [Epoch 9 30976/60000][Iteration 3994][Wall Clock 392.430547743s] Trained 128 records in 0.076123197 seconds. Throughput is 1681.4847 records/second. Loss is 0.18778166. Sequential31006cbd's hyper parameters: Current learning rate is 0.005559879906594018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31104/60000][Iteration 3995][Wall Clock 392.507392381s] Trained 128 records in 0.076844638 seconds. Throughput is 1665.6985 records/second. Loss is 0.23364845. Sequential31006cbd's hyper parameters: Current learning rate is 0.005559261730042251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31232/60000][Iteration 3996][Wall Clock 392.582994851s] Trained 128 records in 0.07560247 seconds. Throughput is 1693.0663 records/second. Loss is 0.23327424. Sequential31006cbd's hyper parameters: Current learning rate is 0.005558643690939411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31360/60000][Iteration 3997][Wall Clock 392.658290533s] Trained 128 records in 0.075295682 seconds. Throughput is 1699.9647 records/second. Loss is 0.24781291. Sequential31006cbd's hyper parameters: Current learning rate is 0.005558025789239663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31488/60000][Iteration 3998][Wall Clock 392.738376826s] Trained 128 records in 0.080086293 seconds. Throughput is 1598.276 records/second. Loss is 0.15088522. Sequential31006cbd's hyper parameters: Current learning rate is 0.005557408024897188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31616/60000][Iteration 3999][Wall Clock 392.827836748s] Trained 128 records in 0.089459922 seconds. Throughput is 1430.8083 records/second. Loss is 0.29338437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005556790397866192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31744/60000][Iteration 4000][Wall Clock 392.923406003s] Trained 128 records in 0.095569255 seconds. Throughput is 1339.3429 records/second. Loss is 0.20061882. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055561729081009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 31872/60000][Iteration 4001][Wall Clock 393.007105868s] Trained 128 records in 0.083699865 seconds. Throughput is 1529.2737 records/second. Loss is 0.22158954. Sequential31006cbd's hyper parameters: Current learning rate is 0.005555555555555556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 32000/60000][Iteration 4002][Wall Clock 393.112507103s] Trained 128 records in 0.105401235 seconds. Throughput is 1214.4071 records/second. Loss is 0.1166859. Sequential31006cbd's hyper parameters: Current learning rate is 0.005554938340184424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 32128/60000][Iteration 4003][Wall Clock 393.211430291s] Trained 128 records in 0.098923188 seconds. Throughput is 1293.9332 records/second. Loss is 0.1798143. Sequential31006cbd's hyper parameters: Current learning rate is 0.005554321261941791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 32256/60000][Iteration 4004][Wall Clock 393.294359472s] Trained 128 records in 0.082929181 seconds. Throughput is 1543.4857 records/second. Loss is 0.22852215. Sequential31006cbd's hyper parameters: Current learning rate is 0.005553704320781961. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:10 INFO  DistriOptimizer$:408 - [Epoch 9 32384/60000][Iteration 4005][Wall Clock 393.378126845s] Trained 128 records in 0.083767373 seconds. Throughput is 1528.0413 records/second. Loss is 0.29187167. Sequential31006cbd's hyper parameters: Current learning rate is 0.005553087516659262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 32512/60000][Iteration 4006][Wall Clock 393.455978929s] Trained 128 records in 0.077852084 seconds. Throughput is 1644.1436 records/second. Loss is 0.21252854. Sequential31006cbd's hyper parameters: Current learning rate is 0.005552470849528039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 32640/60000][Iteration 4007][Wall Clock 393.571003376s] Trained 128 records in 0.115024447 seconds. Throughput is 1112.8069 records/second. Loss is 0.32027775. Sequential31006cbd's hyper parameters: Current learning rate is 0.00555185431934266. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 32768/60000][Iteration 4008][Wall Clock 393.653462385s] Trained 128 records in 0.082459009 seconds. Throughput is 1552.2864 records/second. Loss is 0.17621863. Sequential31006cbd's hyper parameters: Current learning rate is 0.005551237926057511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 32896/60000][Iteration 4009][Wall Clock 393.749386986s] Trained 128 records in 0.095924601 seconds. Throughput is 1334.3813 records/second. Loss is 0.17270142. Sequential31006cbd's hyper parameters: Current learning rate is 0.005550621669626998. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33024/60000][Iteration 4010][Wall Clock 393.847307945s] Trained 128 records in 0.097920959 seconds. Throughput is 1307.1768 records/second. Loss is 0.25506964. Sequential31006cbd's hyper parameters: Current learning rate is 0.00555000555000555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33152/60000][Iteration 4011][Wall Clock 393.938193883s] Trained 128 records in 0.090885938 seconds. Throughput is 1408.3586 records/second. Loss is 0.22949865. Sequential31006cbd's hyper parameters: Current learning rate is 0.005549389567147614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33280/60000][Iteration 4012][Wall Clock 394.021232592s] Trained 128 records in 0.083038709 seconds. Throughput is 1541.4497 records/second. Loss is 0.20214292. Sequential31006cbd's hyper parameters: Current learning rate is 0.005548773721007657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33408/60000][Iteration 4013][Wall Clock 394.099802806s] Trained 128 records in 0.078570214 seconds. Throughput is 1629.1161 records/second. Loss is 0.2966578. Sequential31006cbd's hyper parameters: Current learning rate is 0.005548158011540169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33536/60000][Iteration 4014][Wall Clock 394.183399656s] Trained 128 records in 0.08359685 seconds. Throughput is 1531.1582 records/second. Loss is 0.24889596. Sequential31006cbd's hyper parameters: Current learning rate is 0.005547542438699656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33664/60000][Iteration 4015][Wall Clock 394.275341227s] Trained 128 records in 0.091941571 seconds. Throughput is 1392.1885 records/second. Loss is 0.21603799. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055469270024406485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:11 INFO  DistriOptimizer$:408 - [Epoch 9 33792/60000][Iteration 4016][Wall Clock 394.357762458s] Trained 128 records in 0.082421231 seconds. Throughput is 1552.9979 records/second. Loss is 0.22129333. Sequential31006cbd's hyper parameters: Current learning rate is 0.005546311702717693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 33920/60000][Iteration 4017][Wall Clock 394.434757859s] Trained 128 records in 0.076995401 seconds. Throughput is 1662.4369 records/second. Loss is 0.16530874. Sequential31006cbd's hyper parameters: Current learning rate is 0.00554569653948536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34048/60000][Iteration 4018][Wall Clock 394.509501526s] Trained 128 records in 0.074743667 seconds. Throughput is 1712.5197 records/second. Loss is 0.1706242. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055450815126982375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34176/60000][Iteration 4019][Wall Clock 394.590676299s] Trained 128 records in 0.081174773 seconds. Throughput is 1576.8445 records/second. Loss is 0.15122995. Sequential31006cbd's hyper parameters: Current learning rate is 0.005544466622310933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34304/60000][Iteration 4020][Wall Clock 394.680785677s] Trained 128 records in 0.090109378 seconds. Throughput is 1420.4958 records/second. Loss is 0.3515406. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055438518682780795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34432/60000][Iteration 4021][Wall Clock 394.765459473s] Trained 128 records in 0.084673796 seconds. Throughput is 1511.6837 records/second. Loss is 0.30412838. Sequential31006cbd's hyper parameters: Current learning rate is 0.005543237250554323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34560/60000][Iteration 4022][Wall Clock 394.85842387s] Trained 128 records in 0.092964397 seconds. Throughput is 1376.8712 records/second. Loss is 0.12310994. Sequential31006cbd's hyper parameters: Current learning rate is 0.005542622769094336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34688/60000][Iteration 4023][Wall Clock 394.955368275s] Trained 128 records in 0.096944405 seconds. Throughput is 1320.3444 records/second. Loss is 0.264343. Sequential31006cbd's hyper parameters: Current learning rate is 0.005542008423852805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34816/60000][Iteration 4024][Wall Clock 395.036806615s] Trained 128 records in 0.08143834 seconds. Throughput is 1571.7412 records/second. Loss is 0.30836698. Sequential31006cbd's hyper parameters: Current learning rate is 0.005541394214784439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 34944/60000][Iteration 4025][Wall Clock 395.119380367s] Trained 128 records in 0.082573752 seconds. Throughput is 1550.1294 records/second. Loss is 0.18636833. Sequential31006cbd's hyper parameters: Current learning rate is 0.005540780141843971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 35072/60000][Iteration 4026][Wall Clock 395.201460174s] Trained 128 records in 0.082079807 seconds. Throughput is 1559.4579 records/second. Loss is 0.27560034. Sequential31006cbd's hyper parameters: Current learning rate is 0.00554016620498615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 35200/60000][Iteration 4027][Wall Clock 395.283289018s] Trained 128 records in 0.081828844 seconds. Throughput is 1564.2405 records/second. Loss is 0.17342056. Sequential31006cbd's hyper parameters: Current learning rate is 0.005539552404165743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:12 INFO  DistriOptimizer$:408 - [Epoch 9 35328/60000][Iteration 4028][Wall Clock 395.364847204s] Trained 128 records in 0.081558186 seconds. Throughput is 1569.4318 records/second. Loss is 0.24317686. Sequential31006cbd's hyper parameters: Current learning rate is 0.005538938739337543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 35456/60000][Iteration 4029][Wall Clock 395.440807434s] Trained 128 records in 0.07596023 seconds. Throughput is 1685.0924 records/second. Loss is 0.24012944. Sequential31006cbd's hyper parameters: Current learning rate is 0.005538325210456357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 35584/60000][Iteration 4030][Wall Clock 395.520059619s] Trained 128 records in 0.079252185 seconds. Throughput is 1615.0974 records/second. Loss is 0.2730901. Sequential31006cbd's hyper parameters: Current learning rate is 0.005537711817477018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 35712/60000][Iteration 4031][Wall Clock 395.600583353s] Trained 128 records in 0.080523734 seconds. Throughput is 1589.5934 records/second. Loss is 0.132437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005537098560354374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 35840/60000][Iteration 4032][Wall Clock 395.690276633s] Trained 128 records in 0.08969328 seconds. Throughput is 1427.0858 records/second. Loss is 0.26807937. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055364854390432955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 35968/60000][Iteration 4033][Wall Clock 395.769543629s] Trained 128 records in 0.079266996 seconds. Throughput is 1614.7957 records/second. Loss is 0.18123582. Sequential31006cbd's hyper parameters: Current learning rate is 0.005535872453498672. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36096/60000][Iteration 4034][Wall Clock 395.853860043s] Trained 128 records in 0.084316414 seconds. Throughput is 1518.0911 records/second. Loss is 0.18013519. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055352596036754124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36224/60000][Iteration 4035][Wall Clock 395.956719566s] Trained 128 records in 0.102859523 seconds. Throughput is 1244.4156 records/second. Loss is 0.21974424. Sequential31006cbd's hyper parameters: Current learning rate is 0.005534646889528448. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36352/60000][Iteration 4036][Wall Clock 396.032350725s] Trained 128 records in 0.075631159 seconds. Throughput is 1692.4242 records/second. Loss is 0.25263968. Sequential31006cbd's hyper parameters: Current learning rate is 0.005534034311012729. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36480/60000][Iteration 4037][Wall Clock 396.110032371s] Trained 128 records in 0.077681646 seconds. Throughput is 1647.7509 records/second. Loss is 0.1555686. Sequential31006cbd's hyper parameters: Current learning rate is 0.005533421868083223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36608/60000][Iteration 4038][Wall Clock 396.195282881s] Trained 128 records in 0.08525051 seconds. Throughput is 1501.4573 records/second. Loss is 0.20888579. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055328095606949216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36736/60000][Iteration 4039][Wall Clock 396.280643001s] Trained 128 records in 0.08536012 seconds. Throughput is 1499.5293 records/second. Loss is 0.20922631. Sequential31006cbd's hyper parameters: Current learning rate is 0.005532197388802833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:13 INFO  DistriOptimizer$:408 - [Epoch 9 36864/60000][Iteration 4040][Wall Clock 396.371880499s] Trained 128 records in 0.091237498 seconds. Throughput is 1402.9319 records/second. Loss is 0.2313231. Sequential31006cbd's hyper parameters: Current learning rate is 0.005531585352361987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 36992/60000][Iteration 4041][Wall Clock 396.46044765s] Trained 128 records in 0.088567151 seconds. Throughput is 1445.2311 records/second. Loss is 0.1761982. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055309734513274336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37120/60000][Iteration 4042][Wall Clock 396.553921409s] Trained 128 records in 0.093473759 seconds. Throughput is 1369.3683 records/second. Loss is 0.24587782. Sequential31006cbd's hyper parameters: Current learning rate is 0.005530361685654242. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37248/60000][Iteration 4043][Wall Clock 396.642708027s] Trained 128 records in 0.088786618 seconds. Throughput is 1441.6587 records/second. Loss is 0.26517192. Sequential31006cbd's hyper parameters: Current learning rate is 0.005529750055297501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37376/60000][Iteration 4044][Wall Clock 396.739849371s] Trained 128 records in 0.097141344 seconds. Throughput is 1317.6676 records/second. Loss is 0.22059384. Sequential31006cbd's hyper parameters: Current learning rate is 0.005529138560212319. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37504/60000][Iteration 4045][Wall Clock 396.832646551s] Trained 128 records in 0.09279718 seconds. Throughput is 1379.3522 records/second. Loss is 0.22538461. Sequential31006cbd's hyper parameters: Current learning rate is 0.005528527200353826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37632/60000][Iteration 4046][Wall Clock 396.944452446s] Trained 128 records in 0.111805895 seconds. Throughput is 1144.8413 records/second. Loss is 0.23952934. Sequential31006cbd's hyper parameters: Current learning rate is 0.00552791597567717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37760/60000][Iteration 4047][Wall Clock 397.024262876s] Trained 128 records in 0.07981043 seconds. Throughput is 1603.8003 records/second. Loss is 0.17499296. Sequential31006cbd's hyper parameters: Current learning rate is 0.005527304886137519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 37888/60000][Iteration 4048][Wall Clock 397.099787909s] Trained 128 records in 0.075525033 seconds. Throughput is 1694.8024 records/second. Loss is 0.19136252. Sequential31006cbd's hyper parameters: Current learning rate is 0.005526693931690063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 38016/60000][Iteration 4049][Wall Clock 397.180539608s] Trained 128 records in 0.080751699 seconds. Throughput is 1585.106 records/second. Loss is 0.249739. Sequential31006cbd's hyper parameters: Current learning rate is 0.005526083112290008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 38144/60000][Iteration 4050][Wall Clock 397.271825207s] Trained 128 records in 0.091285599 seconds. Throughput is 1402.1926 records/second. Loss is 0.14671935. Sequential31006cbd's hyper parameters: Current learning rate is 0.005525472427892585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:14 INFO  DistriOptimizer$:408 - [Epoch 9 38272/60000][Iteration 4051][Wall Clock 397.378446069s] Trained 128 records in 0.106620862 seconds. Throughput is 1200.5155 records/second. Loss is 0.16907352. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055248618784530384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 38400/60000][Iteration 4052][Wall Clock 397.459840217s] Trained 128 records in 0.081394148 seconds. Throughput is 1572.5946 records/second. Loss is 0.19370694. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055242514639266375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 38528/60000][Iteration 4053][Wall Clock 397.532870542s] Trained 128 records in 0.073030325 seconds. Throughput is 1752.6967 records/second. Loss is 0.2676447. Sequential31006cbd's hyper parameters: Current learning rate is 0.00552364118426867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 38656/60000][Iteration 4054][Wall Clock 397.611219466s] Trained 128 records in 0.078348924 seconds. Throughput is 1633.7173 records/second. Loss is 0.12594959. Sequential31006cbd's hyper parameters: Current learning rate is 0.005523031039434442. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 38784/60000][Iteration 4055][Wall Clock 397.694907694s] Trained 128 records in 0.083688228 seconds. Throughput is 1529.4863 records/second. Loss is 0.17787331. Sequential31006cbd's hyper parameters: Current learning rate is 0.00552242102937928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 38912/60000][Iteration 4056][Wall Clock 397.769698074s] Trained 128 records in 0.07479038 seconds. Throughput is 1711.4501 records/second. Loss is 0.25736728. Sequential31006cbd's hyper parameters: Current learning rate is 0.005521811154058531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39040/60000][Iteration 4057][Wall Clock 397.846487702s] Trained 128 records in 0.076789628 seconds. Throughput is 1666.8918 records/second. Loss is 0.20030728. Sequential31006cbd's hyper parameters: Current learning rate is 0.005521201413427562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39168/60000][Iteration 4058][Wall Clock 397.936949389s] Trained 128 records in 0.090461687 seconds. Throughput is 1414.9636 records/second. Loss is 0.3150392. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055205918074417585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39296/60000][Iteration 4059][Wall Clock 398.016376982s] Trained 128 records in 0.079427593 seconds. Throughput is 1611.5306 records/second. Loss is 0.1387459. Sequential31006cbd's hyper parameters: Current learning rate is 0.005519982336056525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39424/60000][Iteration 4060][Wall Clock 398.110988256s] Trained 128 records in 0.094611274 seconds. Throughput is 1352.9043 records/second. Loss is 0.25536528. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055193729992272875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39552/60000][Iteration 4061][Wall Clock 398.198874658s] Trained 128 records in 0.087886402 seconds. Throughput is 1456.4255 records/second. Loss is 0.22717512. Sequential31006cbd's hyper parameters: Current learning rate is 0.005518763796909492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39680/60000][Iteration 4062][Wall Clock 398.284578298s] Trained 128 records in 0.08570364 seconds. Throughput is 1493.5188 records/second. Loss is 0.3573796. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055181547290586025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:15 INFO  DistriOptimizer$:408 - [Epoch 9 39808/60000][Iteration 4063][Wall Clock 398.379142098s] Trained 128 records in 0.0945638 seconds. Throughput is 1353.5835 records/second. Loss is 0.20973128. Sequential31006cbd's hyper parameters: Current learning rate is 0.005517545795630104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 39936/60000][Iteration 4064][Wall Clock 398.460348655s] Trained 128 records in 0.081206557 seconds. Throughput is 1576.2273 records/second. Loss is 0.2278305. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055169369965794995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40064/60000][Iteration 4065][Wall Clock 398.537279885s] Trained 128 records in 0.07693123 seconds. Throughput is 1663.8236 records/second. Loss is 0.15879306. Sequential31006cbd's hyper parameters: Current learning rate is 0.005516328331862312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40192/60000][Iteration 4066][Wall Clock 398.657075579s] Trained 128 records in 0.119795694 seconds. Throughput is 1068.4858 records/second. Loss is 0.29455107. Sequential31006cbd's hyper parameters: Current learning rate is 0.005515719801434087. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40320/60000][Iteration 4067][Wall Clock 398.737703046s] Trained 128 records in 0.080627467 seconds. Throughput is 1587.5483 records/second. Loss is 0.20283477. Sequential31006cbd's hyper parameters: Current learning rate is 0.005515111405250386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40448/60000][Iteration 4068][Wall Clock 398.817233579s] Trained 128 records in 0.079530533 seconds. Throughput is 1609.4448 records/second. Loss is 0.2846482. Sequential31006cbd's hyper parameters: Current learning rate is 0.005514503143266791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40576/60000][Iteration 4069][Wall Clock 398.893012315s] Trained 128 records in 0.075778736 seconds. Throughput is 1689.1282 records/second. Loss is 0.41055837. Sequential31006cbd's hyper parameters: Current learning rate is 0.005513895015438906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40704/60000][Iteration 4070][Wall Clock 398.972722534s] Trained 128 records in 0.079710219 seconds. Throughput is 1605.8168 records/second. Loss is 0.2100784. Sequential31006cbd's hyper parameters: Current learning rate is 0.005513287021722351. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40832/60000][Iteration 4071][Wall Clock 399.058238976s] Trained 128 records in 0.085516442 seconds. Throughput is 1496.7881 records/second. Loss is 0.2501093. Sequential31006cbd's hyper parameters: Current learning rate is 0.005512679162072767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 40960/60000][Iteration 4072][Wall Clock 399.139390452s] Trained 128 records in 0.081151476 seconds. Throughput is 1577.2972 records/second. Loss is 0.19883764. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055120714364458165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 41088/60000][Iteration 4073][Wall Clock 399.222101955s] Trained 128 records in 0.082711503 seconds. Throughput is 1547.5477 records/second. Loss is 0.22860777. Sequential31006cbd's hyper parameters: Current learning rate is 0.005511463844797178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 41216/60000][Iteration 4074][Wall Clock 399.306072351s] Trained 128 records in 0.083970396 seconds. Throughput is 1524.3467 records/second. Loss is 0.13376538. Sequential31006cbd's hyper parameters: Current learning rate is 0.005510856387082552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:16 INFO  DistriOptimizer$:408 - [Epoch 9 41344/60000][Iteration 4075][Wall Clock 399.393171886s] Trained 128 records in 0.087099535 seconds. Throughput is 1469.583 records/second. Loss is 0.16266038. Sequential31006cbd's hyper parameters: Current learning rate is 0.00551024906325766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 41472/60000][Iteration 4076][Wall Clock 399.478830474s] Trained 128 records in 0.085658588 seconds. Throughput is 1494.3043 records/second. Loss is 0.26838604. Sequential31006cbd's hyper parameters: Current learning rate is 0.005509641873278237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 41600/60000][Iteration 4077][Wall Clock 399.565414968s] Trained 128 records in 0.086584494 seconds. Throughput is 1478.3247 records/second. Loss is 0.20663881. Sequential31006cbd's hyper parameters: Current learning rate is 0.005509034817100044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 41728/60000][Iteration 4078][Wall Clock 399.645101001s] Trained 128 records in 0.079686033 seconds. Throughput is 1606.3041 records/second. Loss is 0.20949668. Sequential31006cbd's hyper parameters: Current learning rate is 0.005508427894678859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 41856/60000][Iteration 4079][Wall Clock 399.722878925s] Trained 128 records in 0.077777924 seconds. Throughput is 1645.7112 records/second. Loss is 0.23339427. Sequential31006cbd's hyper parameters: Current learning rate is 0.0055078211059704785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 41984/60000][Iteration 4080][Wall Clock 399.805593608s] Trained 128 records in 0.082714683 seconds. Throughput is 1547.4883 records/second. Loss is 0.18141536. Sequential31006cbd's hyper parameters: Current learning rate is 0.005507214450930719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 42112/60000][Iteration 4081][Wall Clock 399.87663077s] Trained 128 records in 0.071037162 seconds. Throughput is 1801.8739 records/second. Loss is 0.32277405. Sequential31006cbd's hyper parameters: Current learning rate is 0.005506607929515419. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 42240/60000][Iteration 4082][Wall Clock 399.960589022s] Trained 128 records in 0.083958252 seconds. Throughput is 1524.5673 records/second. Loss is 0.3625005. Sequential31006cbd's hyper parameters: Current learning rate is 0.005506001541680431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 42368/60000][Iteration 4083][Wall Clock 400.04662147s] Trained 128 records in 0.086032448 seconds. Throughput is 1487.8107 records/second. Loss is 0.22270714. Sequential31006cbd's hyper parameters: Current learning rate is 0.005505395287381634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 42496/60000][Iteration 4084][Wall Clock 400.158656655s] Trained 128 records in 0.112035185 seconds. Throughput is 1142.4982 records/second. Loss is 0.27174792. Sequential31006cbd's hyper parameters: Current learning rate is 0.00550478916657492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 42624/60000][Iteration 4085][Wall Clock 400.261506986s] Trained 128 records in 0.102850331 seconds. Throughput is 1244.5269 records/second. Loss is 0.16187248. Sequential31006cbd's hyper parameters: Current learning rate is 0.005504183179216204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:17 INFO  DistriOptimizer$:408 - [Epoch 9 42752/60000][Iteration 4086][Wall Clock 400.365091302s] Trained 128 records in 0.103584316 seconds. Throughput is 1235.7083 records/second. Loss is 0.26743752. Sequential31006cbd's hyper parameters: Current learning rate is 0.005503577325261419. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 42880/60000][Iteration 4087][Wall Clock 400.456272541s] Trained 128 records in 0.091181239 seconds. Throughput is 1403.7975 records/second. Loss is 0.27468327. Sequential31006cbd's hyper parameters: Current learning rate is 0.00550297160466652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43008/60000][Iteration 4088][Wall Clock 400.540388265s] Trained 128 records in 0.084115724 seconds. Throughput is 1521.7131 records/second. Loss is 0.2180531. Sequential31006cbd's hyper parameters: Current learning rate is 0.005502366017387477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43136/60000][Iteration 4089][Wall Clock 400.626719154s] Trained 128 records in 0.086330889 seconds. Throughput is 1482.6675 records/second. Loss is 0.22771126. Sequential31006cbd's hyper parameters: Current learning rate is 0.005501760563380281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43264/60000][Iteration 4090][Wall Clock 400.706799253s] Trained 128 records in 0.080080099 seconds. Throughput is 1598.3997 records/second. Loss is 0.28004918. Sequential31006cbd's hyper parameters: Current learning rate is 0.005501155242600946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43392/60000][Iteration 4091][Wall Clock 400.781013228s] Trained 128 records in 0.074213975 seconds. Throughput is 1724.7426 records/second. Loss is 0.21993145. Sequential31006cbd's hyper parameters: Current learning rate is 0.005500550055005501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43520/60000][Iteration 4092][Wall Clock 400.859479376s] Trained 128 records in 0.078466148 seconds. Throughput is 1631.2767 records/second. Loss is 0.2881083. Sequential31006cbd's hyper parameters: Current learning rate is 0.005499945000549994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43648/60000][Iteration 4093][Wall Clock 400.941700692s] Trained 128 records in 0.082221316 seconds. Throughput is 1556.7739 records/second. Loss is 0.22302577. Sequential31006cbd's hyper parameters: Current learning rate is 0.005499340079190497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43776/60000][Iteration 4094][Wall Clock 401.019238732s] Trained 128 records in 0.07753804 seconds. Throughput is 1650.8026 records/second. Loss is 0.12872623. Sequential31006cbd's hyper parameters: Current learning rate is 0.005498735290883097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 43904/60000][Iteration 4095][Wall Clock 401.101315273s] Trained 128 records in 0.082076541 seconds. Throughput is 1559.5199 records/second. Loss is 0.25040203. Sequential31006cbd's hyper parameters: Current learning rate is 0.005498130635583902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 44032/60000][Iteration 4096][Wall Clock 401.174847461s] Trained 128 records in 0.073532188 seconds. Throughput is 1740.7343 records/second. Loss is 0.21733536. Sequential31006cbd's hyper parameters: Current learning rate is 0.005497526113249039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 44160/60000][Iteration 4097][Wall Clock 401.248450963s] Trained 128 records in 0.073603502 seconds. Throughput is 1739.0476 records/second. Loss is 0.18617964. Sequential31006cbd's hyper parameters: Current learning rate is 0.005496921723834653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 44288/60000][Iteration 4098][Wall Clock 401.323951085s] Trained 128 records in 0.075500122 seconds. Throughput is 1695.3615 records/second. Loss is 0.24147667. Sequential31006cbd's hyper parameters: Current learning rate is 0.005496317467296912. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:18 INFO  DistriOptimizer$:408 - [Epoch 9 44416/60000][Iteration 4099][Wall Clock 401.399064518s] Trained 128 records in 0.075113433 seconds. Throughput is 1704.0894 records/second. Loss is 0.21888492. Sequential31006cbd's hyper parameters: Current learning rate is 0.005495713343591999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 44544/60000][Iteration 4100][Wall Clock 401.478192145s] Trained 128 records in 0.079127627 seconds. Throughput is 1617.6399 records/second. Loss is 0.17799449. Sequential31006cbd's hyper parameters: Current learning rate is 0.005495109352676118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 44672/60000][Iteration 4101][Wall Clock 401.5613657s] Trained 128 records in 0.083173555 seconds. Throughput is 1538.9507 records/second. Loss is 0.2098373. Sequential31006cbd's hyper parameters: Current learning rate is 0.005494505494505494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 44800/60000][Iteration 4102][Wall Clock 401.639146487s] Trained 128 records in 0.077780787 seconds. Throughput is 1645.6505 records/second. Loss is 0.20103483. Sequential31006cbd's hyper parameters: Current learning rate is 0.00549390176903637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 44928/60000][Iteration 4103][Wall Clock 401.71877593s] Trained 128 records in 0.079629443 seconds. Throughput is 1607.4456 records/second. Loss is 0.2950607. Sequential31006cbd's hyper parameters: Current learning rate is 0.005493298176225006. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45056/60000][Iteration 4104][Wall Clock 401.800281297s] Trained 128 records in 0.081505367 seconds. Throughput is 1570.4487 records/second. Loss is 0.23706883. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054926947160276835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45184/60000][Iteration 4105][Wall Clock 401.875927037s] Trained 128 records in 0.07564574 seconds. Throughput is 1692.098 records/second. Loss is 0.18385383. Sequential31006cbd's hyper parameters: Current learning rate is 0.005492091388400702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45312/60000][Iteration 4106][Wall Clock 401.952682738s] Trained 128 records in 0.076755701 seconds. Throughput is 1667.6285 records/second. Loss is 0.1397992. Sequential31006cbd's hyper parameters: Current learning rate is 0.005491488193300384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45440/60000][Iteration 4107][Wall Clock 402.051242811s] Trained 128 records in 0.098560073 seconds. Throughput is 1298.7003 records/second. Loss is 0.17755151. Sequential31006cbd's hyper parameters: Current learning rate is 0.005490885130683066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45568/60000][Iteration 4108][Wall Clock 402.16126655s] Trained 128 records in 0.110023739 seconds. Throughput is 1163.3854 records/second. Loss is 0.18012753. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054902822005051055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45696/60000][Iteration 4109][Wall Clock 402.27855753s] Trained 128 records in 0.11729098 seconds. Throughput is 1091.303 records/second. Loss is 0.20779833. Sequential31006cbd's hyper parameters: Current learning rate is 0.005489679402722881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:19 INFO  DistriOptimizer$:408 - [Epoch 9 45824/60000][Iteration 4110][Wall Clock 402.360801243s] Trained 128 records in 0.082243713 seconds. Throughput is 1556.35 records/second. Loss is 0.16467622. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054890767372927874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 45952/60000][Iteration 4111][Wall Clock 402.453794489s] Trained 128 records in 0.092993246 seconds. Throughput is 1376.4441 records/second. Loss is 0.22649029. Sequential31006cbd's hyper parameters: Current learning rate is 0.00548847420417124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46080/60000][Iteration 4112][Wall Clock 402.534341705s] Trained 128 records in 0.080547216 seconds. Throughput is 1589.1301 records/second. Loss is 0.14280131. Sequential31006cbd's hyper parameters: Current learning rate is 0.005487871803314674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46208/60000][Iteration 4113][Wall Clock 402.624755829s] Trained 128 records in 0.090414124 seconds. Throughput is 1415.708 records/second. Loss is 0.18853422. Sequential31006cbd's hyper parameters: Current learning rate is 0.005487269534679543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46336/60000][Iteration 4114][Wall Clock 402.699518545s] Trained 128 records in 0.074762716 seconds. Throughput is 1712.0833 records/second. Loss is 0.21328945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054866673982223195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46464/60000][Iteration 4115][Wall Clock 402.776413925s] Trained 128 records in 0.07689538 seconds. Throughput is 1664.5994 records/second. Loss is 0.384538. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054860653938994955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46592/60000][Iteration 4116][Wall Clock 402.852594036s] Trained 128 records in 0.076180111 seconds. Throughput is 1680.2286 records/second. Loss is 0.22925282. Sequential31006cbd's hyper parameters: Current learning rate is 0.005485463521667581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46720/60000][Iteration 4117][Wall Clock 402.932440188s] Trained 128 records in 0.079846152 seconds. Throughput is 1603.0829 records/second. Loss is 0.21985935. Sequential31006cbd's hyper parameters: Current learning rate is 0.005484861781483107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46848/60000][Iteration 4118][Wall Clock 403.014470085s] Trained 128 records in 0.082029897 seconds. Throughput is 1560.4067 records/second. Loss is 0.22197688. Sequential31006cbd's hyper parameters: Current learning rate is 0.005484260173302622. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 46976/60000][Iteration 4119][Wall Clock 403.08253338s] Trained 128 records in 0.068063295 seconds. Throughput is 1880.6024 records/second. Loss is 0.20939127. Sequential31006cbd's hyper parameters: Current learning rate is 0.005483658697082694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 47104/60000][Iteration 4120][Wall Clock 403.155712982s] Trained 128 records in 0.073179602 seconds. Throughput is 1749.1213 records/second. Loss is 0.19117127. Sequential31006cbd's hyper parameters: Current learning rate is 0.00548305735277991. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 47232/60000][Iteration 4121][Wall Clock 403.233136907s] Trained 128 records in 0.077423925 seconds. Throughput is 1653.2358 records/second. Loss is 0.11268337. Sequential31006cbd's hyper parameters: Current learning rate is 0.005482456140350877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:20 INFO  DistriOptimizer$:408 - [Epoch 9 47360/60000][Iteration 4122][Wall Clock 403.309648021s] Trained 128 records in 0.076511114 seconds. Throughput is 1672.9596 records/second. Loss is 0.13487126. Sequential31006cbd's hyper parameters: Current learning rate is 0.00548185505975222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 47488/60000][Iteration 4123][Wall Clock 403.401226787s] Trained 128 records in 0.091578766 seconds. Throughput is 1397.7039 records/second. Loss is 0.122998886. Sequential31006cbd's hyper parameters: Current learning rate is 0.005481254110940584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 47616/60000][Iteration 4124][Wall Clock 403.49056991s] Trained 128 records in 0.089343123 seconds. Throughput is 1432.6788 records/second. Loss is 0.16323079. Sequential31006cbd's hyper parameters: Current learning rate is 0.00548065329387263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 47744/60000][Iteration 4125][Wall Clock 403.567274101s] Trained 128 records in 0.076704191 seconds. Throughput is 1668.7485 records/second. Loss is 0.18836913. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054800526085050415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 47872/60000][Iteration 4126][Wall Clock 403.647784572s] Trained 128 records in 0.080510471 seconds. Throughput is 1589.8553 records/second. Loss is 0.26399404. Sequential31006cbd's hyper parameters: Current learning rate is 0.00547945205479452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48000/60000][Iteration 4127][Wall Clock 403.739045228s] Trained 128 records in 0.091260656 seconds. Throughput is 1402.5759 records/second. Loss is 0.23196189. Sequential31006cbd's hyper parameters: Current learning rate is 0.005478851632697786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48128/60000][Iteration 4128][Wall Clock 403.821816112s] Trained 128 records in 0.082770884 seconds. Throughput is 1546.4375 records/second. Loss is 0.22688799. Sequential31006cbd's hyper parameters: Current learning rate is 0.005478251342171578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48256/60000][Iteration 4129][Wall Clock 403.924161379s] Trained 128 records in 0.102345267 seconds. Throughput is 1250.6685 records/second. Loss is 0.29645938. Sequential31006cbd's hyper parameters: Current learning rate is 0.005477651183172655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48384/60000][Iteration 4130][Wall Clock 404.014360884s] Trained 128 records in 0.090199505 seconds. Throughput is 1419.0765 records/second. Loss is 0.12927607. Sequential31006cbd's hyper parameters: Current learning rate is 0.005477051155657794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48512/60000][Iteration 4131][Wall Clock 404.103350335s] Trained 128 records in 0.088989451 seconds. Throughput is 1438.3727 records/second. Loss is 0.3017862. Sequential31006cbd's hyper parameters: Current learning rate is 0.00547645125958379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48640/60000][Iteration 4132][Wall Clock 404.182323131s] Trained 128 records in 0.078972796 seconds. Throughput is 1620.8113 records/second. Loss is 0.20416671. Sequential31006cbd's hyper parameters: Current learning rate is 0.005475851494907458. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48768/60000][Iteration 4133][Wall Clock 404.258659044s] Trained 128 records in 0.076335913 seconds. Throughput is 1676.7992 records/second. Loss is 0.1353186. Sequential31006cbd's hyper parameters: Current learning rate is 0.005475251861585633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:21 INFO  DistriOptimizer$:408 - [Epoch 9 48896/60000][Iteration 4134][Wall Clock 404.341540985s] Trained 128 records in 0.082881941 seconds. Throughput is 1544.3654 records/second. Loss is 0.16770235. Sequential31006cbd's hyper parameters: Current learning rate is 0.005474652359575167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49024/60000][Iteration 4135][Wall Clock 404.418306367s] Trained 128 records in 0.076765382 seconds. Throughput is 1667.4183 records/second. Loss is 0.17270151. Sequential31006cbd's hyper parameters: Current learning rate is 0.005474052988832932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49152/60000][Iteration 4136][Wall Clock 404.497603621s] Trained 128 records in 0.079297254 seconds. Throughput is 1614.1796 records/second. Loss is 0.22995618. Sequential31006cbd's hyper parameters: Current learning rate is 0.005473453749315818. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49280/60000][Iteration 4137][Wall Clock 404.577396259s] Trained 128 records in 0.079792638 seconds. Throughput is 1604.158 records/second. Loss is 0.20734026. Sequential31006cbd's hyper parameters: Current learning rate is 0.005472854640980736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49408/60000][Iteration 4138][Wall Clock 404.657169952s] Trained 128 records in 0.079773693 seconds. Throughput is 1604.539 records/second. Loss is 0.3172491. Sequential31006cbd's hyper parameters: Current learning rate is 0.005472255663784612. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49536/60000][Iteration 4139][Wall Clock 404.7309002s] Trained 128 records in 0.073730248 seconds. Throughput is 1736.0582 records/second. Loss is 0.19156094. Sequential31006cbd's hyper parameters: Current learning rate is 0.005471656817684395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49664/60000][Iteration 4140][Wall Clock 404.80678487s] Trained 128 records in 0.07588467 seconds. Throughput is 1686.7701 records/second. Loss is 0.17976704. Sequential31006cbd's hyper parameters: Current learning rate is 0.00547105810263705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49792/60000][Iteration 4141][Wall Clock 404.885780206s] Trained 128 records in 0.078995336 seconds. Throughput is 1620.3488 records/second. Loss is 0.15964973. Sequential31006cbd's hyper parameters: Current learning rate is 0.005470459518599562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 49920/60000][Iteration 4142][Wall Clock 404.960730559s] Trained 128 records in 0.074950353 seconds. Throughput is 1707.7971 records/second. Loss is 0.1516675. Sequential31006cbd's hyper parameters: Current learning rate is 0.005469861065528936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 50048/60000][Iteration 4143][Wall Clock 405.053165872s] Trained 128 records in 0.092435313 seconds. Throughput is 1384.7521 records/second. Loss is 0.13739944. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054692627433821925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 50176/60000][Iteration 4144][Wall Clock 405.132630252s] Trained 128 records in 0.07946438 seconds. Throughput is 1610.7845 records/second. Loss is 0.12910596. Sequential31006cbd's hyper parameters: Current learning rate is 0.005468664552116373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 50304/60000][Iteration 4145][Wall Clock 405.208566728s] Trained 128 records in 0.075936476 seconds. Throughput is 1685.6195 records/second. Loss is 0.16889867. Sequential31006cbd's hyper parameters: Current learning rate is 0.005468066491688539. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 50432/60000][Iteration 4146][Wall Clock 405.28922528s] Trained 128 records in 0.080658552 seconds. Throughput is 1586.9364 records/second. Loss is 0.20411153. Sequential31006cbd's hyper parameters: Current learning rate is 0.005467468562055768. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:22 INFO  DistriOptimizer$:408 - [Epoch 9 50560/60000][Iteration 4147][Wall Clock 405.369807937s] Trained 128 records in 0.080582657 seconds. Throughput is 1588.4312 records/second. Loss is 0.17823152. Sequential31006cbd's hyper parameters: Current learning rate is 0.005466870763175158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 50688/60000][Iteration 4148][Wall Clock 405.450943998s] Trained 128 records in 0.081136061 seconds. Throughput is 1577.5969 records/second. Loss is 0.22469589. Sequential31006cbd's hyper parameters: Current learning rate is 0.005466273095003826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 50816/60000][Iteration 4149][Wall Clock 405.525512922s] Trained 128 records in 0.074568924 seconds. Throughput is 1716.5327 records/second. Loss is 0.18495205. Sequential31006cbd's hyper parameters: Current learning rate is 0.005465675557498907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 50944/60000][Iteration 4150][Wall Clock 405.60994598s] Trained 128 records in 0.084433058 seconds. Throughput is 1515.9939 records/second. Loss is 0.21286626. Sequential31006cbd's hyper parameters: Current learning rate is 0.005465078150617554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51072/60000][Iteration 4151][Wall Clock 405.688499377s] Trained 128 records in 0.078553397 seconds. Throughput is 1629.465 records/second. Loss is 0.2804353. Sequential31006cbd's hyper parameters: Current learning rate is 0.00546448087431694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51200/60000][Iteration 4152][Wall Clock 405.773422537s] Trained 128 records in 0.08492316 seconds. Throughput is 1507.2449 records/second. Loss is 0.20736916. Sequential31006cbd's hyper parameters: Current learning rate is 0.005463883728554256. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51328/60000][Iteration 4153][Wall Clock 405.85566341s] Trained 128 records in 0.082240873 seconds. Throughput is 1556.4037 records/second. Loss is 0.15285975. Sequential31006cbd's hyper parameters: Current learning rate is 0.005463286713286713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51456/60000][Iteration 4154][Wall Clock 405.93620722s] Trained 128 records in 0.08054381 seconds. Throughput is 1589.1973 records/second. Loss is 0.25565228. Sequential31006cbd's hyper parameters: Current learning rate is 0.005462689828471539. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51584/60000][Iteration 4155][Wall Clock 406.006141699s] Trained 128 records in 0.069934479 seconds. Throughput is 1830.2845 records/second. Loss is 0.21161962. Sequential31006cbd's hyper parameters: Current learning rate is 0.005462093074065982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51712/60000][Iteration 4156][Wall Clock 406.079771555s] Trained 128 records in 0.073629856 seconds. Throughput is 1738.4253 records/second. Loss is 0.18715474. Sequential31006cbd's hyper parameters: Current learning rate is 0.005461496450027308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51840/60000][Iteration 4157][Wall Clock 406.155645299s] Trained 128 records in 0.075873744 seconds. Throughput is 1687.0131 records/second. Loss is 0.14280665. Sequential31006cbd's hyper parameters: Current learning rate is 0.005460899956312801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 51968/60000][Iteration 4158][Wall Clock 406.240794112s] Trained 128 records in 0.085148813 seconds. Throughput is 1503.2506 records/second. Loss is 0.22276849. Sequential31006cbd's hyper parameters: Current learning rate is 0.005460303592879764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:23 INFO  DistriOptimizer$:408 - [Epoch 9 52096/60000][Iteration 4159][Wall Clock 406.315746211s] Trained 128 records in 0.074952099 seconds. Throughput is 1707.7574 records/second. Loss is 0.20542409. Sequential31006cbd's hyper parameters: Current learning rate is 0.005459707359685521. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52224/60000][Iteration 4160][Wall Clock 406.401391366s] Trained 128 records in 0.085645155 seconds. Throughput is 1494.5387 records/second. Loss is 0.13535479. Sequential31006cbd's hyper parameters: Current learning rate is 0.005459111256687411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52352/60000][Iteration 4161][Wall Clock 406.48377834s] Trained 128 records in 0.082386974 seconds. Throughput is 1553.6437 records/second. Loss is 0.15940854. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054585152838427945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52480/60000][Iteration 4162][Wall Clock 406.560510827s] Trained 128 records in 0.076732487 seconds. Throughput is 1668.133 records/second. Loss is 0.18488917. Sequential31006cbd's hyper parameters: Current learning rate is 0.005457919441109049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52608/60000][Iteration 4163][Wall Clock 406.643149064s] Trained 128 records in 0.082638237 seconds. Throughput is 1548.9198 records/second. Loss is 0.22999495. Sequential31006cbd's hyper parameters: Current learning rate is 0.005457323728443571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52736/60000][Iteration 4164][Wall Clock 406.720045235s] Trained 128 records in 0.076896171 seconds. Throughput is 1664.5823 records/second. Loss is 0.17642008. Sequential31006cbd's hyper parameters: Current learning rate is 0.005456728145803776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52864/60000][Iteration 4165][Wall Clock 406.794472837s] Trained 128 records in 0.074427602 seconds. Throughput is 1719.792 records/second. Loss is 0.2233356. Sequential31006cbd's hyper parameters: Current learning rate is 0.005456132693147098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 52992/60000][Iteration 4166][Wall Clock 406.87775754s] Trained 128 records in 0.083284703 seconds. Throughput is 1536.8969 records/second. Loss is 0.2244634. Sequential31006cbd's hyper parameters: Current learning rate is 0.005455537370430987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 53120/60000][Iteration 4167][Wall Clock 406.954594829s] Trained 128 records in 0.076837289 seconds. Throughput is 1665.8579 records/second. Loss is 0.24971946. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054549421776129165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 53248/60000][Iteration 4168][Wall Clock 407.034517999s] Trained 128 records in 0.07992317 seconds. Throughput is 1601.5381 records/second. Loss is 0.18991125. Sequential31006cbd's hyper parameters: Current learning rate is 0.005454347114650376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 53376/60000][Iteration 4169][Wall Clock 407.106456011s] Trained 128 records in 0.071938012 seconds. Throughput is 1779.3096 records/second. Loss is 0.2734847. Sequential31006cbd's hyper parameters: Current learning rate is 0.005453752181500873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 53504/60000][Iteration 4170][Wall Clock 407.186271722s] Trained 128 records in 0.079815711 seconds. Throughput is 1603.6943 records/second. Loss is 0.29582456. Sequential31006cbd's hyper parameters: Current learning rate is 0.005453157378121932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 53632/60000][Iteration 4171][Wall Clock 407.262243687s] Trained 128 records in 0.075971965 seconds. Throughput is 1684.8319 records/second. Loss is 0.2515601. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054525627044711015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:24 INFO  DistriOptimizer$:408 - [Epoch 9 53760/60000][Iteration 4172][Wall Clock 407.357388238s] Trained 128 records in 0.095144551 seconds. Throughput is 1345.3214 records/second. Loss is 0.16478385. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054519681605059425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 53888/60000][Iteration 4173][Wall Clock 407.462052822s] Trained 128 records in 0.104664584 seconds. Throughput is 1222.9542 records/second. Loss is 0.20079997. Sequential31006cbd's hyper parameters: Current learning rate is 0.005451373746184038. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54016/60000][Iteration 4174][Wall Clock 407.547795067s] Trained 128 records in 0.085742245 seconds. Throughput is 1492.8464 records/second. Loss is 0.23209389. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054507794614629896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54144/60000][Iteration 4175][Wall Clock 407.628305622s] Trained 128 records in 0.080510555 seconds. Throughput is 1589.8536 records/second. Loss is 0.23802382. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054501853063004145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54272/60000][Iteration 4176][Wall Clock 407.703170981s] Trained 128 records in 0.074865359 seconds. Throughput is 1709.7361 records/second. Loss is 0.16065185. Sequential31006cbd's hyper parameters: Current learning rate is 0.005449591280653951. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54400/60000][Iteration 4177][Wall Clock 407.776224365s] Trained 128 records in 0.073053384 seconds. Throughput is 1752.1434 records/second. Loss is 0.25265598. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054489973844812556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54528/60000][Iteration 4178][Wall Clock 407.854662169s] Trained 128 records in 0.078437804 seconds. Throughput is 1631.8662 records/second. Loss is 0.17137001. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054484036177400025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54656/60000][Iteration 4179][Wall Clock 407.950281808s] Trained 128 records in 0.095619639 seconds. Throughput is 1338.6371 records/second. Loss is 0.22883081. Sequential31006cbd's hyper parameters: Current learning rate is 0.005447809980387884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54784/60000][Iteration 4180][Wall Clock 408.047229772s] Trained 128 records in 0.096947964 seconds. Throughput is 1320.2959 records/second. Loss is 0.2238863. Sequential31006cbd's hyper parameters: Current learning rate is 0.005447216472382613. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 54912/60000][Iteration 4181][Wall Clock 408.137596279s] Trained 128 records in 0.090366507 seconds. Throughput is 1416.454 records/second. Loss is 0.17834155. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054466230936819175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 55040/60000][Iteration 4182][Wall Clock 408.215057631s] Trained 128 records in 0.077461352 seconds. Throughput is 1652.4369 records/second. Loss is 0.23932599. Sequential31006cbd's hyper parameters: Current learning rate is 0.005446029844243546. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 55168/60000][Iteration 4183][Wall Clock 408.291155929s] Trained 128 records in 0.076098298 seconds. Throughput is 1682.0349 records/second. Loss is 0.26149508. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054454367240252665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:25 INFO  DistriOptimizer$:408 - [Epoch 9 55296/60000][Iteration 4184][Wall Clock 408.365451193s] Trained 128 records in 0.074295264 seconds. Throughput is 1722.8553 records/second. Loss is 0.25049412. Sequential31006cbd's hyper parameters: Current learning rate is 0.005444843732984863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 55424/60000][Iteration 4185][Wall Clock 408.453313082s] Trained 128 records in 0.087861889 seconds. Throughput is 1456.8319 records/second. Loss is 0.2312729. Sequential31006cbd's hyper parameters: Current learning rate is 0.00544425087108014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 55552/60000][Iteration 4186][Wall Clock 408.533997937s] Trained 128 records in 0.080684855 seconds. Throughput is 1586.4192 records/second. Loss is 0.19127548. Sequential31006cbd's hyper parameters: Current learning rate is 0.005443658138268916. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 55680/60000][Iteration 4187][Wall Clock 408.606734005s] Trained 128 records in 0.072736068 seconds. Throughput is 1759.7871 records/second. Loss is 0.19858132. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054430655345090355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 55808/60000][Iteration 4188][Wall Clock 408.682305955s] Trained 128 records in 0.07557195 seconds. Throughput is 1693.7502 records/second. Loss is 0.26731288. Sequential31006cbd's hyper parameters: Current learning rate is 0.005442473059758354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 55936/60000][Iteration 4189][Wall Clock 408.759974978s] Trained 128 records in 0.077669023 seconds. Throughput is 1648.0187 records/second. Loss is 0.23672235. Sequential31006cbd's hyper parameters: Current learning rate is 0.00544188071397475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56064/60000][Iteration 4190][Wall Clock 408.832844904s] Trained 128 records in 0.072869926 seconds. Throughput is 1756.5546 records/second. Loss is 0.24892326. Sequential31006cbd's hyper parameters: Current learning rate is 0.005441288497116117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56192/60000][Iteration 4191][Wall Clock 408.913578999s] Trained 128 records in 0.080734095 seconds. Throughput is 1585.4515 records/second. Loss is 0.2524433. Sequential31006cbd's hyper parameters: Current learning rate is 0.00544069640914037. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56320/60000][Iteration 4192][Wall Clock 408.992840608s] Trained 128 records in 0.079261609 seconds. Throughput is 1614.9054 records/second. Loss is 0.20011072. Sequential31006cbd's hyper parameters: Current learning rate is 0.00544010445000544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56448/60000][Iteration 4193][Wall Clock 409.069815846s] Trained 128 records in 0.076975238 seconds. Throughput is 1662.8723 records/second. Loss is 0.20150174. Sequential31006cbd's hyper parameters: Current learning rate is 0.005439512619669277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56576/60000][Iteration 4194][Wall Clock 409.176546843s] Trained 128 records in 0.106730997 seconds. Throughput is 1199.2767 records/second. Loss is 0.1673148. Sequential31006cbd's hyper parameters: Current learning rate is 0.005438920918089851. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56704/60000][Iteration 4195][Wall Clock 409.271042525s] Trained 128 records in 0.094495682 seconds. Throughput is 1354.5592 records/second. Loss is 0.32306728. Sequential31006cbd's hyper parameters: Current learning rate is 0.005438329345225147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:26 INFO  DistriOptimizer$:408 - [Epoch 9 56832/60000][Iteration 4196][Wall Clock 409.353189582s] Trained 128 records in 0.082147057 seconds. Throughput is 1558.1813 records/second. Loss is 0.13437991. Sequential31006cbd's hyper parameters: Current learning rate is 0.005437737901033171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 56960/60000][Iteration 4197][Wall Clock 409.427332661s] Trained 128 records in 0.074143079 seconds. Throughput is 1726.3917 records/second. Loss is 0.21779494. Sequential31006cbd's hyper parameters: Current learning rate is 0.005437146585471945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57088/60000][Iteration 4198][Wall Clock 409.502786729s] Trained 128 records in 0.075454068 seconds. Throughput is 1696.3962 records/second. Loss is 0.23269536. Sequential31006cbd's hyper parameters: Current learning rate is 0.005436555398499511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57216/60000][Iteration 4199][Wall Clock 409.579505463s] Trained 128 records in 0.076718734 seconds. Throughput is 1668.4321 records/second. Loss is 0.28673267. Sequential31006cbd's hyper parameters: Current learning rate is 0.00543596434007393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57344/60000][Iteration 4200][Wall Clock 409.661362254s] Trained 128 records in 0.081856791 seconds. Throughput is 1563.7064 records/second. Loss is 0.28026626. Sequential31006cbd's hyper parameters: Current learning rate is 0.005435373410153278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57472/60000][Iteration 4201][Wall Clock 409.745004873s] Trained 128 records in 0.083642619 seconds. Throughput is 1530.3203 records/second. Loss is 0.26154968. Sequential31006cbd's hyper parameters: Current learning rate is 0.005434782608695652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57600/60000][Iteration 4202][Wall Clock 409.824480336s] Trained 128 records in 0.079475463 seconds. Throughput is 1610.5599 records/second. Loss is 0.15372983. Sequential31006cbd's hyper parameters: Current learning rate is 0.005434191935659167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57728/60000][Iteration 4203][Wall Clock 409.900378918s] Trained 128 records in 0.075898582 seconds. Throughput is 1686.461 records/second. Loss is 0.19855492. Sequential31006cbd's hyper parameters: Current learning rate is 0.005433601391001956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57856/60000][Iteration 4204][Wall Clock 409.976512576s] Trained 128 records in 0.076133658 seconds. Throughput is 1681.2537 records/second. Loss is 0.21312517. Sequential31006cbd's hyper parameters: Current learning rate is 0.005433010974682169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 57984/60000][Iteration 4205][Wall Clock 410.053298624s] Trained 128 records in 0.076786048 seconds. Throughput is 1666.9695 records/second. Loss is 0.13851106. Sequential31006cbd's hyper parameters: Current learning rate is 0.005432420686657975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 58112/60000][Iteration 4206][Wall Clock 410.131691825s] Trained 128 records in 0.078393201 seconds. Throughput is 1632.7947 records/second. Loss is 0.26703036. Sequential31006cbd's hyper parameters: Current learning rate is 0.005431830526887561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 58240/60000][Iteration 4207][Wall Clock 410.206578458s] Trained 128 records in 0.074886633 seconds. Throughput is 1709.2502 records/second. Loss is 0.14983903. Sequential31006cbd's hyper parameters: Current learning rate is 0.005431240495329133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:27 INFO  DistriOptimizer$:408 - [Epoch 9 58368/60000][Iteration 4208][Wall Clock 410.282791773s] Trained 128 records in 0.076213315 seconds. Throughput is 1679.4966 records/second. Loss is 0.24088219. Sequential31006cbd's hyper parameters: Current learning rate is 0.005430650591940914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 58496/60000][Iteration 4209][Wall Clock 410.361726325s] Trained 128 records in 0.078934552 seconds. Throughput is 1621.5967 records/second. Loss is 0.2311195. Sequential31006cbd's hyper parameters: Current learning rate is 0.005430060816681147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 58624/60000][Iteration 4210][Wall Clock 410.468785874s] Trained 128 records in 0.107059549 seconds. Throughput is 1195.5963 records/second. Loss is 0.21260807. Sequential31006cbd's hyper parameters: Current learning rate is 0.00542947116950809. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 58752/60000][Iteration 4211][Wall Clock 410.565287271s] Trained 128 records in 0.096501397 seconds. Throughput is 1326.4056 records/second. Loss is 0.20547903. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054288816503800215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 58880/60000][Iteration 4212][Wall Clock 410.642276223s] Trained 128 records in 0.076988952 seconds. Throughput is 1662.5763 records/second. Loss is 0.15166995. Sequential31006cbd's hyper parameters: Current learning rate is 0.005428292259255238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59008/60000][Iteration 4213][Wall Clock 410.72749007s] Trained 128 records in 0.085213847 seconds. Throughput is 1502.1033 records/second. Loss is 0.22072884. Sequential31006cbd's hyper parameters: Current learning rate is 0.005427702996092054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59136/60000][Iteration 4214][Wall Clock 410.810713242s] Trained 128 records in 0.083223172 seconds. Throughput is 1538.0332 records/second. Loss is 0.18332593. Sequential31006cbd's hyper parameters: Current learning rate is 0.005427113860848801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59264/60000][Iteration 4215][Wall Clock 410.884589399s] Trained 128 records in 0.073876157 seconds. Throughput is 1732.6294 records/second. Loss is 0.21876839. Sequential31006cbd's hyper parameters: Current learning rate is 0.005426524853483829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59392/60000][Iteration 4216][Wall Clock 410.972406302s] Trained 128 records in 0.087816903 seconds. Throughput is 1457.5782 records/second. Loss is 0.23164311. Sequential31006cbd's hyper parameters: Current learning rate is 0.005425935973955507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59520/60000][Iteration 4217][Wall Clock 411.049924518s] Trained 128 records in 0.077518216 seconds. Throughput is 1651.2247 records/second. Loss is 0.26478687. Sequential31006cbd's hyper parameters: Current learning rate is 0.005425347222222223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59648/60000][Iteration 4218][Wall Clock 411.125376187s] Trained 128 records in 0.075451669 seconds. Throughput is 1696.4502 records/second. Loss is 0.2725679. Sequential31006cbd's hyper parameters: Current learning rate is 0.005424758598242378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59776/60000][Iteration 4219][Wall Clock 411.206222817s] Trained 128 records in 0.08084663 seconds. Throughput is 1583.2448 records/second. Loss is 0.190268. Sequential31006cbd's hyper parameters: Current learning rate is 0.005424170101974398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:28 INFO  DistriOptimizer$:408 - [Epoch 9 59904/60000][Iteration 4220][Wall Clock 411.28730529s] Trained 128 records in 0.081082473 seconds. Throughput is 1578.6396 records/second. Loss is 0.17494303. Sequential31006cbd's hyper parameters: Current learning rate is 0.005423581733376722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:29 INFO  DistriOptimizer$:408 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 411.361303464s] Trained 128 records in 0.073998174 seconds. Throughput is 1729.7723 records/second. Loss is 0.12950505. Sequential31006cbd's hyper parameters: Current learning rate is 0.005422993492407809. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:29 INFO  DistriOptimizer$:452 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 411.361303464s] Epoch finished. Wall clock time is 412533.45273 ms
2019-10-24 00:04:29 INFO  DistriOptimizer$:111 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 411.361303464s] Validate model...
2019-10-24 00:04:29 INFO  DistriOptimizer$:178 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 411.361303464s] validate model throughput is 12071.82 records/second
2019-10-24 00:04:29 INFO  DistriOptimizer$:181 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 411.361303464s] Top1Accuracy is Accuracy(correct: 9426, count: 10000, accuracy: 0.9426)
2019-10-24 00:04:29 INFO  DistriOptimizer$:221 - [Wall Clock 412.53345273s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:04:29 INFO  DistriOptimizer$:226 - [Wall Clock 412.53345273s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:04:29 INFO  DistriOptimizer$:408 - [Epoch 10 128/60000][Iteration 4222][Wall Clock 412.620646244s] Trained 128 records in 0.087193514 seconds. Throughput is 1467.9991 records/second. Loss is 0.27772027. Sequential31006cbd's hyper parameters: Current learning rate is 0.005422405379026136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 256/60000][Iteration 4223][Wall Clock 412.703709205s] Trained 128 records in 0.083062961 seconds. Throughput is 1540.9998 records/second. Loss is 0.21734963. Sequential31006cbd's hyper parameters: Current learning rate is 0.005421817393190197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 384/60000][Iteration 4224][Wall Clock 412.792038982s] Trained 128 records in 0.088329777 seconds. Throughput is 1449.115 records/second. Loss is 0.1678762. Sequential31006cbd's hyper parameters: Current learning rate is 0.005421229534858506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 512/60000][Iteration 4225][Wall Clock 412.87682992s] Trained 128 records in 0.084790938 seconds. Throughput is 1509.5953 records/second. Loss is 0.22324827. Sequential31006cbd's hyper parameters: Current learning rate is 0.005420641803989592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 640/60000][Iteration 4226][Wall Clock 412.956842071s] Trained 128 records in 0.080012151 seconds. Throughput is 1599.7571 records/second. Loss is 0.41965422. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054200542005420045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 768/60000][Iteration 4227][Wall Clock 413.035545586s] Trained 128 records in 0.078703515 seconds. Throughput is 1626.3568 records/second. Loss is 0.103297725. Sequential31006cbd's hyper parameters: Current learning rate is 0.005419466724474312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 896/60000][Iteration 4228][Wall Clock 413.114395918s] Trained 128 records in 0.078850332 seconds. Throughput is 1623.3287 records/second. Loss is 0.21075052. Sequential31006cbd's hyper parameters: Current learning rate is 0.005418879375745095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 1024/60000][Iteration 4229][Wall Clock 413.188834451s] Trained 128 records in 0.074438533 seconds. Throughput is 1719.5396 records/second. Loss is 0.13678475. Sequential31006cbd's hyper parameters: Current learning rate is 0.00541829215431296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 1152/60000][Iteration 4230][Wall Clock 413.265722187s] Trained 128 records in 0.076887736 seconds. Throughput is 1664.7649 records/second. Loss is 0.12484967. Sequential31006cbd's hyper parameters: Current learning rate is 0.005417705060136526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 1280/60000][Iteration 4231][Wall Clock 413.352939258s] Trained 128 records in 0.087217071 seconds. Throughput is 1467.6027 records/second. Loss is 0.15277928. Sequential31006cbd's hyper parameters: Current learning rate is 0.005417118093174431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 1408/60000][Iteration 4232][Wall Clock 413.442534441s] Trained 128 records in 0.089595183 seconds. Throughput is 1428.6482 records/second. Loss is 0.1992151. Sequential31006cbd's hyper parameters: Current learning rate is 0.005416531253385332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 1536/60000][Iteration 4233][Wall Clock 413.527079458s] Trained 128 records in 0.084545017 seconds. Throughput is 1513.9863 records/second. Loss is 0.31209546. Sequential31006cbd's hyper parameters: Current learning rate is 0.005415944540727903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:30 INFO  DistriOptimizer$:408 - [Epoch 10 1664/60000][Iteration 4234][Wall Clock 413.609582346s] Trained 128 records in 0.082502888 seconds. Throughput is 1551.4608 records/second. Loss is 0.18845092. Sequential31006cbd's hyper parameters: Current learning rate is 0.005415357955160836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 1792/60000][Iteration 4235][Wall Clock 413.696384349s] Trained 128 records in 0.086802003 seconds. Throughput is 1474.6204 records/second. Loss is 0.18001759. Sequential31006cbd's hyper parameters: Current learning rate is 0.005414771496642842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 1920/60000][Iteration 4236][Wall Clock 413.775455732s] Trained 128 records in 0.079071383 seconds. Throughput is 1618.7905 records/second. Loss is 0.13418065. Sequential31006cbd's hyper parameters: Current learning rate is 0.005414185165132647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2048/60000][Iteration 4237][Wall Clock 413.859297923s] Trained 128 records in 0.083842191 seconds. Throughput is 1526.6777 records/second. Loss is 0.3184223. Sequential31006cbd's hyper parameters: Current learning rate is 0.005413598960589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2176/60000][Iteration 4238][Wall Clock 413.939498127s] Trained 128 records in 0.080200204 seconds. Throughput is 1596.006 records/second. Loss is 0.22173008. Sequential31006cbd's hyper parameters: Current learning rate is 0.005413012882970662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2304/60000][Iteration 4239][Wall Clock 414.019563746s] Trained 128 records in 0.080065619 seconds. Throughput is 1598.6887 records/second. Loss is 0.14169928. Sequential31006cbd's hyper parameters: Current learning rate is 0.005412426932236415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2432/60000][Iteration 4240][Wall Clock 414.097401525s] Trained 128 records in 0.077837779 seconds. Throughput is 1644.4457 records/second. Loss is 0.16409898. Sequential31006cbd's hyper parameters: Current learning rate is 0.005411841108345059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2560/60000][Iteration 4241][Wall Clock 414.175055251s] Trained 128 records in 0.077653726 seconds. Throughput is 1648.3433 records/second. Loss is 0.17694145. Sequential31006cbd's hyper parameters: Current learning rate is 0.005411255411255411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2688/60000][Iteration 4242][Wall Clock 414.253133536s] Trained 128 records in 0.078078285 seconds. Throughput is 1639.3802 records/second. Loss is 0.27757755. Sequential31006cbd's hyper parameters: Current learning rate is 0.005410669840926307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2816/60000][Iteration 4243][Wall Clock 414.329994808s] Trained 128 records in 0.076861272 seconds. Throughput is 1665.3381 records/second. Loss is 0.18789962. Sequential31006cbd's hyper parameters: Current learning rate is 0.005410084397316598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 2944/60000][Iteration 4244][Wall Clock 414.424877834s] Trained 128 records in 0.094883026 seconds. Throughput is 1349.0295 records/second. Loss is 0.33314496. Sequential31006cbd's hyper parameters: Current learning rate is 0.005409499080385157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 3072/60000][Iteration 4245][Wall Clock 414.516575428s] Trained 128 records in 0.091697594 seconds. Throughput is 1395.8927 records/second. Loss is 0.124729484. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054089138900908695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:31 INFO  DistriOptimizer$:408 - [Epoch 10 3200/60000][Iteration 4246][Wall Clock 414.597762019s] Trained 128 records in 0.081186591 seconds. Throughput is 1576.615 records/second. Loss is 0.2332517. Sequential31006cbd's hyper parameters: Current learning rate is 0.005408328826392644. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 3328/60000][Iteration 4247][Wall Clock 414.681945254s] Trained 128 records in 0.084183235 seconds. Throughput is 1520.4927 records/second. Loss is 0.29077145. Sequential31006cbd's hyper parameters: Current learning rate is 0.005407743889249405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 3456/60000][Iteration 4248][Wall Clock 414.756299237s] Trained 128 records in 0.074353983 seconds. Throughput is 1721.4948 records/second. Loss is 0.16688943. Sequential31006cbd's hyper parameters: Current learning rate is 0.005407159078620093. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 3584/60000][Iteration 4249][Wall Clock 414.840732965s] Trained 128 records in 0.084433728 seconds. Throughput is 1515.9819 records/second. Loss is 0.14380461. Sequential31006cbd's hyper parameters: Current learning rate is 0.005406574394463667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 3712/60000][Iteration 4250][Wall Clock 414.927420183s] Trained 128 records in 0.086687218 seconds. Throughput is 1476.573 records/second. Loss is 0.18967348. Sequential31006cbd's hyper parameters: Current learning rate is 0.005405989836739107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 3840/60000][Iteration 4251][Wall Clock 415.009955698s] Trained 128 records in 0.082535515 seconds. Throughput is 1550.8475 records/second. Loss is 0.2253243. Sequential31006cbd's hyper parameters: Current learning rate is 0.005405405405405405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 3968/60000][Iteration 4252][Wall Clock 415.087322087s] Trained 128 records in 0.077366389 seconds. Throughput is 1654.4652 records/second. Loss is 0.33275923. Sequential31006cbd's hyper parameters: Current learning rate is 0.005404821100421576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 4096/60000][Iteration 4253][Wall Clock 415.169506815s] Trained 128 records in 0.082184728 seconds. Throughput is 1557.467 records/second. Loss is 0.14788054. Sequential31006cbd's hyper parameters: Current learning rate is 0.005404236921746649. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 4224/60000][Iteration 4254][Wall Clock 415.246156906s] Trained 128 records in 0.076650091 seconds. Throughput is 1669.9263 records/second. Loss is 0.2259647. Sequential31006cbd's hyper parameters: Current learning rate is 0.005403652869339673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 4352/60000][Iteration 4255][Wall Clock 415.323662383s] Trained 128 records in 0.077505477 seconds. Throughput is 1651.4962 records/second. Loss is 0.21677533. Sequential31006cbd's hyper parameters: Current learning rate is 0.005403068943159715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 4480/60000][Iteration 4256][Wall Clock 415.397739399s] Trained 128 records in 0.074077016 seconds. Throughput is 1727.9314 records/second. Loss is 0.18523178. Sequential31006cbd's hyper parameters: Current learning rate is 0.005402485143165856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 4608/60000][Iteration 4257][Wall Clock 415.47678035s] Trained 128 records in 0.079040951 seconds. Throughput is 1619.4137 records/second. Loss is 0.19032803. Sequential31006cbd's hyper parameters: Current learning rate is 0.0054019014693172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:32 INFO  DistriOptimizer$:408 - [Epoch 10 4736/60000][Iteration 4258][Wall Clock 415.55037199s] Trained 128 records in 0.07359164 seconds. Throughput is 1739.328 records/second. Loss is 0.24163663. Sequential31006cbd's hyper parameters: Current learning rate is 0.005401317921572864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 4864/60000][Iteration 4259][Wall Clock 415.634104704s] Trained 128 records in 0.083732714 seconds. Throughput is 1528.6737 records/second. Loss is 0.20135432. Sequential31006cbd's hyper parameters: Current learning rate is 0.005400734499891985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 4992/60000][Iteration 4260][Wall Clock 415.717718206s] Trained 128 records in 0.083613502 seconds. Throughput is 1530.8533 records/second. Loss is 0.14898062. Sequential31006cbd's hyper parameters: Current learning rate is 0.005400151204233719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5120/60000][Iteration 4261][Wall Clock 415.795392352s] Trained 128 records in 0.077674146 seconds. Throughput is 1647.91 records/second. Loss is 0.22172302. Sequential31006cbd's hyper parameters: Current learning rate is 0.005399568034557235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5248/60000][Iteration 4262][Wall Clock 415.872323242s] Trained 128 records in 0.07693089 seconds. Throughput is 1663.831 records/second. Loss is 0.1348979. Sequential31006cbd's hyper parameters: Current learning rate is 0.005398984990821726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5376/60000][Iteration 4263][Wall Clock 415.951500587s] Trained 128 records in 0.079177345 seconds. Throughput is 1616.6241 records/second. Loss is 0.20605072. Sequential31006cbd's hyper parameters: Current learning rate is 0.005398402072986396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5504/60000][Iteration 4264][Wall Clock 416.030816729s] Trained 128 records in 0.079316142 seconds. Throughput is 1613.7952 records/second. Loss is 0.2989695. Sequential31006cbd's hyper parameters: Current learning rate is 0.005397819281010472. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5632/60000][Iteration 4265][Wall Clock 416.132769577s] Trained 128 records in 0.101952848 seconds. Throughput is 1255.4823 records/second. Loss is 0.3323386. Sequential31006cbd's hyper parameters: Current learning rate is 0.005397236614853195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5760/60000][Iteration 4266][Wall Clock 416.230345626s] Trained 128 records in 0.097576049 seconds. Throughput is 1311.7972 records/second. Loss is 0.16702588. Sequential31006cbd's hyper parameters: Current learning rate is 0.005396654074473825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 5888/60000][Iteration 4267][Wall Clock 416.31368139s] Trained 128 records in 0.083335764 seconds. Throughput is 1535.9552 records/second. Loss is 0.20574039. Sequential31006cbd's hyper parameters: Current learning rate is 0.005396071659831642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 6016/60000][Iteration 4268][Wall Clock 416.391859052s] Trained 128 records in 0.078177662 seconds. Throughput is 1637.2964 records/second. Loss is 0.2504859. Sequential31006cbd's hyper parameters: Current learning rate is 0.005395489370885939. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 6144/60000][Iteration 4269][Wall Clock 416.475417763s] Trained 128 records in 0.083558711 seconds. Throughput is 1531.857 records/second. Loss is 0.25555402. Sequential31006cbd's hyper parameters: Current learning rate is 0.005394907207596029. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:33 INFO  DistriOptimizer$:408 - [Epoch 10 6272/60000][Iteration 4270][Wall Clock 416.55343916s] Trained 128 records in 0.078021397 seconds. Throughput is 1640.5756 records/second. Loss is 0.16526255. Sequential31006cbd's hyper parameters: Current learning rate is 0.005394325169921243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 6400/60000][Iteration 4271][Wall Clock 416.640006494s] Trained 128 records in 0.086567334 seconds. Throughput is 1478.6178 records/second. Loss is 0.20359278. Sequential31006cbd's hyper parameters: Current learning rate is 0.005393743257820927. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 6528/60000][Iteration 4272][Wall Clock 416.721916346s] Trained 128 records in 0.081909852 seconds. Throughput is 1562.6936 records/second. Loss is 0.21630666. Sequential31006cbd's hyper parameters: Current learning rate is 0.005393161471254449. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 6656/60000][Iteration 4273][Wall Clock 416.800087015s] Trained 128 records in 0.078170669 seconds. Throughput is 1637.4427 records/second. Loss is 0.15603623. Sequential31006cbd's hyper parameters: Current learning rate is 0.005392579810181191. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 6784/60000][Iteration 4274][Wall Clock 416.879978533s] Trained 128 records in 0.079891518 seconds. Throughput is 1602.1726 records/second. Loss is 0.23044589. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053919982745605525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 6912/60000][Iteration 4275][Wall Clock 416.961602253s] Trained 128 records in 0.08162372 seconds. Throughput is 1568.1716 records/second. Loss is 0.31698895. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053914168643519516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 7040/60000][Iteration 4276][Wall Clock 417.041001629s] Trained 128 records in 0.079399376 seconds. Throughput is 1612.1033 records/second. Loss is 0.2838109. Sequential31006cbd's hyper parameters: Current learning rate is 0.005390835579514825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 7168/60000][Iteration 4277][Wall Clock 417.119262842s] Trained 128 records in 0.078261213 seconds. Throughput is 1635.5485 records/second. Loss is 0.26009008. Sequential31006cbd's hyper parameters: Current learning rate is 0.005390254420008625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 7296/60000][Iteration 4278][Wall Clock 417.205902456s] Trained 128 records in 0.086639614 seconds. Throughput is 1477.3843 records/second. Loss is 0.34844378. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053896733857928215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 7424/60000][Iteration 4279][Wall Clock 417.300979958s] Trained 128 records in 0.095077502 seconds. Throughput is 1346.2701 records/second. Loss is 0.15703227. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053890924768269025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 7552/60000][Iteration 4280][Wall Clock 417.401244615s] Trained 128 records in 0.100264657 seconds. Throughput is 1276.6213 records/second. Loss is 0.19528022. Sequential31006cbd's hyper parameters: Current learning rate is 0.005388511693070374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:34 INFO  DistriOptimizer$:408 - [Epoch 10 7680/60000][Iteration 4281][Wall Clock 417.500337431s] Trained 128 records in 0.099092816 seconds. Throughput is 1291.7183 records/second. Loss is 0.16720329. Sequential31006cbd's hyper parameters: Current learning rate is 0.005387931034482758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 7808/60000][Iteration 4282][Wall Clock 417.603845938s] Trained 128 records in 0.103508507 seconds. Throughput is 1236.6133 records/second. Loss is 0.24720725. Sequential31006cbd's hyper parameters: Current learning rate is 0.005387350501023597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 7936/60000][Iteration 4283][Wall Clock 417.705334537s] Trained 128 records in 0.101488599 seconds. Throughput is 1261.2255 records/second. Loss is 0.26054692. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053867700926524455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8064/60000][Iteration 4284][Wall Clock 417.811245107s] Trained 128 records in 0.10591057 seconds. Throughput is 1208.5668 records/second. Loss is 0.22260559. Sequential31006cbd's hyper parameters: Current learning rate is 0.00538618980932888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8192/60000][Iteration 4285][Wall Clock 417.914285483s] Trained 128 records in 0.103040376 seconds. Throughput is 1242.2314 records/second. Loss is 0.24802865. Sequential31006cbd's hyper parameters: Current learning rate is 0.005385609651012494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8320/60000][Iteration 4286][Wall Clock 418.020178676s] Trained 128 records in 0.105893193 seconds. Throughput is 1208.7651 records/second. Loss is 0.42379546. Sequential31006cbd's hyper parameters: Current learning rate is 0.005385029617662897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8448/60000][Iteration 4287][Wall Clock 418.124055561s] Trained 128 records in 0.103876885 seconds. Throughput is 1232.228 records/second. Loss is 0.16122511. Sequential31006cbd's hyper parameters: Current learning rate is 0.005384449709239715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8576/60000][Iteration 4288][Wall Clock 418.214801841s] Trained 128 records in 0.09074628 seconds. Throughput is 1410.5261 records/second. Loss is 0.15298955. Sequential31006cbd's hyper parameters: Current learning rate is 0.005383869925702595. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8704/60000][Iteration 4289][Wall Clock 418.298369971s] Trained 128 records in 0.08356813 seconds. Throughput is 1531.6843 records/second. Loss is 0.2598383. Sequential31006cbd's hyper parameters: Current learning rate is 0.005383290267011197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8832/60000][Iteration 4290][Wall Clock 418.375126922s] Trained 128 records in 0.076756951 seconds. Throughput is 1667.6013 records/second. Loss is 0.21185267. Sequential31006cbd's hyper parameters: Current learning rate is 0.005382710733125202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 8960/60000][Iteration 4291][Wall Clock 418.451754705s] Trained 128 records in 0.076627783 seconds. Throughput is 1670.4124 records/second. Loss is 0.23750855. Sequential31006cbd's hyper parameters: Current learning rate is 0.005382131324004305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:35 INFO  DistriOptimizer$:408 - [Epoch 10 9088/60000][Iteration 4292][Wall Clock 418.540432987s] Trained 128 records in 0.088678282 seconds. Throughput is 1443.4199 records/second. Loss is 0.25458306. Sequential31006cbd's hyper parameters: Current learning rate is 0.005381552039608223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9216/60000][Iteration 4293][Wall Clock 418.616536395s] Trained 128 records in 0.076103408 seconds. Throughput is 1681.922 records/second. Loss is 0.15001921. Sequential31006cbd's hyper parameters: Current learning rate is 0.005380972879896685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9344/60000][Iteration 4294][Wall Clock 418.69468855s] Trained 128 records in 0.078152155 seconds. Throughput is 1637.8307 records/second. Loss is 0.22368506. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053803938448294415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9472/60000][Iteration 4295][Wall Clock 418.798696551s] Trained 128 records in 0.104008001 seconds. Throughput is 1230.6746 records/second. Loss is 0.20033708. Sequential31006cbd's hyper parameters: Current learning rate is 0.005379814934366258. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9600/60000][Iteration 4296][Wall Clock 418.876266487s] Trained 128 records in 0.077569936 seconds. Throughput is 1650.1238 records/second. Loss is 0.17443931. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053792361484669175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9728/60000][Iteration 4297][Wall Clock 418.952132837s] Trained 128 records in 0.07586635 seconds. Throughput is 1687.1775 records/second. Loss is 0.3188492. Sequential31006cbd's hyper parameters: Current learning rate is 0.005378657487091223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9856/60000][Iteration 4298][Wall Clock 419.029004109s] Trained 128 records in 0.076871272 seconds. Throughput is 1665.1215 records/second. Loss is 0.15285388. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053780789501989895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 9984/60000][Iteration 4299][Wall Clock 419.10892385s] Trained 128 records in 0.079919741 seconds. Throughput is 1601.6068 records/second. Loss is 0.24649295. Sequential31006cbd's hyper parameters: Current learning rate is 0.005377500537750054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 10112/60000][Iteration 4300][Wall Clock 419.185478385s] Trained 128 records in 0.076554535 seconds. Throughput is 1672.0106 records/second. Loss is 0.17475227. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053769222497042695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 10240/60000][Iteration 4301][Wall Clock 419.264827945s] Trained 128 records in 0.07934956 seconds. Throughput is 1613.1154 records/second. Loss is 0.18600455. Sequential31006cbd's hyper parameters: Current learning rate is 0.005376344086021506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 10368/60000][Iteration 4302][Wall Clock 419.345855493s] Trained 128 records in 0.081027548 seconds. Throughput is 1579.7097 records/second. Loss is 0.15095642. Sequential31006cbd's hyper parameters: Current learning rate is 0.005375766046661649. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 10496/60000][Iteration 4303][Wall Clock 419.428942202s] Trained 128 records in 0.083086709 seconds. Throughput is 1540.5593 records/second. Loss is 0.3360174. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053751881315846056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 10624/60000][Iteration 4304][Wall Clock 419.510756003s] Trained 128 records in 0.081813801 seconds. Throughput is 1564.5283 records/second. Loss is 0.1722163. Sequential31006cbd's hyper parameters: Current learning rate is 0.005374610340750295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:36 INFO  DistriOptimizer$:408 - [Epoch 10 10752/60000][Iteration 4305][Wall Clock 419.58941209s] Trained 128 records in 0.078656087 seconds. Throughput is 1627.3375 records/second. Loss is 0.15988131. Sequential31006cbd's hyper parameters: Current learning rate is 0.005374032674118658. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 10880/60000][Iteration 4306][Wall Clock 419.667694153s] Trained 128 records in 0.078282063 seconds. Throughput is 1635.1127 records/second. Loss is 0.16920945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053734551316496505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11008/60000][Iteration 4307][Wall Clock 419.744723644s] Trained 128 records in 0.077029491 seconds. Throughput is 1661.7013 records/second. Loss is 0.20890413. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053728777133032445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11136/60000][Iteration 4308][Wall Clock 419.826696342s] Trained 128 records in 0.081972698 seconds. Throughput is 1561.4956 records/second. Loss is 0.2883339. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053723004190394325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11264/60000][Iteration 4309][Wall Clock 419.902104462s] Trained 128 records in 0.07540812 seconds. Throughput is 1697.4298 records/second. Loss is 0.3890431. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053717232488182205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11392/60000][Iteration 4310][Wall Clock 419.983454345s] Trained 128 records in 0.081349883 seconds. Throughput is 1573.4504 records/second. Loss is 0.12220158. Sequential31006cbd's hyper parameters: Current learning rate is 0.005371146202599634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11520/60000][Iteration 4311][Wall Clock 420.079187491s] Trained 128 records in 0.095733146 seconds. Throughput is 1337.05 records/second. Loss is 0.20834118. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053705692803437165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11648/60000][Iteration 4312][Wall Clock 420.163832845s] Trained 128 records in 0.084645354 seconds. Throughput is 1512.1917 records/second. Loss is 0.21557009. Sequential31006cbd's hyper parameters: Current learning rate is 0.005369992482010525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11776/60000][Iteration 4313][Wall Clock 420.244066897s] Trained 128 records in 0.080234052 seconds. Throughput is 1595.3326 records/second. Loss is 0.20910758. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053694158075601375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 11904/60000][Iteration 4314][Wall Clock 420.32712971s] Trained 128 records in 0.083062813 seconds. Throughput is 1541.0024 records/second. Loss is 0.24131241. Sequential31006cbd's hyper parameters: Current learning rate is 0.005368839256952647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 12032/60000][Iteration 4315][Wall Clock 420.404915948s] Trained 128 records in 0.077786238 seconds. Throughput is 1645.5353 records/second. Loss is 0.14949429. Sequential31006cbd's hyper parameters: Current learning rate is 0.005368262830148164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 12160/60000][Iteration 4316][Wall Clock 420.479837708s] Trained 128 records in 0.07492176 seconds. Throughput is 1708.449 records/second. Loss is 0.32567155. Sequential31006cbd's hyper parameters: Current learning rate is 0.005367686527106817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:37 INFO  DistriOptimizer$:408 - [Epoch 10 12288/60000][Iteration 4317][Wall Clock 420.559810107s] Trained 128 records in 0.079972399 seconds. Throughput is 1600.5521 records/second. Loss is 0.19567862. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053671103477887505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 12416/60000][Iteration 4318][Wall Clock 420.6344678s] Trained 128 records in 0.074657693 seconds. Throughput is 1714.4917 records/second. Loss is 0.24750853. Sequential31006cbd's hyper parameters: Current learning rate is 0.005366534292154127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 12544/60000][Iteration 4319][Wall Clock 420.709262915s] Trained 128 records in 0.074795115 seconds. Throughput is 1711.3418 records/second. Loss is 0.24102552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053659583601631256. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 12672/60000][Iteration 4320][Wall Clock 420.789285622s] Trained 128 records in 0.080022707 seconds. Throughput is 1599.546 records/second. Loss is 0.21347086. Sequential31006cbd's hyper parameters: Current learning rate is 0.005365382551775942. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 12800/60000][Iteration 4321][Wall Clock 420.876934604s] Trained 128 records in 0.087648982 seconds. Throughput is 1460.3707 records/second. Loss is 0.14359432. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053648068669527905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 12928/60000][Iteration 4322][Wall Clock 420.951177022s] Trained 128 records in 0.074242418 seconds. Throughput is 1724.0817 records/second. Loss is 0.15495579. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053642313056538994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13056/60000][Iteration 4323][Wall Clock 421.031429198s] Trained 128 records in 0.080252176 seconds. Throughput is 1594.9723 records/second. Loss is 0.25071245. Sequential31006cbd's hyper parameters: Current learning rate is 0.005363655867839519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13184/60000][Iteration 4324][Wall Clock 421.115942151s] Trained 128 records in 0.084512953 seconds. Throughput is 1514.5607 records/second. Loss is 0.22481441. Sequential31006cbd's hyper parameters: Current learning rate is 0.005363080553469913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13312/60000][Iteration 4325][Wall Clock 421.197018354s] Trained 128 records in 0.081076203 seconds. Throughput is 1578.7616 records/second. Loss is 0.18801026. Sequential31006cbd's hyper parameters: Current learning rate is 0.005362505362505363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13440/60000][Iteration 4326][Wall Clock 421.278387854s] Trained 128 records in 0.0813695 seconds. Throughput is 1573.071 records/second. Loss is 0.1708073. Sequential31006cbd's hyper parameters: Current learning rate is 0.005361930294906166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13568/60000][Iteration 4327][Wall Clock 421.3601379s] Trained 128 records in 0.081750046 seconds. Throughput is 1565.7484 records/second. Loss is 0.2301462. Sequential31006cbd's hyper parameters: Current learning rate is 0.005361355350632639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13696/60000][Iteration 4328][Wall Clock 421.437489575s] Trained 128 records in 0.077351675 seconds. Throughput is 1654.7799 records/second. Loss is 0.20135067. Sequential31006cbd's hyper parameters: Current learning rate is 0.005360780529645116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:38 INFO  DistriOptimizer$:408 - [Epoch 10 13824/60000][Iteration 4329][Wall Clock 421.513512159s] Trained 128 records in 0.076022584 seconds. Throughput is 1683.7101 records/second. Loss is 0.33134967. Sequential31006cbd's hyper parameters: Current learning rate is 0.005360205831903945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 13952/60000][Iteration 4330][Wall Clock 421.591658924s] Trained 128 records in 0.078146765 seconds. Throughput is 1637.9437 records/second. Loss is 0.22272773. Sequential31006cbd's hyper parameters: Current learning rate is 0.005359631257369493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14080/60000][Iteration 4331][Wall Clock 421.66757688s] Trained 128 records in 0.075917956 seconds. Throughput is 1686.0305 records/second. Loss is 0.298508. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053590568060021436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14208/60000][Iteration 4332][Wall Clock 421.752477064s] Trained 128 records in 0.084900184 seconds. Throughput is 1507.6528 records/second. Loss is 0.1762271. Sequential31006cbd's hyper parameters: Current learning rate is 0.005358482477762298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14336/60000][Iteration 4333][Wall Clock 421.831169011s] Trained 128 records in 0.078691947 seconds. Throughput is 1626.596 records/second. Loss is 0.19293219. Sequential31006cbd's hyper parameters: Current learning rate is 0.005357908272610373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14464/60000][Iteration 4334][Wall Clock 421.957282498s] Trained 128 records in 0.126113487 seconds. Throughput is 1014.95886 records/second. Loss is 0.30820537. Sequential31006cbd's hyper parameters: Current learning rate is 0.005357334190506804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14592/60000][Iteration 4335][Wall Clock 422.037625371s] Trained 128 records in 0.080342873 seconds. Throughput is 1593.1718 records/second. Loss is 0.22233894. Sequential31006cbd's hyper parameters: Current learning rate is 0.005356760231412042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14720/60000][Iteration 4336][Wall Clock 422.12052924s] Trained 128 records in 0.082903869 seconds. Throughput is 1543.9569 records/second. Loss is 0.21929857. Sequential31006cbd's hyper parameters: Current learning rate is 0.005356186395286556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14848/60000][Iteration 4337][Wall Clock 422.201092187s] Trained 128 records in 0.080562947 seconds. Throughput is 1588.8197 records/second. Loss is 0.13009813. Sequential31006cbd's hyper parameters: Current learning rate is 0.005355612682090832. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 14976/60000][Iteration 4338][Wall Clock 422.278760624s] Trained 128 records in 0.077668437 seconds. Throughput is 1648.0311 records/second. Loss is 0.24333611. Sequential31006cbd's hyper parameters: Current learning rate is 0.00535503909178537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 15104/60000][Iteration 4339][Wall Clock 422.357075948s] Trained 128 records in 0.078315324 seconds. Throughput is 1634.4183 records/second. Loss is 0.17372137. Sequential31006cbd's hyper parameters: Current learning rate is 0.005354465624330692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 15232/60000][Iteration 4340][Wall Clock 422.432873979s] Trained 128 records in 0.075798031 seconds. Throughput is 1688.6981 records/second. Loss is 0.2082178. Sequential31006cbd's hyper parameters: Current learning rate is 0.005353892279687333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:39 INFO  DistriOptimizer$:408 - [Epoch 10 15360/60000][Iteration 4341][Wall Clock 422.504147887s] Trained 128 records in 0.071273908 seconds. Throughput is 1795.8887 records/second. Loss is 0.27234298. Sequential31006cbd's hyper parameters: Current learning rate is 0.005353319057815846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 15488/60000][Iteration 4342][Wall Clock 422.582082427s] Trained 128 records in 0.07793454 seconds. Throughput is 1642.4039 records/second. Loss is 0.14198431. Sequential31006cbd's hyper parameters: Current learning rate is 0.005352745958676801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 15616/60000][Iteration 4343][Wall Clock 422.661955709s] Trained 128 records in 0.079873282 seconds. Throughput is 1602.5385 records/second. Loss is 0.2486345. Sequential31006cbd's hyper parameters: Current learning rate is 0.005352172982230786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 15744/60000][Iteration 4344][Wall Clock 422.74561647s] Trained 128 records in 0.083660761 seconds. Throughput is 1529.9885 records/second. Loss is 0.19701532. Sequential31006cbd's hyper parameters: Current learning rate is 0.005351600128438403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 15872/60000][Iteration 4345][Wall Clock 422.835033292s] Trained 128 records in 0.089416822 seconds. Throughput is 1431.4979 records/second. Loss is 0.21120265. Sequential31006cbd's hyper parameters: Current learning rate is 0.005351027397260274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16000/60000][Iteration 4346][Wall Clock 422.914711653s] Trained 128 records in 0.079678361 seconds. Throughput is 1606.4587 records/second. Loss is 0.12369809. Sequential31006cbd's hyper parameters: Current learning rate is 0.005350454788657036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16128/60000][Iteration 4347][Wall Clock 423.000650417s] Trained 128 records in 0.085938764 seconds. Throughput is 1489.4326 records/second. Loss is 0.26946065. Sequential31006cbd's hyper parameters: Current learning rate is 0.005349882302589343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16256/60000][Iteration 4348][Wall Clock 423.079140838s] Trained 128 records in 0.078490421 seconds. Throughput is 1630.7722 records/second. Loss is 0.21005231. Sequential31006cbd's hyper parameters: Current learning rate is 0.005349309939017866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16384/60000][Iteration 4349][Wall Clock 423.152154276s] Trained 128 records in 0.073013438 seconds. Throughput is 1753.1019 records/second. Loss is 0.19998428. Sequential31006cbd's hyper parameters: Current learning rate is 0.005348737697903294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16512/60000][Iteration 4350][Wall Clock 423.227780037s] Trained 128 records in 0.075625761 seconds. Throughput is 1692.5449 records/second. Loss is 0.123576656. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053481655792063315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16640/60000][Iteration 4351][Wall Clock 423.304951478s] Trained 128 records in 0.077171441 seconds. Throughput is 1658.6448 records/second. Loss is 0.24698004. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053475935828877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16768/60000][Iteration 4352][Wall Clock 423.380620108s] Trained 128 records in 0.07566863 seconds. Throughput is 1691.5859 records/second. Loss is 0.1598182. Sequential31006cbd's hyper parameters: Current learning rate is 0.005347021708908138. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 16896/60000][Iteration 4353][Wall Clock 423.4553561s] Trained 128 records in 0.074735992 seconds. Throughput is 1712.6956 records/second. Loss is 0.22254863. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053464499572284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:40 INFO  DistriOptimizer$:408 - [Epoch 10 17024/60000][Iteration 4354][Wall Clock 423.532846877s] Trained 128 records in 0.077490777 seconds. Throughput is 1651.8094 records/second. Loss is 0.16371223. Sequential31006cbd's hyper parameters: Current learning rate is 0.005345878327809259. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17152/60000][Iteration 4355][Wall Clock 423.61677103s] Trained 128 records in 0.083924153 seconds. Throughput is 1525.1866 records/second. Loss is 0.19364858. Sequential31006cbd's hyper parameters: Current learning rate is 0.005345306820611503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17280/60000][Iteration 4356][Wall Clock 423.703029994s] Trained 128 records in 0.086258964 seconds. Throughput is 1483.9038 records/second. Loss is 0.21755955. Sequential31006cbd's hyper parameters: Current learning rate is 0.005344735435595938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17408/60000][Iteration 4357][Wall Clock 423.783802667s] Trained 128 records in 0.080772673 seconds. Throughput is 1584.6943 records/second. Loss is 0.14740308. Sequential31006cbd's hyper parameters: Current learning rate is 0.005344164172723386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17536/60000][Iteration 4358][Wall Clock 423.877245173s] Trained 128 records in 0.093442506 seconds. Throughput is 1369.8263 records/second. Loss is 0.17902604. Sequential31006cbd's hyper parameters: Current learning rate is 0.005343593031954687. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17664/60000][Iteration 4359][Wall Clock 423.957042774s] Trained 128 records in 0.079797601 seconds. Throughput is 1604.0582 records/second. Loss is 0.1570612. Sequential31006cbd's hyper parameters: Current learning rate is 0.005343022013250695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17792/60000][Iteration 4360][Wall Clock 424.03771448s] Trained 128 records in 0.080671706 seconds. Throughput is 1586.6777 records/second. Loss is 0.20062435. Sequential31006cbd's hyper parameters: Current learning rate is 0.005342451116572284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 17920/60000][Iteration 4361][Wall Clock 424.116110119s] Trained 128 records in 0.078395639 seconds. Throughput is 1632.7438 records/second. Loss is 0.18384609. Sequential31006cbd's hyper parameters: Current learning rate is 0.005341880341880342. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 18048/60000][Iteration 4362][Wall Clock 424.193063734s] Trained 128 records in 0.076953615 seconds. Throughput is 1663.3397 records/second. Loss is 0.17362577. Sequential31006cbd's hyper parameters: Current learning rate is 0.005341309689135776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 18176/60000][Iteration 4363][Wall Clock 424.266972028s] Trained 128 records in 0.073908294 seconds. Throughput is 1731.8761 records/second. Loss is 0.20895329. Sequential31006cbd's hyper parameters: Current learning rate is 0.005340739158299509. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 18304/60000][Iteration 4364][Wall Clock 424.345697232s] Trained 128 records in 0.078725204 seconds. Throughput is 1625.9088 records/second. Loss is 0.22064781. Sequential31006cbd's hyper parameters: Current learning rate is 0.005340168749332479. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 18432/60000][Iteration 4365][Wall Clock 424.425603213s] Trained 128 records in 0.079905981 seconds. Throughput is 1601.8826 records/second. Loss is 0.18163677. Sequential31006cbd's hyper parameters: Current learning rate is 0.005339598462195643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:41 INFO  DistriOptimizer$:408 - [Epoch 10 18560/60000][Iteration 4366][Wall Clock 424.510587385s] Trained 128 records in 0.084984172 seconds. Throughput is 1506.1628 records/second. Loss is 0.22945668. Sequential31006cbd's hyper parameters: Current learning rate is 0.005339028296849973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 18688/60000][Iteration 4367][Wall Clock 424.583508644s] Trained 128 records in 0.072921259 seconds. Throughput is 1755.318 records/second. Loss is 0.22162092. Sequential31006cbd's hyper parameters: Current learning rate is 0.005338458253256459. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 18816/60000][Iteration 4368][Wall Clock 424.66311752s] Trained 128 records in 0.079608876 seconds. Throughput is 1607.861 records/second. Loss is 0.20089614. Sequential31006cbd's hyper parameters: Current learning rate is 0.005337888331376107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 18944/60000][Iteration 4369][Wall Clock 424.742368405s] Trained 128 records in 0.079250885 seconds. Throughput is 1615.1239 records/second. Loss is 0.2039934. Sequential31006cbd's hyper parameters: Current learning rate is 0.00533731853116994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19072/60000][Iteration 4370][Wall Clock 424.81983325s] Trained 128 records in 0.077464845 seconds. Throughput is 1652.3625 records/second. Loss is 0.16056061. Sequential31006cbd's hyper parameters: Current learning rate is 0.005336748852598996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19200/60000][Iteration 4371][Wall Clock 424.898018484s] Trained 128 records in 0.078185234 seconds. Throughput is 1637.1378 records/second. Loss is 0.3056833. Sequential31006cbd's hyper parameters: Current learning rate is 0.005336179295624333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19328/60000][Iteration 4372][Wall Clock 424.978368815s] Trained 128 records in 0.080350331 seconds. Throughput is 1593.0239 records/second. Loss is 0.21355096. Sequential31006cbd's hyper parameters: Current learning rate is 0.005335609860207022. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19456/60000][Iteration 4373][Wall Clock 425.062014964s] Trained 128 records in 0.083646149 seconds. Throughput is 1530.2557 records/second. Loss is 0.21628113. Sequential31006cbd's hyper parameters: Current learning rate is 0.005335040546308152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19584/60000][Iteration 4374][Wall Clock 425.150101828s] Trained 128 records in 0.088086864 seconds. Throughput is 1453.1111 records/second. Loss is 0.20507462. Sequential31006cbd's hyper parameters: Current learning rate is 0.005334471353888829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19712/60000][Iteration 4375][Wall Clock 425.260231136s] Trained 128 records in 0.110129308 seconds. Throughput is 1162.27 records/second. Loss is 0.16749722. Sequential31006cbd's hyper parameters: Current learning rate is 0.005333902282910177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19840/60000][Iteration 4376][Wall Clock 425.344837474s] Trained 128 records in 0.084606338 seconds. Throughput is 1512.889 records/second. Loss is 0.2033734. Sequential31006cbd's hyper parameters: Current learning rate is 0.005333333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 19968/60000][Iteration 4377][Wall Clock 425.430039425s] Trained 128 records in 0.085201951 seconds. Throughput is 1502.3131 records/second. Loss is 0.25979698. Sequential31006cbd's hyper parameters: Current learning rate is 0.005332764505119454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:42 INFO  DistriOptimizer$:408 - [Epoch 10 20096/60000][Iteration 4378][Wall Clock 425.517161321s] Trained 128 records in 0.087121896 seconds. Throughput is 1469.2058 records/second. Loss is 0.28972578. Sequential31006cbd's hyper parameters: Current learning rate is 0.005332195798229711. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20224/60000][Iteration 4379][Wall Clock 425.594647549s] Trained 128 records in 0.077486228 seconds. Throughput is 1651.9065 records/second. Loss is 0.33727777. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053316272126252935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20352/60000][Iteration 4380][Wall Clock 425.672424734s] Trained 128 records in 0.077777185 seconds. Throughput is 1645.7268 records/second. Loss is 0.3089038. Sequential31006cbd's hyper parameters: Current learning rate is 0.005331058748267406. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20480/60000][Iteration 4381][Wall Clock 425.752401281s] Trained 128 records in 0.079976547 seconds. Throughput is 1600.4692 records/second. Loss is 0.16713092. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053304904051172716. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20608/60000][Iteration 4382][Wall Clock 425.827625951s] Trained 128 records in 0.07522467 seconds. Throughput is 1701.5695 records/second. Loss is 0.27893004. Sequential31006cbd's hyper parameters: Current learning rate is 0.005329922183136126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20736/60000][Iteration 4383][Wall Clock 425.91206949s] Trained 128 records in 0.084443539 seconds. Throughput is 1515.8057 records/second. Loss is 0.256109. Sequential31006cbd's hyper parameters: Current learning rate is 0.005329354082285227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20864/60000][Iteration 4384][Wall Clock 425.997929256s] Trained 128 records in 0.085859766 seconds. Throughput is 1490.803 records/second. Loss is 0.23650934. Sequential31006cbd's hyper parameters: Current learning rate is 0.005328786102525845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 20992/60000][Iteration 4385][Wall Clock 426.083260268s] Trained 128 records in 0.085331012 seconds. Throughput is 1500.0408 records/second. Loss is 0.15155776. Sequential31006cbd's hyper parameters: Current learning rate is 0.005328218243819267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 21120/60000][Iteration 4386][Wall Clock 426.165433298s] Trained 128 records in 0.08217303 seconds. Throughput is 1557.6887 records/second. Loss is 0.19098844. Sequential31006cbd's hyper parameters: Current learning rate is 0.005327650506126798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 21248/60000][Iteration 4387][Wall Clock 426.247266851s] Trained 128 records in 0.081833553 seconds. Throughput is 1564.1505 records/second. Loss is 0.20682713. Sequential31006cbd's hyper parameters: Current learning rate is 0.005327082889409759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 21376/60000][Iteration 4388][Wall Clock 426.330561345s] Trained 128 records in 0.083294494 seconds. Throughput is 1536.7162 records/second. Loss is 0.20744391. Sequential31006cbd's hyper parameters: Current learning rate is 0.005326515393629487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 21504/60000][Iteration 4389][Wall Clock 426.41092545s] Trained 128 records in 0.080364105 seconds. Throughput is 1592.7509 records/second. Loss is 0.22628082. Sequential31006cbd's hyper parameters: Current learning rate is 0.005325948018747337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:43 INFO  DistriOptimizer$:408 - [Epoch 10 21632/60000][Iteration 4390][Wall Clock 426.489063745s] Trained 128 records in 0.078138295 seconds. Throughput is 1638.1213 records/second. Loss is 0.18784592. Sequential31006cbd's hyper parameters: Current learning rate is 0.005325380764724678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 21760/60000][Iteration 4391][Wall Clock 426.576497124s] Trained 128 records in 0.087433379 seconds. Throughput is 1463.9718 records/second. Loss is 0.11322304. Sequential31006cbd's hyper parameters: Current learning rate is 0.005324813631522897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 21888/60000][Iteration 4392][Wall Clock 426.659978902s] Trained 128 records in 0.083481778 seconds. Throughput is 1533.2687 records/second. Loss is 0.19629411. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053242466191033965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22016/60000][Iteration 4393][Wall Clock 426.74391076s] Trained 128 records in 0.083931858 seconds. Throughput is 1525.0468 records/second. Loss is 0.19299823. Sequential31006cbd's hyper parameters: Current learning rate is 0.005323679727427598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22144/60000][Iteration 4394][Wall Clock 426.820960261s] Trained 128 records in 0.077049501 seconds. Throughput is 1661.2697 records/second. Loss is 0.21622002. Sequential31006cbd's hyper parameters: Current learning rate is 0.005323112956456936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22272/60000][Iteration 4395][Wall Clock 426.89997661s] Trained 128 records in 0.079016349 seconds. Throughput is 1619.9178 records/second. Loss is 0.2504025. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053225463061528635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22400/60000][Iteration 4396][Wall Clock 426.982583525s] Trained 128 records in 0.082606915 seconds. Throughput is 1549.5072 records/second. Loss is 0.21980044. Sequential31006cbd's hyper parameters: Current learning rate is 0.005321979776476849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22528/60000][Iteration 4397][Wall Clock 427.06228434s] Trained 128 records in 0.079700815 seconds. Throughput is 1606.0062 records/second. Loss is 0.1937947. Sequential31006cbd's hyper parameters: Current learning rate is 0.005321413367390379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22656/60000][Iteration 4398][Wall Clock 427.137915456s] Trained 128 records in 0.075631116 seconds. Throughput is 1692.425 records/second. Loss is 0.17080538. Sequential31006cbd's hyper parameters: Current learning rate is 0.005320847078854954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22784/60000][Iteration 4399][Wall Clock 427.233112954s] Trained 128 records in 0.095197498 seconds. Throughput is 1344.5731 records/second. Loss is 0.29408437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005320280910832092. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 22912/60000][Iteration 4400][Wall Clock 427.321520501s] Trained 128 records in 0.088407547 seconds. Throughput is 1447.8402 records/second. Loss is 0.2457563. Sequential31006cbd's hyper parameters: Current learning rate is 0.005319714863283328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 23040/60000][Iteration 4401][Wall Clock 427.397624703s] Trained 128 records in 0.076104202 seconds. Throughput is 1681.9045 records/second. Loss is 0.21811219. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053191489361702135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 23168/60000][Iteration 4402][Wall Clock 427.475558472s] Trained 128 records in 0.077933769 seconds. Throughput is 1642.4203 records/second. Loss is 0.21110816. Sequential31006cbd's hyper parameters: Current learning rate is 0.005318583129454314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:44 INFO  DistriOptimizer$:408 - [Epoch 10 23296/60000][Iteration 4403][Wall Clock 427.552325051s] Trained 128 records in 0.076766579 seconds. Throughput is 1667.3922 records/second. Loss is 0.23515908. Sequential31006cbd's hyper parameters: Current learning rate is 0.005318017443097213. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 23424/60000][Iteration 4404][Wall Clock 427.625495328s] Trained 128 records in 0.073170277 seconds. Throughput is 1749.3442 records/second. Loss is 0.23202696. Sequential31006cbd's hyper parameters: Current learning rate is 0.005317451877060513. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 23552/60000][Iteration 4405][Wall Clock 427.70710409s] Trained 128 records in 0.081608762 seconds. Throughput is 1568.459 records/second. Loss is 0.21738689. Sequential31006cbd's hyper parameters: Current learning rate is 0.005316886431305828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 23680/60000][Iteration 4406][Wall Clock 427.787290909s] Trained 128 records in 0.080186819 seconds. Throughput is 1596.2722 records/second. Loss is 0.24297032. Sequential31006cbd's hyper parameters: Current learning rate is 0.00531632110579479. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 23808/60000][Iteration 4407][Wall Clock 427.872690707s] Trained 128 records in 0.085399798 seconds. Throughput is 1498.8325 records/second. Loss is 0.1435893. Sequential31006cbd's hyper parameters: Current learning rate is 0.005315755900489049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 23936/60000][Iteration 4408][Wall Clock 427.975637636s] Trained 128 records in 0.102946929 seconds. Throughput is 1243.3591 records/second. Loss is 0.14852864. Sequential31006cbd's hyper parameters: Current learning rate is 0.005315190815350271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 24064/60000][Iteration 4409][Wall Clock 428.07584043s] Trained 128 records in 0.100202794 seconds. Throughput is 1277.4095 records/second. Loss is 0.19531526. Sequential31006cbd's hyper parameters: Current learning rate is 0.005314625850340136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 24192/60000][Iteration 4410][Wall Clock 428.155373939s] Trained 128 records in 0.079533509 seconds. Throughput is 1609.3845 records/second. Loss is 0.2043086. Sequential31006cbd's hyper parameters: Current learning rate is 0.005314061005420342. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 24320/60000][Iteration 4411][Wall Clock 428.237116663s] Trained 128 records in 0.081742724 seconds. Throughput is 1565.8885 records/second. Loss is 0.28792158. Sequential31006cbd's hyper parameters: Current learning rate is 0.005313496280552604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 24448/60000][Iteration 4412][Wall Clock 428.321579022s] Trained 128 records in 0.084462359 seconds. Throughput is 1515.468 records/second. Loss is 0.15913069. Sequential31006cbd's hyper parameters: Current learning rate is 0.005312931675698651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 24576/60000][Iteration 4413][Wall Clock 428.402456704s] Trained 128 records in 0.080877682 seconds. Throughput is 1582.6368 records/second. Loss is 0.28801733. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053123671908202295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:45 INFO  DistriOptimizer$:408 - [Epoch 10 24704/60000][Iteration 4414][Wall Clock 428.479035158s] Trained 128 records in 0.076578454 seconds. Throughput is 1671.4884 records/second. Loss is 0.19018131. Sequential31006cbd's hyper parameters: Current learning rate is 0.005311802825879103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 24832/60000][Iteration 4415][Wall Clock 428.561439841s] Trained 128 records in 0.082404683 seconds. Throughput is 1553.3098 records/second. Loss is 0.18977335. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053112385808370514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 24960/60000][Iteration 4416][Wall Clock 428.636465628s] Trained 128 records in 0.075025787 seconds. Throughput is 1706.08 records/second. Loss is 0.19621804. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053106744556558685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25088/60000][Iteration 4417][Wall Clock 428.720159283s] Trained 128 records in 0.083693655 seconds. Throughput is 1529.3872 records/second. Loss is 0.28684646. Sequential31006cbd's hyper parameters: Current learning rate is 0.005310110450297366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25216/60000][Iteration 4418][Wall Clock 428.806708849s] Trained 128 records in 0.086549566 seconds. Throughput is 1478.9214 records/second. Loss is 0.22363448. Sequential31006cbd's hyper parameters: Current learning rate is 0.005309546564723373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25344/60000][Iteration 4419][Wall Clock 428.888286831s] Trained 128 records in 0.081577982 seconds. Throughput is 1569.0509 records/second. Loss is 0.22075017. Sequential31006cbd's hyper parameters: Current learning rate is 0.005308982798895732. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25472/60000][Iteration 4420][Wall Clock 428.969841285s] Trained 128 records in 0.081554454 seconds. Throughput is 1569.5034 records/second. Loss is 0.08978695. Sequential31006cbd's hyper parameters: Current learning rate is 0.005308419152776304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25600/60000][Iteration 4421][Wall Clock 429.050298304s] Trained 128 records in 0.080457019 seconds. Throughput is 1590.9116 records/second. Loss is 0.15729564. Sequential31006cbd's hyper parameters: Current learning rate is 0.0053078556263269645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25728/60000][Iteration 4422][Wall Clock 429.134081697s] Trained 128 records in 0.083783393 seconds. Throughput is 1527.749 records/second. Loss is 0.14638239. Sequential31006cbd's hyper parameters: Current learning rate is 0.005307292219509606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25856/60000][Iteration 4423][Wall Clock 429.211876294s] Trained 128 records in 0.077794597 seconds. Throughput is 1645.3585 records/second. Loss is 0.18016529. Sequential31006cbd's hyper parameters: Current learning rate is 0.005306728932286139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 25984/60000][Iteration 4424][Wall Clock 429.295855454s] Trained 128 records in 0.08397916 seconds. Throughput is 1524.1876 records/second. Loss is 0.1951372. Sequential31006cbd's hyper parameters: Current learning rate is 0.005306165764618486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 26112/60000][Iteration 4425][Wall Clock 429.397369047s] Trained 128 records in 0.101513593 seconds. Throughput is 1260.9149 records/second. Loss is 0.16155809. Sequential31006cbd's hyper parameters: Current learning rate is 0.005305602716468591. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:46 INFO  DistriOptimizer$:408 - [Epoch 10 26240/60000][Iteration 4426][Wall Clock 429.477500897s] Trained 128 records in 0.08013185 seconds. Throughput is 1597.3673 records/second. Loss is 0.13797805. Sequential31006cbd's hyper parameters: Current learning rate is 0.005305039787798408. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 26368/60000][Iteration 4427][Wall Clock 429.55704121s] Trained 128 records in 0.079540313 seconds. Throughput is 1609.247 records/second. Loss is 0.23613551. Sequential31006cbd's hyper parameters: Current learning rate is 0.005304476978569912. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 26496/60000][Iteration 4428][Wall Clock 429.642368205s] Trained 128 records in 0.085326995 seconds. Throughput is 1500.1115 records/second. Loss is 0.34032044. Sequential31006cbd's hyper parameters: Current learning rate is 0.005303914288745094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 26624/60000][Iteration 4429][Wall Clock 429.719805572s] Trained 128 records in 0.077437367 seconds. Throughput is 1652.9489 records/second. Loss is 0.26553082. Sequential31006cbd's hyper parameters: Current learning rate is 0.005303351718285956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 26752/60000][Iteration 4430][Wall Clock 429.810331698s] Trained 128 records in 0.090526126 seconds. Throughput is 1413.9564 records/second. Loss is 0.1570347. Sequential31006cbd's hyper parameters: Current learning rate is 0.005302789267154523. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 26880/60000][Iteration 4431][Wall Clock 429.890057196s] Trained 128 records in 0.079725498 seconds. Throughput is 1605.509 records/second. Loss is 0.2643716. Sequential31006cbd's hyper parameters: Current learning rate is 0.005302226935312831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27008/60000][Iteration 4432][Wall Clock 429.961709993s] Trained 128 records in 0.071652797 seconds. Throughput is 1786.3922 records/second. Loss is 0.21882156. Sequential31006cbd's hyper parameters: Current learning rate is 0.005301664722722935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27136/60000][Iteration 4433][Wall Clock 430.041453792s] Trained 128 records in 0.079743799 seconds. Throughput is 1605.1404 records/second. Loss is 0.2486712. Sequential31006cbd's hyper parameters: Current learning rate is 0.005301102629346904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27264/60000][Iteration 4434][Wall Clock 430.120459717s] Trained 128 records in 0.079005925 seconds. Throughput is 1620.1316 records/second. Loss is 0.19687207. Sequential31006cbd's hyper parameters: Current learning rate is 0.005300540655146825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27392/60000][Iteration 4435][Wall Clock 430.19821059s] Trained 128 records in 0.077750873 seconds. Throughput is 1646.2837 records/second. Loss is 0.2637069. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052999788000848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27520/60000][Iteration 4436][Wall Clock 430.274878318s] Trained 128 records in 0.076667728 seconds. Throughput is 1669.5421 records/second. Loss is 0.14033382. Sequential31006cbd's hyper parameters: Current learning rate is 0.005299417064122946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27648/60000][Iteration 4437][Wall Clock 430.35392806s] Trained 128 records in 0.079049742 seconds. Throughput is 1619.2336 records/second. Loss is 0.21709539. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052988554472234. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:47 INFO  DistriOptimizer$:408 - [Epoch 10 27776/60000][Iteration 4438][Wall Clock 430.461757725s] Trained 128 records in 0.107829665 seconds. Throughput is 1187.0574 records/second. Loss is 0.19953622. Sequential31006cbd's hyper parameters: Current learning rate is 0.00529829394934831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 27904/60000][Iteration 4439][Wall Clock 430.543745839s] Trained 128 records in 0.081988114 seconds. Throughput is 1561.2019 records/second. Loss is 0.21284631. Sequential31006cbd's hyper parameters: Current learning rate is 0.005297732570459844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28032/60000][Iteration 4440][Wall Clock 430.620792813s] Trained 128 records in 0.077046974 seconds. Throughput is 1661.3241 records/second. Loss is 0.28593108. Sequential31006cbd's hyper parameters: Current learning rate is 0.005297171310520182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28160/60000][Iteration 4441][Wall Clock 430.703791429s] Trained 128 records in 0.082998616 seconds. Throughput is 1542.1943 records/second. Loss is 0.22735731. Sequential31006cbd's hyper parameters: Current learning rate is 0.005296610169491526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28288/60000][Iteration 4442][Wall Clock 430.783266104s] Trained 128 records in 0.079474675 seconds. Throughput is 1610.576 records/second. Loss is 0.24454507. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052960491473360875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28416/60000][Iteration 4443][Wall Clock 430.866584441s] Trained 128 records in 0.083318337 seconds. Throughput is 1536.2765 records/second. Loss is 0.3200543. Sequential31006cbd's hyper parameters: Current learning rate is 0.005295488244016098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28544/60000][Iteration 4444][Wall Clock 430.942155908s] Trained 128 records in 0.075571467 seconds. Throughput is 1693.7609 records/second. Loss is 0.19161728. Sequential31006cbd's hyper parameters: Current learning rate is 0.005294927459493805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28672/60000][Iteration 4445][Wall Clock 431.018680091s] Trained 128 records in 0.076524183 seconds. Throughput is 1672.6738 records/second. Loss is 0.16947912. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052943667937314694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28800/60000][Iteration 4446][Wall Clock 431.096191356s] Trained 128 records in 0.077511265 seconds. Throughput is 1651.3728 records/second. Loss is 0.2410774. Sequential31006cbd's hyper parameters: Current learning rate is 0.005293806246691371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 28928/60000][Iteration 4447][Wall Clock 431.179220843s] Trained 128 records in 0.083029487 seconds. Throughput is 1541.621 records/second. Loss is 0.19937178. Sequential31006cbd's hyper parameters: Current learning rate is 0.005293245818335804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 29056/60000][Iteration 4448][Wall Clock 431.255029944s] Trained 128 records in 0.075809101 seconds. Throughput is 1688.4517 records/second. Loss is 0.18869683. Sequential31006cbd's hyper parameters: Current learning rate is 0.005292685508627077. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 29184/60000][Iteration 4449][Wall Clock 431.343515906s] Trained 128 records in 0.088485962 seconds. Throughput is 1446.5571 records/second. Loss is 0.23384868. Sequential31006cbd's hyper parameters: Current learning rate is 0.005292125317527519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 29312/60000][Iteration 4450][Wall Clock 431.429710216s] Trained 128 records in 0.08619431 seconds. Throughput is 1485.0168 records/second. Loss is 0.25386456. Sequential31006cbd's hyper parameters: Current learning rate is 0.00529156524499947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:48 INFO  DistriOptimizer$:408 - [Epoch 10 29440/60000][Iteration 4451][Wall Clock 431.535157975s] Trained 128 records in 0.105447759 seconds. Throughput is 1213.8712 records/second. Loss is 0.20991209. Sequential31006cbd's hyper parameters: Current learning rate is 0.005291005291005291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 29568/60000][Iteration 4452][Wall Clock 431.610970813s] Trained 128 records in 0.075812838 seconds. Throughput is 1688.3684 records/second. Loss is 0.12988862. Sequential31006cbd's hyper parameters: Current learning rate is 0.005290445455507354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 29696/60000][Iteration 4453][Wall Clock 431.697892441s] Trained 128 records in 0.086921628 seconds. Throughput is 1472.591 records/second. Loss is 0.25730336. Sequential31006cbd's hyper parameters: Current learning rate is 0.005289885738468049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 29824/60000][Iteration 4454][Wall Clock 431.78125291s] Trained 128 records in 0.083360469 seconds. Throughput is 1535.5 records/second. Loss is 0.35137814. Sequential31006cbd's hyper parameters: Current learning rate is 0.005289326139849783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 29952/60000][Iteration 4455][Wall Clock 431.861531649s] Trained 128 records in 0.080278739 seconds. Throughput is 1594.4446 records/second. Loss is 0.20015475. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052887666596149775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30080/60000][Iteration 4456][Wall Clock 431.941780268s] Trained 128 records in 0.080248619 seconds. Throughput is 1595.0431 records/second. Loss is 0.16876598. Sequential31006cbd's hyper parameters: Current learning rate is 0.005288207297726071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30208/60000][Iteration 4457][Wall Clock 432.021907737s] Trained 128 records in 0.080127469 seconds. Throughput is 1597.4547 records/second. Loss is 0.17960629. Sequential31006cbd's hyper parameters: Current learning rate is 0.005287648054145516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30336/60000][Iteration 4458][Wall Clock 432.102372768s] Trained 128 records in 0.080465031 seconds. Throughput is 1590.753 records/second. Loss is 0.17268452. Sequential31006cbd's hyper parameters: Current learning rate is 0.005287088928835783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30464/60000][Iteration 4459][Wall Clock 432.210301934s] Trained 128 records in 0.107929166 seconds. Throughput is 1185.963 records/second. Loss is 0.11249727. Sequential31006cbd's hyper parameters: Current learning rate is 0.005286529921759357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30592/60000][Iteration 4460][Wall Clock 432.28779209s] Trained 128 records in 0.077490156 seconds. Throughput is 1651.8226 records/second. Loss is 0.1736849. Sequential31006cbd's hyper parameters: Current learning rate is 0.00528597103287874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30720/60000][Iteration 4461][Wall Clock 432.365916785s] Trained 128 records in 0.078124695 seconds. Throughput is 1638.4064 records/second. Loss is 0.18930754. Sequential31006cbd's hyper parameters: Current learning rate is 0.005285412262156448. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30848/60000][Iteration 4462][Wall Clock 432.445282359s] Trained 128 records in 0.079365574 seconds. Throughput is 1612.7899 records/second. Loss is 0.19708908. Sequential31006cbd's hyper parameters: Current learning rate is 0.005284853609555016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:49 INFO  DistriOptimizer$:408 - [Epoch 10 30976/60000][Iteration 4463][Wall Clock 432.531164059s] Trained 128 records in 0.0858817 seconds. Throughput is 1490.4222 records/second. Loss is 0.32607496. Sequential31006cbd's hyper parameters: Current learning rate is 0.00528429507503699. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31104/60000][Iteration 4464][Wall Clock 432.628451063s] Trained 128 records in 0.097287004 seconds. Throughput is 1315.6947 records/second. Loss is 0.20849507. Sequential31006cbd's hyper parameters: Current learning rate is 0.005283736658564937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31232/60000][Iteration 4465][Wall Clock 432.710931049s] Trained 128 records in 0.082479986 seconds. Throughput is 1551.8917 records/second. Loss is 0.26529634. Sequential31006cbd's hyper parameters: Current learning rate is 0.005283178360101437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31360/60000][Iteration 4466][Wall Clock 432.792435211s] Trained 128 records in 0.081504162 seconds. Throughput is 1570.472 records/second. Loss is 0.18117112. Sequential31006cbd's hyper parameters: Current learning rate is 0.005282620179609086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31488/60000][Iteration 4467][Wall Clock 432.872242716s] Trained 128 records in 0.079807505 seconds. Throughput is 1603.8591 records/second. Loss is 0.16564938. Sequential31006cbd's hyper parameters: Current learning rate is 0.005282062117050497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31616/60000][Iteration 4468][Wall Clock 432.960977265s] Trained 128 records in 0.088734549 seconds. Throughput is 1442.5046 records/second. Loss is 0.1315695. Sequential31006cbd's hyper parameters: Current learning rate is 0.005281504172388296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31744/60000][Iteration 4469][Wall Clock 433.040622741s] Trained 128 records in 0.079645476 seconds. Throughput is 1607.1221 records/second. Loss is 0.2577315. Sequential31006cbd's hyper parameters: Current learning rate is 0.005280946345585128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 31872/60000][Iteration 4470][Wall Clock 433.120407497s] Trained 128 records in 0.079784756 seconds. Throughput is 1604.3164 records/second. Loss is 0.33373156. Sequential31006cbd's hyper parameters: Current learning rate is 0.005280388636603654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 32000/60000][Iteration 4471][Wall Clock 433.201736893s] Trained 128 records in 0.081329396 seconds. Throughput is 1573.8467 records/second. Loss is 0.13137513. Sequential31006cbd's hyper parameters: Current learning rate is 0.005279831045406547. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 32128/60000][Iteration 4472][Wall Clock 433.281603334s] Trained 128 records in 0.079866441 seconds. Throughput is 1602.6757 records/second. Loss is 0.21339384. Sequential31006cbd's hyper parameters: Current learning rate is 0.005279273571956499. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 32256/60000][Iteration 4473][Wall Clock 433.356814461s] Trained 128 records in 0.075211127 seconds. Throughput is 1701.8757 records/second. Loss is 0.15219328. Sequential31006cbd's hyper parameters: Current learning rate is 0.005278716216216216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 32384/60000][Iteration 4474][Wall Clock 433.43534081s] Trained 128 records in 0.078526349 seconds. Throughput is 1630.0261 records/second. Loss is 0.19997504. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052781589781484214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:50 INFO  DistriOptimizer$:408 - [Epoch 10 32512/60000][Iteration 4475][Wall Clock 433.511396929s] Trained 128 records in 0.076056119 seconds. Throughput is 1682.9679 records/second. Loss is 0.16829744. Sequential31006cbd's hyper parameters: Current learning rate is 0.005277601857715854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 32640/60000][Iteration 4476][Wall Clock 433.594372754s] Trained 128 records in 0.082975825 seconds. Throughput is 1542.6179 records/second. Loss is 0.20323837. Sequential31006cbd's hyper parameters: Current learning rate is 0.005277044854881266. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 32768/60000][Iteration 4477][Wall Clock 433.685690359s] Trained 128 records in 0.091317605 seconds. Throughput is 1401.7013 records/second. Loss is 0.22723266. Sequential31006cbd's hyper parameters: Current learning rate is 0.00527648796960743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 32896/60000][Iteration 4478][Wall Clock 433.760734014s] Trained 128 records in 0.075043655 seconds. Throughput is 1705.6738 records/second. Loss is 0.16151245. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052759312018571276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33024/60000][Iteration 4479][Wall Clock 433.833602335s] Trained 128 records in 0.072868321 seconds. Throughput is 1756.5934 records/second. Loss is 0.16907999. Sequential31006cbd's hyper parameters: Current learning rate is 0.005275374551593164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33152/60000][Iteration 4480][Wall Clock 433.917257729s] Trained 128 records in 0.083655394 seconds. Throughput is 1530.0867 records/second. Loss is 0.30386245. Sequential31006cbd's hyper parameters: Current learning rate is 0.005274818018778353. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33280/60000][Iteration 4481][Wall Clock 433.998283767s] Trained 128 records in 0.081026038 seconds. Throughput is 1579.739 records/second. Loss is 0.17045636. Sequential31006cbd's hyper parameters: Current learning rate is 0.005274261603375528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33408/60000][Iteration 4482][Wall Clock 434.074083315s] Trained 128 records in 0.075799548 seconds. Throughput is 1688.6644 records/second. Loss is 0.1532467. Sequential31006cbd's hyper parameters: Current learning rate is 0.005273705305347537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33536/60000][Iteration 4483][Wall Clock 434.151444162s] Trained 128 records in 0.077360847 seconds. Throughput is 1654.5837 records/second. Loss is 0.15711974. Sequential31006cbd's hyper parameters: Current learning rate is 0.005273149124657245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33664/60000][Iteration 4484][Wall Clock 434.233034494s] Trained 128 records in 0.081590332 seconds. Throughput is 1568.8134 records/second. Loss is 0.26309907. Sequential31006cbd's hyper parameters: Current learning rate is 0.005272593061267531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33792/60000][Iteration 4485][Wall Clock 434.316061143s] Trained 128 records in 0.083026649 seconds. Throughput is 1541.6737 records/second. Loss is 0.3422153. Sequential31006cbd's hyper parameters: Current learning rate is 0.005272037115141291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 33920/60000][Iteration 4486][Wall Clock 434.398556321s] Trained 128 records in 0.082495178 seconds. Throughput is 1551.6058 records/second. Loss is 0.17415644. Sequential31006cbd's hyper parameters: Current learning rate is 0.005271481286241434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:51 INFO  DistriOptimizer$:408 - [Epoch 10 34048/60000][Iteration 4487][Wall Clock 434.484474466s] Trained 128 records in 0.085918145 seconds. Throughput is 1489.7902 records/second. Loss is 0.27501702. Sequential31006cbd's hyper parameters: Current learning rate is 0.005270925574530887. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34176/60000][Iteration 4488][Wall Clock 434.564065921s] Trained 128 records in 0.079591455 seconds. Throughput is 1608.2129 records/second. Loss is 0.21145704. Sequential31006cbd's hyper parameters: Current learning rate is 0.005270369979972594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34304/60000][Iteration 4489][Wall Clock 434.642666785s] Trained 128 records in 0.078600864 seconds. Throughput is 1628.4808 records/second. Loss is 0.16447192. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052698145025295105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34432/60000][Iteration 4490][Wall Clock 434.724552247s] Trained 128 records in 0.081885462 seconds. Throughput is 1563.1589 records/second. Loss is 0.24425705. Sequential31006cbd's hyper parameters: Current learning rate is 0.005269259142164611. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34560/60000][Iteration 4491][Wall Clock 434.801545007s] Trained 128 records in 0.07699276 seconds. Throughput is 1662.494 records/second. Loss is 0.14816765. Sequential31006cbd's hyper parameters: Current learning rate is 0.005268703898840885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34688/60000][Iteration 4492][Wall Clock 434.876375772s] Trained 128 records in 0.074830765 seconds. Throughput is 1710.5265 records/second. Loss is 0.20932354. Sequential31006cbd's hyper parameters: Current learning rate is 0.005268148772521336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34816/60000][Iteration 4493][Wall Clock 434.954494039s] Trained 128 records in 0.078118267 seconds. Throughput is 1638.5413 records/second. Loss is 0.16379246. Sequential31006cbd's hyper parameters: Current learning rate is 0.005267593763168985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 34944/60000][Iteration 4494][Wall Clock 435.033560682s] Trained 128 records in 0.079066643 seconds. Throughput is 1618.8876 records/second. Loss is 0.23945415. Sequential31006cbd's hyper parameters: Current learning rate is 0.005267038870746866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 35072/60000][Iteration 4495][Wall Clock 435.11125552s] Trained 128 records in 0.077694838 seconds. Throughput is 1647.4711 records/second. Loss is 0.14659254. Sequential31006cbd's hyper parameters: Current learning rate is 0.005266484095218032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 35200/60000][Iteration 4496][Wall Clock 435.191354902s] Trained 128 records in 0.080099382 seconds. Throughput is 1598.0149 records/second. Loss is 0.18459567. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052659294365455505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 35328/60000][Iteration 4497][Wall Clock 435.276653595s] Trained 128 records in 0.085298693 seconds. Throughput is 1500.6091 records/second. Loss is 0.21502158. Sequential31006cbd's hyper parameters: Current learning rate is 0.005265374894692502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 35456/60000][Iteration 4498][Wall Clock 435.354875107s] Trained 128 records in 0.078221512 seconds. Throughput is 1636.3784 records/second. Loss is 0.1594452. Sequential31006cbd's hyper parameters: Current learning rate is 0.005264820469621986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 35584/60000][Iteration 4499][Wall Clock 435.439727776s] Trained 128 records in 0.084852669 seconds. Throughput is 1508.4971 records/second. Loss is 0.1896218. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052642661612971155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:52 INFO  DistriOptimizer$:408 - [Epoch 10 35712/60000][Iteration 4500][Wall Clock 435.516775993s] Trained 128 records in 0.077048217 seconds. Throughput is 1661.2974 records/second. Loss is 0.19082361. Sequential31006cbd's hyper parameters: Current learning rate is 0.005263711969681019. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 35840/60000][Iteration 4501][Wall Clock 435.600135883s] Trained 128 records in 0.08335989 seconds. Throughput is 1535.5106 records/second. Loss is 0.2799934. Sequential31006cbd's hyper parameters: Current learning rate is 0.005263157894736843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 35968/60000][Iteration 4502][Wall Clock 435.68534629s] Trained 128 records in 0.085210407 seconds. Throughput is 1502.164 records/second. Loss is 0.17995001. Sequential31006cbd's hyper parameters: Current learning rate is 0.005262603936427745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36096/60000][Iteration 4503][Wall Clock 435.789629177s] Trained 128 records in 0.104282887 seconds. Throughput is 1227.4305 records/second. Loss is 0.2602731. Sequential31006cbd's hyper parameters: Current learning rate is 0.005262050094716902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36224/60000][Iteration 4504][Wall Clock 435.864572028s] Trained 128 records in 0.074942851 seconds. Throughput is 1707.9681 records/second. Loss is 0.2818118. Sequential31006cbd's hyper parameters: Current learning rate is 0.005261496369567505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36352/60000][Iteration 4505][Wall Clock 435.940098994s] Trained 128 records in 0.075526966 seconds. Throughput is 1694.7589 records/second. Loss is 0.21809413. Sequential31006cbd's hyper parameters: Current learning rate is 0.005260942760942761. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36480/60000][Iteration 4506][Wall Clock 436.014899937s] Trained 128 records in 0.074800943 seconds. Throughput is 1711.2083 records/second. Loss is 0.24983607. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052603892688058915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36608/60000][Iteration 4507][Wall Clock 436.097301233s] Trained 128 records in 0.082401296 seconds. Throughput is 1553.3735 records/second. Loss is 0.16650486. Sequential31006cbd's hyper parameters: Current learning rate is 0.005259835893120135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36736/60000][Iteration 4508][Wall Clock 436.175095038s] Trained 128 records in 0.077793805 seconds. Throughput is 1645.3752 records/second. Loss is 0.18738408. Sequential31006cbd's hyper parameters: Current learning rate is 0.005259282633848742. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36864/60000][Iteration 4509][Wall Clock 436.248191557s] Trained 128 records in 0.073096519 seconds. Throughput is 1751.1094 records/second. Loss is 0.13104482. Sequential31006cbd's hyper parameters: Current learning rate is 0.005258729490954985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 36992/60000][Iteration 4510][Wall Clock 436.323128346s] Trained 128 records in 0.074936789 seconds. Throughput is 1708.1062 records/second. Loss is 0.17235713. Sequential31006cbd's hyper parameters: Current learning rate is 0.005258176464402145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 37120/60000][Iteration 4511][Wall Clock 436.401278997s] Trained 128 records in 0.078150651 seconds. Throughput is 1637.8622 records/second. Loss is 0.18094437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005257623554153522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:53 INFO  DistriOptimizer$:408 - [Epoch 10 37248/60000][Iteration 4512][Wall Clock 436.483372504s] Trained 128 records in 0.082093507 seconds. Throughput is 1559.1976 records/second. Loss is 0.15529598. Sequential31006cbd's hyper parameters: Current learning rate is 0.005257070760172432. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 37376/60000][Iteration 4513][Wall Clock 436.563055595s] Trained 128 records in 0.079683091 seconds. Throughput is 1606.3634 records/second. Loss is 0.23113963. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052565180824222036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 37504/60000][Iteration 4514][Wall Clock 436.639056883s] Trained 128 records in 0.076001288 seconds. Throughput is 1684.182 records/second. Loss is 0.13868201. Sequential31006cbd's hyper parameters: Current learning rate is 0.005255965520866183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 37632/60000][Iteration 4515][Wall Clock 436.714078148s] Trained 128 records in 0.075021265 seconds. Throughput is 1706.1829 records/second. Loss is 0.21209332. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052554130754677315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 37760/60000][Iteration 4516][Wall Clock 436.791561851s] Trained 128 records in 0.077483703 seconds. Throughput is 1651.9602 records/second. Loss is 0.23117527. Sequential31006cbd's hyper parameters: Current learning rate is 0.005254860746190226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 37888/60000][Iteration 4517][Wall Clock 436.866678448s] Trained 128 records in 0.075116597 seconds. Throughput is 1704.0176 records/second. Loss is 0.19640307. Sequential31006cbd's hyper parameters: Current learning rate is 0.005254308532997058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38016/60000][Iteration 4518][Wall Clock 436.948858657s] Trained 128 records in 0.082180209 seconds. Throughput is 1557.5526 records/second. Loss is 0.24878067. Sequential31006cbd's hyper parameters: Current learning rate is 0.005253756435851634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38144/60000][Iteration 4519][Wall Clock 437.026975279s] Trained 128 records in 0.078116622 seconds. Throughput is 1638.5757 records/second. Loss is 0.170737. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052532044547173775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38272/60000][Iteration 4520][Wall Clock 437.105860946s] Trained 128 records in 0.078885667 seconds. Throughput is 1622.6014 records/second. Loss is 0.16667356. Sequential31006cbd's hyper parameters: Current learning rate is 0.005252652589557727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38400/60000][Iteration 4521][Wall Clock 437.180999047s] Trained 128 records in 0.075138101 seconds. Throughput is 1703.5299 records/second. Loss is 0.2240015. Sequential31006cbd's hyper parameters: Current learning rate is 0.005252100840336135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38528/60000][Iteration 4522][Wall Clock 437.263571896s] Trained 128 records in 0.082572849 seconds. Throughput is 1550.1464 records/second. Loss is 0.17276666. Sequential31006cbd's hyper parameters: Current learning rate is 0.00525154920701607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38656/60000][Iteration 4523][Wall Clock 437.341540324s] Trained 128 records in 0.077968428 seconds. Throughput is 1641.6902 records/second. Loss is 0.27111855. Sequential31006cbd's hyper parameters: Current learning rate is 0.005250997689561016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38784/60000][Iteration 4524][Wall Clock 437.419187899s] Trained 128 records in 0.077647575 seconds. Throughput is 1648.4739 records/second. Loss is 0.17973158. Sequential31006cbd's hyper parameters: Current learning rate is 0.005250446287934475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:54 INFO  DistriOptimizer$:408 - [Epoch 10 38912/60000][Iteration 4525][Wall Clock 437.498088256s] Trained 128 records in 0.078900357 seconds. Throughput is 1622.2993 records/second. Loss is 0.22130942. Sequential31006cbd's hyper parameters: Current learning rate is 0.005249895002099958. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39040/60000][Iteration 4526][Wall Clock 437.574706232s] Trained 128 records in 0.076617976 seconds. Throughput is 1670.6262 records/second. Loss is 0.22474267. Sequential31006cbd's hyper parameters: Current learning rate is 0.005249343832020997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39168/60000][Iteration 4527][Wall Clock 437.649265685s] Trained 128 records in 0.074559453 seconds. Throughput is 1716.7509 records/second. Loss is 0.17614518. Sequential31006cbd's hyper parameters: Current learning rate is 0.005248792777661138. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39296/60000][Iteration 4528][Wall Clock 437.756138874s] Trained 128 records in 0.106873189 seconds. Throughput is 1197.681 records/second. Loss is 0.20422809. Sequential31006cbd's hyper parameters: Current learning rate is 0.00524824183898394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39424/60000][Iteration 4529][Wall Clock 437.852349324s] Trained 128 records in 0.09621045 seconds. Throughput is 1330.4169 records/second. Loss is 0.19896366. Sequential31006cbd's hyper parameters: Current learning rate is 0.00524769101595298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39552/60000][Iteration 4530][Wall Clock 437.936393647s] Trained 128 records in 0.084044323 seconds. Throughput is 1523.0059 records/second. Loss is 0.20243445. Sequential31006cbd's hyper parameters: Current learning rate is 0.00524714030853185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39680/60000][Iteration 4531][Wall Clock 438.014482242s] Trained 128 records in 0.078088595 seconds. Throughput is 1639.1638 records/second. Loss is 0.25775817. Sequential31006cbd's hyper parameters: Current learning rate is 0.005246589716684155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39808/60000][Iteration 4532][Wall Clock 438.090733727s] Trained 128 records in 0.076251485 seconds. Throughput is 1678.6559 records/second. Loss is 0.22468081. Sequential31006cbd's hyper parameters: Current learning rate is 0.005246039240373518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 39936/60000][Iteration 4533][Wall Clock 438.167225956s] Trained 128 records in 0.076492229 seconds. Throughput is 1673.3727 records/second. Loss is 0.1786292. Sequential31006cbd's hyper parameters: Current learning rate is 0.005245488879563575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 40064/60000][Iteration 4534][Wall Clock 438.237899889s] Trained 128 records in 0.070673933 seconds. Throughput is 1811.1345 records/second. Loss is 0.30918133. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052449386342179796. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 40192/60000][Iteration 4535][Wall Clock 438.315238187s] Trained 128 records in 0.077338298 seconds. Throughput is 1655.0662 records/second. Loss is 0.107702225. Sequential31006cbd's hyper parameters: Current learning rate is 0.005244388504300398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 40320/60000][Iteration 4536][Wall Clock 438.395059995s] Trained 128 records in 0.079821808 seconds. Throughput is 1603.5718 records/second. Loss is 0.21989758. Sequential31006cbd's hyper parameters: Current learning rate is 0.005243838489774515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:55 INFO  DistriOptimizer$:408 - [Epoch 10 40448/60000][Iteration 4537][Wall Clock 438.462859245s] Trained 128 records in 0.06779925 seconds. Throughput is 1887.9265 records/second. Loss is 0.2303901. Sequential31006cbd's hyper parameters: Current learning rate is 0.005243288590604027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 40576/60000][Iteration 4538][Wall Clock 438.536247559s] Trained 128 records in 0.073388314 seconds. Throughput is 1744.1469 records/second. Loss is 0.3314827. Sequential31006cbd's hyper parameters: Current learning rate is 0.005242738806752648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 40704/60000][Iteration 4539][Wall Clock 438.616491251s] Trained 128 records in 0.080243692 seconds. Throughput is 1595.141 records/second. Loss is 0.1594873. Sequential31006cbd's hyper parameters: Current learning rate is 0.005242189138184106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 40832/60000][Iteration 4540][Wall Clock 438.696572977s] Trained 128 records in 0.080081726 seconds. Throughput is 1598.3672 records/second. Loss is 0.16783053. Sequential31006cbd's hyper parameters: Current learning rate is 0.005241639584862145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 40960/60000][Iteration 4541][Wall Clock 438.775457382s] Trained 128 records in 0.078884405 seconds. Throughput is 1622.6273 records/second. Loss is 0.19676384. Sequential31006cbd's hyper parameters: Current learning rate is 0.005241090146750524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41088/60000][Iteration 4542][Wall Clock 438.854663919s] Trained 128 records in 0.079206537 seconds. Throughput is 1616.0283 records/second. Loss is 0.18837455. Sequential31006cbd's hyper parameters: Current learning rate is 0.005240540823813018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41216/60000][Iteration 4543][Wall Clock 438.935486189s] Trained 128 records in 0.08082227 seconds. Throughput is 1583.7219 records/second. Loss is 0.17005044. Sequential31006cbd's hyper parameters: Current learning rate is 0.005239991616013414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41344/60000][Iteration 4544][Wall Clock 439.014137411s] Trained 128 records in 0.078651222 seconds. Throughput is 1627.4382 records/second. Loss is 0.21995836. Sequential31006cbd's hyper parameters: Current learning rate is 0.005239442523315519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41472/60000][Iteration 4545][Wall Clock 439.097561994s] Trained 128 records in 0.083424583 seconds. Throughput is 1534.32 records/second. Loss is 0.3198461. Sequential31006cbd's hyper parameters: Current learning rate is 0.005238893545683152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41600/60000][Iteration 4546][Wall Clock 439.18067332s] Trained 128 records in 0.083111326 seconds. Throughput is 1540.103 records/second. Loss is 0.13852996. Sequential31006cbd's hyper parameters: Current learning rate is 0.005238344683080147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41728/60000][Iteration 4547][Wall Clock 439.259426789s] Trained 128 records in 0.078753469 seconds. Throughput is 1625.3252 records/second. Loss is 0.10605965. Sequential31006cbd's hyper parameters: Current learning rate is 0.005237795935470354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41856/60000][Iteration 4548][Wall Clock 439.336034964s] Trained 128 records in 0.076608175 seconds. Throughput is 1670.84 records/second. Loss is 0.17311019. Sequential31006cbd's hyper parameters: Current learning rate is 0.005237247302817639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 41984/60000][Iteration 4549][Wall Clock 439.414324414s] Trained 128 records in 0.07828945 seconds. Throughput is 1634.9585 records/second. Loss is 0.19748859. Sequential31006cbd's hyper parameters: Current learning rate is 0.005236698785085881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:56 INFO  DistriOptimizer$:408 - [Epoch 10 42112/60000][Iteration 4550][Wall Clock 439.493181437s] Trained 128 records in 0.078857023 seconds. Throughput is 1623.1909 records/second. Loss is 0.12634595. Sequential31006cbd's hyper parameters: Current learning rate is 0.005236150382238978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 42240/60000][Iteration 4551][Wall Clock 439.569433055s] Trained 128 records in 0.076251618 seconds. Throughput is 1678.6528 records/second. Loss is 0.1618782. Sequential31006cbd's hyper parameters: Current learning rate is 0.005235602094240837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 42368/60000][Iteration 4552][Wall Clock 439.649064078s] Trained 128 records in 0.079631023 seconds. Throughput is 1607.4137 records/second. Loss is 0.12065169. Sequential31006cbd's hyper parameters: Current learning rate is 0.005235053921055386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 42496/60000][Iteration 4553][Wall Clock 439.728554566s] Trained 128 records in 0.079490488 seconds. Throughput is 1610.2555 records/second. Loss is 0.17473206. Sequential31006cbd's hyper parameters: Current learning rate is 0.005234505862646566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 42624/60000][Iteration 4554][Wall Clock 439.817300733s] Trained 128 records in 0.088746167 seconds. Throughput is 1442.3158 records/second. Loss is 0.27558166. Sequential31006cbd's hyper parameters: Current learning rate is 0.005233957918978331. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 42752/60000][Iteration 4555][Wall Clock 439.898911838s] Trained 128 records in 0.081611105 seconds. Throughput is 1568.4141 records/second. Loss is 0.23700365. Sequential31006cbd's hyper parameters: Current learning rate is 0.005233410090014654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 42880/60000][Iteration 4556][Wall Clock 439.972309391s] Trained 128 records in 0.073397553 seconds. Throughput is 1743.9274 records/second. Loss is 0.20102817. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052328623757195184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 43008/60000][Iteration 4557][Wall Clock 440.063046255s] Trained 128 records in 0.090736864 seconds. Throughput is 1410.6725 records/second. Loss is 0.14069456. Sequential31006cbd's hyper parameters: Current learning rate is 0.005232314776056928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 43136/60000][Iteration 4558][Wall Clock 440.143895614s] Trained 128 records in 0.080849359 seconds. Throughput is 1583.1913 records/second. Loss is 0.17901462. Sequential31006cbd's hyper parameters: Current learning rate is 0.005231767290990897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 43264/60000][Iteration 4559][Wall Clock 440.219083143s] Trained 128 records in 0.075187529 seconds. Throughput is 1702.41 records/second. Loss is 0.17054158. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052312199204854574. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 43392/60000][Iteration 4560][Wall Clock 440.297743374s] Trained 128 records in 0.078660231 seconds. Throughput is 1627.2518 records/second. Loss is 0.20978658. Sequential31006cbd's hyper parameters: Current learning rate is 0.005230672664504656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:57 INFO  DistriOptimizer$:408 - [Epoch 10 43520/60000][Iteration 4561][Wall Clock 440.401354637s] Trained 128 records in 0.103611263 seconds. Throughput is 1235.387 records/second. Loss is 0.1460666. Sequential31006cbd's hyper parameters: Current learning rate is 0.005230125523012553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 43648/60000][Iteration 4562][Wall Clock 440.497908556s] Trained 128 records in 0.096553919 seconds. Throughput is 1325.6841 records/second. Loss is 0.25067684. Sequential31006cbd's hyper parameters: Current learning rate is 0.005229578495973225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 43776/60000][Iteration 4563][Wall Clock 440.583529258s] Trained 128 records in 0.085620702 seconds. Throughput is 1494.9656 records/second. Loss is 0.18833657. Sequential31006cbd's hyper parameters: Current learning rate is 0.005229031583350764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 43904/60000][Iteration 4564][Wall Clock 440.691617035s] Trained 128 records in 0.108087777 seconds. Throughput is 1184.2227 records/second. Loss is 0.1500991. Sequential31006cbd's hyper parameters: Current learning rate is 0.005228484785109276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44032/60000][Iteration 4565][Wall Clock 440.774988137s] Trained 128 records in 0.083371102 seconds. Throughput is 1535.3042 records/second. Loss is 0.20925151. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052279381012128815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44160/60000][Iteration 4566][Wall Clock 440.864028434s] Trained 128 records in 0.089040297 seconds. Throughput is 1437.5514 records/second. Loss is 0.25900677. Sequential31006cbd's hyper parameters: Current learning rate is 0.005227391531625719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44288/60000][Iteration 4567][Wall Clock 440.94382798s] Trained 128 records in 0.079799546 seconds. Throughput is 1604.0192 records/second. Loss is 0.20393424. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052268450763119385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44416/60000][Iteration 4568][Wall Clock 441.024945024s] Trained 128 records in 0.081117044 seconds. Throughput is 1577.9668 records/second. Loss is 0.16757593. Sequential31006cbd's hyper parameters: Current learning rate is 0.005226298735235706. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44544/60000][Iteration 4569][Wall Clock 441.102899739s] Trained 128 records in 0.077954715 seconds. Throughput is 1641.9789 records/second. Loss is 0.2007399. Sequential31006cbd's hyper parameters: Current learning rate is 0.005225752508361204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44672/60000][Iteration 4570][Wall Clock 441.182585331s] Trained 128 records in 0.079685592 seconds. Throughput is 1606.313 records/second. Loss is 0.15636438. Sequential31006cbd's hyper parameters: Current learning rate is 0.005225206395652628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44800/60000][Iteration 4571][Wall Clock 441.260654493s] Trained 128 records in 0.078069162 seconds. Throughput is 1639.5718 records/second. Loss is 0.15250933. Sequential31006cbd's hyper parameters: Current learning rate is 0.00522466039707419. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 44928/60000][Iteration 4572][Wall Clock 441.338428363s] Trained 128 records in 0.07777387 seconds. Throughput is 1645.797 records/second. Loss is 0.12559138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052241145125901155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:58 INFO  DistriOptimizer$:408 - [Epoch 10 45056/60000][Iteration 4573][Wall Clock 441.422352858s] Trained 128 records in 0.083924495 seconds. Throughput is 1525.1804 records/second. Loss is 0.17041127. Sequential31006cbd's hyper parameters: Current learning rate is 0.005223568742164647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45184/60000][Iteration 4574][Wall Clock 441.497779199s] Trained 128 records in 0.075426341 seconds. Throughput is 1697.0199 records/second. Loss is 0.21252972. Sequential31006cbd's hyper parameters: Current learning rate is 0.005223023085762039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45312/60000][Iteration 4575][Wall Clock 441.570630643s] Trained 128 records in 0.072851444 seconds. Throughput is 1757.0002 records/second. Loss is 0.20481822. Sequential31006cbd's hyper parameters: Current learning rate is 0.005222477543346564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45440/60000][Iteration 4576][Wall Clock 441.644666121s] Trained 128 records in 0.074035478 seconds. Throughput is 1728.9008 records/second. Loss is 0.16112009. Sequential31006cbd's hyper parameters: Current learning rate is 0.005221932114882507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45568/60000][Iteration 4577][Wall Clock 441.723846559s] Trained 128 records in 0.079180438 seconds. Throughput is 1616.5609 records/second. Loss is 0.15901643. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052213868003341685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45696/60000][Iteration 4578][Wall Clock 441.800123116s] Trained 128 records in 0.076276557 seconds. Throughput is 1678.1041 records/second. Loss is 0.16517463. Sequential31006cbd's hyper parameters: Current learning rate is 0.005220841599665866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45824/60000][Iteration 4579][Wall Clock 441.87987974s] Trained 128 records in 0.079756624 seconds. Throughput is 1604.8823 records/second. Loss is 0.21135966. Sequential31006cbd's hyper parameters: Current learning rate is 0.00522029651284193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 45952/60000][Iteration 4580][Wall Clock 441.971651243s] Trained 128 records in 0.091771503 seconds. Throughput is 1394.7684 records/second. Loss is 0.24623835. Sequential31006cbd's hyper parameters: Current learning rate is 0.005219751539826704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 46080/60000][Iteration 4581][Wall Clock 442.046757312s] Trained 128 records in 0.075106069 seconds. Throughput is 1704.2563 records/second. Loss is 0.15128653. Sequential31006cbd's hyper parameters: Current learning rate is 0.005219206680584551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 46208/60000][Iteration 4582][Wall Clock 442.133964977s] Trained 128 records in 0.087207665 seconds. Throughput is 1467.7609 records/second. Loss is 0.21907112. Sequential31006cbd's hyper parameters: Current learning rate is 0.005218661935079846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 46336/60000][Iteration 4583][Wall Clock 442.215611741s] Trained 128 records in 0.081646764 seconds. Throughput is 1567.729 records/second. Loss is 0.22631755. Sequential31006cbd's hyper parameters: Current learning rate is 0.005218117303276978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 46464/60000][Iteration 4584][Wall Clock 442.30484021s] Trained 128 records in 0.089228469 seconds. Throughput is 1434.5198 records/second. Loss is 0.28361902. Sequential31006cbd's hyper parameters: Current learning rate is 0.005217572785140352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 46592/60000][Iteration 4585][Wall Clock 442.3877466s] Trained 128 records in 0.08290639 seconds. Throughput is 1543.91 records/second. Loss is 0.13329415. Sequential31006cbd's hyper parameters: Current learning rate is 0.005217028380634391. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:04:59 INFO  DistriOptimizer$:408 - [Epoch 10 46720/60000][Iteration 4586][Wall Clock 442.469211804s] Trained 128 records in 0.081465204 seconds. Throughput is 1571.2229 records/second. Loss is 0.21011113. Sequential31006cbd's hyper parameters: Current learning rate is 0.005216484089723527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 46848/60000][Iteration 4587][Wall Clock 442.547652797s] Trained 128 records in 0.078440993 seconds. Throughput is 1631.7998 records/second. Loss is 0.17666376. Sequential31006cbd's hyper parameters: Current learning rate is 0.005215939912372209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 46976/60000][Iteration 4588][Wall Clock 442.638160414s] Trained 128 records in 0.090507617 seconds. Throughput is 1414.2456 records/second. Loss is 0.20665273. Sequential31006cbd's hyper parameters: Current learning rate is 0.005215395848544905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47104/60000][Iteration 4589][Wall Clock 442.721840261s] Trained 128 records in 0.083679847 seconds. Throughput is 1529.6395 records/second. Loss is 0.2015332. Sequential31006cbd's hyper parameters: Current learning rate is 0.005214851898206091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47232/60000][Iteration 4590][Wall Clock 442.805095002s] Trained 128 records in 0.083254741 seconds. Throughput is 1537.45 records/second. Loss is 0.14840926. Sequential31006cbd's hyper parameters: Current learning rate is 0.005214308061320262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47360/60000][Iteration 4591][Wall Clock 442.885602274s] Trained 128 records in 0.080507272 seconds. Throughput is 1589.9185 records/second. Loss is 0.21877818. Sequential31006cbd's hyper parameters: Current learning rate is 0.005213764337851929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47488/60000][Iteration 4592][Wall Clock 442.976708008s] Trained 128 records in 0.091105734 seconds. Throughput is 1404.9609 records/second. Loss is 0.18103583. Sequential31006cbd's hyper parameters: Current learning rate is 0.005213220727765614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47616/60000][Iteration 4593][Wall Clock 443.05541862s] Trained 128 records in 0.078710612 seconds. Throughput is 1626.2101 records/second. Loss is 0.17044176. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052126772310258545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47744/60000][Iteration 4594][Wall Clock 443.143578556s] Trained 128 records in 0.088159936 seconds. Throughput is 1451.9067 records/second. Loss is 0.19708891. Sequential31006cbd's hyper parameters: Current learning rate is 0.005212133847597206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 47872/60000][Iteration 4595][Wall Clock 443.226460119s] Trained 128 records in 0.082881563 seconds. Throughput is 1544.3724 records/second. Loss is 0.262761. Sequential31006cbd's hyper parameters: Current learning rate is 0.005211590577444236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 48000/60000][Iteration 4596][Wall Clock 443.303204278s] Trained 128 records in 0.076744159 seconds. Throughput is 1667.8793 records/second. Loss is 0.14862265. Sequential31006cbd's hyper parameters: Current learning rate is 0.005211047420531527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 48128/60000][Iteration 4597][Wall Clock 443.382155276s] Trained 128 records in 0.078950998 seconds. Throughput is 1621.2588 records/second. Loss is 0.22076282. Sequential31006cbd's hyper parameters: Current learning rate is 0.005210504376823677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:00 INFO  DistriOptimizer$:408 - [Epoch 10 48256/60000][Iteration 4598][Wall Clock 443.46040065s] Trained 128 records in 0.078245374 seconds. Throughput is 1635.8795 records/second. Loss is 0.19051626. Sequential31006cbd's hyper parameters: Current learning rate is 0.005209961446285298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 48384/60000][Iteration 4599][Wall Clock 443.539687888s] Trained 128 records in 0.079287238 seconds. Throughput is 1614.3834 records/second. Loss is 0.2360868. Sequential31006cbd's hyper parameters: Current learning rate is 0.005209418628881017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 48512/60000][Iteration 4600][Wall Clock 443.619511953s] Trained 128 records in 0.079824065 seconds. Throughput is 1603.5264 records/second. Loss is 0.23497419. Sequential31006cbd's hyper parameters: Current learning rate is 0.005208875924575477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 48640/60000][Iteration 4601][Wall Clock 443.699609009s] Trained 128 records in 0.080097056 seconds. Throughput is 1598.0612 records/second. Loss is 0.269786. Sequential31006cbd's hyper parameters: Current learning rate is 0.005208333333333334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 48768/60000][Iteration 4602][Wall Clock 443.781312729s] Trained 128 records in 0.08170372 seconds. Throughput is 1566.6361 records/second. Loss is 0.14768013. Sequential31006cbd's hyper parameters: Current learning rate is 0.005207790855119259. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 48896/60000][Iteration 4603][Wall Clock 443.859516685s] Trained 128 records in 0.078203956 seconds. Throughput is 1636.7458 records/second. Loss is 0.228808. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052072484898979384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 49024/60000][Iteration 4604][Wall Clock 443.9360027s] Trained 128 records in 0.076486015 seconds. Throughput is 1673.5085 records/second. Loss is 0.2392981. Sequential31006cbd's hyper parameters: Current learning rate is 0.005206706237634072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 49152/60000][Iteration 4605][Wall Clock 444.024185178s] Trained 128 records in 0.088182478 seconds. Throughput is 1451.5355 records/second. Loss is 0.21777321. Sequential31006cbd's hyper parameters: Current learning rate is 0.005206164098292378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 49280/60000][Iteration 4606][Wall Clock 444.106870983s] Trained 128 records in 0.082685805 seconds. Throughput is 1548.0287 records/second. Loss is 0.20119818. Sequential31006cbd's hyper parameters: Current learning rate is 0.0052056220718375845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 49408/60000][Iteration 4607][Wall Clock 444.191386636s] Trained 128 records in 0.084515653 seconds. Throughput is 1514.5123 records/second. Loss is 0.3105951. Sequential31006cbd's hyper parameters: Current learning rate is 0.005205080158234437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 49536/60000][Iteration 4608][Wall Clock 444.300566811s] Trained 128 records in 0.109180175 seconds. Throughput is 1172.374 records/second. Loss is 0.13657945. Sequential31006cbd's hyper parameters: Current learning rate is 0.005204538357447695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:01 INFO  DistriOptimizer$:408 - [Epoch 10 49664/60000][Iteration 4609][Wall Clock 444.404264026s] Trained 128 records in 0.103697215 seconds. Throughput is 1234.3629 records/second. Loss is 0.13214248. Sequential31006cbd's hyper parameters: Current learning rate is 0.005203996669442131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 49792/60000][Iteration 4610][Wall Clock 444.48756885s] Trained 128 records in 0.083304824 seconds. Throughput is 1536.5256 records/second. Loss is 0.30163032. Sequential31006cbd's hyper parameters: Current learning rate is 0.005203455094182537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 49920/60000][Iteration 4611][Wall Clock 444.566374842s] Trained 128 records in 0.078805992 seconds. Throughput is 1624.2421 records/second. Loss is 0.32575062. Sequential31006cbd's hyper parameters: Current learning rate is 0.005202913631633715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50048/60000][Iteration 4612][Wall Clock 444.641969841s] Trained 128 records in 0.075594999 seconds. Throughput is 1693.2338 records/second. Loss is 0.2249956. Sequential31006cbd's hyper parameters: Current learning rate is 0.005202372281760482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50176/60000][Iteration 4613][Wall Clock 444.726906875s] Trained 128 records in 0.084937034 seconds. Throughput is 1506.9987 records/second. Loss is 0.15328068. Sequential31006cbd's hyper parameters: Current learning rate is 0.005201831044527674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50304/60000][Iteration 4614][Wall Clock 444.808806114s] Trained 128 records in 0.081899239 seconds. Throughput is 1562.896 records/second. Loss is 0.3035444. Sequential31006cbd's hyper parameters: Current learning rate is 0.005201289919900135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50432/60000][Iteration 4615][Wall Clock 444.887861366s] Trained 128 records in 0.079055252 seconds. Throughput is 1619.1208 records/second. Loss is 0.19489717. Sequential31006cbd's hyper parameters: Current learning rate is 0.00520074890784273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50560/60000][Iteration 4616][Wall Clock 444.96832602s] Trained 128 records in 0.080464654 seconds. Throughput is 1590.7606 records/second. Loss is 0.11975735. Sequential31006cbd's hyper parameters: Current learning rate is 0.005200208008320333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50688/60000][Iteration 4617][Wall Clock 445.043357536s] Trained 128 records in 0.075031516 seconds. Throughput is 1705.9497 records/second. Loss is 0.25005168. Sequential31006cbd's hyper parameters: Current learning rate is 0.005199667221297837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50816/60000][Iteration 4618][Wall Clock 445.118089051s] Trained 128 records in 0.074731515 seconds. Throughput is 1712.7982 records/second. Loss is 0.13644905. Sequential31006cbd's hyper parameters: Current learning rate is 0.005199126546740148. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 50944/60000][Iteration 4619][Wall Clock 445.193680711s] Trained 128 records in 0.07559166 seconds. Throughput is 1693.3085 records/second. Loss is 0.21040012. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051985859846121855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 51072/60000][Iteration 4620][Wall Clock 445.272165964s] Trained 128 records in 0.078485253 seconds. Throughput is 1630.8796 records/second. Loss is 0.103156924. Sequential31006cbd's hyper parameters: Current learning rate is 0.005198045534878886. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 51200/60000][Iteration 4621][Wall Clock 445.346784559s] Trained 128 records in 0.074618595 seconds. Throughput is 1715.3901 records/second. Loss is 0.12865724. Sequential31006cbd's hyper parameters: Current learning rate is 0.005197505197505198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:02 INFO  DistriOptimizer$:408 - [Epoch 10 51328/60000][Iteration 4622][Wall Clock 445.419233958s] Trained 128 records in 0.072449399 seconds. Throughput is 1766.7502 records/second. Loss is 0.256204. Sequential31006cbd's hyper parameters: Current learning rate is 0.005196964972456086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 51456/60000][Iteration 4623][Wall Clock 445.496279739s] Trained 128 records in 0.077045781 seconds. Throughput is 1661.3499 records/second. Loss is 0.22868831. Sequential31006cbd's hyper parameters: Current learning rate is 0.005196424859696529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 51584/60000][Iteration 4624][Wall Clock 445.580169427s] Trained 128 records in 0.083889688 seconds. Throughput is 1525.8134 records/second. Loss is 0.24684137. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051958848591915205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 51712/60000][Iteration 4625][Wall Clock 445.663949958s] Trained 128 records in 0.083780531 seconds. Throughput is 1527.8011 records/second. Loss is 0.17179713. Sequential31006cbd's hyper parameters: Current learning rate is 0.005195344970906068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 51840/60000][Iteration 4626][Wall Clock 445.746530392s] Trained 128 records in 0.082580434 seconds. Throughput is 1550.004 records/second. Loss is 0.295964. Sequential31006cbd's hyper parameters: Current learning rate is 0.005194805194805195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 51968/60000][Iteration 4627][Wall Clock 445.834466444s] Trained 128 records in 0.087936052 seconds. Throughput is 1455.6033 records/second. Loss is 0.22571579. Sequential31006cbd's hyper parameters: Current learning rate is 0.005194265530853937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52096/60000][Iteration 4628][Wall Clock 445.916817301s] Trained 128 records in 0.082350857 seconds. Throughput is 1554.3251 records/second. Loss is 0.14511168. Sequential31006cbd's hyper parameters: Current learning rate is 0.005193725979017347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52224/60000][Iteration 4629][Wall Clock 445.998427661s] Trained 128 records in 0.08161036 seconds. Throughput is 1568.4283 records/second. Loss is 0.2228836. Sequential31006cbd's hyper parameters: Current learning rate is 0.00519318653926049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52352/60000][Iteration 4630][Wall Clock 446.080153848s] Trained 128 records in 0.081726187 seconds. Throughput is 1566.2054 records/second. Loss is 0.18016165. Sequential31006cbd's hyper parameters: Current learning rate is 0.005192647211548447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52480/60000][Iteration 4631][Wall Clock 446.179203438s] Trained 128 records in 0.09904959 seconds. Throughput is 1292.282 records/second. Loss is 0.20101437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005192107995846313. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52608/60000][Iteration 4632][Wall Clock 446.259355143s] Trained 128 records in 0.080151705 seconds. Throughput is 1596.9716 records/second. Loss is 0.14980182. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051915688921191985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52736/60000][Iteration 4633][Wall Clock 446.348241821s] Trained 128 records in 0.088886678 seconds. Throughput is 1440.0358 records/second. Loss is 0.21116161. Sequential31006cbd's hyper parameters: Current learning rate is 0.005191029900332226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:03 INFO  DistriOptimizer$:408 - [Epoch 10 52864/60000][Iteration 4634][Wall Clock 446.430629735s] Trained 128 records in 0.082387914 seconds. Throughput is 1553.6259 records/second. Loss is 0.18082348. Sequential31006cbd's hyper parameters: Current learning rate is 0.005190491020450535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 52992/60000][Iteration 4635][Wall Clock 446.511953312s] Trained 128 records in 0.081323577 seconds. Throughput is 1573.9592 records/second. Loss is 0.27502522. Sequential31006cbd's hyper parameters: Current learning rate is 0.005189952252439277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53120/60000][Iteration 4636][Wall Clock 446.593415163s] Trained 128 records in 0.081461851 seconds. Throughput is 1571.2876 records/second. Loss is 0.26811755. Sequential31006cbd's hyper parameters: Current learning rate is 0.005189413596263622. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53248/60000][Iteration 4637][Wall Clock 446.674804153s] Trained 128 records in 0.08138899 seconds. Throughput is 1572.6943 records/second. Loss is 0.21604082. Sequential31006cbd's hyper parameters: Current learning rate is 0.00518887505188875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53376/60000][Iteration 4638][Wall Clock 446.750349633s] Trained 128 records in 0.07554548 seconds. Throughput is 1694.3435 records/second. Loss is 0.19309019. Sequential31006cbd's hyper parameters: Current learning rate is 0.005188336619279859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53504/60000][Iteration 4639][Wall Clock 446.83836516s] Trained 128 records in 0.088015527 seconds. Throughput is 1454.2888 records/second. Loss is 0.2090536. Sequential31006cbd's hyper parameters: Current learning rate is 0.005187798298402158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53632/60000][Iteration 4640][Wall Clock 446.922239994s] Trained 128 records in 0.083874834 seconds. Throughput is 1526.0835 records/second. Loss is 0.25671056. Sequential31006cbd's hyper parameters: Current learning rate is 0.005187260089220874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53760/60000][Iteration 4641][Wall Clock 446.996999723s] Trained 128 records in 0.074759729 seconds. Throughput is 1712.1517 records/second. Loss is 0.20501396. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051867219917012455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 53888/60000][Iteration 4642][Wall Clock 447.076241632s] Trained 128 records in 0.079241909 seconds. Throughput is 1615.3069 records/second. Loss is 0.18847442. Sequential31006cbd's hyper parameters: Current learning rate is 0.005186184005808526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 54016/60000][Iteration 4643][Wall Clock 447.150826046s] Trained 128 records in 0.074584414 seconds. Throughput is 1716.1761 records/second. Loss is 0.1798916. Sequential31006cbd's hyper parameters: Current learning rate is 0.005185646131507986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 54144/60000][Iteration 4644][Wall Clock 447.229820877s] Trained 128 records in 0.078994831 seconds. Throughput is 1620.3591 records/second. Loss is 0.15096739. Sequential31006cbd's hyper parameters: Current learning rate is 0.005185108368764907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 54272/60000][Iteration 4645][Wall Clock 447.316747438s] Trained 128 records in 0.086926561 seconds. Throughput is 1472.5073 records/second. Loss is 0.17320734. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051845707175445874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:04 INFO  DistriOptimizer$:408 - [Epoch 10 54400/60000][Iteration 4646][Wall Clock 447.404317079s] Trained 128 records in 0.087569641 seconds. Throughput is 1461.6938 records/second. Loss is 0.18774772. Sequential31006cbd's hyper parameters: Current learning rate is 0.005184033177812338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 54528/60000][Iteration 4647][Wall Clock 447.47983768s] Trained 128 records in 0.075520601 seconds. Throughput is 1694.9019 records/second. Loss is 0.188538. Sequential31006cbd's hyper parameters: Current learning rate is 0.005183495749533485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 54656/60000][Iteration 4648][Wall Clock 447.556787796s] Trained 128 records in 0.076950116 seconds. Throughput is 1663.4153 records/second. Loss is 0.12223087. Sequential31006cbd's hyper parameters: Current learning rate is 0.00518295843267337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 54784/60000][Iteration 4649][Wall Clock 447.63852561s] Trained 128 records in 0.081737814 seconds. Throughput is 1565.9827 records/second. Loss is 0.25692922. Sequential31006cbd's hyper parameters: Current learning rate is 0.005182421227197346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 54912/60000][Iteration 4650][Wall Clock 447.71253642s] Trained 128 records in 0.07401081 seconds. Throughput is 1729.477 records/second. Loss is 0.25143537. Sequential31006cbd's hyper parameters: Current learning rate is 0.005181884133070784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55040/60000][Iteration 4651][Wall Clock 447.788957592s] Trained 128 records in 0.076421172 seconds. Throughput is 1674.9285 records/second. Loss is 0.21577197. Sequential31006cbd's hyper parameters: Current learning rate is 0.005181347150259067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55168/60000][Iteration 4652][Wall Clock 447.867505415s] Trained 128 records in 0.078547823 seconds. Throughput is 1629.5806 records/second. Loss is 0.11486457. Sequential31006cbd's hyper parameters: Current learning rate is 0.005180810278727592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55296/60000][Iteration 4653][Wall Clock 447.946807877s] Trained 128 records in 0.079302462 seconds. Throughput is 1614.0735 records/second. Loss is 0.25382143. Sequential31006cbd's hyper parameters: Current learning rate is 0.005180273518441774. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55424/60000][Iteration 4654][Wall Clock 448.037502049s] Trained 128 records in 0.090694172 seconds. Throughput is 1411.3365 records/second. Loss is 0.25849316. Sequential31006cbd's hyper parameters: Current learning rate is 0.005179736869367036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55552/60000][Iteration 4655][Wall Clock 448.115051223s] Trained 128 records in 0.077549174 seconds. Throughput is 1650.5656 records/second. Loss is 0.18493056. Sequential31006cbd's hyper parameters: Current learning rate is 0.005179200331468821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55680/60000][Iteration 4656][Wall Clock 448.189138541s] Trained 128 records in 0.074087318 seconds. Throughput is 1727.6912 records/second. Loss is 0.19793868. Sequential31006cbd's hyper parameters: Current learning rate is 0.005178663904712584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55808/60000][Iteration 4657][Wall Clock 448.284795707s] Trained 128 records in 0.095657166 seconds. Throughput is 1338.112 records/second. Loss is 0.1476132. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051781275890637945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 55936/60000][Iteration 4658][Wall Clock 448.372308722s] Trained 128 records in 0.087513015 seconds. Throughput is 1462.6396 records/second. Loss is 0.1949837. Sequential31006cbd's hyper parameters: Current learning rate is 0.005177591384487936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:05 INFO  DistriOptimizer$:408 - [Epoch 10 56064/60000][Iteration 4659][Wall Clock 448.447547675s] Trained 128 records in 0.075238953 seconds. Throughput is 1701.2465 records/second. Loss is 0.18676612. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051770552909505075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56192/60000][Iteration 4660][Wall Clock 448.523619327s] Trained 128 records in 0.076071652 seconds. Throughput is 1682.6243 records/second. Loss is 0.2131628. Sequential31006cbd's hyper parameters: Current learning rate is 0.00517651930841702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56320/60000][Iteration 4661][Wall Clock 448.604648818s] Trained 128 records in 0.081029491 seconds. Throughput is 1579.6718 records/second. Loss is 0.1888567. Sequential31006cbd's hyper parameters: Current learning rate is 0.005175983436853002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56448/60000][Iteration 4662][Wall Clock 448.684134734s] Trained 128 records in 0.079485916 seconds. Throughput is 1610.3481 records/second. Loss is 0.14930765. Sequential31006cbd's hyper parameters: Current learning rate is 0.005175447676223994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56576/60000][Iteration 4663][Wall Clock 448.769207717s] Trained 128 records in 0.085072983 seconds. Throughput is 1504.5906 records/second. Loss is 0.22935122. Sequential31006cbd's hyper parameters: Current learning rate is 0.00517491202649555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56704/60000][Iteration 4664][Wall Clock 448.846864821s] Trained 128 records in 0.077657104 seconds. Throughput is 1648.2716 records/second. Loss is 0.21944208. Sequential31006cbd's hyper parameters: Current learning rate is 0.00517437648763324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56832/60000][Iteration 4665][Wall Clock 448.969300773s] Trained 128 records in 0.122435952 seconds. Throughput is 1045.4446 records/second. Loss is 0.19082998. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051738410596026485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 56960/60000][Iteration 4666][Wall Clock 449.061602827s] Trained 128 records in 0.092302054 seconds. Throughput is 1386.7513 records/second. Loss is 0.2597615. Sequential31006cbd's hyper parameters: Current learning rate is 0.005173305742369374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 57088/60000][Iteration 4667][Wall Clock 449.145012295s] Trained 128 records in 0.083409468 seconds. Throughput is 1534.598 records/second. Loss is 0.23859887. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051727705358990276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 57216/60000][Iteration 4668][Wall Clock 449.22578422s] Trained 128 records in 0.080771925 seconds. Throughput is 1584.7091 records/second. Loss is 0.16858941. Sequential31006cbd's hyper parameters: Current learning rate is 0.005172235440157236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 57344/60000][Iteration 4669][Wall Clock 449.299321628s] Trained 128 records in 0.073537408 seconds. Throughput is 1740.6107 records/second. Loss is 0.15415989. Sequential31006cbd's hyper parameters: Current learning rate is 0.00517170045510964. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 57472/60000][Iteration 4670][Wall Clock 449.374454927s] Trained 128 records in 0.075133299 seconds. Throughput is 1703.6387 records/second. Loss is 0.25623262. Sequential31006cbd's hyper parameters: Current learning rate is 0.005171165580721894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:06 INFO  DistriOptimizer$:408 - [Epoch 10 57600/60000][Iteration 4671][Wall Clock 449.446500803s] Trained 128 records in 0.072045876 seconds. Throughput is 1776.6458 records/second. Loss is 0.19084768. Sequential31006cbd's hyper parameters: Current learning rate is 0.005170630816959669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 57728/60000][Iteration 4672][Wall Clock 449.525983848s] Trained 128 records in 0.079483045 seconds. Throughput is 1610.4062 records/second. Loss is 0.1303439. Sequential31006cbd's hyper parameters: Current learning rate is 0.005170096163788647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 57856/60000][Iteration 4673][Wall Clock 449.611273096s] Trained 128 records in 0.085289248 seconds. Throughput is 1500.7754 records/second. Loss is 0.2652401. Sequential31006cbd's hyper parameters: Current learning rate is 0.005169561621174525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 57984/60000][Iteration 4674][Wall Clock 449.691932336s] Trained 128 records in 0.08065924 seconds. Throughput is 1586.923 records/second. Loss is 0.19603813. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051690271890830145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58112/60000][Iteration 4675][Wall Clock 449.766578363s] Trained 128 records in 0.074646027 seconds. Throughput is 1714.7598 records/second. Loss is 0.122951366. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051684928674798425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58240/60000][Iteration 4676][Wall Clock 449.840317818s] Trained 128 records in 0.073739455 seconds. Throughput is 1735.8414 records/second. Loss is 0.12126212. Sequential31006cbd's hyper parameters: Current learning rate is 0.00516795865633075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58368/60000][Iteration 4677][Wall Clock 449.91682099s] Trained 128 records in 0.076503172 seconds. Throughput is 1673.1332 records/second. Loss is 0.21768627. Sequential31006cbd's hyper parameters: Current learning rate is 0.005167424555601488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58496/60000][Iteration 4678][Wall Clock 449.995118175s] Trained 128 records in 0.078297185 seconds. Throughput is 1634.797 records/second. Loss is 0.16037564. Sequential31006cbd's hyper parameters: Current learning rate is 0.005166890565257828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58624/60000][Iteration 4679][Wall Clock 450.074078297s] Trained 128 records in 0.078960122 seconds. Throughput is 1621.0715 records/second. Loss is 0.21459666. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051663566852655505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58752/60000][Iteration 4680][Wall Clock 450.153514841s] Trained 128 records in 0.079436544 seconds. Throughput is 1611.3491 records/second. Loss is 0.18434235. Sequential31006cbd's hyper parameters: Current learning rate is 0.005165822915590454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 58880/60000][Iteration 4681][Wall Clock 450.231312614s] Trained 128 records in 0.077797773 seconds. Throughput is 1645.2914 records/second. Loss is 0.15485808. Sequential31006cbd's hyper parameters: Current learning rate is 0.005165289256198347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 59008/60000][Iteration 4682][Wall Clock 450.318323087s] Trained 128 records in 0.087010473 seconds. Throughput is 1471.0873 records/second. Loss is 0.22920115. Sequential31006cbd's hyper parameters: Current learning rate is 0.005164755707055057. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:07 INFO  DistriOptimizer$:408 - [Epoch 10 59136/60000][Iteration 4683][Wall Clock 450.396939452s] Trained 128 records in 0.078616365 seconds. Throughput is 1628.1597 records/second. Loss is 0.12361351. Sequential31006cbd's hyper parameters: Current learning rate is 0.005164222268126421. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 59264/60000][Iteration 4684][Wall Clock 450.473841537s] Trained 128 records in 0.076902085 seconds. Throughput is 1664.4542 records/second. Loss is 0.3524132. Sequential31006cbd's hyper parameters: Current learning rate is 0.005163688939378292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 59392/60000][Iteration 4685][Wall Clock 450.549302104s] Trained 128 records in 0.075460567 seconds. Throughput is 1696.2501 records/second. Loss is 0.16384056. Sequential31006cbd's hyper parameters: Current learning rate is 0.005163155720776538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 59520/60000][Iteration 4686][Wall Clock 450.630945949s] Trained 128 records in 0.081643845 seconds. Throughput is 1567.7852 records/second. Loss is 0.24098602. Sequential31006cbd's hyper parameters: Current learning rate is 0.005162622612287042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 59648/60000][Iteration 4687][Wall Clock 450.718533671s] Trained 128 records in 0.087587722 seconds. Throughput is 1461.3921 records/second. Loss is 0.27502358. Sequential31006cbd's hyper parameters: Current learning rate is 0.005162089613875697. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 59776/60000][Iteration 4688][Wall Clock 450.797770562s] Trained 128 records in 0.079236891 seconds. Throughput is 1615.4092 records/second. Loss is 0.18924943. Sequential31006cbd's hyper parameters: Current learning rate is 0.005161556725508413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 59904/60000][Iteration 4689][Wall Clock 450.87196388s] Trained 128 records in 0.074193318 seconds. Throughput is 1725.2227 records/second. Loss is 0.2079688. Sequential31006cbd's hyper parameters: Current learning rate is 0.005161023947151114. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:408 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 450.955257643s] Trained 128 records in 0.083293763 seconds. Throughput is 1536.7296 records/second. Loss is 0.15800698. Sequential31006cbd's hyper parameters: Current learning rate is 0.005160491278769739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:08 INFO  DistriOptimizer$:452 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 450.955257643s] Epoch finished. Wall clock time is 452035.143379 ms
2019-10-24 00:05:08 INFO  DistriOptimizer$:111 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 450.955257643s] Validate model...
2019-10-24 00:05:09 INFO  DistriOptimizer$:178 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 450.955257643s] validate model throughput is 11883.719 records/second
2019-10-24 00:05:09 INFO  DistriOptimizer$:181 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 450.955257643s] Top1Accuracy is Accuracy(correct: 9449, count: 10000, accuracy: 0.9449)
2019-10-24 00:05:09 INFO  DistriOptimizer$:221 - [Wall Clock 452.035143379s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:05:09 INFO  DistriOptimizer$:226 - [Wall Clock 452.035143379s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 128/60000][Iteration 4691][Wall Clock 452.12342198s] Trained 128 records in 0.088278601 seconds. Throughput is 1449.9551 records/second. Loss is 0.17859757. Sequential31006cbd's hyper parameters: Current learning rate is 0.005159958720330237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 256/60000][Iteration 4692][Wall Clock 452.200707632s] Trained 128 records in 0.077285652 seconds. Throughput is 1656.1935 records/second. Loss is 0.2678401. Sequential31006cbd's hyper parameters: Current learning rate is 0.005159426271798576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 384/60000][Iteration 4693][Wall Clock 452.277858332s] Trained 128 records in 0.0771507 seconds. Throughput is 1659.0906 records/second. Loss is 0.18477347. Sequential31006cbd's hyper parameters: Current learning rate is 0.005158893933140734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 512/60000][Iteration 4694][Wall Clock 452.356555902s] Trained 128 records in 0.07869757 seconds. Throughput is 1626.4797 records/second. Loss is 0.21518628. Sequential31006cbd's hyper parameters: Current learning rate is 0.005158361704322707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 640/60000][Iteration 4695][Wall Clock 452.437499911s] Trained 128 records in 0.080944009 seconds. Throughput is 1581.34 records/second. Loss is 0.29322243. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051578295853105015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 768/60000][Iteration 4696][Wall Clock 452.516810321s] Trained 128 records in 0.07931041 seconds. Throughput is 1613.9117 records/second. Loss is 0.24220121. Sequential31006cbd's hyper parameters: Current learning rate is 0.005157297576070139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:09 INFO  DistriOptimizer$:408 - [Epoch 11 896/60000][Iteration 4697][Wall Clock 452.596565874s] Trained 128 records in 0.079755553 seconds. Throughput is 1604.9039 records/second. Loss is 0.17045027. Sequential31006cbd's hyper parameters: Current learning rate is 0.005156765676567657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1024/60000][Iteration 4698][Wall Clock 452.67213051s] Trained 128 records in 0.075564636 seconds. Throughput is 1693.9141 records/second. Loss is 0.15200043. Sequential31006cbd's hyper parameters: Current learning rate is 0.005156233886769104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1152/60000][Iteration 4699][Wall Clock 452.747479677s] Trained 128 records in 0.075349167 seconds. Throughput is 1698.758 records/second. Loss is 0.19170392. Sequential31006cbd's hyper parameters: Current learning rate is 0.005155702206640545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1280/60000][Iteration 4700][Wall Clock 452.831378004s] Trained 128 records in 0.083898327 seconds. Throughput is 1525.6561 records/second. Loss is 0.21109173. Sequential31006cbd's hyper parameters: Current learning rate is 0.005155170636148057. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1408/60000][Iteration 4701][Wall Clock 452.907302421s] Trained 128 records in 0.075924417 seconds. Throughput is 1685.8871 records/second. Loss is 0.23256543. Sequential31006cbd's hyper parameters: Current learning rate is 0.005154639175257732. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1536/60000][Iteration 4702][Wall Clock 452.991924622s] Trained 128 records in 0.084622201 seconds. Throughput is 1512.6053 records/second. Loss is 0.17699137. Sequential31006cbd's hyper parameters: Current learning rate is 0.005154107823935677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1664/60000][Iteration 4703][Wall Clock 453.065725626s] Trained 128 records in 0.073801004 seconds. Throughput is 1734.3938 records/second. Loss is 0.14337742. Sequential31006cbd's hyper parameters: Current learning rate is 0.005153576582148011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1792/60000][Iteration 4704][Wall Clock 453.142634424s] Trained 128 records in 0.076908798 seconds. Throughput is 1664.309 records/second. Loss is 0.13432479. Sequential31006cbd's hyper parameters: Current learning rate is 0.005153045449860868. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 1920/60000][Iteration 4705][Wall Clock 453.218349382s] Trained 128 records in 0.075714958 seconds. Throughput is 1690.551 records/second. Loss is 0.19439794. Sequential31006cbd's hyper parameters: Current learning rate is 0.005152514427040396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 2048/60000][Iteration 4706][Wall Clock 453.310885396s] Trained 128 records in 0.092536014 seconds. Throughput is 1383.2452 records/second. Loss is 0.2572543. Sequential31006cbd's hyper parameters: Current learning rate is 0.005151983513652756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 2176/60000][Iteration 4707][Wall Clock 453.39025221s] Trained 128 records in 0.079366814 seconds. Throughput is 1612.7648 records/second. Loss is 0.11997965. Sequential31006cbd's hyper parameters: Current learning rate is 0.005151452709664125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 2304/60000][Iteration 4708][Wall Clock 453.472144868s] Trained 128 records in 0.081892658 seconds. Throughput is 1563.0217 records/second. Loss is 0.18076283. Sequential31006cbd's hyper parameters: Current learning rate is 0.005150922015040692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:10 INFO  DistriOptimizer$:408 - [Epoch 11 2432/60000][Iteration 4709][Wall Clock 453.550956718s] Trained 128 records in 0.07881185 seconds. Throughput is 1624.1213 records/second. Loss is 0.15971805. Sequential31006cbd's hyper parameters: Current learning rate is 0.005150391429748661. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 2560/60000][Iteration 4710][Wall Clock 453.626170601s] Trained 128 records in 0.075213883 seconds. Throughput is 1701.8136 records/second. Loss is 0.17096694. Sequential31006cbd's hyper parameters: Current learning rate is 0.005149860953754248. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 2688/60000][Iteration 4711][Wall Clock 453.702148044s] Trained 128 records in 0.075977443 seconds. Throughput is 1684.7106 records/second. Loss is 0.2161059. Sequential31006cbd's hyper parameters: Current learning rate is 0.005149330587023686. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 2816/60000][Iteration 4712][Wall Clock 453.778510202s] Trained 128 records in 0.076362158 seconds. Throughput is 1676.223 records/second. Loss is 0.1534112. Sequential31006cbd's hyper parameters: Current learning rate is 0.005148800329523221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 2944/60000][Iteration 4713][Wall Clock 453.863745846s] Trained 128 records in 0.085235644 seconds. Throughput is 1501.7192 records/second. Loss is 0.22130226. Sequential31006cbd's hyper parameters: Current learning rate is 0.00514827018121911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3072/60000][Iteration 4714][Wall Clock 453.954237579s] Trained 128 records in 0.090491733 seconds. Throughput is 1414.4938 records/second. Loss is 0.17931053. Sequential31006cbd's hyper parameters: Current learning rate is 0.005147740142077628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3200/60000][Iteration 4715][Wall Clock 454.05214205s] Trained 128 records in 0.097904471 seconds. Throughput is 1307.3969 records/second. Loss is 0.18223579. Sequential31006cbd's hyper parameters: Current learning rate is 0.005147210212065061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3328/60000][Iteration 4716][Wall Clock 454.137926903s] Trained 128 records in 0.085784853 seconds. Throughput is 1492.1049 records/second. Loss is 0.17100206. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051466803911477095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3456/60000][Iteration 4717][Wall Clock 454.217715714s] Trained 128 records in 0.079788811 seconds. Throughput is 1604.235 records/second. Loss is 0.2307857. Sequential31006cbd's hyper parameters: Current learning rate is 0.00514615067929189. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3584/60000][Iteration 4718][Wall Clock 454.295981325s] Trained 128 records in 0.078265611 seconds. Throughput is 1635.4565 records/second. Loss is 0.19074601. Sequential31006cbd's hyper parameters: Current learning rate is 0.005145621076463929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3712/60000][Iteration 4719][Wall Clock 454.376252088s] Trained 128 records in 0.080270763 seconds. Throughput is 1594.603 records/second. Loss is 0.20372906. Sequential31006cbd's hyper parameters: Current learning rate is 0.005145091582630171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3840/60000][Iteration 4720][Wall Clock 454.458088352s] Trained 128 records in 0.081836264 seconds. Throughput is 1564.0989 records/second. Loss is 0.24428928. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051445621977569715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:11 INFO  DistriOptimizer$:408 - [Epoch 11 3968/60000][Iteration 4721][Wall Clock 454.546745835s] Trained 128 records in 0.088657483 seconds. Throughput is 1443.7585 records/second. Loss is 0.24140361. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051440329218107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4096/60000][Iteration 4722][Wall Clock 454.626949931s] Trained 128 records in 0.080204096 seconds. Throughput is 1595.9283 records/second. Loss is 0.174678. Sequential31006cbd's hyper parameters: Current learning rate is 0.005143503754757741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4224/60000][Iteration 4723][Wall Clock 454.714702102s] Trained 128 records in 0.087752171 seconds. Throughput is 1458.6533 records/second. Loss is 0.2017832. Sequential31006cbd's hyper parameters: Current learning rate is 0.005142974696564493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4352/60000][Iteration 4724][Wall Clock 454.792378206s] Trained 128 records in 0.077676104 seconds. Throughput is 1647.8684 records/second. Loss is 0.16586979. Sequential31006cbd's hyper parameters: Current learning rate is 0.005142445747197367. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4480/60000][Iteration 4725][Wall Clock 454.876727319s] Trained 128 records in 0.084349113 seconds. Throughput is 1517.5027 records/second. Loss is 0.25588125. Sequential31006cbd's hyper parameters: Current learning rate is 0.005141916906622789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4608/60000][Iteration 4726][Wall Clock 454.959841784s] Trained 128 records in 0.083114465 seconds. Throughput is 1540.0448 records/second. Loss is 0.20851326. Sequential31006cbd's hyper parameters: Current learning rate is 0.005141388174807198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4736/60000][Iteration 4727][Wall Clock 455.041410989s] Trained 128 records in 0.081569205 seconds. Throughput is 1569.2197 records/second. Loss is 0.15155269. Sequential31006cbd's hyper parameters: Current learning rate is 0.005140859551717047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4864/60000][Iteration 4728][Wall Clock 455.115024685s] Trained 128 records in 0.073613696 seconds. Throughput is 1738.8069 records/second. Loss is 0.20284398. Sequential31006cbd's hyper parameters: Current learning rate is 0.005140331037318803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 4992/60000][Iteration 4729][Wall Clock 455.196946846s] Trained 128 records in 0.081922161 seconds. Throughput is 1562.4589 records/second. Loss is 0.14394115. Sequential31006cbd's hyper parameters: Current learning rate is 0.005139802631578948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 5120/60000][Iteration 4730][Wall Clock 455.278023719s] Trained 128 records in 0.081076873 seconds. Throughput is 1578.7485 records/second. Loss is 0.19900128. Sequential31006cbd's hyper parameters: Current learning rate is 0.005139274334463973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 5248/60000][Iteration 4731][Wall Clock 455.357399591s] Trained 128 records in 0.079375872 seconds. Throughput is 1612.5807 records/second. Loss is 0.2708406. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051387461459403904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 5376/60000][Iteration 4732][Wall Clock 455.460675264s] Trained 128 records in 0.103275673 seconds. Throughput is 1239.4012 records/second. Loss is 0.31585893. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051382180659747196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:12 INFO  DistriOptimizer$:408 - [Epoch 11 5504/60000][Iteration 4733][Wall Clock 455.538920554s] Trained 128 records in 0.07824529 seconds. Throughput is 1635.8812 records/second. Loss is 0.1923719. Sequential31006cbd's hyper parameters: Current learning rate is 0.005137690094533498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 5632/60000][Iteration 4734][Wall Clock 455.614110007s] Trained 128 records in 0.075189453 seconds. Throughput is 1702.3663 records/second. Loss is 0.13848762. Sequential31006cbd's hyper parameters: Current learning rate is 0.005137162231583273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 5760/60000][Iteration 4735][Wall Clock 455.692490231s] Trained 128 records in 0.078380224 seconds. Throughput is 1633.065 records/second. Loss is 0.22387552. Sequential31006cbd's hyper parameters: Current learning rate is 0.00513663447709061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 5888/60000][Iteration 4736][Wall Clock 455.788692293s] Trained 128 records in 0.096202062 seconds. Throughput is 1330.5328 records/second. Loss is 0.14605358. Sequential31006cbd's hyper parameters: Current learning rate is 0.005136106831022085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6016/60000][Iteration 4737][Wall Clock 455.881797772s] Trained 128 records in 0.093105479 seconds. Throughput is 1374.7848 records/second. Loss is 0.12772292. Sequential31006cbd's hyper parameters: Current learning rate is 0.005135579293344289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6144/60000][Iteration 4738][Wall Clock 455.960033485s] Trained 128 records in 0.078235713 seconds. Throughput is 1636.0814 records/second. Loss is 0.21749066. Sequential31006cbd's hyper parameters: Current learning rate is 0.005135051864023826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6272/60000][Iteration 4739][Wall Clock 456.037772879s] Trained 128 records in 0.077739394 seconds. Throughput is 1646.5269 records/second. Loss is 0.23736252. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051345245430273155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6400/60000][Iteration 4740][Wall Clock 456.145393206s] Trained 128 records in 0.107620327 seconds. Throughput is 1189.3663 records/second. Loss is 0.2990774. Sequential31006cbd's hyper parameters: Current learning rate is 0.005133997330321389. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6528/60000][Iteration 4741][Wall Clock 456.240246435s] Trained 128 records in 0.094853229 seconds. Throughput is 1349.4532 records/second. Loss is 0.09041738. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051334702258726906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6656/60000][Iteration 4742][Wall Clock 456.323143286s] Trained 128 records in 0.082896851 seconds. Throughput is 1544.0876 records/second. Loss is 0.33937085. Sequential31006cbd's hyper parameters: Current learning rate is 0.005132943229647881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6784/60000][Iteration 4743][Wall Clock 456.398858136s] Trained 128 records in 0.07571485 seconds. Throughput is 1690.5535 records/second. Loss is 0.19707496. Sequential31006cbd's hyper parameters: Current learning rate is 0.005132416341613632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 6912/60000][Iteration 4744][Wall Clock 456.481546625s] Trained 128 records in 0.082688489 seconds. Throughput is 1547.9785 records/second. Loss is 0.14398004. Sequential31006cbd's hyper parameters: Current learning rate is 0.005131889561736632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:13 INFO  DistriOptimizer$:408 - [Epoch 11 7040/60000][Iteration 4745][Wall Clock 456.561041121s] Trained 128 records in 0.079494496 seconds. Throughput is 1610.1743 records/second. Loss is 0.17836326. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051313628899835794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7168/60000][Iteration 4746][Wall Clock 456.637285678s] Trained 128 records in 0.076244557 seconds. Throughput is 1678.8083 records/second. Loss is 0.20143057. Sequential31006cbd's hyper parameters: Current learning rate is 0.00513083632632119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7296/60000][Iteration 4747][Wall Clock 456.722129331s] Trained 128 records in 0.084843653 seconds. Throughput is 1508.6573 records/second. Loss is 0.10656014. Sequential31006cbd's hyper parameters: Current learning rate is 0.005130309870716191. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7424/60000][Iteration 4748][Wall Clock 456.800636865s] Trained 128 records in 0.078507534 seconds. Throughput is 1630.4167 records/second. Loss is 0.13804933. Sequential31006cbd's hyper parameters: Current learning rate is 0.005129783523135324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7552/60000][Iteration 4749][Wall Clock 456.898851807s] Trained 128 records in 0.098214942 seconds. Throughput is 1303.264 records/second. Loss is 0.31125498. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051292572835453425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7680/60000][Iteration 4750][Wall Clock 456.987404805s] Trained 128 records in 0.088552998 seconds. Throughput is 1445.462 records/second. Loss is 0.2577829. Sequential31006cbd's hyper parameters: Current learning rate is 0.005128731151913016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7808/60000][Iteration 4751][Wall Clock 457.067089512s] Trained 128 records in 0.079684707 seconds. Throughput is 1606.3308 records/second. Loss is 0.15432599. Sequential31006cbd's hyper parameters: Current learning rate is 0.005128205128205128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 7936/60000][Iteration 4752][Wall Clock 457.154339675s] Trained 128 records in 0.087250163 seconds. Throughput is 1467.0459 records/second. Loss is 0.1835419. Sequential31006cbd's hyper parameters: Current learning rate is 0.005127679212388473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 8064/60000][Iteration 4753][Wall Clock 457.235914983s] Trained 128 records in 0.081575308 seconds. Throughput is 1569.1022 records/second. Loss is 0.22579867. Sequential31006cbd's hyper parameters: Current learning rate is 0.00512715340442986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 8192/60000][Iteration 4754][Wall Clock 457.317652343s] Trained 128 records in 0.08173736 seconds. Throughput is 1565.9913 records/second. Loss is 0.18597238. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051266277042961135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 8320/60000][Iteration 4755][Wall Clock 457.400776816s] Trained 128 records in 0.083124473 seconds. Throughput is 1539.8594 records/second. Loss is 0.30479935. Sequential31006cbd's hyper parameters: Current learning rate is 0.00512610211195407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:14 INFO  DistriOptimizer$:408 - [Epoch 11 8448/60000][Iteration 4756][Wall Clock 457.505243958s] Trained 128 records in 0.104467142 seconds. Throughput is 1225.2656 records/second. Loss is 0.17393842. Sequential31006cbd's hyper parameters: Current learning rate is 0.005125576627370579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 8576/60000][Iteration 4757][Wall Clock 457.60561431s] Trained 128 records in 0.100370352 seconds. Throughput is 1275.277 records/second. Loss is 0.2591322. Sequential31006cbd's hyper parameters: Current learning rate is 0.005125051250512505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 8704/60000][Iteration 4758][Wall Clock 457.685921123s] Trained 128 records in 0.080306813 seconds. Throughput is 1593.8872 records/second. Loss is 0.19409837. Sequential31006cbd's hyper parameters: Current learning rate is 0.005124525981346726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 8832/60000][Iteration 4759][Wall Clock 457.783833493s] Trained 128 records in 0.09791237 seconds. Throughput is 1307.2914 records/second. Loss is 0.107306615. Sequential31006cbd's hyper parameters: Current learning rate is 0.005124000819840132. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 8960/60000][Iteration 4760][Wall Clock 457.869454799s] Trained 128 records in 0.085621306 seconds. Throughput is 1494.9551 records/second. Loss is 0.111661926. Sequential31006cbd's hyper parameters: Current learning rate is 0.005123475765959627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9088/60000][Iteration 4761][Wall Clock 457.96323601s] Trained 128 records in 0.093781211 seconds. Throughput is 1364.8789 records/second. Loss is 0.22485018. Sequential31006cbd's hyper parameters: Current learning rate is 0.005122950819672132. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9216/60000][Iteration 4762][Wall Clock 458.053667238s] Trained 128 records in 0.090431228 seconds. Throughput is 1415.4402 records/second. Loss is 0.16944699. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051224259809445755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9344/60000][Iteration 4763][Wall Clock 458.136065827s] Trained 128 records in 0.082398589 seconds. Throughput is 1553.4247 records/second. Loss is 0.17280443. Sequential31006cbd's hyper parameters: Current learning rate is 0.005121901249743905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9472/60000][Iteration 4764][Wall Clock 458.218881744s] Trained 128 records in 0.082815917 seconds. Throughput is 1545.5967 records/second. Loss is 0.23286422. Sequential31006cbd's hyper parameters: Current learning rate is 0.005121376626037079. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9600/60000][Iteration 4765][Wall Clock 458.325121756s] Trained 128 records in 0.106240012 seconds. Throughput is 1204.8191 records/second. Loss is 0.14584431. Sequential31006cbd's hyper parameters: Current learning rate is 0.005120852109791069. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9728/60000][Iteration 4766][Wall Clock 458.421894271s] Trained 128 records in 0.096772515 seconds. Throughput is 1322.6896 records/second. Loss is 0.20795256. Sequential31006cbd's hyper parameters: Current learning rate is 0.005120327700972862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:15 INFO  DistriOptimizer$:408 - [Epoch 11 9856/60000][Iteration 4767][Wall Clock 458.509166159s] Trained 128 records in 0.087271888 seconds. Throughput is 1466.6807 records/second. Loss is 0.25374246. Sequential31006cbd's hyper parameters: Current learning rate is 0.005119803399549457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 9984/60000][Iteration 4768][Wall Clock 458.597847718s] Trained 128 records in 0.088681559 seconds. Throughput is 1443.3667 records/second. Loss is 0.18681706. Sequential31006cbd's hyper parameters: Current learning rate is 0.005119279205487867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10112/60000][Iteration 4769][Wall Clock 458.679616798s] Trained 128 records in 0.08176908 seconds. Throughput is 1565.3839 records/second. Loss is 0.23887506. Sequential31006cbd's hyper parameters: Current learning rate is 0.005118755118755119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10240/60000][Iteration 4770][Wall Clock 458.766551327s] Trained 128 records in 0.086934529 seconds. Throughput is 1472.3724 records/second. Loss is 0.26509085. Sequential31006cbd's hyper parameters: Current learning rate is 0.005118231139318251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10368/60000][Iteration 4771][Wall Clock 458.850014554s] Trained 128 records in 0.083463227 seconds. Throughput is 1533.6095 records/second. Loss is 0.14767288. Sequential31006cbd's hyper parameters: Current learning rate is 0.005117707267144319. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10496/60000][Iteration 4772][Wall Clock 458.941161183s] Trained 128 records in 0.091146629 seconds. Throughput is 1404.3307 records/second. Loss is 0.13376272. Sequential31006cbd's hyper parameters: Current learning rate is 0.005117183502200389. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10624/60000][Iteration 4773][Wall Clock 459.027001311s] Trained 128 records in 0.085840128 seconds. Throughput is 1491.144 records/second. Loss is 0.21734273. Sequential31006cbd's hyper parameters: Current learning rate is 0.00511665984445354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10752/60000][Iteration 4774][Wall Clock 459.113006668s] Trained 128 records in 0.086005357 seconds. Throughput is 1488.2793 records/second. Loss is 0.16371685. Sequential31006cbd's hyper parameters: Current learning rate is 0.005116136293870869. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 10880/60000][Iteration 4775][Wall Clock 459.191167052s] Trained 128 records in 0.078160384 seconds. Throughput is 1637.6583 records/second. Loss is 0.26115677. Sequential31006cbd's hyper parameters: Current learning rate is 0.00511561285041948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 11008/60000][Iteration 4776][Wall Clock 459.269057278s] Trained 128 records in 0.077890226 seconds. Throughput is 1643.3384 records/second. Loss is 0.19411288. Sequential31006cbd's hyper parameters: Current learning rate is 0.005115089514066496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 11136/60000][Iteration 4777][Wall Clock 459.352306407s] Trained 128 records in 0.083249129 seconds. Throughput is 1537.5536 records/second. Loss is 0.16346838. Sequential31006cbd's hyper parameters: Current learning rate is 0.005114566284779051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 11264/60000][Iteration 4778][Wall Clock 459.432963582s] Trained 128 records in 0.080657175 seconds. Throughput is 1586.9635 records/second. Loss is 0.22027218. Sequential31006cbd's hyper parameters: Current learning rate is 0.005114043162524291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:16 INFO  DistriOptimizer$:408 - [Epoch 11 11392/60000][Iteration 4779][Wall Clock 459.509744454s] Trained 128 records in 0.076780872 seconds. Throughput is 1667.0819 records/second. Loss is 0.2252257. Sequential31006cbd's hyper parameters: Current learning rate is 0.005113520147269381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 11520/60000][Iteration 4780][Wall Clock 459.594626015s] Trained 128 records in 0.084881561 seconds. Throughput is 1507.9836 records/second. Loss is 0.21780883. Sequential31006cbd's hyper parameters: Current learning rate is 0.005112997238981491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 11648/60000][Iteration 4781][Wall Clock 459.695199251s] Trained 128 records in 0.100573236 seconds. Throughput is 1272.7045 records/second. Loss is 0.2559778. Sequential31006cbd's hyper parameters: Current learning rate is 0.005112474437627812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 11776/60000][Iteration 4782][Wall Clock 459.777871891s] Trained 128 records in 0.08267264 seconds. Throughput is 1548.2753 records/second. Loss is 0.19449264. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051119517431755445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 11904/60000][Iteration 4783][Wall Clock 459.858290991s] Trained 128 records in 0.0804191 seconds. Throughput is 1591.6616 records/second. Loss is 0.26539004. Sequential31006cbd's hyper parameters: Current learning rate is 0.005111429155591904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12032/60000][Iteration 4784][Wall Clock 459.92788967s] Trained 128 records in 0.069598679 seconds. Throughput is 1839.1152 records/second. Loss is 0.22572581. Sequential31006cbd's hyper parameters: Current learning rate is 0.005110906674844117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12160/60000][Iteration 4785][Wall Clock 459.997376548s] Trained 128 records in 0.069486878 seconds. Throughput is 1842.0743 records/second. Loss is 0.19964193. Sequential31006cbd's hyper parameters: Current learning rate is 0.005110384300899428. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12288/60000][Iteration 4786][Wall Clock 460.070816037s] Trained 128 records in 0.073439489 seconds. Throughput is 1742.9316 records/second. Loss is 0.2766111. Sequential31006cbd's hyper parameters: Current learning rate is 0.005109862033725089. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12416/60000][Iteration 4787][Wall Clock 460.147821905s] Trained 128 records in 0.077005868 seconds. Throughput is 1662.2109 records/second. Loss is 0.27392215. Sequential31006cbd's hyper parameters: Current learning rate is 0.005109339873288371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12544/60000][Iteration 4788][Wall Clock 460.227271708s] Trained 128 records in 0.079449803 seconds. Throughput is 1611.0802 records/second. Loss is 0.2699756. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051088178195565544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12672/60000][Iteration 4789][Wall Clock 460.307392733s] Trained 128 records in 0.080121025 seconds. Throughput is 1597.5831 records/second. Loss is 0.22589932. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051082958724969355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12800/60000][Iteration 4790][Wall Clock 460.385997063s] Trained 128 records in 0.07860433 seconds. Throughput is 1628.4089 records/second. Loss is 0.16582692. Sequential31006cbd's hyper parameters: Current learning rate is 0.00510777403207682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 12928/60000][Iteration 4791][Wall Clock 460.467359968s] Trained 128 records in 0.081362905 seconds. Throughput is 1573.1985 records/second. Loss is 0.19052313. Sequential31006cbd's hyper parameters: Current learning rate is 0.005107252298263534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:17 INFO  DistriOptimizer$:408 - [Epoch 11 13056/60000][Iteration 4792][Wall Clock 460.539185719s] Trained 128 records in 0.071825751 seconds. Throughput is 1782.0907 records/second. Loss is 0.14018118. Sequential31006cbd's hyper parameters: Current learning rate is 0.00510673067102441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13184/60000][Iteration 4793][Wall Clock 460.612967267s] Trained 128 records in 0.073781548 seconds. Throughput is 1734.8511 records/second. Loss is 0.30273986. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051062091503267975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13312/60000][Iteration 4794][Wall Clock 460.689712371s] Trained 128 records in 0.076745104 seconds. Throughput is 1667.8589 records/second. Loss is 0.276224. Sequential31006cbd's hyper parameters: Current learning rate is 0.005105687736138058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13440/60000][Iteration 4795][Wall Clock 460.767139588s] Trained 128 records in 0.077427217 seconds. Throughput is 1653.1655 records/second. Loss is 0.2309988. Sequential31006cbd's hyper parameters: Current learning rate is 0.005105166428425566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13568/60000][Iteration 4796][Wall Clock 460.845189702s] Trained 128 records in 0.078050114 seconds. Throughput is 1639.9719 records/second. Loss is 0.17896438. Sequential31006cbd's hyper parameters: Current learning rate is 0.005104645227156712. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13696/60000][Iteration 4797][Wall Clock 460.920766954s] Trained 128 records in 0.075577252 seconds. Throughput is 1693.6313 records/second. Loss is 0.14204545. Sequential31006cbd's hyper parameters: Current learning rate is 0.005104124132298897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13824/60000][Iteration 4798][Wall Clock 460.995181208s] Trained 128 records in 0.074414254 seconds. Throughput is 1720.1006 records/second. Loss is 0.2437501. Sequential31006cbd's hyper parameters: Current learning rate is 0.005103603143819537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 13952/60000][Iteration 4799][Wall Clock 461.086718667s] Trained 128 records in 0.091537459 seconds. Throughput is 1398.3346 records/second. Loss is 0.2636437. Sequential31006cbd's hyper parameters: Current learning rate is 0.005103082261686058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 14080/60000][Iteration 4800][Wall Clock 461.166225496s] Trained 128 records in 0.079506829 seconds. Throughput is 1609.9246 records/second. Loss is 0.2717476. Sequential31006cbd's hyper parameters: Current learning rate is 0.005102561485865905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 14208/60000][Iteration 4801][Wall Clock 461.242504355s] Trained 128 records in 0.076278859 seconds. Throughput is 1678.0535 records/second. Loss is 0.17745765. Sequential31006cbd's hyper parameters: Current learning rate is 0.005102040816326531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 14336/60000][Iteration 4802][Wall Clock 461.317536914s] Trained 128 records in 0.075032559 seconds. Throughput is 1705.926 records/second. Loss is 0.22393137. Sequential31006cbd's hyper parameters: Current learning rate is 0.005101520253035405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 14464/60000][Iteration 4803][Wall Clock 461.39366377s] Trained 128 records in 0.076126856 seconds. Throughput is 1681.4039 records/second. Loss is 0.16491377. Sequential31006cbd's hyper parameters: Current learning rate is 0.005100999795960008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 14592/60000][Iteration 4804][Wall Clock 461.474735673s] Trained 128 records in 0.081071903 seconds. Throughput is 1578.8453 records/second. Loss is 0.16301863. Sequential31006cbd's hyper parameters: Current learning rate is 0.0051004794450678365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:18 INFO  DistriOptimizer$:408 - [Epoch 11 14720/60000][Iteration 4805][Wall Clock 461.549565523s] Trained 128 records in 0.07482985 seconds. Throughput is 1710.5474 records/second. Loss is 0.12840746. Sequential31006cbd's hyper parameters: Current learning rate is 0.005099959200326397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 14848/60000][Iteration 4806][Wall Clock 461.659798548s] Trained 128 records in 0.110233025 seconds. Throughput is 1161.1765 records/second. Loss is 0.17912762. Sequential31006cbd's hyper parameters: Current learning rate is 0.005099439061703213. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 14976/60000][Iteration 4807][Wall Clock 461.75423765s] Trained 128 records in 0.094439102 seconds. Throughput is 1355.3707 records/second. Loss is 0.21867833. Sequential31006cbd's hyper parameters: Current learning rate is 0.005098919029165817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15104/60000][Iteration 4808][Wall Clock 461.843809503s] Trained 128 records in 0.089571853 seconds. Throughput is 1429.0203 records/second. Loss is 0.18335673. Sequential31006cbd's hyper parameters: Current learning rate is 0.005098399102681758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15232/60000][Iteration 4809][Wall Clock 461.92876006s] Trained 128 records in 0.084950557 seconds. Throughput is 1506.7588 records/second. Loss is 0.2006828. Sequential31006cbd's hyper parameters: Current learning rate is 0.005097879282218597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15360/60000][Iteration 4810][Wall Clock 462.007877409s] Trained 128 records in 0.079117349 seconds. Throughput is 1617.85 records/second. Loss is 0.10366486. Sequential31006cbd's hyper parameters: Current learning rate is 0.005097359567743908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15488/60000][Iteration 4811][Wall Clock 462.090466079s] Trained 128 records in 0.08258867 seconds. Throughput is 1549.8494 records/second. Loss is 0.22167313. Sequential31006cbd's hyper parameters: Current learning rate is 0.00509683995922528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15616/60000][Iteration 4812][Wall Clock 462.167001523s] Trained 128 records in 0.076535444 seconds. Throughput is 1672.4279 records/second. Loss is 0.24662845. Sequential31006cbd's hyper parameters: Current learning rate is 0.005096320456630312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15744/60000][Iteration 4813][Wall Clock 462.265426681s] Trained 128 records in 0.098425158 seconds. Throughput is 1300.4805 records/second. Loss is 0.17136496. Sequential31006cbd's hyper parameters: Current learning rate is 0.005095801059926621. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 15872/60000][Iteration 4814][Wall Clock 462.345616951s] Trained 128 records in 0.08019027 seconds. Throughput is 1596.2036 records/second. Loss is 0.18817899. Sequential31006cbd's hyper parameters: Current learning rate is 0.00509528176908183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 16000/60000][Iteration 4815][Wall Clock 462.423764635s] Trained 128 records in 0.078147684 seconds. Throughput is 1637.9243 records/second. Loss is 0.2451607. Sequential31006cbd's hyper parameters: Current learning rate is 0.005094762584063582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:19 INFO  DistriOptimizer$:408 - [Epoch 11 16128/60000][Iteration 4816][Wall Clock 462.510028797s] Trained 128 records in 0.086264162 seconds. Throughput is 1483.8143 records/second. Loss is 0.16223188. Sequential31006cbd's hyper parameters: Current learning rate is 0.005094243504839531. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 16256/60000][Iteration 4817][Wall Clock 462.613533358s] Trained 128 records in 0.103504561 seconds. Throughput is 1236.6605 records/second. Loss is 0.19215198. Sequential31006cbd's hyper parameters: Current learning rate is 0.005093724531377343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 16384/60000][Iteration 4818][Wall Clock 462.697420001s] Trained 128 records in 0.083886643 seconds. Throughput is 1525.8687 records/second. Loss is 0.20055959. Sequential31006cbd's hyper parameters: Current learning rate is 0.005093205663644698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 16512/60000][Iteration 4819][Wall Clock 462.774511899s] Trained 128 records in 0.077091898 seconds. Throughput is 1660.3561 records/second. Loss is 0.24502966. Sequential31006cbd's hyper parameters: Current learning rate is 0.005092686901609289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 16640/60000][Iteration 4820][Wall Clock 462.868899322s] Trained 128 records in 0.094387423 seconds. Throughput is 1356.1129 records/second. Loss is 0.083390616. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050921682452388225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 16768/60000][Iteration 4821][Wall Clock 462.964983316s] Trained 128 records in 0.096083994 seconds. Throughput is 1332.1678 records/second. Loss is 0.2759158. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050916496945010185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 16896/60000][Iteration 4822][Wall Clock 463.043097605s] Trained 128 records in 0.078114289 seconds. Throughput is 1638.6248 records/second. Loss is 0.3299991. Sequential31006cbd's hyper parameters: Current learning rate is 0.005091131249363609. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 17024/60000][Iteration 4823][Wall Clock 463.117461731s] Trained 128 records in 0.074364126 seconds. Throughput is 1721.26 records/second. Loss is 0.16485445. Sequential31006cbd's hyper parameters: Current learning rate is 0.005090612909794339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 17152/60000][Iteration 4824][Wall Clock 463.20365267s] Trained 128 records in 0.086190939 seconds. Throughput is 1485.075 records/second. Loss is 0.16877967. Sequential31006cbd's hyper parameters: Current learning rate is 0.00509009467576097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 17280/60000][Iteration 4825][Wall Clock 463.283641275s] Trained 128 records in 0.079988605 seconds. Throughput is 1600.2279 records/second. Loss is 0.27374744. Sequential31006cbd's hyper parameters: Current learning rate is 0.005089576547231271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 17408/60000][Iteration 4826][Wall Clock 463.365757902s] Trained 128 records in 0.082116627 seconds. Throughput is 1558.7587 records/second. Loss is 0.30036163. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050890585241730275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 17536/60000][Iteration 4827][Wall Clock 463.445902266s] Trained 128 records in 0.080144364 seconds. Throughput is 1597.118 records/second. Loss is 0.13616076. Sequential31006cbd's hyper parameters: Current learning rate is 0.00508854060655404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:20 INFO  DistriOptimizer$:408 - [Epoch 11 17664/60000][Iteration 4828][Wall Clock 463.526663141s] Trained 128 records in 0.080760875 seconds. Throughput is 1584.9259 records/second. Loss is 0.24293903. Sequential31006cbd's hyper parameters: Current learning rate is 0.005088022794342118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 17792/60000][Iteration 4829][Wall Clock 463.605019588s] Trained 128 records in 0.078356447 seconds. Throughput is 1633.5605 records/second. Loss is 0.21967104. Sequential31006cbd's hyper parameters: Current learning rate is 0.005087505087505087. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 17920/60000][Iteration 4830][Wall Clock 463.695363824s] Trained 128 records in 0.090344236 seconds. Throughput is 1416.8032 records/second. Loss is 0.15827782. Sequential31006cbd's hyper parameters: Current learning rate is 0.005086987486010785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18048/60000][Iteration 4831][Wall Clock 463.794721333s] Trained 128 records in 0.099357509 seconds. Throughput is 1288.2771 records/second. Loss is 0.13822621. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050864699898270594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18176/60000][Iteration 4832][Wall Clock 463.898283518s] Trained 128 records in 0.103562185 seconds. Throughput is 1235.9724 records/second. Loss is 0.19160324. Sequential31006cbd's hyper parameters: Current learning rate is 0.005085952598921778. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18304/60000][Iteration 4833][Wall Clock 463.989845335s] Trained 128 records in 0.091561817 seconds. Throughput is 1397.9626 records/second. Loss is 0.16516925. Sequential31006cbd's hyper parameters: Current learning rate is 0.005085435313262815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18432/60000][Iteration 4834][Wall Clock 464.069937518s] Trained 128 records in 0.080092183 seconds. Throughput is 1598.1584 records/second. Loss is 0.1999051. Sequential31006cbd's hyper parameters: Current learning rate is 0.005084918132818061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18560/60000][Iteration 4835][Wall Clock 464.148005353s] Trained 128 records in 0.078067835 seconds. Throughput is 1639.5997 records/second. Loss is 0.17755212. Sequential31006cbd's hyper parameters: Current learning rate is 0.00508440105755542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18688/60000][Iteration 4836][Wall Clock 464.228593369s] Trained 128 records in 0.080588016 seconds. Throughput is 1588.3256 records/second. Loss is 0.19947678. Sequential31006cbd's hyper parameters: Current learning rate is 0.005083884087442806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18816/60000][Iteration 4837][Wall Clock 464.309718707s] Trained 128 records in 0.081125338 seconds. Throughput is 1577.8054 records/second. Loss is 0.17277606. Sequential31006cbd's hyper parameters: Current learning rate is 0.005083367222448149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 18944/60000][Iteration 4838][Wall Clock 464.381140746s] Trained 128 records in 0.071422039 seconds. Throughput is 1792.1638 records/second. Loss is 0.13201153. Sequential31006cbd's hyper parameters: Current learning rate is 0.005082850462539392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 19072/60000][Iteration 4839][Wall Clock 464.462037537s] Trained 128 records in 0.080896791 seconds. Throughput is 1582.2631 records/second. Loss is 0.118135065. Sequential31006cbd's hyper parameters: Current learning rate is 0.005082333807684488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:21 INFO  DistriOptimizer$:408 - [Epoch 11 19200/60000][Iteration 4840][Wall Clock 464.552977459s] Trained 128 records in 0.090939922 seconds. Throughput is 1407.5226 records/second. Loss is 0.17316212. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050818172578514075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 19328/60000][Iteration 4841][Wall Clock 464.640953158s] Trained 128 records in 0.087975699 seconds. Throughput is 1454.9473 records/second. Loss is 0.16333129. Sequential31006cbd's hyper parameters: Current learning rate is 0.00508130081300813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 19456/60000][Iteration 4842][Wall Clock 464.715836227s] Trained 128 records in 0.074883069 seconds. Throughput is 1709.3317 records/second. Loss is 0.14207509. Sequential31006cbd's hyper parameters: Current learning rate is 0.00508078447312265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 19584/60000][Iteration 4843][Wall Clock 464.808978275s] Trained 128 records in 0.093142048 seconds. Throughput is 1374.2451 records/second. Loss is 0.2464961. Sequential31006cbd's hyper parameters: Current learning rate is 0.005080268238162975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 19712/60000][Iteration 4844][Wall Clock 464.888785464s] Trained 128 records in 0.079807189 seconds. Throughput is 1603.8655 records/second. Loss is 0.23347744. Sequential31006cbd's hyper parameters: Current learning rate is 0.005079752108097125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 19840/60000][Iteration 4845][Wall Clock 464.974433015s] Trained 128 records in 0.085647551 seconds. Throughput is 1494.4968 records/second. Loss is 0.13701123. Sequential31006cbd's hyper parameters: Current learning rate is 0.005079236082893133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 19968/60000][Iteration 4846][Wall Clock 465.054605448s] Trained 128 records in 0.080172433 seconds. Throughput is 1596.5587 records/second. Loss is 0.19699627. Sequential31006cbd's hyper parameters: Current learning rate is 0.005078720162519045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 20096/60000][Iteration 4847][Wall Clock 465.129246915s] Trained 128 records in 0.074641467 seconds. Throughput is 1714.8645 records/second. Loss is 0.11842291. Sequential31006cbd's hyper parameters: Current learning rate is 0.005078204346942921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 20224/60000][Iteration 4848][Wall Clock 465.20328783s] Trained 128 records in 0.074040915 seconds. Throughput is 1728.7739 records/second. Loss is 0.34995255. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050776886361328325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 20352/60000][Iteration 4849][Wall Clock 465.279926965s] Trained 128 records in 0.076639135 seconds. Throughput is 1670.1649 records/second. Loss is 0.21713847. Sequential31006cbd's hyper parameters: Current learning rate is 0.005077173030056864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 20480/60000][Iteration 4850][Wall Clock 465.348667779s] Trained 128 records in 0.068740814 seconds. Throughput is 1862.067 records/second. Loss is 0.21580875. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050766575286831156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 20608/60000][Iteration 4851][Wall Clock 465.421516449s] Trained 128 records in 0.07284867 seconds. Throughput is 1757.067 records/second. Loss is 0.20916261. Sequential31006cbd's hyper parameters: Current learning rate is 0.005076142131979695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:22 INFO  DistriOptimizer$:408 - [Epoch 11 20736/60000][Iteration 4852][Wall Clock 465.503345473s] Trained 128 records in 0.081829024 seconds. Throughput is 1564.237 records/second. Loss is 0.20859909. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050756268399147295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 20864/60000][Iteration 4853][Wall Clock 465.581299545s] Trained 128 records in 0.077954072 seconds. Throughput is 1641.9926 records/second. Loss is 0.20714997. Sequential31006cbd's hyper parameters: Current learning rate is 0.005075111652456354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 20992/60000][Iteration 4854][Wall Clock 465.659107973s] Trained 128 records in 0.077808428 seconds. Throughput is 1645.066 records/second. Loss is 0.28483015. Sequential31006cbd's hyper parameters: Current learning rate is 0.005074596569572719. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21120/60000][Iteration 4855][Wall Clock 465.736608465s] Trained 128 records in 0.077500492 seconds. Throughput is 1651.6024 records/second. Loss is 0.16466714. Sequential31006cbd's hyper parameters: Current learning rate is 0.005074081591231987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21248/60000][Iteration 4856][Wall Clock 465.820176891s] Trained 128 records in 0.083568426 seconds. Throughput is 1531.679 records/second. Loss is 0.27210322. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050735667174023336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21376/60000][Iteration 4857][Wall Clock 465.894832298s] Trained 128 records in 0.074655407 seconds. Throughput is 1714.5443 records/second. Loss is 0.23283985. Sequential31006cbd's hyper parameters: Current learning rate is 0.005073051948051948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21504/60000][Iteration 4858][Wall Clock 465.970231719s] Trained 128 records in 0.075399421 seconds. Throughput is 1697.6257 records/second. Loss is 0.3372922. Sequential31006cbd's hyper parameters: Current learning rate is 0.005072537283149031. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21632/60000][Iteration 4859][Wall Clock 466.045894176s] Trained 128 records in 0.075662457 seconds. Throughput is 1691.7241 records/second. Loss is 0.1258464. Sequential31006cbd's hyper parameters: Current learning rate is 0.005072022722661797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21760/60000][Iteration 4860][Wall Clock 466.120371486s] Trained 128 records in 0.07447731 seconds. Throughput is 1718.6443 records/second. Loss is 0.19361879. Sequential31006cbd's hyper parameters: Current learning rate is 0.005071508266558475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 21888/60000][Iteration 4861][Wall Clock 466.193871076s] Trained 128 records in 0.07349959 seconds. Throughput is 1741.5063 records/second. Loss is 0.12607598. Sequential31006cbd's hyper parameters: Current learning rate is 0.005070993914807302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 22016/60000][Iteration 4862][Wall Clock 466.286148338s] Trained 128 records in 0.092277262 seconds. Throughput is 1387.124 records/second. Loss is 0.29912302. Sequential31006cbd's hyper parameters: Current learning rate is 0.005070479667376534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 22144/60000][Iteration 4863][Wall Clock 466.367133354s] Trained 128 records in 0.080985016 seconds. Throughput is 1580.5393 records/second. Loss is 0.11793766. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050699655242344354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 22272/60000][Iteration 4864][Wall Clock 466.439081688s] Trained 128 records in 0.071948334 seconds. Throughput is 1779.0544 records/second. Loss is 0.18893473. Sequential31006cbd's hyper parameters: Current learning rate is 0.005069451485349286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:23 INFO  DistriOptimizer$:408 - [Epoch 11 22400/60000][Iteration 4865][Wall Clock 466.511548025s] Trained 128 records in 0.072466337 seconds. Throughput is 1766.3374 records/second. Loss is 0.093548745. Sequential31006cbd's hyper parameters: Current learning rate is 0.005068937550689376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 22528/60000][Iteration 4866][Wall Clock 466.587639588s] Trained 128 records in 0.076091563 seconds. Throughput is 1682.1838 records/second. Loss is 0.1251762. Sequential31006cbd's hyper parameters: Current learning rate is 0.00506842372022301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 22656/60000][Iteration 4867][Wall Clock 466.661891889s] Trained 128 records in 0.074252301 seconds. Throughput is 1723.8523 records/second. Loss is 0.29328117. Sequential31006cbd's hyper parameters: Current learning rate is 0.005067909993918508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 22784/60000][Iteration 4868][Wall Clock 466.739551405s] Trained 128 records in 0.077659516 seconds. Throughput is 1648.2203 records/second. Loss is 0.20798701. Sequential31006cbd's hyper parameters: Current learning rate is 0.005067396371744198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 22912/60000][Iteration 4869][Wall Clock 466.819279065s] Trained 128 records in 0.07972766 seconds. Throughput is 1605.4655 records/second. Loss is 0.23374885. Sequential31006cbd's hyper parameters: Current learning rate is 0.005066882853668423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23040/60000][Iteration 4870][Wall Clock 466.893619397s] Trained 128 records in 0.074340332 seconds. Throughput is 1721.811 records/second. Loss is 0.20394099. Sequential31006cbd's hyper parameters: Current learning rate is 0.00506636943965954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23168/60000][Iteration 4871][Wall Clock 466.971684545s] Trained 128 records in 0.078065148 seconds. Throughput is 1639.6561 records/second. Loss is 0.14628981. Sequential31006cbd's hyper parameters: Current learning rate is 0.005065856129685916. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23296/60000][Iteration 4872][Wall Clock 467.049078168s] Trained 128 records in 0.077393623 seconds. Throughput is 1653.883 records/second. Loss is 0.23875293. Sequential31006cbd's hyper parameters: Current learning rate is 0.005065342923715935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23424/60000][Iteration 4873][Wall Clock 467.130739641s] Trained 128 records in 0.081661473 seconds. Throughput is 1567.4467 records/second. Loss is 0.254722. Sequential31006cbd's hyper parameters: Current learning rate is 0.00506482982171799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23552/60000][Iteration 4874][Wall Clock 467.204532187s] Trained 128 records in 0.073792546 seconds. Throughput is 1734.5925 records/second. Loss is 0.16388974. Sequential31006cbd's hyper parameters: Current learning rate is 0.005064316823660488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23680/60000][Iteration 4875][Wall Clock 467.281761811s] Trained 128 records in 0.077229624 seconds. Throughput is 1657.395 records/second. Loss is 0.15715024. Sequential31006cbd's hyper parameters: Current learning rate is 0.005063803929511849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23808/60000][Iteration 4876][Wall Clock 467.361988501s] Trained 128 records in 0.08022669 seconds. Throughput is 1595.479 records/second. Loss is 0.19665852. Sequential31006cbd's hyper parameters: Current learning rate is 0.005063291139240506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 23936/60000][Iteration 4877][Wall Clock 467.44179983s] Trained 128 records in 0.079811329 seconds. Throughput is 1603.7823 records/second. Loss is 0.16371617. Sequential31006cbd's hyper parameters: Current learning rate is 0.005062778452814905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:24 INFO  DistriOptimizer$:408 - [Epoch 11 24064/60000][Iteration 4878][Wall Clock 467.518573843s] Trained 128 records in 0.076774013 seconds. Throughput is 1667.2307 records/second. Loss is 0.26659727. Sequential31006cbd's hyper parameters: Current learning rate is 0.005062265870203503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24192/60000][Iteration 4879][Wall Clock 467.597213052s] Trained 128 records in 0.078639209 seconds. Throughput is 1627.6868 records/second. Loss is 0.111157835. Sequential31006cbd's hyper parameters: Current learning rate is 0.005061753391374772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24320/60000][Iteration 4880][Wall Clock 467.675497582s] Trained 128 records in 0.07828453 seconds. Throughput is 1635.0612 records/second. Loss is 0.23645216. Sequential31006cbd's hyper parameters: Current learning rate is 0.005061241016297196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24448/60000][Iteration 4881][Wall Clock 467.760779609s] Trained 128 records in 0.085282027 seconds. Throughput is 1500.9023 records/second. Loss is 0.21031895. Sequential31006cbd's hyper parameters: Current learning rate is 0.005060728744939271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24576/60000][Iteration 4882][Wall Clock 467.837121125s] Trained 128 records in 0.076341516 seconds. Throughput is 1676.6761 records/second. Loss is 0.1525634. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050602165772695076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24704/60000][Iteration 4883][Wall Clock 467.917752035s] Trained 128 records in 0.08063091 seconds. Throughput is 1587.4805 records/second. Loss is 0.23639008. Sequential31006cbd's hyper parameters: Current learning rate is 0.005059704513256426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24832/60000][Iteration 4884][Wall Clock 467.990360243s] Trained 128 records in 0.072608208 seconds. Throughput is 1762.886 records/second. Loss is 0.17897725. Sequential31006cbd's hyper parameters: Current learning rate is 0.005059192552868562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 24960/60000][Iteration 4885][Wall Clock 468.065321292s] Trained 128 records in 0.074961049 seconds. Throughput is 1707.5535 records/second. Loss is 0.07568148. Sequential31006cbd's hyper parameters: Current learning rate is 0.005058680696074464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 25088/60000][Iteration 4886][Wall Clock 468.140830304s] Trained 128 records in 0.075509012 seconds. Throughput is 1695.1619 records/second. Loss is 0.2777468. Sequential31006cbd's hyper parameters: Current learning rate is 0.005058168942842691. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 25216/60000][Iteration 4887][Wall Clock 468.217569012s] Trained 128 records in 0.076738708 seconds. Throughput is 1667.9978 records/second. Loss is 0.22448984. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050576572931418165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 25344/60000][Iteration 4888][Wall Clock 468.292586053s] Trained 128 records in 0.075017041 seconds. Throughput is 1706.2789 records/second. Loss is 0.3344339. Sequential31006cbd's hyper parameters: Current learning rate is 0.005057145746940427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 25472/60000][Iteration 4889][Wall Clock 468.374011348s] Trained 128 records in 0.081425295 seconds. Throughput is 1571.993 records/second. Loss is 0.14124726. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050566343042071195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 25600/60000][Iteration 4890][Wall Clock 468.449629747s] Trained 128 records in 0.075618399 seconds. Throughput is 1692.7097 records/second. Loss is 0.18368874. Sequential31006cbd's hyper parameters: Current learning rate is 0.005056122964910507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:25 INFO  DistriOptimizer$:408 - [Epoch 11 25728/60000][Iteration 4891][Wall Clock 468.522409495s] Trained 128 records in 0.072779748 seconds. Throughput is 1758.7311 records/second. Loss is 0.24733733. Sequential31006cbd's hyper parameters: Current learning rate is 0.005055611729019211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 25856/60000][Iteration 4892][Wall Clock 468.597917655s] Trained 128 records in 0.07550816 seconds. Throughput is 1695.181 records/second. Loss is 0.24769995. Sequential31006cbd's hyper parameters: Current learning rate is 0.00505510059650187. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 25984/60000][Iteration 4893][Wall Clock 468.673280592s] Trained 128 records in 0.075362937 seconds. Throughput is 1698.4476 records/second. Loss is 0.26431543. Sequential31006cbd's hyper parameters: Current learning rate is 0.005054589567327133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26112/60000][Iteration 4894][Wall Clock 468.751760307s] Trained 128 records in 0.078479715 seconds. Throughput is 1630.9948 records/second. Loss is 0.124466494. Sequential31006cbd's hyper parameters: Current learning rate is 0.005054078641463661. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26240/60000][Iteration 4895][Wall Clock 468.838715222s] Trained 128 records in 0.086954915 seconds. Throughput is 1472.0272 records/second. Loss is 0.21638332. Sequential31006cbd's hyper parameters: Current learning rate is 0.005053567818880129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26368/60000][Iteration 4896][Wall Clock 468.912499645s] Trained 128 records in 0.073784423 seconds. Throughput is 1734.7834 records/second. Loss is 0.17182834. Sequential31006cbd's hyper parameters: Current learning rate is 0.005053057099545225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26496/60000][Iteration 4897][Wall Clock 468.988544772s] Trained 128 records in 0.076045127 seconds. Throughput is 1683.211 records/second. Loss is 0.18700199. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050525464834276475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26624/60000][Iteration 4898][Wall Clock 469.071616724s] Trained 128 records in 0.083071952 seconds. Throughput is 1540.8329 records/second. Loss is 0.19159661. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050520359704961096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26752/60000][Iteration 4899][Wall Clock 469.146949075s] Trained 128 records in 0.075332351 seconds. Throughput is 1699.1372 records/second. Loss is 0.21129867. Sequential31006cbd's hyper parameters: Current learning rate is 0.005051525560719338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 26880/60000][Iteration 4900][Wall Clock 469.21991741s] Trained 128 records in 0.072968335 seconds. Throughput is 1754.1855 records/second. Loss is 0.20940693. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050510152540660675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 27008/60000][Iteration 4901][Wall Clock 469.294422294s] Trained 128 records in 0.074504884 seconds. Throughput is 1718.0082 records/second. Loss is 0.19817825. Sequential31006cbd's hyper parameters: Current learning rate is 0.005050505050505051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 27136/60000][Iteration 4902][Wall Clock 469.368318472s] Trained 128 records in 0.073896178 seconds. Throughput is 1732.1599 records/second. Loss is 0.11646758. Sequential31006cbd's hyper parameters: Current learning rate is 0.00504999495000505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 27264/60000][Iteration 4903][Wall Clock 469.443272536s] Trained 128 records in 0.074954064 seconds. Throughput is 1707.7126 records/second. Loss is 0.24335054. Sequential31006cbd's hyper parameters: Current learning rate is 0.005049484952534842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:26 INFO  DistriOptimizer$:408 - [Epoch 11 27392/60000][Iteration 4904][Wall Clock 469.520855147s] Trained 128 records in 0.077582611 seconds. Throughput is 1649.8542 records/second. Loss is 0.16753027. Sequential31006cbd's hyper parameters: Current learning rate is 0.005048975058063214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 27520/60000][Iteration 4905][Wall Clock 469.597749636s] Trained 128 records in 0.076894489 seconds. Throughput is 1664.6185 records/second. Loss is 0.20668802. Sequential31006cbd's hyper parameters: Current learning rate is 0.005048465266558966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 27648/60000][Iteration 4906][Wall Clock 469.67882913s] Trained 128 records in 0.081079494 seconds. Throughput is 1578.6976 records/second. Loss is 0.3392677. Sequential31006cbd's hyper parameters: Current learning rate is 0.005047955577990914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 27776/60000][Iteration 4907][Wall Clock 469.774712842s] Trained 128 records in 0.095883712 seconds. Throughput is 1334.9504 records/second. Loss is 0.13807188. Sequential31006cbd's hyper parameters: Current learning rate is 0.005047445992327882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 27904/60000][Iteration 4908][Wall Clock 469.848976031s] Trained 128 records in 0.074263189 seconds. Throughput is 1723.5995 records/second. Loss is 0.18927887. Sequential31006cbd's hyper parameters: Current learning rate is 0.00504693650953871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28032/60000][Iteration 4909][Wall Clock 469.931266806s] Trained 128 records in 0.082290775 seconds. Throughput is 1555.4598 records/second. Loss is 0.16496497. Sequential31006cbd's hyper parameters: Current learning rate is 0.005046427129592248. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28160/60000][Iteration 4910][Wall Clock 470.01320724s] Trained 128 records in 0.081940434 seconds. Throughput is 1562.1104 records/second. Loss is 0.24598801. Sequential31006cbd's hyper parameters: Current learning rate is 0.005045917852457362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28288/60000][Iteration 4911][Wall Clock 470.089259668s] Trained 128 records in 0.076052428 seconds. Throughput is 1683.0496 records/second. Loss is 0.22221676. Sequential31006cbd's hyper parameters: Current learning rate is 0.005045408678102926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28416/60000][Iteration 4912][Wall Clock 470.164813989s] Trained 128 records in 0.075554321 seconds. Throughput is 1694.1454 records/second. Loss is 0.16678584. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050448996064978305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28544/60000][Iteration 4913][Wall Clock 470.240812742s] Trained 128 records in 0.075998753 seconds. Throughput is 1684.2382 records/second. Loss is 0.18280905. Sequential31006cbd's hyper parameters: Current learning rate is 0.005044390637610976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28672/60000][Iteration 4914][Wall Clock 470.314995383s] Trained 128 records in 0.074182641 seconds. Throughput is 1725.471 records/second. Loss is 0.098695986. Sequential31006cbd's hyper parameters: Current learning rate is 0.005043881771411278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28800/60000][Iteration 4915][Wall Clock 470.391980097s] Trained 128 records in 0.076984714 seconds. Throughput is 1662.6678 records/second. Loss is 0.13211763. Sequential31006cbd's hyper parameters: Current learning rate is 0.005043373007867662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:27 INFO  DistriOptimizer$:408 - [Epoch 11 28928/60000][Iteration 4916][Wall Clock 470.469791804s] Trained 128 records in 0.077811707 seconds. Throughput is 1644.9966 records/second. Loss is 0.2521878. Sequential31006cbd's hyper parameters: Current learning rate is 0.005042864346949067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29056/60000][Iteration 4917][Wall Clock 470.54675005s] Trained 128 records in 0.076958246 seconds. Throughput is 1663.2395 records/second. Loss is 0.2192198. Sequential31006cbd's hyper parameters: Current learning rate is 0.005042355788624445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29184/60000][Iteration 4918][Wall Clock 470.621153618s] Trained 128 records in 0.074403568 seconds. Throughput is 1720.3475 records/second. Loss is 0.19042681. Sequential31006cbd's hyper parameters: Current learning rate is 0.005041847332862761. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29312/60000][Iteration 4919][Wall Clock 470.698598327s] Trained 128 records in 0.077444709 seconds. Throughput is 1652.792 records/second. Loss is 0.30532876. Sequential31006cbd's hyper parameters: Current learning rate is 0.00504133897963299. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29440/60000][Iteration 4920][Wall Clock 470.775009387s] Trained 128 records in 0.07641106 seconds. Throughput is 1675.1501 records/second. Loss is 0.19192725. Sequential31006cbd's hyper parameters: Current learning rate is 0.005040830728904123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29568/60000][Iteration 4921][Wall Clock 470.863993073s] Trained 128 records in 0.088983686 seconds. Throughput is 1438.466 records/second. Loss is 0.1753046. Sequential31006cbd's hyper parameters: Current learning rate is 0.005040322580645161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29696/60000][Iteration 4922][Wall Clock 470.936243971s] Trained 128 records in 0.072250898 seconds. Throughput is 1771.6044 records/second. Loss is 0.23475905. Sequential31006cbd's hyper parameters: Current learning rate is 0.005039814534825118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29824/60000][Iteration 4923][Wall Clock 471.004753179s] Trained 128 records in 0.068509208 seconds. Throughput is 1868.362 records/second. Loss is 0.13646482. Sequential31006cbd's hyper parameters: Current learning rate is 0.005039306591413022. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 29952/60000][Iteration 4924][Wall Clock 471.080082791s] Trained 128 records in 0.075329612 seconds. Throughput is 1699.1991 records/second. Loss is 0.22415087. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050387987503779106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 30080/60000][Iteration 4925][Wall Clock 471.159982831s] Trained 128 records in 0.07990004 seconds. Throughput is 1602.0017 records/second. Loss is 0.16587889. Sequential31006cbd's hyper parameters: Current learning rate is 0.005038291011688835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 30208/60000][Iteration 4926][Wall Clock 471.2343637s] Trained 128 records in 0.074380869 seconds. Throughput is 1720.8727 records/second. Loss is 0.1950669. Sequential31006cbd's hyper parameters: Current learning rate is 0.005037783375314861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 30336/60000][Iteration 4927][Wall Clock 471.309498786s] Trained 128 records in 0.075135086 seconds. Throughput is 1703.5981 records/second. Loss is 0.23657455. Sequential31006cbd's hyper parameters: Current learning rate is 0.005037275841225065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 30464/60000][Iteration 4928][Wall Clock 471.386035134s] Trained 128 records in 0.076536348 seconds. Throughput is 1672.408 records/second. Loss is 0.15693048. Sequential31006cbd's hyper parameters: Current learning rate is 0.005036768409388537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:28 INFO  DistriOptimizer$:408 - [Epoch 11 30592/60000][Iteration 4929][Wall Clock 471.461161078s] Trained 128 records in 0.075125944 seconds. Throughput is 1703.8054 records/second. Loss is 0.21757554. Sequential31006cbd's hyper parameters: Current learning rate is 0.005036261079774376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 30720/60000][Iteration 4930][Wall Clock 471.534903735s] Trained 128 records in 0.073742657 seconds. Throughput is 1735.766 records/second. Loss is 0.2197315. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050357538523516975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 30848/60000][Iteration 4931][Wall Clock 471.60818193s] Trained 128 records in 0.073278195 seconds. Throughput is 1746.768 records/second. Loss is 0.22227263. Sequential31006cbd's hyper parameters: Current learning rate is 0.005035246727089627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 30976/60000][Iteration 4932][Wall Clock 471.685420474s] Trained 128 records in 0.077238544 seconds. Throughput is 1657.2036 records/second. Loss is 0.24891068. Sequential31006cbd's hyper parameters: Current learning rate is 0.005034739703957305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31104/60000][Iteration 4933][Wall Clock 471.758225462s] Trained 128 records in 0.072804988 seconds. Throughput is 1758.1213 records/second. Loss is 0.21024114. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050342327829238824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31232/60000][Iteration 4934][Wall Clock 471.841573961s] Trained 128 records in 0.083348499 seconds. Throughput is 1535.7206 records/second. Loss is 0.20127304. Sequential31006cbd's hyper parameters: Current learning rate is 0.005033725963958522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31360/60000][Iteration 4935][Wall Clock 471.920944285s] Trained 128 records in 0.079370324 seconds. Throughput is 1612.6934 records/second. Loss is 0.22479753. Sequential31006cbd's hyper parameters: Current learning rate is 0.005033219247030401. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31488/60000][Iteration 4936][Wall Clock 471.99388945s] Trained 128 records in 0.072945165 seconds. Throughput is 1754.7428 records/second. Loss is 0.14257117. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050327126321087065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31616/60000][Iteration 4937][Wall Clock 472.067732855s] Trained 128 records in 0.073843405 seconds. Throughput is 1733.3978 records/second. Loss is 0.21571866. Sequential31006cbd's hyper parameters: Current learning rate is 0.005032206119162641. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31744/60000][Iteration 4938][Wall Clock 472.149391312s] Trained 128 records in 0.081658457 seconds. Throughput is 1567.5044 records/second. Loss is 0.2493154. Sequential31006cbd's hyper parameters: Current learning rate is 0.005031699708161417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 31872/60000][Iteration 4939][Wall Clock 472.225505774s] Trained 128 records in 0.076114462 seconds. Throughput is 1681.6779 records/second. Loss is 0.13739881. Sequential31006cbd's hyper parameters: Current learning rate is 0.00503119339907426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 32000/60000][Iteration 4940][Wall Clock 472.296649318s] Trained 128 records in 0.071143544 seconds. Throughput is 1799.1794 records/second. Loss is 0.19826782. Sequential31006cbd's hyper parameters: Current learning rate is 0.005030687191870409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 32128/60000][Iteration 4941][Wall Clock 472.366814623s] Trained 128 records in 0.070165305 seconds. Throughput is 1824.2634 records/second. Loss is 0.22568619. Sequential31006cbd's hyper parameters: Current learning rate is 0.005030181086519115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:29 INFO  DistriOptimizer$:408 - [Epoch 11 32256/60000][Iteration 4942][Wall Clock 472.443681796s] Trained 128 records in 0.076867173 seconds. Throughput is 1665.2102 records/second. Loss is 0.29959854. Sequential31006cbd's hyper parameters: Current learning rate is 0.005029675082989639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 32384/60000][Iteration 4943][Wall Clock 472.526698727s] Trained 128 records in 0.083016931 seconds. Throughput is 1541.8541 records/second. Loss is 0.19783966. Sequential31006cbd's hyper parameters: Current learning rate is 0.005029169181251258. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 32512/60000][Iteration 4944][Wall Clock 472.602840383s] Trained 128 records in 0.076141656 seconds. Throughput is 1681.0771 records/second. Loss is 0.13617735. Sequential31006cbd's hyper parameters: Current learning rate is 0.005028663381273258. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 32640/60000][Iteration 4945][Wall Clock 472.682186433s] Trained 128 records in 0.07934605 seconds. Throughput is 1613.1868 records/second. Loss is 0.2537747. Sequential31006cbd's hyper parameters: Current learning rate is 0.00502815768302494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 32768/60000][Iteration 4946][Wall Clock 472.764560565s] Trained 128 records in 0.082374132 seconds. Throughput is 1553.8859 records/second. Loss is 0.24583265. Sequential31006cbd's hyper parameters: Current learning rate is 0.005027652086475615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 32896/60000][Iteration 4947][Wall Clock 472.849199087s] Trained 128 records in 0.084638522 seconds. Throughput is 1512.3137 records/second. Loss is 0.12891749. Sequential31006cbd's hyper parameters: Current learning rate is 0.005027146591594611. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33024/60000][Iteration 4948][Wall Clock 472.917113042s] Trained 128 records in 0.067913955 seconds. Throughput is 1884.7378 records/second. Loss is 0.15780266. Sequential31006cbd's hyper parameters: Current learning rate is 0.005026641198351262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33152/60000][Iteration 4949][Wall Clock 472.993096386s] Trained 128 records in 0.075983344 seconds. Throughput is 1684.5797 records/second. Loss is 0.24131808. Sequential31006cbd's hyper parameters: Current learning rate is 0.005026135906714918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33280/60000][Iteration 4950][Wall Clock 473.070049946s] Trained 128 records in 0.07695356 seconds. Throughput is 1663.3408 records/second. Loss is 0.15188967. Sequential31006cbd's hyper parameters: Current learning rate is 0.00502563071665494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33408/60000][Iteration 4951][Wall Clock 473.147103527s] Trained 128 records in 0.077053581 seconds. Throughput is 1661.1816 records/second. Loss is 0.24167755. Sequential31006cbd's hyper parameters: Current learning rate is 0.005025125628140703. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33536/60000][Iteration 4952][Wall Clock 473.223854115s] Trained 128 records in 0.076750588 seconds. Throughput is 1667.7396 records/second. Loss is 0.24898408. Sequential31006cbd's hyper parameters: Current learning rate is 0.005024620641141593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33664/60000][Iteration 4953][Wall Clock 473.296626205s] Trained 128 records in 0.07277209 seconds. Throughput is 1758.916 records/second. Loss is 0.23204179. Sequential31006cbd's hyper parameters: Current learning rate is 0.00502411575562701. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33792/60000][Iteration 4954][Wall Clock 473.376280982s] Trained 128 records in 0.079654777 seconds. Throughput is 1606.9344 records/second. Loss is 0.21864352. Sequential31006cbd's hyper parameters: Current learning rate is 0.005023610971566362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:30 INFO  DistriOptimizer$:408 - [Epoch 11 33920/60000][Iteration 4955][Wall Clock 473.454499843s] Trained 128 records in 0.078218861 seconds. Throughput is 1636.434 records/second. Loss is 0.11549738. Sequential31006cbd's hyper parameters: Current learning rate is 0.005023106288929074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34048/60000][Iteration 4956][Wall Clock 473.534337964s] Trained 128 records in 0.079838121 seconds. Throughput is 1603.2441 records/second. Loss is 0.16980687. Sequential31006cbd's hyper parameters: Current learning rate is 0.005022601707684581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34176/60000][Iteration 4957][Wall Clock 473.608466668s] Trained 128 records in 0.074128704 seconds. Throughput is 1726.7266 records/second. Loss is 0.12872468. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050220972278023305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34304/60000][Iteration 4958][Wall Clock 473.675203781s] Trained 128 records in 0.066737113 seconds. Throughput is 1917.9733 records/second. Loss is 0.19018355. Sequential31006cbd's hyper parameters: Current learning rate is 0.005021592849251783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34432/60000][Iteration 4959][Wall Clock 473.752447124s] Trained 128 records in 0.077243343 seconds. Throughput is 1657.1007 records/second. Loss is 0.1435136. Sequential31006cbd's hyper parameters: Current learning rate is 0.00502108857200241. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34560/60000][Iteration 4960][Wall Clock 473.829849004s] Trained 128 records in 0.07740188 seconds. Throughput is 1653.7067 records/second. Loss is 0.3140487. Sequential31006cbd's hyper parameters: Current learning rate is 0.005020584396023697. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34688/60000][Iteration 4961][Wall Clock 473.908454584s] Trained 128 records in 0.07860558 seconds. Throughput is 1628.3832 records/second. Loss is 0.20006678. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050200803212851405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34816/60000][Iteration 4962][Wall Clock 473.987776426s] Trained 128 records in 0.079321842 seconds. Throughput is 1613.6792 records/second. Loss is 0.1398349. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050195763477562496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 34944/60000][Iteration 4963][Wall Clock 474.063254537s] Trained 128 records in 0.075478111 seconds. Throughput is 1695.8558 records/second. Loss is 0.17882031. Sequential31006cbd's hyper parameters: Current learning rate is 0.005019072475406545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 35072/60000][Iteration 4964][Wall Clock 474.137600838s] Trained 128 records in 0.074346301 seconds. Throughput is 1721.6727 records/second. Loss is 0.2764678. Sequential31006cbd's hyper parameters: Current learning rate is 0.005018568704205561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 35200/60000][Iteration 4965][Wall Clock 474.219977733s] Trained 128 records in 0.082376895 seconds. Throughput is 1553.8337 records/second. Loss is 0.12395194. Sequential31006cbd's hyper parameters: Current learning rate is 0.005018065034122843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 35328/60000][Iteration 4966][Wall Clock 474.299506904s] Trained 128 records in 0.079529171 seconds. Throughput is 1609.4723 records/second. Loss is 0.2179752. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050175614651279486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 35456/60000][Iteration 4967][Wall Clock 474.370660878s] Trained 128 records in 0.071153974 seconds. Throughput is 1798.9156 records/second. Loss is 0.11437811. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050170579971904475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:31 INFO  DistriOptimizer$:408 - [Epoch 11 35584/60000][Iteration 4968][Wall Clock 474.445762509s] Trained 128 records in 0.075101631 seconds. Throughput is 1704.3572 records/second. Loss is 0.23749222. Sequential31006cbd's hyper parameters: Current learning rate is 0.005016554630279924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 35712/60000][Iteration 4969][Wall Clock 474.52280807s] Trained 128 records in 0.077045561 seconds. Throughput is 1661.3546 records/second. Loss is 0.15248208. Sequential31006cbd's hyper parameters: Current learning rate is 0.005016051364365971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 35840/60000][Iteration 4970][Wall Clock 474.599537467s] Trained 128 records in 0.076729397 seconds. Throughput is 1668.2003 records/second. Loss is 0.14549541. Sequential31006cbd's hyper parameters: Current learning rate is 0.005015548199418196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 35968/60000][Iteration 4971][Wall Clock 474.673699553s] Trained 128 records in 0.074162086 seconds. Throughput is 1725.9492 records/second. Loss is 0.15498714. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050150451354062184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36096/60000][Iteration 4972][Wall Clock 474.755372683s] Trained 128 records in 0.08167313 seconds. Throughput is 1567.2229 records/second. Loss is 0.25743097. Sequential31006cbd's hyper parameters: Current learning rate is 0.005014542172299669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36224/60000][Iteration 4973][Wall Clock 474.838927357s] Trained 128 records in 0.083554674 seconds. Throughput is 1531.931 records/second. Loss is 0.13813385. Sequential31006cbd's hyper parameters: Current learning rate is 0.00501403931006819. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36352/60000][Iteration 4974][Wall Clock 474.915383066s] Trained 128 records in 0.076455709 seconds. Throughput is 1674.1719 records/second. Loss is 0.33516857. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050135365486814396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36480/60000][Iteration 4975][Wall Clock 474.996397311s] Trained 128 records in 0.081014245 seconds. Throughput is 1579.969 records/second. Loss is 0.25009358. Sequential31006cbd's hyper parameters: Current learning rate is 0.005013033888109084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36608/60000][Iteration 4976][Wall Clock 475.074222169s] Trained 128 records in 0.077824858 seconds. Throughput is 1644.7186 records/second. Loss is 0.3675848. Sequential31006cbd's hyper parameters: Current learning rate is 0.005012531328320802. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36736/60000][Iteration 4977][Wall Clock 475.153966541s] Trained 128 records in 0.079744372 seconds. Throughput is 1605.129 records/second. Loss is 0.2562203. Sequential31006cbd's hyper parameters: Current learning rate is 0.005012028869286287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36864/60000][Iteration 4978][Wall Clock 475.247916395s] Trained 128 records in 0.093949854 seconds. Throughput is 1362.429 records/second. Loss is 0.2460055. Sequential31006cbd's hyper parameters: Current learning rate is 0.005011526510975243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 36992/60000][Iteration 4979][Wall Clock 475.324078148s] Trained 128 records in 0.076161753 seconds. Throughput is 1680.6337 records/second. Loss is 0.23044714. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050110242533573865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 37120/60000][Iteration 4980][Wall Clock 475.395319493s] Trained 128 records in 0.071241345 seconds. Throughput is 1796.7096 records/second. Loss is 0.22490776. Sequential31006cbd's hyper parameters: Current learning rate is 0.005010522096402445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:32 INFO  DistriOptimizer$:408 - [Epoch 11 37248/60000][Iteration 4981][Wall Clock 475.481726882s] Trained 128 records in 0.086407389 seconds. Throughput is 1481.3549 records/second. Loss is 0.2569989. Sequential31006cbd's hyper parameters: Current learning rate is 0.00501002004008016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 37376/60000][Iteration 4982][Wall Clock 475.556006525s] Trained 128 records in 0.074279643 seconds. Throughput is 1723.2178 records/second. Loss is 0.20611496. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050095180843602845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 37504/60000][Iteration 4983][Wall Clock 475.629164496s] Trained 128 records in 0.073157971 seconds. Throughput is 1749.6384 records/second. Loss is 0.14962968. Sequential31006cbd's hyper parameters: Current learning rate is 0.005009016229212583. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 37632/60000][Iteration 4984][Wall Clock 475.705053765s] Trained 128 records in 0.075889269 seconds. Throughput is 1686.668 records/second. Loss is 0.21719001. Sequential31006cbd's hyper parameters: Current learning rate is 0.005008514474606832. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 37760/60000][Iteration 4985][Wall Clock 475.78216039s] Trained 128 records in 0.077106625 seconds. Throughput is 1660.039 records/second. Loss is 0.14675023. Sequential31006cbd's hyper parameters: Current learning rate is 0.005008012820512821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 37888/60000][Iteration 4986][Wall Clock 475.86236788s] Trained 128 records in 0.08020749 seconds. Throughput is 1595.861 records/second. Loss is 0.12420265. Sequential31006cbd's hyper parameters: Current learning rate is 0.005007511266900351. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38016/60000][Iteration 4987][Wall Clock 475.942871916s] Trained 128 records in 0.080504036 seconds. Throughput is 1589.9824 records/second. Loss is 0.11359407. Sequential31006cbd's hyper parameters: Current learning rate is 0.005007009813739235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38144/60000][Iteration 4988][Wall Clock 476.0251147s] Trained 128 records in 0.082242784 seconds. Throughput is 1556.3674 records/second. Loss is 0.19186497. Sequential31006cbd's hyper parameters: Current learning rate is 0.005006508460999299. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38272/60000][Iteration 4989][Wall Clock 476.103278463s] Trained 128 records in 0.078163763 seconds. Throughput is 1637.5874 records/second. Loss is 0.15336585. Sequential31006cbd's hyper parameters: Current learning rate is 0.005006007208650381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38400/60000][Iteration 4990][Wall Clock 476.177647937s] Trained 128 records in 0.074369474 seconds. Throughput is 1721.1362 records/second. Loss is 0.26671958. Sequential31006cbd's hyper parameters: Current learning rate is 0.005005506056662328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38528/60000][Iteration 4991][Wall Clock 476.255167781s] Trained 128 records in 0.077519844 seconds. Throughput is 1651.1902 records/second. Loss is 0.26482192. Sequential31006cbd's hyper parameters: Current learning rate is 0.005005005005005005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38656/60000][Iteration 4992][Wall Clock 476.333123636s] Trained 128 records in 0.077955855 seconds. Throughput is 1641.9548 records/second. Loss is 0.15306962. Sequential31006cbd's hyper parameters: Current learning rate is 0.005004504053648283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38784/60000][Iteration 4993][Wall Clock 476.40730404s] Trained 128 records in 0.074180404 seconds. Throughput is 1725.5232 records/second. Loss is 0.1320651. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050040032025620495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:33 INFO  DistriOptimizer$:408 - [Epoch 11 38912/60000][Iteration 4994][Wall Clock 476.479316919s] Trained 128 records in 0.072012879 seconds. Throughput is 1777.4598 records/second. Loss is 0.10793886. Sequential31006cbd's hyper parameters: Current learning rate is 0.005003502451716201. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39040/60000][Iteration 4995][Wall Clock 476.552593777s] Trained 128 records in 0.073276858 seconds. Throughput is 1746.7998 records/second. Loss is 0.1997571. Sequential31006cbd's hyper parameters: Current learning rate is 0.005003001801080648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39168/60000][Iteration 4996][Wall Clock 476.629864497s] Trained 128 records in 0.07727072 seconds. Throughput is 1656.5137 records/second. Loss is 0.17568967. Sequential31006cbd's hyper parameters: Current learning rate is 0.0050025012506253125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39296/60000][Iteration 4997][Wall Clock 476.707059671s] Trained 128 records in 0.077195174 seconds. Throughput is 1658.1348 records/second. Loss is 0.1537871. Sequential31006cbd's hyper parameters: Current learning rate is 0.005002000800320128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39424/60000][Iteration 4998][Wall Clock 476.77952616s] Trained 128 records in 0.072466489 seconds. Throughput is 1766.3336 records/second. Loss is 0.21088602. Sequential31006cbd's hyper parameters: Current learning rate is 0.00500150045013504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39552/60000][Iteration 4999][Wall Clock 476.864102968s] Trained 128 records in 0.084576808 seconds. Throughput is 1513.4172 records/second. Loss is 0.2413167. Sequential31006cbd's hyper parameters: Current learning rate is 0.005001000200040008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39680/60000][Iteration 5000][Wall Clock 476.935230163s] Trained 128 records in 0.071127195 seconds. Throughput is 1799.5929 records/second. Loss is 0.1411349. Sequential31006cbd's hyper parameters: Current learning rate is 0.005000500050005001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39808/60000][Iteration 5001][Wall Clock 477.005446s] Trained 128 records in 0.070215837 seconds. Throughput is 1822.9506 records/second. Loss is 0.14179203. Sequential31006cbd's hyper parameters: Current learning rate is 0.005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 39936/60000][Iteration 5002][Wall Clock 477.087993019s] Trained 128 records in 0.082547019 seconds. Throughput is 1550.6315 records/second. Loss is 0.19280465. Sequential31006cbd's hyper parameters: Current learning rate is 0.004999500049995001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 40064/60000][Iteration 5003][Wall Clock 477.164293376s] Trained 128 records in 0.076300357 seconds. Throughput is 1677.5806 records/second. Loss is 0.121547684. Sequential31006cbd's hyper parameters: Current learning rate is 0.004999000199960009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 40192/60000][Iteration 5004][Wall Clock 477.239333354s] Trained 128 records in 0.075039978 seconds. Throughput is 1705.7574 records/second. Loss is 0.24131876. Sequential31006cbd's hyper parameters: Current learning rate is 0.00499850044986504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 40320/60000][Iteration 5005][Wall Clock 477.317986694s] Trained 128 records in 0.07865334 seconds. Throughput is 1627.3943 records/second. Loss is 0.17460898. Sequential31006cbd's hyper parameters: Current learning rate is 0.004998000799680128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:34 INFO  DistriOptimizer$:408 - [Epoch 11 40448/60000][Iteration 5006][Wall Clock 477.408226112s] Trained 128 records in 0.090239418 seconds. Throughput is 1418.4489 records/second. Loss is 0.21505734. Sequential31006cbd's hyper parameters: Current learning rate is 0.004997501249375312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 40576/60000][Iteration 5007][Wall Clock 477.508558892s] Trained 128 records in 0.10033278 seconds. Throughput is 1275.7545 records/second. Loss is 0.16706957. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049970017989206484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 40704/60000][Iteration 5008][Wall Clock 477.590180307s] Trained 128 records in 0.081621415 seconds. Throughput is 1568.2158 records/second. Loss is 0.1409381. Sequential31006cbd's hyper parameters: Current learning rate is 0.004996502448286199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 40832/60000][Iteration 5009][Wall Clock 477.679430893s] Trained 128 records in 0.089250586 seconds. Throughput is 1434.1642 records/second. Loss is 0.2103305. Sequential31006cbd's hyper parameters: Current learning rate is 0.004996003197442047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 40960/60000][Iteration 5010][Wall Clock 477.758903477s] Trained 128 records in 0.079472584 seconds. Throughput is 1610.6183 records/second. Loss is 0.20271927. Sequential31006cbd's hyper parameters: Current learning rate is 0.004995504046358277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41088/60000][Iteration 5011][Wall Clock 477.835718298s] Trained 128 records in 0.076814821 seconds. Throughput is 1666.3451 records/second. Loss is 0.2153182. Sequential31006cbd's hyper parameters: Current learning rate is 0.004995004995004996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41216/60000][Iteration 5012][Wall Clock 477.911336222s] Trained 128 records in 0.075617924 seconds. Throughput is 1692.7203 records/second. Loss is 0.22631463. Sequential31006cbd's hyper parameters: Current learning rate is 0.004994506043352312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41344/60000][Iteration 5013][Wall Clock 477.987434251s] Trained 128 records in 0.076098029 seconds. Throughput is 1682.0409 records/second. Loss is 0.27213892. Sequential31006cbd's hyper parameters: Current learning rate is 0.004994007191370356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41472/60000][Iteration 5014][Wall Clock 478.06909495s] Trained 128 records in 0.081660699 seconds. Throughput is 1567.4615 records/second. Loss is 0.19134249. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049935084390292615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41600/60000][Iteration 5015][Wall Clock 478.145884675s] Trained 128 records in 0.076789725 seconds. Throughput is 1666.8898 records/second. Loss is 0.2150615. Sequential31006cbd's hyper parameters: Current learning rate is 0.004993009786299181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41728/60000][Iteration 5016][Wall Clock 478.218229187s] Trained 128 records in 0.072344512 seconds. Throughput is 1769.3118 records/second. Loss is 0.21145192. Sequential31006cbd's hyper parameters: Current learning rate is 0.004992511233150274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41856/60000][Iteration 5017][Wall Clock 478.291271827s] Trained 128 records in 0.07304264 seconds. Throughput is 1752.4011 records/second. Loss is 0.2797871. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049920127795527154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 41984/60000][Iteration 5018][Wall Clock 478.366219348s] Trained 128 records in 0.074947521 seconds. Throughput is 1707.8617 records/second. Loss is 0.18088014. Sequential31006cbd's hyper parameters: Current learning rate is 0.004991514425476689. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:35 INFO  DistriOptimizer$:408 - [Epoch 11 42112/60000][Iteration 5019][Wall Clock 478.446332143s] Trained 128 records in 0.080112795 seconds. Throughput is 1597.7473 records/second. Loss is 0.15556802. Sequential31006cbd's hyper parameters: Current learning rate is 0.004991016170892394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 42240/60000][Iteration 5020][Wall Clock 478.522492895s] Trained 128 records in 0.076160752 seconds. Throughput is 1680.6556 records/second. Loss is 0.16999285. Sequential31006cbd's hyper parameters: Current learning rate is 0.004990518015770037. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 42368/60000][Iteration 5021][Wall Clock 478.608341799s] Trained 128 records in 0.085848904 seconds. Throughput is 1490.9917 records/second. Loss is 0.21769418. Sequential31006cbd's hyper parameters: Current learning rate is 0.00499001996007984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 42496/60000][Iteration 5022][Wall Clock 478.688044301s] Trained 128 records in 0.079702502 seconds. Throughput is 1605.9722 records/second. Loss is 0.1367316. Sequential31006cbd's hyper parameters: Current learning rate is 0.004989522003792037. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 42624/60000][Iteration 5023][Wall Clock 478.769691324s] Trained 128 records in 0.081647023 seconds. Throughput is 1567.724 records/second. Loss is 0.16524906. Sequential31006cbd's hyper parameters: Current learning rate is 0.004989024146876871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 42752/60000][Iteration 5024][Wall Clock 478.848976349s] Trained 128 records in 0.079285025 seconds. Throughput is 1614.4285 records/second. Loss is 0.13174088. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049885263893046. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 42880/60000][Iteration 5025][Wall Clock 478.932232649s] Trained 128 records in 0.0832563 seconds. Throughput is 1537.4213 records/second. Loss is 0.14422607. Sequential31006cbd's hyper parameters: Current learning rate is 0.00498802873104549. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43008/60000][Iteration 5026][Wall Clock 479.015435074s] Trained 128 records in 0.083202425 seconds. Throughput is 1538.4167 records/second. Loss is 0.17014967. Sequential31006cbd's hyper parameters: Current learning rate is 0.004987531172069826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43136/60000][Iteration 5027][Wall Clock 479.090150911s] Trained 128 records in 0.074715837 seconds. Throughput is 1713.1575 records/second. Loss is 0.15721674. Sequential31006cbd's hyper parameters: Current learning rate is 0.004987033712347895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43264/60000][Iteration 5028][Wall Clock 479.168320368s] Trained 128 records in 0.078169457 seconds. Throughput is 1637.4681 records/second. Loss is 0.18477607. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049865363518500055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43392/60000][Iteration 5029][Wall Clock 479.242859985s] Trained 128 records in 0.074539617 seconds. Throughput is 1717.2076 records/second. Loss is 0.21894017. Sequential31006cbd's hyper parameters: Current learning rate is 0.004986039090546469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43520/60000][Iteration 5030][Wall Clock 479.319881838s] Trained 128 records in 0.077021853 seconds. Throughput is 1661.8661 records/second. Loss is 0.14216505. Sequential31006cbd's hyper parameters: Current learning rate is 0.004985541928407619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43648/60000][Iteration 5031][Wall Clock 479.398125851s] Trained 128 records in 0.078244013 seconds. Throughput is 1635.9078 records/second. Loss is 0.12720287. Sequential31006cbd's hyper parameters: Current learning rate is 0.004985044865403788. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:36 INFO  DistriOptimizer$:408 - [Epoch 11 43776/60000][Iteration 5032][Wall Clock 479.474256s] Trained 128 records in 0.076130149 seconds. Throughput is 1681.3312 records/second. Loss is 0.1449886. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049845479015053346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 43904/60000][Iteration 5033][Wall Clock 479.554000589s] Trained 128 records in 0.079744589 seconds. Throughput is 1605.1245 records/second. Loss is 0.1694175. Sequential31006cbd's hyper parameters: Current learning rate is 0.004984051036682615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44032/60000][Iteration 5034][Wall Clock 479.628748232s] Trained 128 records in 0.074747643 seconds. Throughput is 1712.4286 records/second. Loss is 0.14032568. Sequential31006cbd's hyper parameters: Current learning rate is 0.004983554270906011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44160/60000][Iteration 5035][Wall Clock 479.708965692s] Trained 128 records in 0.08021746 seconds. Throughput is 1595.6626 records/second. Loss is 0.12907076. Sequential31006cbd's hyper parameters: Current learning rate is 0.004983057604145903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44288/60000][Iteration 5036][Wall Clock 479.782619954s] Trained 128 records in 0.073654262 seconds. Throughput is 1737.8491 records/second. Loss is 0.09964254. Sequential31006cbd's hyper parameters: Current learning rate is 0.004982561036372696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44416/60000][Iteration 5037][Wall Clock 479.854839897s] Trained 128 records in 0.072219943 seconds. Throughput is 1772.3635 records/second. Loss is 0.22260703. Sequential31006cbd's hyper parameters: Current learning rate is 0.004982064567556795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44544/60000][Iteration 5038][Wall Clock 479.934569989s] Trained 128 records in 0.079730092 seconds. Throughput is 1605.4164 records/second. Loss is 0.2023925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004981568197668626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44672/60000][Iteration 5039][Wall Clock 480.012876781s] Trained 128 records in 0.078306792 seconds. Throughput is 1634.5963 records/second. Loss is 0.14128914. Sequential31006cbd's hyper parameters: Current learning rate is 0.004981071926678621. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44800/60000][Iteration 5040][Wall Clock 480.090666313s] Trained 128 records in 0.077789532 seconds. Throughput is 1645.4657 records/second. Loss is 0.16306247. Sequential31006cbd's hyper parameters: Current learning rate is 0.004980575754557227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 44928/60000][Iteration 5041][Wall Clock 480.16988616s] Trained 128 records in 0.079219847 seconds. Throughput is 1615.7567 records/second. Loss is 0.1519866. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049800796812749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 45056/60000][Iteration 5042][Wall Clock 480.254740977s] Trained 128 records in 0.084854817 seconds. Throughput is 1508.4589 records/second. Loss is 0.23746358. Sequential31006cbd's hyper parameters: Current learning rate is 0.004979583706802112. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 45184/60000][Iteration 5043][Wall Clock 480.333029287s] Trained 128 records in 0.07828831 seconds. Throughput is 1634.9823 records/second. Loss is 0.33522853. Sequential31006cbd's hyper parameters: Current learning rate is 0.004979087831109341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:37 INFO  DistriOptimizer$:408 - [Epoch 11 45312/60000][Iteration 5044][Wall Clock 480.417464818s] Trained 128 records in 0.084435531 seconds. Throughput is 1515.9495 records/second. Loss is 0.15139993. Sequential31006cbd's hyper parameters: Current learning rate is 0.004978592054167082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 45440/60000][Iteration 5045][Wall Clock 480.494824299s] Trained 128 records in 0.077359481 seconds. Throughput is 1654.6129 records/second. Loss is 0.25473425. Sequential31006cbd's hyper parameters: Current learning rate is 0.004978096375945838. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 45568/60000][Iteration 5046][Wall Clock 480.567712646s] Trained 128 records in 0.072888347 seconds. Throughput is 1756.1107 records/second. Loss is 0.124905586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004977600796416127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 45696/60000][Iteration 5047][Wall Clock 480.648906682s] Trained 128 records in 0.081194036 seconds. Throughput is 1576.4705 records/second. Loss is 0.23670438. Sequential31006cbd's hyper parameters: Current learning rate is 0.004977105315548477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 45824/60000][Iteration 5048][Wall Clock 480.738748703s] Trained 128 records in 0.089842021 seconds. Throughput is 1424.723 records/second. Loss is 0.23228648. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049766099333134264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 45952/60000][Iteration 5049][Wall Clock 480.817719791s] Trained 128 records in 0.078971088 seconds. Throughput is 1620.8463 records/second. Loss is 0.10940248. Sequential31006cbd's hyper parameters: Current learning rate is 0.004976114649681529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46080/60000][Iteration 5050][Wall Clock 480.91313134s] Trained 128 records in 0.095411549 seconds. Throughput is 1341.5568 records/second. Loss is 0.17809154. Sequential31006cbd's hyper parameters: Current learning rate is 0.004975619464623345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46208/60000][Iteration 5051][Wall Clock 480.992036123s] Trained 128 records in 0.078904783 seconds. Throughput is 1622.2084 records/second. Loss is 0.26153398. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049751243781094535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46336/60000][Iteration 5052][Wall Clock 481.066780209s] Trained 128 records in 0.074744086 seconds. Throughput is 1712.5101 records/second. Loss is 0.19717224. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049746293901104365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46464/60000][Iteration 5053][Wall Clock 481.141330296s] Trained 128 records in 0.074550087 seconds. Throughput is 1716.9666 records/second. Loss is 0.18864705. Sequential31006cbd's hyper parameters: Current learning rate is 0.004974134500596897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46592/60000][Iteration 5054][Wall Clock 481.20888853s] Trained 128 records in 0.067558234 seconds. Throughput is 1894.6616 records/second. Loss is 0.1615185. Sequential31006cbd's hyper parameters: Current learning rate is 0.00497363970953944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46720/60000][Iteration 5055][Wall Clock 481.282649169s] Trained 128 records in 0.073760639 seconds. Throughput is 1735.3429 records/second. Loss is 0.140881. Sequential31006cbd's hyper parameters: Current learning rate is 0.004973145016908693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46848/60000][Iteration 5056][Wall Clock 481.354960614s] Trained 128 records in 0.072311445 seconds. Throughput is 1770.1208 records/second. Loss is 0.21641947. Sequential31006cbd's hyper parameters: Current learning rate is 0.004972650422675286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:38 INFO  DistriOptimizer$:408 - [Epoch 11 46976/60000][Iteration 5057][Wall Clock 481.430575954s] Trained 128 records in 0.07561534 seconds. Throughput is 1692.7782 records/second. Loss is 0.24999793. Sequential31006cbd's hyper parameters: Current learning rate is 0.004972155926809865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47104/60000][Iteration 5058][Wall Clock 481.512153257s] Trained 128 records in 0.081577303 seconds. Throughput is 1569.064 records/second. Loss is 0.22115028. Sequential31006cbd's hyper parameters: Current learning rate is 0.004971661529283087. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47232/60000][Iteration 5059][Wall Clock 481.582627185s] Trained 128 records in 0.070473928 seconds. Throughput is 1816.2747 records/second. Loss is 0.11316763. Sequential31006cbd's hyper parameters: Current learning rate is 0.00497116723006562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47360/60000][Iteration 5060][Wall Clock 481.655211347s] Trained 128 records in 0.072584162 seconds. Throughput is 1763.4702 records/second. Loss is 0.15058579. Sequential31006cbd's hyper parameters: Current learning rate is 0.004970673029128144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47488/60000][Iteration 5061][Wall Clock 481.731260293s] Trained 128 records in 0.076048946 seconds. Throughput is 1683.1265 records/second. Loss is 0.23766392. Sequential31006cbd's hyper parameters: Current learning rate is 0.004970178926441352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47616/60000][Iteration 5062][Wall Clock 481.803153203s] Trained 128 records in 0.07189291 seconds. Throughput is 1780.4259 records/second. Loss is 0.17334238. Sequential31006cbd's hyper parameters: Current learning rate is 0.004969684921975947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47744/60000][Iteration 5063][Wall Clock 481.876930739s] Trained 128 records in 0.073777536 seconds. Throughput is 1734.9454 records/second. Loss is 0.21561895. Sequential31006cbd's hyper parameters: Current learning rate is 0.004969191015702644. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 47872/60000][Iteration 5064][Wall Clock 481.950606641s] Trained 128 records in 0.073675902 seconds. Throughput is 1737.3387 records/second. Loss is 0.21627116. Sequential31006cbd's hyper parameters: Current learning rate is 0.004968697207592169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 48000/60000][Iteration 5065][Wall Clock 482.032497645s] Trained 128 records in 0.081891004 seconds. Throughput is 1563.0532 records/second. Loss is 0.1424886. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049682034976152615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 48128/60000][Iteration 5066][Wall Clock 482.107741315s] Trained 128 records in 0.07524367 seconds. Throughput is 1701.1399 records/second. Loss is 0.16647834. Sequential31006cbd's hyper parameters: Current learning rate is 0.004967709885742673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 48256/60000][Iteration 5067][Wall Clock 482.181261394s] Trained 128 records in 0.073520079 seconds. Throughput is 1741.021 records/second. Loss is 0.19924529. Sequential31006cbd's hyper parameters: Current learning rate is 0.004967216371945161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 48384/60000][Iteration 5068][Wall Clock 482.275108684s] Trained 128 records in 0.09384729 seconds. Throughput is 1363.918 records/second. Loss is 0.25880012. Sequential31006cbd's hyper parameters: Current learning rate is 0.004966722956193504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 48512/60000][Iteration 5069][Wall Clock 482.347182302s] Trained 128 records in 0.072073618 seconds. Throughput is 1775.9619 records/second. Loss is 0.17124546. Sequential31006cbd's hyper parameters: Current learning rate is 0.004966229638458481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:39 INFO  DistriOptimizer$:408 - [Epoch 11 48640/60000][Iteration 5070][Wall Clock 482.421586191s] Trained 128 records in 0.074403889 seconds. Throughput is 1720.3402 records/second. Loss is 0.19750658. Sequential31006cbd's hyper parameters: Current learning rate is 0.004965736418710895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 48768/60000][Iteration 5071][Wall Clock 482.497966812s] Trained 128 records in 0.076380621 seconds. Throughput is 1675.8179 records/second. Loss is 0.23034957. Sequential31006cbd's hyper parameters: Current learning rate is 0.004965243296921548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 48896/60000][Iteration 5072][Wall Clock 482.577291783s] Trained 128 records in 0.079324971 seconds. Throughput is 1613.6155 records/second. Loss is 0.23358871. Sequential31006cbd's hyper parameters: Current learning rate is 0.004964750273061266. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49024/60000][Iteration 5073][Wall Clock 482.653319233s] Trained 128 records in 0.07602745 seconds. Throughput is 1683.6024 records/second. Loss is 0.14814976. Sequential31006cbd's hyper parameters: Current learning rate is 0.004964257347100873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49152/60000][Iteration 5074][Wall Clock 482.732451773s] Trained 128 records in 0.07913254 seconds. Throughput is 1617.5393 records/second. Loss is 0.23870626. Sequential31006cbd's hyper parameters: Current learning rate is 0.004963764519011219. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49280/60000][Iteration 5075][Wall Clock 482.808617249s] Trained 128 records in 0.076165476 seconds. Throughput is 1680.5515 records/second. Loss is 0.22924975. Sequential31006cbd's hyper parameters: Current learning rate is 0.004963271788763152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49408/60000][Iteration 5076][Wall Clock 482.888414959s] Trained 128 records in 0.07979771 seconds. Throughput is 1604.0562 records/second. Loss is 0.22138427. Sequential31006cbd's hyper parameters: Current learning rate is 0.004962779156327543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49536/60000][Iteration 5077][Wall Clock 482.959006558s] Trained 128 records in 0.070591599 seconds. Throughput is 1813.247 records/second. Loss is 0.13312718. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049622866216752675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49664/60000][Iteration 5078][Wall Clock 483.031589159s] Trained 128 records in 0.072582601 seconds. Throughput is 1763.508 records/second. Loss is 0.235389. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049617941847772155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49792/60000][Iteration 5079][Wall Clock 483.10855343s] Trained 128 records in 0.076964271 seconds. Throughput is 1663.1093 records/second. Loss is 0.18274881. Sequential31006cbd's hyper parameters: Current learning rate is 0.004961301845604287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 49920/60000][Iteration 5080][Wall Clock 483.187174501s] Trained 128 records in 0.078621071 seconds. Throughput is 1628.0623 records/second. Loss is 0.22143024. Sequential31006cbd's hyper parameters: Current learning rate is 0.004960809604127394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 50048/60000][Iteration 5081][Wall Clock 483.273604302s] Trained 128 records in 0.086429801 seconds. Throughput is 1480.9706 records/second. Loss is 0.20386109. Sequential31006cbd's hyper parameters: Current learning rate is 0.00496031746031746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 50176/60000][Iteration 5082][Wall Clock 483.354880935s] Trained 128 records in 0.081276633 seconds. Throughput is 1574.8684 records/second. Loss is 0.18692452. Sequential31006cbd's hyper parameters: Current learning rate is 0.004959825414145422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:40 INFO  DistriOptimizer$:408 - [Epoch 11 50304/60000][Iteration 5083][Wall Clock 483.428908403s] Trained 128 records in 0.074027468 seconds. Throughput is 1729.0879 records/second. Loss is 0.19137147. Sequential31006cbd's hyper parameters: Current learning rate is 0.004959333465582226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 50432/60000][Iteration 5084][Wall Clock 483.517084018s] Trained 128 records in 0.088175615 seconds. Throughput is 1451.6484 records/second. Loss is 0.15643263. Sequential31006cbd's hyper parameters: Current learning rate is 0.00495884161459883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 50560/60000][Iteration 5085][Wall Clock 483.59292739s] Trained 128 records in 0.075843372 seconds. Throughput is 1687.6887 records/second. Loss is 0.2585755. Sequential31006cbd's hyper parameters: Current learning rate is 0.004958349861166204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 50688/60000][Iteration 5086][Wall Clock 483.710719734s] Trained 128 records in 0.117792344 seconds. Throughput is 1086.6581 records/second. Loss is 0.20321417. Sequential31006cbd's hyper parameters: Current learning rate is 0.004957858205255329. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 50816/60000][Iteration 5087][Wall Clock 483.812319554s] Trained 128 records in 0.10159982 seconds. Throughput is 1259.8447 records/second. Loss is 0.20252484. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049573666468372005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 50944/60000][Iteration 5088][Wall Clock 483.901013624s] Trained 128 records in 0.08869407 seconds. Throughput is 1443.163 records/second. Loss is 0.3120248. Sequential31006cbd's hyper parameters: Current learning rate is 0.004956875185882819. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 51072/60000][Iteration 5089][Wall Clock 483.996048337s] Trained 128 records in 0.095034713 seconds. Throughput is 1346.8763 records/second. Loss is 0.2112759. Sequential31006cbd's hyper parameters: Current learning rate is 0.004956383822363204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 51200/60000][Iteration 5090][Wall Clock 484.079547338s] Trained 128 records in 0.083499001 seconds. Throughput is 1532.9525 records/second. Loss is 0.22997838. Sequential31006cbd's hyper parameters: Current learning rate is 0.00495589255624938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 51328/60000][Iteration 5091][Wall Clock 484.157956832s] Trained 128 records in 0.078409494 seconds. Throughput is 1632.4554 records/second. Loss is 0.1691484. Sequential31006cbd's hyper parameters: Current learning rate is 0.004955401387512389. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 51456/60000][Iteration 5092][Wall Clock 484.240470983s] Trained 128 records in 0.082514151 seconds. Throughput is 1551.249 records/second. Loss is 0.16274112. Sequential31006cbd's hyper parameters: Current learning rate is 0.004954910316123278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 51584/60000][Iteration 5093][Wall Clock 484.323389354s] Trained 128 records in 0.082918371 seconds. Throughput is 1543.6869 records/second. Loss is 0.19902197. Sequential31006cbd's hyper parameters: Current learning rate is 0.004954419342053112. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:41 INFO  DistriOptimizer$:408 - [Epoch 11 51712/60000][Iteration 5094][Wall Clock 484.396933246s] Trained 128 records in 0.073543892 seconds. Throughput is 1740.4573 records/second. Loss is 0.26041302. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049539284652729615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 51840/60000][Iteration 5095][Wall Clock 484.485835035s] Trained 128 records in 0.088901789 seconds. Throughput is 1439.791 records/second. Loss is 0.19150211. Sequential31006cbd's hyper parameters: Current learning rate is 0.004953437685753913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 51968/60000][Iteration 5096][Wall Clock 484.5864283s] Trained 128 records in 0.100593265 seconds. Throughput is 1272.451 records/second. Loss is 0.22403455. Sequential31006cbd's hyper parameters: Current learning rate is 0.004952947003467063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52096/60000][Iteration 5097][Wall Clock 484.669241416s] Trained 128 records in 0.082813116 seconds. Throughput is 1545.6489 records/second. Loss is 0.2389047. Sequential31006cbd's hyper parameters: Current learning rate is 0.004952456418383518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52224/60000][Iteration 5098][Wall Clock 484.747834707s] Trained 128 records in 0.078593291 seconds. Throughput is 1628.6377 records/second. Loss is 0.24677983. Sequential31006cbd's hyper parameters: Current learning rate is 0.004951965930474398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52352/60000][Iteration 5099][Wall Clock 484.826486325s] Trained 128 records in 0.078651618 seconds. Throughput is 1627.43 records/second. Loss is 0.1790275. Sequential31006cbd's hyper parameters: Current learning rate is 0.004951475539710834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52480/60000][Iteration 5100][Wall Clock 484.90734366s] Trained 128 records in 0.080857335 seconds. Throughput is 1583.035 records/second. Loss is 0.20711693. Sequential31006cbd's hyper parameters: Current learning rate is 0.004950985246063967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52608/60000][Iteration 5101][Wall Clock 484.982668298s] Trained 128 records in 0.075324638 seconds. Throughput is 1699.3112 records/second. Loss is 0.0944168. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049504950495049506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52736/60000][Iteration 5102][Wall Clock 485.088875446s] Trained 128 records in 0.106207148 seconds. Throughput is 1205.192 records/second. Loss is 0.23344427. Sequential31006cbd's hyper parameters: Current learning rate is 0.00495000495000495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52864/60000][Iteration 5103][Wall Clock 485.175109206s] Trained 128 records in 0.08623376 seconds. Throughput is 1484.3375 records/second. Loss is 0.22530589. Sequential31006cbd's hyper parameters: Current learning rate is 0.004949514947535142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 52992/60000][Iteration 5104][Wall Clock 485.268276106s] Trained 128 records in 0.0931669 seconds. Throughput is 1373.8784 records/second. Loss is 0.18523246. Sequential31006cbd's hyper parameters: Current learning rate is 0.004949025042066713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 53120/60000][Iteration 5105][Wall Clock 485.340996851s] Trained 128 records in 0.072720745 seconds. Throughput is 1760.158 records/second. Loss is 0.21312188. Sequential31006cbd's hyper parameters: Current learning rate is 0.004948535233570862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:42 INFO  DistriOptimizer$:408 - [Epoch 11 53248/60000][Iteration 5106][Wall Clock 485.426412487s] Trained 128 records in 0.085415636 seconds. Throughput is 1498.5546 records/second. Loss is 0.19679499. Sequential31006cbd's hyper parameters: Current learning rate is 0.004948045522018803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 53376/60000][Iteration 5107][Wall Clock 485.506778745s] Trained 128 records in 0.080366258 seconds. Throughput is 1592.7081 records/second. Loss is 0.21829453. Sequential31006cbd's hyper parameters: Current learning rate is 0.004947555907381752. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 53504/60000][Iteration 5108][Wall Clock 485.584880338s] Trained 128 records in 0.078101593 seconds. Throughput is 1638.8911 records/second. Loss is 0.20761937. Sequential31006cbd's hyper parameters: Current learning rate is 0.004947066389630949. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 53632/60000][Iteration 5109][Wall Clock 485.664168604s] Trained 128 records in 0.079288266 seconds. Throughput is 1614.3624 records/second. Loss is 0.22056887. Sequential31006cbd's hyper parameters: Current learning rate is 0.004946576968737633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 53760/60000][Iteration 5110][Wall Clock 485.75303337s] Trained 128 records in 0.088864766 seconds. Throughput is 1440.3909 records/second. Loss is 0.210598. Sequential31006cbd's hyper parameters: Current learning rate is 0.004946087644673064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 53888/60000][Iteration 5111][Wall Clock 485.850988277s] Trained 128 records in 0.097954907 seconds. Throughput is 1306.7238 records/second. Loss is 0.13218196. Sequential31006cbd's hyper parameters: Current learning rate is 0.004945598417408506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 54016/60000][Iteration 5112][Wall Clock 485.930379667s] Trained 128 records in 0.07939139 seconds. Throughput is 1612.2655 records/second. Loss is 0.21368235. Sequential31006cbd's hyper parameters: Current learning rate is 0.004945109286915241. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 54144/60000][Iteration 5113][Wall Clock 486.013108488s] Trained 128 records in 0.082728821 seconds. Throughput is 1547.2239 records/second. Loss is 0.1915799. Sequential31006cbd's hyper parameters: Current learning rate is 0.004944620253164556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 54272/60000][Iteration 5114][Wall Clock 486.111315092s] Trained 128 records in 0.098206604 seconds. Throughput is 1303.3748 records/second. Loss is 0.070888355. Sequential31006cbd's hyper parameters: Current learning rate is 0.004944131316127757. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 54400/60000][Iteration 5115][Wall Clock 486.19287303s] Trained 128 records in 0.081557938 seconds. Throughput is 1569.4364 records/second. Loss is 0.22769462. Sequential31006cbd's hyper parameters: Current learning rate is 0.004943642475776152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 54528/60000][Iteration 5116][Wall Clock 486.283444542s] Trained 128 records in 0.090571512 seconds. Throughput is 1413.2478 records/second. Loss is 0.17284676. Sequential31006cbd's hyper parameters: Current learning rate is 0.004943153732081067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:43 INFO  DistriOptimizer$:408 - [Epoch 11 54656/60000][Iteration 5117][Wall Clock 486.389093701s] Trained 128 records in 0.105649159 seconds. Throughput is 1211.5573 records/second. Loss is 0.18743859. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049426650850138395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 54784/60000][Iteration 5118][Wall Clock 486.466538032s] Trained 128 records in 0.077444331 seconds. Throughput is 1652.8002 records/second. Loss is 0.13487715. Sequential31006cbd's hyper parameters: Current learning rate is 0.004942176534545814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 54912/60000][Iteration 5119][Wall Clock 486.552065122s] Trained 128 records in 0.08552709 seconds. Throughput is 1496.6018 records/second. Loss is 0.1594593. Sequential31006cbd's hyper parameters: Current learning rate is 0.00494168808064835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55040/60000][Iteration 5120][Wall Clock 486.64334943s] Trained 128 records in 0.091284308 seconds. Throughput is 1402.2125 records/second. Loss is 0.17190036. Sequential31006cbd's hyper parameters: Current learning rate is 0.004941199723292816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55168/60000][Iteration 5121][Wall Clock 486.728681023s] Trained 128 records in 0.085331593 seconds. Throughput is 1500.0305 records/second. Loss is 0.19773155. Sequential31006cbd's hyper parameters: Current learning rate is 0.004940711462450593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55296/60000][Iteration 5122][Wall Clock 486.804989251s] Trained 128 records in 0.076308228 seconds. Throughput is 1677.4076 records/second. Loss is 0.22992891. Sequential31006cbd's hyper parameters: Current learning rate is 0.004940223298093074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55424/60000][Iteration 5123][Wall Clock 486.892409329s] Trained 128 records in 0.087420078 seconds. Throughput is 1464.1946 records/second. Loss is 0.14391452. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049397352301916615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55552/60000][Iteration 5124][Wall Clock 486.976630814s] Trained 128 records in 0.084221485 seconds. Throughput is 1519.8022 records/second. Loss is 0.13261351. Sequential31006cbd's hyper parameters: Current learning rate is 0.004939247258717772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55680/60000][Iteration 5125][Wall Clock 487.054275634s] Trained 128 records in 0.07764482 seconds. Throughput is 1648.5325 records/second. Loss is 0.19119611. Sequential31006cbd's hyper parameters: Current learning rate is 0.004938759383642829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55808/60000][Iteration 5126][Wall Clock 487.148910994s] Trained 128 records in 0.09463536 seconds. Throughput is 1352.5599 records/second. Loss is 0.1755196. Sequential31006cbd's hyper parameters: Current learning rate is 0.004938271604938271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 55936/60000][Iteration 5127][Wall Clock 487.248574468s] Trained 128 records in 0.099663474 seconds. Throughput is 1284.322 records/second. Loss is 0.21830994. Sequential31006cbd's hyper parameters: Current learning rate is 0.004937783922575548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 56064/60000][Iteration 5128][Wall Clock 487.32638071s] Trained 128 records in 0.077806242 seconds. Throughput is 1645.1122 records/second. Loss is 0.30955416. Sequential31006cbd's hyper parameters: Current learning rate is 0.004937296336526118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:44 INFO  DistriOptimizer$:408 - [Epoch 11 56192/60000][Iteration 5129][Wall Clock 487.400018308s] Trained 128 records in 0.073637598 seconds. Throughput is 1738.2424 records/second. Loss is 0.31198415. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049368088467614535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 56320/60000][Iteration 5130][Wall Clock 487.472304964s] Trained 128 records in 0.072286656 seconds. Throughput is 1770.7279 records/second. Loss is 0.16912006. Sequential31006cbd's hyper parameters: Current learning rate is 0.004936321453253035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 56448/60000][Iteration 5131][Wall Clock 487.556968601s] Trained 128 records in 0.084663637 seconds. Throughput is 1511.8651 records/second. Loss is 0.15124607. Sequential31006cbd's hyper parameters: Current learning rate is 0.00493583415597236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 56576/60000][Iteration 5132][Wall Clock 487.640970826s] Trained 128 records in 0.084002225 seconds. Throughput is 1523.7692 records/second. Loss is 0.1463431. Sequential31006cbd's hyper parameters: Current learning rate is 0.004935346954890929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 56704/60000][Iteration 5133][Wall Clock 487.719837098s] Trained 128 records in 0.078866272 seconds. Throughput is 1623.0005 records/second. Loss is 0.21997252. Sequential31006cbd's hyper parameters: Current learning rate is 0.004934859849980261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 56832/60000][Iteration 5134][Wall Clock 487.816381629s] Trained 128 records in 0.096544531 seconds. Throughput is 1325.813 records/second. Loss is 0.10073644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004934372841211882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 56960/60000][Iteration 5135][Wall Clock 487.920985685s] Trained 128 records in 0.104604056 seconds. Throughput is 1223.6619 records/second. Loss is 0.23625648. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049338859285573316. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 57088/60000][Iteration 5136][Wall Clock 488.009647182s] Trained 128 records in 0.088661497 seconds. Throughput is 1443.6931 records/second. Loss is 0.17802724. Sequential31006cbd's hyper parameters: Current learning rate is 0.00493339911198816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 57216/60000][Iteration 5137][Wall Clock 488.087928963s] Trained 128 records in 0.078281781 seconds. Throughput is 1635.1187 records/second. Loss is 0.20272662. Sequential31006cbd's hyper parameters: Current learning rate is 0.004932912391475927. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 57344/60000][Iteration 5138][Wall Clock 488.168024268s] Trained 128 records in 0.080095305 seconds. Throughput is 1598.0962 records/second. Loss is 0.13239214. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049324257669922066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 57472/60000][Iteration 5139][Wall Clock 488.252220802s] Trained 128 records in 0.084196534 seconds. Throughput is 1520.2527 records/second. Loss is 0.24510878. Sequential31006cbd's hyper parameters: Current learning rate is 0.004931939238508582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 57600/60000][Iteration 5140][Wall Clock 488.34301628s] Trained 128 records in 0.090795478 seconds. Throughput is 1409.7618 records/second. Loss is 0.14430149. Sequential31006cbd's hyper parameters: Current learning rate is 0.004931452805996646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:45 INFO  DistriOptimizer$:408 - [Epoch 11 57728/60000][Iteration 5141][Wall Clock 488.432982214s] Trained 128 records in 0.089965934 seconds. Throughput is 1422.7607 records/second. Loss is 0.1797811. Sequential31006cbd's hyper parameters: Current learning rate is 0.004930966469428008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 57856/60000][Iteration 5142][Wall Clock 488.509527211s] Trained 128 records in 0.076544997 seconds. Throughput is 1672.219 records/second. Loss is 0.14946556. Sequential31006cbd's hyper parameters: Current learning rate is 0.004930480228774283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 57984/60000][Iteration 5143][Wall Clock 488.597743732s] Trained 128 records in 0.088216521 seconds. Throughput is 1450.9753 records/second. Loss is 0.23202753. Sequential31006cbd's hyper parameters: Current learning rate is 0.004929994084007099. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58112/60000][Iteration 5144][Wall Clock 488.676899696s] Trained 128 records in 0.079155964 seconds. Throughput is 1617.0607 records/second. Loss is 0.15473348. Sequential31006cbd's hyper parameters: Current learning rate is 0.004929508035098097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58240/60000][Iteration 5145][Wall Clock 488.753154932s] Trained 128 records in 0.076255236 seconds. Throughput is 1678.5731 records/second. Loss is 0.1738939. Sequential31006cbd's hyper parameters: Current learning rate is 0.004929022082018926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58368/60000][Iteration 5146][Wall Clock 488.834677261s] Trained 128 records in 0.081522329 seconds. Throughput is 1570.122 records/second. Loss is 0.18255748. Sequential31006cbd's hyper parameters: Current learning rate is 0.004928536224741252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58496/60000][Iteration 5147][Wall Clock 488.9263003s] Trained 128 records in 0.091623039 seconds. Throughput is 1397.0286 records/second. Loss is 0.26150107. Sequential31006cbd's hyper parameters: Current learning rate is 0.004928050463236743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58624/60000][Iteration 5148][Wall Clock 489.010743707s] Trained 128 records in 0.084443407 seconds. Throughput is 1515.8081 records/second. Loss is 0.19611087. Sequential31006cbd's hyper parameters: Current learning rate is 0.004927564797477088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58752/60000][Iteration 5149][Wall Clock 489.092883511s] Trained 128 records in 0.082139804 seconds. Throughput is 1558.3187 records/second. Loss is 0.15653643. Sequential31006cbd's hyper parameters: Current learning rate is 0.004927079227433976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 58880/60000][Iteration 5150][Wall Clock 489.167963413s] Trained 128 records in 0.075079902 seconds. Throughput is 1704.8503 records/second. Loss is 0.18647021. Sequential31006cbd's hyper parameters: Current learning rate is 0.004926593753079122. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 59008/60000][Iteration 5151][Wall Clock 489.248200148s] Trained 128 records in 0.080236735 seconds. Throughput is 1595.2793 records/second. Loss is 0.20211545. Sequential31006cbd's hyper parameters: Current learning rate is 0.004926108374384236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:46 INFO  DistriOptimizer$:408 - [Epoch 11 59136/60000][Iteration 5152][Wall Clock 489.341435216s] Trained 128 records in 0.093235068 seconds. Throughput is 1372.874 records/second. Loss is 0.17694719. Sequential31006cbd's hyper parameters: Current learning rate is 0.004925623091321053. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 59264/60000][Iteration 5153][Wall Clock 489.477764152s] Trained 128 records in 0.136328936 seconds. Throughput is 938.9056 records/second. Loss is 0.21684359. Sequential31006cbd's hyper parameters: Current learning rate is 0.004925137903861307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 59392/60000][Iteration 5154][Wall Clock 489.572111305s] Trained 128 records in 0.094347153 seconds. Throughput is 1356.6917 records/second. Loss is 0.10159023. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049246528119767565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 59520/60000][Iteration 5155][Wall Clock 489.665867755s] Trained 128 records in 0.09375645 seconds. Throughput is 1365.2394 records/second. Loss is 0.17567015. Sequential31006cbd's hyper parameters: Current learning rate is 0.004924167815639157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 59648/60000][Iteration 5156][Wall Clock 489.759633305s] Trained 128 records in 0.09376555 seconds. Throughput is 1365.1069 records/second. Loss is 0.1861068. Sequential31006cbd's hyper parameters: Current learning rate is 0.004923682914820285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 59776/60000][Iteration 5157][Wall Clock 489.838253779s] Trained 128 records in 0.078620474 seconds. Throughput is 1628.0747 records/second. Loss is 0.14369014. Sequential31006cbd's hyper parameters: Current learning rate is 0.004923198109491926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 59904/60000][Iteration 5158][Wall Clock 489.952137496s] Trained 128 records in 0.113883717 seconds. Throughput is 1123.9535 records/second. Loss is 0.16224253. Sequential31006cbd's hyper parameters: Current learning rate is 0.004922713399625874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:408 - [Epoch 11 60032/60000][Iteration 5159][Wall Clock 490.038869564s] Trained 128 records in 0.086732068 seconds. Throughput is 1475.8094 records/second. Loss is 0.17200956. Sequential31006cbd's hyper parameters: Current learning rate is 0.004922228785193936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:47 INFO  DistriOptimizer$:452 - [Epoch 11 60032/60000][Iteration 5159][Wall Clock 490.038869564s] Epoch finished. Wall clock time is 491119.635201 ms
2019-10-24 00:05:47 INFO  DistriOptimizer$:111 - [Epoch 11 60032/60000][Iteration 5159][Wall Clock 490.038869564s] Validate model...
2019-10-24 00:05:48 INFO  DistriOptimizer$:178 - [Epoch 11 60032/60000][Iteration 5159][Wall Clock 490.038869564s] validate model throughput is 12065.576 records/second
2019-10-24 00:05:48 INFO  DistriOptimizer$:181 - [Epoch 11 60032/60000][Iteration 5159][Wall Clock 490.038869564s] Top1Accuracy is Accuracy(correct: 9478, count: 10000, accuracy: 0.9478)
2019-10-24 00:05:48 INFO  DistriOptimizer$:221 - [Wall Clock 491.119635201s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:05:48 INFO  DistriOptimizer$:226 - [Wall Clock 491.119635201s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:05:48 INFO  DistriOptimizer$:408 - [Epoch 12 128/60000][Iteration 5160][Wall Clock 491.238906763s] Trained 128 records in 0.119271562 seconds. Throughput is 1073.1813 records/second. Loss is 0.12369756. Sequential31006cbd's hyper parameters: Current learning rate is 0.00492174426616793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:48 INFO  DistriOptimizer$:408 - [Epoch 12 256/60000][Iteration 5161][Wall Clock 491.355728185s] Trained 128 records in 0.116821422 seconds. Throughput is 1095.6895 records/second. Loss is 0.17250516. Sequential31006cbd's hyper parameters: Current learning rate is 0.004921259842519685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:48 INFO  DistriOptimizer$:408 - [Epoch 12 384/60000][Iteration 5162][Wall Clock 491.439337338s] Trained 128 records in 0.083609153 seconds. Throughput is 1530.9329 records/second. Loss is 0.14760011. Sequential31006cbd's hyper parameters: Current learning rate is 0.004920775514221041. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:48 INFO  DistriOptimizer$:408 - [Epoch 12 512/60000][Iteration 5163][Wall Clock 491.521655557s] Trained 128 records in 0.082318219 seconds. Throughput is 1554.9414 records/second. Loss is 0.1355609. Sequential31006cbd's hyper parameters: Current learning rate is 0.00492029128124385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 640/60000][Iteration 5164][Wall Clock 491.607259084s] Trained 128 records in 0.085603527 seconds. Throughput is 1495.2655 records/second. Loss is 0.1580216. Sequential31006cbd's hyper parameters: Current learning rate is 0.004919807143559973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 768/60000][Iteration 5165][Wall Clock 491.688632637s] Trained 128 records in 0.081373553 seconds. Throughput is 1572.9927 records/second. Loss is 0.1075649. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049193231011412835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 896/60000][Iteration 5166][Wall Clock 491.775824085s] Trained 128 records in 0.087191448 seconds. Throughput is 1468.0339 records/second. Loss is 0.1637541. Sequential31006cbd's hyper parameters: Current learning rate is 0.004918839153959665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1024/60000][Iteration 5167][Wall Clock 491.863247674s] Trained 128 records in 0.087423589 seconds. Throughput is 1464.1357 records/second. Loss is 0.14869165. Sequential31006cbd's hyper parameters: Current learning rate is 0.004918355301987016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1152/60000][Iteration 5168][Wall Clock 491.952368776s] Trained 128 records in 0.089121102 seconds. Throughput is 1436.2479 records/second. Loss is 0.17508358. Sequential31006cbd's hyper parameters: Current learning rate is 0.004917871545195239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1280/60000][Iteration 5169][Wall Clock 492.032222148s] Trained 128 records in 0.079853372 seconds. Throughput is 1602.938 records/second. Loss is 0.15416618. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049173878835562556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1408/60000][Iteration 5170][Wall Clock 492.133520612s] Trained 128 records in 0.101298464 seconds. Throughput is 1263.5927 records/second. Loss is 0.15942907. Sequential31006cbd's hyper parameters: Current learning rate is 0.00491690431704199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1536/60000][Iteration 5171][Wall Clock 492.216101564s] Trained 128 records in 0.082580952 seconds. Throughput is 1549.9943 records/second. Loss is 0.122066855. Sequential31006cbd's hyper parameters: Current learning rate is 0.004916420845624386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1664/60000][Iteration 5172][Wall Clock 492.302233646s] Trained 128 records in 0.086132082 seconds. Throughput is 1486.0897 records/second. Loss is 0.21299437. Sequential31006cbd's hyper parameters: Current learning rate is 0.004915937469275391. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1792/60000][Iteration 5173][Wall Clock 492.384602695s] Trained 128 records in 0.082369049 seconds. Throughput is 1553.9817 records/second. Loss is 0.14441182. Sequential31006cbd's hyper parameters: Current learning rate is 0.004915454187966969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 1920/60000][Iteration 5174][Wall Clock 492.469991071s] Trained 128 records in 0.085388376 seconds. Throughput is 1499.0331 records/second. Loss is 0.17352787. Sequential31006cbd's hyper parameters: Current learning rate is 0.00491497100167109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:49 INFO  DistriOptimizer$:408 - [Epoch 12 2048/60000][Iteration 5175][Wall Clock 492.550944083s] Trained 128 records in 0.080953012 seconds. Throughput is 1581.1642 records/second. Loss is 0.21462084. Sequential31006cbd's hyper parameters: Current learning rate is 0.004914487910359741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2176/60000][Iteration 5176][Wall Clock 492.632057956s] Trained 128 records in 0.081113873 seconds. Throughput is 1578.0284 records/second. Loss is 0.11889527. Sequential31006cbd's hyper parameters: Current learning rate is 0.004914004914004914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2304/60000][Iteration 5177][Wall Clock 492.735931225s] Trained 128 records in 0.103873269 seconds. Throughput is 1232.2709 records/second. Loss is 0.18859622. Sequential31006cbd's hyper parameters: Current learning rate is 0.004913522012578616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2432/60000][Iteration 5178][Wall Clock 492.815876895s] Trained 128 records in 0.07994567 seconds. Throughput is 1601.0874 records/second. Loss is 0.2136496. Sequential31006cbd's hyper parameters: Current learning rate is 0.004913039206052864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2560/60000][Iteration 5179][Wall Clock 492.910272688s] Trained 128 records in 0.094395793 seconds. Throughput is 1355.9927 records/second. Loss is 0.10838189. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049125564943996855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2688/60000][Iteration 5180][Wall Clock 492.992498866s] Trained 128 records in 0.082226178 seconds. Throughput is 1556.6819 records/second. Loss is 0.12709484. Sequential31006cbd's hyper parameters: Current learning rate is 0.004912073877591119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2816/60000][Iteration 5181][Wall Clock 493.064688605s] Trained 128 records in 0.072189739 seconds. Throughput is 1773.1051 records/second. Loss is 0.15731536. Sequential31006cbd's hyper parameters: Current learning rate is 0.004911591355599214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 2944/60000][Iteration 5182][Wall Clock 493.140162488s] Trained 128 records in 0.075473883 seconds. Throughput is 1695.9509 records/second. Loss is 0.23988563. Sequential31006cbd's hyper parameters: Current learning rate is 0.004911108928396032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 3072/60000][Iteration 5183][Wall Clock 493.222565993s] Trained 128 records in 0.082403505 seconds. Throughput is 1553.332 records/second. Loss is 0.25632077. Sequential31006cbd's hyper parameters: Current learning rate is 0.004910626595953644. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 3200/60000][Iteration 5184][Wall Clock 493.297813997s] Trained 128 records in 0.075248004 seconds. Throughput is 1701.0419 records/second. Loss is 0.18288434. Sequential31006cbd's hyper parameters: Current learning rate is 0.004910144358244132. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 3328/60000][Iteration 5185][Wall Clock 493.379934806s] Trained 128 records in 0.082120809 seconds. Throughput is 1558.6793 records/second. Loss is 0.20742255. Sequential31006cbd's hyper parameters: Current learning rate is 0.004909662215239592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:50 INFO  DistriOptimizer$:408 - [Epoch 12 3456/60000][Iteration 5186][Wall Clock 493.479794591s] Trained 128 records in 0.099859785 seconds. Throughput is 1281.7974 records/second. Loss is 0.18206266. Sequential31006cbd's hyper parameters: Current learning rate is 0.004909180166912126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 3584/60000][Iteration 5187][Wall Clock 493.56221742s] Trained 128 records in 0.082422829 seconds. Throughput is 1552.9678 records/second. Loss is 0.19528612. Sequential31006cbd's hyper parameters: Current learning rate is 0.004908698213233849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 3712/60000][Iteration 5188][Wall Clock 493.650267445s] Trained 128 records in 0.088050025 seconds. Throughput is 1453.7191 records/second. Loss is 0.16298556. Sequential31006cbd's hyper parameters: Current learning rate is 0.004908216354176893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 3840/60000][Iteration 5189][Wall Clock 493.725301267s] Trained 128 records in 0.075033822 seconds. Throughput is 1705.8973 records/second. Loss is 0.27643466. Sequential31006cbd's hyper parameters: Current learning rate is 0.004907734589713388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 3968/60000][Iteration 5190][Wall Clock 493.797048174s] Trained 128 records in 0.071746907 seconds. Throughput is 1784.049 records/second. Loss is 0.14954601. Sequential31006cbd's hyper parameters: Current learning rate is 0.004907252919815488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4096/60000][Iteration 5191][Wall Clock 493.874909491s] Trained 128 records in 0.077861317 seconds. Throughput is 1643.9486 records/second. Loss is 0.19444497. Sequential31006cbd's hyper parameters: Current learning rate is 0.004906771344455348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4224/60000][Iteration 5192][Wall Clock 493.950695857s] Trained 128 records in 0.075786366 seconds. Throughput is 1688.9581 records/second. Loss is 0.19818549. Sequential31006cbd's hyper parameters: Current learning rate is 0.004906289863605143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4352/60000][Iteration 5193][Wall Clock 494.02807477s] Trained 128 records in 0.077378913 seconds. Throughput is 1654.1974 records/second. Loss is 0.2209022. Sequential31006cbd's hyper parameters: Current learning rate is 0.004905808477237048. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4480/60000][Iteration 5194][Wall Clock 494.102929694s] Trained 128 records in 0.074854924 seconds. Throughput is 1709.9744 records/second. Loss is 0.17181444. Sequential31006cbd's hyper parameters: Current learning rate is 0.004905327185323262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4608/60000][Iteration 5195][Wall Clock 494.178027604s] Trained 128 records in 0.07509791 seconds. Throughput is 1704.4415 records/second. Loss is 0.16572821. Sequential31006cbd's hyper parameters: Current learning rate is 0.004904845987835982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4736/60000][Iteration 5196][Wall Clock 494.261608418s] Trained 128 records in 0.083580814 seconds. Throughput is 1531.4519 records/second. Loss is 0.10399094. Sequential31006cbd's hyper parameters: Current learning rate is 0.004904364884747425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4864/60000][Iteration 5197][Wall Clock 494.355537421s] Trained 128 records in 0.093929003 seconds. Throughput is 1362.7314 records/second. Loss is 0.12935744. Sequential31006cbd's hyper parameters: Current learning rate is 0.004903883876029815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 4992/60000][Iteration 5198][Wall Clock 494.437038257s] Trained 128 records in 0.081500836 seconds. Throughput is 1570.536 records/second. Loss is 0.1823909. Sequential31006cbd's hyper parameters: Current learning rate is 0.004903402961655388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:51 INFO  DistriOptimizer$:408 - [Epoch 12 5120/60000][Iteration 5199][Wall Clock 494.52888957s] Trained 128 records in 0.091851313 seconds. Throughput is 1393.5565 records/second. Loss is 0.17009783. Sequential31006cbd's hyper parameters: Current learning rate is 0.004902922141596391. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 5248/60000][Iteration 5200][Wall Clock 494.608775464s] Trained 128 records in 0.079885894 seconds. Throughput is 1602.2854 records/second. Loss is 0.16907418. Sequential31006cbd's hyper parameters: Current learning rate is 0.0049024414158250805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 5376/60000][Iteration 5201][Wall Clock 494.687311807s] Trained 128 records in 0.078536343 seconds. Throughput is 1629.8186 records/second. Loss is 0.18335363. Sequential31006cbd's hyper parameters: Current learning rate is 0.004901960784313725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 5504/60000][Iteration 5202][Wall Clock 494.763020912s] Trained 128 records in 0.075709105 seconds. Throughput is 1690.6818 records/second. Loss is 0.36067078. Sequential31006cbd's hyper parameters: Current learning rate is 0.004901480247034604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 5632/60000][Iteration 5203][Wall Clock 494.844432525s] Trained 128 records in 0.081411613 seconds. Throughput is 1572.2572 records/second. Loss is 0.21926162. Sequential31006cbd's hyper parameters: Current learning rate is 0.004900999803960008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 5760/60000][Iteration 5204][Wall Clock 494.94371048s] Trained 128 records in 0.099277955 seconds. Throughput is 1289.3093 records/second. Loss is 0.1931546. Sequential31006cbd's hyper parameters: Current learning rate is 0.004900519455062237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 5888/60000][Iteration 5205][Wall Clock 495.030250601s] Trained 128 records in 0.086540121 seconds. Throughput is 1479.0828 records/second. Loss is 0.19634297. Sequential31006cbd's hyper parameters: Current learning rate is 0.004900039200313603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 6016/60000][Iteration 5206][Wall Clock 495.138469791s] Trained 128 records in 0.10821919 seconds. Throughput is 1182.7847 records/second. Loss is 0.23333517. Sequential31006cbd's hyper parameters: Current learning rate is 0.004899559039686427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 6144/60000][Iteration 5207][Wall Clock 495.241396778s] Trained 128 records in 0.102926987 seconds. Throughput is 1243.6 records/second. Loss is 0.2152587. Sequential31006cbd's hyper parameters: Current learning rate is 0.004899078973153047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 6272/60000][Iteration 5208][Wall Clock 495.341839701s] Trained 128 records in 0.100442923 seconds. Throughput is 1274.3556 records/second. Loss is 0.14439537. Sequential31006cbd's hyper parameters: Current learning rate is 0.004898599000685803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 6400/60000][Iteration 5209][Wall Clock 495.420321834s] Trained 128 records in 0.078482133 seconds. Throughput is 1630.9443 records/second. Loss is 0.17166756. Sequential31006cbd's hyper parameters: Current learning rate is 0.004898119122257054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:52 INFO  DistriOptimizer$:408 - [Epoch 12 6528/60000][Iteration 5210][Wall Clock 495.507662422s] Trained 128 records in 0.087340588 seconds. Throughput is 1465.5271 records/second. Loss is 0.21006. Sequential31006cbd's hyper parameters: Current learning rate is 0.004897639337839161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 6656/60000][Iteration 5211][Wall Clock 495.600407704s] Trained 128 records in 0.092745282 seconds. Throughput is 1380.1241 records/second. Loss is 0.23782897. Sequential31006cbd's hyper parameters: Current learning rate is 0.004897159647404506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 6784/60000][Iteration 5212][Wall Clock 495.681663736s] Trained 128 records in 0.081256032 seconds. Throughput is 1575.2677 records/second. Loss is 0.1127157. Sequential31006cbd's hyper parameters: Current learning rate is 0.004896680050925472. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 6912/60000][Iteration 5213][Wall Clock 495.759305238s] Trained 128 records in 0.077641502 seconds. Throughput is 1648.6028 records/second. Loss is 0.22636648. Sequential31006cbd's hyper parameters: Current learning rate is 0.004896200548374462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7040/60000][Iteration 5214][Wall Clock 495.845418377s] Trained 128 records in 0.086113139 seconds. Throughput is 1486.4166 records/second. Loss is 0.20069094. Sequential31006cbd's hyper parameters: Current learning rate is 0.004895721139723881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7168/60000][Iteration 5215][Wall Clock 495.925875984s] Trained 128 records in 0.080457607 seconds. Throughput is 1590.8999 records/second. Loss is 0.21790767. Sequential31006cbd's hyper parameters: Current learning rate is 0.004895241824946153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7296/60000][Iteration 5216][Wall Clock 496.015725976s] Trained 128 records in 0.089849992 seconds. Throughput is 1424.5967 records/second. Loss is 0.24269737. Sequential31006cbd's hyper parameters: Current learning rate is 0.004894762604013705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7424/60000][Iteration 5217][Wall Clock 496.093809257s] Trained 128 records in 0.078083281 seconds. Throughput is 1639.2753 records/second. Loss is 0.2293316. Sequential31006cbd's hyper parameters: Current learning rate is 0.004894283476898981. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7552/60000][Iteration 5218][Wall Clock 496.166712651s] Trained 128 records in 0.072903394 seconds. Throughput is 1755.7482 records/second. Loss is 0.18479255. Sequential31006cbd's hyper parameters: Current learning rate is 0.004893804443574435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7680/60000][Iteration 5219][Wall Clock 496.243221643s] Trained 128 records in 0.076508992 seconds. Throughput is 1673.006 records/second. Loss is 0.23975235. Sequential31006cbd's hyper parameters: Current learning rate is 0.004893325504012527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7808/60000][Iteration 5220][Wall Clock 496.326534311s] Trained 128 records in 0.083312668 seconds. Throughput is 1536.381 records/second. Loss is 0.15598786. Sequential31006cbd's hyper parameters: Current learning rate is 0.004892846658185733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 7936/60000][Iteration 5221][Wall Clock 496.399699009s] Trained 128 records in 0.073164698 seconds. Throughput is 1749.4775 records/second. Loss is 0.2720752. Sequential31006cbd's hyper parameters: Current learning rate is 0.004892367906066536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:53 INFO  DistriOptimizer$:408 - [Epoch 12 8064/60000][Iteration 5222][Wall Clock 496.473191747s] Trained 128 records in 0.073492738 seconds. Throughput is 1741.6687 records/second. Loss is 0.12797202. Sequential31006cbd's hyper parameters: Current learning rate is 0.004891889247627434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8192/60000][Iteration 5223][Wall Clock 496.55056559s] Trained 128 records in 0.077373843 seconds. Throughput is 1654.3059 records/second. Loss is 0.22965719. Sequential31006cbd's hyper parameters: Current learning rate is 0.004891410682840931. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8320/60000][Iteration 5224][Wall Clock 496.635898675s] Trained 128 records in 0.085333085 seconds. Throughput is 1500.0044 records/second. Loss is 0.14357018. Sequential31006cbd's hyper parameters: Current learning rate is 0.004890932211679546. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8448/60000][Iteration 5225][Wall Clock 496.712662836s] Trained 128 records in 0.076764161 seconds. Throughput is 1667.4448 records/second. Loss is 0.17550321. Sequential31006cbd's hyper parameters: Current learning rate is 0.004890453834115806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8576/60000][Iteration 5226][Wall Clock 496.799379362s] Trained 128 records in 0.086716526 seconds. Throughput is 1476.0739 records/second. Loss is 0.12998495. Sequential31006cbd's hyper parameters: Current learning rate is 0.004889975550122249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8704/60000][Iteration 5227][Wall Clock 496.869776748s] Trained 128 records in 0.070397386 seconds. Throughput is 1818.2494 records/second. Loss is 0.2949265. Sequential31006cbd's hyper parameters: Current learning rate is 0.004889497359671425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8832/60000][Iteration 5228][Wall Clock 496.960478054s] Trained 128 records in 0.090701306 seconds. Throughput is 1411.2256 records/second. Loss is 0.27310067. Sequential31006cbd's hyper parameters: Current learning rate is 0.004889019262735895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 8960/60000][Iteration 5229][Wall Clock 497.06978694s] Trained 128 records in 0.109308886 seconds. Throughput is 1170.9935 records/second. Loss is 0.16644901. Sequential31006cbd's hyper parameters: Current learning rate is 0.004888541259288228. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 9088/60000][Iteration 5230][Wall Clock 497.171705841s] Trained 128 records in 0.101918901 seconds. Throughput is 1255.9005 records/second. Loss is 0.18615101. Sequential31006cbd's hyper parameters: Current learning rate is 0.004888063349301007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 9216/60000][Iteration 5231][Wall Clock 497.259007976s] Trained 128 records in 0.087302135 seconds. Throughput is 1466.1726 records/second. Loss is 0.20571496. Sequential31006cbd's hyper parameters: Current learning rate is 0.004887585532746822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 9344/60000][Iteration 5232][Wall Clock 497.343407593s] Trained 128 records in 0.084399617 seconds. Throughput is 1516.5945 records/second. Loss is 0.120632865. Sequential31006cbd's hyper parameters: Current learning rate is 0.004887107809598281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 9472/60000][Iteration 5233][Wall Clock 497.423615656s] Trained 128 records in 0.080208063 seconds. Throughput is 1595.8495 records/second. Loss is 0.22423902. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048866301798279905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:54 INFO  DistriOptimizer$:408 - [Epoch 12 9600/60000][Iteration 5234][Wall Clock 497.496538183s] Trained 128 records in 0.072922527 seconds. Throughput is 1755.2875 records/second. Loss is 0.19455653. Sequential31006cbd's hyper parameters: Current learning rate is 0.004886152643408581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 9728/60000][Iteration 5235][Wall Clock 497.582021149s] Trained 128 records in 0.085482966 seconds. Throughput is 1497.3744 records/second. Loss is 0.17518263. Sequential31006cbd's hyper parameters: Current learning rate is 0.004885675200312683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 9856/60000][Iteration 5236][Wall Clock 497.665335634s] Trained 128 records in 0.083314485 seconds. Throughput is 1536.3475 records/second. Loss is 0.12542994. Sequential31006cbd's hyper parameters: Current learning rate is 0.004885197850512946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 9984/60000][Iteration 5237][Wall Clock 497.760689773s] Trained 128 records in 0.095354139 seconds. Throughput is 1342.3644 records/second. Loss is 0.21238896. Sequential31006cbd's hyper parameters: Current learning rate is 0.004884720593982024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10112/60000][Iteration 5238][Wall Clock 497.847565345s] Trained 128 records in 0.086875572 seconds. Throughput is 1473.3716 records/second. Loss is 0.21317236. Sequential31006cbd's hyper parameters: Current learning rate is 0.004884243430692586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10240/60000][Iteration 5239][Wall Clock 497.926461295s] Trained 128 records in 0.07889595 seconds. Throughput is 1622.39 records/second. Loss is 0.19604543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004883766360617308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10368/60000][Iteration 5240][Wall Clock 498.003005259s] Trained 128 records in 0.076543964 seconds. Throughput is 1672.2416 records/second. Loss is 0.17958663. Sequential31006cbd's hyper parameters: Current learning rate is 0.00488328938372888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10496/60000][Iteration 5241][Wall Clock 498.078956414s] Trained 128 records in 0.075951155 seconds. Throughput is 1685.2937 records/second. Loss is 0.1896587. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048828125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10624/60000][Iteration 5242][Wall Clock 498.158481928s] Trained 128 records in 0.079525514 seconds. Throughput is 1609.5463 records/second. Loss is 0.14611082. Sequential31006cbd's hyper parameters: Current learning rate is 0.004882335709403379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10752/60000][Iteration 5243][Wall Clock 498.255800825s] Trained 128 records in 0.097318897 seconds. Throughput is 1315.2635 records/second. Loss is 0.19813108. Sequential31006cbd's hyper parameters: Current learning rate is 0.004881859011911736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 10880/60000][Iteration 5244][Wall Clock 498.338295755s] Trained 128 records in 0.08249493 seconds. Throughput is 1551.6105 records/second. Loss is 0.22583877. Sequential31006cbd's hyper parameters: Current learning rate is 0.004881382407497804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 11008/60000][Iteration 5245][Wall Clock 498.4135219s] Trained 128 records in 0.075226145 seconds. Throughput is 1701.5361 records/second. Loss is 0.109660104. Sequential31006cbd's hyper parameters: Current learning rate is 0.004880905896134323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:55 INFO  DistriOptimizer$:408 - [Epoch 12 11136/60000][Iteration 5246][Wall Clock 498.48811457s] Trained 128 records in 0.07459267 seconds. Throughput is 1715.9862 records/second. Loss is 0.18696913. Sequential31006cbd's hyper parameters: Current learning rate is 0.004880429477794045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 11264/60000][Iteration 5247][Wall Clock 498.582301565s] Trained 128 records in 0.094186995 seconds. Throughput is 1358.9987 records/second. Loss is 0.244683. Sequential31006cbd's hyper parameters: Current learning rate is 0.004879953152449737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 11392/60000][Iteration 5248][Wall Clock 498.669615728s] Trained 128 records in 0.087314163 seconds. Throughput is 1465.9706 records/second. Loss is 0.11924086. Sequential31006cbd's hyper parameters: Current learning rate is 0.004879476920074168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 11520/60000][Iteration 5249][Wall Clock 498.758310189s] Trained 128 records in 0.088694461 seconds. Throughput is 1443.1566 records/second. Loss is 0.14404558. Sequential31006cbd's hyper parameters: Current learning rate is 0.004879000780640125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 11648/60000][Iteration 5250][Wall Clock 498.843865643s] Trained 128 records in 0.085555454 seconds. Throughput is 1496.1056 records/second. Loss is 0.19086917. Sequential31006cbd's hyper parameters: Current learning rate is 0.004878524734120401. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 11776/60000][Iteration 5251][Wall Clock 498.923497763s] Trained 128 records in 0.07963212 seconds. Throughput is 1607.3916 records/second. Loss is 0.19300663. Sequential31006cbd's hyper parameters: Current learning rate is 0.004878048780487806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 11904/60000][Iteration 5252][Wall Clock 499.004167834s] Trained 128 records in 0.080670071 seconds. Throughput is 1586.7098 records/second. Loss is 0.32000595. Sequential31006cbd's hyper parameters: Current learning rate is 0.00487757291971515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 12032/60000][Iteration 5253][Wall Clock 499.09661011s] Trained 128 records in 0.092442276 seconds. Throughput is 1384.648 records/second. Loss is 0.24913594. Sequential31006cbd's hyper parameters: Current learning rate is 0.004877097151775264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 12160/60000][Iteration 5254][Wall Clock 499.198491324s] Trained 128 records in 0.101881214 seconds. Throughput is 1256.3651 records/second. Loss is 0.1914704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004876621476640983. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 12288/60000][Iteration 5255][Wall Clock 499.288279145s] Trained 128 records in 0.089787821 seconds. Throughput is 1425.5831 records/second. Loss is 0.1316276. Sequential31006cbd's hyper parameters: Current learning rate is 0.004876145894285157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 12416/60000][Iteration 5256][Wall Clock 499.37600894s] Trained 128 records in 0.087729795 seconds. Throughput is 1459.0254 records/second. Loss is 0.12565725. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048756704046806435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:56 INFO  DistriOptimizer$:408 - [Epoch 12 12544/60000][Iteration 5257][Wall Clock 499.48692336s] Trained 128 records in 0.11091442 seconds. Throughput is 1154.043 records/second. Loss is 0.19128202. Sequential31006cbd's hyper parameters: Current learning rate is 0.004875195007800312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 12672/60000][Iteration 5258][Wall Clock 499.591444551s] Trained 128 records in 0.104521191 seconds. Throughput is 1224.6321 records/second. Loss is 0.1804432. Sequential31006cbd's hyper parameters: Current learning rate is 0.004874719703617042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 12800/60000][Iteration 5259][Wall Clock 499.683764002s] Trained 128 records in 0.092319451 seconds. Throughput is 1386.49 records/second. Loss is 0.17812781. Sequential31006cbd's hyper parameters: Current learning rate is 0.004874244492103724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 12928/60000][Iteration 5260][Wall Clock 499.78999629s] Trained 128 records in 0.106232288 seconds. Throughput is 1204.9067 records/second. Loss is 0.26544285. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048737693732332586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13056/60000][Iteration 5261][Wall Clock 499.879416802s] Trained 128 records in 0.089420512 seconds. Throughput is 1431.4388 records/second. Loss is 0.17142743. Sequential31006cbd's hyper parameters: Current learning rate is 0.004873294346978557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13184/60000][Iteration 5262][Wall Clock 499.989250366s] Trained 128 records in 0.109833564 seconds. Throughput is 1165.3997 records/second. Loss is 0.1426345. Sequential31006cbd's hyper parameters: Current learning rate is 0.004872819413312543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13312/60000][Iteration 5263][Wall Clock 500.067700004s] Trained 128 records in 0.078449638 seconds. Throughput is 1631.62 records/second. Loss is 0.2575612. Sequential31006cbd's hyper parameters: Current learning rate is 0.004872344572208147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13440/60000][Iteration 5264][Wall Clock 500.170578333s] Trained 128 records in 0.102878329 seconds. Throughput is 1244.1881 records/second. Loss is 0.30117288. Sequential31006cbd's hyper parameters: Current learning rate is 0.004871869823638313. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13568/60000][Iteration 5265][Wall Clock 500.249138358s] Trained 128 records in 0.078560025 seconds. Throughput is 1629.3274 records/second. Loss is 0.13970949. Sequential31006cbd's hyper parameters: Current learning rate is 0.004871395167575994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13696/60000][Iteration 5266][Wall Clock 500.330382211s] Trained 128 records in 0.081243853 seconds. Throughput is 1575.5039 records/second. Loss is 0.17376988. Sequential31006cbd's hyper parameters: Current learning rate is 0.004870920603994155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13824/60000][Iteration 5267][Wall Clock 500.41737457s] Trained 128 records in 0.086992359 seconds. Throughput is 1471.3936 records/second. Loss is 0.19401208. Sequential31006cbd's hyper parameters: Current learning rate is 0.00487044613286577. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:57 INFO  DistriOptimizer$:408 - [Epoch 12 13952/60000][Iteration 5268][Wall Clock 500.492327611s] Trained 128 records in 0.074953041 seconds. Throughput is 1707.7358 records/second. Loss is 0.1422137. Sequential31006cbd's hyper parameters: Current learning rate is 0.004869971754163826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14080/60000][Iteration 5269][Wall Clock 500.566276308s] Trained 128 records in 0.073948697 seconds. Throughput is 1730.9298 records/second. Loss is 0.22508661. Sequential31006cbd's hyper parameters: Current learning rate is 0.004869497467861316. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14208/60000][Iteration 5270][Wall Clock 500.640982173s] Trained 128 records in 0.074705865 seconds. Throughput is 1713.3864 records/second. Loss is 0.18027411. Sequential31006cbd's hyper parameters: Current learning rate is 0.00486902327393125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14336/60000][Iteration 5271][Wall Clock 500.721476418s] Trained 128 records in 0.080494245 seconds. Throughput is 1590.1758 records/second. Loss is 0.23716123. Sequential31006cbd's hyper parameters: Current learning rate is 0.00486854917234664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14464/60000][Iteration 5272][Wall Clock 500.797497317s] Trained 128 records in 0.076020899 seconds. Throughput is 1683.7476 records/second. Loss is 0.25050604. Sequential31006cbd's hyper parameters: Current learning rate is 0.004868075163080518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14592/60000][Iteration 5273][Wall Clock 500.876219604s] Trained 128 records in 0.078722287 seconds. Throughput is 1625.969 records/second. Loss is 0.19323407. Sequential31006cbd's hyper parameters: Current learning rate is 0.004867601246105919. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14720/60000][Iteration 5274][Wall Clock 500.94951202s] Trained 128 records in 0.073292416 seconds. Throughput is 1746.429 records/second. Loss is 0.15692738. Sequential31006cbd's hyper parameters: Current learning rate is 0.004867127421395893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14848/60000][Iteration 5275][Wall Clock 501.021372515s] Trained 128 records in 0.071860495 seconds. Throughput is 1781.2291 records/second. Loss is 0.15698394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004866653688923496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 14976/60000][Iteration 5276][Wall Clock 501.102707453s] Trained 128 records in 0.081334938 seconds. Throughput is 1573.7394 records/second. Loss is 0.19954571. Sequential31006cbd's hyper parameters: Current learning rate is 0.004866180048661801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 15104/60000][Iteration 5277][Wall Clock 501.19304071s] Trained 128 records in 0.090333257 seconds. Throughput is 1416.9753 records/second. Loss is 0.16439357. Sequential31006cbd's hyper parameters: Current learning rate is 0.004865706500583884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 15232/60000][Iteration 5278][Wall Clock 501.273802411s] Trained 128 records in 0.080761701 seconds. Throughput is 1584.9097 records/second. Loss is 0.15442157. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048652330446628395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 15360/60000][Iteration 5279][Wall Clock 501.35820132s] Trained 128 records in 0.084398909 seconds. Throughput is 1516.6073 records/second. Loss is 0.27519038. Sequential31006cbd's hyper parameters: Current learning rate is 0.004864759680871765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:58 INFO  DistriOptimizer$:408 - [Epoch 12 15488/60000][Iteration 5280][Wall Clock 501.44414537s] Trained 128 records in 0.08594405 seconds. Throughput is 1489.3411 records/second. Loss is 0.19963983. Sequential31006cbd's hyper parameters: Current learning rate is 0.004864286409183773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 15616/60000][Iteration 5281][Wall Clock 501.517138921s] Trained 128 records in 0.072993551 seconds. Throughput is 1753.5795 records/second. Loss is 0.3398663. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048638132295719845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 15744/60000][Iteration 5282][Wall Clock 501.596594747s] Trained 128 records in 0.079455826 seconds. Throughput is 1610.9581 records/second. Loss is 0.12863499. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048633401420095325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 15872/60000][Iteration 5283][Wall Clock 501.6777855s] Trained 128 records in 0.081190753 seconds. Throughput is 1576.5343 records/second. Loss is 0.14129308. Sequential31006cbd's hyper parameters: Current learning rate is 0.004862867146469559. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16000/60000][Iteration 5284][Wall Clock 501.756005404s] Trained 128 records in 0.078219904 seconds. Throughput is 1636.4121 records/second. Loss is 0.1060833. Sequential31006cbd's hyper parameters: Current learning rate is 0.004862394242925216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16128/60000][Iteration 5285][Wall Clock 501.838438475s] Trained 128 records in 0.082433071 seconds. Throughput is 1552.7748 records/second. Loss is 0.14452584. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048619214313496695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16256/60000][Iteration 5286][Wall Clock 501.918280809s] Trained 128 records in 0.079842334 seconds. Throughput is 1603.1595 records/second. Loss is 0.28607935. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048614487117160906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16384/60000][Iteration 5287][Wall Clock 501.997784067s] Trained 128 records in 0.079503258 seconds. Throughput is 1609.9968 records/second. Loss is 0.1091088. Sequential31006cbd's hyper parameters: Current learning rate is 0.004860976083997667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16512/60000][Iteration 5288][Wall Clock 502.107053315s] Trained 128 records in 0.109269248 seconds. Throughput is 1171.4183 records/second. Loss is 0.21521014. Sequential31006cbd's hyper parameters: Current learning rate is 0.00486050354816759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16640/60000][Iteration 5289][Wall Clock 502.189186823s] Trained 128 records in 0.082133508 seconds. Throughput is 1558.4382 records/second. Loss is 0.18136625. Sequential31006cbd's hyper parameters: Current learning rate is 0.004860031104199068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16768/60000][Iteration 5290][Wall Clock 502.266002385s] Trained 128 records in 0.076815562 seconds. Throughput is 1666.3291 records/second. Loss is 0.16505027. Sequential31006cbd's hyper parameters: Current learning rate is 0.004859558752065312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 16896/60000][Iteration 5291][Wall Clock 502.348035496s] Trained 128 records in 0.082033111 seconds. Throughput is 1560.3456 records/second. Loss is 0.13847336. Sequential31006cbd's hyper parameters: Current learning rate is 0.004859086491739554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:05:59 INFO  DistriOptimizer$:408 - [Epoch 12 17024/60000][Iteration 5292][Wall Clock 502.430683958s] Trained 128 records in 0.082648462 seconds. Throughput is 1548.7281 records/second. Loss is 0.15656517. Sequential31006cbd's hyper parameters: Current learning rate is 0.004858614323195024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17152/60000][Iteration 5293][Wall Clock 502.507978797s] Trained 128 records in 0.077294839 seconds. Throughput is 1655.9967 records/second. Loss is 0.17290542. Sequential31006cbd's hyper parameters: Current learning rate is 0.004858142246404976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17280/60000][Iteration 5294][Wall Clock 502.582015049s] Trained 128 records in 0.074036252 seconds. Throughput is 1728.8827 records/second. Loss is 0.13208476. Sequential31006cbd's hyper parameters: Current learning rate is 0.00485767026134266. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17408/60000][Iteration 5295][Wall Clock 502.658082575s] Trained 128 records in 0.076067526 seconds. Throughput is 1682.7153 records/second. Loss is 0.22696008. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048571983679813495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17536/60000][Iteration 5296][Wall Clock 502.739435903s] Trained 128 records in 0.081353328 seconds. Throughput is 1573.3837 records/second. Loss is 0.21361473. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048567265662943174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17664/60000][Iteration 5297][Wall Clock 502.817799433s] Trained 128 records in 0.07836353 seconds. Throughput is 1633.4128 records/second. Loss is 0.16767013. Sequential31006cbd's hyper parameters: Current learning rate is 0.004856254856254856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17792/60000][Iteration 5298][Wall Clock 502.898772016s] Trained 128 records in 0.080972583 seconds. Throughput is 1580.782 records/second. Loss is 0.24081224. Sequential31006cbd's hyper parameters: Current learning rate is 0.004855783237836263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 17920/60000][Iteration 5299][Wall Clock 502.979827239s] Trained 128 records in 0.081055223 seconds. Throughput is 1579.1703 records/second. Loss is 0.15995663. Sequential31006cbd's hyper parameters: Current learning rate is 0.004855311711011847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 18048/60000][Iteration 5300][Wall Clock 503.055106122s] Trained 128 records in 0.075278883 seconds. Throughput is 1700.344 records/second. Loss is 0.21339644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004854840275754928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 18176/60000][Iteration 5301][Wall Clock 503.138742779s] Trained 128 records in 0.083636657 seconds. Throughput is 1530.4294 records/second. Loss is 0.15354687. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048543689320388345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 18304/60000][Iteration 5302][Wall Clock 503.222177881s] Trained 128 records in 0.083435102 seconds. Throughput is 1534.1265 records/second. Loss is 0.24075016. Sequential31006cbd's hyper parameters: Current learning rate is 0.004853897679836909. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 18432/60000][Iteration 5303][Wall Clock 503.30467762s] Trained 128 records in 0.082499739 seconds. Throughput is 1551.52 records/second. Loss is 0.14703336. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048534265191225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 18560/60000][Iteration 5304][Wall Clock 503.388181795s] Trained 128 records in 0.083504175 seconds. Throughput is 1532.8574 records/second. Loss is 0.12898515. Sequential31006cbd's hyper parameters: Current learning rate is 0.00485295544986897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:00 INFO  DistriOptimizer$:408 - [Epoch 12 18688/60000][Iteration 5305][Wall Clock 503.488479245s] Trained 128 records in 0.10029745 seconds. Throughput is 1276.2039 records/second. Loss is 0.18447766. Sequential31006cbd's hyper parameters: Current learning rate is 0.00485248447204969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 18816/60000][Iteration 5306][Wall Clock 503.564213246s] Trained 128 records in 0.075734001 seconds. Throughput is 1690.1259 records/second. Loss is 0.20277567. Sequential31006cbd's hyper parameters: Current learning rate is 0.00485201358563804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 18944/60000][Iteration 5307][Wall Clock 503.642349072s] Trained 128 records in 0.078135826 seconds. Throughput is 1638.173 records/second. Loss is 0.26368394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004851542790607412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19072/60000][Iteration 5308][Wall Clock 503.725895665s] Trained 128 records in 0.083546593 seconds. Throughput is 1532.0792 records/second. Loss is 0.13917984. Sequential31006cbd's hyper parameters: Current learning rate is 0.004851072086931212. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19200/60000][Iteration 5309][Wall Clock 503.805279621s] Trained 128 records in 0.079383956 seconds. Throughput is 1612.4165 records/second. Loss is 0.22931975. Sequential31006cbd's hyper parameters: Current learning rate is 0.004850601474582847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19328/60000][Iteration 5310][Wall Clock 503.896947674s] Trained 128 records in 0.091668053 seconds. Throughput is 1396.3425 records/second. Loss is 0.13216424. Sequential31006cbd's hyper parameters: Current learning rate is 0.004850130953535746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19456/60000][Iteration 5311][Wall Clock 503.980250737s] Trained 128 records in 0.083303063 seconds. Throughput is 1536.5581 records/second. Loss is 0.19438311. Sequential31006cbd's hyper parameters: Current learning rate is 0.004849660523763336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19584/60000][Iteration 5312][Wall Clock 504.060054465s] Trained 128 records in 0.079803728 seconds. Throughput is 1603.935 records/second. Loss is 0.15113531. Sequential31006cbd's hyper parameters: Current learning rate is 0.004849190185239066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19712/60000][Iteration 5313][Wall Clock 504.149543501s] Trained 128 records in 0.089489036 seconds. Throughput is 1430.3428 records/second. Loss is 0.17656133. Sequential31006cbd's hyper parameters: Current learning rate is 0.004848719937936384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19840/60000][Iteration 5314][Wall Clock 504.229148458s] Trained 128 records in 0.079604957 seconds. Throughput is 1607.9402 records/second. Loss is 0.21360363. Sequential31006cbd's hyper parameters: Current learning rate is 0.00484824978182876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 19968/60000][Iteration 5315][Wall Clock 504.310843564s] Trained 128 records in 0.081695106 seconds. Throughput is 1566.8013 records/second. Loss is 0.1861768. Sequential31006cbd's hyper parameters: Current learning rate is 0.004847779716889664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 20096/60000][Iteration 5316][Wall Clock 504.393982573s] Trained 128 records in 0.083139009 seconds. Throughput is 1539.5901 records/second. Loss is 0.24248022. Sequential31006cbd's hyper parameters: Current learning rate is 0.004847309743092584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:01 INFO  DistriOptimizer$:408 - [Epoch 12 20224/60000][Iteration 5317][Wall Clock 504.478009765s] Trained 128 records in 0.084027192 seconds. Throughput is 1523.3164 records/second. Loss is 0.13575223. Sequential31006cbd's hyper parameters: Current learning rate is 0.004846839860411012. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 20352/60000][Iteration 5318][Wall Clock 504.567002488s] Trained 128 records in 0.088992723 seconds. Throughput is 1438.3198 records/second. Loss is 0.23513034. Sequential31006cbd's hyper parameters: Current learning rate is 0.004846370068818454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 20480/60000][Iteration 5319][Wall Clock 504.651584073s] Trained 128 records in 0.084581585 seconds. Throughput is 1513.3318 records/second. Loss is 0.16289733. Sequential31006cbd's hyper parameters: Current learning rate is 0.004845900368288428. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 20608/60000][Iteration 5320][Wall Clock 504.752920353s] Trained 128 records in 0.10133628 seconds. Throughput is 1263.1212 records/second. Loss is 0.078311026. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048454307587944565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 20736/60000][Iteration 5321][Wall Clock 504.833454309s] Trained 128 records in 0.080533956 seconds. Throughput is 1589.3916 records/second. Loss is 0.14028852. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048449612403100775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 20864/60000][Iteration 5322][Wall Clock 504.923721672s] Trained 128 records in 0.090267363 seconds. Throughput is 1418.0098 records/second. Loss is 0.16881707. Sequential31006cbd's hyper parameters: Current learning rate is 0.004844491812808836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 20992/60000][Iteration 5323][Wall Clock 505.014449238s] Trained 128 records in 0.090727566 seconds. Throughput is 1410.817 records/second. Loss is 0.24419352. Sequential31006cbd's hyper parameters: Current learning rate is 0.00484402247626429. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 21120/60000][Iteration 5324][Wall Clock 505.096841762s] Trained 128 records in 0.082392524 seconds. Throughput is 1553.5391 records/second. Loss is 0.15489744. Sequential31006cbd's hyper parameters: Current learning rate is 0.004843553230650005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 21248/60000][Iteration 5325][Wall Clock 505.198734114s] Trained 128 records in 0.101892352 seconds. Throughput is 1256.2278 records/second. Loss is 0.16824934. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048430840759395586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 21376/60000][Iteration 5326][Wall Clock 505.283230379s] Trained 128 records in 0.084496265 seconds. Throughput is 1514.8599 records/second. Loss is 0.14892904. Sequential31006cbd's hyper parameters: Current learning rate is 0.004842615012106538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 21504/60000][Iteration 5327][Wall Clock 505.38198467s] Trained 128 records in 0.098754291 seconds. Throughput is 1296.1461 records/second. Loss is 0.24992217. Sequential31006cbd's hyper parameters: Current learning rate is 0.00484214603912454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:02 INFO  DistriOptimizer$:408 - [Epoch 12 21632/60000][Iteration 5328][Wall Clock 505.47045467s] Trained 128 records in 0.08847 seconds. Throughput is 1446.8182 records/second. Loss is 0.18710393. Sequential31006cbd's hyper parameters: Current learning rate is 0.004841677156967173. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 21760/60000][Iteration 5329][Wall Clock 505.60864643s] Trained 128 records in 0.13819176 seconds. Throughput is 926.24915 records/second. Loss is 0.16542006. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048412083656080565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 21888/60000][Iteration 5330][Wall Clock 505.716502002s] Trained 128 records in 0.107855572 seconds. Throughput is 1186.7722 records/second. Loss is 0.20109932. Sequential31006cbd's hyper parameters: Current learning rate is 0.004840739665020815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22016/60000][Iteration 5331][Wall Clock 505.808164878s] Trained 128 records in 0.091662876 seconds. Throughput is 1396.4214 records/second. Loss is 0.27715474. Sequential31006cbd's hyper parameters: Current learning rate is 0.004840271055179091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22144/60000][Iteration 5332][Wall Clock 505.901818305s] Trained 128 records in 0.093653427 seconds. Throughput is 1366.7412 records/second. Loss is 0.20624396. Sequential31006cbd's hyper parameters: Current learning rate is 0.004839802536056528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22272/60000][Iteration 5333][Wall Clock 505.987767885s] Trained 128 records in 0.08594958 seconds. Throughput is 1489.2452 records/second. Loss is 0.17298077. Sequential31006cbd's hyper parameters: Current learning rate is 0.004839334107626791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22400/60000][Iteration 5334][Wall Clock 506.073443314s] Trained 128 records in 0.085675429 seconds. Throughput is 1494.0106 records/second. Loss is 0.19442338. Sequential31006cbd's hyper parameters: Current learning rate is 0.004838865769863544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22528/60000][Iteration 5335][Wall Clock 506.156957276s] Trained 128 records in 0.083513962 seconds. Throughput is 1532.6779 records/second. Loss is 0.1956548. Sequential31006cbd's hyper parameters: Current learning rate is 0.004838397522740469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22656/60000][Iteration 5336][Wall Clock 506.244277122s] Trained 128 records in 0.087319846 seconds. Throughput is 1465.8752 records/second. Loss is 0.18523571. Sequential31006cbd's hyper parameters: Current learning rate is 0.004837929366231253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22784/60000][Iteration 5337][Wall Clock 506.329122754s] Trained 128 records in 0.084845632 seconds. Throughput is 1508.6222 records/second. Loss is 0.13936956. Sequential31006cbd's hyper parameters: Current learning rate is 0.004837461300309597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:03 INFO  DistriOptimizer$:408 - [Epoch 12 22912/60000][Iteration 5338][Wall Clock 506.418099191s] Trained 128 records in 0.088976437 seconds. Throughput is 1438.5831 records/second. Loss is 0.22839862. Sequential31006cbd's hyper parameters: Current learning rate is 0.004836993324949211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23040/60000][Iteration 5339][Wall Clock 506.527654883s] Trained 128 records in 0.109555692 seconds. Throughput is 1168.3556 records/second. Loss is 0.16566503. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048365254401238145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23168/60000][Iteration 5340][Wall Clock 506.635627731s] Trained 128 records in 0.107972848 seconds. Throughput is 1185.4833 records/second. Loss is 0.25222802. Sequential31006cbd's hyper parameters: Current learning rate is 0.004836057645807138. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23296/60000][Iteration 5341][Wall Clock 506.724094423s] Trained 128 records in 0.088466692 seconds. Throughput is 1446.8723 records/second. Loss is 0.19689234. Sequential31006cbd's hyper parameters: Current learning rate is 0.004835589941972921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23424/60000][Iteration 5342][Wall Clock 506.817889195s] Trained 128 records in 0.093794772 seconds. Throughput is 1364.6816 records/second. Loss is 0.18446217. Sequential31006cbd's hyper parameters: Current learning rate is 0.004835122328594913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23552/60000][Iteration 5343][Wall Clock 506.90057627s] Trained 128 records in 0.082687075 seconds. Throughput is 1548.005 records/second. Loss is 0.18196005. Sequential31006cbd's hyper parameters: Current learning rate is 0.004834654805646877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23680/60000][Iteration 5344][Wall Clock 506.997295666s] Trained 128 records in 0.096719396 seconds. Throughput is 1323.416 records/second. Loss is 0.2523615. Sequential31006cbd's hyper parameters: Current learning rate is 0.004834187373102581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23808/60000][Iteration 5345][Wall Clock 507.081328428s] Trained 128 records in 0.084032762 seconds. Throughput is 1523.2155 records/second. Loss is 0.12755133. Sequential31006cbd's hyper parameters: Current learning rate is 0.004833720030935808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 23936/60000][Iteration 5346][Wall Clock 507.163230438s] Trained 128 records in 0.08190201 seconds. Throughput is 1562.8431 records/second. Loss is 0.15693924. Sequential31006cbd's hyper parameters: Current learning rate is 0.004833252779120348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 24064/60000][Iteration 5347][Wall Clock 507.246246059s] Trained 128 records in 0.083015621 seconds. Throughput is 1541.8785 records/second. Loss is 0.23795256. Sequential31006cbd's hyper parameters: Current learning rate is 0.004832785617630001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 24192/60000][Iteration 5348][Wall Clock 507.329145596s] Trained 128 records in 0.082899537 seconds. Throughput is 1544.0375 records/second. Loss is 0.20877051. Sequential31006cbd's hyper parameters: Current learning rate is 0.004832318546438581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:04 INFO  DistriOptimizer$:408 - [Epoch 12 24320/60000][Iteration 5349][Wall Clock 507.41411002s] Trained 128 records in 0.084964424 seconds. Throughput is 1506.513 records/second. Loss is 0.3655588. Sequential31006cbd's hyper parameters: Current learning rate is 0.004831851565519907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 24448/60000][Iteration 5350][Wall Clock 507.496770108s] Trained 128 records in 0.082660088 seconds. Throughput is 1548.5104 records/second. Loss is 0.18697026. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048313846748478115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 24576/60000][Iteration 5351][Wall Clock 507.57857124s] Trained 128 records in 0.081801132 seconds. Throughput is 1564.7705 records/second. Loss is 0.15875061. Sequential31006cbd's hyper parameters: Current learning rate is 0.004830917874396135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 24704/60000][Iteration 5352][Wall Clock 507.663074595s] Trained 128 records in 0.084503355 seconds. Throughput is 1514.7328 records/second. Loss is 0.17303658. Sequential31006cbd's hyper parameters: Current learning rate is 0.004830451164138731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 24832/60000][Iteration 5353][Wall Clock 507.762523625s] Trained 128 records in 0.09944903 seconds. Throughput is 1287.0914 records/second. Loss is 0.19730234. Sequential31006cbd's hyper parameters: Current learning rate is 0.004829984544049459. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 24960/60000][Iteration 5354][Wall Clock 507.86807313s] Trained 128 records in 0.105549505 seconds. Throughput is 1212.701 records/second. Loss is 0.18082409. Sequential31006cbd's hyper parameters: Current learning rate is 0.004829518014102193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25088/60000][Iteration 5355][Wall Clock 507.950233193s] Trained 128 records in 0.082160063 seconds. Throughput is 1557.9346 records/second. Loss is 0.16992071. Sequential31006cbd's hyper parameters: Current learning rate is 0.004829051574270813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25216/60000][Iteration 5356][Wall Clock 508.040397996s] Trained 128 records in 0.090164803 seconds. Throughput is 1419.6227 records/second. Loss is 0.24999966. Sequential31006cbd's hyper parameters: Current learning rate is 0.004828585224529214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25344/60000][Iteration 5357][Wall Clock 508.127610887s] Trained 128 records in 0.087212891 seconds. Throughput is 1467.673 records/second. Loss is 0.148166. Sequential31006cbd's hyper parameters: Current learning rate is 0.004828118964851294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25472/60000][Iteration 5358][Wall Clock 508.217204492s] Trained 128 records in 0.089593605 seconds. Throughput is 1428.6735 records/second. Loss is 0.21073805. Sequential31006cbd's hyper parameters: Current learning rate is 0.004827652795210968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25600/60000][Iteration 5359][Wall Clock 508.296544791s] Trained 128 records in 0.079340299 seconds. Throughput is 1613.3037 records/second. Loss is 0.20986943. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048271867155821584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25728/60000][Iteration 5360][Wall Clock 508.379049316s] Trained 128 records in 0.082504525 seconds. Throughput is 1551.43 records/second. Loss is 0.1462798. Sequential31006cbd's hyper parameters: Current learning rate is 0.004826720725938797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:05 INFO  DistriOptimizer$:408 - [Epoch 12 25856/60000][Iteration 5361][Wall Clock 508.464449533s] Trained 128 records in 0.085400217 seconds. Throughput is 1498.8252 records/second. Loss is 0.22471827. Sequential31006cbd's hyper parameters: Current learning rate is 0.004826254826254826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 25984/60000][Iteration 5362][Wall Clock 508.558382029s] Trained 128 records in 0.093932496 seconds. Throughput is 1362.6808 records/second. Loss is 0.20709497. Sequential31006cbd's hyper parameters: Current learning rate is 0.004825789016504199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26112/60000][Iteration 5363][Wall Clock 508.640490218s] Trained 128 records in 0.082108189 seconds. Throughput is 1558.9187 records/second. Loss is 0.19730201. Sequential31006cbd's hyper parameters: Current learning rate is 0.004825323296660877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26240/60000][Iteration 5364][Wall Clock 508.768809092s] Trained 128 records in 0.128318874 seconds. Throughput is 997.51495 records/second. Loss is 0.12254867. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048248576666988325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26368/60000][Iteration 5365][Wall Clock 508.867850604s] Trained 128 records in 0.099041512 seconds. Throughput is 1292.3873 records/second. Loss is 0.16863042. Sequential31006cbd's hyper parameters: Current learning rate is 0.00482439212659205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26496/60000][Iteration 5366][Wall Clock 508.967068939s] Trained 128 records in 0.099218335 seconds. Throughput is 1290.0842 records/second. Loss is 0.22030213. Sequential31006cbd's hyper parameters: Current learning rate is 0.00482392667631452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26624/60000][Iteration 5367][Wall Clock 509.060440761s] Trained 128 records in 0.093371822 seconds. Throughput is 1370.8633 records/second. Loss is 0.11220613. Sequential31006cbd's hyper parameters: Current learning rate is 0.004823461315840247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26752/60000][Iteration 5368][Wall Clock 509.14421679s] Trained 128 records in 0.083776029 seconds. Throughput is 1527.8834 records/second. Loss is 0.13465546. Sequential31006cbd's hyper parameters: Current learning rate is 0.004822996045143242. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 26880/60000][Iteration 5369][Wall Clock 509.227478172s] Trained 128 records in 0.083261382 seconds. Throughput is 1537.3273 records/second. Loss is 0.16105136. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048225308641975315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 27008/60000][Iteration 5370][Wall Clock 509.311607028s] Trained 128 records in 0.084128856 seconds. Throughput is 1521.4756 records/second. Loss is 0.19649017. Sequential31006cbd's hyper parameters: Current learning rate is 0.004822065772977143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:06 INFO  DistriOptimizer$:408 - [Epoch 12 27136/60000][Iteration 5371][Wall Clock 509.402037027s] Trained 128 records in 0.090429999 seconds. Throughput is 1415.4595 records/second. Loss is 0.21807319. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048216007714561235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 27264/60000][Iteration 5372][Wall Clock 509.482683065s] Trained 128 records in 0.080646038 seconds. Throughput is 1587.1827 records/second. Loss is 0.20710611. Sequential31006cbd's hyper parameters: Current learning rate is 0.004821135859608523. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 27392/60000][Iteration 5373][Wall Clock 509.572087481s] Trained 128 records in 0.089404416 seconds. Throughput is 1431.6965 records/second. Loss is 0.13862866. Sequential31006cbd's hyper parameters: Current learning rate is 0.004820671037408407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 27520/60000][Iteration 5374][Wall Clock 509.673611536s] Trained 128 records in 0.101524055 seconds. Throughput is 1260.7849 records/second. Loss is 0.22923395. Sequential31006cbd's hyper parameters: Current learning rate is 0.004820206304829846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 27648/60000][Iteration 5375][Wall Clock 509.784329976s] Trained 128 records in 0.11071844 seconds. Throughput is 1156.0857 records/second. Loss is 0.17159802. Sequential31006cbd's hyper parameters: Current learning rate is 0.004819741661846926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 27776/60000][Iteration 5376][Wall Clock 509.89933789s] Trained 128 records in 0.115007914 seconds. Throughput is 1112.9669 records/second. Loss is 0.3829135. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048192771084337345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 27904/60000][Iteration 5377][Wall Clock 510.007623668s] Trained 128 records in 0.108285778 seconds. Throughput is 1182.0574 records/second. Loss is 0.13092805. Sequential31006cbd's hyper parameters: Current learning rate is 0.004818812644564379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 28032/60000][Iteration 5378][Wall Clock 510.108552309s] Trained 128 records in 0.100928641 seconds. Throughput is 1268.2228 records/second. Loss is 0.14633027. Sequential31006cbd's hyper parameters: Current learning rate is 0.004818348270212971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 28160/60000][Iteration 5379][Wall Clock 510.209817818s] Trained 128 records in 0.101265509 seconds. Throughput is 1264.0039 records/second. Loss is 0.23704161. Sequential31006cbd's hyper parameters: Current learning rate is 0.004817883985353632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 28288/60000][Iteration 5380][Wall Clock 510.374352915s] Trained 128 records in 0.164535097 seconds. Throughput is 777.9495 records/second. Loss is 0.15530291. Sequential31006cbd's hyper parameters: Current learning rate is 0.004817419789960497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:07 INFO  DistriOptimizer$:408 - [Epoch 12 28416/60000][Iteration 5381][Wall Clock 510.45239877s] Trained 128 records in 0.078045855 seconds. Throughput is 1640.0615 records/second. Loss is 0.1942636. Sequential31006cbd's hyper parameters: Current learning rate is 0.004816955684007707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 28544/60000][Iteration 5382][Wall Clock 510.543940608s] Trained 128 records in 0.091541838 seconds. Throughput is 1398.2677 records/second. Loss is 0.12958148. Sequential31006cbd's hyper parameters: Current learning rate is 0.004816491667469416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 28672/60000][Iteration 5383][Wall Clock 510.639728472s] Trained 128 records in 0.095787864 seconds. Throughput is 1336.2863 records/second. Loss is 0.16147675. Sequential31006cbd's hyper parameters: Current learning rate is 0.004816027740319784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 28800/60000][Iteration 5384][Wall Clock 510.71857909s] Trained 128 records in 0.078850618 seconds. Throughput is 1623.3228 records/second. Loss is 0.16236037. Sequential31006cbd's hyper parameters: Current learning rate is 0.004815563902532987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 28928/60000][Iteration 5385][Wall Clock 510.793240101s] Trained 128 records in 0.074661011 seconds. Throughput is 1714.4156 records/second. Loss is 0.25120786. Sequential31006cbd's hyper parameters: Current learning rate is 0.0048151001540832055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29056/60000][Iteration 5386][Wall Clock 510.870110736s] Trained 128 records in 0.076870635 seconds. Throughput is 1665.1353 records/second. Loss is 0.18951757. Sequential31006cbd's hyper parameters: Current learning rate is 0.004814636494944632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29184/60000][Iteration 5387][Wall Clock 510.950053098s] Trained 128 records in 0.079942362 seconds. Throughput is 1601.1536 records/second. Loss is 0.18609288. Sequential31006cbd's hyper parameters: Current learning rate is 0.004814172925091468. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29312/60000][Iteration 5388][Wall Clock 511.02779738s] Trained 128 records in 0.077744282 seconds. Throughput is 1646.4233 records/second. Loss is 0.14532797. Sequential31006cbd's hyper parameters: Current learning rate is 0.00481370944449793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29440/60000][Iteration 5389][Wall Clock 511.109354901s] Trained 128 records in 0.081557521 seconds. Throughput is 1569.4445 records/second. Loss is 0.2643233. Sequential31006cbd's hyper parameters: Current learning rate is 0.004813246053138235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29568/60000][Iteration 5390][Wall Clock 511.203755441s] Trained 128 records in 0.09440054 seconds. Throughput is 1355.9244 records/second. Loss is 0.26263368. Sequential31006cbd's hyper parameters: Current learning rate is 0.004812782750986621. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29696/60000][Iteration 5391][Wall Clock 511.286057781s] Trained 128 records in 0.08230234 seconds. Throughput is 1555.2413 records/second. Loss is 0.2251538. Sequential31006cbd's hyper parameters: Current learning rate is 0.004812319538017324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29824/60000][Iteration 5392][Wall Clock 511.372466272s] Trained 128 records in 0.086408491 seconds. Throughput is 1481.3359 records/second. Loss is 0.2684759. Sequential31006cbd's hyper parameters: Current learning rate is 0.004811856414204601. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:08 INFO  DistriOptimizer$:408 - [Epoch 12 29952/60000][Iteration 5393][Wall Clock 511.453391724s] Trained 128 records in 0.080925452 seconds. Throughput is 1581.7026 records/second. Loss is 0.12851438. Sequential31006cbd's hyper parameters: Current learning rate is 0.004811393379522709. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30080/60000][Iteration 5394][Wall Clock 511.528758472s] Trained 128 records in 0.075366748 seconds. Throughput is 1698.3617 records/second. Loss is 0.20293397. Sequential31006cbd's hyper parameters: Current learning rate is 0.004810930433945926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30208/60000][Iteration 5395][Wall Clock 511.603521524s] Trained 128 records in 0.074763052 seconds. Throughput is 1712.0757 records/second. Loss is 0.19641446. Sequential31006cbd's hyper parameters: Current learning rate is 0.004810467577448528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30336/60000][Iteration 5396][Wall Clock 511.679357755s] Trained 128 records in 0.075836231 seconds. Throughput is 1687.8475 records/second. Loss is 0.16299896. Sequential31006cbd's hyper parameters: Current learning rate is 0.00481000481000481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30464/60000][Iteration 5397][Wall Clock 511.75808297s] Trained 128 records in 0.078725215 seconds. Throughput is 1625.9086 records/second. Loss is 0.16735634. Sequential31006cbd's hyper parameters: Current learning rate is 0.004809542131589072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30592/60000][Iteration 5398][Wall Clock 511.833097297s] Trained 128 records in 0.075014327 seconds. Throughput is 1706.3406 records/second. Loss is 0.09521082. Sequential31006cbd's hyper parameters: Current learning rate is 0.004809079542175627. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30720/60000][Iteration 5399][Wall Clock 511.913442372s] Trained 128 records in 0.080345075 seconds. Throughput is 1593.1282 records/second. Loss is 0.2309297. Sequential31006cbd's hyper parameters: Current learning rate is 0.004808617041738796. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30848/60000][Iteration 5400][Wall Clock 512.008570831s] Trained 128 records in 0.095128459 seconds. Throughput is 1345.549 records/second. Loss is 0.19312252. Sequential31006cbd's hyper parameters: Current learning rate is 0.004808154630252909. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 30976/60000][Iteration 5401][Wall Clock 512.092643234s] Trained 128 records in 0.084072403 seconds. Throughput is 1522.4972 records/second. Loss is 0.103317946. Sequential31006cbd's hyper parameters: Current learning rate is 0.004807692307692308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 31104/60000][Iteration 5402][Wall Clock 512.175776825s] Trained 128 records in 0.083133591 seconds. Throughput is 1539.6904 records/second. Loss is 0.27064282. Sequential31006cbd's hyper parameters: Current learning rate is 0.004807230074031343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 31232/60000][Iteration 5403][Wall Clock 512.25773437s] Trained 128 records in 0.081957545 seconds. Throughput is 1561.7843 records/second. Loss is 0.16900818. Sequential31006cbd's hyper parameters: Current learning rate is 0.004806767929244376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 31360/60000][Iteration 5404][Wall Clock 512.355544666s] Trained 128 records in 0.097810296 seconds. Throughput is 1308.6556 records/second. Loss is 0.23886934. Sequential31006cbd's hyper parameters: Current learning rate is 0.004806305873305777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:09 INFO  DistriOptimizer$:408 - [Epoch 12 31488/60000][Iteration 5405][Wall Clock 512.449567512s] Trained 128 records in 0.094022846 seconds. Throughput is 1361.3712 records/second. Loss is 0.15738736. Sequential31006cbd's hyper parameters: Current learning rate is 0.004805843906189927. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 31616/60000][Iteration 5406][Wall Clock 512.52931577s] Trained 128 records in 0.079748258 seconds. Throughput is 1605.0508 records/second. Loss is 0.20623286. Sequential31006cbd's hyper parameters: Current learning rate is 0.004805382027871216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 31744/60000][Iteration 5407][Wall Clock 512.600980166s] Trained 128 records in 0.071664396 seconds. Throughput is 1786.1031 records/second. Loss is 0.16992253. Sequential31006cbd's hyper parameters: Current learning rate is 0.004804920238324044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 31872/60000][Iteration 5408][Wall Clock 512.681835135s] Trained 128 records in 0.080854969 seconds. Throughput is 1583.0814 records/second. Loss is 0.2726818. Sequential31006cbd's hyper parameters: Current learning rate is 0.004804458537522821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32000/60000][Iteration 5409][Wall Clock 512.763151105s] Trained 128 records in 0.08131597 seconds. Throughput is 1574.1064 records/second. Loss is 0.21450019. Sequential31006cbd's hyper parameters: Current learning rate is 0.004803996925441968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32128/60000][Iteration 5410][Wall Clock 512.839389211s] Trained 128 records in 0.076238106 seconds. Throughput is 1678.9504 records/second. Loss is 0.2429916. Sequential31006cbd's hyper parameters: Current learning rate is 0.004803535402055912. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32256/60000][Iteration 5411][Wall Clock 512.927386204s] Trained 128 records in 0.087996993 seconds. Throughput is 1454.5952 records/second. Loss is 0.22244889. Sequential31006cbd's hyper parameters: Current learning rate is 0.004803073967339097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32384/60000][Iteration 5412][Wall Clock 513.005121755s] Trained 128 records in 0.077735551 seconds. Throughput is 1646.6083 records/second. Loss is 0.2085751. Sequential31006cbd's hyper parameters: Current learning rate is 0.004802612621265968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32512/60000][Iteration 5413][Wall Clock 513.098297164s] Trained 128 records in 0.093175409 seconds. Throughput is 1373.753 records/second. Loss is 0.22823241. Sequential31006cbd's hyper parameters: Current learning rate is 0.004802151363810988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32640/60000][Iteration 5414][Wall Clock 513.180010414s] Trained 128 records in 0.08171325 seconds. Throughput is 1566.4534 records/second. Loss is 0.16274925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004801690194948621. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32768/60000][Iteration 5415][Wall Clock 513.262042799s] Trained 128 records in 0.082032385 seconds. Throughput is 1560.3594 records/second. Loss is 0.10007309. Sequential31006cbd's hyper parameters: Current learning rate is 0.004801229114653352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:10 INFO  DistriOptimizer$:408 - [Epoch 12 32896/60000][Iteration 5416][Wall Clock 513.353833908s] Trained 128 records in 0.091791109 seconds. Throughput is 1394.4706 records/second. Loss is 0.15480614. Sequential31006cbd's hyper parameters: Current learning rate is 0.004800768122899664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33024/60000][Iteration 5417][Wall Clock 513.465532449s] Trained 128 records in 0.111698541 seconds. Throughput is 1145.9415 records/second. Loss is 0.13717908. Sequential31006cbd's hyper parameters: Current learning rate is 0.004800307219662058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33152/60000][Iteration 5418][Wall Clock 513.549191989s] Trained 128 records in 0.08365954 seconds. Throughput is 1530.0109 records/second. Loss is 0.20143193. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047998464049150424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33280/60000][Iteration 5419][Wall Clock 513.625034315s] Trained 128 records in 0.075842326 seconds. Throughput is 1687.7119 records/second. Loss is 0.25718635. Sequential31006cbd's hyper parameters: Current learning rate is 0.004799385678633135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33408/60000][Iteration 5420][Wall Clock 513.708254627s] Trained 128 records in 0.083220312 seconds. Throughput is 1538.086 records/second. Loss is 0.14731702. Sequential31006cbd's hyper parameters: Current learning rate is 0.004798925040790863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33536/60000][Iteration 5421][Wall Clock 513.788756382s] Trained 128 records in 0.080501755 seconds. Throughput is 1590.0273 records/second. Loss is 0.13751662. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047984644913627635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33664/60000][Iteration 5422][Wall Clock 513.866590774s] Trained 128 records in 0.077834392 seconds. Throughput is 1644.5173 records/second. Loss is 0.15253925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004798004030323385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33792/60000][Iteration 5423][Wall Clock 513.949657725s] Trained 128 records in 0.083066951 seconds. Throughput is 1540.9258 records/second. Loss is 0.13667122. Sequential31006cbd's hyper parameters: Current learning rate is 0.004797543657647284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 33920/60000][Iteration 5424][Wall Clock 514.04919481s] Trained 128 records in 0.099537085 seconds. Throughput is 1285.9529 records/second. Loss is 0.20750132. Sequential31006cbd's hyper parameters: Current learning rate is 0.004797083373309028. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 34048/60000][Iteration 5425][Wall Clock 514.137951231s] Trained 128 records in 0.088756421 seconds. Throughput is 1442.1492 records/second. Loss is 0.1332424. Sequential31006cbd's hyper parameters: Current learning rate is 0.004796623177283193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 34176/60000][Iteration 5426][Wall Clock 514.231084954s] Trained 128 records in 0.093133723 seconds. Throughput is 1374.3679 records/second. Loss is 0.32821536. Sequential31006cbd's hyper parameters: Current learning rate is 0.004796163069544365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 34304/60000][Iteration 5427][Wall Clock 514.324412022s] Trained 128 records in 0.093327068 seconds. Throughput is 1371.5206 records/second. Loss is 0.12204343. Sequential31006cbd's hyper parameters: Current learning rate is 0.00479570305006714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:11 INFO  DistriOptimizer$:408 - [Epoch 12 34432/60000][Iteration 5428][Wall Clock 514.405933835s] Trained 128 records in 0.081521813 seconds. Throughput is 1570.1318 records/second. Loss is 0.12854278. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047952431188261245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 34560/60000][Iteration 5429][Wall Clock 514.488022879s] Trained 128 records in 0.082089044 seconds. Throughput is 1559.2823 records/second. Loss is 0.20802568. Sequential31006cbd's hyper parameters: Current learning rate is 0.004794783275795933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 34688/60000][Iteration 5430][Wall Clock 514.584378521s] Trained 128 records in 0.096355642 seconds. Throughput is 1328.4121 records/second. Loss is 0.29237443. Sequential31006cbd's hyper parameters: Current learning rate is 0.004794323520951194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 34816/60000][Iteration 5431][Wall Clock 514.694435928s] Trained 128 records in 0.110057407 seconds. Throughput is 1163.0294 records/second. Loss is 0.17280546. Sequential31006cbd's hyper parameters: Current learning rate is 0.004793863854266538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 34944/60000][Iteration 5432][Wall Clock 514.794884217s] Trained 128 records in 0.100448289 seconds. Throughput is 1274.2875 records/second. Loss is 0.18560374. Sequential31006cbd's hyper parameters: Current learning rate is 0.004793404275716615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35072/60000][Iteration 5433][Wall Clock 514.879016139s] Trained 128 records in 0.084131922 seconds. Throughput is 1521.4202 records/second. Loss is 0.25923005. Sequential31006cbd's hyper parameters: Current learning rate is 0.004792944785276073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35200/60000][Iteration 5434][Wall Clock 514.977991487s] Trained 128 records in 0.098975348 seconds. Throughput is 1293.2513 records/second. Loss is 0.0976515. Sequential31006cbd's hyper parameters: Current learning rate is 0.004792485382919582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35328/60000][Iteration 5435][Wall Clock 515.058957919s] Trained 128 records in 0.080966432 seconds. Throughput is 1580.902 records/second. Loss is 0.13725312. Sequential31006cbd's hyper parameters: Current learning rate is 0.004792026068621813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35456/60000][Iteration 5436][Wall Clock 515.140607377s] Trained 128 records in 0.081649458 seconds. Throughput is 1567.6772 records/second. Loss is 0.14483409. Sequential31006cbd's hyper parameters: Current learning rate is 0.004791566842357452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35584/60000][Iteration 5437][Wall Clock 515.226980621s] Trained 128 records in 0.086373244 seconds. Throughput is 1481.9403 records/second. Loss is 0.13235308. Sequential31006cbd's hyper parameters: Current learning rate is 0.004791107704101188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35712/60000][Iteration 5438][Wall Clock 515.30824693s] Trained 128 records in 0.081266309 seconds. Throughput is 1575.0685 records/second. Loss is 0.1561299. Sequential31006cbd's hyper parameters: Current learning rate is 0.004790648653827728. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:12 INFO  DistriOptimizer$:408 - [Epoch 12 35840/60000][Iteration 5439][Wall Clock 515.422672614s] Trained 128 records in 0.114425684 seconds. Throughput is 1118.63 records/second. Loss is 0.25332117. Sequential31006cbd's hyper parameters: Current learning rate is 0.004790189691511784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 35968/60000][Iteration 5440][Wall Clock 515.519990492s] Trained 128 records in 0.097317878 seconds. Throughput is 1315.2773 records/second. Loss is 0.1911586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004789730817128077. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36096/60000][Iteration 5441][Wall Clock 515.623287391s] Trained 128 records in 0.103296899 seconds. Throughput is 1239.1466 records/second. Loss is 0.17236634. Sequential31006cbd's hyper parameters: Current learning rate is 0.004789272030651341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36224/60000][Iteration 5442][Wall Clock 515.698768162s] Trained 128 records in 0.075480771 seconds. Throughput is 1695.796 records/second. Loss is 0.196222. Sequential31006cbd's hyper parameters: Current learning rate is 0.004788813332056317. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36352/60000][Iteration 5443][Wall Clock 515.803591661s] Trained 128 records in 0.104823499 seconds. Throughput is 1221.1002 records/second. Loss is 0.22326851. Sequential31006cbd's hyper parameters: Current learning rate is 0.004788354721317755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36480/60000][Iteration 5444][Wall Clock 515.892396532s] Trained 128 records in 0.088804871 seconds. Throughput is 1441.3624 records/second. Loss is 0.17878452. Sequential31006cbd's hyper parameters: Current learning rate is 0.004787896198410418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36608/60000][Iteration 5445][Wall Clock 515.970866867s] Trained 128 records in 0.078470335 seconds. Throughput is 1631.1897 records/second. Loss is 0.18035643. Sequential31006cbd's hyper parameters: Current learning rate is 0.004787437763309077. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36736/60000][Iteration 5446][Wall Clock 516.054902788s] Trained 128 records in 0.084035921 seconds. Throughput is 1523.1582 records/second. Loss is 0.20932117. Sequential31006cbd's hyper parameters: Current learning rate is 0.004786979415988511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36864/60000][Iteration 5447][Wall Clock 516.142768026s] Trained 128 records in 0.087865238 seconds. Throughput is 1456.7762 records/second. Loss is 0.16644487. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047865211564235115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 36992/60000][Iteration 5448][Wall Clock 516.230851691s] Trained 128 records in 0.088083665 seconds. Throughput is 1453.164 records/second. Loss is 0.13392721. Sequential31006cbd's hyper parameters: Current learning rate is 0.004786062984588876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 37120/60000][Iteration 5449][Wall Clock 516.321141089s] Trained 128 records in 0.090289398 seconds. Throughput is 1417.6637 records/second. Loss is 0.19467625. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047856049004594186. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:13 INFO  DistriOptimizer$:408 - [Epoch 12 37248/60000][Iteration 5450][Wall Clock 516.402826767s] Trained 128 records in 0.081685678 seconds. Throughput is 1566.9822 records/second. Loss is 0.18000181. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047851469040099525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 37376/60000][Iteration 5451][Wall Clock 516.498169723s] Trained 128 records in 0.095342956 seconds. Throughput is 1342.5219 records/second. Loss is 0.20785692. Sequential31006cbd's hyper parameters: Current learning rate is 0.004784688995215312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 37504/60000][Iteration 5452][Wall Clock 516.595448106s] Trained 128 records in 0.097278383 seconds. Throughput is 1315.8113 records/second. Loss is 0.18146765. Sequential31006cbd's hyper parameters: Current learning rate is 0.00478423117405033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 37632/60000][Iteration 5453][Wall Clock 516.689471877s] Trained 128 records in 0.094023771 seconds. Throughput is 1361.3579 records/second. Loss is 0.19991869. Sequential31006cbd's hyper parameters: Current learning rate is 0.004783773440489859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 37760/60000][Iteration 5454][Wall Clock 516.77048229s] Trained 128 records in 0.081010413 seconds. Throughput is 1580.0437 records/second. Loss is 0.13364401. Sequential31006cbd's hyper parameters: Current learning rate is 0.004783315794508753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 37888/60000][Iteration 5455][Wall Clock 516.873275878s] Trained 128 records in 0.102793588 seconds. Throughput is 1245.2139 records/second. Loss is 0.17797126. Sequential31006cbd's hyper parameters: Current learning rate is 0.004782858236081883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38016/60000][Iteration 5456][Wall Clock 516.948332204s] Trained 128 records in 0.075056326 seconds. Throughput is 1705.3859 records/second. Loss is 0.16228113. Sequential31006cbd's hyper parameters: Current learning rate is 0.004782400765184122. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38144/60000][Iteration 5457][Wall Clock 517.018302973s] Trained 128 records in 0.069970769 seconds. Throughput is 1829.3352 records/second. Loss is 0.18208203. Sequential31006cbd's hyper parameters: Current learning rate is 0.00478194338179036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38272/60000][Iteration 5458][Wall Clock 517.101522063s] Trained 128 records in 0.08321909 seconds. Throughput is 1538.1086 records/second. Loss is 0.1059156. Sequential31006cbd's hyper parameters: Current learning rate is 0.00478148608587549. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38400/60000][Iteration 5459][Wall Clock 517.179542868s] Trained 128 records in 0.078020805 seconds. Throughput is 1640.5881 records/second. Loss is 0.131439. Sequential31006cbd's hyper parameters: Current learning rate is 0.004781028877414419. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38528/60000][Iteration 5460][Wall Clock 517.260781474s] Trained 128 records in 0.081238606 seconds. Throughput is 1575.6056 records/second. Loss is 0.19617926. Sequential31006cbd's hyper parameters: Current learning rate is 0.004780571756382063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38656/60000][Iteration 5461][Wall Clock 517.334367584s] Trained 128 records in 0.07358611 seconds. Throughput is 1739.4587 records/second. Loss is 0.262659. Sequential31006cbd's hyper parameters: Current learning rate is 0.004780114722753346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:14 INFO  DistriOptimizer$:408 - [Epoch 12 38784/60000][Iteration 5462][Wall Clock 517.407940502s] Trained 128 records in 0.073572918 seconds. Throughput is 1739.7706 records/second. Loss is 0.18756759. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047796577765032025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 38912/60000][Iteration 5463][Wall Clock 517.481168161s] Trained 128 records in 0.073227659 seconds. Throughput is 1747.9734 records/second. Loss is 0.19325598. Sequential31006cbd's hyper parameters: Current learning rate is 0.004779200917606577. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39040/60000][Iteration 5464][Wall Clock 517.558480038s] Trained 128 records in 0.077311877 seconds. Throughput is 1655.6318 records/second. Loss is 0.11694735. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047787441460384215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39168/60000][Iteration 5465][Wall Clock 517.637119214s] Trained 128 records in 0.078639176 seconds. Throughput is 1627.6874 records/second. Loss is 0.18220477. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047782874617737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39296/60000][Iteration 5466][Wall Clock 517.707426378s] Trained 128 records in 0.070307164 seconds. Throughput is 1820.5825 records/second. Loss is 0.14649025. Sequential31006cbd's hyper parameters: Current learning rate is 0.004777830864787387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39424/60000][Iteration 5467][Wall Clock 517.804156726s] Trained 128 records in 0.096730348 seconds. Throughput is 1323.2661 records/second. Loss is 0.14424106. Sequential31006cbd's hyper parameters: Current learning rate is 0.004777374355054462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39552/60000][Iteration 5468][Wall Clock 517.87727825s] Trained 128 records in 0.073121524 seconds. Throughput is 1750.5105 records/second. Loss is 0.27013484. Sequential31006cbd's hyper parameters: Current learning rate is 0.004776917932549919. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39680/60000][Iteration 5469][Wall Clock 517.956036424s] Trained 128 records in 0.078758174 seconds. Throughput is 1625.2281 records/second. Loss is 0.13986433. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047764615972487575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39808/60000][Iteration 5470][Wall Clock 518.029171063s] Trained 128 records in 0.073134639 seconds. Throughput is 1750.1967 records/second. Loss is 0.1554478. Sequential31006cbd's hyper parameters: Current learning rate is 0.004776005349125991. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 39936/60000][Iteration 5471][Wall Clock 518.107732561s] Trained 128 records in 0.078561498 seconds. Throughput is 1629.2968 records/second. Loss is 0.21346958. Sequential31006cbd's hyper parameters: Current learning rate is 0.004775549188156637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 40064/60000][Iteration 5472][Wall Clock 518.18837987s] Trained 128 records in 0.080647309 seconds. Throughput is 1587.1577 records/second. Loss is 0.1263262. Sequential31006cbd's hyper parameters: Current learning rate is 0.00477509311431573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 40192/60000][Iteration 5473][Wall Clock 518.26940978s] Trained 128 records in 0.08102991 seconds. Throughput is 1579.6637 records/second. Loss is 0.18788138. Sequential31006cbd's hyper parameters: Current learning rate is 0.004774637127578304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 40320/60000][Iteration 5474][Wall Clock 518.353889796s] Trained 128 records in 0.084480016 seconds. Throughput is 1515.1512 records/second. Loss is 0.14526272. Sequential31006cbd's hyper parameters: Current learning rate is 0.004774181227919412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:15 INFO  DistriOptimizer$:408 - [Epoch 12 40448/60000][Iteration 5475][Wall Clock 518.430504405s] Trained 128 records in 0.076614609 seconds. Throughput is 1670.6996 records/second. Loss is 0.1349354. Sequential31006cbd's hyper parameters: Current learning rate is 0.004773725415314111. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 40576/60000][Iteration 5476][Wall Clock 518.505469929s] Trained 128 records in 0.074965524 seconds. Throughput is 1707.4517 records/second. Loss is 0.17958206. Sequential31006cbd's hyper parameters: Current learning rate is 0.004773269689737471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 40704/60000][Iteration 5477][Wall Clock 518.579058905s] Trained 128 records in 0.073588976 seconds. Throughput is 1739.391 records/second. Loss is 0.106254965. Sequential31006cbd's hyper parameters: Current learning rate is 0.004772814051164567. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 40832/60000][Iteration 5478][Wall Clock 518.664004439s] Trained 128 records in 0.084945534 seconds. Throughput is 1506.8479 records/second. Loss is 0.22979465. Sequential31006cbd's hyper parameters: Current learning rate is 0.004772358499570487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 40960/60000][Iteration 5479][Wall Clock 518.755277436s] Trained 128 records in 0.091272997 seconds. Throughput is 1402.3864 records/second. Loss is 0.30208063. Sequential31006cbd's hyper parameters: Current learning rate is 0.00477190303493033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41088/60000][Iteration 5480][Wall Clock 518.842666158s] Trained 128 records in 0.087388722 seconds. Throughput is 1464.7198 records/second. Loss is 0.19991052. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047714476572192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41216/60000][Iteration 5481][Wall Clock 518.951851079s] Trained 128 records in 0.109184921 seconds. Throughput is 1172.323 records/second. Loss is 0.16794021. Sequential31006cbd's hyper parameters: Current learning rate is 0.004770992366412214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41344/60000][Iteration 5482][Wall Clock 519.026396251s] Trained 128 records in 0.074545172 seconds. Throughput is 1717.0796 records/second. Loss is 0.21814172. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047705371624844955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41472/60000][Iteration 5483][Wall Clock 519.097965626s] Trained 128 records in 0.071569375 seconds. Throughput is 1788.4745 records/second. Loss is 0.14725813. Sequential31006cbd's hyper parameters: Current learning rate is 0.004770082045411181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41600/60000][Iteration 5484][Wall Clock 519.186552835s] Trained 128 records in 0.088587209 seconds. Throughput is 1444.9038 records/second. Loss is 0.121760026. Sequential31006cbd's hyper parameters: Current learning rate is 0.004769627015167414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41728/60000][Iteration 5485][Wall Clock 519.27091726s] Trained 128 records in 0.084364425 seconds. Throughput is 1517.2273 records/second. Loss is 0.18974596. Sequential31006cbd's hyper parameters: Current learning rate is 0.004769172071728348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:16 INFO  DistriOptimizer$:408 - [Epoch 12 41856/60000][Iteration 5486][Wall Clock 519.368626127s] Trained 128 records in 0.097708867 seconds. Throughput is 1310.0142 records/second. Loss is 0.1826704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004768717215069147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 41984/60000][Iteration 5487][Wall Clock 519.45118214s] Trained 128 records in 0.082556013 seconds. Throughput is 1550.4625 records/second. Loss is 0.23643239. Sequential31006cbd's hyper parameters: Current learning rate is 0.004768262445164982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42112/60000][Iteration 5488][Wall Clock 519.52763359s] Trained 128 records in 0.07645145 seconds. Throughput is 1674.2651 records/second. Loss is 0.13680126. Sequential31006cbd's hyper parameters: Current learning rate is 0.004767807761991036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42240/60000][Iteration 5489][Wall Clock 519.604653856s] Trained 128 records in 0.077020266 seconds. Throughput is 1661.9003 records/second. Loss is 0.170553. Sequential31006cbd's hyper parameters: Current learning rate is 0.004767353165522502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42368/60000][Iteration 5490][Wall Clock 519.684098977s] Trained 128 records in 0.079445121 seconds. Throughput is 1611.175 records/second. Loss is 0.12664875. Sequential31006cbd's hyper parameters: Current learning rate is 0.004766898655734578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42496/60000][Iteration 5491][Wall Clock 519.760875119s] Trained 128 records in 0.076776142 seconds. Throughput is 1667.1847 records/second. Loss is 0.25067058. Sequential31006cbd's hyper parameters: Current learning rate is 0.004766444232602479. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42624/60000][Iteration 5492][Wall Clock 519.838268236s] Trained 128 records in 0.077393117 seconds. Throughput is 1653.8939 records/second. Loss is 0.21985689. Sequential31006cbd's hyper parameters: Current learning rate is 0.00476598989610142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42752/60000][Iteration 5493][Wall Clock 519.926730653s] Trained 128 records in 0.088462417 seconds. Throughput is 1446.9421 records/second. Loss is 0.17937768. Sequential31006cbd's hyper parameters: Current learning rate is 0.004765535646206634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 42880/60000][Iteration 5494][Wall Clock 519.999158064s] Trained 128 records in 0.072427411 seconds. Throughput is 1767.2866 records/second. Loss is 0.074036025. Sequential31006cbd's hyper parameters: Current learning rate is 0.004765081482893357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 43008/60000][Iteration 5495][Wall Clock 520.081476773s] Trained 128 records in 0.082318709 seconds. Throughput is 1554.9321 records/second. Loss is 0.1813053. Sequential31006cbd's hyper parameters: Current learning rate is 0.004764627406136841. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 43136/60000][Iteration 5496][Wall Clock 520.158199369s] Trained 128 records in 0.076722596 seconds. Throughput is 1668.348 records/second. Loss is 0.25543886. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047641734159123384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 43264/60000][Iteration 5497][Wall Clock 520.234060936s] Trained 128 records in 0.075861567 seconds. Throughput is 1687.2839 records/second. Loss is 0.14438704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004763719512195123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 43392/60000][Iteration 5498][Wall Clock 520.309982203s] Trained 128 records in 0.075921267 seconds. Throughput is 1685.9572 records/second. Loss is 0.17964928. Sequential31006cbd's hyper parameters: Current learning rate is 0.004763265694960464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:17 INFO  DistriOptimizer$:408 - [Epoch 12 43520/60000][Iteration 5499][Wall Clock 520.384753803s] Trained 128 records in 0.0747716 seconds. Throughput is 1711.88 records/second. Loss is 0.20299351. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047628119641836535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 43648/60000][Iteration 5500][Wall Clock 520.470046097s] Trained 128 records in 0.085292294 seconds. Throughput is 1500.7217 records/second. Loss is 0.24233444. Sequential31006cbd's hyper parameters: Current learning rate is 0.004762358319839985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 43776/60000][Iteration 5501][Wall Clock 520.54899231s] Trained 128 records in 0.078946213 seconds. Throughput is 1621.357 records/second. Loss is 0.22110417. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047619047619047615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 43904/60000][Iteration 5502][Wall Clock 520.628021206s] Trained 128 records in 0.079028896 seconds. Throughput is 1619.6608 records/second. Loss is 0.11358213. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047614512903532994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44032/60000][Iteration 5503][Wall Clock 520.720265452s] Trained 128 records in 0.092244246 seconds. Throughput is 1387.6205 records/second. Loss is 0.30325186. Sequential31006cbd's hyper parameters: Current learning rate is 0.004760997905160921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44160/60000][Iteration 5504][Wall Clock 520.809608963s] Trained 128 records in 0.089343511 seconds. Throughput is 1432.6726 records/second. Loss is 0.19167352. Sequential31006cbd's hyper parameters: Current learning rate is 0.004760544606302961. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44288/60000][Iteration 5505][Wall Clock 520.904423375s] Trained 128 records in 0.094814412 seconds. Throughput is 1350.0057 records/second. Loss is 0.26285285. Sequential31006cbd's hyper parameters: Current learning rate is 0.00476009139375476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44416/60000][Iteration 5506][Wall Clock 521.008236694s] Trained 128 records in 0.103813319 seconds. Throughput is 1232.9824 records/second. Loss is 0.27759987. Sequential31006cbd's hyper parameters: Current learning rate is 0.00475963826749167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44544/60000][Iteration 5507][Wall Clock 521.086201208s] Trained 128 records in 0.077964514 seconds. Throughput is 1641.7726 records/second. Loss is 0.12981552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047591852274890545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44672/60000][Iteration 5508][Wall Clock 521.162052527s] Trained 128 records in 0.075851319 seconds. Throughput is 1687.5118 records/second. Loss is 0.17476837. Sequential31006cbd's hyper parameters: Current learning rate is 0.004758732273722281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44800/60000][Iteration 5509][Wall Clock 521.237665595s] Trained 128 records in 0.075613068 seconds. Throughput is 1692.8291 records/second. Loss is 0.23358557. Sequential31006cbd's hyper parameters: Current learning rate is 0.004758279406166729. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 44928/60000][Iteration 5510][Wall Clock 521.321991537s] Trained 128 records in 0.084325942 seconds. Throughput is 1517.9197 records/second. Loss is 0.14394131. Sequential31006cbd's hyper parameters: Current learning rate is 0.004757826624797793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:18 INFO  DistriOptimizer$:408 - [Epoch 12 45056/60000][Iteration 5511][Wall Clock 521.397596188s] Trained 128 records in 0.075604651 seconds. Throughput is 1693.0176 records/second. Loss is 0.13870603. Sequential31006cbd's hyper parameters: Current learning rate is 0.004757373929590865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45184/60000][Iteration 5512][Wall Clock 521.474683687s] Trained 128 records in 0.077087499 seconds. Throughput is 1660.4508 records/second. Loss is 0.19601238. Sequential31006cbd's hyper parameters: Current learning rate is 0.004756921320521359. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45312/60000][Iteration 5513][Wall Clock 521.547052969s] Trained 128 records in 0.072369282 seconds. Throughput is 1768.7062 records/second. Loss is 0.21132873. Sequential31006cbd's hyper parameters: Current learning rate is 0.004756468797564688. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45440/60000][Iteration 5514][Wall Clock 521.625455916s] Trained 128 records in 0.078402947 seconds. Throughput is 1632.5918 records/second. Loss is 0.15852147. Sequential31006cbd's hyper parameters: Current learning rate is 0.004756016360696281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45568/60000][Iteration 5515][Wall Clock 521.704656188s] Trained 128 records in 0.079200272 seconds. Throughput is 1616.156 records/second. Loss is 0.22891596. Sequential31006cbd's hyper parameters: Current learning rate is 0.004755564009891573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45696/60000][Iteration 5516][Wall Clock 521.786137886s] Trained 128 records in 0.081481698 seconds. Throughput is 1570.905 records/second. Loss is 0.18521875. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047551117451260115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45824/60000][Iteration 5517][Wall Clock 521.86292971s] Trained 128 records in 0.076791824 seconds. Throughput is 1666.8441 records/second. Loss is 0.10835846. Sequential31006cbd's hyper parameters: Current learning rate is 0.004754659566375047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 45952/60000][Iteration 5518][Wall Clock 521.939231252s] Trained 128 records in 0.076301542 seconds. Throughput is 1677.5544 records/second. Loss is 0.24222012. Sequential31006cbd's hyper parameters: Current learning rate is 0.004754207473614149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 46080/60000][Iteration 5519][Wall Clock 522.019940372s] Trained 128 records in 0.08070912 seconds. Throughput is 1585.9421 records/second. Loss is 0.1444914. Sequential31006cbd's hyper parameters: Current learning rate is 0.004753755466818787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 46208/60000][Iteration 5520][Wall Clock 522.092241421s] Trained 128 records in 0.072301049 seconds. Throughput is 1770.3754 records/second. Loss is 0.14347857. Sequential31006cbd's hyper parameters: Current learning rate is 0.004753303545964445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 46336/60000][Iteration 5521][Wall Clock 522.165145816s] Trained 128 records in 0.072904395 seconds. Throughput is 1755.7241 records/second. Loss is 0.20861167. Sequential31006cbd's hyper parameters: Current learning rate is 0.004752851711026616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 46464/60000][Iteration 5522][Wall Clock 522.241599088s] Trained 128 records in 0.076453272 seconds. Throughput is 1674.2253 records/second. Loss is 0.16784275. Sequential31006cbd's hyper parameters: Current learning rate is 0.004752399961980801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 46592/60000][Iteration 5523][Wall Clock 522.318255721s] Trained 128 records in 0.076656633 seconds. Throughput is 1669.7838 records/second. Loss is 0.16608082. Sequential31006cbd's hyper parameters: Current learning rate is 0.004751948298802509. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:19 INFO  DistriOptimizer$:408 - [Epoch 12 46720/60000][Iteration 5524][Wall Clock 522.394894333s] Trained 128 records in 0.076638612 seconds. Throughput is 1670.1764 records/second. Loss is 0.1352061. Sequential31006cbd's hyper parameters: Current learning rate is 0.004751496721467262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 46848/60000][Iteration 5525][Wall Clock 522.471729859s] Trained 128 records in 0.076835526 seconds. Throughput is 1665.896 records/second. Loss is 0.1606675. Sequential31006cbd's hyper parameters: Current learning rate is 0.00475104522995059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 46976/60000][Iteration 5526][Wall Clock 522.547902206s] Trained 128 records in 0.076172347 seconds. Throughput is 1680.3999 records/second. Loss is 0.26467174. Sequential31006cbd's hyper parameters: Current learning rate is 0.004750593824228029. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47104/60000][Iteration 5527][Wall Clock 522.622058749s] Trained 128 records in 0.074156543 seconds. Throughput is 1726.0782 records/second. Loss is 0.25749314. Sequential31006cbd's hyper parameters: Current learning rate is 0.004750142504275128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47232/60000][Iteration 5528][Wall Clock 522.696681529s] Trained 128 records in 0.07462278 seconds. Throughput is 1715.294 records/second. Loss is 0.21207398. Sequential31006cbd's hyper parameters: Current learning rate is 0.004749691270067444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47360/60000][Iteration 5529][Wall Clock 522.774798971s] Trained 128 records in 0.078117442 seconds. Throughput is 1638.5585 records/second. Loss is 0.1979519. Sequential31006cbd's hyper parameters: Current learning rate is 0.004749240121580548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47488/60000][Iteration 5530][Wall Clock 522.848319019s] Trained 128 records in 0.073520048 seconds. Throughput is 1741.0217 records/second. Loss is 0.15601033. Sequential31006cbd's hyper parameters: Current learning rate is 0.004748789058790008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47616/60000][Iteration 5531][Wall Clock 522.914918606s] Trained 128 records in 0.066599587 seconds. Throughput is 1921.9338 records/second. Loss is 0.23956606. Sequential31006cbd's hyper parameters: Current learning rate is 0.004748338081671416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47744/60000][Iteration 5532][Wall Clock 522.991123617s] Trained 128 records in 0.076205011 seconds. Throughput is 1679.6797 records/second. Loss is 0.3529309. Sequential31006cbd's hyper parameters: Current learning rate is 0.00474788719020036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 47872/60000][Iteration 5533][Wall Clock 523.067590491s] Trained 128 records in 0.076466874 seconds. Throughput is 1673.9275 records/second. Loss is 0.16417071. Sequential31006cbd's hyper parameters: Current learning rate is 0.00474743638435245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 48000/60000][Iteration 5534][Wall Clock 523.145967214s] Trained 128 records in 0.078376723 seconds. Throughput is 1633.138 records/second. Loss is 0.24089694. Sequential31006cbd's hyper parameters: Current learning rate is 0.004746985664103294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 48128/60000][Iteration 5535][Wall Clock 523.221994688s] Trained 128 records in 0.076027474 seconds. Throughput is 1683.6019 records/second. Loss is 0.1744741. Sequential31006cbd's hyper parameters: Current learning rate is 0.004746535029428517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 48256/60000][Iteration 5536][Wall Clock 523.302437779s] Trained 128 records in 0.080443091 seconds. Throughput is 1591.187 records/second. Loss is 0.17767331. Sequential31006cbd's hyper parameters: Current learning rate is 0.004746084480303749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:20 INFO  DistriOptimizer$:408 - [Epoch 12 48384/60000][Iteration 5537][Wall Clock 523.378046256s] Trained 128 records in 0.075608477 seconds. Throughput is 1692.9319 records/second. Loss is 0.13261591. Sequential31006cbd's hyper parameters: Current learning rate is 0.004745634016704633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 48512/60000][Iteration 5538][Wall Clock 523.454592844s] Trained 128 records in 0.076546588 seconds. Throughput is 1672.1843 records/second. Loss is 0.15653491. Sequential31006cbd's hyper parameters: Current learning rate is 0.004745183638606814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 48640/60000][Iteration 5539][Wall Clock 523.530675264s] Trained 128 records in 0.07608242 seconds. Throughput is 1682.386 records/second. Loss is 0.17210138. Sequential31006cbd's hyper parameters: Current learning rate is 0.004744733345985955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 48768/60000][Iteration 5540][Wall Clock 523.604172879s] Trained 128 records in 0.073497615 seconds. Throughput is 1741.5531 records/second. Loss is 0.22719982. Sequential31006cbd's hyper parameters: Current learning rate is 0.004744283138817725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 48896/60000][Iteration 5541][Wall Clock 523.67918987s] Trained 128 records in 0.075016991 seconds. Throughput is 1706.2802 records/second. Loss is 0.24406755. Sequential31006cbd's hyper parameters: Current learning rate is 0.004743833017077799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49024/60000][Iteration 5542][Wall Clock 523.756258091s] Trained 128 records in 0.077068221 seconds. Throughput is 1660.8661 records/second. Loss is 0.14454393. Sequential31006cbd's hyper parameters: Current learning rate is 0.004743382980741865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49152/60000][Iteration 5543][Wall Clock 523.834620109s] Trained 128 records in 0.078362018 seconds. Throughput is 1633.4445 records/second. Loss is 0.21288455. Sequential31006cbd's hyper parameters: Current learning rate is 0.00474293302978562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49280/60000][Iteration 5544][Wall Clock 523.903985268s] Trained 128 records in 0.069365159 seconds. Throughput is 1845.3068 records/second. Loss is 0.15577494. Sequential31006cbd's hyper parameters: Current learning rate is 0.004742483164184767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49408/60000][Iteration 5545][Wall Clock 523.982081036s] Trained 128 records in 0.078095768 seconds. Throughput is 1639.0132 records/second. Loss is 0.19592956. Sequential31006cbd's hyper parameters: Current learning rate is 0.004742033383915023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49536/60000][Iteration 5546][Wall Clock 524.060356724s] Trained 128 records in 0.078275688 seconds. Throughput is 1635.246 records/second. Loss is 0.14804235. Sequential31006cbd's hyper parameters: Current learning rate is 0.00474158368895211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49664/60000][Iteration 5547][Wall Clock 524.128516485s] Trained 128 records in 0.068159761 seconds. Throughput is 1877.9409 records/second. Loss is 0.18490484. Sequential31006cbd's hyper parameters: Current learning rate is 0.004741134079271762. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49792/60000][Iteration 5548][Wall Clock 524.197961s] Trained 128 records in 0.069444515 seconds. Throughput is 1843.1981 records/second. Loss is 0.14206372. Sequential31006cbd's hyper parameters: Current learning rate is 0.00474068455484972. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 49920/60000][Iteration 5549][Wall Clock 524.271448522s] Trained 128 records in 0.073487522 seconds. Throughput is 1741.7924 records/second. Loss is 0.09848787. Sequential31006cbd's hyper parameters: Current learning rate is 0.004740235115661736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:21 INFO  DistriOptimizer$:408 - [Epoch 12 50048/60000][Iteration 5550][Wall Clock 524.34764528s] Trained 128 records in 0.076196758 seconds. Throughput is 1679.8615 records/second. Loss is 0.25574714. Sequential31006cbd's hyper parameters: Current learning rate is 0.004739785761683572. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50176/60000][Iteration 5551][Wall Clock 524.422866984s] Trained 128 records in 0.075221704 seconds. Throughput is 1701.6366 records/second. Loss is 0.19294958. Sequential31006cbd's hyper parameters: Current learning rate is 0.004739336492890995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50304/60000][Iteration 5552][Wall Clock 524.500432009s] Trained 128 records in 0.077565025 seconds. Throughput is 1650.2284 records/second. Loss is 0.13279764. Sequential31006cbd's hyper parameters: Current learning rate is 0.004738887309259786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50432/60000][Iteration 5553][Wall Clock 524.578166355s] Trained 128 records in 0.077734346 seconds. Throughput is 1646.6338 records/second. Loss is 0.14044301. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047384382107657315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50560/60000][Iteration 5554][Wall Clock 524.649886711s] Trained 128 records in 0.071720356 seconds. Throughput is 1784.7095 records/second. Loss is 0.18922284. Sequential31006cbd's hyper parameters: Current learning rate is 0.00473798919738463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50688/60000][Iteration 5555][Wall Clock 524.735611239s] Trained 128 records in 0.085724528 seconds. Throughput is 1493.1549 records/second. Loss is 0.2712227. Sequential31006cbd's hyper parameters: Current learning rate is 0.004737540269092287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50816/60000][Iteration 5556][Wall Clock 524.815384993s] Trained 128 records in 0.079773754 seconds. Throughput is 1604.5377 records/second. Loss is 0.1280407. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047370914258645196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 50944/60000][Iteration 5557][Wall Clock 524.891813153s] Trained 128 records in 0.07642816 seconds. Throughput is 1674.7754 records/second. Loss is 0.21405609. Sequential31006cbd's hyper parameters: Current learning rate is 0.00473664266767715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 51072/60000][Iteration 5558][Wall Clock 524.969081331s] Trained 128 records in 0.077268178 seconds. Throughput is 1656.5681 records/second. Loss is 0.22562537. Sequential31006cbd's hyper parameters: Current learning rate is 0.004736193994506015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 51200/60000][Iteration 5559][Wall Clock 525.046568061s] Trained 128 records in 0.07748673 seconds. Throughput is 1651.8958 records/second. Loss is 0.24213526. Sequential31006cbd's hyper parameters: Current learning rate is 0.004735745406326956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 51328/60000][Iteration 5560][Wall Clock 525.127708348s] Trained 128 records in 0.081140287 seconds. Throughput is 1577.5148 records/second. Loss is 0.26081276. Sequential31006cbd's hyper parameters: Current learning rate is 0.004735296903115825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 51456/60000][Iteration 5561][Wall Clock 525.200265355s] Trained 128 records in 0.072557007 seconds. Throughput is 1764.13 records/second. Loss is 0.21789739. Sequential31006cbd's hyper parameters: Current learning rate is 0.004734848484848485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 51584/60000][Iteration 5562][Wall Clock 525.272540141s] Trained 128 records in 0.072274786 seconds. Throughput is 1771.0187 records/second. Loss is 0.2261068. Sequential31006cbd's hyper parameters: Current learning rate is 0.004734400151500805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:22 INFO  DistriOptimizer$:408 - [Epoch 12 51712/60000][Iteration 5563][Wall Clock 525.348105012s] Trained 128 records in 0.075564871 seconds. Throughput is 1693.9088 records/second. Loss is 0.19387634. Sequential31006cbd's hyper parameters: Current learning rate is 0.004733951903048665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 51840/60000][Iteration 5564][Wall Clock 525.423174441s] Trained 128 records in 0.075069429 seconds. Throughput is 1705.0883 records/second. Loss is 0.22809796. Sequential31006cbd's hyper parameters: Current learning rate is 0.004733503739467954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 51968/60000][Iteration 5565][Wall Clock 525.50067319s] Trained 128 records in 0.077498749 seconds. Throughput is 1651.6395 records/second. Loss is 0.22293504. Sequential31006cbd's hyper parameters: Current learning rate is 0.00473305566073457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52096/60000][Iteration 5566][Wall Clock 525.578301486s] Trained 128 records in 0.077628296 seconds. Throughput is 1648.8832 records/second. Loss is 0.22178432. Sequential31006cbd's hyper parameters: Current learning rate is 0.00473260766682442. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52224/60000][Iteration 5567][Wall Clock 525.660122973s] Trained 128 records in 0.081821487 seconds. Throughput is 1564.3812 records/second. Loss is 0.22407986. Sequential31006cbd's hyper parameters: Current learning rate is 0.00473215975771342. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52352/60000][Iteration 5568][Wall Clock 525.743063204s] Trained 128 records in 0.082940231 seconds. Throughput is 1543.28 records/second. Loss is 0.19550472. Sequential31006cbd's hyper parameters: Current learning rate is 0.004731711933377496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52480/60000][Iteration 5569][Wall Clock 525.82150683s] Trained 128 records in 0.078443626 seconds. Throughput is 1631.7451 records/second. Loss is 0.10910964. Sequential31006cbd's hyper parameters: Current learning rate is 0.004731264193792582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52608/60000][Iteration 5570][Wall Clock 525.902238999s] Trained 128 records in 0.080732169 seconds. Throughput is 1585.4895 records/second. Loss is 0.24852991. Sequential31006cbd's hyper parameters: Current learning rate is 0.00473081653893462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52736/60000][Iteration 5571][Wall Clock 525.974955643s] Trained 128 records in 0.072716644 seconds. Throughput is 1760.2572 records/second. Loss is 0.11277035. Sequential31006cbd's hyper parameters: Current learning rate is 0.004730368968779565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52864/60000][Iteration 5572][Wall Clock 526.055021179s] Trained 128 records in 0.080065536 seconds. Throughput is 1598.6904 records/second. Loss is 0.16642785. Sequential31006cbd's hyper parameters: Current learning rate is 0.004729921483303376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 52992/60000][Iteration 5573][Wall Clock 526.130065542s] Trained 128 records in 0.075044363 seconds. Throughput is 1705.6577 records/second. Loss is 0.2439703. Sequential31006cbd's hyper parameters: Current learning rate is 0.004729474082482028. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 53120/60000][Iteration 5574][Wall Clock 526.199132294s] Trained 128 records in 0.069066752 seconds. Throughput is 1853.2794 records/second. Loss is 0.24527694. Sequential31006cbd's hyper parameters: Current learning rate is 0.004729026766291497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 53248/60000][Iteration 5575][Wall Clock 526.270132209s] Trained 128 records in 0.070999915 seconds. Throughput is 1802.8191 records/second. Loss is 0.14095989. Sequential31006cbd's hyper parameters: Current learning rate is 0.004728579534707775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:23 INFO  DistriOptimizer$:408 - [Epoch 12 53376/60000][Iteration 5576][Wall Clock 526.356482491s] Trained 128 records in 0.086350282 seconds. Throughput is 1482.3345 records/second. Loss is 0.15792815. Sequential31006cbd's hyper parameters: Current learning rate is 0.004728132387706856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 53504/60000][Iteration 5577][Wall Clock 526.438818286s] Trained 128 records in 0.082335795 seconds. Throughput is 1554.6095 records/second. Loss is 0.135132. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047276853252647515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 53632/60000][Iteration 5578][Wall Clock 526.518471466s] Trained 128 records in 0.07965318 seconds. Throughput is 1606.9666 records/second. Loss is 0.21628931. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047272383473574734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 53760/60000][Iteration 5579][Wall Clock 526.610707523s] Trained 128 records in 0.092236057 seconds. Throughput is 1387.7437 records/second. Loss is 0.14954138. Sequential31006cbd's hyper parameters: Current learning rate is 0.004726791453961051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 53888/60000][Iteration 5580][Wall Clock 526.690654497s] Trained 128 records in 0.079946974 seconds. Throughput is 1601.0613 records/second. Loss is 0.1956069. Sequential31006cbd's hyper parameters: Current learning rate is 0.004726344645051517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54016/60000][Iteration 5581][Wall Clock 526.76546398s] Trained 128 records in 0.074809483 seconds. Throughput is 1711.0131 records/second. Loss is 0.1766928. Sequential31006cbd's hyper parameters: Current learning rate is 0.004725897920604915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54144/60000][Iteration 5582][Wall Clock 526.84245632s] Trained 128 records in 0.07699234 seconds. Throughput is 1662.503 records/second. Loss is 0.23027027. Sequential31006cbd's hyper parameters: Current learning rate is 0.004725451280597297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54272/60000][Iteration 5583][Wall Clock 526.918900568s] Trained 128 records in 0.076444248 seconds. Throughput is 1674.423 records/second. Loss is 0.1546843. Sequential31006cbd's hyper parameters: Current learning rate is 0.004725004725004725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54400/60000][Iteration 5584][Wall Clock 526.989740103s] Trained 128 records in 0.070839535 seconds. Throughput is 1806.9008 records/second. Loss is 0.21738501. Sequential31006cbd's hyper parameters: Current learning rate is 0.004724558253803269. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54528/60000][Iteration 5585][Wall Clock 527.063080934s] Trained 128 records in 0.073340831 seconds. Throughput is 1745.276 records/second. Loss is 0.18908343. Sequential31006cbd's hyper parameters: Current learning rate is 0.00472411186696901. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54656/60000][Iteration 5586][Wall Clock 527.140051653s] Trained 128 records in 0.076970719 seconds. Throughput is 1662.9701 records/second. Loss is 0.15879117. Sequential31006cbd's hyper parameters: Current learning rate is 0.004723665564478035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54784/60000][Iteration 5587][Wall Clock 527.215740432s] Trained 128 records in 0.075688779 seconds. Throughput is 1691.1357 records/second. Loss is 0.1472231. Sequential31006cbd's hyper parameters: Current learning rate is 0.004723219346306443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 54912/60000][Iteration 5588][Wall Clock 527.286246583s] Trained 128 records in 0.070506151 seconds. Throughput is 1815.4445 records/second. Loss is 0.21249042. Sequential31006cbd's hyper parameters: Current learning rate is 0.004722773212430339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:24 INFO  DistriOptimizer$:408 - [Epoch 12 55040/60000][Iteration 5589][Wall Clock 527.361716065s] Trained 128 records in 0.075469482 seconds. Throughput is 1696.0499 records/second. Loss is 0.14579871. Sequential31006cbd's hyper parameters: Current learning rate is 0.00472232716282584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55168/60000][Iteration 5590][Wall Clock 527.436510768s] Trained 128 records in 0.074794703 seconds. Throughput is 1711.3512 records/second. Loss is 0.21579388. Sequential31006cbd's hyper parameters: Current learning rate is 0.004721881197469072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55296/60000][Iteration 5591][Wall Clock 527.510998196s] Trained 128 records in 0.074487428 seconds. Throughput is 1718.4109 records/second. Loss is 0.18245034. Sequential31006cbd's hyper parameters: Current learning rate is 0.004721435316336166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55424/60000][Iteration 5592][Wall Clock 527.589364787s] Trained 128 records in 0.078366591 seconds. Throughput is 1633.349 records/second. Loss is 0.13689998. Sequential31006cbd's hyper parameters: Current learning rate is 0.004720989519403267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55552/60000][Iteration 5593][Wall Clock 527.664199376s] Trained 128 records in 0.074834589 seconds. Throughput is 1710.439 records/second. Loss is 0.16330636. Sequential31006cbd's hyper parameters: Current learning rate is 0.004720543806646525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55680/60000][Iteration 5594][Wall Clock 527.738566258s] Trained 128 records in 0.074366882 seconds. Throughput is 1721.1963 records/second. Loss is 0.20066443. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047200981780421035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55808/60000][Iteration 5595][Wall Clock 527.813084328s] Trained 128 records in 0.07451807 seconds. Throughput is 1717.7042 records/second. Loss is 0.18497597. Sequential31006cbd's hyper parameters: Current learning rate is 0.004719652633566169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 55936/60000][Iteration 5596][Wall Clock 527.889206862s] Trained 128 records in 0.076122534 seconds. Throughput is 1681.4994 records/second. Loss is 0.17864244. Sequential31006cbd's hyper parameters: Current learning rate is 0.004719207173194904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 56064/60000][Iteration 5597][Wall Clock 527.976060963s] Trained 128 records in 0.086854101 seconds. Throughput is 1473.7358 records/second. Loss is 0.16309. Sequential31006cbd's hyper parameters: Current learning rate is 0.004718761796904492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 56192/60000][Iteration 5598][Wall Clock 528.048849615s] Trained 128 records in 0.072788652 seconds. Throughput is 1758.516 records/second. Loss is 0.1395913. Sequential31006cbd's hyper parameters: Current learning rate is 0.004718316504671134. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 56320/60000][Iteration 5599][Wall Clock 528.135371963s] Trained 128 records in 0.086522348 seconds. Throughput is 1479.3866 records/second. Loss is 0.26736683. Sequential31006cbd's hyper parameters: Current learning rate is 0.004717871296471032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 56448/60000][Iteration 5600][Wall Clock 528.213623652s] Trained 128 records in 0.078251689 seconds. Throughput is 1635.7474 records/second. Loss is 0.26458058. Sequential31006cbd's hyper parameters: Current learning rate is 0.004717426172280404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 56576/60000][Iteration 5601][Wall Clock 528.29284698s] Trained 128 records in 0.079223328 seconds. Throughput is 1615.6858 records/second. Loss is 0.24559334. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047169811320754715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:25 INFO  DistriOptimizer$:408 - [Epoch 12 56704/60000][Iteration 5602][Wall Clock 528.372897737s] Trained 128 records in 0.080050757 seconds. Throughput is 1598.9855 records/second. Loss is 0.18632126. Sequential31006cbd's hyper parameters: Current learning rate is 0.004716536175832469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 56832/60000][Iteration 5603][Wall Clock 528.46993708s] Trained 128 records in 0.097039343 seconds. Throughput is 1319.0526 records/second. Loss is 0.14626646. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047160913035276366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 56960/60000][Iteration 5604][Wall Clock 528.548807548s] Trained 128 records in 0.078870468 seconds. Throughput is 1622.9142 records/second. Loss is 0.1365943. Sequential31006cbd's hyper parameters: Current learning rate is 0.004715646515137225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57088/60000][Iteration 5605][Wall Clock 528.624602142s] Trained 128 records in 0.075794594 seconds. Throughput is 1688.7748 records/second. Loss is 0.1527826. Sequential31006cbd's hyper parameters: Current learning rate is 0.004715201810637495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57216/60000][Iteration 5606][Wall Clock 528.703023724s] Trained 128 records in 0.078421582 seconds. Throughput is 1632.2037 records/second. Loss is 0.12561429. Sequential31006cbd's hyper parameters: Current learning rate is 0.004714757190004715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57344/60000][Iteration 5607][Wall Clock 528.77592788s] Trained 128 records in 0.072904156 seconds. Throughput is 1755.7299 records/second. Loss is 0.19653347. Sequential31006cbd's hyper parameters: Current learning rate is 0.004714312653215162. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57472/60000][Iteration 5608][Wall Clock 528.850930827s] Trained 128 records in 0.075002947 seconds. Throughput is 1706.5996 records/second. Loss is 0.13995141. Sequential31006cbd's hyper parameters: Current learning rate is 0.004713868200245121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57600/60000][Iteration 5609][Wall Clock 528.927474848s] Trained 128 records in 0.076544021 seconds. Throughput is 1672.2402 records/second. Loss is 0.09617113. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047134238310708905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57728/60000][Iteration 5610][Wall Clock 529.00810881s] Trained 128 records in 0.080633962 seconds. Throughput is 1587.4205 records/second. Loss is 0.16852117. Sequential31006cbd's hyper parameters: Current learning rate is 0.004712979545668771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57856/60000][Iteration 5611][Wall Clock 529.078664708s] Trained 128 records in 0.070555898 seconds. Throughput is 1814.1644 records/second. Loss is 0.1067384. Sequential31006cbd's hyper parameters: Current learning rate is 0.004712535344015081. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 57984/60000][Iteration 5612][Wall Clock 529.156647006s] Trained 128 records in 0.077982298 seconds. Throughput is 1641.3982 records/second. Loss is 0.12749037. Sequential31006cbd's hyper parameters: Current learning rate is 0.004712091226086137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 58112/60000][Iteration 5613][Wall Clock 529.232926763s] Trained 128 records in 0.076279757 seconds. Throughput is 1678.0336 records/second. Loss is 0.13685486. Sequential31006cbd's hyper parameters: Current learning rate is 0.004711647191858274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 58240/60000][Iteration 5614][Wall Clock 529.307671758s] Trained 128 records in 0.074744995 seconds. Throughput is 1712.4893 records/second. Loss is 0.16399911. Sequential31006cbd's hyper parameters: Current learning rate is 0.004711203241307829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:26 INFO  DistriOptimizer$:408 - [Epoch 12 58368/60000][Iteration 5615][Wall Clock 529.382014301s] Trained 128 records in 0.074342543 seconds. Throughput is 1721.7598 records/second. Loss is 0.16345933. Sequential31006cbd's hyper parameters: Current learning rate is 0.004710759374411156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 58496/60000][Iteration 5616][Wall Clock 529.463192288s] Trained 128 records in 0.081177987 seconds. Throughput is 1576.7821 records/second. Loss is 0.16006333. Sequential31006cbd's hyper parameters: Current learning rate is 0.004710315591144606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 58624/60000][Iteration 5617][Wall Clock 529.541732107s] Trained 128 records in 0.078539819 seconds. Throughput is 1629.7466 records/second. Loss is 0.14959572. Sequential31006cbd's hyper parameters: Current learning rate is 0.004709871891484552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 58752/60000][Iteration 5618][Wall Clock 529.618647053s] Trained 128 records in 0.076914946 seconds. Throughput is 1664.1759 records/second. Loss is 0.13020259. Sequential31006cbd's hyper parameters: Current learning rate is 0.004709428275407365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 58880/60000][Iteration 5619][Wall Clock 529.695878982s] Trained 128 records in 0.077231929 seconds. Throughput is 1657.3456 records/second. Loss is 0.13566808. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047089847428894325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59008/60000][Iteration 5620][Wall Clock 529.772101602s] Trained 128 records in 0.07622262 seconds. Throughput is 1679.2915 records/second. Loss is 0.15275727. Sequential31006cbd's hyper parameters: Current learning rate is 0.004708541293907147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59136/60000][Iteration 5621][Wall Clock 529.844248839s] Trained 128 records in 0.072147237 seconds. Throughput is 1774.1498 records/second. Loss is 0.30114207. Sequential31006cbd's hyper parameters: Current learning rate is 0.004708097928436911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59264/60000][Iteration 5622][Wall Clock 529.921718517s] Trained 128 records in 0.077469678 seconds. Throughput is 1652.2594 records/second. Loss is 0.14556983. Sequential31006cbd's hyper parameters: Current learning rate is 0.004707654646455136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59392/60000][Iteration 5623][Wall Clock 530.006266364s] Trained 128 records in 0.084547847 seconds. Throughput is 1513.9357 records/second. Loss is 0.15263215. Sequential31006cbd's hyper parameters: Current learning rate is 0.004707211447938241. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59520/60000][Iteration 5624][Wall Clock 530.083985604s] Trained 128 records in 0.07771924 seconds. Throughput is 1646.9539 records/second. Loss is 0.29539055. Sequential31006cbd's hyper parameters: Current learning rate is 0.004706768332862657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59648/60000][Iteration 5625][Wall Clock 530.158885307s] Trained 128 records in 0.074899703 seconds. Throughput is 1708.952 records/second. Loss is 0.08790807. Sequential31006cbd's hyper parameters: Current learning rate is 0.00470632530120482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59776/60000][Iteration 5626][Wall Clock 530.254865471s] Trained 128 records in 0.095980164 seconds. Throughput is 1333.6089 records/second. Loss is 0.21224762. Sequential31006cbd's hyper parameters: Current learning rate is 0.004705882352941177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:27 INFO  DistriOptimizer$:408 - [Epoch 12 59904/60000][Iteration 5627][Wall Clock 530.332225612s] Trained 128 records in 0.077360141 seconds. Throughput is 1654.5989 records/second. Loss is 0.27953398. Sequential31006cbd's hyper parameters: Current learning rate is 0.004705439488048184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:28 INFO  DistriOptimizer$:408 - [Epoch 12 60032/60000][Iteration 5628][Wall Clock 530.409131944s] Trained 128 records in 0.076906332 seconds. Throughput is 1664.3623 records/second. Loss is 0.19204563. Sequential31006cbd's hyper parameters: Current learning rate is 0.004704996706502306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:28 INFO  DistriOptimizer$:452 - [Epoch 12 60032/60000][Iteration 5628][Wall Clock 530.409131944s] Epoch finished. Wall clock time is 531545.848268 ms
2019-10-24 00:06:28 INFO  DistriOptimizer$:111 - [Epoch 12 60032/60000][Iteration 5628][Wall Clock 530.409131944s] Validate model...
2019-10-24 00:06:28 INFO  DistriOptimizer$:178 - [Epoch 12 60032/60000][Iteration 5628][Wall Clock 530.409131944s] validate model throughput is 12112.986 records/second
2019-10-24 00:06:28 INFO  DistriOptimizer$:181 - [Epoch 12 60032/60000][Iteration 5628][Wall Clock 530.409131944s] Top1Accuracy is Accuracy(correct: 9494, count: 10000, accuracy: 0.9494)
2019-10-24 00:06:28 INFO  DistriOptimizer$:221 - [Wall Clock 531.545848268s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:06:28 INFO  DistriOptimizer$:226 - [Wall Clock 531.545848268s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 128/60000][Iteration 5629][Wall Clock 531.628430185s] Trained 128 records in 0.082581917 seconds. Throughput is 1549.9762 records/second. Loss is 0.12195756. Sequential31006cbd's hyper parameters: Current learning rate is 0.004704554008280014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 256/60000][Iteration 5630][Wall Clock 531.71360853s] Trained 128 records in 0.085178345 seconds. Throughput is 1502.7294 records/second. Loss is 0.1827403. Sequential31006cbd's hyper parameters: Current learning rate is 0.004704111393357795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 384/60000][Iteration 5631][Wall Clock 531.791198139s] Trained 128 records in 0.077589609 seconds. Throughput is 1649.7054 records/second. Loss is 0.171116. Sequential31006cbd's hyper parameters: Current learning rate is 0.004703668861712135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 512/60000][Iteration 5632][Wall Clock 531.89007076s] Trained 128 records in 0.098872621 seconds. Throughput is 1294.595 records/second. Loss is 0.23786622. Sequential31006cbd's hyper parameters: Current learning rate is 0.004703226413319538. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 640/60000][Iteration 5633][Wall Clock 531.974460662s] Trained 128 records in 0.084389902 seconds. Throughput is 1516.7692 records/second. Loss is 0.14094296. Sequential31006cbd's hyper parameters: Current learning rate is 0.004702784048156508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 768/60000][Iteration 5634][Wall Clock 532.056804237s] Trained 128 records in 0.082343575 seconds. Throughput is 1554.4624 records/second. Loss is 0.13129967. Sequential31006cbd's hyper parameters: Current learning rate is 0.004702341766199568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 896/60000][Iteration 5635][Wall Clock 532.125843164s] Trained 128 records in 0.069038927 seconds. Throughput is 1854.0265 records/second. Loss is 0.20002481. Sequential31006cbd's hyper parameters: Current learning rate is 0.0047018995674252394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 1024/60000][Iteration 5636][Wall Clock 532.20690359s] Trained 128 records in 0.081060426 seconds. Throughput is 1579.069 records/second. Loss is 0.1607706. Sequential31006cbd's hyper parameters: Current learning rate is 0.004701457451810062. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 1152/60000][Iteration 5637][Wall Clock 532.286626877s] Trained 128 records in 0.079723287 seconds. Throughput is 1605.5536 records/second. Loss is 0.2336084. Sequential31006cbd's hyper parameters: Current learning rate is 0.004701015419330575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 1280/60000][Iteration 5638][Wall Clock 532.368769634s] Trained 128 records in 0.082142757 seconds. Throughput is 1558.2628 records/second. Loss is 0.21678516. Sequential31006cbd's hyper parameters: Current learning rate is 0.004700573469963336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 1408/60000][Iteration 5639][Wall Clock 532.455133611s] Trained 128 records in 0.086363977 seconds. Throughput is 1482.0994 records/second. Loss is 0.2003386. Sequential31006cbd's hyper parameters: Current learning rate is 0.004700131603684903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 1536/60000][Iteration 5640][Wall Clock 532.538147354s] Trained 128 records in 0.083013743 seconds. Throughput is 1541.9133 records/second. Loss is 0.16451946. Sequential31006cbd's hyper parameters: Current learning rate is 0.004699689820471848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:29 INFO  DistriOptimizer$:408 - [Epoch 13 1664/60000][Iteration 5641][Wall Clock 532.611058901s] Trained 128 records in 0.072911547 seconds. Throughput is 1755.5519 records/second. Loss is 0.20956528. Sequential31006cbd's hyper parameters: Current learning rate is 0.004699248120300752. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 1792/60000][Iteration 5642][Wall Clock 532.684106659s] Trained 128 records in 0.073047758 seconds. Throughput is 1752.2783 records/second. Loss is 0.2598775. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046988065031482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 1920/60000][Iteration 5643][Wall Clock 532.759278038s] Trained 128 records in 0.075171379 seconds. Throughput is 1702.7756 records/second. Loss is 0.16601788. Sequential31006cbd's hyper parameters: Current learning rate is 0.004698364968990791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2048/60000][Iteration 5644][Wall Clock 532.837746056s] Trained 128 records in 0.078468018 seconds. Throughput is 1631.2378 records/second. Loss is 0.13166866. Sequential31006cbd's hyper parameters: Current learning rate is 0.00469792351780513. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2176/60000][Iteration 5645][Wall Clock 532.919447164s] Trained 128 records in 0.081701108 seconds. Throughput is 1566.6863 records/second. Loss is 0.14534943. Sequential31006cbd's hyper parameters: Current learning rate is 0.004697482149567831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2304/60000][Iteration 5646][Wall Clock 532.994834691s] Trained 128 records in 0.075387527 seconds. Throughput is 1697.8936 records/second. Loss is 0.21148556. Sequential31006cbd's hyper parameters: Current learning rate is 0.004697040864255519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2432/60000][Iteration 5647][Wall Clock 533.068698083s] Trained 128 records in 0.073863392 seconds. Throughput is 1732.9287 records/second. Loss is 0.18517587. Sequential31006cbd's hyper parameters: Current learning rate is 0.004696599661844825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2560/60000][Iteration 5648][Wall Clock 533.151874022s] Trained 128 records in 0.083175939 seconds. Throughput is 1538.9065 records/second. Loss is 0.10965793. Sequential31006cbd's hyper parameters: Current learning rate is 0.004696158542312388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2688/60000][Iteration 5649][Wall Clock 533.224214439s] Trained 128 records in 0.072340417 seconds. Throughput is 1769.4121 records/second. Loss is 0.23191643. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046957175056348615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2816/60000][Iteration 5650][Wall Clock 533.30208259s] Trained 128 records in 0.077868151 seconds. Throughput is 1643.8043 records/second. Loss is 0.20851205. Sequential31006cbd's hyper parameters: Current learning rate is 0.004695276551788899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 2944/60000][Iteration 5651][Wall Clock 533.379322626s] Trained 128 records in 0.077240036 seconds. Throughput is 1657.1718 records/second. Loss is 0.16360524. Sequential31006cbd's hyper parameters: Current learning rate is 0.004694835680751174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 3072/60000][Iteration 5652][Wall Clock 533.454944885s] Trained 128 records in 0.075622259 seconds. Throughput is 1692.6233 records/second. Loss is 0.19496454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004694394892498357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:30 INFO  DistriOptimizer$:408 - [Epoch 13 3200/60000][Iteration 5653][Wall Clock 533.544676037s] Trained 128 records in 0.089731152 seconds. Throughput is 1426.4834 records/second. Loss is 0.2051377. Sequential31006cbd's hyper parameters: Current learning rate is 0.004693954187007136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 3328/60000][Iteration 5654][Wall Clock 533.64552413s] Trained 128 records in 0.100848093 seconds. Throughput is 1269.2357 records/second. Loss is 0.27548406. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046935135642542005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 3456/60000][Iteration 5655][Wall Clock 533.721800112s] Trained 128 records in 0.076275982 seconds. Throughput is 1678.1167 records/second. Loss is 0.18953645. Sequential31006cbd's hyper parameters: Current learning rate is 0.004693073024216257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 3584/60000][Iteration 5656][Wall Clock 533.821630987s] Trained 128 records in 0.099830875 seconds. Throughput is 1282.1685 records/second. Loss is 0.18052319. Sequential31006cbd's hyper parameters: Current learning rate is 0.004692632566870014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 3712/60000][Iteration 5657][Wall Clock 533.912386048s] Trained 128 records in 0.090755061 seconds. Throughput is 1410.3896 records/second. Loss is 0.19933228. Sequential31006cbd's hyper parameters: Current learning rate is 0.004692192192192193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 3840/60000][Iteration 5658][Wall Clock 533.995831607s] Trained 128 records in 0.083445559 seconds. Throughput is 1533.9343 records/second. Loss is 0.13835089. Sequential31006cbd's hyper parameters: Current learning rate is 0.004691751900159519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 3968/60000][Iteration 5659][Wall Clock 534.072593857s] Trained 128 records in 0.07676225 seconds. Throughput is 1667.4862 records/second. Loss is 0.2577394. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046913116907487335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 4096/60000][Iteration 5660][Wall Clock 534.145838331s] Trained 128 records in 0.073244474 seconds. Throughput is 1747.5721 records/second. Loss is 0.17247804. Sequential31006cbd's hyper parameters: Current learning rate is 0.004690871563936579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 4224/60000][Iteration 5661][Wall Clock 534.220687747s] Trained 128 records in 0.074849416 seconds. Throughput is 1710.1001 records/second. Loss is 0.17066498. Sequential31006cbd's hyper parameters: Current learning rate is 0.004690431519699812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 4352/60000][Iteration 5662][Wall Clock 534.296999921s] Trained 128 records in 0.076312174 seconds. Throughput is 1677.3208 records/second. Loss is 0.17659165. Sequential31006cbd's hyper parameters: Current learning rate is 0.004689991558015196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 4480/60000][Iteration 5663][Wall Clock 534.374393477s] Trained 128 records in 0.077393556 seconds. Throughput is 1653.8845 records/second. Loss is 0.21234669. Sequential31006cbd's hyper parameters: Current learning rate is 0.004689551678859501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 4608/60000][Iteration 5664][Wall Clock 534.457381331s] Trained 128 records in 0.082987854 seconds. Throughput is 1542.3944 records/second. Loss is 0.108855054. Sequential31006cbd's hyper parameters: Current learning rate is 0.00468911188220951. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:31 INFO  DistriOptimizer$:408 - [Epoch 13 4736/60000][Iteration 5665][Wall Clock 534.536892704s] Trained 128 records in 0.079511373 seconds. Throughput is 1609.8325 records/second. Loss is 0.2622905. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046886721680420105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 4864/60000][Iteration 5666][Wall Clock 534.615072547s] Trained 128 records in 0.078179843 seconds. Throughput is 1637.2506 records/second. Loss is 0.2541551. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046882325363338025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 4992/60000][Iteration 5667][Wall Clock 534.702583845s] Trained 128 records in 0.087511298 seconds. Throughput is 1462.6682 records/second. Loss is 0.12720388. Sequential31006cbd's hyper parameters: Current learning rate is 0.004687792987061692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5120/60000][Iteration 5668][Wall Clock 534.782394964s] Trained 128 records in 0.079811119 seconds. Throughput is 1603.7866 records/second. Loss is 0.13630861. Sequential31006cbd's hyper parameters: Current learning rate is 0.004687353520202494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5248/60000][Iteration 5669][Wall Clock 534.861946592s] Trained 128 records in 0.079551628 seconds. Throughput is 1609.018 records/second. Loss is 0.13872035. Sequential31006cbd's hyper parameters: Current learning rate is 0.004686914135733033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5376/60000][Iteration 5670][Wall Clock 534.943335487s] Trained 128 records in 0.081388895 seconds. Throughput is 1572.696 records/second. Loss is 0.14861909. Sequential31006cbd's hyper parameters: Current learning rate is 0.004686474833630144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5504/60000][Iteration 5671][Wall Clock 535.024016363s] Trained 128 records in 0.080680876 seconds. Throughput is 1586.4974 records/second. Loss is 0.17311357. Sequential31006cbd's hyper parameters: Current learning rate is 0.004686035613870665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5632/60000][Iteration 5672][Wall Clock 535.110798493s] Trained 128 records in 0.08678213 seconds. Throughput is 1474.9581 records/second. Loss is 0.109146975. Sequential31006cbd's hyper parameters: Current learning rate is 0.00468559647643145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5760/60000][Iteration 5673][Wall Clock 535.196664804s] Trained 128 records in 0.085866311 seconds. Throughput is 1490.6895 records/second. Loss is 0.28592128. Sequential31006cbd's hyper parameters: Current learning rate is 0.004685157421289355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 5888/60000][Iteration 5674][Wall Clock 535.273578928s] Trained 128 records in 0.076914124 seconds. Throughput is 1664.1937 records/second. Loss is 0.21368293. Sequential31006cbd's hyper parameters: Current learning rate is 0.004684718448421251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 6016/60000][Iteration 5675][Wall Clock 535.35414332s] Trained 128 records in 0.080564392 seconds. Throughput is 1588.7911 records/second. Loss is 0.15843636. Sequential31006cbd's hyper parameters: Current learning rate is 0.004684279557804009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 6144/60000][Iteration 5676][Wall Clock 535.423702622s] Trained 128 records in 0.069559302 seconds. Throughput is 1840.1566 records/second. Loss is 0.20052. Sequential31006cbd's hyper parameters: Current learning rate is 0.004683840749414521. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 6272/60000][Iteration 5677][Wall Clock 535.495656056s] Trained 128 records in 0.071953434 seconds. Throughput is 1778.9283 records/second. Loss is 0.23614085. Sequential31006cbd's hyper parameters: Current learning rate is 0.004683402023229674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:32 INFO  DistriOptimizer$:408 - [Epoch 13 6400/60000][Iteration 5678][Wall Clock 535.574267692s] Trained 128 records in 0.078611636 seconds. Throughput is 1628.2577 records/second. Loss is 0.18560286. Sequential31006cbd's hyper parameters: Current learning rate is 0.004682963379226375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 6528/60000][Iteration 5679][Wall Clock 535.664148568s] Trained 128 records in 0.089880876 seconds. Throughput is 1424.1072 records/second. Loss is 0.15608478. Sequential31006cbd's hyper parameters: Current learning rate is 0.004682524817381532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 6656/60000][Iteration 5680][Wall Clock 535.750905859s] Trained 128 records in 0.086757291 seconds. Throughput is 1475.3804 records/second. Loss is 0.1345252. Sequential31006cbd's hyper parameters: Current learning rate is 0.004682086337672067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 6784/60000][Iteration 5681][Wall Clock 535.851165337s] Trained 128 records in 0.100259478 seconds. Throughput is 1276.6873 records/second. Loss is 0.1646841. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046816479400749065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 6912/60000][Iteration 5682][Wall Clock 535.930519996s] Trained 128 records in 0.079354659 seconds. Throughput is 1613.0118 records/second. Loss is 0.17855363. Sequential31006cbd's hyper parameters: Current learning rate is 0.004681209624566988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7040/60000][Iteration 5683][Wall Clock 536.022082964s] Trained 128 records in 0.091562968 seconds. Throughput is 1397.9451 records/second. Loss is 0.19991328. Sequential31006cbd's hyper parameters: Current learning rate is 0.004680771391125257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7168/60000][Iteration 5684][Wall Clock 536.104617218s] Trained 128 records in 0.082534254 seconds. Throughput is 1550.8712 records/second. Loss is 0.16050488. Sequential31006cbd's hyper parameters: Current learning rate is 0.004680333239726668. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7296/60000][Iteration 5685][Wall Clock 536.184814981s] Trained 128 records in 0.080197763 seconds. Throughput is 1596.0544 records/second. Loss is 0.14683962. Sequential31006cbd's hyper parameters: Current learning rate is 0.004679895170348184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7424/60000][Iteration 5686][Wall Clock 536.263696402s] Trained 128 records in 0.078881421 seconds. Throughput is 1622.6888 records/second. Loss is 0.17325696. Sequential31006cbd's hyper parameters: Current learning rate is 0.004679457182966776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7552/60000][Iteration 5687][Wall Clock 536.348777494s] Trained 128 records in 0.085081092 seconds. Throughput is 1504.447 records/second. Loss is 0.16705605. Sequential31006cbd's hyper parameters: Current learning rate is 0.004679019277559424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7680/60000][Iteration 5688][Wall Clock 536.443388252s] Trained 128 records in 0.094610758 seconds. Throughput is 1352.9117 records/second. Loss is 0.12970522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046785814541031165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:33 INFO  DistriOptimizer$:408 - [Epoch 13 7808/60000][Iteration 5689][Wall Clock 536.520412855s] Trained 128 records in 0.077024603 seconds. Throughput is 1661.8068 records/second. Loss is 0.22273424. Sequential31006cbd's hyper parameters: Current learning rate is 0.004678143712574851. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 7936/60000][Iteration 5690][Wall Clock 536.616409314s] Trained 128 records in 0.095996459 seconds. Throughput is 1333.3824 records/second. Loss is 0.18940318. Sequential31006cbd's hyper parameters: Current learning rate is 0.004677706052951632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8064/60000][Iteration 5691][Wall Clock 536.707059131s] Trained 128 records in 0.090649817 seconds. Throughput is 1412.0272 records/second. Loss is 0.17879751. Sequential31006cbd's hyper parameters: Current learning rate is 0.004677268475210478. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8192/60000][Iteration 5692][Wall Clock 536.792201536s] Trained 128 records in 0.085142405 seconds. Throughput is 1503.3638 records/second. Loss is 0.19408931. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046768309793284064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8320/60000][Iteration 5693][Wall Clock 536.885056768s] Trained 128 records in 0.092855232 seconds. Throughput is 1378.49 records/second. Loss is 0.19680536. Sequential31006cbd's hyper parameters: Current learning rate is 0.004676393565282455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8448/60000][Iteration 5694][Wall Clock 536.978810948s] Trained 128 records in 0.09375418 seconds. Throughput is 1365.2725 records/second. Loss is 0.26768818. Sequential31006cbd's hyper parameters: Current learning rate is 0.004675956233049658. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8576/60000][Iteration 5695][Wall Clock 537.067289603s] Trained 128 records in 0.088478655 seconds. Throughput is 1446.6766 records/second. Loss is 0.14559805. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046755189826070695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8704/60000][Iteration 5696][Wall Clock 537.163230198s] Trained 128 records in 0.095940595 seconds. Throughput is 1334.1589 records/second. Loss is 0.092795. Sequential31006cbd's hyper parameters: Current learning rate is 0.004675081813931743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8832/60000][Iteration 5697][Wall Clock 537.250128333s] Trained 128 records in 0.086898135 seconds. Throughput is 1472.989 records/second. Loss is 0.28761613. Sequential31006cbd's hyper parameters: Current learning rate is 0.004674644727000748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 8960/60000][Iteration 5698][Wall Clock 537.34355026s] Trained 128 records in 0.093421927 seconds. Throughput is 1370.128 records/second. Loss is 0.20489204. Sequential31006cbd's hyper parameters: Current learning rate is 0.004674207721791156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 9088/60000][Iteration 5699][Wall Clock 537.426620485s] Trained 128 records in 0.083070225 seconds. Throughput is 1540.865 records/second. Loss is 0.15291029. Sequential31006cbd's hyper parameters: Current learning rate is 0.004673770798280053. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:34 INFO  DistriOptimizer$:408 - [Epoch 13 9216/60000][Iteration 5700][Wall Clock 537.50515547s] Trained 128 records in 0.078534985 seconds. Throughput is 1629.8469 records/second. Loss is 0.20214613. Sequential31006cbd's hyper parameters: Current learning rate is 0.004673333956444527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 9344/60000][Iteration 5701][Wall Clock 537.595402305s] Trained 128 records in 0.090246835 seconds. Throughput is 1418.3323 records/second. Loss is 0.25216946. Sequential31006cbd's hyper parameters: Current learning rate is 0.004672897196261682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 9472/60000][Iteration 5702][Wall Clock 537.693044001s] Trained 128 records in 0.097641696 seconds. Throughput is 1310.9153 records/second. Loss is 0.22300762. Sequential31006cbd's hyper parameters: Current learning rate is 0.004672460517708625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 9600/60000][Iteration 5703][Wall Clock 537.780889092s] Trained 128 records in 0.087845091 seconds. Throughput is 1457.1104 records/second. Loss is 0.15499544. Sequential31006cbd's hyper parameters: Current learning rate is 0.004672023920762474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 9728/60000][Iteration 5704][Wall Clock 537.874291449s] Trained 128 records in 0.093402357 seconds. Throughput is 1370.4152 records/second. Loss is 0.096395776. Sequential31006cbd's hyper parameters: Current learning rate is 0.004671587405400355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 9856/60000][Iteration 5705][Wall Clock 538.009075294s] Trained 128 records in 0.134783845 seconds. Throughput is 949.6687 records/second. Loss is 0.2630962. Sequential31006cbd's hyper parameters: Current learning rate is 0.004671150971599402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 9984/60000][Iteration 5706][Wall Clock 538.100400698s] Trained 128 records in 0.091325404 seconds. Throughput is 1401.5815 records/second. Loss is 0.172394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004670714619336758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 10112/60000][Iteration 5707][Wall Clock 538.218441366s] Trained 128 records in 0.118040668 seconds. Throughput is 1084.3721 records/second. Loss is 0.20716628. Sequential31006cbd's hyper parameters: Current learning rate is 0.004670278348589576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 10240/60000][Iteration 5708][Wall Clock 538.305108964s] Trained 128 records in 0.086667598 seconds. Throughput is 1476.9072 records/second. Loss is 0.14199178. Sequential31006cbd's hyper parameters: Current learning rate is 0.004669842159335014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 10368/60000][Iteration 5709][Wall Clock 538.396394201s] Trained 128 records in 0.091285237 seconds. Throughput is 1402.1982 records/second. Loss is 0.13576297. Sequential31006cbd's hyper parameters: Current learning rate is 0.004669406051550243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 10496/60000][Iteration 5710][Wall Clock 538.480589487s] Trained 128 records in 0.084195286 seconds. Throughput is 1520.2751 records/second. Loss is 0.255528. Sequential31006cbd's hyper parameters: Current learning rate is 0.004668970025212439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:35 INFO  DistriOptimizer$:408 - [Epoch 13 10624/60000][Iteration 5711][Wall Clock 538.555485368s] Trained 128 records in 0.074895881 seconds. Throughput is 1709.0392 records/second. Loss is 0.24101734. Sequential31006cbd's hyper parameters: Current learning rate is 0.004668534080298785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 10752/60000][Iteration 5712][Wall Clock 538.645822455s] Trained 128 records in 0.090337087 seconds. Throughput is 1416.9153 records/second. Loss is 0.24931306. Sequential31006cbd's hyper parameters: Current learning rate is 0.004668098216786482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 10880/60000][Iteration 5713][Wall Clock 538.728012254s] Trained 128 records in 0.082189799 seconds. Throughput is 1557.3708 records/second. Loss is 0.22390947. Sequential31006cbd's hyper parameters: Current learning rate is 0.004667662434652726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11008/60000][Iteration 5714][Wall Clock 538.822061322s] Trained 128 records in 0.094049068 seconds. Throughput is 1360.9917 records/second. Loss is 0.2014023. Sequential31006cbd's hyper parameters: Current learning rate is 0.004667226733874732. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11136/60000][Iteration 5715][Wall Clock 538.929927939s] Trained 128 records in 0.107866617 seconds. Throughput is 1186.6508 records/second. Loss is 0.18658525. Sequential31006cbd's hyper parameters: Current learning rate is 0.004666791114429717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11264/60000][Iteration 5716][Wall Clock 539.01937315s] Trained 128 records in 0.089445211 seconds. Throughput is 1431.0436 records/second. Loss is 0.24007183. Sequential31006cbd's hyper parameters: Current learning rate is 0.004666355576294914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11392/60000][Iteration 5717][Wall Clock 539.111902091s] Trained 128 records in 0.092528941 seconds. Throughput is 1383.351 records/second. Loss is 0.18893239. Sequential31006cbd's hyper parameters: Current learning rate is 0.004665920119447555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11520/60000][Iteration 5718][Wall Clock 539.203367927s] Trained 128 records in 0.091465836 seconds. Throughput is 1399.4296 records/second. Loss is 0.16479567. Sequential31006cbd's hyper parameters: Current learning rate is 0.004665484743864888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11648/60000][Iteration 5719][Wall Clock 539.280860424s] Trained 128 records in 0.077492497 seconds. Throughput is 1651.7728 records/second. Loss is 0.15676303. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046650494495241645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11776/60000][Iteration 5720][Wall Clock 539.367611316s] Trained 128 records in 0.086750892 seconds. Throughput is 1475.4891 records/second. Loss is 0.17825763. Sequential31006cbd's hyper parameters: Current learning rate is 0.004664614236402649. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 11904/60000][Iteration 5721][Wall Clock 539.456550998s] Trained 128 records in 0.088939682 seconds. Throughput is 1439.1776 records/second. Loss is 0.17199525. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046641791044776115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:36 INFO  DistriOptimizer$:408 - [Epoch 13 12032/60000][Iteration 5722][Wall Clock 539.542197056s] Trained 128 records in 0.085646058 seconds. Throughput is 1494.523 records/second. Loss is 0.1606125. Sequential31006cbd's hyper parameters: Current learning rate is 0.004663744053726332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12160/60000][Iteration 5723][Wall Clock 539.642970595s] Trained 128 records in 0.100773539 seconds. Throughput is 1270.1748 records/second. Loss is 0.1985473. Sequential31006cbd's hyper parameters: Current learning rate is 0.004663309084126096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12288/60000][Iteration 5724][Wall Clock 539.7455244s] Trained 128 records in 0.102553805 seconds. Throughput is 1248.1252 records/second. Loss is 0.14933984. Sequential31006cbd's hyper parameters: Current learning rate is 0.004662874195654201. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12416/60000][Iteration 5725][Wall Clock 539.868430711s] Trained 128 records in 0.122906311 seconds. Throughput is 1041.4436 records/second. Loss is 0.13188493. Sequential31006cbd's hyper parameters: Current learning rate is 0.004662439388287952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12544/60000][Iteration 5726][Wall Clock 539.957362042s] Trained 128 records in 0.088931331 seconds. Throughput is 1439.3127 records/second. Loss is 0.14401828. Sequential31006cbd's hyper parameters: Current learning rate is 0.004662004662004662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12672/60000][Iteration 5727][Wall Clock 540.055250963s] Trained 128 records in 0.097888921 seconds. Throughput is 1307.6045 records/second. Loss is 0.18646526. Sequential31006cbd's hyper parameters: Current learning rate is 0.004661570016781652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12800/60000][Iteration 5728][Wall Clock 540.14654244s] Trained 128 records in 0.091291477 seconds. Throughput is 1402.1024 records/second. Loss is 0.09724247. Sequential31006cbd's hyper parameters: Current learning rate is 0.004661135452596252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 12928/60000][Iteration 5729][Wall Clock 540.23127687s] Trained 128 records in 0.08473443 seconds. Throughput is 1510.6019 records/second. Loss is 0.19161029. Sequential31006cbd's hyper parameters: Current learning rate is 0.004660700969425802. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 13056/60000][Iteration 5730][Wall Clock 540.314045797s] Trained 128 records in 0.082768927 seconds. Throughput is 1546.4741 records/second. Loss is 0.25342122. Sequential31006cbd's hyper parameters: Current learning rate is 0.004660266567247646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 13184/60000][Iteration 5731][Wall Clock 540.396425311s] Trained 128 records in 0.082379514 seconds. Throughput is 1553.7844 records/second. Loss is 0.2711201. Sequential31006cbd's hyper parameters: Current learning rate is 0.004659832246039143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:37 INFO  DistriOptimizer$:408 - [Epoch 13 13312/60000][Iteration 5732][Wall Clock 540.487132004s] Trained 128 records in 0.090706693 seconds. Throughput is 1411.1417 records/second. Loss is 0.17453413. Sequential31006cbd's hyper parameters: Current learning rate is 0.004659398005777653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 13440/60000][Iteration 5733][Wall Clock 540.601890385s] Trained 128 records in 0.114758381 seconds. Throughput is 1115.387 records/second. Loss is 0.16937065. Sequential31006cbd's hyper parameters: Current learning rate is 0.004658963846440552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 13568/60000][Iteration 5734][Wall Clock 540.699846991s] Trained 128 records in 0.097956606 seconds. Throughput is 1306.701 records/second. Loss is 0.22454566. Sequential31006cbd's hyper parameters: Current learning rate is 0.004658529768005217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 13696/60000][Iteration 5735][Wall Clock 540.779726748s] Trained 128 records in 0.079879757 seconds. Throughput is 1602.4086 records/second. Loss is 0.13936356. Sequential31006cbd's hyper parameters: Current learning rate is 0.004658095770449041. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 13824/60000][Iteration 5736][Wall Clock 540.867652141s] Trained 128 records in 0.087925393 seconds. Throughput is 1455.7798 records/second. Loss is 0.24405524. Sequential31006cbd's hyper parameters: Current learning rate is 0.004657661853749417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 13952/60000][Iteration 5737][Wall Clock 540.949337442s] Trained 128 records in 0.081685301 seconds. Throughput is 1566.9894 records/second. Loss is 0.17560978. Sequential31006cbd's hyper parameters: Current learning rate is 0.004657228017883756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14080/60000][Iteration 5738][Wall Clock 541.031811564s] Trained 128 records in 0.082474122 seconds. Throughput is 1552.002 records/second. Loss is 0.106769025. Sequential31006cbd's hyper parameters: Current learning rate is 0.004656794262829468. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14208/60000][Iteration 5739][Wall Clock 541.112059803s] Trained 128 records in 0.080248239 seconds. Throughput is 1595.0507 records/second. Loss is 0.1603033. Sequential31006cbd's hyper parameters: Current learning rate is 0.004656360588563979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14336/60000][Iteration 5740][Wall Clock 541.19129221s] Trained 128 records in 0.079232407 seconds. Throughput is 1615.5005 records/second. Loss is 0.23481734. Sequential31006cbd's hyper parameters: Current learning rate is 0.004655926995064717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14464/60000][Iteration 5741][Wall Clock 541.279323436s] Trained 128 records in 0.088031226 seconds. Throughput is 1454.0295 records/second. Loss is 0.08719076. Sequential31006cbd's hyper parameters: Current learning rate is 0.004655493482309124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14592/60000][Iteration 5742][Wall Clock 541.365704048s] Trained 128 records in 0.086380612 seconds. Throughput is 1481.8141 records/second. Loss is 0.14653604. Sequential31006cbd's hyper parameters: Current learning rate is 0.004655060050274648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14720/60000][Iteration 5743][Wall Clock 541.44470062s] Trained 128 records in 0.078996572 seconds. Throughput is 1620.3235 records/second. Loss is 0.20929678. Sequential31006cbd's hyper parameters: Current learning rate is 0.004654626698938745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:38 INFO  DistriOptimizer$:408 - [Epoch 13 14848/60000][Iteration 5744][Wall Clock 541.526885239s] Trained 128 records in 0.082184619 seconds. Throughput is 1557.469 records/second. Loss is 0.1798199. Sequential31006cbd's hyper parameters: Current learning rate is 0.004654193428278879. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 14976/60000][Iteration 5745][Wall Clock 541.606606412s] Trained 128 records in 0.079721173 seconds. Throughput is 1605.596 records/second. Loss is 0.12795155. Sequential31006cbd's hyper parameters: Current learning rate is 0.004653760238272524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15104/60000][Iteration 5746][Wall Clock 541.694706064s] Trained 128 records in 0.088099652 seconds. Throughput is 1452.9001 records/second. Loss is 0.20374933. Sequential31006cbd's hyper parameters: Current learning rate is 0.004653327128897162. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15232/60000][Iteration 5747][Wall Clock 541.785942324s] Trained 128 records in 0.09123626 seconds. Throughput is 1402.9509 records/second. Loss is 0.29330978. Sequential31006cbd's hyper parameters: Current learning rate is 0.004652894100130281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15360/60000][Iteration 5748][Wall Clock 541.871230234s] Trained 128 records in 0.08528791 seconds. Throughput is 1500.7988 records/second. Loss is 0.15317121. Sequential31006cbd's hyper parameters: Current learning rate is 0.004652461151949381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15488/60000][Iteration 5749][Wall Clock 541.970736241s] Trained 128 records in 0.099506007 seconds. Throughput is 1286.3545 records/second. Loss is 0.21547431. Sequential31006cbd's hyper parameters: Current learning rate is 0.004652028284331969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15616/60000][Iteration 5750][Wall Clock 542.06382015s] Trained 128 records in 0.093083909 seconds. Throughput is 1375.1034 records/second. Loss is 0.18356173. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046515954972555585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15744/60000][Iteration 5751][Wall Clock 542.157709705s] Trained 128 records in 0.093889555 seconds. Throughput is 1363.304 records/second. Loss is 0.12016374. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046511627906976735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 15872/60000][Iteration 5752][Wall Clock 542.249405625s] Trained 128 records in 0.09169592 seconds. Throughput is 1395.9182 records/second. Loss is 0.20849603. Sequential31006cbd's hyper parameters: Current learning rate is 0.004650730164635848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 16000/60000][Iteration 5753][Wall Clock 542.352478636s] Trained 128 records in 0.103073011 seconds. Throughput is 1241.8383 records/second. Loss is 0.21669397. Sequential31006cbd's hyper parameters: Current learning rate is 0.004650297619047618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 16128/60000][Iteration 5754][Wall Clock 542.431460939s] Trained 128 records in 0.078982303 seconds. Throughput is 1620.6162 records/second. Loss is 0.132186. Sequential31006cbd's hyper parameters: Current learning rate is 0.004649865153910537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:39 INFO  DistriOptimizer$:408 - [Epoch 13 16256/60000][Iteration 5755][Wall Clock 542.513120684s] Trained 128 records in 0.081659745 seconds. Throughput is 1567.4799 records/second. Loss is 0.13034534. Sequential31006cbd's hyper parameters: Current learning rate is 0.004649432769202157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 16384/60000][Iteration 5756][Wall Clock 542.602688744s] Trained 128 records in 0.08956806 seconds. Throughput is 1429.0808 records/second. Loss is 0.2085162. Sequential31006cbd's hyper parameters: Current learning rate is 0.004649000464900047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 16512/60000][Iteration 5757][Wall Clock 542.68530128s] Trained 128 records in 0.082612536 seconds. Throughput is 1549.4016 records/second. Loss is 0.11211644. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046485682409817776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 16640/60000][Iteration 5758][Wall Clock 542.80941932s] Trained 128 records in 0.12411804 seconds. Throughput is 1031.2764 records/second. Loss is 0.3191045. Sequential31006cbd's hyper parameters: Current learning rate is 0.004648136097424933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 16768/60000][Iteration 5759][Wall Clock 542.889934632s] Trained 128 records in 0.080515312 seconds. Throughput is 1589.7598 records/second. Loss is 0.20318171. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046477040342071015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 16896/60000][Iteration 5760][Wall Clock 542.966663737s] Trained 128 records in 0.076729105 seconds. Throughput is 1668.2067 records/second. Loss is 0.14394394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004647272051305883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17024/60000][Iteration 5761][Wall Clock 543.042569514s] Trained 128 records in 0.075905777 seconds. Throughput is 1686.3011 records/second. Loss is 0.2059578. Sequential31006cbd's hyper parameters: Current learning rate is 0.004646840148698885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17152/60000][Iteration 5762][Wall Clock 543.119956098s] Trained 128 records in 0.077386584 seconds. Throughput is 1654.0336 records/second. Loss is 0.23908612. Sequential31006cbd's hyper parameters: Current learning rate is 0.004646408326363721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17280/60000][Iteration 5763][Wall Clock 543.199034219s] Trained 128 records in 0.079078121 seconds. Throughput is 1618.6525 records/second. Loss is 0.3296766. Sequential31006cbd's hyper parameters: Current learning rate is 0.004645976584278015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17408/60000][Iteration 5764][Wall Clock 543.288411429s] Trained 128 records in 0.08937721 seconds. Throughput is 1432.1324 records/second. Loss is 0.14695898. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046455449224194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17536/60000][Iteration 5765][Wall Clock 543.371201061s] Trained 128 records in 0.082789632 seconds. Throughput is 1546.0874 records/second. Loss is 0.17954107. Sequential31006cbd's hyper parameters: Current learning rate is 0.004645113340765515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17664/60000][Iteration 5766][Wall Clock 543.458587099s] Trained 128 records in 0.087386038 seconds. Throughput is 1464.7649 records/second. Loss is 0.19262516. Sequential31006cbd's hyper parameters: Current learning rate is 0.004644681839294009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:40 INFO  DistriOptimizer$:408 - [Epoch 13 17792/60000][Iteration 5767][Wall Clock 543.560830681s] Trained 128 records in 0.102243582 seconds. Throughput is 1251.9124 records/second. Loss is 0.12717897. Sequential31006cbd's hyper parameters: Current learning rate is 0.004644250417982537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 17920/60000][Iteration 5768][Wall Clock 543.646831853s] Trained 128 records in 0.086001172 seconds. Throughput is 1488.3518 records/second. Loss is 0.26043472. Sequential31006cbd's hyper parameters: Current learning rate is 0.004643819076808768. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18048/60000][Iteration 5769][Wall Clock 543.7239239s] Trained 128 records in 0.077092047 seconds. Throughput is 1660.3529 records/second. Loss is 0.16741304. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046433878157503715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18176/60000][Iteration 5770][Wall Clock 543.801745912s] Trained 128 records in 0.077822012 seconds. Throughput is 1644.7788 records/second. Loss is 0.3014835. Sequential31006cbd's hyper parameters: Current learning rate is 0.00464295663478503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18304/60000][Iteration 5771][Wall Clock 543.880645808s] Trained 128 records in 0.078899896 seconds. Throughput is 1622.3088 records/second. Loss is 0.14959861. Sequential31006cbd's hyper parameters: Current learning rate is 0.004642525533890437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18432/60000][Iteration 5772][Wall Clock 543.967254084s] Trained 128 records in 0.086608276 seconds. Throughput is 1477.9188 records/second. Loss is 0.17455576. Sequential31006cbd's hyper parameters: Current learning rate is 0.004642094513044285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18560/60000][Iteration 5773][Wall Clock 544.044659819s] Trained 128 records in 0.077405735 seconds. Throughput is 1653.6243 records/second. Loss is 0.12993872. Sequential31006cbd's hyper parameters: Current learning rate is 0.004641663572224285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18688/60000][Iteration 5774][Wall Clock 544.120988316s] Trained 128 records in 0.076328497 seconds. Throughput is 1676.9622 records/second. Loss is 0.1210252. Sequential31006cbd's hyper parameters: Current learning rate is 0.00464123271140815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18816/60000][Iteration 5775][Wall Clock 544.21170123s] Trained 128 records in 0.090712914 seconds. Throughput is 1411.045 records/second. Loss is 0.12941995. Sequential31006cbd's hyper parameters: Current learning rate is 0.004640801930573603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 18944/60000][Iteration 5776][Wall Clock 544.319466229s] Trained 128 records in 0.107764999 seconds. Throughput is 1187.7698 records/second. Loss is 0.16898787. Sequential31006cbd's hyper parameters: Current learning rate is 0.004640371229698376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 19072/60000][Iteration 5777][Wall Clock 544.394005698s] Trained 128 records in 0.074539469 seconds. Throughput is 1717.211 records/second. Loss is 0.15643784. Sequential31006cbd's hyper parameters: Current learning rate is 0.004639940608760208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 19200/60000][Iteration 5778][Wall Clock 544.466602875s] Trained 128 records in 0.072597177 seconds. Throughput is 1763.1539 records/second. Loss is 0.16115451. Sequential31006cbd's hyper parameters: Current learning rate is 0.004639510067736847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:41 INFO  DistriOptimizer$:408 - [Epoch 13 19328/60000][Iteration 5779][Wall Clock 544.549901194s] Trained 128 records in 0.083298319 seconds. Throughput is 1536.6456 records/second. Loss is 0.20792225. Sequential31006cbd's hyper parameters: Current learning rate is 0.00463907960660605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 19456/60000][Iteration 5780][Wall Clock 544.635769981s] Trained 128 records in 0.085868787 seconds. Throughput is 1490.6465 records/second. Loss is 0.1626169. Sequential31006cbd's hyper parameters: Current learning rate is 0.004638649225345579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 19584/60000][Iteration 5781][Wall Clock 544.717770663s] Trained 128 records in 0.082000682 seconds. Throughput is 1560.9626 records/second. Loss is 0.21432394. Sequential31006cbd's hyper parameters: Current learning rate is 0.00463821892393321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 19712/60000][Iteration 5782][Wall Clock 544.796505447s] Trained 128 records in 0.078734784 seconds. Throughput is 1625.7109 records/second. Loss is 0.1447941. Sequential31006cbd's hyper parameters: Current learning rate is 0.004637788702346721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 19840/60000][Iteration 5783][Wall Clock 544.873604346s] Trained 128 records in 0.077098899 seconds. Throughput is 1660.2053 records/second. Loss is 0.20256501. Sequential31006cbd's hyper parameters: Current learning rate is 0.004637358560563903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 19968/60000][Iteration 5784][Wall Clock 544.988171624s] Trained 128 records in 0.114567278 seconds. Throughput is 1117.2474 records/second. Loss is 0.1449641. Sequential31006cbd's hyper parameters: Current learning rate is 0.004636928498562552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 20096/60000][Iteration 5785][Wall Clock 545.06764309s] Trained 128 records in 0.079471466 seconds. Throughput is 1610.6409 records/second. Loss is 0.16304089. Sequential31006cbd's hyper parameters: Current learning rate is 0.004636498516320474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 20224/60000][Iteration 5786][Wall Clock 545.147597441s] Trained 128 records in 0.079954351 seconds. Throughput is 1600.9136 records/second. Loss is 0.20043081. Sequential31006cbd's hyper parameters: Current learning rate is 0.004636068613815485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 20352/60000][Iteration 5787][Wall Clock 545.239205618s] Trained 128 records in 0.091608177 seconds. Throughput is 1397.2552 records/second. Loss is 0.16383524. Sequential31006cbd's hyper parameters: Current learning rate is 0.004635638791025403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 20480/60000][Iteration 5788][Wall Clock 545.322882703s] Trained 128 records in 0.083677085 seconds. Throughput is 1529.6901 records/second. Loss is 0.2666452. Sequential31006cbd's hyper parameters: Current learning rate is 0.004635209047928062. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 20608/60000][Iteration 5789][Wall Clock 545.409237076s] Trained 128 records in 0.086354373 seconds. Throughput is 1482.2642 records/second. Loss is 0.18970507. Sequential31006cbd's hyper parameters: Current learning rate is 0.004634779384501298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:42 INFO  DistriOptimizer$:408 - [Epoch 13 20736/60000][Iteration 5790][Wall Clock 545.486699149s] Trained 128 records in 0.077462073 seconds. Throughput is 1652.4216 records/second. Loss is 0.18668541. Sequential31006cbd's hyper parameters: Current learning rate is 0.004634349800722959. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 20864/60000][Iteration 5791][Wall Clock 545.568505587s] Trained 128 records in 0.081806438 seconds. Throughput is 1564.6691 records/second. Loss is 0.1988574. Sequential31006cbd's hyper parameters: Current learning rate is 0.004633920296570899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 20992/60000][Iteration 5792][Wall Clock 545.666754055s] Trained 128 records in 0.098248468 seconds. Throughput is 1302.8193 records/second. Loss is 0.22533289. Sequential31006cbd's hyper parameters: Current learning rate is 0.004633490872022982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21120/60000][Iteration 5793][Wall Clock 545.749050481s] Trained 128 records in 0.082296426 seconds. Throughput is 1555.3531 records/second. Loss is 0.17067727. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046330615270570785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21248/60000][Iteration 5794][Wall Clock 545.827074505s] Trained 128 records in 0.078024024 seconds. Throughput is 1640.5204 records/second. Loss is 0.18502282. Sequential31006cbd's hyper parameters: Current learning rate is 0.004632632261651071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21376/60000][Iteration 5795][Wall Clock 545.90864599s] Trained 128 records in 0.081571485 seconds. Throughput is 1569.1759 records/second. Loss is 0.23442543. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046322030757828415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21504/60000][Iteration 5796][Wall Clock 546.002454437s] Trained 128 records in 0.093808447 seconds. Throughput is 1364.4827 records/second. Loss is 0.1262728. Sequential31006cbd's hyper parameters: Current learning rate is 0.004631773969430293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21632/60000][Iteration 5797][Wall Clock 546.085077758s] Trained 128 records in 0.082623321 seconds. Throughput is 1549.1995 records/second. Loss is 0.12385692. Sequential31006cbd's hyper parameters: Current learning rate is 0.004631344942571322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21760/60000][Iteration 5798][Wall Clock 546.177506307s] Trained 128 records in 0.092428549 seconds. Throughput is 1384.8535 records/second. Loss is 0.20072356. Sequential31006cbd's hyper parameters: Current learning rate is 0.004630915995183848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 21888/60000][Iteration 5799][Wall Clock 546.255128647s] Trained 128 records in 0.07762234 seconds. Throughput is 1649.0099 records/second. Loss is 0.23637411. Sequential31006cbd's hyper parameters: Current learning rate is 0.004630487127245786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 22016/60000][Iteration 5800][Wall Clock 546.336421517s] Trained 128 records in 0.08129287 seconds. Throughput is 1574.5538 records/second. Loss is 0.17079636. Sequential31006cbd's hyper parameters: Current learning rate is 0.004630058338735068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 22144/60000][Iteration 5801][Wall Clock 546.416164727s] Trained 128 records in 0.07974321 seconds. Throughput is 1605.1525 records/second. Loss is 0.22826232. Sequential31006cbd's hyper parameters: Current learning rate is 0.004629629629629629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:43 INFO  DistriOptimizer$:408 - [Epoch 13 22272/60000][Iteration 5802][Wall Clock 546.501624688s] Trained 128 records in 0.085459961 seconds. Throughput is 1497.7773 records/second. Loss is 0.14835814. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046292009999074155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 22400/60000][Iteration 5803][Wall Clock 546.587444482s] Trained 128 records in 0.085819794 seconds. Throughput is 1491.4973 records/second. Loss is 0.24802801. Sequential31006cbd's hyper parameters: Current learning rate is 0.00462877244954638. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 22528/60000][Iteration 5804][Wall Clock 546.671772531s] Trained 128 records in 0.084328049 seconds. Throughput is 1517.8817 records/second. Loss is 0.18499501. Sequential31006cbd's hyper parameters: Current learning rate is 0.004628343978524484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 22656/60000][Iteration 5805][Wall Clock 546.759429654s] Trained 128 records in 0.087657123 seconds. Throughput is 1460.235 records/second. Loss is 0.19847417. Sequential31006cbd's hyper parameters: Current learning rate is 0.004627915586819697. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 22784/60000][Iteration 5806][Wall Clock 546.842047617s] Trained 128 records in 0.082617963 seconds. Throughput is 1549.2999 records/second. Loss is 0.14363879. Sequential31006cbd's hyper parameters: Current learning rate is 0.004627487274409995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 22912/60000][Iteration 5807][Wall Clock 546.922682192s] Trained 128 records in 0.080634575 seconds. Throughput is 1587.4084 records/second. Loss is 0.10015504. Sequential31006cbd's hyper parameters: Current learning rate is 0.004627059041273367. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23040/60000][Iteration 5808][Wall Clock 547.003776592s] Trained 128 records in 0.0810944 seconds. Throughput is 1578.4073 records/second. Loss is 0.15967776. Sequential31006cbd's hyper parameters: Current learning rate is 0.004626630887387804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23168/60000][Iteration 5809][Wall Clock 547.08151826s] Trained 128 records in 0.077741668 seconds. Throughput is 1646.4788 records/second. Loss is 0.1610461. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046262028127313105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23296/60000][Iteration 5810][Wall Clock 547.175042983s] Trained 128 records in 0.093524723 seconds. Throughput is 1368.6221 records/second. Loss is 0.21063718. Sequential31006cbd's hyper parameters: Current learning rate is 0.004625774817281894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23424/60000][Iteration 5811][Wall Clock 547.266870647s] Trained 128 records in 0.091827664 seconds. Throughput is 1393.9155 records/second. Loss is 0.22357117. Sequential31006cbd's hyper parameters: Current learning rate is 0.004625346901017576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23552/60000][Iteration 5812][Wall Clock 547.357028182s] Trained 128 records in 0.090157535 seconds. Throughput is 1419.737 records/second. Loss is 0.16396964. Sequential31006cbd's hyper parameters: Current learning rate is 0.004624919063916381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23680/60000][Iteration 5813][Wall Clock 547.444330072s] Trained 128 records in 0.08730189 seconds. Throughput is 1466.1768 records/second. Loss is 0.10266465. Sequential31006cbd's hyper parameters: Current learning rate is 0.004624491305956345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:44 INFO  DistriOptimizer$:408 - [Epoch 13 23808/60000][Iteration 5814][Wall Clock 547.536464708s] Trained 128 records in 0.092134636 seconds. Throughput is 1389.2712 records/second. Loss is 0.22724435. Sequential31006cbd's hyper parameters: Current learning rate is 0.004624063627115508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 23936/60000][Iteration 5815][Wall Clock 547.617567142s] Trained 128 records in 0.081102434 seconds. Throughput is 1578.2511 records/second. Loss is 0.21104911. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046236360273719255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24064/60000][Iteration 5816][Wall Clock 547.70035463s] Trained 128 records in 0.082787488 seconds. Throughput is 1546.1273 records/second. Loss is 0.16251427. Sequential31006cbd's hyper parameters: Current learning rate is 0.004623208506703652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24192/60000][Iteration 5817][Wall Clock 547.793818483s] Trained 128 records in 0.093463853 seconds. Throughput is 1369.5134 records/second. Loss is 0.25041178. Sequential31006cbd's hyper parameters: Current learning rate is 0.004622781065088758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24320/60000][Iteration 5818][Wall Clock 547.86635486s] Trained 128 records in 0.072536377 seconds. Throughput is 1764.6318 records/second. Loss is 0.18051642. Sequential31006cbd's hyper parameters: Current learning rate is 0.004622353702505315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24448/60000][Iteration 5819][Wall Clock 547.95481156s] Trained 128 records in 0.0884567 seconds. Throughput is 1447.0356 records/second. Loss is 0.19150184. Sequential31006cbd's hyper parameters: Current learning rate is 0.004621926418931411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24576/60000][Iteration 5820][Wall Clock 548.036802469s] Trained 128 records in 0.081990909 seconds. Throughput is 1561.1486 records/second. Loss is 0.21222158. Sequential31006cbd's hyper parameters: Current learning rate is 0.004621499214345133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24704/60000][Iteration 5821][Wall Clock 548.131525007s] Trained 128 records in 0.094722538 seconds. Throughput is 1351.3152 records/second. Loss is 0.21340941. Sequential31006cbd's hyper parameters: Current learning rate is 0.004621072088724584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24832/60000][Iteration 5822][Wall Clock 548.217265732s] Trained 128 records in 0.085740725 seconds. Throughput is 1492.8729 records/second. Loss is 0.26720876. Sequential31006cbd's hyper parameters: Current learning rate is 0.00462064504204787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 24960/60000][Iteration 5823][Wall Clock 548.298844089s] Trained 128 records in 0.081578357 seconds. Throughput is 1569.0436 records/second. Loss is 0.13893291. Sequential31006cbd's hyper parameters: Current learning rate is 0.004620218074293106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 25088/60000][Iteration 5824][Wall Clock 548.3814117s] Trained 128 records in 0.082567611 seconds. Throughput is 1550.2448 records/second. Loss is 0.14246152. Sequential31006cbd's hyper parameters: Current learning rate is 0.004619791185438418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:45 INFO  DistriOptimizer$:408 - [Epoch 13 25216/60000][Iteration 5825][Wall Clock 548.46244146s] Trained 128 records in 0.08102976 seconds. Throughput is 1579.6666 records/second. Loss is 0.18929291. Sequential31006cbd's hyper parameters: Current learning rate is 0.004619364375461937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 25344/60000][Iteration 5826][Wall Clock 548.542825161s] Trained 128 records in 0.080383701 seconds. Throughput is 1592.3625 records/second. Loss is 0.12970291. Sequential31006cbd's hyper parameters: Current learning rate is 0.004618937644341801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 25472/60000][Iteration 5827][Wall Clock 548.645528017s] Trained 128 records in 0.102702856 seconds. Throughput is 1246.314 records/second. Loss is 0.17728053. Sequential31006cbd's hyper parameters: Current learning rate is 0.004618510992056161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 25600/60000][Iteration 5828][Wall Clock 548.745343186s] Trained 128 records in 0.099815169 seconds. Throughput is 1282.3702 records/second. Loss is 0.1747762. Sequential31006cbd's hyper parameters: Current learning rate is 0.004618084418583172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 25728/60000][Iteration 5829][Wall Clock 548.831444762s] Trained 128 records in 0.086101576 seconds. Throughput is 1486.6162 records/second. Loss is 0.2192205. Sequential31006cbd's hyper parameters: Current learning rate is 0.004617657923900997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 25856/60000][Iteration 5830][Wall Clock 548.928677555s] Trained 128 records in 0.097232793 seconds. Throughput is 1316.4282 records/second. Loss is 0.18408951. Sequential31006cbd's hyper parameters: Current learning rate is 0.004617231507987811. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 25984/60000][Iteration 5831][Wall Clock 549.015148163s] Trained 128 records in 0.086470608 seconds. Throughput is 1480.2717 records/second. Loss is 0.23738195. Sequential31006cbd's hyper parameters: Current learning rate is 0.004616805170821791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 26112/60000][Iteration 5832][Wall Clock 549.10382085s] Trained 128 records in 0.088672687 seconds. Throughput is 1443.511 records/second. Loss is 0.16011094. Sequential31006cbd's hyper parameters: Current learning rate is 0.004616378912381129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 26240/60000][Iteration 5833][Wall Clock 549.185231075s] Trained 128 records in 0.081410225 seconds. Throughput is 1572.2842 records/second. Loss is 0.13690947. Sequential31006cbd's hyper parameters: Current learning rate is 0.004615952732644017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 26368/60000][Iteration 5834][Wall Clock 549.270327958s] Trained 128 records in 0.085096883 seconds. Throughput is 1504.168 records/second. Loss is 0.24358828. Sequential31006cbd's hyper parameters: Current learning rate is 0.004615526631588665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 26496/60000][Iteration 5835][Wall Clock 549.363988701s] Trained 128 records in 0.093660743 seconds. Throughput is 1366.6345 records/second. Loss is 0.20746733. Sequential31006cbd's hyper parameters: Current learning rate is 0.00461510060919328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 26624/60000][Iteration 5836][Wall Clock 549.451677024s] Trained 128 records in 0.087688323 seconds. Throughput is 1459.7155 records/second. Loss is 0.1563513. Sequential31006cbd's hyper parameters: Current learning rate is 0.004614674665436087. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:46 INFO  DistriOptimizer$:408 - [Epoch 13 26752/60000][Iteration 5837][Wall Clock 549.535245395s] Trained 128 records in 0.083568371 seconds. Throughput is 1531.6799 records/second. Loss is 0.18984292. Sequential31006cbd's hyper parameters: Current learning rate is 0.004614248800295311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 26880/60000][Iteration 5838][Wall Clock 549.617907344s] Trained 128 records in 0.082661949 seconds. Throughput is 1548.4755 records/second. Loss is 0.15355478. Sequential31006cbd's hyper parameters: Current learning rate is 0.004613823013749193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27008/60000][Iteration 5839][Wall Clock 549.702153743s] Trained 128 records in 0.084246399 seconds. Throughput is 1519.3528 records/second. Loss is 0.21095385. Sequential31006cbd's hyper parameters: Current learning rate is 0.004613397305775973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27136/60000][Iteration 5840][Wall Clock 549.78383723s] Trained 128 records in 0.081683487 seconds. Throughput is 1567.0242 records/second. Loss is 0.19061013. Sequential31006cbd's hyper parameters: Current learning rate is 0.004612971676353908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27264/60000][Iteration 5841][Wall Clock 549.861792571s] Trained 128 records in 0.077955341 seconds. Throughput is 1641.9657 records/second. Loss is 0.15616001. Sequential31006cbd's hyper parameters: Current learning rate is 0.004612546125461255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27392/60000][Iteration 5842][Wall Clock 549.95340511s] Trained 128 records in 0.091612539 seconds. Throughput is 1397.1886 records/second. Loss is 0.16011705. Sequential31006cbd's hyper parameters: Current learning rate is 0.004612120653076284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27520/60000][Iteration 5843][Wall Clock 550.043278857s] Trained 128 records in 0.089873747 seconds. Throughput is 1424.2201 records/second. Loss is 0.21836357. Sequential31006cbd's hyper parameters: Current learning rate is 0.004611695259177273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27648/60000][Iteration 5844][Wall Clock 550.120102118s] Trained 128 records in 0.076823261 seconds. Throughput is 1666.162 records/second. Loss is 0.19644892. Sequential31006cbd's hyper parameters: Current learning rate is 0.004611269943742506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27776/60000][Iteration 5845][Wall Clock 550.199595502s] Trained 128 records in 0.079493384 seconds. Throughput is 1610.1969 records/second. Loss is 0.15505081. Sequential31006cbd's hyper parameters: Current learning rate is 0.004610844706750277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 27904/60000][Iteration 5846][Wall Clock 550.284204627s] Trained 128 records in 0.084609125 seconds. Throughput is 1512.8391 records/second. Loss is 0.1722649. Sequential31006cbd's hyper parameters: Current learning rate is 0.004610419548178884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 28032/60000][Iteration 5847][Wall Clock 550.361819088s] Trained 128 records in 0.077614461 seconds. Throughput is 1649.1771 records/second. Loss is 0.11310303. Sequential31006cbd's hyper parameters: Current learning rate is 0.004609994468006639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 28160/60000][Iteration 5848][Wall Clock 550.437554442s] Trained 128 records in 0.075735354 seconds. Throughput is 1690.0958 records/second. Loss is 0.14738765. Sequential31006cbd's hyper parameters: Current learning rate is 0.004609569466211856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:47 INFO  DistriOptimizer$:408 - [Epoch 13 28288/60000][Iteration 5849][Wall Clock 550.513828298s] Trained 128 records in 0.076273856 seconds. Throughput is 1678.1635 records/second. Loss is 0.19250096. Sequential31006cbd's hyper parameters: Current learning rate is 0.004609144542772861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 28416/60000][Iteration 5850][Wall Clock 550.58833165s] Trained 128 records in 0.074503352 seconds. Throughput is 1718.0435 records/second. Loss is 0.19770733. Sequential31006cbd's hyper parameters: Current learning rate is 0.004608719697667988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 28544/60000][Iteration 5851][Wall Clock 550.659211666s] Trained 128 records in 0.070880016 seconds. Throughput is 1805.8687 records/second. Loss is 0.14319065. Sequential31006cbd's hyper parameters: Current learning rate is 0.004608294930875576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 28672/60000][Iteration 5852][Wall Clock 550.760867289s] Trained 128 records in 0.101655623 seconds. Throughput is 1259.1532 records/second. Loss is 0.12740251. Sequential31006cbd's hyper parameters: Current learning rate is 0.004607870242373974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 28800/60000][Iteration 5853][Wall Clock 550.842910244s] Trained 128 records in 0.082042955 seconds. Throughput is 1560.1583 records/second. Loss is 0.12002309. Sequential31006cbd's hyper parameters: Current learning rate is 0.004607445632141541. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 28928/60000][Iteration 5854][Wall Clock 550.915900438s] Trained 128 records in 0.072990194 seconds. Throughput is 1753.6603 records/second. Loss is 0.24326071. Sequential31006cbd's hyper parameters: Current learning rate is 0.004607021100156638. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 29056/60000][Iteration 5855][Wall Clock 550.995994802s] Trained 128 records in 0.080094364 seconds. Throughput is 1598.1149 records/second. Loss is 0.24720003. Sequential31006cbd's hyper parameters: Current learning rate is 0.004606596646397642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 29184/60000][Iteration 5856][Wall Clock 551.079821775s] Trained 128 records in 0.083826973 seconds. Throughput is 1526.9548 records/second. Loss is 0.22824925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004606172270842929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 29312/60000][Iteration 5857][Wall Clock 551.166439528s] Trained 128 records in 0.086617753 seconds. Throughput is 1477.7571 records/second. Loss is 0.15760759. Sequential31006cbd's hyper parameters: Current learning rate is 0.004605747973470892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 29440/60000][Iteration 5858][Wall Clock 551.248276416s] Trained 128 records in 0.081836888 seconds. Throughput is 1564.0869 records/second. Loss is 0.23269461. Sequential31006cbd's hyper parameters: Current learning rate is 0.004605323754259924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 29568/60000][Iteration 5859][Wall Clock 551.330810694s] Trained 128 records in 0.082534278 seconds. Throughput is 1550.8708 records/second. Loss is 0.179045. Sequential31006cbd's hyper parameters: Current learning rate is 0.004604899613188433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:48 INFO  DistriOptimizer$:408 - [Epoch 13 29696/60000][Iteration 5860][Wall Clock 551.427592985s] Trained 128 records in 0.096782291 seconds. Throughput is 1322.556 records/second. Loss is 0.184468. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046044755502348276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 29824/60000][Iteration 5861][Wall Clock 551.529058457s] Trained 128 records in 0.101465472 seconds. Throughput is 1261.513 records/second. Loss is 0.1624771. Sequential31006cbd's hyper parameters: Current learning rate is 0.004604051565377532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 29952/60000][Iteration 5862][Wall Clock 551.601202035s] Trained 128 records in 0.072143578 seconds. Throughput is 1774.2397 records/second. Loss is 0.16977002. Sequential31006cbd's hyper parameters: Current learning rate is 0.004603627658594973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30080/60000][Iteration 5863][Wall Clock 551.684441721s] Trained 128 records in 0.083239686 seconds. Throughput is 1537.728 records/second. Loss is 0.20194396. Sequential31006cbd's hyper parameters: Current learning rate is 0.004603203829865586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30208/60000][Iteration 5864][Wall Clock 551.771967807s] Trained 128 records in 0.087526086 seconds. Throughput is 1462.4213 records/second. Loss is 0.19642836. Sequential31006cbd's hyper parameters: Current learning rate is 0.004602780079167817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30336/60000][Iteration 5865][Wall Clock 551.856920419s] Trained 128 records in 0.084952612 seconds. Throughput is 1506.7223 records/second. Loss is 0.14000814. Sequential31006cbd's hyper parameters: Current learning rate is 0.004602356406480118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30464/60000][Iteration 5866][Wall Clock 551.943766531s] Trained 128 records in 0.086846112 seconds. Throughput is 1473.8713 records/second. Loss is 0.14870656. Sequential31006cbd's hyper parameters: Current learning rate is 0.0046019328117809484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30592/60000][Iteration 5867][Wall Clock 552.023117779s] Trained 128 records in 0.079351248 seconds. Throughput is 1613.0812 records/second. Loss is 0.22222015. Sequential31006cbd's hyper parameters: Current learning rate is 0.004601509295048776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30720/60000][Iteration 5868][Wall Clock 552.103196856s] Trained 128 records in 0.080079077 seconds. Throughput is 1598.42 records/second. Loss is 0.2077185. Sequential31006cbd's hyper parameters: Current learning rate is 0.004601085856262078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30848/60000][Iteration 5869][Wall Clock 552.18530587s] Trained 128 records in 0.082109014 seconds. Throughput is 1558.9032 records/second. Loss is 0.22747107. Sequential31006cbd's hyper parameters: Current learning rate is 0.004600662495399338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 30976/60000][Iteration 5870][Wall Clock 552.270421361s] Trained 128 records in 0.085115491 seconds. Throughput is 1503.839 records/second. Loss is 0.15564243. Sequential31006cbd's hyper parameters: Current learning rate is 0.004600239212439047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 31104/60000][Iteration 5871][Wall Clock 552.362563648s] Trained 128 records in 0.092142287 seconds. Throughput is 1389.1559 records/second. Loss is 0.17163917. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045998160073597045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:49 INFO  DistriOptimizer$:408 - [Epoch 13 31232/60000][Iteration 5872][Wall Clock 552.449349986s] Trained 128 records in 0.086786338 seconds. Throughput is 1474.8865 records/second. Loss is 0.1092606. Sequential31006cbd's hyper parameters: Current learning rate is 0.004599392880139822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 31360/60000][Iteration 5873][Wall Clock 552.552277691s] Trained 128 records in 0.102927705 seconds. Throughput is 1243.5913 records/second. Loss is 0.2487894. Sequential31006cbd's hyper parameters: Current learning rate is 0.00459896983075791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 31488/60000][Iteration 5874][Wall Clock 552.633994684s] Trained 128 records in 0.081716993 seconds. Throughput is 1566.3817 records/second. Loss is 0.13395174. Sequential31006cbd's hyper parameters: Current learning rate is 0.004598546859192495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 31616/60000][Iteration 5875][Wall Clock 552.705784816s] Trained 128 records in 0.071790132 seconds. Throughput is 1782.975 records/second. Loss is 0.14892377. Sequential31006cbd's hyper parameters: Current learning rate is 0.004598123965422108. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 31744/60000][Iteration 5876][Wall Clock 552.785593451s] Trained 128 records in 0.079808635 seconds. Throughput is 1603.8364 records/second. Loss is 0.18951134. Sequential31006cbd's hyper parameters: Current learning rate is 0.004597701149425288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 31872/60000][Iteration 5877][Wall Clock 552.866415611s] Trained 128 records in 0.08082216 seconds. Throughput is 1583.724 records/second. Loss is 0.19190414. Sequential31006cbd's hyper parameters: Current learning rate is 0.004597278411180581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32000/60000][Iteration 5878][Wall Clock 552.953975925s] Trained 128 records in 0.087560314 seconds. Throughput is 1461.8495 records/second. Loss is 0.21082471. Sequential31006cbd's hyper parameters: Current learning rate is 0.004596855750666545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32128/60000][Iteration 5879][Wall Clock 553.051523896s] Trained 128 records in 0.097547971 seconds. Throughput is 1312.1749 records/second. Loss is 0.20598513. Sequential31006cbd's hyper parameters: Current learning rate is 0.004596433167861739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32256/60000][Iteration 5880][Wall Clock 553.130114237s] Trained 128 records in 0.078590341 seconds. Throughput is 1628.6989 records/second. Loss is 0.23496233. Sequential31006cbd's hyper parameters: Current learning rate is 0.004596010662744739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32384/60000][Iteration 5881][Wall Clock 553.22066019s] Trained 128 records in 0.090545953 seconds. Throughput is 1413.6469 records/second. Loss is 0.24992228. Sequential31006cbd's hyper parameters: Current learning rate is 0.004595588235294118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32512/60000][Iteration 5882][Wall Clock 553.301357826s] Trained 128 records in 0.080697636 seconds. Throughput is 1586.168 records/second. Loss is 0.1640134. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045951658854884656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32640/60000][Iteration 5883][Wall Clock 553.386767132s] Trained 128 records in 0.085409306 seconds. Throughput is 1498.6658 records/second. Loss is 0.22990952. Sequential31006cbd's hyper parameters: Current learning rate is 0.004594743613306377. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:50 INFO  DistriOptimizer$:408 - [Epoch 13 32768/60000][Iteration 5884][Wall Clock 553.46852087s] Trained 128 records in 0.081753738 seconds. Throughput is 1565.6776 records/second. Loss is 0.1643599. Sequential31006cbd's hyper parameters: Current learning rate is 0.004594321418726454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 32896/60000][Iteration 5885][Wall Clock 553.543203238s] Trained 128 records in 0.074682368 seconds. Throughput is 1713.9253 records/second. Loss is 0.28213066. Sequential31006cbd's hyper parameters: Current learning rate is 0.004593899301727306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33024/60000][Iteration 5886][Wall Clock 553.622820959s] Trained 128 records in 0.079617721 seconds. Throughput is 1607.6823 records/second. Loss is 0.21552029. Sequential31006cbd's hyper parameters: Current learning rate is 0.004593477262287551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33152/60000][Iteration 5887][Wall Clock 553.701770766s] Trained 128 records in 0.078949807 seconds. Throughput is 1621.2832 records/second. Loss is 0.17424074. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045930553003858164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33280/60000][Iteration 5888][Wall Clock 553.773179229s] Trained 128 records in 0.071408463 seconds. Throughput is 1792.5045 records/second. Loss is 0.20227732. Sequential31006cbd's hyper parameters: Current learning rate is 0.004592633416000735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33408/60000][Iteration 5889][Wall Clock 553.871538791s] Trained 128 records in 0.098359562 seconds. Throughput is 1301.3478 records/second. Loss is 0.21771127. Sequential31006cbd's hyper parameters: Current learning rate is 0.004592211609110948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33536/60000][Iteration 5890][Wall Clock 553.947551629s] Trained 128 records in 0.076012838 seconds. Throughput is 1683.9261 records/second. Loss is 0.23550922. Sequential31006cbd's hyper parameters: Current learning rate is 0.004591789879695106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33664/60000][Iteration 5891][Wall Clock 554.027474303s] Trained 128 records in 0.079922674 seconds. Throughput is 1601.548 records/second. Loss is 0.1619678. Sequential31006cbd's hyper parameters: Current learning rate is 0.004591368227731864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33792/60000][Iteration 5892][Wall Clock 554.106615758s] Trained 128 records in 0.079141455 seconds. Throughput is 1617.3572 records/second. Loss is 0.12664934. Sequential31006cbd's hyper parameters: Current learning rate is 0.004590946653199889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 33920/60000][Iteration 5893][Wall Clock 554.199798241s] Trained 128 records in 0.093182483 seconds. Throughput is 1373.6488 records/second. Loss is 0.25191048. Sequential31006cbd's hyper parameters: Current learning rate is 0.004590525156077855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 34048/60000][Iteration 5894][Wall Clock 554.274389319s] Trained 128 records in 0.074591078 seconds. Throughput is 1716.023 records/second. Loss is 0.25209254. Sequential31006cbd's hyper parameters: Current learning rate is 0.004590103736344441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 34176/60000][Iteration 5895][Wall Clock 554.352824908s] Trained 128 records in 0.078435589 seconds. Throughput is 1631.9122 records/second. Loss is 0.23021418. Sequential31006cbd's hyper parameters: Current learning rate is 0.004589682393978337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:51 INFO  DistriOptimizer$:408 - [Epoch 13 34304/60000][Iteration 5896][Wall Clock 554.435750276s] Trained 128 records in 0.082925368 seconds. Throughput is 1543.5566 records/second. Loss is 0.24574967. Sequential31006cbd's hyper parameters: Current learning rate is 0.004589261128958237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 34432/60000][Iteration 5897][Wall Clock 554.519287585s] Trained 128 records in 0.083537309 seconds. Throughput is 1532.2495 records/second. Loss is 0.19929433. Sequential31006cbd's hyper parameters: Current learning rate is 0.004588839941262849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 34560/60000][Iteration 5898][Wall Clock 554.598117479s] Trained 128 records in 0.078829894 seconds. Throughput is 1623.7495 records/second. Loss is 0.18522523. Sequential31006cbd's hyper parameters: Current learning rate is 0.004588418830870881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 34688/60000][Iteration 5899][Wall Clock 554.671078032s] Trained 128 records in 0.072960553 seconds. Throughput is 1754.3726 records/second. Loss is 0.24436472. Sequential31006cbd's hyper parameters: Current learning rate is 0.004587997797761058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 34816/60000][Iteration 5900][Wall Clock 554.75244515s] Trained 128 records in 0.081367118 seconds. Throughput is 1573.117 records/second. Loss is 0.17459604. Sequential31006cbd's hyper parameters: Current learning rate is 0.004587576841912102. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 34944/60000][Iteration 5901][Wall Clock 554.830722858s] Trained 128 records in 0.078277708 seconds. Throughput is 1635.2037 records/second. Loss is 0.15075417. Sequential31006cbd's hyper parameters: Current learning rate is 0.004587155963302752. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35072/60000][Iteration 5902][Wall Clock 554.909086974s] Trained 128 records in 0.078364116 seconds. Throughput is 1633.4006 records/second. Loss is 0.1965481. Sequential31006cbd's hyper parameters: Current learning rate is 0.004586735161911751. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35200/60000][Iteration 5903][Wall Clock 554.996097744s] Trained 128 records in 0.08701077 seconds. Throughput is 1471.0823 records/second. Loss is 0.17772554. Sequential31006cbd's hyper parameters: Current learning rate is 0.00458631443771785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35328/60000][Iteration 5904][Wall Clock 555.0795605s] Trained 128 records in 0.083462756 seconds. Throughput is 1533.6183 records/second. Loss is 0.10203181. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045858937906998075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35456/60000][Iteration 5905][Wall Clock 555.174116706s] Trained 128 records in 0.094556206 seconds. Throughput is 1353.6923 records/second. Loss is 0.22324698. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045854732208363905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35584/60000][Iteration 5906][Wall Clock 555.257964632s] Trained 128 records in 0.083847926 seconds. Throughput is 1526.5732 records/second. Loss is 0.24853078. Sequential31006cbd's hyper parameters: Current learning rate is 0.004585052728106373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35712/60000][Iteration 5907][Wall Clock 555.338636908s] Trained 128 records in 0.080672276 seconds. Throughput is 1586.6665 records/second. Loss is 0.15991086. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045846323124885385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35840/60000][Iteration 5908][Wall Clock 555.419755372s] Trained 128 records in 0.081118464 seconds. Throughput is 1577.9391 records/second. Loss is 0.24254565. Sequential31006cbd's hyper parameters: Current learning rate is 0.004584211973961676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:52 INFO  DistriOptimizer$:408 - [Epoch 13 35968/60000][Iteration 5909][Wall Clock 555.503216515s] Trained 128 records in 0.083461143 seconds. Throughput is 1533.6478 records/second. Loss is 0.14206748. Sequential31006cbd's hyper parameters: Current learning rate is 0.004583791712504584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36096/60000][Iteration 5910][Wall Clock 555.587257542s] Trained 128 records in 0.084041027 seconds. Throughput is 1523.0656 records/second. Loss is 0.121883705. Sequential31006cbd's hyper parameters: Current learning rate is 0.004583371528096068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36224/60000][Iteration 5911][Wall Clock 555.662413621s] Trained 128 records in 0.075156079 seconds. Throughput is 1703.1224 records/second. Loss is 0.25570756. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045829514207149395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36352/60000][Iteration 5912][Wall Clock 555.742020995s] Trained 128 records in 0.079607374 seconds. Throughput is 1607.8912 records/second. Loss is 0.19674444. Sequential31006cbd's hyper parameters: Current learning rate is 0.004582531390340024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36480/60000][Iteration 5913][Wall Clock 555.85567228s] Trained 128 records in 0.113651285 seconds. Throughput is 1126.2521 records/second. Loss is 0.23107935. Sequential31006cbd's hyper parameters: Current learning rate is 0.004582111436950146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36608/60000][Iteration 5914][Wall Clock 555.939983126s] Trained 128 records in 0.084310846 seconds. Throughput is 1518.1914 records/second. Loss is 0.24187076. Sequential31006cbd's hyper parameters: Current learning rate is 0.004581691560524146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36736/60000][Iteration 5915][Wall Clock 556.021342241s] Trained 128 records in 0.081359115 seconds. Throughput is 1573.2717 records/second. Loss is 0.17608936. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045812717610408645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36864/60000][Iteration 5916][Wall Clock 556.100657705s] Trained 128 records in 0.079315464 seconds. Throughput is 1613.809 records/second. Loss is 0.22269228. Sequential31006cbd's hyper parameters: Current learning rate is 0.004580852038479157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 36992/60000][Iteration 5917][Wall Clock 556.185198069s] Trained 128 records in 0.084540364 seconds. Throughput is 1514.0696 records/second. Loss is 0.22936618. Sequential31006cbd's hyper parameters: Current learning rate is 0.004580432392817881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 37120/60000][Iteration 5918][Wall Clock 556.275067163s] Trained 128 records in 0.089869094 seconds. Throughput is 1424.2938 records/second. Loss is 0.10262849. Sequential31006cbd's hyper parameters: Current learning rate is 0.004580012824035908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 37248/60000][Iteration 5919][Wall Clock 556.357570076s] Trained 128 records in 0.082502913 seconds. Throughput is 1551.4603 records/second. Loss is 0.12926465. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045795933321121085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:53 INFO  DistriOptimizer$:408 - [Epoch 13 37376/60000][Iteration 5920][Wall Clock 556.435637865s] Trained 128 records in 0.078067789 seconds. Throughput is 1639.6007 records/second. Loss is 0.114504546. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045791739170253695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 37504/60000][Iteration 5921][Wall Clock 556.519045105s] Trained 128 records in 0.08340724 seconds. Throughput is 1534.639 records/second. Loss is 0.10960072. Sequential31006cbd's hyper parameters: Current learning rate is 0.004578754578754578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 37632/60000][Iteration 5922][Wall Clock 556.595811487s] Trained 128 records in 0.076766382 seconds. Throughput is 1667.3966 records/second. Loss is 0.10329293. Sequential31006cbd's hyper parameters: Current learning rate is 0.004578335317278638. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 37760/60000][Iteration 5923][Wall Clock 556.688417173s] Trained 128 records in 0.092605686 seconds. Throughput is 1382.2045 records/second. Loss is 0.16455811. Sequential31006cbd's hyper parameters: Current learning rate is 0.004577916132576451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 37888/60000][Iteration 5924][Wall Clock 556.762750799s] Trained 128 records in 0.074333626 seconds. Throughput is 1721.9664 records/second. Loss is 0.22843303. Sequential31006cbd's hyper parameters: Current learning rate is 0.004577497024626934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38016/60000][Iteration 5925][Wall Clock 556.847119541s] Trained 128 records in 0.084368742 seconds. Throughput is 1517.1495 records/second. Loss is 0.123996854. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045770779934090075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38144/60000][Iteration 5926][Wall Clock 556.923056617s] Trained 128 records in 0.075937076 seconds. Throughput is 1685.6061 records/second. Loss is 0.16625413. Sequential31006cbd's hyper parameters: Current learning rate is 0.004576659038901602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38272/60000][Iteration 5927][Wall Clock 557.000725878s] Trained 128 records in 0.077669261 seconds. Throughput is 1648.0135 records/second. Loss is 0.20846331. Sequential31006cbd's hyper parameters: Current learning rate is 0.004576240161083654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38400/60000][Iteration 5928][Wall Clock 557.089580362s] Trained 128 records in 0.088854484 seconds. Throughput is 1440.5576 records/second. Loss is 0.10886778. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045758213599341084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38528/60000][Iteration 5929][Wall Clock 557.175568534s] Trained 128 records in 0.085988172 seconds. Throughput is 1488.5768 records/second. Loss is 0.2508424. Sequential31006cbd's hyper parameters: Current learning rate is 0.004575402635431918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38656/60000][Iteration 5930][Wall Clock 557.26502995s] Trained 128 records in 0.089461416 seconds. Throughput is 1430.7844 records/second. Loss is 0.16452894. Sequential31006cbd's hyper parameters: Current learning rate is 0.004574983987556043. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38784/60000][Iteration 5931][Wall Clock 557.344385454s] Trained 128 records in 0.079355504 seconds. Throughput is 1612.9946 records/second. Loss is 0.20959422. Sequential31006cbd's hyper parameters: Current learning rate is 0.004574565416285453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 38912/60000][Iteration 5932][Wall Clock 557.418622487s] Trained 128 records in 0.074237033 seconds. Throughput is 1724.2068 records/second. Loss is 0.27986535. Sequential31006cbd's hyper parameters: Current learning rate is 0.004574146921599121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:54 INFO  DistriOptimizer$:408 - [Epoch 13 39040/60000][Iteration 5933][Wall Clock 557.499615817s] Trained 128 records in 0.08099333 seconds. Throughput is 1580.377 records/second. Loss is 0.21072882. Sequential31006cbd's hyper parameters: Current learning rate is 0.004573728503476034. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39168/60000][Iteration 5934][Wall Clock 557.591513542s] Trained 128 records in 0.091897725 seconds. Throughput is 1392.8528 records/second. Loss is 0.22818284. Sequential31006cbd's hyper parameters: Current learning rate is 0.004573310161895179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39296/60000][Iteration 5935][Wall Clock 557.677622736s] Trained 128 records in 0.086109194 seconds. Throughput is 1486.4847 records/second. Loss is 0.11128847. Sequential31006cbd's hyper parameters: Current learning rate is 0.004572891896835559. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39424/60000][Iteration 5936][Wall Clock 557.759422233s] Trained 128 records in 0.081799497 seconds. Throughput is 1564.8018 records/second. Loss is 0.20443548. Sequential31006cbd's hyper parameters: Current learning rate is 0.004572473708276177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39552/60000][Iteration 5937][Wall Clock 557.848618361s] Trained 128 records in 0.089196128 seconds. Throughput is 1435.0398 records/second. Loss is 0.2802664. Sequential31006cbd's hyper parameters: Current learning rate is 0.00457205559619605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39680/60000][Iteration 5938][Wall Clock 557.931219333s] Trained 128 records in 0.082600972 seconds. Throughput is 1549.6185 records/second. Loss is 0.24915694. Sequential31006cbd's hyper parameters: Current learning rate is 0.004571637560574197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39808/60000][Iteration 5939][Wall Clock 558.024370837s] Trained 128 records in 0.093151504 seconds. Throughput is 1374.1056 records/second. Loss is 0.17282051. Sequential31006cbd's hyper parameters: Current learning rate is 0.004571219601389651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 39936/60000][Iteration 5940][Wall Clock 558.103652965s] Trained 128 records in 0.079282128 seconds. Throughput is 1614.4874 records/second. Loss is 0.14408481. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045708017186214455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 40064/60000][Iteration 5941][Wall Clock 558.188507932s] Trained 128 records in 0.084854967 seconds. Throughput is 1508.4562 records/second. Loss is 0.19919686. Sequential31006cbd's hyper parameters: Current learning rate is 0.004570383912248629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 40192/60000][Iteration 5942][Wall Clock 558.265605085s] Trained 128 records in 0.077097153 seconds. Throughput is 1660.2428 records/second. Loss is 0.1218677. Sequential31006cbd's hyper parameters: Current learning rate is 0.004569966182250251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 40320/60000][Iteration 5943][Wall Clock 558.346978326s] Trained 128 records in 0.081373241 seconds. Throughput is 1572.9987 records/second. Loss is 0.17604047. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045695485286053735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:55 INFO  DistriOptimizer$:408 - [Epoch 13 40448/60000][Iteration 5944][Wall Clock 558.425391175s] Trained 128 records in 0.078412849 seconds. Throughput is 1632.3856 records/second. Loss is 0.20427656. Sequential31006cbd's hyper parameters: Current learning rate is 0.004569130951293064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 40576/60000][Iteration 5945][Wall Clock 558.509285744s] Trained 128 records in 0.083894569 seconds. Throughput is 1525.7246 records/second. Loss is 0.19022733. Sequential31006cbd's hyper parameters: Current learning rate is 0.004568713450292397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 40704/60000][Iteration 5946][Wall Clock 558.591579995s] Trained 128 records in 0.082294251 seconds. Throughput is 1555.3943 records/second. Loss is 0.12239707. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045682960255824575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 40832/60000][Iteration 5947][Wall Clock 558.67178588s] Trained 128 records in 0.080205885 seconds. Throughput is 1595.8928 records/second. Loss is 0.11725289. Sequential31006cbd's hyper parameters: Current learning rate is 0.004567878677142335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 40960/60000][Iteration 5948][Wall Clock 558.751914618s] Trained 128 records in 0.080128738 seconds. Throughput is 1597.4294 records/second. Loss is 0.15525681. Sequential31006cbd's hyper parameters: Current learning rate is 0.004567461404951128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41088/60000][Iteration 5949][Wall Clock 558.830899592s] Trained 128 records in 0.078984974 seconds. Throughput is 1620.5614 records/second. Loss is 0.19195649. Sequential31006cbd's hyper parameters: Current learning rate is 0.004567044208987943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41216/60000][Iteration 5950][Wall Clock 558.909794764s] Trained 128 records in 0.078895172 seconds. Throughput is 1622.406 records/second. Loss is 0.16243124. Sequential31006cbd's hyper parameters: Current learning rate is 0.004566627089231894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41344/60000][Iteration 5951][Wall Clock 558.987042563s] Trained 128 records in 0.077247799 seconds. Throughput is 1657.0051 records/second. Loss is 0.27435732. Sequential31006cbd's hyper parameters: Current learning rate is 0.004566210045662101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41472/60000][Iteration 5952][Wall Clock 559.06515519s] Trained 128 records in 0.078112627 seconds. Throughput is 1638.6595 records/second. Loss is 0.18160813. Sequential31006cbd's hyper parameters: Current learning rate is 0.004565793078257694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41600/60000][Iteration 5953][Wall Clock 559.139411891s] Trained 128 records in 0.074256701 seconds. Throughput is 1723.7501 records/second. Loss is 0.15271303. Sequential31006cbd's hyper parameters: Current learning rate is 0.004565376186997808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41728/60000][Iteration 5954][Wall Clock 559.239355777s] Trained 128 records in 0.099943886 seconds. Throughput is 1280.7188 records/second. Loss is 0.20899713. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045649593718615905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41856/60000][Iteration 5955][Wall Clock 559.333878551s] Trained 128 records in 0.094522774 seconds. Throughput is 1354.171 records/second. Loss is 0.15062414. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045645426328281904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:56 INFO  DistriOptimizer$:408 - [Epoch 13 41984/60000][Iteration 5956][Wall Clock 559.416877902s] Trained 128 records in 0.082999351 seconds. Throughput is 1542.1808 records/second. Loss is 0.19905454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004564125969876769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42112/60000][Iteration 5957][Wall Clock 559.494848165s] Trained 128 records in 0.077970263 seconds. Throughput is 1641.6515 records/second. Loss is 0.24118239. Sequential31006cbd's hyper parameters: Current learning rate is 0.004563709382986491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42240/60000][Iteration 5958][Wall Clock 559.575825139s] Trained 128 records in 0.080976974 seconds. Throughput is 1580.6963 records/second. Loss is 0.12800029. Sequential31006cbd's hyper parameters: Current learning rate is 0.004563292872136534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42368/60000][Iteration 5959][Wall Clock 559.656210818s] Trained 128 records in 0.080385679 seconds. Throughput is 1592.3235 records/second. Loss is 0.115903035. Sequential31006cbd's hyper parameters: Current learning rate is 0.004562876437306077. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42496/60000][Iteration 5960][Wall Clock 559.738439988s] Trained 128 records in 0.08222917 seconds. Throughput is 1556.6252 records/second. Loss is 0.13427071. Sequential31006cbd's hyper parameters: Current learning rate is 0.004562460078474314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42624/60000][Iteration 5961][Wall Clock 559.825279865s] Trained 128 records in 0.086839877 seconds. Throughput is 1473.9772 records/second. Loss is 0.21428423. Sequential31006cbd's hyper parameters: Current learning rate is 0.004562043795620438. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42752/60000][Iteration 5962][Wall Clock 559.907480411s] Trained 128 records in 0.082200546 seconds. Throughput is 1557.1672 records/second. Loss is 0.22477788. Sequential31006cbd's hyper parameters: Current learning rate is 0.004561627588723656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 42880/60000][Iteration 5963][Wall Clock 559.98657221s] Trained 128 records in 0.079091799 seconds. Throughput is 1618.3726 records/second. Loss is 0.17294827. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045612114577631814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 43008/60000][Iteration 5964][Wall Clock 560.067229793s] Trained 128 records in 0.080657583 seconds. Throughput is 1586.9554 records/second. Loss is 0.2724869. Sequential31006cbd's hyper parameters: Current learning rate is 0.004560795402718234. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 43136/60000][Iteration 5965][Wall Clock 560.156964813s] Trained 128 records in 0.08973502 seconds. Throughput is 1426.4219 records/second. Loss is 0.19763336. Sequential31006cbd's hyper parameters: Current learning rate is 0.004560379423568041. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 43264/60000][Iteration 5966][Wall Clock 560.242909214s] Trained 128 records in 0.085944401 seconds. Throughput is 1489.335 records/second. Loss is 0.19405286. Sequential31006cbd's hyper parameters: Current learning rate is 0.004559963520291838. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 43392/60000][Iteration 5967][Wall Clock 560.316384327s] Trained 128 records in 0.073475113 seconds. Throughput is 1742.0864 records/second. Loss is 0.098517545. Sequential31006cbd's hyper parameters: Current learning rate is 0.004559547692868867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 43520/60000][Iteration 5968][Wall Clock 560.391140171s] Trained 128 records in 0.074755844 seconds. Throughput is 1712.2406 records/second. Loss is 0.14218536. Sequential31006cbd's hyper parameters: Current learning rate is 0.004559131941278381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:57 INFO  DistriOptimizer$:408 - [Epoch 13 43648/60000][Iteration 5969][Wall Clock 560.466478359s] Trained 128 records in 0.075338188 seconds. Throughput is 1699.0056 records/second. Loss is 0.19759026. Sequential31006cbd's hyper parameters: Current learning rate is 0.004558716265499635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 43776/60000][Iteration 5970][Wall Clock 560.546688838s] Trained 128 records in 0.080210479 seconds. Throughput is 1595.8015 records/second. Loss is 0.13492537. Sequential31006cbd's hyper parameters: Current learning rate is 0.004558300665511898. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 43904/60000][Iteration 5971][Wall Clock 560.626064446s] Trained 128 records in 0.079375608 seconds. Throughput is 1612.586 records/second. Loss is 0.20539743. Sequential31006cbd's hyper parameters: Current learning rate is 0.00455788514129444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44032/60000][Iteration 5972][Wall Clock 560.71409168s] Trained 128 records in 0.088027234 seconds. Throughput is 1454.0955 records/second. Loss is 0.12362318. Sequential31006cbd's hyper parameters: Current learning rate is 0.004557469692826542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44160/60000][Iteration 5973][Wall Clock 560.804962991s] Trained 128 records in 0.090871311 seconds. Throughput is 1408.5853 records/second. Loss is 0.12101704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004557054320087496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44288/60000][Iteration 5974][Wall Clock 560.887511598s] Trained 128 records in 0.082548607 seconds. Throughput is 1550.6017 records/second. Loss is 0.23158786. Sequential31006cbd's hyper parameters: Current learning rate is 0.004556639023056593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44416/60000][Iteration 5975][Wall Clock 560.960932791s] Trained 128 records in 0.073421193 seconds. Throughput is 1743.3658 records/second. Loss is 0.1596924. Sequential31006cbd's hyper parameters: Current learning rate is 0.00455622380171314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44544/60000][Iteration 5976][Wall Clock 561.060146891s] Trained 128 records in 0.0992141 seconds. Throughput is 1290.1392 records/second. Loss is 0.24623057. Sequential31006cbd's hyper parameters: Current learning rate is 0.004555808656036446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44672/60000][Iteration 5977][Wall Clock 561.135133957s] Trained 128 records in 0.074987066 seconds. Throughput is 1706.9609 records/second. Loss is 0.15689063. Sequential31006cbd's hyper parameters: Current learning rate is 0.004555393586005831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44800/60000][Iteration 5978][Wall Clock 561.209884182s] Trained 128 records in 0.074750225 seconds. Throughput is 1712.3695 records/second. Loss is 0.10146427. Sequential31006cbd's hyper parameters: Current learning rate is 0.004554978591600619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 44928/60000][Iteration 5979][Wall Clock 561.28397439s] Trained 128 records in 0.074090208 seconds. Throughput is 1727.6238 records/second. Loss is 0.10827057. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045545636728001465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 45056/60000][Iteration 5980][Wall Clock 561.357907957s] Trained 128 records in 0.073933567 seconds. Throughput is 1731.284 records/second. Loss is 0.18038544. Sequential31006cbd's hyper parameters: Current learning rate is 0.004554148829583751. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:58 INFO  DistriOptimizer$:408 - [Epoch 13 45184/60000][Iteration 5981][Wall Clock 561.427740851s] Trained 128 records in 0.069832894 seconds. Throughput is 1832.9471 records/second. Loss is 0.12056026. Sequential31006cbd's hyper parameters: Current learning rate is 0.004553734061930784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 45312/60000][Iteration 5982][Wall Clock 561.507094826s] Trained 128 records in 0.079353975 seconds. Throughput is 1613.0258 records/second. Loss is 0.16499297. Sequential31006cbd's hyper parameters: Current learning rate is 0.004553319369820599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 45440/60000][Iteration 5983][Wall Clock 561.583009487s] Trained 128 records in 0.075914661 seconds. Throughput is 1686.1039 records/second. Loss is 0.21556856. Sequential31006cbd's hyper parameters: Current learning rate is 0.004552904753232562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 45568/60000][Iteration 5984][Wall Clock 561.663838491s] Trained 128 records in 0.080829004 seconds. Throughput is 1583.59 records/second. Loss is 0.10340804. Sequential31006cbd's hyper parameters: Current learning rate is 0.004552490212146044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 45696/60000][Iteration 5985][Wall Clock 561.741635682s] Trained 128 records in 0.077797191 seconds. Throughput is 1645.3037 records/second. Loss is 0.16649403. Sequential31006cbd's hyper parameters: Current learning rate is 0.004552075746540422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 45824/60000][Iteration 5986][Wall Clock 561.823012757s] Trained 128 records in 0.081377075 seconds. Throughput is 1572.9246 records/second. Loss is 0.21975514. Sequential31006cbd's hyper parameters: Current learning rate is 0.004551661356395084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 45952/60000][Iteration 5987][Wall Clock 561.899570145s] Trained 128 records in 0.076557388 seconds. Throughput is 1671.9484 records/second. Loss is 0.2473824. Sequential31006cbd's hyper parameters: Current learning rate is 0.004551247041689423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46080/60000][Iteration 5988][Wall Clock 561.979824331s] Trained 128 records in 0.080254186 seconds. Throughput is 1594.9323 records/second. Loss is 0.16691846. Sequential31006cbd's hyper parameters: Current learning rate is 0.00455083280240284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46208/60000][Iteration 5989][Wall Clock 562.059330053s] Trained 128 records in 0.079505722 seconds. Throughput is 1609.947 records/second. Loss is 0.1632543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004550418638514743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46336/60000][Iteration 5990][Wall Clock 562.138993604s] Trained 128 records in 0.079663551 seconds. Throughput is 1606.7573 records/second. Loss is 0.20096856. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045500045500045504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46464/60000][Iteration 5991][Wall Clock 562.225178173s] Trained 128 records in 0.086184569 seconds. Throughput is 1485.1847 records/second. Loss is 0.1613251. Sequential31006cbd's hyper parameters: Current learning rate is 0.004549590536851684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46592/60000][Iteration 5992][Wall Clock 562.308733259s] Trained 128 records in 0.083555086 seconds. Throughput is 1531.9235 records/second. Loss is 0.28340024. Sequential31006cbd's hyper parameters: Current learning rate is 0.004549176599035575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46720/60000][Iteration 5993][Wall Clock 562.385250012s] Trained 128 records in 0.076516753 seconds. Throughput is 1672.8362 records/second. Loss is 0.13713478. Sequential31006cbd's hyper parameters: Current learning rate is 0.004548762736535662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:06:59 INFO  DistriOptimizer$:408 - [Epoch 13 46848/60000][Iteration 5994][Wall Clock 562.464715223s] Trained 128 records in 0.079465211 seconds. Throughput is 1610.7678 records/second. Loss is 0.19507144. Sequential31006cbd's hyper parameters: Current learning rate is 0.004548348949331393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 46976/60000][Iteration 5995][Wall Clock 562.542239292s] Trained 128 records in 0.077524069 seconds. Throughput is 1651.1002 records/second. Loss is 0.12623888. Sequential31006cbd's hyper parameters: Current learning rate is 0.004547935237402219. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47104/60000][Iteration 5996][Wall Clock 562.63554129s] Trained 128 records in 0.093301998 seconds. Throughput is 1371.8892 records/second. Loss is 0.09798245. Sequential31006cbd's hyper parameters: Current learning rate is 0.004547521600727604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47232/60000][Iteration 5997][Wall Clock 562.726887319s] Trained 128 records in 0.091346029 seconds. Throughput is 1401.2651 records/second. Loss is 0.2126208. Sequential31006cbd's hyper parameters: Current learning rate is 0.004547108039287013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47360/60000][Iteration 5998][Wall Clock 562.813719482s] Trained 128 records in 0.086832163 seconds. Throughput is 1474.1082 records/second. Loss is 0.13511318. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045466945530599255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47488/60000][Iteration 5999][Wall Clock 562.901025648s] Trained 128 records in 0.087306166 seconds. Throughput is 1466.105 records/second. Loss is 0.18539481. Sequential31006cbd's hyper parameters: Current learning rate is 0.004546281142025823. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47616/60000][Iteration 6000][Wall Clock 562.978749706s] Trained 128 records in 0.077724058 seconds. Throughput is 1646.8518 records/second. Loss is 0.11478382. Sequential31006cbd's hyper parameters: Current learning rate is 0.004545867806164197. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47744/60000][Iteration 6001][Wall Clock 563.058493777s] Trained 128 records in 0.079744071 seconds. Throughput is 1605.135 records/second. Loss is 0.26485404. Sequential31006cbd's hyper parameters: Current learning rate is 0.004545454545454545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 47872/60000][Iteration 6002][Wall Clock 563.145496266s] Trained 128 records in 0.087002489 seconds. Throughput is 1471.2223 records/second. Loss is 0.19012102. Sequential31006cbd's hyper parameters: Current learning rate is 0.004545041359876375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 48000/60000][Iteration 6003][Wall Clock 563.233163831s] Trained 128 records in 0.087667565 seconds. Throughput is 1460.0612 records/second. Loss is 0.25139025. Sequential31006cbd's hyper parameters: Current learning rate is 0.004544628249409198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 48128/60000][Iteration 6004][Wall Clock 563.323216449s] Trained 128 records in 0.090052618 seconds. Throughput is 1421.3912 records/second. Loss is 0.2211428. Sequential31006cbd's hyper parameters: Current learning rate is 0.004544215214032536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:00 INFO  DistriOptimizer$:408 - [Epoch 13 48256/60000][Iteration 6005][Wall Clock 563.422390423s] Trained 128 records in 0.099173974 seconds. Throughput is 1290.6613 records/second. Loss is 0.13743888. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045438022537259174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 48384/60000][Iteration 6006][Wall Clock 563.502613748s] Trained 128 records in 0.080223325 seconds. Throughput is 1595.546 records/second. Loss is 0.15040253. Sequential31006cbd's hyper parameters: Current learning rate is 0.004543389368468878. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 48512/60000][Iteration 6007][Wall Clock 563.582671641s] Trained 128 records in 0.080057893 seconds. Throughput is 1598.8429 records/second. Loss is 0.21481124. Sequential31006cbd's hyper parameters: Current learning rate is 0.004542976558240959. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 48640/60000][Iteration 6008][Wall Clock 563.668003846s] Trained 128 records in 0.085332205 seconds. Throughput is 1500.0198 records/second. Loss is 0.14066888. Sequential31006cbd's hyper parameters: Current learning rate is 0.004542563823021714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 48768/60000][Iteration 6009][Wall Clock 563.746715687s] Trained 128 records in 0.078711841 seconds. Throughput is 1626.1849 records/second. Loss is 0.32387257. Sequential31006cbd's hyper parameters: Current learning rate is 0.004542151162790698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 48896/60000][Iteration 6010][Wall Clock 563.829200136s] Trained 128 records in 0.082484449 seconds. Throughput is 1551.8077 records/second. Loss is 0.18499725. Sequential31006cbd's hyper parameters: Current learning rate is 0.004541738577527477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49024/60000][Iteration 6011][Wall Clock 563.92115891s] Trained 128 records in 0.091958774 seconds. Throughput is 1391.9281 records/second. Loss is 0.16509831. Sequential31006cbd's hyper parameters: Current learning rate is 0.004541326067211626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49152/60000][Iteration 6012][Wall Clock 563.998101637s] Trained 128 records in 0.076942727 seconds. Throughput is 1663.5751 records/second. Loss is 0.10120464. Sequential31006cbd's hyper parameters: Current learning rate is 0.004540913631822722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49280/60000][Iteration 6013][Wall Clock 564.075480353s] Trained 128 records in 0.077378716 seconds. Throughput is 1654.2018 records/second. Loss is 0.20321056. Sequential31006cbd's hyper parameters: Current learning rate is 0.004540501271340356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49408/60000][Iteration 6014][Wall Clock 564.151614591s] Trained 128 records in 0.076134238 seconds. Throughput is 1681.2411 records/second. Loss is 0.09170094. Sequential31006cbd's hyper parameters: Current learning rate is 0.00454008898574412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49536/60000][Iteration 6015][Wall Clock 564.234598751s] Trained 128 records in 0.08298416 seconds. Throughput is 1542.4631 records/second. Loss is 0.15526296. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045396767750136196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49664/60000][Iteration 6016][Wall Clock 564.309879666s] Trained 128 records in 0.075280915 seconds. Throughput is 1700.2982 records/second. Loss is 0.17683564. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045392646391284605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:01 INFO  DistriOptimizer$:408 - [Epoch 13 49792/60000][Iteration 6017][Wall Clock 564.413833182s] Trained 128 records in 0.103953516 seconds. Throughput is 1231.3196 records/second. Loss is 0.18228635. Sequential31006cbd's hyper parameters: Current learning rate is 0.004538852578068265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 49920/60000][Iteration 6018][Wall Clock 564.49885871s] Trained 128 records in 0.085025528 seconds. Throughput is 1505.4303 records/second. Loss is 0.155176. Sequential31006cbd's hyper parameters: Current learning rate is 0.004538440591812653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50048/60000][Iteration 6019][Wall Clock 564.588397684s] Trained 128 records in 0.089538974 seconds. Throughput is 1429.545 records/second. Loss is 0.18050775. Sequential31006cbd's hyper parameters: Current learning rate is 0.00453802868034126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50176/60000][Iteration 6020][Wall Clock 564.69019788s] Trained 128 records in 0.101800196 seconds. Throughput is 1257.365 records/second. Loss is 0.11302547. Sequential31006cbd's hyper parameters: Current learning rate is 0.004537616843633723. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50304/60000][Iteration 6021][Wall Clock 564.783378852s] Trained 128 records in 0.093180972 seconds. Throughput is 1373.671 records/second. Loss is 0.12031224. Sequential31006cbd's hyper parameters: Current learning rate is 0.004537205081669692. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50432/60000][Iteration 6022][Wall Clock 564.87390437s] Trained 128 records in 0.090525518 seconds. Throughput is 1413.966 records/second. Loss is 0.11839852. Sequential31006cbd's hyper parameters: Current learning rate is 0.004536793394428818. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50560/60000][Iteration 6023][Wall Clock 564.953685369s] Trained 128 records in 0.079780999 seconds. Throughput is 1604.3921 records/second. Loss is 0.17781423. Sequential31006cbd's hyper parameters: Current learning rate is 0.004536381781890764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50688/60000][Iteration 6024][Wall Clock 565.031697607s] Trained 128 records in 0.078012238 seconds. Throughput is 1640.7683 records/second. Loss is 0.23472472. Sequential31006cbd's hyper parameters: Current learning rate is 0.004535970244035199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50816/60000][Iteration 6025][Wall Clock 565.112550503s] Trained 128 records in 0.080852896 seconds. Throughput is 1583.1221 records/second. Loss is 0.29413933. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045355587808417995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 50944/60000][Iteration 6026][Wall Clock 565.195222409s] Trained 128 records in 0.082671906 seconds. Throughput is 1548.2891 records/second. Loss is 0.15916453. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045351473922902496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 51072/60000][Iteration 6027][Wall Clock 565.280283188s] Trained 128 records in 0.085060779 seconds. Throughput is 1504.8064 records/second. Loss is 0.15378202. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045347360783602395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:02 INFO  DistriOptimizer$:408 - [Epoch 13 51200/60000][Iteration 6028][Wall Clock 565.373939867s] Trained 128 records in 0.093656679 seconds. Throughput is 1366.6937 records/second. Loss is 0.14296444. Sequential31006cbd's hyper parameters: Current learning rate is 0.004534324839031469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 51328/60000][Iteration 6029][Wall Clock 565.501498379s] Trained 128 records in 0.127558512 seconds. Throughput is 1003.46106 records/second. Loss is 0.18009058. Sequential31006cbd's hyper parameters: Current learning rate is 0.004533913674283642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 51456/60000][Iteration 6030][Wall Clock 565.581485788s] Trained 128 records in 0.079987409 seconds. Throughput is 1600.252 records/second. Loss is 0.22216973. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045335025840964735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 51584/60000][Iteration 6031][Wall Clock 565.683538604s] Trained 128 records in 0.102052816 seconds. Throughput is 1254.2526 records/second. Loss is 0.2177012. Sequential31006cbd's hyper parameters: Current learning rate is 0.004533091568449683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 51712/60000][Iteration 6032][Wall Clock 565.769900087s] Trained 128 records in 0.086361483 seconds. Throughput is 1482.1422 records/second. Loss is 0.24906453. Sequential31006cbd's hyper parameters: Current learning rate is 0.004532680627322999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 51840/60000][Iteration 6033][Wall Clock 565.859622918s] Trained 128 records in 0.089722831 seconds. Throughput is 1426.6156 records/second. Loss is 0.2129707. Sequential31006cbd's hyper parameters: Current learning rate is 0.004532269760696156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 51968/60000][Iteration 6034][Wall Clock 565.938426773s] Trained 128 records in 0.078803855 seconds. Throughput is 1624.2861 records/second. Loss is 0.12557326. Sequential31006cbd's hyper parameters: Current learning rate is 0.004531858968548899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 52096/60000][Iteration 6035][Wall Clock 566.022229662s] Trained 128 records in 0.083802889 seconds. Throughput is 1527.3937 records/second. Loss is 0.20041198. Sequential31006cbd's hyper parameters: Current learning rate is 0.004531448250860975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 52224/60000][Iteration 6036][Wall Clock 566.101440107s] Trained 128 records in 0.079210445 seconds. Throughput is 1615.9485 records/second. Loss is 0.17836818. Sequential31006cbd's hyper parameters: Current learning rate is 0.004531037607612144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 52352/60000][Iteration 6037][Wall Clock 566.179688363s] Trained 128 records in 0.078248256 seconds. Throughput is 1635.8192 records/second. Loss is 0.19987348. Sequential31006cbd's hyper parameters: Current learning rate is 0.004530627038782167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 52480/60000][Iteration 6038][Wall Clock 566.262626718s] Trained 128 records in 0.082938355 seconds. Throughput is 1543.3148 records/second. Loss is 0.27320337. Sequential31006cbd's hyper parameters: Current learning rate is 0.004530216544350821. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 52608/60000][Iteration 6039][Wall Clock 566.337954013s] Trained 128 records in 0.075327295 seconds. Throughput is 1699.2513 records/second. Loss is 0.1411604. Sequential31006cbd's hyper parameters: Current learning rate is 0.00452980612429788. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:03 INFO  DistriOptimizer$:408 - [Epoch 13 52736/60000][Iteration 6040][Wall Clock 566.418246185s] Trained 128 records in 0.080292172 seconds. Throughput is 1594.1779 records/second. Loss is 0.23492299. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045293957786031345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 52864/60000][Iteration 6041][Wall Clock 566.504499191s] Trained 128 records in 0.086253006 seconds. Throughput is 1484.0063 records/second. Loss is 0.17307517. Sequential31006cbd's hyper parameters: Current learning rate is 0.004528985507246376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 52992/60000][Iteration 6042][Wall Clock 566.588769013s] Trained 128 records in 0.084269822 seconds. Throughput is 1518.9304 records/second. Loss is 0.18808982. Sequential31006cbd's hyper parameters: Current learning rate is 0.004528575310207408. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53120/60000][Iteration 6043][Wall Clock 566.689004133s] Trained 128 records in 0.10023512 seconds. Throughput is 1276.9976 records/second. Loss is 0.11245214. Sequential31006cbd's hyper parameters: Current learning rate is 0.004528165187466038. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53248/60000][Iteration 6044][Wall Clock 566.772885564s] Trained 128 records in 0.083881431 seconds. Throughput is 1525.9635 records/second. Loss is 0.20700139. Sequential31006cbd's hyper parameters: Current learning rate is 0.004527755139002083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53376/60000][Iteration 6045][Wall Clock 566.862049372s] Trained 128 records in 0.089163808 seconds. Throughput is 1435.56 records/second. Loss is 0.15123293. Sequential31006cbd's hyper parameters: Current learning rate is 0.004527345164795364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53504/60000][Iteration 6046][Wall Clock 566.943515694s] Trained 128 records in 0.081466322 seconds. Throughput is 1571.2014 records/second. Loss is 0.22807536. Sequential31006cbd's hyper parameters: Current learning rate is 0.004526935264825713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53632/60000][Iteration 6047][Wall Clock 567.020148634s] Trained 128 records in 0.07663294 seconds. Throughput is 1670.3 records/second. Loss is 0.11112022. Sequential31006cbd's hyper parameters: Current learning rate is 0.004526525439072967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53760/60000][Iteration 6048][Wall Clock 567.109498075s] Trained 128 records in 0.089349441 seconds. Throughput is 1432.5775 records/second. Loss is 0.20309603. Sequential31006cbd's hyper parameters: Current learning rate is 0.004526115687516973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 53888/60000][Iteration 6049][Wall Clock 567.195675397s] Trained 128 records in 0.086177322 seconds. Throughput is 1485.3096 records/second. Loss is 0.21255764. Sequential31006cbd's hyper parameters: Current learning rate is 0.004525706010137582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 54016/60000][Iteration 6050][Wall Clock 567.278166761s] Trained 128 records in 0.082491364 seconds. Throughput is 1551.6776 records/second. Loss is 0.14986664. Sequential31006cbd's hyper parameters: Current learning rate is 0.004525296406914653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 54144/60000][Iteration 6051][Wall Clock 567.353806555s] Trained 128 records in 0.075639794 seconds. Throughput is 1692.231 records/second. Loss is 0.15024266. Sequential31006cbd's hyper parameters: Current learning rate is 0.004524886877828055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:04 INFO  DistriOptimizer$:408 - [Epoch 13 54272/60000][Iteration 6052][Wall Clock 567.440491217s] Trained 128 records in 0.086684662 seconds. Throughput is 1476.6166 records/second. Loss is 0.08573796. Sequential31006cbd's hyper parameters: Current learning rate is 0.004524477422857659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 54400/60000][Iteration 6053][Wall Clock 567.534719507s] Trained 128 records in 0.09422829 seconds. Throughput is 1358.4031 records/second. Loss is 0.17754991. Sequential31006cbd's hyper parameters: Current learning rate is 0.004524068041983352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 54528/60000][Iteration 6054][Wall Clock 567.649442349s] Trained 128 records in 0.114722842 seconds. Throughput is 1115.7325 records/second. Loss is 0.15110454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004523658735185017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 54656/60000][Iteration 6055][Wall Clock 567.727205233s] Trained 128 records in 0.077762884 seconds. Throughput is 1646.0294 records/second. Loss is 0.17968467. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045232495024425555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 54784/60000][Iteration 6056][Wall Clock 567.817238347s] Trained 128 records in 0.090033114 seconds. Throughput is 1421.6991 records/second. Loss is 0.21343979. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045228403437358655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 54912/60000][Iteration 6057][Wall Clock 567.90647608s] Trained 128 records in 0.089237733 seconds. Throughput is 1434.3708 records/second. Loss is 0.13234682. Sequential31006cbd's hyper parameters: Current learning rate is 0.004522431259044863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 55040/60000][Iteration 6058][Wall Clock 567.992147313s] Trained 128 records in 0.085671233 seconds. Throughput is 1494.0839 records/second. Loss is 0.23230061. Sequential31006cbd's hyper parameters: Current learning rate is 0.004522022248349461. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 55168/60000][Iteration 6059][Wall Clock 568.073252934s] Trained 128 records in 0.081105621 seconds. Throughput is 1578.1891 records/second. Loss is 0.21349165. Sequential31006cbd's hyper parameters: Current learning rate is 0.00452161331162959. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 55296/60000][Iteration 6060][Wall Clock 568.156722501s] Trained 128 records in 0.083469567 seconds. Throughput is 1533.493 records/second. Loss is 0.16065097. Sequential31006cbd's hyper parameters: Current learning rate is 0.004521204448865178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 55424/60000][Iteration 6061][Wall Clock 568.246077148s] Trained 128 records in 0.089354647 seconds. Throughput is 1432.494 records/second. Loss is 0.22604683. Sequential31006cbd's hyper parameters: Current learning rate is 0.004520795660036167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 55552/60000][Iteration 6062][Wall Clock 568.328062479s] Trained 128 records in 0.081985331 seconds. Throughput is 1561.2549 records/second. Loss is 0.1342543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004520386945122502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:05 INFO  DistriOptimizer$:408 - [Epoch 13 55680/60000][Iteration 6063][Wall Clock 568.403847962s] Trained 128 records in 0.075785483 seconds. Throughput is 1688.9779 records/second. Loss is 0.21113023. Sequential31006cbd's hyper parameters: Current learning rate is 0.00451997830410414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 55808/60000][Iteration 6064][Wall Clock 568.490689059s] Trained 128 records in 0.086841097 seconds. Throughput is 1473.9564 records/second. Loss is 0.19462046. Sequential31006cbd's hyper parameters: Current learning rate is 0.004519569736961041. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 55936/60000][Iteration 6065][Wall Clock 568.57854949s] Trained 128 records in 0.087860431 seconds. Throughput is 1456.8561 records/second. Loss is 0.2110035. Sequential31006cbd's hyper parameters: Current learning rate is 0.004519161243673174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56064/60000][Iteration 6066][Wall Clock 568.662736635s] Trained 128 records in 0.084187145 seconds. Throughput is 1520.4222 records/second. Loss is 0.14211045. Sequential31006cbd's hyper parameters: Current learning rate is 0.004518752824220515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56192/60000][Iteration 6067][Wall Clock 568.759268276s] Trained 128 records in 0.096531641 seconds. Throughput is 1325.99 records/second. Loss is 0.1431477. Sequential31006cbd's hyper parameters: Current learning rate is 0.004518344478583047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56320/60000][Iteration 6068][Wall Clock 568.841229471s] Trained 128 records in 0.081961195 seconds. Throughput is 1561.7147 records/second. Loss is 0.1969894. Sequential31006cbd's hyper parameters: Current learning rate is 0.004517936206740761. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56448/60000][Iteration 6069][Wall Clock 568.921688894s] Trained 128 records in 0.080459423 seconds. Throughput is 1590.864 records/second. Loss is 0.16722131. Sequential31006cbd's hyper parameters: Current learning rate is 0.004517528008673654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56576/60000][Iteration 6070][Wall Clock 569.01356634s] Trained 128 records in 0.091877446 seconds. Throughput is 1393.1602 records/second. Loss is 0.20207003. Sequential31006cbd's hyper parameters: Current learning rate is 0.004517119884361731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56704/60000][Iteration 6071][Wall Clock 569.09798237s] Trained 128 records in 0.08441603 seconds. Throughput is 1516.2997 records/second. Loss is 0.1611639. Sequential31006cbd's hyper parameters: Current learning rate is 0.004516711833785005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56832/60000][Iteration 6072][Wall Clock 569.185759566s] Trained 128 records in 0.087777196 seconds. Throughput is 1458.2375 records/second. Loss is 0.15243024. Sequential31006cbd's hyper parameters: Current learning rate is 0.004516303856923494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 56960/60000][Iteration 6073][Wall Clock 569.277431243s] Trained 128 records in 0.091671677 seconds. Throughput is 1396.2874 records/second. Loss is 0.18256766. Sequential31006cbd's hyper parameters: Current learning rate is 0.004515895953757225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 57088/60000][Iteration 6074][Wall Clock 569.358478941s] Trained 128 records in 0.081047698 seconds. Throughput is 1579.3169 records/second. Loss is 0.097659916. Sequential31006cbd's hyper parameters: Current learning rate is 0.004515488124266233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:06 INFO  DistriOptimizer$:408 - [Epoch 13 57216/60000][Iteration 6075][Wall Clock 569.434672939s] Trained 128 records in 0.076193998 seconds. Throughput is 1679.9224 records/second. Loss is 0.123594396. Sequential31006cbd's hyper parameters: Current learning rate is 0.004515080368430557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 57344/60000][Iteration 6076][Wall Clock 569.507064947s] Trained 128 records in 0.072392008 seconds. Throughput is 1768.151 records/second. Loss is 0.21452428. Sequential31006cbd's hyper parameters: Current learning rate is 0.004514672686230249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 57472/60000][Iteration 6077][Wall Clock 569.583830991s] Trained 128 records in 0.076766044 seconds. Throughput is 1667.4039 records/second. Loss is 0.21466261. Sequential31006cbd's hyper parameters: Current learning rate is 0.004514265077645359. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 57600/60000][Iteration 6078][Wall Clock 569.663436718s] Trained 128 records in 0.079605727 seconds. Throughput is 1607.9244 records/second. Loss is 0.15327637. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045138575426559545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 57728/60000][Iteration 6079][Wall Clock 569.746552126s] Trained 128 records in 0.083115408 seconds. Throughput is 1540.0273 records/second. Loss is 0.25346014. Sequential31006cbd's hyper parameters: Current learning rate is 0.004513450081242101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 57856/60000][Iteration 6080][Wall Clock 569.832337758s] Trained 128 records in 0.085785632 seconds. Throughput is 1492.0913 records/second. Loss is 0.11317963. Sequential31006cbd's hyper parameters: Current learning rate is 0.00451304269338388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 57984/60000][Iteration 6081][Wall Clock 569.91130714s] Trained 128 records in 0.078969382 seconds. Throughput is 1620.8813 records/second. Loss is 0.123118654. Sequential31006cbd's hyper parameters: Current learning rate is 0.004512635379061372. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 58112/60000][Iteration 6082][Wall Clock 570.039169739s] Trained 128 records in 0.127862599 seconds. Throughput is 1001.0746 records/second. Loss is 0.15268491. Sequential31006cbd's hyper parameters: Current learning rate is 0.004512228138254671. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 58240/60000][Iteration 6083][Wall Clock 570.141263885s] Trained 128 records in 0.102094146 seconds. Throughput is 1253.7448 records/second. Loss is 0.2405329. Sequential31006cbd's hyper parameters: Current learning rate is 0.004511820970943873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 58368/60000][Iteration 6084][Wall Clock 570.221685367s] Trained 128 records in 0.080421482 seconds. Throughput is 1591.6145 records/second. Loss is 0.17041185. Sequential31006cbd's hyper parameters: Current learning rate is 0.004511413877109086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 58496/60000][Iteration 6085][Wall Clock 570.303654518s] Trained 128 records in 0.081969151 seconds. Throughput is 1561.5631 records/second. Loss is 0.15289141. Sequential31006cbd's hyper parameters: Current learning rate is 0.004511006856730422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:07 INFO  DistriOptimizer$:408 - [Epoch 13 58624/60000][Iteration 6086][Wall Clock 570.381272709s] Trained 128 records in 0.077618191 seconds. Throughput is 1649.098 records/second. Loss is 0.18022047. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045105999097880016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 58752/60000][Iteration 6087][Wall Clock 570.454743821s] Trained 128 records in 0.073471112 seconds. Throughput is 1742.1813 records/second. Loss is 0.21735623. Sequential31006cbd's hyper parameters: Current learning rate is 0.004510193036261952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 58880/60000][Iteration 6088][Wall Clock 570.532636109s] Trained 128 records in 0.077892288 seconds. Throughput is 1643.2949 records/second. Loss is 0.13852586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004509786236132407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59008/60000][Iteration 6089][Wall Clock 570.608264846s] Trained 128 records in 0.075628737 seconds. Throughput is 1692.4784 records/second. Loss is 0.1664506. Sequential31006cbd's hyper parameters: Current learning rate is 0.004509379509379509. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59136/60000][Iteration 6090][Wall Clock 570.686188121s] Trained 128 records in 0.077923275 seconds. Throughput is 1642.6415 records/second. Loss is 0.18626478. Sequential31006cbd's hyper parameters: Current learning rate is 0.004508972855983407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59264/60000][Iteration 6091][Wall Clock 570.76408923s] Trained 128 records in 0.077901109 seconds. Throughput is 1643.1088 records/second. Loss is 0.18321043. Sequential31006cbd's hyper parameters: Current learning rate is 0.004508566275924256. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59392/60000][Iteration 6092][Wall Clock 570.868428853s] Trained 128 records in 0.104339623 seconds. Throughput is 1226.7631 records/second. Loss is 0.18274042. Sequential31006cbd's hyper parameters: Current learning rate is 0.00450815976918222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59520/60000][Iteration 6093][Wall Clock 570.960577966s] Trained 128 records in 0.092149113 seconds. Throughput is 1389.053 records/second. Loss is 0.17662948. Sequential31006cbd's hyper parameters: Current learning rate is 0.004507753335737469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59648/60000][Iteration 6094][Wall Clock 571.041974813s] Trained 128 records in 0.081396847 seconds. Throughput is 1572.5425 records/second. Loss is 0.13915992. Sequential31006cbd's hyper parameters: Current learning rate is 0.004507346975570179. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59776/60000][Iteration 6095][Wall Clock 571.119601074s] Trained 128 records in 0.077626261 seconds. Throughput is 1648.9266 records/second. Loss is 0.28158292. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045069406886605375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 59904/60000][Iteration 6096][Wall Clock 571.20407948s] Trained 128 records in 0.084478406 seconds. Throughput is 1515.18 records/second. Loss is 0.19240832. Sequential31006cbd's hyper parameters: Current learning rate is 0.004506534474988733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:408 - [Epoch 13 60032/60000][Iteration 6097][Wall Clock 571.280636111s] Trained 128 records in 0.076556631 seconds. Throughput is 1671.965 records/second. Loss is 0.2633597. Sequential31006cbd's hyper parameters: Current learning rate is 0.004506128334534968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:08 INFO  DistriOptimizer$:452 - [Epoch 13 60032/60000][Iteration 6097][Wall Clock 571.280636111s] Epoch finished. Wall clock time is 572362.7266 ms
2019-10-24 00:07:08 INFO  DistriOptimizer$:111 - [Epoch 13 60032/60000][Iteration 6097][Wall Clock 571.280636111s] Validate model...
2019-10-24 00:07:09 INFO  DistriOptimizer$:178 - [Epoch 13 60032/60000][Iteration 6097][Wall Clock 571.280636111s] validate model throughput is 11998.36 records/second
2019-10-24 00:07:09 INFO  DistriOptimizer$:181 - [Epoch 13 60032/60000][Iteration 6097][Wall Clock 571.280636111s] Top1Accuracy is Accuracy(correct: 9506, count: 10000, accuracy: 0.9506)
2019-10-24 00:07:09 INFO  DistriOptimizer$:221 - [Wall Clock 572.3627266s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:07:09 INFO  DistriOptimizer$:226 - [Wall Clock 572.3627266s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:07:09 INFO  DistriOptimizer$:408 - [Epoch 14 128/60000][Iteration 6098][Wall Clock 572.444030647s] Trained 128 records in 0.081304047 seconds. Throughput is 1574.3374 records/second. Loss is 0.0830103. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045057222672794444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:09 INFO  DistriOptimizer$:408 - [Epoch 14 256/60000][Iteration 6099][Wall Clock 572.525415732s] Trained 128 records in 0.081385085 seconds. Throughput is 1572.7698 records/second. Loss is 0.1298432. Sequential31006cbd's hyper parameters: Current learning rate is 0.00450531627320238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:09 INFO  DistriOptimizer$:408 - [Epoch 14 384/60000][Iteration 6100][Wall Clock 572.608563378s] Trained 128 records in 0.083147646 seconds. Throughput is 1539.4303 records/second. Loss is 0.17701964. Sequential31006cbd's hyper parameters: Current learning rate is 0.004504910352283989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 512/60000][Iteration 6101][Wall Clock 572.688084579s] Trained 128 records in 0.079521201 seconds. Throughput is 1609.6337 records/second. Loss is 0.16856675. Sequential31006cbd's hyper parameters: Current learning rate is 0.004504504504504505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 640/60000][Iteration 6102][Wall Clock 572.768436537s] Trained 128 records in 0.080351958 seconds. Throughput is 1592.9917 records/second. Loss is 0.17191637. Sequential31006cbd's hyper parameters: Current learning rate is 0.004504098729844158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 768/60000][Iteration 6103][Wall Clock 572.861069666s] Trained 128 records in 0.092633129 seconds. Throughput is 1381.795 records/second. Loss is 0.08940117. Sequential31006cbd's hyper parameters: Current learning rate is 0.004503693028283192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 896/60000][Iteration 6104][Wall Clock 572.940996967s] Trained 128 records in 0.079927301 seconds. Throughput is 1601.4553 records/second. Loss is 0.15951626. Sequential31006cbd's hyper parameters: Current learning rate is 0.004503287399801856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1024/60000][Iteration 6105][Wall Clock 573.03188344s] Trained 128 records in 0.090886473 seconds. Throughput is 1408.3503 records/second. Loss is 0.19156651. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045028818443804035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1152/60000][Iteration 6106][Wall Clock 573.112695443s] Trained 128 records in 0.080812003 seconds. Throughput is 1583.9232 records/second. Loss is 0.16781692. Sequential31006cbd's hyper parameters: Current learning rate is 0.004502476361999099. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1280/60000][Iteration 6107][Wall Clock 573.198117136s] Trained 128 records in 0.085421693 seconds. Throughput is 1498.4484 records/second. Loss is 0.16259597. Sequential31006cbd's hyper parameters: Current learning rate is 0.0045020709526382135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1408/60000][Iteration 6108][Wall Clock 573.286414565s] Trained 128 records in 0.088297429 seconds. Throughput is 1449.6459 records/second. Loss is 0.15241405. Sequential31006cbd's hyper parameters: Current learning rate is 0.004501665616278023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1536/60000][Iteration 6109][Wall Clock 573.366705325s] Trained 128 records in 0.08029076 seconds. Throughput is 1594.2059 records/second. Loss is 0.18922958. Sequential31006cbd's hyper parameters: Current learning rate is 0.004501260352898812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1664/60000][Iteration 6110][Wall Clock 573.442654288s] Trained 128 records in 0.075948963 seconds. Throughput is 1685.3423 records/second. Loss is 0.16345327. Sequential31006cbd's hyper parameters: Current learning rate is 0.004500855162480871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:10 INFO  DistriOptimizer$:408 - [Epoch 14 1792/60000][Iteration 6111][Wall Clock 573.537210503s] Trained 128 records in 0.094556215 seconds. Throughput is 1353.6921 records/second. Loss is 0.16194993. Sequential31006cbd's hyper parameters: Current learning rate is 0.004500450045004501. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 1920/60000][Iteration 6112][Wall Clock 573.621041337s] Trained 128 records in 0.083830834 seconds. Throughput is 1526.8845 records/second. Loss is 0.22842312. Sequential31006cbd's hyper parameters: Current learning rate is 0.004500045000450005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2048/60000][Iteration 6113][Wall Clock 573.699527888s] Trained 128 records in 0.078486551 seconds. Throughput is 1630.8525 records/second. Loss is 0.117921434. Sequential31006cbd's hyper parameters: Current learning rate is 0.004499640028797695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2176/60000][Iteration 6114][Wall Clock 573.785948805s] Trained 128 records in 0.086420917 seconds. Throughput is 1481.1229 records/second. Loss is 0.24789208. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044992351300278954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2304/60000][Iteration 6115][Wall Clock 573.864279077s] Trained 128 records in 0.078330272 seconds. Throughput is 1634.1064 records/second. Loss is 0.16232863. Sequential31006cbd's hyper parameters: Current learning rate is 0.004498830304120928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2432/60000][Iteration 6116][Wall Clock 573.943613793s] Trained 128 records in 0.079334716 seconds. Throughput is 1613.4174 records/second. Loss is 0.26254198. Sequential31006cbd's hyper parameters: Current learning rate is 0.00449842555105713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2560/60000][Iteration 6117][Wall Clock 574.01601261s] Trained 128 records in 0.072398817 seconds. Throughput is 1767.9846 records/second. Loss is 0.21521746. Sequential31006cbd's hyper parameters: Current learning rate is 0.00449802087081684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2688/60000][Iteration 6118][Wall Clock 574.098675728s] Trained 128 records in 0.082663118 seconds. Throughput is 1548.4535 records/second. Loss is 0.18400082. Sequential31006cbd's hyper parameters: Current learning rate is 0.004497616263380409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2816/60000][Iteration 6119][Wall Clock 574.177879627s] Trained 128 records in 0.079203899 seconds. Throughput is 1616.0822 records/second. Loss is 0.20329475. Sequential31006cbd's hyper parameters: Current learning rate is 0.004497211728728188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 2944/60000][Iteration 6120][Wall Clock 574.258324868s] Trained 128 records in 0.080445241 seconds. Throughput is 1591.1445 records/second. Loss is 0.17021224. Sequential31006cbd's hyper parameters: Current learning rate is 0.004496807266840544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 3072/60000][Iteration 6121][Wall Clock 574.352516792s] Trained 128 records in 0.094191924 seconds. Throughput is 1358.9275 records/second. Loss is 0.24126747. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044964028776978415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 3200/60000][Iteration 6122][Wall Clock 574.450317483s] Trained 128 records in 0.097800691 seconds. Throughput is 1308.7842 records/second. Loss is 0.17453456. Sequential31006cbd's hyper parameters: Current learning rate is 0.004495998561280461. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:11 INFO  DistriOptimizer$:408 - [Epoch 14 3328/60000][Iteration 6123][Wall Clock 574.549898361s] Trained 128 records in 0.099580878 seconds. Throughput is 1285.3873 records/second. Loss is 0.15068808. Sequential31006cbd's hyper parameters: Current learning rate is 0.004495594317568782. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 3456/60000][Iteration 6124][Wall Clock 574.636574733s] Trained 128 records in 0.086676372 seconds. Throughput is 1476.7577 records/second. Loss is 0.10829054. Sequential31006cbd's hyper parameters: Current learning rate is 0.004495190146543198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 3584/60000][Iteration 6125][Wall Clock 574.719938955s] Trained 128 records in 0.083364222 seconds. Throughput is 1535.4309 records/second. Loss is 0.12983154. Sequential31006cbd's hyper parameters: Current learning rate is 0.004494786048184107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 3712/60000][Iteration 6126][Wall Clock 574.801908054s] Trained 128 records in 0.081969099 seconds. Throughput is 1561.5641 records/second. Loss is 0.20236833. Sequential31006cbd's hyper parameters: Current learning rate is 0.00449438202247191. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 3840/60000][Iteration 6127][Wall Clock 574.887647749s] Trained 128 records in 0.085739695 seconds. Throughput is 1492.8907 records/second. Loss is 0.12193592. Sequential31006cbd's hyper parameters: Current learning rate is 0.004493978069387021. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 3968/60000][Iteration 6128][Wall Clock 574.965980117s] Trained 128 records in 0.078332368 seconds. Throughput is 1634.0627 records/second. Loss is 0.29351336. Sequential31006cbd's hyper parameters: Current learning rate is 0.004493574188909859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4096/60000][Iteration 6129][Wall Clock 575.043389973s] Trained 128 records in 0.077409856 seconds. Throughput is 1653.5363 records/second. Loss is 0.19690724. Sequential31006cbd's hyper parameters: Current learning rate is 0.004493170381020848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4224/60000][Iteration 6130][Wall Clock 575.121541191s] Trained 128 records in 0.078151218 seconds. Throughput is 1637.8503 records/second. Loss is 0.14436516. Sequential31006cbd's hyper parameters: Current learning rate is 0.004492766645700422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4352/60000][Iteration 6131][Wall Clock 575.205546663s] Trained 128 records in 0.084005472 seconds. Throughput is 1523.7102 records/second. Loss is 0.14681748. Sequential31006cbd's hyper parameters: Current learning rate is 0.004492362982929021. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4480/60000][Iteration 6132][Wall Clock 575.295006959s] Trained 128 records in 0.089460296 seconds. Throughput is 1430.8022 records/second. Loss is 0.14153655. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044919593926870905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4608/60000][Iteration 6133][Wall Clock 575.379418199s] Trained 128 records in 0.08441124 seconds. Throughput is 1516.3857 records/second. Loss is 0.19167528. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044915558749550845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4736/60000][Iteration 6134][Wall Clock 575.455331586s] Trained 128 records in 0.075913387 seconds. Throughput is 1686.1322 records/second. Loss is 0.20535274. Sequential31006cbd's hyper parameters: Current learning rate is 0.004491152429713464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:12 INFO  DistriOptimizer$:408 - [Epoch 14 4864/60000][Iteration 6135][Wall Clock 575.528176054s] Trained 128 records in 0.072844468 seconds. Throughput is 1757.1685 records/second. Loss is 0.26256582. Sequential31006cbd's hyper parameters: Current learning rate is 0.004490749056942698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 4992/60000][Iteration 6136][Wall Clock 575.604522673s] Trained 128 records in 0.076346619 seconds. Throughput is 1676.5641 records/second. Loss is 0.16438007. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044903457566232595. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5120/60000][Iteration 6137][Wall Clock 575.686952825s] Trained 128 records in 0.082430152 seconds. Throughput is 1552.8298 records/second. Loss is 0.19403332. Sequential31006cbd's hyper parameters: Current learning rate is 0.004489942528735633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5248/60000][Iteration 6138][Wall Clock 575.767839611s] Trained 128 records in 0.080886786 seconds. Throughput is 1582.4586 records/second. Loss is 0.07234461. Sequential31006cbd's hyper parameters: Current learning rate is 0.004489539373260303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5376/60000][Iteration 6139][Wall Clock 575.842954656s] Trained 128 records in 0.075115045 seconds. Throughput is 1704.0527 records/second. Loss is 0.08007923. Sequential31006cbd's hyper parameters: Current learning rate is 0.00448913629017777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5504/60000][Iteration 6140][Wall Clock 575.921945012s] Trained 128 records in 0.078990356 seconds. Throughput is 1620.451 records/second. Loss is 0.15693738. Sequential31006cbd's hyper parameters: Current learning rate is 0.004488733279468533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5632/60000][Iteration 6141][Wall Clock 576.001028911s] Trained 128 records in 0.079083899 seconds. Throughput is 1618.5343 records/second. Loss is 0.21671188. Sequential31006cbd's hyper parameters: Current learning rate is 0.004488330341113106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5760/60000][Iteration 6142][Wall Clock 576.076324959s] Trained 128 records in 0.075296048 seconds. Throughput is 1699.9565 records/second. Loss is 0.21275423. Sequential31006cbd's hyper parameters: Current learning rate is 0.004487927475092002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 5888/60000][Iteration 6143][Wall Clock 576.155181298s] Trained 128 records in 0.078856339 seconds. Throughput is 1623.205 records/second. Loss is 0.14333858. Sequential31006cbd's hyper parameters: Current learning rate is 0.004487524681385747. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 6016/60000][Iteration 6144][Wall Clock 576.244202031s] Trained 128 records in 0.089020733 seconds. Throughput is 1437.8672 records/second. Loss is 0.19428027. Sequential31006cbd's hyper parameters: Current learning rate is 0.004487121959974872. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 6144/60000][Iteration 6145][Wall Clock 576.324516131s] Trained 128 records in 0.0803141 seconds. Throughput is 1593.7426 records/second. Loss is 0.13251017. Sequential31006cbd's hyper parameters: Current learning rate is 0.004486719310839914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 6272/60000][Iteration 6146][Wall Clock 576.408438778s] Trained 128 records in 0.083922647 seconds. Throughput is 1525.214 records/second. Loss is 0.17261674. Sequential31006cbd's hyper parameters: Current learning rate is 0.004486316733961417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:13 INFO  DistriOptimizer$:408 - [Epoch 14 6400/60000][Iteration 6147][Wall Clock 576.491754471s] Trained 128 records in 0.083315693 seconds. Throughput is 1536.3252 records/second. Loss is 0.24563989. Sequential31006cbd's hyper parameters: Current learning rate is 0.004485914229319935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 6528/60000][Iteration 6148][Wall Clock 576.604318696s] Trained 128 records in 0.112564225 seconds. Throughput is 1137.1285 records/second. Loss is 0.25053313. Sequential31006cbd's hyper parameters: Current learning rate is 0.004485511796896026. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 6656/60000][Iteration 6149][Wall Clock 576.687563295s] Trained 128 records in 0.083244599 seconds. Throughput is 1537.6373 records/second. Loss is 0.17884536. Sequential31006cbd's hyper parameters: Current learning rate is 0.004485109436670255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 6784/60000][Iteration 6150][Wall Clock 576.758144373s] Trained 128 records in 0.070581078 seconds. Throughput is 1813.5172 records/second. Loss is 0.12694539. Sequential31006cbd's hyper parameters: Current learning rate is 0.004484707148623195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 6912/60000][Iteration 6151][Wall Clock 576.831220744s] Trained 128 records in 0.073076371 seconds. Throughput is 1751.5923 records/second. Loss is 0.19261743. Sequential31006cbd's hyper parameters: Current learning rate is 0.004484304932735426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7040/60000][Iteration 6152][Wall Clock 576.916883729s] Trained 128 records in 0.085662985 seconds. Throughput is 1494.2277 records/second. Loss is 0.19093. Sequential31006cbd's hyper parameters: Current learning rate is 0.004483902788987535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7168/60000][Iteration 6153][Wall Clock 577.022636813s] Trained 128 records in 0.105753084 seconds. Throughput is 1210.3666 records/second. Loss is 0.18731186. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044835007173601145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7296/60000][Iteration 6154][Wall Clock 577.101863886s] Trained 128 records in 0.079227073 seconds. Throughput is 1615.6093 records/second. Loss is 0.17778482. Sequential31006cbd's hyper parameters: Current learning rate is 0.004483098717833767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7424/60000][Iteration 6155][Wall Clock 577.211706782s] Trained 128 records in 0.109842896 seconds. Throughput is 1165.3007 records/second. Loss is 0.16377728. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044826967903890975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7552/60000][Iteration 6156][Wall Clock 577.296269363s] Trained 128 records in 0.084562581 seconds. Throughput is 1513.6719 records/second. Loss is 0.20338604. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044822949350067235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7680/60000][Iteration 6157][Wall Clock 577.396117266s] Trained 128 records in 0.099847903 seconds. Throughput is 1281.9498 records/second. Loss is 0.22001642. Sequential31006cbd's hyper parameters: Current learning rate is 0.004481893151667264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7808/60000][Iteration 6158][Wall Clock 577.484845226s] Trained 128 records in 0.08872796 seconds. Throughput is 1442.6118 records/second. Loss is 0.19521144. Sequential31006cbd's hyper parameters: Current learning rate is 0.00448149144035135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:14 INFO  DistriOptimizer$:408 - [Epoch 14 7936/60000][Iteration 6159][Wall Clock 577.562331256s] Trained 128 records in 0.07748603 seconds. Throughput is 1651.9106 records/second. Loss is 0.1381163. Sequential31006cbd's hyper parameters: Current learning rate is 0.004481089801039613. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8064/60000][Iteration 6160][Wall Clock 577.644668581s] Trained 128 records in 0.082337325 seconds. Throughput is 1554.5804 records/second. Loss is 0.079369575. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044806882337126985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8192/60000][Iteration 6161][Wall Clock 577.724016789s] Trained 128 records in 0.079348208 seconds. Throughput is 1613.143 records/second. Loss is 0.29640287. Sequential31006cbd's hyper parameters: Current learning rate is 0.004480286738351254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8320/60000][Iteration 6162][Wall Clock 577.802554892s] Trained 128 records in 0.078538103 seconds. Throughput is 1629.7821 records/second. Loss is 0.14533617. Sequential31006cbd's hyper parameters: Current learning rate is 0.004479885314935938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8448/60000][Iteration 6163][Wall Clock 577.877032785s] Trained 128 records in 0.074477893 seconds. Throughput is 1718.6307 records/second. Loss is 0.15638986. Sequential31006cbd's hyper parameters: Current learning rate is 0.004479483963447411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8576/60000][Iteration 6164][Wall Clock 577.951979714s] Trained 128 records in 0.074946929 seconds. Throughput is 1707.8751 records/second. Loss is 0.16804184. Sequential31006cbd's hyper parameters: Current learning rate is 0.004479082683866344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8704/60000][Iteration 6165][Wall Clock 578.033207721s] Trained 128 records in 0.081228007 seconds. Throughput is 1575.811 records/second. Loss is 0.16135304. Sequential31006cbd's hyper parameters: Current learning rate is 0.004478681476173414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8832/60000][Iteration 6166][Wall Clock 578.102479272s] Trained 128 records in 0.069271551 seconds. Throughput is 1847.8004 records/second. Loss is 0.19139005. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044782803403493054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 8960/60000][Iteration 6167][Wall Clock 578.176838329s] Trained 128 records in 0.074359057 seconds. Throughput is 1721.3773 records/second. Loss is 0.20090501. Sequential31006cbd's hyper parameters: Current learning rate is 0.004477879276374709. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 9088/60000][Iteration 6168][Wall Clock 578.253762552s] Trained 128 records in 0.076924223 seconds. Throughput is 1663.9752 records/second. Loss is 0.16820374. Sequential31006cbd's hyper parameters: Current learning rate is 0.004477478284230322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 9216/60000][Iteration 6169][Wall Clock 578.342415396s] Trained 128 records in 0.088652844 seconds. Throughput is 1443.8341 records/second. Loss is 0.1782602. Sequential31006cbd's hyper parameters: Current learning rate is 0.004477077363896848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 9344/60000][Iteration 6170][Wall Clock 578.423457448s] Trained 128 records in 0.081042052 seconds. Throughput is 1579.427 records/second. Loss is 0.15986824. Sequential31006cbd's hyper parameters: Current learning rate is 0.004476676515355001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:15 INFO  DistriOptimizer$:408 - [Epoch 14 9472/60000][Iteration 6171][Wall Clock 578.5055154s] Trained 128 records in 0.082057952 seconds. Throughput is 1559.8732 records/second. Loss is 0.20228274. Sequential31006cbd's hyper parameters: Current learning rate is 0.004476275738585497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 9600/60000][Iteration 6172][Wall Clock 578.608916838s] Trained 128 records in 0.103401438 seconds. Throughput is 1237.8938 records/second. Loss is 0.17362988. Sequential31006cbd's hyper parameters: Current learning rate is 0.004475875033569063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 9728/60000][Iteration 6173][Wall Clock 578.682538858s] Trained 128 records in 0.07362202 seconds. Throughput is 1738.6104 records/second. Loss is 0.19786432. Sequential31006cbd's hyper parameters: Current learning rate is 0.004475474400286431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 9856/60000][Iteration 6174][Wall Clock 578.767059617s] Trained 128 records in 0.084520759 seconds. Throughput is 1514.4209 records/second. Loss is 0.16511288. Sequential31006cbd's hyper parameters: Current learning rate is 0.004475073838718338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 9984/60000][Iteration 6175][Wall Clock 578.858878769s] Trained 128 records in 0.091819152 seconds. Throughput is 1394.0447 records/second. Loss is 0.15664555. Sequential31006cbd's hyper parameters: Current learning rate is 0.004474673348845534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10112/60000][Iteration 6176][Wall Clock 578.957260641s] Trained 128 records in 0.098381872 seconds. Throughput is 1301.0527 records/second. Loss is 0.19047134. Sequential31006cbd's hyper parameters: Current learning rate is 0.004474272930648769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10240/60000][Iteration 6177][Wall Clock 579.051375195s] Trained 128 records in 0.094114554 seconds. Throughput is 1360.0447 records/second. Loss is 0.24922428. Sequential31006cbd's hyper parameters: Current learning rate is 0.004473872584108805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10368/60000][Iteration 6178][Wall Clock 579.149172099s] Trained 128 records in 0.097796904 seconds. Throughput is 1308.835 records/second. Loss is 0.23077913. Sequential31006cbd's hyper parameters: Current learning rate is 0.004473472309206405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10496/60000][Iteration 6179][Wall Clock 579.236638755s] Trained 128 records in 0.087466656 seconds. Throughput is 1463.4148 records/second. Loss is 0.22088276. Sequential31006cbd's hyper parameters: Current learning rate is 0.004473072105922348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10624/60000][Iteration 6180][Wall Clock 579.329373416s] Trained 128 records in 0.092734661 seconds. Throughput is 1380.2821 records/second. Loss is 0.15094663. Sequential31006cbd's hyper parameters: Current learning rate is 0.004472671974237409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10752/60000][Iteration 6181][Wall Clock 579.412385005s] Trained 128 records in 0.083011589 seconds. Throughput is 1541.9534 records/second. Loss is 0.23824526. Sequential31006cbd's hyper parameters: Current learning rate is 0.00447227191413238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 10880/60000][Iteration 6182][Wall Clock 579.48714427s] Trained 128 records in 0.074759265 seconds. Throughput is 1712.1624 records/second. Loss is 0.16611354. Sequential31006cbd's hyper parameters: Current learning rate is 0.004471871925588051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:16 INFO  DistriOptimizer$:408 - [Epoch 14 11008/60000][Iteration 6183][Wall Clock 579.561025454s] Trained 128 records in 0.073881184 seconds. Throughput is 1732.5115 records/second. Loss is 0.18851608. Sequential31006cbd's hyper parameters: Current learning rate is 0.004471472008585226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11136/60000][Iteration 6184][Wall Clock 579.629157147s] Trained 128 records in 0.068131693 seconds. Throughput is 1878.7145 records/second. Loss is 0.25601947. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044710721631047124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11264/60000][Iteration 6185][Wall Clock 579.705106855s] Trained 128 records in 0.075949708 seconds. Throughput is 1685.3258 records/second. Loss is 0.24281724. Sequential31006cbd's hyper parameters: Current learning rate is 0.004470672389127324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11392/60000][Iteration 6186][Wall Clock 579.78808967s] Trained 128 records in 0.082982815 seconds. Throughput is 1542.488 records/second. Loss is 0.123085305. Sequential31006cbd's hyper parameters: Current learning rate is 0.004470272686633884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11520/60000][Iteration 6187][Wall Clock 579.864143195s] Trained 128 records in 0.076053525 seconds. Throughput is 1683.0253 records/second. Loss is 0.26708755. Sequential31006cbd's hyper parameters: Current learning rate is 0.004469873055605221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11648/60000][Iteration 6188][Wall Clock 579.939846785s] Trained 128 records in 0.07570359 seconds. Throughput is 1690.8048 records/second. Loss is 0.11940795. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044694734960221685. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11776/60000][Iteration 6189][Wall Clock 580.018028692s] Trained 128 records in 0.078181907 seconds. Throughput is 1637.2074 records/second. Loss is 0.15355057. Sequential31006cbd's hyper parameters: Current learning rate is 0.00446907400786557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 11904/60000][Iteration 6190][Wall Clock 580.093687382s] Trained 128 records in 0.07565869 seconds. Throughput is 1691.8083 records/second. Loss is 0.19468231. Sequential31006cbd's hyper parameters: Current learning rate is 0.004468674591116275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 12032/60000][Iteration 6191][Wall Clock 580.168153481s] Trained 128 records in 0.074466099 seconds. Throughput is 1718.903 records/second. Loss is 0.18262762. Sequential31006cbd's hyper parameters: Current learning rate is 0.004468275245755138. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 12160/60000][Iteration 6192][Wall Clock 580.242087606s] Trained 128 records in 0.073934125 seconds. Throughput is 1731.271 records/second. Loss is 0.17803192. Sequential31006cbd's hyper parameters: Current learning rate is 0.004467875971763024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 12288/60000][Iteration 6193][Wall Clock 580.319164412s] Trained 128 records in 0.077076806 seconds. Throughput is 1660.6812 records/second. Loss is 0.14785233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044674767691208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 12416/60000][Iteration 6194][Wall Clock 580.396159805s] Trained 128 records in 0.076995393 seconds. Throughput is 1662.4371 records/second. Loss is 0.12667832. Sequential31006cbd's hyper parameters: Current learning rate is 0.004467077637809345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 12544/60000][Iteration 6195][Wall Clock 580.48041033s] Trained 128 records in 0.084250525 seconds. Throughput is 1519.2783 records/second. Loss is 0.17361987. Sequential31006cbd's hyper parameters: Current learning rate is 0.004466678577809541. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:17 INFO  DistriOptimizer$:408 - [Epoch 14 12672/60000][Iteration 6196][Wall Clock 580.560451203s] Trained 128 records in 0.080040873 seconds. Throughput is 1599.183 records/second. Loss is 0.14894398. Sequential31006cbd's hyper parameters: Current learning rate is 0.004466279589102278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 12800/60000][Iteration 6197][Wall Clock 580.633300542s] Trained 128 records in 0.072849339 seconds. Throughput is 1757.0509 records/second. Loss is 0.2647311. Sequential31006cbd's hyper parameters: Current learning rate is 0.004465880671668453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 12928/60000][Iteration 6198][Wall Clock 580.722070281s] Trained 128 records in 0.088769739 seconds. Throughput is 1441.9327 records/second. Loss is 0.22398911. Sequential31006cbd's hyper parameters: Current learning rate is 0.004465481825488971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13056/60000][Iteration 6199][Wall Clock 580.805371391s] Trained 128 records in 0.08330111 seconds. Throughput is 1536.5941 records/second. Loss is 0.27244294. Sequential31006cbd's hyper parameters: Current learning rate is 0.004465083050544739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13184/60000][Iteration 6200][Wall Clock 580.886071313s] Trained 128 records in 0.080699922 seconds. Throughput is 1586.123 records/second. Loss is 0.1990874. Sequential31006cbd's hyper parameters: Current learning rate is 0.00446468434681668. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13312/60000][Iteration 6201][Wall Clock 580.981901719s] Trained 128 records in 0.095830406 seconds. Throughput is 1335.693 records/second. Loss is 0.1927568. Sequential31006cbd's hyper parameters: Current learning rate is 0.004464285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13440/60000][Iteration 6202][Wall Clock 581.075428998s] Trained 128 records in 0.093527279 seconds. Throughput is 1368.5846 records/second. Loss is 0.14535531. Sequential31006cbd's hyper parameters: Current learning rate is 0.004463887152932775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13568/60000][Iteration 6203][Wall Clock 581.160818708s] Trained 128 records in 0.08538971 seconds. Throughput is 1499.0096 records/second. Loss is 0.17035109. Sequential31006cbd's hyper parameters: Current learning rate is 0.004463488662738797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13696/60000][Iteration 6204][Wall Clock 581.250904538s] Trained 128 records in 0.09008583 seconds. Throughput is 1420.8672 records/second. Loss is 0.1558894. Sequential31006cbd's hyper parameters: Current learning rate is 0.004463090243684727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13824/60000][Iteration 6205][Wall Clock 581.332390237s] Trained 128 records in 0.081485699 seconds. Throughput is 1570.8279 records/second. Loss is 0.113539845. Sequential31006cbd's hyper parameters: Current learning rate is 0.004462691895751517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 13952/60000][Iteration 6206][Wall Clock 581.422267585s] Trained 128 records in 0.089877348 seconds. Throughput is 1424.1631 records/second. Loss is 0.18789217. Sequential31006cbd's hyper parameters: Current learning rate is 0.004462293618920125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:18 INFO  DistriOptimizer$:408 - [Epoch 14 14080/60000][Iteration 6207][Wall Clock 581.512109s] Trained 128 records in 0.089841415 seconds. Throughput is 1424.7327 records/second. Loss is 0.25365692. Sequential31006cbd's hyper parameters: Current learning rate is 0.004461895413171515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14208/60000][Iteration 6208][Wall Clock 581.600237234s] Trained 128 records in 0.088128234 seconds. Throughput is 1452.429 records/second. Loss is 0.16986082. Sequential31006cbd's hyper parameters: Current learning rate is 0.00446149727848666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14336/60000][Iteration 6209][Wall Clock 581.68427681s] Trained 128 records in 0.084039576 seconds. Throughput is 1523.0919 records/second. Loss is 0.22383781. Sequential31006cbd's hyper parameters: Current learning rate is 0.004461099214846539. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14464/60000][Iteration 6210][Wall Clock 581.761786197s] Trained 128 records in 0.077509387 seconds. Throughput is 1651.4128 records/second. Loss is 0.16718394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004460701222232135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14592/60000][Iteration 6211][Wall Clock 581.843015334s] Trained 128 records in 0.081229137 seconds. Throughput is 1575.7893 records/second. Loss is 0.14710426. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044603033006244425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14720/60000][Iteration 6212][Wall Clock 581.92172663s] Trained 128 records in 0.078711296 seconds. Throughput is 1626.1962 records/second. Loss is 0.11841745. Sequential31006cbd's hyper parameters: Current learning rate is 0.00445990545000446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14848/60000][Iteration 6213][Wall Clock 582.001268795s] Trained 128 records in 0.079542165 seconds. Throughput is 1609.2094 records/second. Loss is 0.18381351. Sequential31006cbd's hyper parameters: Current learning rate is 0.004459507670353193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 14976/60000][Iteration 6214][Wall Clock 582.081168841s] Trained 128 records in 0.079900046 seconds. Throughput is 1602.0016 records/second. Loss is 0.15919356. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044591099616516534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 15104/60000][Iteration 6215][Wall Clock 582.158873018s] Trained 128 records in 0.077704177 seconds. Throughput is 1647.2731 records/second. Loss is 0.16152653. Sequential31006cbd's hyper parameters: Current learning rate is 0.004458712323880863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 15232/60000][Iteration 6216][Wall Clock 582.234901673s] Trained 128 records in 0.076028655 seconds. Throughput is 1683.5758 records/second. Loss is 0.3113727. Sequential31006cbd's hyper parameters: Current learning rate is 0.004458314757021845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 15360/60000][Iteration 6217][Wall Clock 582.31229795s] Trained 128 records in 0.077396277 seconds. Throughput is 1653.8264 records/second. Loss is 0.19163013. Sequential31006cbd's hyper parameters: Current learning rate is 0.004457917261055635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 15488/60000][Iteration 6218][Wall Clock 582.390543192s] Trained 128 records in 0.078245242 seconds. Throughput is 1635.8822 records/second. Loss is 0.19376165. Sequential31006cbd's hyper parameters: Current learning rate is 0.004457519835963269. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 15616/60000][Iteration 6219][Wall Clock 582.477733539s] Trained 128 records in 0.087190347 seconds. Throughput is 1468.0525 records/second. Loss is 0.22193874. Sequential31006cbd's hyper parameters: Current learning rate is 0.004457122481725798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:19 INFO  DistriOptimizer$:408 - [Epoch 14 15744/60000][Iteration 6220][Wall Clock 582.565773852s] Trained 128 records in 0.088040313 seconds. Throughput is 1453.8794 records/second. Loss is 0.15587705. Sequential31006cbd's hyper parameters: Current learning rate is 0.004456725198324271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 15872/60000][Iteration 6221][Wall Clock 582.640288687s] Trained 128 records in 0.074514835 seconds. Throughput is 1717.7787 records/second. Loss is 0.1586073. Sequential31006cbd's hyper parameters: Current learning rate is 0.004456327985739751. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16000/60000][Iteration 6222][Wall Clock 582.722520408s] Trained 128 records in 0.082231721 seconds. Throughput is 1556.5769 records/second. Loss is 0.14173324. Sequential31006cbd's hyper parameters: Current learning rate is 0.004455930843953302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16128/60000][Iteration 6223][Wall Clock 582.799868179s] Trained 128 records in 0.077347771 seconds. Throughput is 1654.8635 records/second. Loss is 0.1349125. Sequential31006cbd's hyper parameters: Current learning rate is 0.004455533772946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16256/60000][Iteration 6224][Wall Clock 582.897450958s] Trained 128 records in 0.097582779 seconds. Throughput is 1311.7068 records/second. Loss is 0.1753479. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044551367726989215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16384/60000][Iteration 6225][Wall Clock 582.975110601s] Trained 128 records in 0.077659643 seconds. Throughput is 1648.2177 records/second. Loss is 0.22916397. Sequential31006cbd's hyper parameters: Current learning rate is 0.004454739843193158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16512/60000][Iteration 6226][Wall Clock 583.080498155s] Trained 128 records in 0.105387554 seconds. Throughput is 1214.5647 records/second. Loss is 0.20029914. Sequential31006cbd's hyper parameters: Current learning rate is 0.004454342984409799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16640/60000][Iteration 6227][Wall Clock 583.183707038s] Trained 128 records in 0.103208883 seconds. Throughput is 1240.2032 records/second. Loss is 0.1734901. Sequential31006cbd's hyper parameters: Current learning rate is 0.004453946196329948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16768/60000][Iteration 6228][Wall Clock 583.266155158s] Trained 128 records in 0.08244812 seconds. Throughput is 1552.4915 records/second. Loss is 0.16270958. Sequential31006cbd's hyper parameters: Current learning rate is 0.004453549478934711. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 16896/60000][Iteration 6229][Wall Clock 583.345757925s] Trained 128 records in 0.079602767 seconds. Throughput is 1607.9843 records/second. Loss is 0.1192843. Sequential31006cbd's hyper parameters: Current learning rate is 0.004453152832205202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 17024/60000][Iteration 6230][Wall Clock 583.42194893s] Trained 128 records in 0.076191005 seconds. Throughput is 1679.9883 records/second. Loss is 0.14138804. Sequential31006cbd's hyper parameters: Current learning rate is 0.00445275625612254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:20 INFO  DistriOptimizer$:408 - [Epoch 14 17152/60000][Iteration 6231][Wall Clock 583.500468878s] Trained 128 records in 0.078519948 seconds. Throughput is 1630.159 records/second. Loss is 0.17292169. Sequential31006cbd's hyper parameters: Current learning rate is 0.004452359750667854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 17280/60000][Iteration 6232][Wall Clock 583.592513782s] Trained 128 records in 0.092044904 seconds. Throughput is 1390.6256 records/second. Loss is 0.1597576. Sequential31006cbd's hyper parameters: Current learning rate is 0.004451963315822278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 17408/60000][Iteration 6233][Wall Clock 583.683856708s] Trained 128 records in 0.091342926 seconds. Throughput is 1401.3126 records/second. Loss is 0.115014195. Sequential31006cbd's hyper parameters: Current learning rate is 0.004451566951566952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 17536/60000][Iteration 6234][Wall Clock 583.770955528s] Trained 128 records in 0.08709882 seconds. Throughput is 1469.5951 records/second. Loss is 0.14872043. Sequential31006cbd's hyper parameters: Current learning rate is 0.004451170657883023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 17664/60000][Iteration 6235][Wall Clock 583.856237329s] Trained 128 records in 0.085281801 seconds. Throughput is 1500.9064 records/second. Loss is 0.1572789. Sequential31006cbd's hyper parameters: Current learning rate is 0.004450774434751646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 17792/60000][Iteration 6236][Wall Clock 583.950398994s] Trained 128 records in 0.094161665 seconds. Throughput is 1359.3643 records/second. Loss is 0.17934589. Sequential31006cbd's hyper parameters: Current learning rate is 0.004450378282153984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 17920/60000][Iteration 6237][Wall Clock 584.022762537s] Trained 128 records in 0.072363543 seconds. Throughput is 1768.8466 records/second. Loss is 0.14927179. Sequential31006cbd's hyper parameters: Current learning rate is 0.004449982200071199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 18048/60000][Iteration 6238][Wall Clock 584.100967522s] Trained 128 records in 0.078204985 seconds. Throughput is 1636.7244 records/second. Loss is 0.22532094. Sequential31006cbd's hyper parameters: Current learning rate is 0.004449586188484471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 18176/60000][Iteration 6239][Wall Clock 584.19184395s] Trained 128 records in 0.090876428 seconds. Throughput is 1408.506 records/second. Loss is 0.15392187. Sequential31006cbd's hyper parameters: Current learning rate is 0.004449190247374978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 18304/60000][Iteration 6240][Wall Clock 584.272425025s] Trained 128 records in 0.080581075 seconds. Throughput is 1588.4623 records/second. Loss is 0.13845494. Sequential31006cbd's hyper parameters: Current learning rate is 0.004448794376723908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 18432/60000][Iteration 6241][Wall Clock 584.347351457s] Trained 128 records in 0.074926432 seconds. Throughput is 1708.3425 records/second. Loss is 0.17833817. Sequential31006cbd's hyper parameters: Current learning rate is 0.004448398576512455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 18560/60000][Iteration 6242][Wall Clock 584.419837885s] Trained 128 records in 0.072486428 seconds. Throughput is 1765.8478 records/second. Loss is 0.169767. Sequential31006cbd's hyper parameters: Current learning rate is 0.004448002846721822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:21 INFO  DistriOptimizer$:408 - [Epoch 14 18688/60000][Iteration 6243][Wall Clock 584.497150589s] Trained 128 records in 0.077312704 seconds. Throughput is 1655.6141 records/second. Loss is 0.16305307. Sequential31006cbd's hyper parameters: Current learning rate is 0.004447607187333214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 18816/60000][Iteration 6244][Wall Clock 584.572649328s] Trained 128 records in 0.075498739 seconds. Throughput is 1695.3926 records/second. Loss is 0.17265555. Sequential31006cbd's hyper parameters: Current learning rate is 0.004447211598327849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 18944/60000][Iteration 6245][Wall Clock 584.653825108s] Trained 128 records in 0.08117578 seconds. Throughput is 1576.825 records/second. Loss is 0.09394695. Sequential31006cbd's hyper parameters: Current learning rate is 0.004446816079686944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19072/60000][Iteration 6246][Wall Clock 584.736650758s] Trained 128 records in 0.08282565 seconds. Throughput is 1545.4149 records/second. Loss is 0.21836346. Sequential31006cbd's hyper parameters: Current learning rate is 0.004446420631391729. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19200/60000][Iteration 6247][Wall Clock 584.814349679s] Trained 128 records in 0.077698921 seconds. Throughput is 1647.3845 records/second. Loss is 0.15355718. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044460252534234395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19328/60000][Iteration 6248][Wall Clock 584.894536634s] Trained 128 records in 0.080186955 seconds. Throughput is 1596.2697 records/second. Loss is 0.26824632. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044456299457633144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19456/60000][Iteration 6249][Wall Clock 585.007220657s] Trained 128 records in 0.112684023 seconds. Throughput is 1135.9197 records/second. Loss is 0.21133246. Sequential31006cbd's hyper parameters: Current learning rate is 0.004445234708392603. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19584/60000][Iteration 6250][Wall Clock 585.102470086s] Trained 128 records in 0.095249429 seconds. Throughput is 1343.8401 records/second. Loss is 0.18322554. Sequential31006cbd's hyper parameters: Current learning rate is 0.004444839541292559. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19712/60000][Iteration 6251][Wall Clock 585.219897507s] Trained 128 records in 0.117427421 seconds. Throughput is 1090.035 records/second. Loss is 0.2894419. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044444444444444444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19840/60000][Iteration 6252][Wall Clock 585.328923344s] Trained 128 records in 0.109025837 seconds. Throughput is 1174.0337 records/second. Loss is 0.17982936. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044440494178295264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 19968/60000][Iteration 6253][Wall Clock 585.449689756s] Trained 128 records in 0.120766412 seconds. Throughput is 1059.8973 records/second. Loss is 0.13844019. Sequential31006cbd's hyper parameters: Current learning rate is 0.00444365446142908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:22 INFO  DistriOptimizer$:408 - [Epoch 14 20096/60000][Iteration 6254][Wall Clock 585.523772968s] Trained 128 records in 0.074083212 seconds. Throughput is 1727.7869 records/second. Loss is 0.17293. Sequential31006cbd's hyper parameters: Current learning rate is 0.004443259575224384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20224/60000][Iteration 6255][Wall Clock 585.59879257s] Trained 128 records in 0.075019602 seconds. Throughput is 1706.2207 records/second. Loss is 0.06913574. Sequential31006cbd's hyper parameters: Current learning rate is 0.00444286475919673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20352/60000][Iteration 6256][Wall Clock 585.676516444s] Trained 128 records in 0.077723874 seconds. Throughput is 1646.8556 records/second. Loss is 0.2506264. Sequential31006cbd's hyper parameters: Current learning rate is 0.004442470013327409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20480/60000][Iteration 6257][Wall Clock 585.757489976s] Trained 128 records in 0.080973532 seconds. Throughput is 1580.7635 records/second. Loss is 0.13235387. Sequential31006cbd's hyper parameters: Current learning rate is 0.004442075337597726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20608/60000][Iteration 6258][Wall Clock 585.829223583s] Trained 128 records in 0.071733607 seconds. Throughput is 1784.3798 records/second. Loss is 0.22856924. Sequential31006cbd's hyper parameters: Current learning rate is 0.004441680731988984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20736/60000][Iteration 6259][Wall Clock 585.906755718s] Trained 128 records in 0.077532135 seconds. Throughput is 1650.9283 records/second. Loss is 0.25067347. Sequential31006cbd's hyper parameters: Current learning rate is 0.004441286196482502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20864/60000][Iteration 6260][Wall Clock 585.986437237s] Trained 128 records in 0.079681519 seconds. Throughput is 1606.3951 records/second. Loss is 0.2065941. Sequential31006cbd's hyper parameters: Current learning rate is 0.004440891731059596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 20992/60000][Iteration 6261][Wall Clock 586.062651085s] Trained 128 records in 0.076213848 seconds. Throughput is 1679.4847 records/second. Loss is 0.16297384. Sequential31006cbd's hyper parameters: Current learning rate is 0.004440497335701599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 21120/60000][Iteration 6262][Wall Clock 586.140567049s] Trained 128 records in 0.077915964 seconds. Throughput is 1642.7955 records/second. Loss is 0.22921763. Sequential31006cbd's hyper parameters: Current learning rate is 0.004440103010389841. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 21248/60000][Iteration 6263][Wall Clock 586.218035512s] Trained 128 records in 0.077468463 seconds. Throughput is 1652.2853 records/second. Loss is 0.11721367. Sequential31006cbd's hyper parameters: Current learning rate is 0.004439708755105666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 21376/60000][Iteration 6264][Wall Clock 586.294986459s] Trained 128 records in 0.076950947 seconds. Throughput is 1663.3973 records/second. Loss is 0.1780291. Sequential31006cbd's hyper parameters: Current learning rate is 0.004439314569830418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 21504/60000][Iteration 6265][Wall Clock 586.366440533s] Trained 128 records in 0.071454074 seconds. Throughput is 1791.3605 records/second. Loss is 0.10134129. Sequential31006cbd's hyper parameters: Current learning rate is 0.004438920454545454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:23 INFO  DistriOptimizer$:408 - [Epoch 14 21632/60000][Iteration 6266][Wall Clock 586.451915825s] Trained 128 records in 0.085475292 seconds. Throughput is 1497.5088 records/second. Loss is 0.1297111. Sequential31006cbd's hyper parameters: Current learning rate is 0.004438526409232135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 21760/60000][Iteration 6267][Wall Clock 586.554058479s] Trained 128 records in 0.102142654 seconds. Throughput is 1253.1493 records/second. Loss is 0.18234354. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044381324338718265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 21888/60000][Iteration 6268][Wall Clock 586.648915043s] Trained 128 records in 0.094856564 seconds. Throughput is 1349.4058 records/second. Loss is 0.14245278. Sequential31006cbd's hyper parameters: Current learning rate is 0.004437738528445904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22016/60000][Iteration 6269][Wall Clock 586.73962343s] Trained 128 records in 0.090708387 seconds. Throughput is 1411.1154 records/second. Loss is 0.19701464. Sequential31006cbd's hyper parameters: Current learning rate is 0.004437344692935747. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22144/60000][Iteration 6270][Wall Clock 586.829118495s] Trained 128 records in 0.089495065 seconds. Throughput is 1430.2465 records/second. Loss is 0.10568949. Sequential31006cbd's hyper parameters: Current learning rate is 0.004436950927322744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22272/60000][Iteration 6271][Wall Clock 586.919033s] Trained 128 records in 0.089914505 seconds. Throughput is 1423.5745 records/second. Loss is 0.19157784. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044365572315882874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22400/60000][Iteration 6272][Wall Clock 587.010583915s] Trained 128 records in 0.091550915 seconds. Throughput is 1398.1292 records/second. Loss is 0.20376813. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044361636057137785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22528/60000][Iteration 6273][Wall Clock 587.086112008s] Trained 128 records in 0.075528093 seconds. Throughput is 1694.7336 records/second. Loss is 0.121031515. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044357700496806245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22656/60000][Iteration 6274][Wall Clock 587.158260099s] Trained 128 records in 0.072148091 seconds. Throughput is 1774.1287 records/second. Loss is 0.13796118. Sequential31006cbd's hyper parameters: Current learning rate is 0.004435376563470239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22784/60000][Iteration 6275][Wall Clock 587.243714599s] Trained 128 records in 0.0854545 seconds. Throughput is 1497.8732 records/second. Loss is 0.26520032. Sequential31006cbd's hyper parameters: Current learning rate is 0.004434983147064041. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 22912/60000][Iteration 6276][Wall Clock 587.331047768s] Trained 128 records in 0.087333169 seconds. Throughput is 1465.6516 records/second. Loss is 0.12792528. Sequential31006cbd's hyper parameters: Current learning rate is 0.004434589800443459. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 23040/60000][Iteration 6277][Wall Clock 587.424324936s] Trained 128 records in 0.093277168 seconds. Throughput is 1372.2543 records/second. Loss is 0.17595547. Sequential31006cbd's hyper parameters: Current learning rate is 0.004434196523589925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:24 INFO  DistriOptimizer$:408 - [Epoch 14 23168/60000][Iteration 6278][Wall Clock 587.500240799s] Trained 128 records in 0.075915863 seconds. Throughput is 1686.077 records/second. Loss is 0.1634278. Sequential31006cbd's hyper parameters: Current learning rate is 0.004433803316484881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 23296/60000][Iteration 6279][Wall Clock 587.584240088s] Trained 128 records in 0.083999289 seconds. Throughput is 1523.8224 records/second. Loss is 0.19995989. Sequential31006cbd's hyper parameters: Current learning rate is 0.004433410179109771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 23424/60000][Iteration 6280][Wall Clock 587.6642847s] Trained 128 records in 0.080044612 seconds. Throughput is 1599.1083 records/second. Loss is 0.1893221. Sequential31006cbd's hyper parameters: Current learning rate is 0.00443301711144605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 23552/60000][Iteration 6281][Wall Clock 587.746155322s] Trained 128 records in 0.081870622 seconds. Throughput is 1563.4424 records/second. Loss is 0.08340953. Sequential31006cbd's hyper parameters: Current learning rate is 0.004432624113475177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 23680/60000][Iteration 6282][Wall Clock 587.823749773s] Trained 128 records in 0.077594451 seconds. Throughput is 1649.6025 records/second. Loss is 0.12150569. Sequential31006cbd's hyper parameters: Current learning rate is 0.00443223118517862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 23808/60000][Iteration 6283][Wall Clock 587.907834108s] Trained 128 records in 0.084084335 seconds. Throughput is 1522.2812 records/second. Loss is 0.18613045. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044318383265378476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 23936/60000][Iteration 6284][Wall Clock 587.990152973s] Trained 128 records in 0.082318865 seconds. Throughput is 1554.9291 records/second. Loss is 0.06960082. Sequential31006cbd's hyper parameters: Current learning rate is 0.004431445537534343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 24064/60000][Iteration 6285][Wall Clock 588.080339476s] Trained 128 records in 0.090186503 seconds. Throughput is 1419.281 records/second. Loss is 0.15461928. Sequential31006cbd's hyper parameters: Current learning rate is 0.004431052818149592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 24192/60000][Iteration 6286][Wall Clock 588.161692899s] Trained 128 records in 0.081353423 seconds. Throughput is 1573.3818 records/second. Loss is 0.13694535. Sequential31006cbd's hyper parameters: Current learning rate is 0.004430660168365086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 24320/60000][Iteration 6287][Wall Clock 588.239060438s] Trained 128 records in 0.077367539 seconds. Throughput is 1654.4407 records/second. Loss is 0.08233084. Sequential31006cbd's hyper parameters: Current learning rate is 0.004430267588162325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 24448/60000][Iteration 6288][Wall Clock 588.32065917s] Trained 128 records in 0.081598732 seconds. Throughput is 1568.6519 records/second. Loss is 0.16970971. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044298750775228135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 24576/60000][Iteration 6289][Wall Clock 588.405365135s] Trained 128 records in 0.084705965 seconds. Throughput is 1511.1096 records/second. Loss is 0.18689586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004429482636428065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:25 INFO  DistriOptimizer$:408 - [Epoch 14 24704/60000][Iteration 6290][Wall Clock 588.48279732s] Trained 128 records in 0.077432185 seconds. Throughput is 1653.0593 records/second. Loss is 0.12079627. Sequential31006cbd's hyper parameters: Current learning rate is 0.004429090264859598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 24832/60000][Iteration 6291][Wall Clock 588.562306392s] Trained 128 records in 0.079509072 seconds. Throughput is 1609.8792 records/second. Loss is 0.13765013. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044286979627989375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 24960/60000][Iteration 6292][Wall Clock 588.646651405s] Trained 128 records in 0.084345013 seconds. Throughput is 1517.5764 records/second. Loss is 0.22086586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004428305730227615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25088/60000][Iteration 6293][Wall Clock 588.730790423s] Trained 128 records in 0.084139018 seconds. Throughput is 1521.2917 records/second. Loss is 0.23753361. Sequential31006cbd's hyper parameters: Current learning rate is 0.00442791356712717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25216/60000][Iteration 6294][Wall Clock 588.818316327s] Trained 128 records in 0.087525904 seconds. Throughput is 1462.4242 records/second. Loss is 0.13220018. Sequential31006cbd's hyper parameters: Current learning rate is 0.004427521473479146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25344/60000][Iteration 6295][Wall Clock 588.894708742s] Trained 128 records in 0.076392415 seconds. Throughput is 1675.5591 records/second. Loss is 0.2218046. Sequential31006cbd's hyper parameters: Current learning rate is 0.004427129449265097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25472/60000][Iteration 6296][Wall Clock 588.981344261s] Trained 128 records in 0.086635519 seconds. Throughput is 1477.454 records/second. Loss is 0.21402434. Sequential31006cbd's hyper parameters: Current learning rate is 0.004426737494466578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25600/60000][Iteration 6297][Wall Clock 589.059198038s] Trained 128 records in 0.077853777 seconds. Throughput is 1644.1078 records/second. Loss is 0.21864597. Sequential31006cbd's hyper parameters: Current learning rate is 0.004426345609065156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25728/60000][Iteration 6298][Wall Clock 589.135486689s] Trained 128 records in 0.076288651 seconds. Throughput is 1677.8381 records/second. Loss is 0.10795944. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044259537930424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25856/60000][Iteration 6299][Wall Clock 589.212307558s] Trained 128 records in 0.076820869 seconds. Throughput is 1666.2139 records/second. Loss is 0.11917487. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044255620463798905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 25984/60000][Iteration 6300][Wall Clock 589.298374416s] Trained 128 records in 0.086066858 seconds. Throughput is 1487.216 records/second. Loss is 0.19527958. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044251703690592085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 26112/60000][Iteration 6301][Wall Clock 589.389218357s] Trained 128 records in 0.090843941 seconds. Throughput is 1409.0098 records/second. Loss is 0.1774441. Sequential31006cbd's hyper parameters: Current learning rate is 0.004424778761061948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:26 INFO  DistriOptimizer$:408 - [Epoch 14 26240/60000][Iteration 6302][Wall Clock 589.470632656s] Trained 128 records in 0.081414299 seconds. Throughput is 1572.2054 records/second. Loss is 0.146164. Sequential31006cbd's hyper parameters: Current learning rate is 0.004424387222369702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 26368/60000][Iteration 6303][Wall Clock 589.551399941s] Trained 128 records in 0.080767285 seconds. Throughput is 1584.8002 records/second. Loss is 0.26757348. Sequential31006cbd's hyper parameters: Current learning rate is 0.004423995752964077. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 26496/60000][Iteration 6304][Wall Clock 589.629001001s] Trained 128 records in 0.07760106 seconds. Throughput is 1649.462 records/second. Loss is 0.15411901. Sequential31006cbd's hyper parameters: Current learning rate is 0.004423604352826683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 26624/60000][Iteration 6305][Wall Clock 589.704627185s] Trained 128 records in 0.075626184 seconds. Throughput is 1692.5354 records/second. Loss is 0.15586947. Sequential31006cbd's hyper parameters: Current learning rate is 0.004423213021939137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 26752/60000][Iteration 6306][Wall Clock 589.7797893s] Trained 128 records in 0.075162115 seconds. Throughput is 1702.9857 records/second. Loss is 0.23515895. Sequential31006cbd's hyper parameters: Current learning rate is 0.004422821760283061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 26880/60000][Iteration 6307][Wall Clock 589.853662672s] Trained 128 records in 0.073873372 seconds. Throughput is 1732.6947 records/second. Loss is 0.15223324. Sequential31006cbd's hyper parameters: Current learning rate is 0.004422430567840085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27008/60000][Iteration 6308][Wall Clock 589.934653613s] Trained 128 records in 0.080990941 seconds. Throughput is 1580.4237 records/second. Loss is 0.15657727. Sequential31006cbd's hyper parameters: Current learning rate is 0.004422039444591846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27136/60000][Iteration 6309][Wall Clock 590.023012112s] Trained 128 records in 0.088358499 seconds. Throughput is 1448.6439 records/second. Loss is 0.16378707. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044216483905199855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27264/60000][Iteration 6310][Wall Clock 590.112275482s] Trained 128 records in 0.08926337 seconds. Throughput is 1433.9589 records/second. Loss is 0.13624564. Sequential31006cbd's hyper parameters: Current learning rate is 0.004421257405606154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27392/60000][Iteration 6311][Wall Clock 590.204315247s] Trained 128 records in 0.092039765 seconds. Throughput is 1390.7032 records/second. Loss is 0.20519984. Sequential31006cbd's hyper parameters: Current learning rate is 0.004420866489832007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27520/60000][Iteration 6312][Wall Clock 590.308258771s] Trained 128 records in 0.103943524 seconds. Throughput is 1231.4379 records/second. Loss is 0.09882906. Sequential31006cbd's hyper parameters: Current learning rate is 0.004420475643179206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27648/60000][Iteration 6313][Wall Clock 590.41673215s] Trained 128 records in 0.108473379 seconds. Throughput is 1180.0131 records/second. Loss is 0.23200786. Sequential31006cbd's hyper parameters: Current learning rate is 0.00442008486562942. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:27 INFO  DistriOptimizer$:408 - [Epoch 14 27776/60000][Iteration 6314][Wall Clock 590.506334813s] Trained 128 records in 0.089602663 seconds. Throughput is 1428.5289 records/second. Loss is 0.16413234. Sequential31006cbd's hyper parameters: Current learning rate is 0.004419694157164324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 27904/60000][Iteration 6315][Wall Clock 590.588058225s] Trained 128 records in 0.081723412 seconds. Throughput is 1566.2585 records/second. Loss is 0.12819438. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044193035177656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28032/60000][Iteration 6316][Wall Clock 590.66602892s] Trained 128 records in 0.077970695 seconds. Throughput is 1641.6423 records/second. Loss is 0.14750779. Sequential31006cbd's hyper parameters: Current learning rate is 0.004418912947414936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28160/60000][Iteration 6317][Wall Clock 590.747633743s] Trained 128 records in 0.081604823 seconds. Throughput is 1568.5348 records/second. Loss is 0.2162751. Sequential31006cbd's hyper parameters: Current learning rate is 0.004418522446094026. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28288/60000][Iteration 6318][Wall Clock 590.830793982s] Trained 128 records in 0.083160239 seconds. Throughput is 1539.1971 records/second. Loss is 0.16090916. Sequential31006cbd's hyper parameters: Current learning rate is 0.004418132013784572. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28416/60000][Iteration 6319][Wall Clock 590.907839407s] Trained 128 records in 0.077045425 seconds. Throughput is 1661.3575 records/second. Loss is 0.13544695. Sequential31006cbd's hyper parameters: Current learning rate is 0.00441774165046828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28544/60000][Iteration 6320][Wall Clock 590.989990101s] Trained 128 records in 0.082150694 seconds. Throughput is 1558.1122 records/second. Loss is 0.16382807. Sequential31006cbd's hyper parameters: Current learning rate is 0.004417351356126867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28672/60000][Iteration 6321][Wall Clock 591.073411634s] Trained 128 records in 0.083421533 seconds. Throughput is 1534.376 records/second. Loss is 0.1727111. Sequential31006cbd's hyper parameters: Current learning rate is 0.004416961130742049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28800/60000][Iteration 6322][Wall Clock 591.152337955s] Trained 128 records in 0.078926321 seconds. Throughput is 1621.7657 records/second. Loss is 0.1116503. Sequential31006cbd's hyper parameters: Current learning rate is 0.004416570974295557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 28928/60000][Iteration 6323][Wall Clock 591.230729192s] Trained 128 records in 0.078391237 seconds. Throughput is 1632.8356 records/second. Loss is 0.25489286. Sequential31006cbd's hyper parameters: Current learning rate is 0.004416180886769122. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 29056/60000][Iteration 6324][Wall Clock 591.312145832s] Trained 128 records in 0.08141664 seconds. Throughput is 1572.1603 records/second. Loss is 0.19064274. Sequential31006cbd's hyper parameters: Current learning rate is 0.004415790868144484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 29184/60000][Iteration 6325][Wall Clock 591.420022568s] Trained 128 records in 0.107876736 seconds. Throughput is 1186.5394 records/second. Loss is 0.112629466. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044154009184033905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:28 INFO  DistriOptimizer$:408 - [Epoch 14 29312/60000][Iteration 6326][Wall Clock 591.506212389s] Trained 128 records in 0.086189821 seconds. Throughput is 1485.0941 records/second. Loss is 0.1619479. Sequential31006cbd's hyper parameters: Current learning rate is 0.004415011037527594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 29440/60000][Iteration 6327][Wall Clock 591.642196769s] Trained 128 records in 0.13598438 seconds. Throughput is 941.2846 records/second. Loss is 0.11130114. Sequential31006cbd's hyper parameters: Current learning rate is 0.004414621225498852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 29568/60000][Iteration 6328][Wall Clock 591.734595682s] Trained 128 records in 0.092398913 seconds. Throughput is 1385.2977 records/second. Loss is 0.28954595. Sequential31006cbd's hyper parameters: Current learning rate is 0.004414231482298932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 29696/60000][Iteration 6329][Wall Clock 591.829078681s] Trained 128 records in 0.094482999 seconds. Throughput is 1354.7411 records/second. Loss is 0.14138599. Sequential31006cbd's hyper parameters: Current learning rate is 0.004413841807909605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 29824/60000][Iteration 6330][Wall Clock 591.908813528s] Trained 128 records in 0.079734847 seconds. Throughput is 1605.3207 records/second. Loss is 0.22907925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004413452202312649. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 29952/60000][Iteration 6331][Wall Clock 591.985203573s] Trained 128 records in 0.076390045 seconds. Throughput is 1675.6111 records/second. Loss is 0.18588915. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044130626654898504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 30080/60000][Iteration 6332][Wall Clock 592.060058061s] Trained 128 records in 0.074854488 seconds. Throughput is 1709.9844 records/second. Loss is 0.2579385. Sequential31006cbd's hyper parameters: Current learning rate is 0.004412673197422999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 30208/60000][Iteration 6333][Wall Clock 592.136359457s] Trained 128 records in 0.076301396 seconds. Throughput is 1677.5577 records/second. Loss is 0.12336703. Sequential31006cbd's hyper parameters: Current learning rate is 0.004412283798093893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 30336/60000][Iteration 6334][Wall Clock 592.231228325s] Trained 128 records in 0.094868868 seconds. Throughput is 1349.2308 records/second. Loss is 0.08090967. Sequential31006cbd's hyper parameters: Current learning rate is 0.004411894467484337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 30464/60000][Iteration 6335][Wall Clock 592.318238796s] Trained 128 records in 0.087010471 seconds. Throughput is 1471.0873 records/second. Loss is 0.14522345. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044115052055761425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 30592/60000][Iteration 6336][Wall Clock 592.406568287s] Trained 128 records in 0.088329491 seconds. Throughput is 1449.1196 records/second. Loss is 0.18058714. Sequential31006cbd's hyper parameters: Current learning rate is 0.004411116012351124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:29 INFO  DistriOptimizer$:408 - [Epoch 14 30720/60000][Iteration 6337][Wall Clock 592.482528685s] Trained 128 records in 0.075960398 seconds. Throughput is 1685.0886 records/second. Loss is 0.16238427. Sequential31006cbd's hyper parameters: Current learning rate is 0.004410726887791108. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 30848/60000][Iteration 6338][Wall Clock 592.558610182s] Trained 128 records in 0.076081497 seconds. Throughput is 1682.4064 records/second. Loss is 0.12962198. Sequential31006cbd's hyper parameters: Current learning rate is 0.004410337831877921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 30976/60000][Iteration 6339][Wall Clock 592.638635255s] Trained 128 records in 0.080025073 seconds. Throughput is 1599.4988 records/second. Loss is 0.10156754. Sequential31006cbd's hyper parameters: Current learning rate is 0.004409948844593403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31104/60000][Iteration 6340][Wall Clock 592.725549189s] Trained 128 records in 0.086913934 seconds. Throughput is 1472.7212 records/second. Loss is 0.15062737. Sequential31006cbd's hyper parameters: Current learning rate is 0.004409559925919393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31232/60000][Iteration 6341][Wall Clock 592.807923133s] Trained 128 records in 0.082373944 seconds. Throughput is 1553.8894 records/second. Loss is 0.1489407. Sequential31006cbd's hyper parameters: Current learning rate is 0.004409171075837743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31360/60000][Iteration 6342][Wall Clock 592.889372635s] Trained 128 records in 0.081449502 seconds. Throughput is 1571.5259 records/second. Loss is 0.18870997. Sequential31006cbd's hyper parameters: Current learning rate is 0.004408782294330306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31488/60000][Iteration 6343][Wall Clock 592.969864021s] Trained 128 records in 0.080491386 seconds. Throughput is 1590.2323 records/second. Loss is 0.14015388. Sequential31006cbd's hyper parameters: Current learning rate is 0.004408393581378946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31616/60000][Iteration 6344][Wall Clock 593.052387698s] Trained 128 records in 0.082523677 seconds. Throughput is 1551.0701 records/second. Loss is 0.12904224. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044080049369655296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31744/60000][Iteration 6345][Wall Clock 593.133845104s] Trained 128 records in 0.081457406 seconds. Throughput is 1571.3734 records/second. Loss is 0.18136297. Sequential31006cbd's hyper parameters: Current learning rate is 0.004407616361071932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 31872/60000][Iteration 6346][Wall Clock 593.211421949s] Trained 128 records in 0.077576845 seconds. Throughput is 1649.9768 records/second. Loss is 0.17553318. Sequential31006cbd's hyper parameters: Current learning rate is 0.004407227853680035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 32000/60000][Iteration 6347][Wall Clock 593.285646387s] Trained 128 records in 0.074224438 seconds. Throughput is 1724.4995 records/second. Loss is 0.14684278. Sequential31006cbd's hyper parameters: Current learning rate is 0.004406839414771726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 32128/60000][Iteration 6348][Wall Clock 593.377273205s] Trained 128 records in 0.091626818 seconds. Throughput is 1396.971 records/second. Loss is 0.14650717. Sequential31006cbd's hyper parameters: Current learning rate is 0.004406451044328898. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:30 INFO  DistriOptimizer$:408 - [Epoch 14 32256/60000][Iteration 6349][Wall Clock 593.45972301s] Trained 128 records in 0.082449805 seconds. Throughput is 1552.4596 records/second. Loss is 0.1864864. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044060627423334504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 32384/60000][Iteration 6350][Wall Clock 593.540554011s] Trained 128 records in 0.080831001 seconds. Throughput is 1583.5509 records/second. Loss is 0.1764608. Sequential31006cbd's hyper parameters: Current learning rate is 0.004405674508767292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 32512/60000][Iteration 6351][Wall Clock 593.652683425s] Trained 128 records in 0.112129414 seconds. Throughput is 1141.5381 records/second. Loss is 0.22115633. Sequential31006cbd's hyper parameters: Current learning rate is 0.004405286343612335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 32640/60000][Iteration 6352][Wall Clock 593.737169321s] Trained 128 records in 0.084485896 seconds. Throughput is 1515.0458 records/second. Loss is 0.17397432. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044048982468504975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 32768/60000][Iteration 6353][Wall Clock 593.822843369s] Trained 128 records in 0.085674048 seconds. Throughput is 1494.0347 records/second. Loss is 0.1793158. Sequential31006cbd's hyper parameters: Current learning rate is 0.004404510218463707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 32896/60000][Iteration 6354][Wall Clock 593.900997455s] Trained 128 records in 0.078154086 seconds. Throughput is 1637.7903 records/second. Loss is 0.23977885. Sequential31006cbd's hyper parameters: Current learning rate is 0.004404122258433894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33024/60000][Iteration 6355][Wall Clock 593.977296171s] Trained 128 records in 0.076298716 seconds. Throughput is 1677.6167 records/second. Loss is 0.1961497. Sequential31006cbd's hyper parameters: Current learning rate is 0.004403734366742997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33152/60000][Iteration 6356][Wall Clock 594.053544635s] Trained 128 records in 0.076248464 seconds. Throughput is 1678.7223 records/second. Loss is 0.19438837. Sequential31006cbd's hyper parameters: Current learning rate is 0.004403346543372964. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33280/60000][Iteration 6357][Wall Clock 594.140385558s] Trained 128 records in 0.086840923 seconds. Throughput is 1473.9595 records/second. Loss is 0.12680933. Sequential31006cbd's hyper parameters: Current learning rate is 0.004402958788305741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33408/60000][Iteration 6358][Wall Clock 594.24654021s] Trained 128 records in 0.106154652 seconds. Throughput is 1205.788 records/second. Loss is 0.13497384. Sequential31006cbd's hyper parameters: Current learning rate is 0.00440257110152329. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33536/60000][Iteration 6359][Wall Clock 594.336434823s] Trained 128 records in 0.089894613 seconds. Throughput is 1423.8895 records/second. Loss is 0.113257244. Sequential31006cbd's hyper parameters: Current learning rate is 0.004402183483007571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33664/60000][Iteration 6360][Wall Clock 594.43722828s] Trained 128 records in 0.100793457 seconds. Throughput is 1269.9237 records/second. Loss is 0.20554543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004401795932740558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:31 INFO  DistriOptimizer$:408 - [Epoch 14 33792/60000][Iteration 6361][Wall Clock 594.514198364s] Trained 128 records in 0.076970084 seconds. Throughput is 1662.9838 records/second. Loss is 0.13678542. Sequential31006cbd's hyper parameters: Current learning rate is 0.004401408450704225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 33920/60000][Iteration 6362][Wall Clock 594.597397265s] Trained 128 records in 0.083198901 seconds. Throughput is 1538.4819 records/second. Loss is 0.14355204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0044010210368805565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34048/60000][Iteration 6363][Wall Clock 594.673156128s] Trained 128 records in 0.075758863 seconds. Throughput is 1689.5714 records/second. Loss is 0.093650885. Sequential31006cbd's hyper parameters: Current learning rate is 0.00440063369125154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34176/60000][Iteration 6364][Wall Clock 594.755334045s] Trained 128 records in 0.082177917 seconds. Throughput is 1557.5961 records/second. Loss is 0.09758613. Sequential31006cbd's hyper parameters: Current learning rate is 0.004400246413799174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34304/60000][Iteration 6365][Wall Clock 594.84320263s] Trained 128 records in 0.087868585 seconds. Throughput is 1456.7208 records/second. Loss is 0.17261904. Sequential31006cbd's hyper parameters: Current learning rate is 0.004399859204505456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34432/60000][Iteration 6366][Wall Clock 594.926290396s] Trained 128 records in 0.083087766 seconds. Throughput is 1540.5397 records/second. Loss is 0.16399227. Sequential31006cbd's hyper parameters: Current learning rate is 0.004399472063352398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34560/60000][Iteration 6367][Wall Clock 595.001629429s] Trained 128 records in 0.075339033 seconds. Throughput is 1698.9865 records/second. Loss is 0.1300264. Sequential31006cbd's hyper parameters: Current learning rate is 0.004399084990322013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34688/60000][Iteration 6368][Wall Clock 595.078514613s] Trained 128 records in 0.076885184 seconds. Throughput is 1664.8201 records/second. Loss is 0.17290473. Sequential31006cbd's hyper parameters: Current learning rate is 0.004398697985396323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34816/60000][Iteration 6369][Wall Clock 595.160583954s] Trained 128 records in 0.082069341 seconds. Throughput is 1559.6567 records/second. Loss is 0.116537645. Sequential31006cbd's hyper parameters: Current learning rate is 0.004398311048557354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 34944/60000][Iteration 6370][Wall Clock 595.24057148s] Trained 128 records in 0.079987526 seconds. Throughput is 1600.2495 records/second. Loss is 0.21489751. Sequential31006cbd's hyper parameters: Current learning rate is 0.00439792417978714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 35072/60000][Iteration 6371][Wall Clock 595.315965804s] Trained 128 records in 0.075394324 seconds. Throughput is 1697.7405 records/second. Loss is 0.23263127. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043975373790677225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 35200/60000][Iteration 6372][Wall Clock 595.395793162s] Trained 128 records in 0.079827358 seconds. Throughput is 1603.4602 records/second. Loss is 0.14500792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043971506463811455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:32 INFO  DistriOptimizer$:408 - [Epoch 14 35328/60000][Iteration 6373][Wall Clock 595.478185663s] Trained 128 records in 0.082392501 seconds. Throughput is 1553.5394 records/second. Loss is 0.09482835. Sequential31006cbd's hyper parameters: Current learning rate is 0.004396763981709462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 35456/60000][Iteration 6374][Wall Clock 595.561769606s] Trained 128 records in 0.083583943 seconds. Throughput is 1531.3947 records/second. Loss is 0.17873167. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043963773850347315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 35584/60000][Iteration 6375][Wall Clock 595.651165197s] Trained 128 records in 0.089395591 seconds. Throughput is 1431.838 records/second. Loss is 0.1632683. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043959908563390195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 35712/60000][Iteration 6376][Wall Clock 595.737673773s] Trained 128 records in 0.086508576 seconds. Throughput is 1479.6221 records/second. Loss is 0.13948433. Sequential31006cbd's hyper parameters: Current learning rate is 0.004395604395604395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 35840/60000][Iteration 6377][Wall Clock 595.834604169s] Trained 128 records in 0.096930396 seconds. Throughput is 1320.5352 records/second. Loss is 0.15260977. Sequential31006cbd's hyper parameters: Current learning rate is 0.00439521800281294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 35968/60000][Iteration 6378][Wall Clock 595.920218735s] Trained 128 records in 0.085614566 seconds. Throughput is 1495.0726 records/second. Loss is 0.18219176. Sequential31006cbd's hyper parameters: Current learning rate is 0.004394831677946734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 36096/60000][Iteration 6379][Wall Clock 596.004565662s] Trained 128 records in 0.084346927 seconds. Throughput is 1517.542 records/second. Loss is 0.20223789. Sequential31006cbd's hyper parameters: Current learning rate is 0.004394445420987872. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 36224/60000][Iteration 6380][Wall Clock 596.087072257s] Trained 128 records in 0.082506595 seconds. Throughput is 1551.3911 records/second. Loss is 0.2530275. Sequential31006cbd's hyper parameters: Current learning rate is 0.004394059231918446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 36352/60000][Iteration 6381][Wall Clock 596.17593863s] Trained 128 records in 0.088866373 seconds. Throughput is 1440.3649 records/second. Loss is 0.14867155. Sequential31006cbd's hyper parameters: Current learning rate is 0.004393673110720563. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 36480/60000][Iteration 6382][Wall Clock 596.269856523s] Trained 128 records in 0.093917893 seconds. Throughput is 1362.8926 records/second. Loss is 0.12872632. Sequential31006cbd's hyper parameters: Current learning rate is 0.004393287057376329. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 36608/60000][Iteration 6383][Wall Clock 596.357374071s] Trained 128 records in 0.087517548 seconds. Throughput is 1462.5638 records/second. Loss is 0.20662053. Sequential31006cbd's hyper parameters: Current learning rate is 0.004392901071867862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:33 INFO  DistriOptimizer$:408 - [Epoch 14 36736/60000][Iteration 6384][Wall Clock 596.442699355s] Trained 128 records in 0.085325284 seconds. Throughput is 1500.1415 records/second. Loss is 0.15456276. Sequential31006cbd's hyper parameters: Current learning rate is 0.004392515154177282. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 36864/60000][Iteration 6385][Wall Clock 596.536786834s] Trained 128 records in 0.094087479 seconds. Throughput is 1360.436 records/second. Loss is 0.19882044. Sequential31006cbd's hyper parameters: Current learning rate is 0.004392129304286718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 36992/60000][Iteration 6386][Wall Clock 596.631987249s] Trained 128 records in 0.095200415 seconds. Throughput is 1344.532 records/second. Loss is 0.15080643. Sequential31006cbd's hyper parameters: Current learning rate is 0.004391743522178305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37120/60000][Iteration 6387][Wall Clock 596.735469833s] Trained 128 records in 0.103482584 seconds. Throughput is 1236.9231 records/second. Loss is 0.19000109. Sequential31006cbd's hyper parameters: Current learning rate is 0.004391357807834183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37248/60000][Iteration 6388][Wall Clock 596.819031984s] Trained 128 records in 0.083562151 seconds. Throughput is 1531.794 records/second. Loss is 0.1695058. Sequential31006cbd's hyper parameters: Current learning rate is 0.004390972161236498. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37376/60000][Iteration 6389][Wall Clock 596.898947883s] Trained 128 records in 0.079915899 seconds. Throughput is 1601.6838 records/second. Loss is 0.16962792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043905865823674044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37504/60000][Iteration 6390][Wall Clock 596.977396114s] Trained 128 records in 0.078448231 seconds. Throughput is 1631.6493 records/second. Loss is 0.17282856. Sequential31006cbd's hyper parameters: Current learning rate is 0.004390201071209061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37632/60000][Iteration 6391][Wall Clock 597.055372812s] Trained 128 records in 0.077976698 seconds. Throughput is 1641.5161 records/second. Loss is 0.2146264. Sequential31006cbd's hyper parameters: Current learning rate is 0.004389815627743635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37760/60000][Iteration 6392][Wall Clock 597.129790873s] Trained 128 records in 0.074418061 seconds. Throughput is 1720.0126 records/second. Loss is 0.26505068. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043894302519532965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 37888/60000][Iteration 6393][Wall Clock 597.204650052s] Trained 128 records in 0.074859179 seconds. Throughput is 1709.8772 records/second. Loss is 0.19738409. Sequential31006cbd's hyper parameters: Current learning rate is 0.004389044943820225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 38016/60000][Iteration 6394][Wall Clock 597.287015801s] Trained 128 records in 0.082365749 seconds. Throughput is 1554.044 records/second. Loss is 0.23419419. Sequential31006cbd's hyper parameters: Current learning rate is 0.004388659703326604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 38144/60000][Iteration 6395][Wall Clock 597.365737783s] Trained 128 records in 0.078721982 seconds. Throughput is 1625.9752 records/second. Loss is 0.15102978. Sequential31006cbd's hyper parameters: Current learning rate is 0.004388274530454625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:34 INFO  DistriOptimizer$:408 - [Epoch 14 38272/60000][Iteration 6396][Wall Clock 597.442554638s] Trained 128 records in 0.076816855 seconds. Throughput is 1666.3009 records/second. Loss is 0.17378104. Sequential31006cbd's hyper parameters: Current learning rate is 0.004387889425186486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 38400/60000][Iteration 6397][Wall Clock 597.517117165s] Trained 128 records in 0.074562527 seconds. Throughput is 1716.68 records/second. Loss is 0.15188316. Sequential31006cbd's hyper parameters: Current learning rate is 0.004387504387504387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 38528/60000][Iteration 6398][Wall Clock 597.600720919s] Trained 128 records in 0.083603754 seconds. Throughput is 1531.0317 records/second. Loss is 0.1329422. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043871194173905415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 38656/60000][Iteration 6399][Wall Clock 597.695805494s] Trained 128 records in 0.095084575 seconds. Throughput is 1346.1699 records/second. Loss is 0.14277752. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043867345148271624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 38784/60000][Iteration 6400][Wall Clock 597.782373593s] Trained 128 records in 0.086568099 seconds. Throughput is 1478.6046 records/second. Loss is 0.16034958. Sequential31006cbd's hyper parameters: Current learning rate is 0.004386349679796474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 38912/60000][Iteration 6401][Wall Clock 597.87968257s] Trained 128 records in 0.097308977 seconds. Throughput is 1315.3976 records/second. Loss is 0.113515094. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043859649122807015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39040/60000][Iteration 6402][Wall Clock 597.958210586s] Trained 128 records in 0.078528016 seconds. Throughput is 1629.9915 records/second. Loss is 0.12086266. Sequential31006cbd's hyper parameters: Current learning rate is 0.004385580212262083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39168/60000][Iteration 6403][Wall Clock 598.041270969s] Trained 128 records in 0.083060383 seconds. Throughput is 1541.0475 records/second. Loss is 0.11723092. Sequential31006cbd's hyper parameters: Current learning rate is 0.004385195579722855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39296/60000][Iteration 6404][Wall Clock 598.132597054s] Trained 128 records in 0.091326085 seconds. Throughput is 1401.571 records/second. Loss is 0.13045323. Sequential31006cbd's hyper parameters: Current learning rate is 0.004384811014645269. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39424/60000][Iteration 6405][Wall Clock 598.215795131s] Trained 128 records in 0.083198077 seconds. Throughput is 1538.4971 records/second. Loss is 0.17194915. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043844265170115745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39552/60000][Iteration 6406][Wall Clock 598.302161784s] Trained 128 records in 0.086366653 seconds. Throughput is 1482.0535 records/second. Loss is 0.23125105. Sequential31006cbd's hyper parameters: Current learning rate is 0.004384042086804033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39680/60000][Iteration 6407][Wall Clock 598.383063573s] Trained 128 records in 0.080901789 seconds. Throughput is 1582.1653 records/second. Loss is 0.16506991. Sequential31006cbd's hyper parameters: Current learning rate is 0.00438365772400491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:35 INFO  DistriOptimizer$:408 - [Epoch 14 39808/60000][Iteration 6408][Wall Clock 598.459537971s] Trained 128 records in 0.076474398 seconds. Throughput is 1673.7628 records/second. Loss is 0.12136147. Sequential31006cbd's hyper parameters: Current learning rate is 0.004383273428596476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 39936/60000][Iteration 6409][Wall Clock 598.537276096s] Trained 128 records in 0.077738125 seconds. Throughput is 1646.5537 records/second. Loss is 0.16922815. Sequential31006cbd's hyper parameters: Current learning rate is 0.00438288920056101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40064/60000][Iteration 6410][Wall Clock 598.622469383s] Trained 128 records in 0.085193287 seconds. Throughput is 1502.4658 records/second. Loss is 0.1472978. Sequential31006cbd's hyper parameters: Current learning rate is 0.004382505039880796. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40192/60000][Iteration 6411][Wall Clock 598.713681078s] Trained 128 records in 0.091211695 seconds. Throughput is 1403.3289 records/second. Loss is 0.281059. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043821209465381246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40320/60000][Iteration 6412][Wall Clock 598.792213156s] Trained 128 records in 0.078532078 seconds. Throughput is 1629.9072 records/second. Loss is 0.20363754. Sequential31006cbd's hyper parameters: Current learning rate is 0.004381736920515292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40448/60000][Iteration 6413][Wall Clock 598.875274908s] Trained 128 records in 0.083061752 seconds. Throughput is 1541.0221 records/second. Loss is 0.26459005. Sequential31006cbd's hyper parameters: Current learning rate is 0.004381352961794602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40576/60000][Iteration 6414][Wall Clock 598.954113442s] Trained 128 records in 0.078838534 seconds. Throughput is 1623.5715 records/second. Loss is 0.16621822. Sequential31006cbd's hyper parameters: Current learning rate is 0.004380969070358363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40704/60000][Iteration 6415][Wall Clock 599.030968338s] Trained 128 records in 0.076854896 seconds. Throughput is 1665.4761 records/second. Loss is 0.22754046. Sequential31006cbd's hyper parameters: Current learning rate is 0.004380585246188891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40832/60000][Iteration 6416][Wall Clock 599.11013921s] Trained 128 records in 0.079170872 seconds. Throughput is 1616.7561 records/second. Loss is 0.09189096. Sequential31006cbd's hyper parameters: Current learning rate is 0.004380201489268506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 40960/60000][Iteration 6417][Wall Clock 599.184265338s] Trained 128 records in 0.074126128 seconds. Throughput is 1726.7866 records/second. Loss is 0.17761582. Sequential31006cbd's hyper parameters: Current learning rate is 0.004379817799579537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 41088/60000][Iteration 6418][Wall Clock 599.266754138s] Trained 128 records in 0.0824888 seconds. Throughput is 1551.7258 records/second. Loss is 0.22231103. Sequential31006cbd's hyper parameters: Current learning rate is 0.004379434177104318. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 41216/60000][Iteration 6419][Wall Clock 599.346934585s] Trained 128 records in 0.080180447 seconds. Throughput is 1596.3993 records/second. Loss is 0.1967436. Sequential31006cbd's hyper parameters: Current learning rate is 0.004379050621825188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 41344/60000][Iteration 6420][Wall Clock 599.421523793s] Trained 128 records in 0.074589208 seconds. Throughput is 1716.0659 records/second. Loss is 0.13496068. Sequential31006cbd's hyper parameters: Current learning rate is 0.004378667133724493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:36 INFO  DistriOptimizer$:408 - [Epoch 14 41472/60000][Iteration 6421][Wall Clock 599.494897073s] Trained 128 records in 0.07337328 seconds. Throughput is 1744.5043 records/second. Loss is 0.09410399. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043782837127845885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 41600/60000][Iteration 6422][Wall Clock 599.567159114s] Trained 128 records in 0.072262041 seconds. Throughput is 1771.331 records/second. Loss is 0.21788582. Sequential31006cbd's hyper parameters: Current learning rate is 0.004377900358987829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 41728/60000][Iteration 6423][Wall Clock 599.650935544s] Trained 128 records in 0.08377643 seconds. Throughput is 1527.8761 records/second. Loss is 0.15470621. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043775170723165824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 41856/60000][Iteration 6424][Wall Clock 599.732556082s] Trained 128 records in 0.081620538 seconds. Throughput is 1568.2328 records/second. Loss is 0.12854639. Sequential31006cbd's hyper parameters: Current learning rate is 0.004377133852753217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 41984/60000][Iteration 6425][Wall Clock 599.818960507s] Trained 128 records in 0.086404425 seconds. Throughput is 1481.4055 records/second. Loss is 0.16391839. Sequential31006cbd's hyper parameters: Current learning rate is 0.004376750700280112. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42112/60000][Iteration 6426][Wall Clock 599.913003126s] Trained 128 records in 0.094042619 seconds. Throughput is 1361.085 records/second. Loss is 0.10469712. Sequential31006cbd's hyper parameters: Current learning rate is 0.00437636761487965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42240/60000][Iteration 6427][Wall Clock 599.991579576s] Trained 128 records in 0.07857645 seconds. Throughput is 1628.9867 records/second. Loss is 0.18629123. Sequential31006cbd's hyper parameters: Current learning rate is 0.00437598459653422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42368/60000][Iteration 6428][Wall Clock 600.070374022s] Trained 128 records in 0.078794446 seconds. Throughput is 1624.4799 records/second. Loss is 0.1353743. Sequential31006cbd's hyper parameters: Current learning rate is 0.004375601645226219. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42496/60000][Iteration 6429][Wall Clock 600.145988092s] Trained 128 records in 0.07561407 seconds. Throughput is 1692.8066 records/second. Loss is 0.16843982. Sequential31006cbd's hyper parameters: Current learning rate is 0.004375218760938047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42624/60000][Iteration 6430][Wall Clock 600.220378987s] Trained 128 records in 0.074390895 seconds. Throughput is 1720.6406 records/second. Loss is 0.1753659. Sequential31006cbd's hyper parameters: Current learning rate is 0.004374835943652113. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42752/60000][Iteration 6431][Wall Clock 600.293957107s] Trained 128 records in 0.07357812 seconds. Throughput is 1739.6476 records/second. Loss is 0.10155076. Sequential31006cbd's hyper parameters: Current learning rate is 0.004374453193350831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 42880/60000][Iteration 6432][Wall Clock 600.373053538s] Trained 128 records in 0.079096431 seconds. Throughput is 1618.2778 records/second. Loss is 0.30775106. Sequential31006cbd's hyper parameters: Current learning rate is 0.004374070510016622. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:37 INFO  DistriOptimizer$:408 - [Epoch 14 43008/60000][Iteration 6433][Wall Clock 600.454157797s] Trained 128 records in 0.081104259 seconds. Throughput is 1578.2156 records/second. Loss is 0.1446999. Sequential31006cbd's hyper parameters: Current learning rate is 0.004373687893631911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43136/60000][Iteration 6434][Wall Clock 600.530506017s] Trained 128 records in 0.07634822 seconds. Throughput is 1676.5289 records/second. Loss is 0.14441673. Sequential31006cbd's hyper parameters: Current learning rate is 0.004373305344179131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43264/60000][Iteration 6435][Wall Clock 600.617372401s] Trained 128 records in 0.086866384 seconds. Throughput is 1473.5273 records/second. Loss is 0.26104093. Sequential31006cbd's hyper parameters: Current learning rate is 0.00437292286164072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43392/60000][Iteration 6436][Wall Clock 600.709570772s] Trained 128 records in 0.092198371 seconds. Throughput is 1388.3108 records/second. Loss is 0.12551293. Sequential31006cbd's hyper parameters: Current learning rate is 0.004372540445999126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43520/60000][Iteration 6437][Wall Clock 600.800951588s] Trained 128 records in 0.091380816 seconds. Throughput is 1400.7316 records/second. Loss is 0.18972027. Sequential31006cbd's hyper parameters: Current learning rate is 0.004372158097236795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43648/60000][Iteration 6438][Wall Clock 600.89220169s] Trained 128 records in 0.091250102 seconds. Throughput is 1402.7382 records/second. Loss is 0.15188141. Sequential31006cbd's hyper parameters: Current learning rate is 0.00437177581533619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43776/60000][Iteration 6439][Wall Clock 600.988077559s] Trained 128 records in 0.095875869 seconds. Throughput is 1335.0597 records/second. Loss is 0.1495394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004371393600279769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 43904/60000][Iteration 6440][Wall Clock 601.071163011s] Trained 128 records in 0.083085452 seconds. Throughput is 1540.5825 records/second. Loss is 0.14485931. Sequential31006cbd's hyper parameters: Current learning rate is 0.004371011452050004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 44032/60000][Iteration 6441][Wall Clock 601.148512067s] Trained 128 records in 0.077349056 seconds. Throughput is 1654.8359 records/second. Loss is 0.15894218. Sequential31006cbd's hyper parameters: Current learning rate is 0.00437062937062937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 44160/60000][Iteration 6442][Wall Clock 601.22410485s] Trained 128 records in 0.075592783 seconds. Throughput is 1693.2833 records/second. Loss is 0.20854722. Sequential31006cbd's hyper parameters: Current learning rate is 0.00437024735600035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 44288/60000][Iteration 6443][Wall Clock 601.302920363s] Trained 128 records in 0.078815513 seconds. Throughput is 1624.0458 records/second. Loss is 0.088591866. Sequential31006cbd's hyper parameters: Current learning rate is 0.004369865408145429. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 44416/60000][Iteration 6444][Wall Clock 601.381859727s] Trained 128 records in 0.078939364 seconds. Throughput is 1621.4978 records/second. Loss is 0.13073727. Sequential31006cbd's hyper parameters: Current learning rate is 0.004369483527047103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:38 INFO  DistriOptimizer$:408 - [Epoch 14 44544/60000][Iteration 6445][Wall Clock 601.462121108s] Trained 128 records in 0.080261381 seconds. Throughput is 1594.7894 records/second. Loss is 0.119327344. Sequential31006cbd's hyper parameters: Current learning rate is 0.004369101712687871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 44672/60000][Iteration 6446][Wall Clock 601.540331667s] Trained 128 records in 0.078210559 seconds. Throughput is 1636.6075 records/second. Loss is 0.110150255. Sequential31006cbd's hyper parameters: Current learning rate is 0.00436871996505024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 44800/60000][Iteration 6447][Wall Clock 601.614113873s] Trained 128 records in 0.073782206 seconds. Throughput is 1734.8357 records/second. Loss is 0.16910177. Sequential31006cbd's hyper parameters: Current learning rate is 0.004368338284116722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 44928/60000][Iteration 6448][Wall Clock 601.692508623s] Trained 128 records in 0.07839475 seconds. Throughput is 1632.7625 records/second. Loss is 0.15507697. Sequential31006cbd's hyper parameters: Current learning rate is 0.004367956669869835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45056/60000][Iteration 6449][Wall Clock 601.767713093s] Trained 128 records in 0.07520447 seconds. Throughput is 1702.0265 records/second. Loss is 0.13452345. Sequential31006cbd's hyper parameters: Current learning rate is 0.004367575122292103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45184/60000][Iteration 6450][Wall Clock 601.847495124s] Trained 128 records in 0.079782031 seconds. Throughput is 1604.3713 records/second. Loss is 0.18773893. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043671936413660585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45312/60000][Iteration 6451][Wall Clock 601.975119867s] Trained 128 records in 0.127624743 seconds. Throughput is 1002.94025 records/second. Loss is 0.1861956. Sequential31006cbd's hyper parameters: Current learning rate is 0.004366812227074236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45440/60000][Iteration 6452][Wall Clock 602.051675761s] Trained 128 records in 0.076555894 seconds. Throughput is 1671.9811 records/second. Loss is 0.19648075. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043664308793991795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45568/60000][Iteration 6453][Wall Clock 602.154137552s] Trained 128 records in 0.102461791 seconds. Throughput is 1249.2461 records/second. Loss is 0.10505837. Sequential31006cbd's hyper parameters: Current learning rate is 0.004366049598323437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45696/60000][Iteration 6454][Wall Clock 602.225889336s] Trained 128 records in 0.071751784 seconds. Throughput is 1783.9279 records/second. Loss is 0.10775145. Sequential31006cbd's hyper parameters: Current learning rate is 0.004365668383829564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45824/60000][Iteration 6455][Wall Clock 602.305721677s] Trained 128 records in 0.079832341 seconds. Throughput is 1603.3602 records/second. Loss is 0.1479971. Sequential31006cbd's hyper parameters: Current learning rate is 0.004365287235900122. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 45952/60000][Iteration 6456][Wall Clock 602.386861361s] Trained 128 records in 0.081139684 seconds. Throughput is 1577.5265 records/second. Loss is 0.2294661. Sequential31006cbd's hyper parameters: Current learning rate is 0.004364906154517677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:39 INFO  DistriOptimizer$:408 - [Epoch 14 46080/60000][Iteration 6457][Wall Clock 602.469443337s] Trained 128 records in 0.082581976 seconds. Throughput is 1549.9751 records/second. Loss is 0.19137006. Sequential31006cbd's hyper parameters: Current learning rate is 0.004364525139664805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46208/60000][Iteration 6458][Wall Clock 602.545072248s] Trained 128 records in 0.075628911 seconds. Throughput is 1692.4744 records/second. Loss is 0.120351106. Sequential31006cbd's hyper parameters: Current learning rate is 0.004364144191324081. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46336/60000][Iteration 6459][Wall Clock 602.628332325s] Trained 128 records in 0.083260077 seconds. Throughput is 1537.3514 records/second. Loss is 0.19829099. Sequential31006cbd's hyper parameters: Current learning rate is 0.004363763309478094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46464/60000][Iteration 6460][Wall Clock 602.712647411s] Trained 128 records in 0.084315086 seconds. Throughput is 1518.1151 records/second. Loss is 0.09777579. Sequential31006cbd's hyper parameters: Current learning rate is 0.004363382494109433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46592/60000][Iteration 6461][Wall Clock 602.795760679s] Trained 128 records in 0.083113268 seconds. Throughput is 1540.067 records/second. Loss is 0.15974744. Sequential31006cbd's hyper parameters: Current learning rate is 0.004363001745200699. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46720/60000][Iteration 6462][Wall Clock 602.875217809s] Trained 128 records in 0.07945713 seconds. Throughput is 1610.9316 records/second. Loss is 0.23319966. Sequential31006cbd's hyper parameters: Current learning rate is 0.004362621062734491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46848/60000][Iteration 6463][Wall Clock 602.973413782s] Trained 128 records in 0.098195973 seconds. Throughput is 1303.5159 records/second. Loss is 0.13157415. Sequential31006cbd's hyper parameters: Current learning rate is 0.004362240446693423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 46976/60000][Iteration 6464][Wall Clock 603.076335259s] Trained 128 records in 0.102921477 seconds. Throughput is 1243.6665 records/second. Loss is 0.1545363. Sequential31006cbd's hyper parameters: Current learning rate is 0.004361859897060106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 47104/60000][Iteration 6465][Wall Clock 603.164396967s] Trained 128 records in 0.088061708 seconds. Throughput is 1453.5262 records/second. Loss is 0.19782762. Sequential31006cbd's hyper parameters: Current learning rate is 0.004361479413817167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 47232/60000][Iteration 6466][Wall Clock 603.241780701s] Trained 128 records in 0.077383734 seconds. Throughput is 1654.0944 records/second. Loss is 0.15993787. Sequential31006cbd's hyper parameters: Current learning rate is 0.00436109899694723. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 47360/60000][Iteration 6467][Wall Clock 603.316639405s] Trained 128 records in 0.074858704 seconds. Throughput is 1709.8881 records/second. Loss is 0.10188918. Sequential31006cbd's hyper parameters: Current learning rate is 0.004360718646432932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:40 INFO  DistriOptimizer$:408 - [Epoch 14 47488/60000][Iteration 6468][Wall Clock 603.399310506s] Trained 128 records in 0.082671101 seconds. Throughput is 1548.3041 records/second. Loss is 0.13764971. Sequential31006cbd's hyper parameters: Current learning rate is 0.004360338362256911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 47616/60000][Iteration 6469][Wall Clock 603.484514968s] Trained 128 records in 0.085204462 seconds. Throughput is 1502.2688 records/second. Loss is 0.09869211. Sequential31006cbd's hyper parameters: Current learning rate is 0.004359958144401814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 47744/60000][Iteration 6470][Wall Clock 603.563444199s] Trained 128 records in 0.078929231 seconds. Throughput is 1621.7059 records/second. Loss is 0.20593144. Sequential31006cbd's hyper parameters: Current learning rate is 0.004359577992850292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 47872/60000][Iteration 6471][Wall Clock 603.644228409s] Trained 128 records in 0.08078421 seconds. Throughput is 1584.468 records/second. Loss is 0.17848147. Sequential31006cbd's hyper parameters: Current learning rate is 0.004359197907585004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48000/60000][Iteration 6472][Wall Clock 603.722154722s] Trained 128 records in 0.077926313 seconds. Throughput is 1642.5774 records/second. Loss is 0.23772317. Sequential31006cbd's hyper parameters: Current learning rate is 0.004358817888588615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48128/60000][Iteration 6473][Wall Clock 603.796404886s] Trained 128 records in 0.074250164 seconds. Throughput is 1723.902 records/second. Loss is 0.15995714. Sequential31006cbd's hyper parameters: Current learning rate is 0.004358437935843794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48256/60000][Iteration 6474][Wall Clock 603.872376262s] Trained 128 records in 0.075971376 seconds. Throughput is 1684.8452 records/second. Loss is 0.27042937. Sequential31006cbd's hyper parameters: Current learning rate is 0.004358058049333217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48384/60000][Iteration 6475][Wall Clock 603.955823858s] Trained 128 records in 0.083447596 seconds. Throughput is 1533.8967 records/second. Loss is 0.18792373. Sequential31006cbd's hyper parameters: Current learning rate is 0.004357678229039567. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48512/60000][Iteration 6476][Wall Clock 604.070643067s] Trained 128 records in 0.114819209 seconds. Throughput is 1114.796 records/second. Loss is 0.14729193. Sequential31006cbd's hyper parameters: Current learning rate is 0.004357298474945534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48640/60000][Iteration 6477][Wall Clock 604.153681453s] Trained 128 records in 0.083038386 seconds. Throughput is 1541.4557 records/second. Loss is 0.100127935. Sequential31006cbd's hyper parameters: Current learning rate is 0.004356918787033809. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48768/60000][Iteration 6478][Wall Clock 604.266445731s] Trained 128 records in 0.112764278 seconds. Throughput is 1135.1112 records/second. Loss is 0.19348055. Sequential31006cbd's hyper parameters: Current learning rate is 0.004356539165287096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 48896/60000][Iteration 6479][Wall Clock 604.340808769s] Trained 128 records in 0.074363038 seconds. Throughput is 1721.2853 records/second. Loss is 0.20196196. Sequential31006cbd's hyper parameters: Current learning rate is 0.004356159609688099. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:41 INFO  DistriOptimizer$:408 - [Epoch 14 49024/60000][Iteration 6480][Wall Clock 604.417452597s] Trained 128 records in 0.076643828 seconds. Throughput is 1670.0627 records/second. Loss is 0.22058061. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043557801202195314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49152/60000][Iteration 6481][Wall Clock 604.495863934s] Trained 128 records in 0.078411337 seconds. Throughput is 1632.4169 records/second. Loss is 0.11586438. Sequential31006cbd's hyper parameters: Current learning rate is 0.004355400696864111. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49280/60000][Iteration 6482][Wall Clock 604.575050507s] Trained 128 records in 0.079186573 seconds. Throughput is 1616.4357 records/second. Loss is 0.13810277. Sequential31006cbd's hyper parameters: Current learning rate is 0.004355021339604565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49408/60000][Iteration 6483][Wall Clock 604.648559235s] Trained 128 records in 0.073508728 seconds. Throughput is 1741.2899 records/second. Loss is 0.17942825. Sequential31006cbd's hyper parameters: Current learning rate is 0.004354642048423619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49536/60000][Iteration 6484][Wall Clock 604.728907243s] Trained 128 records in 0.080348008 seconds. Throughput is 1593.07 records/second. Loss is 0.20153135. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043542628233040155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49664/60000][Iteration 6485][Wall Clock 604.809452884s] Trained 128 records in 0.080545641 seconds. Throughput is 1589.1611 records/second. Loss is 0.15825677. Sequential31006cbd's hyper parameters: Current learning rate is 0.004353883664228492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49792/60000][Iteration 6486][Wall Clock 604.887137327s] Trained 128 records in 0.077684443 seconds. Throughput is 1647.6917 records/second. Loss is 0.20102355. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043535045711798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 49920/60000][Iteration 6487][Wall Clock 604.963682814s] Trained 128 records in 0.076545487 seconds. Throughput is 1672.2084 records/second. Loss is 0.12495573. Sequential31006cbd's hyper parameters: Current learning rate is 0.004353125544140693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 50048/60000][Iteration 6488][Wall Clock 605.069610834s] Trained 128 records in 0.10592802 seconds. Throughput is 1208.3677 records/second. Loss is 0.14287406. Sequential31006cbd's hyper parameters: Current learning rate is 0.004352746583093932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 50176/60000][Iteration 6489][Wall Clock 605.149863748s] Trained 128 records in 0.080252914 seconds. Throughput is 1594.9576 records/second. Loss is 0.30852613. Sequential31006cbd's hyper parameters: Current learning rate is 0.004352367688022284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 50304/60000][Iteration 6490][Wall Clock 605.228828895s] Trained 128 records in 0.078965147 seconds. Throughput is 1620.9683 records/second. Loss is 0.17878684. Sequential31006cbd's hyper parameters: Current learning rate is 0.004351988858908521. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 50432/60000][Iteration 6491][Wall Clock 605.308371077s] Trained 128 records in 0.079542182 seconds. Throughput is 1609.2091 records/second. Loss is 0.12851062. Sequential31006cbd's hyper parameters: Current learning rate is 0.004351610095735422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 50560/60000][Iteration 6492][Wall Clock 605.385843203s] Trained 128 records in 0.077472126 seconds. Throughput is 1652.2072 records/second. Loss is 0.26195046. Sequential31006cbd's hyper parameters: Current learning rate is 0.004351231398485772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:42 INFO  DistriOptimizer$:408 - [Epoch 14 50688/60000][Iteration 6493][Wall Clock 605.460306488s] Trained 128 records in 0.074463285 seconds. Throughput is 1718.9679 records/second. Loss is 0.18390267. Sequential31006cbd's hyper parameters: Current learning rate is 0.00435085276714236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 50816/60000][Iteration 6494][Wall Clock 605.538477177s] Trained 128 records in 0.078170689 seconds. Throughput is 1637.4424 records/second. Loss is 0.14772198. Sequential31006cbd's hyper parameters: Current learning rate is 0.004350474201687984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 50944/60000][Iteration 6495][Wall Clock 605.614307094s] Trained 128 records in 0.075829917 seconds. Throughput is 1687.9882 records/second. Loss is 0.13126343. Sequential31006cbd's hyper parameters: Current learning rate is 0.004350095702105447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51072/60000][Iteration 6496][Wall Clock 605.687604616s] Trained 128 records in 0.073297522 seconds. Throughput is 1746.3073 records/second. Loss is 0.26339048. Sequential31006cbd's hyper parameters: Current learning rate is 0.004349717268377555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51200/60000][Iteration 6497][Wall Clock 605.766316261s] Trained 128 records in 0.078711645 seconds. Throughput is 1626.1888 records/second. Loss is 0.07327075. Sequential31006cbd's hyper parameters: Current learning rate is 0.004349338900487126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51328/60000][Iteration 6498][Wall Clock 605.850683048s] Trained 128 records in 0.084366787 seconds. Throughput is 1517.1848 records/second. Loss is 0.1712111. Sequential31006cbd's hyper parameters: Current learning rate is 0.004348960598416978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51456/60000][Iteration 6499][Wall Clock 605.943427182s] Trained 128 records in 0.092744134 seconds. Throughput is 1380.1412 records/second. Loss is 0.10234979. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043485823621499395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51584/60000][Iteration 6500][Wall Clock 606.051217982s] Trained 128 records in 0.1077908 seconds. Throughput is 1187.4854 records/second. Loss is 0.12205308. Sequential31006cbd's hyper parameters: Current learning rate is 0.00434820419166884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51712/60000][Iteration 6501][Wall Clock 606.162325234s] Trained 128 records in 0.111107252 seconds. Throughput is 1152.04 records/second. Loss is 0.19718891. Sequential31006cbd's hyper parameters: Current learning rate is 0.004347826086956522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51840/60000][Iteration 6502][Wall Clock 606.275361728s] Trained 128 records in 0.113036494 seconds. Throughput is 1132.3777 records/second. Loss is 0.16462247. Sequential31006cbd's hyper parameters: Current learning rate is 0.004347448047995826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 51968/60000][Iteration 6503][Wall Clock 606.353509114s] Trained 128 records in 0.078147386 seconds. Throughput is 1637.9307 records/second. Loss is 0.1670533. Sequential31006cbd's hyper parameters: Current learning rate is 0.004347070074769606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:43 INFO  DistriOptimizer$:408 - [Epoch 14 52096/60000][Iteration 6504][Wall Clock 606.425600417s] Trained 128 records in 0.072091303 seconds. Throughput is 1775.5262 records/second. Loss is 0.17010418. Sequential31006cbd's hyper parameters: Current learning rate is 0.004346692167260714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52224/60000][Iteration 6505][Wall Clock 606.507396679s] Trained 128 records in 0.081796262 seconds. Throughput is 1564.8638 records/second. Loss is 0.1898852. Sequential31006cbd's hyper parameters: Current learning rate is 0.004346314325452017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52352/60000][Iteration 6506][Wall Clock 606.586251336s] Trained 128 records in 0.078854657 seconds. Throughput is 1623.2395 records/second. Loss is 0.1848371. Sequential31006cbd's hyper parameters: Current learning rate is 0.004345936549326379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52480/60000][Iteration 6507][Wall Clock 606.660032187s] Trained 128 records in 0.073780851 seconds. Throughput is 1734.8676 records/second. Loss is 0.18136223. Sequential31006cbd's hyper parameters: Current learning rate is 0.004345558838866678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52608/60000][Iteration 6508][Wall Clock 606.739496402s] Trained 128 records in 0.079464215 seconds. Throughput is 1610.788 records/second. Loss is 0.15916301. Sequential31006cbd's hyper parameters: Current learning rate is 0.004345181194055792. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52736/60000][Iteration 6509][Wall Clock 606.842789038s] Trained 128 records in 0.103292636 seconds. Throughput is 1239.1978 records/second. Loss is 0.11943839. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043448036148766075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52864/60000][Iteration 6510][Wall Clock 606.92341739s] Trained 128 records in 0.080628352 seconds. Throughput is 1587.5309 records/second. Loss is 0.083969615. Sequential31006cbd's hyper parameters: Current learning rate is 0.004344426101312016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 52992/60000][Iteration 6511][Wall Clock 607.003624607s] Trained 128 records in 0.080207217 seconds. Throughput is 1595.8665 records/second. Loss is 0.17776915. Sequential31006cbd's hyper parameters: Current learning rate is 0.004344048653344918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 53120/60000][Iteration 6512][Wall Clock 607.079215178s] Trained 128 records in 0.075590571 seconds. Throughput is 1693.3329 records/second. Loss is 0.27483827. Sequential31006cbd's hyper parameters: Current learning rate is 0.004343671270958214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 53248/60000][Iteration 6513][Wall Clock 607.156293453s] Trained 128 records in 0.077078275 seconds. Throughput is 1660.6495 records/second. Loss is 0.17079383. Sequential31006cbd's hyper parameters: Current learning rate is 0.004343293954134816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 53376/60000][Iteration 6514][Wall Clock 607.258448219s] Trained 128 records in 0.102154766 seconds. Throughput is 1253.0007 records/second. Loss is 0.12289385. Sequential31006cbd's hyper parameters: Current learning rate is 0.004342916702857639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 53504/60000][Iteration 6515][Wall Clock 607.345660074s] Trained 128 records in 0.087211855 seconds. Throughput is 1467.6904 records/second. Loss is 0.11832421. Sequential31006cbd's hyper parameters: Current learning rate is 0.004342539517109606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:44 INFO  DistriOptimizer$:408 - [Epoch 14 53632/60000][Iteration 6516][Wall Clock 607.428139943s] Trained 128 records in 0.082479869 seconds. Throughput is 1551.8938 records/second. Loss is 0.19351378. Sequential31006cbd's hyper parameters: Current learning rate is 0.004342162396873643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 53760/60000][Iteration 6517][Wall Clock 607.505435149s] Trained 128 records in 0.077295206 seconds. Throughput is 1655.9889 records/second. Loss is 0.17258522. Sequential31006cbd's hyper parameters: Current learning rate is 0.004341785342132684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 53888/60000][Iteration 6518][Wall Clock 607.586134125s] Trained 128 records in 0.080698976 seconds. Throughput is 1586.1416 records/second. Loss is 0.14564008. Sequential31006cbd's hyper parameters: Current learning rate is 0.004341408352869672. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54016/60000][Iteration 6519][Wall Clock 607.664655563s] Trained 128 records in 0.078521438 seconds. Throughput is 1630.128 records/second. Loss is 0.12178242. Sequential31006cbd's hyper parameters: Current learning rate is 0.004341031429067546. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54144/60000][Iteration 6520][Wall Clock 607.741920659s] Trained 128 records in 0.077265096 seconds. Throughput is 1656.6342 records/second. Loss is 0.21938841. Sequential31006cbd's hyper parameters: Current learning rate is 0.004340654570709263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54272/60000][Iteration 6521][Wall Clock 607.831426436s] Trained 128 records in 0.089505777 seconds. Throughput is 1430.0753 records/second. Loss is 0.26920512. Sequential31006cbd's hyper parameters: Current learning rate is 0.004340277777777777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54400/60000][Iteration 6522][Wall Clock 607.911155298s] Trained 128 records in 0.079728862 seconds. Throughput is 1605.4412 records/second. Loss is 0.15197214. Sequential31006cbd's hyper parameters: Current learning rate is 0.004339901050256055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54528/60000][Iteration 6523][Wall Clock 607.984926801s] Trained 128 records in 0.073771503 seconds. Throughput is 1735.0873 records/second. Loss is 0.16818239. Sequential31006cbd's hyper parameters: Current learning rate is 0.004339524388127061. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54656/60000][Iteration 6524][Wall Clock 608.060835312s] Trained 128 records in 0.075908511 seconds. Throughput is 1686.2404 records/second. Loss is 0.09152756. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043391477913737745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54784/60000][Iteration 6525][Wall Clock 608.139948635s] Trained 128 records in 0.079113323 seconds. Throughput is 1617.9324 records/second. Loss is 0.1458376. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043387712599791736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 54912/60000][Iteration 6526][Wall Clock 608.234143415s] Trained 128 records in 0.09419478 seconds. Throughput is 1358.8864 records/second. Loss is 0.113056056. Sequential31006cbd's hyper parameters: Current learning rate is 0.004338394793926247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 55040/60000][Iteration 6527][Wall Clock 608.313157865s] Trained 128 records in 0.07901445 seconds. Throughput is 1619.9569 records/second. Loss is 0.16241795. Sequential31006cbd's hyper parameters: Current learning rate is 0.004338018393197987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:45 INFO  DistriOptimizer$:408 - [Epoch 14 55168/60000][Iteration 6528][Wall Clock 608.392630073s] Trained 128 records in 0.079472208 seconds. Throughput is 1610.626 records/second. Loss is 0.1867384. Sequential31006cbd's hyper parameters: Current learning rate is 0.004337642057777392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 55296/60000][Iteration 6529][Wall Clock 608.466282174s] Trained 128 records in 0.073652101 seconds. Throughput is 1737.9001 records/second. Loss is 0.14833304. Sequential31006cbd's hyper parameters: Current learning rate is 0.004337265787647467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 55424/60000][Iteration 6530][Wall Clock 608.542084051s] Trained 128 records in 0.075801877 seconds. Throughput is 1688.6125 records/second. Loss is 0.20467798. Sequential31006cbd's hyper parameters: Current learning rate is 0.004336889582791222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 55552/60000][Iteration 6531][Wall Clock 608.622949462s] Trained 128 records in 0.080865411 seconds. Throughput is 1582.877 records/second. Loss is 0.23360236. Sequential31006cbd's hyper parameters: Current learning rate is 0.004336513443191674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 55680/60000][Iteration 6532][Wall Clock 608.704413884s] Trained 128 records in 0.081464422 seconds. Throughput is 1571.238 records/second. Loss is 0.12930201. Sequential31006cbd's hyper parameters: Current learning rate is 0.004336137368831845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 55808/60000][Iteration 6533][Wall Clock 608.791514837s] Trained 128 records in 0.087100953 seconds. Throughput is 1469.5591 records/second. Loss is 0.14334707. Sequential31006cbd's hyper parameters: Current learning rate is 0.004335761359694762. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 55936/60000][Iteration 6534][Wall Clock 608.870117523s] Trained 128 records in 0.078602686 seconds. Throughput is 1628.4431 records/second. Loss is 0.17288667. Sequential31006cbd's hyper parameters: Current learning rate is 0.004335385415763462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56064/60000][Iteration 6535][Wall Clock 608.94805557s] Trained 128 records in 0.077938047 seconds. Throughput is 1642.3301 records/second. Loss is 0.13784857. Sequential31006cbd's hyper parameters: Current learning rate is 0.004335009537020981. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56192/60000][Iteration 6536][Wall Clock 609.02309107s] Trained 128 records in 0.0750355 seconds. Throughput is 1705.8593 records/second. Loss is 0.20406185. Sequential31006cbd's hyper parameters: Current learning rate is 0.004334633723450367. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56320/60000][Iteration 6537][Wall Clock 609.098639981s] Trained 128 records in 0.075548911 seconds. Throughput is 1694.2667 records/second. Loss is 0.16553807. Sequential31006cbd's hyper parameters: Current learning rate is 0.004334257975034675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56448/60000][Iteration 6538][Wall Clock 609.176643287s] Trained 128 records in 0.078003306 seconds. Throughput is 1640.956 records/second. Loss is 0.15945631. Sequential31006cbd's hyper parameters: Current learning rate is 0.004333882291756955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56576/60000][Iteration 6539][Wall Clock 609.256502392s] Trained 128 records in 0.079859105 seconds. Throughput is 1602.8229 records/second. Loss is 0.25319186. Sequential31006cbd's hyper parameters: Current learning rate is 0.004333506673600278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56704/60000][Iteration 6540][Wall Clock 609.348160933s] Trained 128 records in 0.091658541 seconds. Throughput is 1396.4874 records/second. Loss is 0.13452229. Sequential31006cbd's hyper parameters: Current learning rate is 0.004333131120547708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:46 INFO  DistriOptimizer$:408 - [Epoch 14 56832/60000][Iteration 6541][Wall Clock 609.424734719s] Trained 128 records in 0.076573786 seconds. Throughput is 1671.5902 records/second. Loss is 0.18160877. Sequential31006cbd's hyper parameters: Current learning rate is 0.004332755632582323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 56960/60000][Iteration 6542][Wall Clock 609.500192426s] Trained 128 records in 0.075457707 seconds. Throughput is 1696.3145 records/second. Loss is 0.11142364. Sequential31006cbd's hyper parameters: Current learning rate is 0.004332380209687202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57088/60000][Iteration 6543][Wall Clock 609.577022606s] Trained 128 records in 0.07683018 seconds. Throughput is 1666.012 records/second. Loss is 0.13369939. Sequential31006cbd's hyper parameters: Current learning rate is 0.004332004851845435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57216/60000][Iteration 6544][Wall Clock 609.655943435s] Trained 128 records in 0.078920829 seconds. Throughput is 1621.8787 records/second. Loss is 0.1255143. Sequential31006cbd's hyper parameters: Current learning rate is 0.00433162955904011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57344/60000][Iteration 6545][Wall Clock 609.74275191s] Trained 128 records in 0.086808475 seconds. Throughput is 1474.5105 records/second. Loss is 0.139204. Sequential31006cbd's hyper parameters: Current learning rate is 0.004331254331254332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57472/60000][Iteration 6546][Wall Clock 609.819223096s] Trained 128 records in 0.076471186 seconds. Throughput is 1673.833 records/second. Loss is 0.18697497. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043308791684712. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57600/60000][Iteration 6547][Wall Clock 609.90226424s] Trained 128 records in 0.083041144 seconds. Throughput is 1541.4045 records/second. Loss is 0.21767452. Sequential31006cbd's hyper parameters: Current learning rate is 0.004330504070673826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57728/60000][Iteration 6548][Wall Clock 609.981463433s] Trained 128 records in 0.079199193 seconds. Throughput is 1616.1781 records/second. Loss is 0.18631431. Sequential31006cbd's hyper parameters: Current learning rate is 0.004330129037845328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57856/60000][Iteration 6549][Wall Clock 610.056040585s] Trained 128 records in 0.074577152 seconds. Throughput is 1716.3434 records/second. Loss is 0.15499532. Sequential31006cbd's hyper parameters: Current learning rate is 0.004329754069968826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 57984/60000][Iteration 6550][Wall Clock 610.138074963s] Trained 128 records in 0.082034378 seconds. Throughput is 1560.3214 records/second. Loss is 0.16762635. Sequential31006cbd's hyper parameters: Current learning rate is 0.004329379167027448. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 58112/60000][Iteration 6551][Wall Clock 610.224643234s] Trained 128 records in 0.086568271 seconds. Throughput is 1478.6017 records/second. Loss is 0.11478919. Sequential31006cbd's hyper parameters: Current learning rate is 0.004329004329004329. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 58240/60000][Iteration 6552][Wall Clock 610.318704588s] Trained 128 records in 0.094061354 seconds. Throughput is 1360.814 records/second. Loss is 0.175102. Sequential31006cbd's hyper parameters: Current learning rate is 0.004328629555882608. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:47 INFO  DistriOptimizer$:408 - [Epoch 14 58368/60000][Iteration 6553][Wall Clock 610.398693275s] Trained 128 records in 0.079988687 seconds. Throughput is 1600.2263 records/second. Loss is 0.15214822. Sequential31006cbd's hyper parameters: Current learning rate is 0.00432825484764543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 58496/60000][Iteration 6554][Wall Clock 610.473522286s] Trained 128 records in 0.074829011 seconds. Throughput is 1710.5665 records/second. Loss is 0.16156746. Sequential31006cbd's hyper parameters: Current learning rate is 0.004327880204275946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 58624/60000][Iteration 6555][Wall Clock 610.55042555s] Trained 128 records in 0.076903264 seconds. Throughput is 1664.4287 records/second. Loss is 0.09041186. Sequential31006cbd's hyper parameters: Current learning rate is 0.004327505625757314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 58752/60000][Iteration 6556][Wall Clock 610.6253446s] Trained 128 records in 0.07491905 seconds. Throughput is 1708.5106 records/second. Loss is 0.14532503. Sequential31006cbd's hyper parameters: Current learning rate is 0.004327131112072696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 58880/60000][Iteration 6557][Wall Clock 610.708632326s] Trained 128 records in 0.083287726 seconds. Throughput is 1536.8412 records/second. Loss is 0.16680102. Sequential31006cbd's hyper parameters: Current learning rate is 0.004326756663205261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59008/60000][Iteration 6558][Wall Clock 610.781448904s] Trained 128 records in 0.072816578 seconds. Throughput is 1757.8414 records/second. Loss is 0.15377712. Sequential31006cbd's hyper parameters: Current learning rate is 0.004326382279138185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59136/60000][Iteration 6559][Wall Clock 610.855434952s] Trained 128 records in 0.073986048 seconds. Throughput is 1730.0559 records/second. Loss is 0.14645882. Sequential31006cbd's hyper parameters: Current learning rate is 0.004326007959854645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59264/60000][Iteration 6560][Wall Clock 610.934270784s] Trained 128 records in 0.078835832 seconds. Throughput is 1623.6272 records/second. Loss is 0.1261077. Sequential31006cbd's hyper parameters: Current learning rate is 0.004325633705337832. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59392/60000][Iteration 6561][Wall Clock 611.008357481s] Trained 128 records in 0.074086697 seconds. Throughput is 1727.7056 records/second. Loss is 0.20765269. Sequential31006cbd's hyper parameters: Current learning rate is 0.004325259515570934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59520/60000][Iteration 6562][Wall Clock 611.080676753s] Trained 128 records in 0.072319272 seconds. Throughput is 1769.9294 records/second. Loss is 0.19602689. Sequential31006cbd's hyper parameters: Current learning rate is 0.004324885390537151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59648/60000][Iteration 6563][Wall Clock 611.156828303s] Trained 128 records in 0.07615155 seconds. Throughput is 1680.8588 records/second. Loss is 0.12882861. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043245113302196846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59776/60000][Iteration 6564][Wall Clock 611.235621625s] Trained 128 records in 0.078793322 seconds. Throughput is 1624.503 records/second. Loss is 0.16890426. Sequential31006cbd's hyper parameters: Current learning rate is 0.004324137334601748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 59904/60000][Iteration 6565][Wall Clock 611.310102061s] Trained 128 records in 0.074480436 seconds. Throughput is 1718.5721 records/second. Loss is 0.15045017. Sequential31006cbd's hyper parameters: Current learning rate is 0.004323763403666551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:408 - [Epoch 14 60032/60000][Iteration 6566][Wall Clock 611.424740602s] Trained 128 records in 0.114638541 seconds. Throughput is 1116.5529 records/second. Loss is 0.14818913. Sequential31006cbd's hyper parameters: Current learning rate is 0.004323389537397319. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:48 INFO  DistriOptimizer$:452 - [Epoch 14 60032/60000][Iteration 6566][Wall Clock 611.424740602s] Epoch finished. Wall clock time is 612511.389086 ms
2019-10-24 00:07:48 INFO  DistriOptimizer$:111 - [Epoch 14 60032/60000][Iteration 6566][Wall Clock 611.424740602s] Validate model...
2019-10-24 00:07:49 INFO  DistriOptimizer$:178 - [Epoch 14 60032/60000][Iteration 6566][Wall Clock 611.424740602s] validate model throughput is 11487.78 records/second
2019-10-24 00:07:49 INFO  DistriOptimizer$:181 - [Epoch 14 60032/60000][Iteration 6566][Wall Clock 611.424740602s] Top1Accuracy is Accuracy(correct: 9523, count: 10000, accuracy: 0.9523)
2019-10-24 00:07:49 INFO  DistriOptimizer$:221 - [Wall Clock 612.511389086s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:07:49 INFO  DistriOptimizer$:226 - [Wall Clock 612.511389086s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 128/60000][Iteration 6567][Wall Clock 612.598604973s] Trained 128 records in 0.087215887 seconds. Throughput is 1467.6226 records/second. Loss is 0.16730462. Sequential31006cbd's hyper parameters: Current learning rate is 0.004323015735777278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 256/60000][Iteration 6568][Wall Clock 612.677042516s] Trained 128 records in 0.078437543 seconds. Throughput is 1631.8716 records/second. Loss is 0.32833987. Sequential31006cbd's hyper parameters: Current learning rate is 0.00432264199878966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 384/60000][Iteration 6569][Wall Clock 612.75291614s] Trained 128 records in 0.075873624 seconds. Throughput is 1687.0159 records/second. Loss is 0.14412835. Sequential31006cbd's hyper parameters: Current learning rate is 0.004322268326417704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 512/60000][Iteration 6570][Wall Clock 612.835448428s] Trained 128 records in 0.082532288 seconds. Throughput is 1550.9082 records/second. Loss is 0.14804307. Sequential31006cbd's hyper parameters: Current learning rate is 0.004321894718644654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 640/60000][Iteration 6571][Wall Clock 612.913491709s] Trained 128 records in 0.078043281 seconds. Throughput is 1640.1156 records/second. Loss is 0.13032106. Sequential31006cbd's hyper parameters: Current learning rate is 0.00432152117545376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 768/60000][Iteration 6572][Wall Clock 612.986519802s] Trained 128 records in 0.073028093 seconds. Throughput is 1752.7501 records/second. Loss is 0.27865073. Sequential31006cbd's hyper parameters: Current learning rate is 0.004321147696828277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 896/60000][Iteration 6573][Wall Clock 613.063969333s] Trained 128 records in 0.077449531 seconds. Throughput is 1652.6892 records/second. Loss is 0.19325253. Sequential31006cbd's hyper parameters: Current learning rate is 0.004320774282751469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 1024/60000][Iteration 6574][Wall Clock 613.144194573s] Trained 128 records in 0.08022524 seconds. Throughput is 1595.5079 records/second. Loss is 0.10988716. Sequential31006cbd's hyper parameters: Current learning rate is 0.004320400933206602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 1152/60000][Iteration 6575][Wall Clock 613.220178704s] Trained 128 records in 0.075984131 seconds. Throughput is 1684.5624 records/second. Loss is 0.09033945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043200276481769485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 1280/60000][Iteration 6576][Wall Clock 613.293323983s] Trained 128 records in 0.073145279 seconds. Throughput is 1749.9421 records/second. Loss is 0.17251465. Sequential31006cbd's hyper parameters: Current learning rate is 0.004319654427645788. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 1408/60000][Iteration 6577][Wall Clock 613.368812286s] Trained 128 records in 0.075488303 seconds. Throughput is 1695.6268 records/second. Loss is 0.15171508. Sequential31006cbd's hyper parameters: Current learning rate is 0.004319281271596406. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 1536/60000][Iteration 6578][Wall Clock 613.444361728s] Trained 128 records in 0.075549442 seconds. Throughput is 1694.2548 records/second. Loss is 0.1417545. Sequential31006cbd's hyper parameters: Current learning rate is 0.004318908180012093. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:50 INFO  DistriOptimizer$:408 - [Epoch 15 1664/60000][Iteration 6579][Wall Clock 613.528317488s] Trained 128 records in 0.08395576 seconds. Throughput is 1524.6125 records/second. Loss is 0.16687013. Sequential31006cbd's hyper parameters: Current learning rate is 0.004318535152876145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 1792/60000][Iteration 6580][Wall Clock 613.610971924s] Trained 128 records in 0.082654436 seconds. Throughput is 1548.6162 records/second. Loss is 0.1783343. Sequential31006cbd's hyper parameters: Current learning rate is 0.004318162190171862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 1920/60000][Iteration 6581][Wall Clock 613.683019516s] Trained 128 records in 0.072047592 seconds. Throughput is 1776.6035 records/second. Loss is 0.17260301. Sequential31006cbd's hyper parameters: Current learning rate is 0.004317789291882556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2048/60000][Iteration 6582][Wall Clock 613.763898826s] Trained 128 records in 0.08087931 seconds. Throughput is 1582.605 records/second. Loss is 0.1053571. Sequential31006cbd's hyper parameters: Current learning rate is 0.004317416457991537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2176/60000][Iteration 6583][Wall Clock 613.847909579s] Trained 128 records in 0.084010753 seconds. Throughput is 1523.6145 records/second. Loss is 0.16056715. Sequential31006cbd's hyper parameters: Current learning rate is 0.004317043688482128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2304/60000][Iteration 6584][Wall Clock 613.92743162s] Trained 128 records in 0.079522041 seconds. Throughput is 1609.6166 records/second. Loss is 0.2210376. Sequential31006cbd's hyper parameters: Current learning rate is 0.00431667098333765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2432/60000][Iteration 6585][Wall Clock 614.003584836s] Trained 128 records in 0.076153216 seconds. Throughput is 1680.8219 records/second. Loss is 0.18247235. Sequential31006cbd's hyper parameters: Current learning rate is 0.004316298342541437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2560/60000][Iteration 6586][Wall Clock 614.08156613s] Trained 128 records in 0.077981294 seconds. Throughput is 1641.4193 records/second. Loss is 0.122084275. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043159257660768235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2688/60000][Iteration 6587][Wall Clock 614.15785821s] Trained 128 records in 0.07629208 seconds. Throughput is 1677.7626 records/second. Loss is 0.20696685. Sequential31006cbd's hyper parameters: Current learning rate is 0.004315553253927153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2816/60000][Iteration 6588][Wall Clock 614.23750625s] Trained 128 records in 0.07964804 seconds. Throughput is 1607.0703 records/second. Loss is 0.14289767. Sequential31006cbd's hyper parameters: Current learning rate is 0.004315180806075775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 2944/60000][Iteration 6589][Wall Clock 614.32090752s] Trained 128 records in 0.08340127 seconds. Throughput is 1534.7488 records/second. Loss is 0.23901711. Sequential31006cbd's hyper parameters: Current learning rate is 0.00431480842250604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 3072/60000][Iteration 6590][Wall Clock 614.40450291s] Trained 128 records in 0.08359539 seconds. Throughput is 1531.1849 records/second. Loss is 0.19148403. Sequential31006cbd's hyper parameters: Current learning rate is 0.004314436103201312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:51 INFO  DistriOptimizer$:408 - [Epoch 15 3200/60000][Iteration 6591][Wall Clock 614.495272341s] Trained 128 records in 0.090769431 seconds. Throughput is 1410.1664 records/second. Loss is 0.13284032. Sequential31006cbd's hyper parameters: Current learning rate is 0.004314063848144953. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 3328/60000][Iteration 6592][Wall Clock 614.573668087s] Trained 128 records in 0.078395746 seconds. Throughput is 1632.7417 records/second. Loss is 0.20912465. Sequential31006cbd's hyper parameters: Current learning rate is 0.004313691657320335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 3456/60000][Iteration 6593][Wall Clock 614.654335818s] Trained 128 records in 0.080667731 seconds. Throughput is 1586.7559 records/second. Loss is 0.19333771. Sequential31006cbd's hyper parameters: Current learning rate is 0.004313319530710835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 3584/60000][Iteration 6594][Wall Clock 614.739496205s] Trained 128 records in 0.085160387 seconds. Throughput is 1503.0461 records/second. Loss is 0.15964797. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043129474682998365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 3712/60000][Iteration 6595][Wall Clock 614.823050575s] Trained 128 records in 0.08355437 seconds. Throughput is 1531.9366 records/second. Loss is 0.19304033. Sequential31006cbd's hyper parameters: Current learning rate is 0.004312575470070726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 3840/60000][Iteration 6596][Wall Clock 614.914702745s] Trained 128 records in 0.09165217 seconds. Throughput is 1396.5845 records/second. Loss is 0.13373458. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043122035360069. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 3968/60000][Iteration 6597][Wall Clock 614.991927003s] Trained 128 records in 0.077224258 seconds. Throughput is 1657.5104 records/second. Loss is 0.19695286. Sequential31006cbd's hyper parameters: Current learning rate is 0.004311831666091755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 4096/60000][Iteration 6598][Wall Clock 615.069620836s] Trained 128 records in 0.077693833 seconds. Throughput is 1647.4923 records/second. Loss is 0.07882531. Sequential31006cbd's hyper parameters: Current learning rate is 0.004311459860308701. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 4224/60000][Iteration 6599][Wall Clock 615.151627833s] Trained 128 records in 0.082006997 seconds. Throughput is 1560.8424 records/second. Loss is 0.19233367. Sequential31006cbd's hyper parameters: Current learning rate is 0.004311088118641145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 4352/60000][Iteration 6600][Wall Clock 615.244720032s] Trained 128 records in 0.093092199 seconds. Throughput is 1374.981 records/second. Loss is 0.34902376. Sequential31006cbd's hyper parameters: Current learning rate is 0.004310716441072507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 4480/60000][Iteration 6601][Wall Clock 615.327806896s] Trained 128 records in 0.083086864 seconds. Throughput is 1540.5564 records/second. Loss is 0.110373385. Sequential31006cbd's hyper parameters: Current learning rate is 0.004310344827586207. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 4608/60000][Iteration 6602][Wall Clock 615.408391007s] Trained 128 records in 0.080584111 seconds. Throughput is 1588.4025 records/second. Loss is 0.1016301. Sequential31006cbd's hyper parameters: Current learning rate is 0.004309973278165676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:52 INFO  DistriOptimizer$:408 - [Epoch 15 4736/60000][Iteration 6603][Wall Clock 615.487229463s] Trained 128 records in 0.078838456 seconds. Throughput is 1623.5732 records/second. Loss is 0.26361766. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043096017927943455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 4864/60000][Iteration 6604][Wall Clock 615.570503355s] Trained 128 records in 0.083273892 seconds. Throughput is 1537.0963 records/second. Loss is 0.2272636. Sequential31006cbd's hyper parameters: Current learning rate is 0.004309230371455659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 4992/60000][Iteration 6605][Wall Clock 615.64910471s] Trained 128 records in 0.078601355 seconds. Throughput is 1628.4707 records/second. Loss is 0.1752417. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043088590141330575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5120/60000][Iteration 6606][Wall Clock 615.727039944s] Trained 128 records in 0.077935234 seconds. Throughput is 1642.3894 records/second. Loss is 0.26592165. Sequential31006cbd's hyper parameters: Current learning rate is 0.004308487720809996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5248/60000][Iteration 6607][Wall Clock 615.799859966s] Trained 128 records in 0.072820022 seconds. Throughput is 1757.7583 records/second. Loss is 0.12711067. Sequential31006cbd's hyper parameters: Current learning rate is 0.004308116491469929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5376/60000][Iteration 6608][Wall Clock 615.876260496s] Trained 128 records in 0.07640053 seconds. Throughput is 1675.381 records/second. Loss is 0.14692137. Sequential31006cbd's hyper parameters: Current learning rate is 0.004307745326096321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5504/60000][Iteration 6609][Wall Clock 615.952797235s] Trained 128 records in 0.076536739 seconds. Throughput is 1672.3995 records/second. Loss is 0.17450717. Sequential31006cbd's hyper parameters: Current learning rate is 0.004307374224672639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5632/60000][Iteration 6610][Wall Clock 616.031009005s] Trained 128 records in 0.07821177 seconds. Throughput is 1636.5823 records/second. Loss is 0.1958552. Sequential31006cbd's hyper parameters: Current learning rate is 0.004307003187182358. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5760/60000][Iteration 6611][Wall Clock 616.116952045s] Trained 128 records in 0.08594304 seconds. Throughput is 1489.3585 records/second. Loss is 0.15430069. Sequential31006cbd's hyper parameters: Current learning rate is 0.004306632213608958. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 5888/60000][Iteration 6612][Wall Clock 616.201300881s] Trained 128 records in 0.084348836 seconds. Throughput is 1517.5076 records/second. Loss is 0.11529127. Sequential31006cbd's hyper parameters: Current learning rate is 0.004306261303935923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 6016/60000][Iteration 6613][Wall Clock 616.280322402s] Trained 128 records in 0.079021521 seconds. Throughput is 1619.8119 records/second. Loss is 0.19056669. Sequential31006cbd's hyper parameters: Current learning rate is 0.004305890458146745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 6144/60000][Iteration 6614][Wall Clock 616.356365472s] Trained 128 records in 0.07604307 seconds. Throughput is 1683.2566 records/second. Loss is 0.17676613. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043055196762249205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 6272/60000][Iteration 6615][Wall Clock 616.433684072s] Trained 128 records in 0.0773186 seconds. Throughput is 1655.4878 records/second. Loss is 0.19449314. Sequential31006cbd's hyper parameters: Current learning rate is 0.004305148958153952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:53 INFO  DistriOptimizer$:408 - [Epoch 15 6400/60000][Iteration 6616][Wall Clock 616.509109219s] Trained 128 records in 0.075425147 seconds. Throughput is 1697.0468 records/second. Loss is 0.16277333. Sequential31006cbd's hyper parameters: Current learning rate is 0.004304778303917348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 6528/60000][Iteration 6617][Wall Clock 616.602432928s] Trained 128 records in 0.093323709 seconds. Throughput is 1371.5701 records/second. Loss is 0.103607774. Sequential31006cbd's hyper parameters: Current learning rate is 0.004304407713498623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 6656/60000][Iteration 6618][Wall Clock 616.677619063s] Trained 128 records in 0.075186135 seconds. Throughput is 1702.4415 records/second. Loss is 0.19770339. Sequential31006cbd's hyper parameters: Current learning rate is 0.0043040371868812944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 6784/60000][Iteration 6619][Wall Clock 616.756945891s] Trained 128 records in 0.079326828 seconds. Throughput is 1613.5776 records/second. Loss is 0.20144147. Sequential31006cbd's hyper parameters: Current learning rate is 0.00430366672404889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 6912/60000][Iteration 6620][Wall Clock 616.835313544s] Trained 128 records in 0.078367653 seconds. Throughput is 1633.327 records/second. Loss is 0.15433279. Sequential31006cbd's hyper parameters: Current learning rate is 0.004303296324984938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7040/60000][Iteration 6621][Wall Clock 616.911962325s] Trained 128 records in 0.076648781 seconds. Throughput is 1669.9548 records/second. Loss is 0.13716379. Sequential31006cbd's hyper parameters: Current learning rate is 0.004302925989672978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7168/60000][Iteration 6622][Wall Clock 616.996701479s] Trained 128 records in 0.084739154 seconds. Throughput is 1510.5177 records/second. Loss is 0.2644578. Sequential31006cbd's hyper parameters: Current learning rate is 0.004302555718096549. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7296/60000][Iteration 6623][Wall Clock 617.079420481s] Trained 128 records in 0.082719002 seconds. Throughput is 1547.4073 records/second. Loss is 0.14334902. Sequential31006cbd's hyper parameters: Current learning rate is 0.004302185510239202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7424/60000][Iteration 6624][Wall Clock 617.159729466s] Trained 128 records in 0.080308985 seconds. Throughput is 1593.844 records/second. Loss is 0.1853492. Sequential31006cbd's hyper parameters: Current learning rate is 0.004301815366084487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7552/60000][Iteration 6625][Wall Clock 617.240124568s] Trained 128 records in 0.080395102 seconds. Throughput is 1592.1368 records/second. Loss is 0.1290124. Sequential31006cbd's hyper parameters: Current learning rate is 0.004301445285615968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7680/60000][Iteration 6626][Wall Clock 617.323096851s] Trained 128 records in 0.082972283 seconds. Throughput is 1542.6838 records/second. Loss is 0.11782372. Sequential31006cbd's hyper parameters: Current learning rate is 0.004301075268817204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7808/60000][Iteration 6627][Wall Clock 617.403711721s] Trained 128 records in 0.08061487 seconds. Throughput is 1587.7964 records/second. Loss is 0.13438049. Sequential31006cbd's hyper parameters: Current learning rate is 0.00430070531567177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:54 INFO  DistriOptimizer$:408 - [Epoch 15 7936/60000][Iteration 6628][Wall Clock 617.502618061s] Trained 128 records in 0.09890634 seconds. Throughput is 1294.1537 records/second. Loss is 0.19968764. Sequential31006cbd's hyper parameters: Current learning rate is 0.004300335426163241. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8064/60000][Iteration 6629][Wall Clock 617.60409583s] Trained 128 records in 0.101477769 seconds. Throughput is 1261.36 records/second. Loss is 0.19838533. Sequential31006cbd's hyper parameters: Current learning rate is 0.004299965600275198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8192/60000][Iteration 6630][Wall Clock 617.689551805s] Trained 128 records in 0.085455975 seconds. Throughput is 1497.8473 records/second. Loss is 0.1552606. Sequential31006cbd's hyper parameters: Current learning rate is 0.004299595837991229. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8320/60000][Iteration 6631][Wall Clock 617.763021208s] Trained 128 records in 0.073469403 seconds. Throughput is 1742.2219 records/second. Loss is 0.08123094. Sequential31006cbd's hyper parameters: Current learning rate is 0.004299226139294927. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8448/60000][Iteration 6632][Wall Clock 617.836475308s] Trained 128 records in 0.0734541 seconds. Throughput is 1742.5848 records/second. Loss is 0.20474601. Sequential31006cbd's hyper parameters: Current learning rate is 0.004298856504169891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8576/60000][Iteration 6633][Wall Clock 617.914032931s] Trained 128 records in 0.077557623 seconds. Throughput is 1650.3857 records/second. Loss is 0.20319507. Sequential31006cbd's hyper parameters: Current learning rate is 0.004298486932599725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8704/60000][Iteration 6634][Wall Clock 617.993432704s] Trained 128 records in 0.079399773 seconds. Throughput is 1612.0953 records/second. Loss is 0.18453634. Sequential31006cbd's hyper parameters: Current learning rate is 0.004298117424568039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8832/60000][Iteration 6635][Wall Clock 618.073518665s] Trained 128 records in 0.080085961 seconds. Throughput is 1598.2826 records/second. Loss is 0.16239396. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042977479800584495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 8960/60000][Iteration 6636][Wall Clock 618.155823282s] Trained 128 records in 0.082304617 seconds. Throughput is 1555.1982 records/second. Loss is 0.15534547. Sequential31006cbd's hyper parameters: Current learning rate is 0.004297378599054577. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 9088/60000][Iteration 6637][Wall Clock 618.237173303s] Trained 128 records in 0.081350021 seconds. Throughput is 1573.4476 records/second. Loss is 0.16327918. Sequential31006cbd's hyper parameters: Current learning rate is 0.004297009281540047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 9216/60000][Iteration 6638][Wall Clock 618.31498731s] Trained 128 records in 0.077814007 seconds. Throughput is 1644.9481 records/second. Loss is 0.29256597. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042966400274984965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 9344/60000][Iteration 6639][Wall Clock 618.392843691s] Trained 128 records in 0.077856381 seconds. Throughput is 1644.0527 records/second. Loss is 0.16580847. Sequential31006cbd's hyper parameters: Current learning rate is 0.004296270836913559. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:55 INFO  DistriOptimizer$:408 - [Epoch 15 9472/60000][Iteration 6640][Wall Clock 618.469979083s] Trained 128 records in 0.077135392 seconds. Throughput is 1659.4198 records/second. Loss is 0.1385898. Sequential31006cbd's hyper parameters: Current learning rate is 0.004295901709768881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 9600/60000][Iteration 6641][Wall Clock 618.548317431s] Trained 128 records in 0.078338348 seconds. Throughput is 1633.938 records/second. Loss is 0.17970699. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042955326460481094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 9728/60000][Iteration 6642][Wall Clock 618.629175777s] Trained 128 records in 0.080858346 seconds. Throughput is 1583.0154 records/second. Loss is 0.18000162. Sequential31006cbd's hyper parameters: Current learning rate is 0.004295163645734903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 9856/60000][Iteration 6643][Wall Clock 618.722760871s] Trained 128 records in 0.093585094 seconds. Throughput is 1367.7391 records/second. Loss is 0.2128611. Sequential31006cbd's hyper parameters: Current learning rate is 0.004294794708812918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 9984/60000][Iteration 6644][Wall Clock 618.81161011s] Trained 128 records in 0.088849239 seconds. Throughput is 1440.6426 records/second. Loss is 0.17554085. Sequential31006cbd's hyper parameters: Current learning rate is 0.004294425835265825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10112/60000][Iteration 6645][Wall Clock 618.894903739s] Trained 128 records in 0.083293629 seconds. Throughput is 1536.7322 records/second. Loss is 0.20704377. Sequential31006cbd's hyper parameters: Current learning rate is 0.004294057025077293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10240/60000][Iteration 6646][Wall Clock 618.978723178s] Trained 128 records in 0.083819439 seconds. Throughput is 1527.092 records/second. Loss is 0.16821463. Sequential31006cbd's hyper parameters: Current learning rate is 0.004293688278231001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10368/60000][Iteration 6647][Wall Clock 619.060921278s] Trained 128 records in 0.0821981 seconds. Throughput is 1557.2136 records/second. Loss is 0.2149074. Sequential31006cbd's hyper parameters: Current learning rate is 0.00429331959471063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10496/60000][Iteration 6648][Wall Clock 619.142205405s] Trained 128 records in 0.081284127 seconds. Throughput is 1574.7231 records/second. Loss is 0.12538972. Sequential31006cbd's hyper parameters: Current learning rate is 0.004292950974499871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10624/60000][Iteration 6649][Wall Clock 619.222158619s] Trained 128 records in 0.079953214 seconds. Throughput is 1600.9363 records/second. Loss is 0.23843542. Sequential31006cbd's hyper parameters: Current learning rate is 0.004292582417582417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10752/60000][Iteration 6650][Wall Clock 619.30681165s] Trained 128 records in 0.084653031 seconds. Throughput is 1512.0546 records/second. Loss is 0.074046165. Sequential31006cbd's hyper parameters: Current learning rate is 0.004292213923941969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 10880/60000][Iteration 6651][Wall Clock 619.398266298s] Trained 128 records in 0.091454648 seconds. Throughput is 1399.6008 records/second. Loss is 0.1657381. Sequential31006cbd's hyper parameters: Current learning rate is 0.004291845493562232. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:56 INFO  DistriOptimizer$:408 - [Epoch 15 11008/60000][Iteration 6652][Wall Clock 619.481190199s] Trained 128 records in 0.082923901 seconds. Throughput is 1543.5839 records/second. Loss is 0.13427016. Sequential31006cbd's hyper parameters: Current learning rate is 0.004291477126426916. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11136/60000][Iteration 6653][Wall Clock 619.567269466s] Trained 128 records in 0.086079267 seconds. Throughput is 1487.0015 records/second. Loss is 0.086731106. Sequential31006cbd's hyper parameters: Current learning rate is 0.004291108822519739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11264/60000][Iteration 6654][Wall Clock 619.652171564s] Trained 128 records in 0.084902098 seconds. Throughput is 1507.6188 records/second. Loss is 0.14888859. Sequential31006cbd's hyper parameters: Current learning rate is 0.004290740581824423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11392/60000][Iteration 6655][Wall Clock 619.751077067s] Trained 128 records in 0.098905503 seconds. Throughput is 1294.1646 records/second. Loss is 0.14975972. Sequential31006cbd's hyper parameters: Current learning rate is 0.004290372404324696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11520/60000][Iteration 6656][Wall Clock 619.841818483s] Trained 128 records in 0.090741416 seconds. Throughput is 1410.6017 records/second. Loss is 0.09604615. Sequential31006cbd's hyper parameters: Current learning rate is 0.004290004290004291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11648/60000][Iteration 6657][Wall Clock 619.928686211s] Trained 128 records in 0.086867728 seconds. Throughput is 1473.5046 records/second. Loss is 0.20691769. Sequential31006cbd's hyper parameters: Current learning rate is 0.004289636238846946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11776/60000][Iteration 6658][Wall Clock 620.014589112s] Trained 128 records in 0.085902901 seconds. Throughput is 1490.0544 records/second. Loss is 0.19249985. Sequential31006cbd's hyper parameters: Current learning rate is 0.004289268250836407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 11904/60000][Iteration 6659][Wall Clock 620.106201992s] Trained 128 records in 0.09161288 seconds. Throughput is 1397.1833 records/second. Loss is 0.22724655. Sequential31006cbd's hyper parameters: Current learning rate is 0.004288900325956425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 12032/60000][Iteration 6660][Wall Clock 620.186315256s] Trained 128 records in 0.080113264 seconds. Throughput is 1597.7379 records/second. Loss is 0.16095275. Sequential31006cbd's hyper parameters: Current learning rate is 0.004288532464190754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 12160/60000][Iteration 6661][Wall Clock 620.268689828s] Trained 128 records in 0.082374572 seconds. Throughput is 1553.8776 records/second. Loss is 0.17647943. Sequential31006cbd's hyper parameters: Current learning rate is 0.004288164665523156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 12288/60000][Iteration 6662][Wall Clock 620.345247235s] Trained 128 records in 0.076557407 seconds. Throughput is 1671.948 records/second. Loss is 0.17458153. Sequential31006cbd's hyper parameters: Current learning rate is 0.004287796929937398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 12416/60000][Iteration 6663][Wall Clock 620.429542992s] Trained 128 records in 0.084295757 seconds. Throughput is 1518.4631 records/second. Loss is 0.14037885. Sequential31006cbd's hyper parameters: Current learning rate is 0.004287429257417253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:57 INFO  DistriOptimizer$:408 - [Epoch 15 12544/60000][Iteration 6664][Wall Clock 620.507426281s] Trained 128 records in 0.077883289 seconds. Throughput is 1643.4847 records/second. Loss is 0.13414007. Sequential31006cbd's hyper parameters: Current learning rate is 0.004287061647946497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 12672/60000][Iteration 6665][Wall Clock 620.586022689s] Trained 128 records in 0.078596408 seconds. Throughput is 1628.5732 records/second. Loss is 0.0957598. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042866941015089165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 12800/60000][Iteration 6666][Wall Clock 620.665707422s] Trained 128 records in 0.079684733 seconds. Throughput is 1606.3302 records/second. Loss is 0.14757766. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042863266180882984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 12928/60000][Iteration 6667][Wall Clock 620.746233198s] Trained 128 records in 0.080525776 seconds. Throughput is 1589.5531 records/second. Loss is 0.15768582. Sequential31006cbd's hyper parameters: Current learning rate is 0.004285959197668438. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13056/60000][Iteration 6668][Wall Clock 620.821429647s] Trained 128 records in 0.075196449 seconds. Throughput is 1702.208 records/second. Loss is 0.22751786. Sequential31006cbd's hyper parameters: Current learning rate is 0.004285591840233136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13184/60000][Iteration 6669][Wall Clock 620.922940045s] Trained 128 records in 0.101510398 seconds. Throughput is 1260.9546 records/second. Loss is 0.20932901. Sequential31006cbd's hyper parameters: Current learning rate is 0.004285224545766198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13312/60000][Iteration 6670][Wall Clock 621.001558971s] Trained 128 records in 0.078618926 seconds. Throughput is 1628.1067 records/second. Loss is 0.12945555. Sequential31006cbd's hyper parameters: Current learning rate is 0.004284857314251435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13440/60000][Iteration 6671][Wall Clock 621.07999577s] Trained 128 records in 0.078436799 seconds. Throughput is 1631.8871 records/second. Loss is 0.1289729. Sequential31006cbd's hyper parameters: Current learning rate is 0.004284490145672665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13568/60000][Iteration 6672][Wall Clock 621.153529763s] Trained 128 records in 0.073533993 seconds. Throughput is 1740.6917 records/second. Loss is 0.14743797. Sequential31006cbd's hyper parameters: Current learning rate is 0.004284123040013709. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13696/60000][Iteration 6673][Wall Clock 621.226327424s] Trained 128 records in 0.072797661 seconds. Throughput is 1758.2982 records/second. Loss is 0.08905133. Sequential31006cbd's hyper parameters: Current learning rate is 0.004283755997258396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13824/60000][Iteration 6674][Wall Clock 621.304603658s] Trained 128 records in 0.078276234 seconds. Throughput is 1635.2346 records/second. Loss is 0.13626362. Sequential31006cbd's hyper parameters: Current learning rate is 0.00428338901739056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 13952/60000][Iteration 6675][Wall Clock 621.382663159s] Trained 128 records in 0.078059501 seconds. Throughput is 1639.7748 records/second. Loss is 0.16084099. Sequential31006cbd's hyper parameters: Current learning rate is 0.004283022100394038. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:58 INFO  DistriOptimizer$:408 - [Epoch 15 14080/60000][Iteration 6676][Wall Clock 621.461456456s] Trained 128 records in 0.078793297 seconds. Throughput is 1624.5037 records/second. Loss is 0.15952861. Sequential31006cbd's hyper parameters: Current learning rate is 0.004282655246252677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14208/60000][Iteration 6677][Wall Clock 621.552574267s] Trained 128 records in 0.091117811 seconds. Throughput is 1404.7747 records/second. Loss is 0.26179823. Sequential31006cbd's hyper parameters: Current learning rate is 0.004282288454950325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14336/60000][Iteration 6678][Wall Clock 621.632009455s] Trained 128 records in 0.079435188 seconds. Throughput is 1611.3766 records/second. Loss is 0.113968045. Sequential31006cbd's hyper parameters: Current learning rate is 0.00428192172647084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14464/60000][Iteration 6679][Wall Clock 621.712300151s] Trained 128 records in 0.080290696 seconds. Throughput is 1594.2072 records/second. Loss is 0.26479706. Sequential31006cbd's hyper parameters: Current learning rate is 0.004281555060798081. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14592/60000][Iteration 6680][Wall Clock 621.795847176s] Trained 128 records in 0.083547025 seconds. Throughput is 1532.0713 records/second. Loss is 0.26057684. Sequential31006cbd's hyper parameters: Current learning rate is 0.004281188457915918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14720/60000][Iteration 6681][Wall Clock 621.877563455s] Trained 128 records in 0.081716279 seconds. Throughput is 1566.3954 records/second. Loss is 0.28409895. Sequential31006cbd's hyper parameters: Current learning rate is 0.004280821917808219. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14848/60000][Iteration 6682][Wall Clock 621.949202984s] Trained 128 records in 0.071639529 seconds. Throughput is 1786.723 records/second. Loss is 0.1746173. Sequential31006cbd's hyper parameters: Current learning rate is 0.004280455440458865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 14976/60000][Iteration 6683][Wall Clock 622.032651153s] Trained 128 records in 0.083448169 seconds. Throughput is 1533.8862 records/second. Loss is 0.14819966. Sequential31006cbd's hyper parameters: Current learning rate is 0.004280089025851737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 15104/60000][Iteration 6684][Wall Clock 622.132682159s] Trained 128 records in 0.100031006 seconds. Throughput is 1279.6033 records/second. Loss is 0.22223693. Sequential31006cbd's hyper parameters: Current learning rate is 0.004279722673970727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 15232/60000][Iteration 6685][Wall Clock 622.213438689s] Trained 128 records in 0.08075653 seconds. Throughput is 1585.0111 records/second. Loss is 0.09620206. Sequential31006cbd's hyper parameters: Current learning rate is 0.004279356384799726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 15360/60000][Iteration 6686][Wall Clock 622.296622464s] Trained 128 records in 0.083183775 seconds. Throughput is 1538.7616 records/second. Loss is 0.1294589. Sequential31006cbd's hyper parameters: Current learning rate is 0.004278990158322636. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 15488/60000][Iteration 6687][Wall Clock 622.380476622s] Trained 128 records in 0.083854158 seconds. Throughput is 1526.4597 records/second. Loss is 0.25726053. Sequential31006cbd's hyper parameters: Current learning rate is 0.004278623994523361. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:07:59 INFO  DistriOptimizer$:408 - [Epoch 15 15616/60000][Iteration 6688][Wall Clock 622.460133959s] Trained 128 records in 0.079657337 seconds. Throughput is 1606.8827 records/second. Loss is 0.18497884. Sequential31006cbd's hyper parameters: Current learning rate is 0.004278257893385813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 15744/60000][Iteration 6689][Wall Clock 622.536434497s] Trained 128 records in 0.076300538 seconds. Throughput is 1677.5767 records/second. Loss is 0.12894124. Sequential31006cbd's hyper parameters: Current learning rate is 0.004277891854893908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 15872/60000][Iteration 6690][Wall Clock 622.61493074s] Trained 128 records in 0.078496243 seconds. Throughput is 1630.6514 records/second. Loss is 0.09536283. Sequential31006cbd's hyper parameters: Current learning rate is 0.004277525879031568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16000/60000][Iteration 6691][Wall Clock 622.711519099s] Trained 128 records in 0.096588359 seconds. Throughput is 1325.2114 records/second. Loss is 0.07721221. Sequential31006cbd's hyper parameters: Current learning rate is 0.00427715996578272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16128/60000][Iteration 6692][Wall Clock 622.794172495s] Trained 128 records in 0.082653396 seconds. Throughput is 1548.6357 records/second. Loss is 0.119161144. Sequential31006cbd's hyper parameters: Current learning rate is 0.004276794115131297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16256/60000][Iteration 6693][Wall Clock 622.879773428s] Trained 128 records in 0.085600933 seconds. Throughput is 1495.3108 records/second. Loss is 0.17991221. Sequential31006cbd's hyper parameters: Current learning rate is 0.004276428327061239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16384/60000][Iteration 6694][Wall Clock 622.978725985s] Trained 128 records in 0.098952557 seconds. Throughput is 1293.5492 records/second. Loss is 0.06703409. Sequential31006cbd's hyper parameters: Current learning rate is 0.004276062601556487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16512/60000][Iteration 6695][Wall Clock 623.061088625s] Trained 128 records in 0.08236264 seconds. Throughput is 1554.1028 records/second. Loss is 0.17479144. Sequential31006cbd's hyper parameters: Current learning rate is 0.004275696938600992. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16640/60000][Iteration 6696][Wall Clock 623.138821915s] Trained 128 records in 0.07773329 seconds. Throughput is 1646.6561 records/second. Loss is 0.12606037. Sequential31006cbd's hyper parameters: Current learning rate is 0.004275331338178709. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16768/60000][Iteration 6697][Wall Clock 623.221168176s] Trained 128 records in 0.082346261 seconds. Throughput is 1554.4119 records/second. Loss is 0.12771925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004274965800273598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 16896/60000][Iteration 6698][Wall Clock 623.299315439s] Trained 128 records in 0.078147263 seconds. Throughput is 1637.9332 records/second. Loss is 0.095759876. Sequential31006cbd's hyper parameters: Current learning rate is 0.004274600324869624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 17024/60000][Iteration 6699][Wall Clock 623.3861763s] Trained 128 records in 0.086860861 seconds. Throughput is 1473.6212 records/second. Loss is 0.32496142. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042742349119507615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:00 INFO  DistriOptimizer$:408 - [Epoch 15 17152/60000][Iteration 6700][Wall Clock 623.463214049s] Trained 128 records in 0.077037749 seconds. Throughput is 1661.5231 records/second. Loss is 0.1724681. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042738695615009824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 17280/60000][Iteration 6701][Wall Clock 623.536373859s] Trained 128 records in 0.07315981 seconds. Throughput is 1749.5946 records/second. Loss is 0.17019421. Sequential31006cbd's hyper parameters: Current learning rate is 0.004273504273504274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 17408/60000][Iteration 6702][Wall Clock 623.62022321s] Trained 128 records in 0.083849351 seconds. Throughput is 1526.5474 records/second. Loss is 0.14593834. Sequential31006cbd's hyper parameters: Current learning rate is 0.00427313904794462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 17536/60000][Iteration 6703][Wall Clock 623.700851893s] Trained 128 records in 0.080628683 seconds. Throughput is 1587.5243 records/second. Loss is 0.20986208. Sequential31006cbd's hyper parameters: Current learning rate is 0.004272773884806016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 17664/60000][Iteration 6704][Wall Clock 623.774768233s] Trained 128 records in 0.07391634 seconds. Throughput is 1731.6875 records/second. Loss is 0.18284374. Sequential31006cbd's hyper parameters: Current learning rate is 0.00427240878407246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 17792/60000][Iteration 6705][Wall Clock 623.851817307s] Trained 128 records in 0.077049074 seconds. Throughput is 1661.2788 records/second. Loss is 0.109657556. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042720437457279565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 17920/60000][Iteration 6706][Wall Clock 623.932523281s] Trained 128 records in 0.080705974 seconds. Throughput is 1586.0042 records/second. Loss is 0.14658228. Sequential31006cbd's hyper parameters: Current learning rate is 0.004271678769756514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18048/60000][Iteration 6707][Wall Clock 624.005597893s] Trained 128 records in 0.073074612 seconds. Throughput is 1751.6344 records/second. Loss is 0.14551032. Sequential31006cbd's hyper parameters: Current learning rate is 0.004271313856142149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18176/60000][Iteration 6708][Wall Clock 624.088166092s] Trained 128 records in 0.082568199 seconds. Throughput is 1550.2336 records/second. Loss is 0.14042985. Sequential31006cbd's hyper parameters: Current learning rate is 0.004270949004868882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18304/60000][Iteration 6709][Wall Clock 624.169508664s] Trained 128 records in 0.081342572 seconds. Throughput is 1573.5918 records/second. Loss is 0.23089616. Sequential31006cbd's hyper parameters: Current learning rate is 0.004270584215920738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18432/60000][Iteration 6710][Wall Clock 624.24637489s] Trained 128 records in 0.076866226 seconds. Throughput is 1665.2307 records/second. Loss is 0.13836843. Sequential31006cbd's hyper parameters: Current learning rate is 0.004270219489281749. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18560/60000][Iteration 6711][Wall Clock 624.322883341s] Trained 128 records in 0.076508451 seconds. Throughput is 1673.0178 records/second. Loss is 0.14763406. Sequential31006cbd's hyper parameters: Current learning rate is 0.004269854824935952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18688/60000][Iteration 6712][Wall Clock 624.397295587s] Trained 128 records in 0.074412246 seconds. Throughput is 1720.1469 records/second. Loss is 0.11682598. Sequential31006cbd's hyper parameters: Current learning rate is 0.004269490222867389. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:01 INFO  DistriOptimizer$:408 - [Epoch 15 18816/60000][Iteration 6713][Wall Clock 624.480319914s] Trained 128 records in 0.083024327 seconds. Throughput is 1541.7168 records/second. Loss is 0.21801409. Sequential31006cbd's hyper parameters: Current learning rate is 0.00426912568306011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 18944/60000][Iteration 6714][Wall Clock 624.561141706s] Trained 128 records in 0.080821792 seconds. Throughput is 1583.7313 records/second. Loss is 0.14689994. Sequential31006cbd's hyper parameters: Current learning rate is 0.004268761205498165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19072/60000][Iteration 6715][Wall Clock 624.641372218s] Trained 128 records in 0.080230512 seconds. Throughput is 1595.403 records/second. Loss is 0.29146516. Sequential31006cbd's hyper parameters: Current learning rate is 0.004268396790165614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19200/60000][Iteration 6716][Wall Clock 624.715399509s] Trained 128 records in 0.074027291 seconds. Throughput is 1729.092 records/second. Loss is 0.2627335. Sequential31006cbd's hyper parameters: Current learning rate is 0.004268032437046522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19328/60000][Iteration 6717][Wall Clock 624.791327043s] Trained 128 records in 0.075927534 seconds. Throughput is 1685.818 records/second. Loss is 0.15268475. Sequential31006cbd's hyper parameters: Current learning rate is 0.004267668146124956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19456/60000][Iteration 6718][Wall Clock 624.871158167s] Trained 128 records in 0.079831124 seconds. Throughput is 1603.3846 records/second. Loss is 0.150718. Sequential31006cbd's hyper parameters: Current learning rate is 0.004267303917384996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19584/60000][Iteration 6719][Wall Clock 624.948369901s] Trained 128 records in 0.077211734 seconds. Throughput is 1657.779 records/second. Loss is 0.086159244. Sequential31006cbd's hyper parameters: Current learning rate is 0.004266939750810718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19712/60000][Iteration 6720][Wall Clock 625.040597254s] Trained 128 records in 0.092227353 seconds. Throughput is 1387.8745 records/second. Loss is 0.14236301. Sequential31006cbd's hyper parameters: Current learning rate is 0.004266575646386211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19840/60000][Iteration 6721][Wall Clock 625.13835315s] Trained 128 records in 0.097755896 seconds. Throughput is 1309.3839 records/second. Loss is 0.1396133. Sequential31006cbd's hyper parameters: Current learning rate is 0.004266211604095562. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 19968/60000][Iteration 6722][Wall Clock 625.225008776s] Trained 128 records in 0.086655626 seconds. Throughput is 1477.1113 records/second. Loss is 0.19014272. Sequential31006cbd's hyper parameters: Current learning rate is 0.004265847623922874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 20096/60000][Iteration 6723][Wall Clock 625.315651375s] Trained 128 records in 0.090642599 seconds. Throughput is 1412.1395 records/second. Loss is 0.17478123. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042654837058522434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 20224/60000][Iteration 6724][Wall Clock 625.406163786s] Trained 128 records in 0.090512411 seconds. Throughput is 1414.1708 records/second. Loss is 0.14482044. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042651198498677816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:02 INFO  DistriOptimizer$:408 - [Epoch 15 20352/60000][Iteration 6725][Wall Clock 625.487176967s] Trained 128 records in 0.081013181 seconds. Throughput is 1579.9899 records/second. Loss is 0.15450588. Sequential31006cbd's hyper parameters: Current learning rate is 0.004264756055953599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 20480/60000][Iteration 6726][Wall Clock 625.568058646s] Trained 128 records in 0.080881679 seconds. Throughput is 1582.5587 records/second. Loss is 0.24368021. Sequential31006cbd's hyper parameters: Current learning rate is 0.004264392324093817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 20608/60000][Iteration 6727][Wall Clock 625.642927506s] Trained 128 records in 0.07486886 seconds. Throughput is 1709.6561 records/second. Loss is 0.08624962. Sequential31006cbd's hyper parameters: Current learning rate is 0.004264028654272557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 20736/60000][Iteration 6728][Wall Clock 625.725865223s] Trained 128 records in 0.082937717 seconds. Throughput is 1543.3268 records/second. Loss is 0.18193403. Sequential31006cbd's hyper parameters: Current learning rate is 0.004263665046473949. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 20864/60000][Iteration 6729][Wall Clock 625.802372094s] Trained 128 records in 0.076506871 seconds. Throughput is 1673.0524 records/second. Loss is 0.18836269. Sequential31006cbd's hyper parameters: Current learning rate is 0.004263301500682128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 20992/60000][Iteration 6730][Wall Clock 625.889537394s] Trained 128 records in 0.0871653 seconds. Throughput is 1468.4742 records/second. Loss is 0.20141551. Sequential31006cbd's hyper parameters: Current learning rate is 0.004262938016881234. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21120/60000][Iteration 6731][Wall Clock 625.969876802s] Trained 128 records in 0.080339408 seconds. Throughput is 1593.2405 records/second. Loss is 0.13953261. Sequential31006cbd's hyper parameters: Current learning rate is 0.004262574595055414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21248/60000][Iteration 6732][Wall Clock 626.048762155s] Trained 128 records in 0.078885353 seconds. Throughput is 1622.6079 records/second. Loss is 0.069892794. Sequential31006cbd's hyper parameters: Current learning rate is 0.004262211235188816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21376/60000][Iteration 6733][Wall Clock 626.128254668s] Trained 128 records in 0.079492513 seconds. Throughput is 1610.2146 records/second. Loss is 0.121444896. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042618479372655985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21504/60000][Iteration 6734][Wall Clock 626.210558509s] Trained 128 records in 0.082303841 seconds. Throughput is 1555.2129 records/second. Loss is 0.1335213. Sequential31006cbd's hyper parameters: Current learning rate is 0.004261484701269923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21632/60000][Iteration 6735][Wall Clock 626.309142355s] Trained 128 records in 0.098583846 seconds. Throughput is 1298.3871 records/second. Loss is 0.1434149. Sequential31006cbd's hyper parameters: Current learning rate is 0.004261121527185955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21760/60000][Iteration 6736][Wall Clock 626.395256674s] Trained 128 records in 0.086114319 seconds. Throughput is 1486.3962 records/second. Loss is 0.2435828. Sequential31006cbd's hyper parameters: Current learning rate is 0.00426075841499787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:03 INFO  DistriOptimizer$:408 - [Epoch 15 21888/60000][Iteration 6737][Wall Clock 626.472902104s] Trained 128 records in 0.07764543 seconds. Throughput is 1648.5194 records/second. Loss is 0.20821714. Sequential31006cbd's hyper parameters: Current learning rate is 0.004260395364689844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22016/60000][Iteration 6738][Wall Clock 626.550697548s] Trained 128 records in 0.077795444 seconds. Throughput is 1645.3406 records/second. Loss is 0.113721594. Sequential31006cbd's hyper parameters: Current learning rate is 0.004260032376246059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22144/60000][Iteration 6739][Wall Clock 626.625244634s] Trained 128 records in 0.074547086 seconds. Throughput is 1717.0355 records/second. Loss is 0.12998137. Sequential31006cbd's hyper parameters: Current learning rate is 0.004259669449650707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22272/60000][Iteration 6740][Wall Clock 626.705410671s] Trained 128 records in 0.080166037 seconds. Throughput is 1596.6862 records/second. Loss is 0.14559896. Sequential31006cbd's hyper parameters: Current learning rate is 0.00425930658488798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22400/60000][Iteration 6741][Wall Clock 626.783698893s] Trained 128 records in 0.078288222 seconds. Throughput is 1634.9841 records/second. Loss is 0.1678967. Sequential31006cbd's hyper parameters: Current learning rate is 0.004258943781942079. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22528/60000][Iteration 6742][Wall Clock 626.866842125s] Trained 128 records in 0.083143232 seconds. Throughput is 1539.512 records/second. Loss is 0.1921697. Sequential31006cbd's hyper parameters: Current learning rate is 0.004258581040797206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22656/60000][Iteration 6743][Wall Clock 626.952859078s] Trained 128 records in 0.086016953 seconds. Throughput is 1488.0787 records/second. Loss is 0.17179994. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042582183614375746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22784/60000][Iteration 6744][Wall Clock 627.033117243s] Trained 128 records in 0.080258165 seconds. Throughput is 1594.8533 records/second. Loss is 0.10579063. Sequential31006cbd's hyper parameters: Current learning rate is 0.004257855743847398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 22912/60000][Iteration 6745][Wall Clock 627.107781899s] Trained 128 records in 0.074664656 seconds. Throughput is 1714.3319 records/second. Loss is 0.20364201. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042574931880109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 23040/60000][Iteration 6746][Wall Clock 627.20478256s] Trained 128 records in 0.097000661 seconds. Throughput is 1319.5786 records/second. Loss is 0.07722004. Sequential31006cbd's hyper parameters: Current learning rate is 0.004257130693912303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 23168/60000][Iteration 6747][Wall Clock 627.28030697s] Trained 128 records in 0.07552441 seconds. Throughput is 1694.8163 records/second. Loss is 0.1416503. Sequential31006cbd's hyper parameters: Current learning rate is 0.004256768261535843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 23296/60000][Iteration 6748][Wall Clock 627.357794108s] Trained 128 records in 0.077487138 seconds. Throughput is 1651.887 records/second. Loss is 0.14329281. Sequential31006cbd's hyper parameters: Current learning rate is 0.004256405890865753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:04 INFO  DistriOptimizer$:408 - [Epoch 15 23424/60000][Iteration 6749][Wall Clock 627.440212173s] Trained 128 records in 0.082418065 seconds. Throughput is 1553.0576 records/second. Loss is 0.24838756. Sequential31006cbd's hyper parameters: Current learning rate is 0.004256043581886278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 23552/60000][Iteration 6750][Wall Clock 627.5225316s] Trained 128 records in 0.082319427 seconds. Throughput is 1554.9186 records/second. Loss is 0.15778089. Sequential31006cbd's hyper parameters: Current learning rate is 0.004255681334581666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 23680/60000][Iteration 6751][Wall Clock 627.601498988s] Trained 128 records in 0.078967388 seconds. Throughput is 1620.9224 records/second. Loss is 0.22386612. Sequential31006cbd's hyper parameters: Current learning rate is 0.00425531914893617. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 23808/60000][Iteration 6752][Wall Clock 627.682237033s] Trained 128 records in 0.080738045 seconds. Throughput is 1585.374 records/second. Loss is 0.1367129. Sequential31006cbd's hyper parameters: Current learning rate is 0.004254957024934048. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 23936/60000][Iteration 6753][Wall Clock 627.761292852s] Trained 128 records in 0.079055819 seconds. Throughput is 1619.1093 records/second. Loss is 0.19377917. Sequential31006cbd's hyper parameters: Current learning rate is 0.004254594962559565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24064/60000][Iteration 6754][Wall Clock 627.857441791s] Trained 128 records in 0.096148939 seconds. Throughput is 1331.268 records/second. Loss is 0.13895336. Sequential31006cbd's hyper parameters: Current learning rate is 0.004254232961796988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24192/60000][Iteration 6755][Wall Clock 627.947493952s] Trained 128 records in 0.090052161 seconds. Throughput is 1421.3984 records/second. Loss is 0.20948386. Sequential31006cbd's hyper parameters: Current learning rate is 0.004253871022630594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24320/60000][Iteration 6756][Wall Clock 628.030988947s] Trained 128 records in 0.083494995 seconds. Throughput is 1533.026 records/second. Loss is 0.15742166. Sequential31006cbd's hyper parameters: Current learning rate is 0.004253509145044662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24448/60000][Iteration 6757][Wall Clock 628.110035024s] Trained 128 records in 0.079046077 seconds. Throughput is 1619.3087 records/second. Loss is 0.17132589. Sequential31006cbd's hyper parameters: Current learning rate is 0.004253147329023477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24576/60000][Iteration 6758][Wall Clock 628.189224645s] Trained 128 records in 0.079189621 seconds. Throughput is 1616.3734 records/second. Loss is 0.23458916. Sequential31006cbd's hyper parameters: Current learning rate is 0.004252785574551331. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24704/60000][Iteration 6759][Wall Clock 628.273938922s] Trained 128 records in 0.084714277 seconds. Throughput is 1510.9613 records/second. Loss is 0.20916179. Sequential31006cbd's hyper parameters: Current learning rate is 0.004252423881612518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24832/60000][Iteration 6760][Wall Clock 628.349606583s] Trained 128 records in 0.075667661 seconds. Throughput is 1691.6077 records/second. Loss is 0.13613799. Sequential31006cbd's hyper parameters: Current learning rate is 0.004252062250191343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:05 INFO  DistriOptimizer$:408 - [Epoch 15 24960/60000][Iteration 6761][Wall Clock 628.423744556s] Trained 128 records in 0.074137973 seconds. Throughput is 1726.5107 records/second. Loss is 0.16746968. Sequential31006cbd's hyper parameters: Current learning rate is 0.004251700680272108. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25088/60000][Iteration 6762][Wall Clock 628.4948909s] Trained 128 records in 0.071146344 seconds. Throughput is 1799.1085 records/second. Loss is 0.14621355. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042513391718391295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25216/60000][Iteration 6763][Wall Clock 628.570251712s] Trained 128 records in 0.075360812 seconds. Throughput is 1698.4955 records/second. Loss is 0.10923387. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042509777248767215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25344/60000][Iteration 6764][Wall Clock 628.646099808s] Trained 128 records in 0.075848096 seconds. Throughput is 1687.5836 records/second. Loss is 0.10316448. Sequential31006cbd's hyper parameters: Current learning rate is 0.004250616339369209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25472/60000][Iteration 6765][Wall Clock 628.721328428s] Trained 128 records in 0.07522862 seconds. Throughput is 1701.4802 records/second. Loss is 0.23748283. Sequential31006cbd's hyper parameters: Current learning rate is 0.004250255015300917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25600/60000][Iteration 6766][Wall Clock 628.797465569s] Trained 128 records in 0.076137141 seconds. Throughput is 1681.1769 records/second. Loss is 0.19936182. Sequential31006cbd's hyper parameters: Current learning rate is 0.004249893752656184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25728/60000][Iteration 6767][Wall Clock 628.872639169s] Trained 128 records in 0.0751736 seconds. Throughput is 1702.7253 records/second. Loss is 0.17616515. Sequential31006cbd's hyper parameters: Current learning rate is 0.004249532551419344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25856/60000][Iteration 6768][Wall Clock 628.949508452s] Trained 128 records in 0.076869283 seconds. Throughput is 1665.1644 records/second. Loss is 0.28921542. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042491714115747425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 25984/60000][Iteration 6769][Wall Clock 629.031776456s] Trained 128 records in 0.082268004 seconds. Throughput is 1555.8904 records/second. Loss is 0.13493843. Sequential31006cbd's hyper parameters: Current learning rate is 0.00424881033310673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 26112/60000][Iteration 6770][Wall Clock 629.109789357s] Trained 128 records in 0.078012901 seconds. Throughput is 1640.7543 records/second. Loss is 0.25474402. Sequential31006cbd's hyper parameters: Current learning rate is 0.00424844931599966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 26240/60000][Iteration 6771][Wall Clock 629.204007331s] Trained 128 records in 0.094217974 seconds. Throughput is 1358.5519 records/second. Loss is 0.10404001. Sequential31006cbd's hyper parameters: Current learning rate is 0.004248088360237893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 26368/60000][Iteration 6772][Wall Clock 629.283482821s] Trained 128 records in 0.07947549 seconds. Throughput is 1610.5593 records/second. Loss is 0.099518865. Sequential31006cbd's hyper parameters: Current learning rate is 0.004247727465805794. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 26496/60000][Iteration 6773][Wall Clock 629.366066614s] Trained 128 records in 0.082583793 seconds. Throughput is 1549.9409 records/second. Loss is 0.09559323. Sequential31006cbd's hyper parameters: Current learning rate is 0.004247366632687734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:06 INFO  DistriOptimizer$:408 - [Epoch 15 26624/60000][Iteration 6774][Wall Clock 629.443561317s] Trained 128 records in 0.077494703 seconds. Throughput is 1651.7258 records/second. Loss is 0.1740858. Sequential31006cbd's hyper parameters: Current learning rate is 0.004247005860868088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 26752/60000][Iteration 6775][Wall Clock 629.529581872s] Trained 128 records in 0.086020555 seconds. Throughput is 1488.0165 records/second. Loss is 0.17972967. Sequential31006cbd's hyper parameters: Current learning rate is 0.004246645150331238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 26880/60000][Iteration 6776][Wall Clock 629.606312513s] Trained 128 records in 0.076730641 seconds. Throughput is 1668.1732 records/second. Loss is 0.121494114. Sequential31006cbd's hyper parameters: Current learning rate is 0.004246284501061571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27008/60000][Iteration 6777][Wall Clock 629.684436026s] Trained 128 records in 0.078123513 seconds. Throughput is 1638.4313 records/second. Loss is 0.16812736. Sequential31006cbd's hyper parameters: Current learning rate is 0.004245923913043478. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27136/60000][Iteration 6778][Wall Clock 629.760354813s] Trained 128 records in 0.075918787 seconds. Throughput is 1686.0122 records/second. Loss is 0.34968418. Sequential31006cbd's hyper parameters: Current learning rate is 0.004245563386261356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27264/60000][Iteration 6779][Wall Clock 629.851424419s] Trained 128 records in 0.091069606 seconds. Throughput is 1405.5183 records/second. Loss is 0.16960818. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042452029206996094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27392/60000][Iteration 6780][Wall Clock 629.92765702s] Trained 128 records in 0.076232601 seconds. Throughput is 1679.0715 records/second. Loss is 0.15105143. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042448425163426435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27520/60000][Iteration 6781][Wall Clock 630.010359238s] Trained 128 records in 0.082702218 seconds. Throughput is 1547.7214 records/second. Loss is 0.24147174. Sequential31006cbd's hyper parameters: Current learning rate is 0.004244482173174873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27648/60000][Iteration 6782][Wall Clock 630.093957616s] Trained 128 records in 0.083598378 seconds. Throughput is 1531.1302 records/second. Loss is 0.09686963. Sequential31006cbd's hyper parameters: Current learning rate is 0.004244121891180714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27776/60000][Iteration 6783][Wall Clock 630.169414798s] Trained 128 records in 0.075457182 seconds. Throughput is 1696.3262 records/second. Loss is 0.21013615. Sequential31006cbd's hyper parameters: Current learning rate is 0.004243761670344594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 27904/60000][Iteration 6784][Wall Clock 630.246253937s] Trained 128 records in 0.076839139 seconds. Throughput is 1665.8176 records/second. Loss is 0.23231576. Sequential31006cbd's hyper parameters: Current learning rate is 0.004243401510650937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 28032/60000][Iteration 6785][Wall Clock 630.323949214s] Trained 128 records in 0.077695277 seconds. Throughput is 1647.4617 records/second. Loss is 0.13846931. Sequential31006cbd's hyper parameters: Current learning rate is 0.004243041412084182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 28160/60000][Iteration 6786][Wall Clock 630.399391222s] Trained 128 records in 0.075442008 seconds. Throughput is 1696.6675 records/second. Loss is 0.14956595. Sequential31006cbd's hyper parameters: Current learning rate is 0.004242681374628765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:07 INFO  DistriOptimizer$:408 - [Epoch 15 28288/60000][Iteration 6787][Wall Clock 630.474380929s] Trained 128 records in 0.074989707 seconds. Throughput is 1706.9009 records/second. Loss is 0.2775622. Sequential31006cbd's hyper parameters: Current learning rate is 0.004242321398269133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 28416/60000][Iteration 6788][Wall Clock 630.564804746s] Trained 128 records in 0.090423817 seconds. Throughput is 1415.5563 records/second. Loss is 0.1590875. Sequential31006cbd's hyper parameters: Current learning rate is 0.004241961482989734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 28544/60000][Iteration 6789][Wall Clock 630.658724603s] Trained 128 records in 0.093919857 seconds. Throughput is 1362.864 records/second. Loss is 0.16750273. Sequential31006cbd's hyper parameters: Current learning rate is 0.004241601628775025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 28672/60000][Iteration 6790][Wall Clock 630.735290887s] Trained 128 records in 0.076566284 seconds. Throughput is 1671.754 records/second. Loss is 0.16462436. Sequential31006cbd's hyper parameters: Current learning rate is 0.004241241835609466. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 28800/60000][Iteration 6791][Wall Clock 630.813984994s] Trained 128 records in 0.078694107 seconds. Throughput is 1626.5513 records/second. Loss is 0.16576208. Sequential31006cbd's hyper parameters: Current learning rate is 0.004240882103477523. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 28928/60000][Iteration 6792][Wall Clock 630.895486166s] Trained 128 records in 0.081501172 seconds. Throughput is 1570.5295 records/second. Loss is 0.2407692. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042405224323636675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 29056/60000][Iteration 6793][Wall Clock 630.982204598s] Trained 128 records in 0.086718432 seconds. Throughput is 1476.0414 records/second. Loss is 0.15051015. Sequential31006cbd's hyper parameters: Current learning rate is 0.004240162822252374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 29184/60000][Iteration 6794][Wall Clock 631.067739066s] Trained 128 records in 0.085534468 seconds. Throughput is 1496.4728 records/second. Loss is 0.23576975. Sequential31006cbd's hyper parameters: Current learning rate is 0.004239803273128127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 29312/60000][Iteration 6795][Wall Clock 631.147338922s] Trained 128 records in 0.079599856 seconds. Throughput is 1608.0431 records/second. Loss is 0.2117954. Sequential31006cbd's hyper parameters: Current learning rate is 0.004239443784975411. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 29440/60000][Iteration 6796][Wall Clock 631.220114749s] Trained 128 records in 0.072775827 seconds. Throughput is 1758.8258 records/second. Loss is 0.1679532. Sequential31006cbd's hyper parameters: Current learning rate is 0.00423908435777872. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 29568/60000][Iteration 6797][Wall Clock 631.307417595s] Trained 128 records in 0.087302846 seconds. Throughput is 1466.1606 records/second. Loss is 0.09694594. Sequential31006cbd's hyper parameters: Current learning rate is 0.00423872499152255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:08 INFO  DistriOptimizer$:408 - [Epoch 15 29696/60000][Iteration 6798][Wall Clock 631.395787433s] Trained 128 records in 0.088369838 seconds. Throughput is 1448.458 records/second. Loss is 0.24141087. Sequential31006cbd's hyper parameters: Current learning rate is 0.004238365686191405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 29824/60000][Iteration 6799][Wall Clock 631.487887959s] Trained 128 records in 0.092100526 seconds. Throughput is 1389.7858 records/second. Loss is 0.16061193. Sequential31006cbd's hyper parameters: Current learning rate is 0.004238006441769791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 29952/60000][Iteration 6800][Wall Clock 631.569704832s] Trained 128 records in 0.081816873 seconds. Throughput is 1564.4695 records/second. Loss is 0.18353902. Sequential31006cbd's hyper parameters: Current learning rate is 0.004237647258242224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30080/60000][Iteration 6801][Wall Clock 631.652187675s] Trained 128 records in 0.082482843 seconds. Throughput is 1551.8379 records/second. Loss is 0.17294648. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042372881355932195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30208/60000][Iteration 6802][Wall Clock 631.731945106s] Trained 128 records in 0.079757431 seconds. Throughput is 1604.8662 records/second. Loss is 0.12503767. Sequential31006cbd's hyper parameters: Current learning rate is 0.004236929073807304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30336/60000][Iteration 6803][Wall Clock 631.814229299s] Trained 128 records in 0.082284193 seconds. Throughput is 1555.5844 records/second. Loss is 0.11810599. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042365700728690045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30464/60000][Iteration 6804][Wall Clock 631.893421952s] Trained 128 records in 0.079192653 seconds. Throughput is 1616.3115 records/second. Loss is 0.14122245. Sequential31006cbd's hyper parameters: Current learning rate is 0.004236211132762857. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30592/60000][Iteration 6805][Wall Clock 631.983325183s] Trained 128 records in 0.089903231 seconds. Throughput is 1423.753 records/second. Loss is 0.10421498. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042358522534733985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30720/60000][Iteration 6806][Wall Clock 632.077086099s] Trained 128 records in 0.093760916 seconds. Throughput is 1365.1744 records/second. Loss is 0.18028198. Sequential31006cbd's hyper parameters: Current learning rate is 0.004235493434985176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30848/60000][Iteration 6807][Wall Clock 632.154496562s] Trained 128 records in 0.077410463 seconds. Throughput is 1653.5233 records/second. Loss is 0.10495503. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042351346772827375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 30976/60000][Iteration 6808][Wall Clock 632.227863126s] Trained 128 records in 0.073366564 seconds. Throughput is 1744.6638 records/second. Loss is 0.13073933. Sequential31006cbd's hyper parameters: Current learning rate is 0.004234775980350639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 31104/60000][Iteration 6809][Wall Clock 632.299633988s] Trained 128 records in 0.071770862 seconds. Throughput is 1783.4536 records/second. Loss is 0.21658345. Sequential31006cbd's hyper parameters: Current learning rate is 0.004234417344173441. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 31232/60000][Iteration 6810][Wall Clock 632.375814604s] Trained 128 records in 0.076180616 seconds. Throughput is 1680.2175 records/second. Loss is 0.11698185. Sequential31006cbd's hyper parameters: Current learning rate is 0.00423405876873571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:09 INFO  DistriOptimizer$:408 - [Epoch 15 31360/60000][Iteration 6811][Wall Clock 632.453114428s] Trained 128 records in 0.077299824 seconds. Throughput is 1655.8899 records/second. Loss is 0.21711996. Sequential31006cbd's hyper parameters: Current learning rate is 0.004233700254022015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 31488/60000][Iteration 6812][Wall Clock 632.527804751s] Trained 128 records in 0.074690323 seconds. Throughput is 1713.7428 records/second. Loss is 0.21309209. Sequential31006cbd's hyper parameters: Current learning rate is 0.004233341800016934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 31616/60000][Iteration 6813][Wall Clock 632.602531471s] Trained 128 records in 0.07472672 seconds. Throughput is 1712.908 records/second. Loss is 0.15491185. Sequential31006cbd's hyper parameters: Current learning rate is 0.004232983406705046. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 31744/60000][Iteration 6814][Wall Clock 632.681425403s] Trained 128 records in 0.078893932 seconds. Throughput is 1622.4315 records/second. Loss is 0.106423035. Sequential31006cbd's hyper parameters: Current learning rate is 0.004232625074070939. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 31872/60000][Iteration 6815][Wall Clock 632.755187676s] Trained 128 records in 0.073762273 seconds. Throughput is 1735.3044 records/second. Loss is 0.19742003. Sequential31006cbd's hyper parameters: Current learning rate is 0.004232266802099204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32000/60000][Iteration 6816][Wall Clock 632.828762554s] Trained 128 records in 0.073574878 seconds. Throughput is 1739.7242 records/second. Loss is 0.2586764. Sequential31006cbd's hyper parameters: Current learning rate is 0.004231908590774439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32128/60000][Iteration 6817][Wall Clock 632.905377805s] Trained 128 records in 0.076615251 seconds. Throughput is 1670.6857 records/second. Loss is 0.12486136. Sequential31006cbd's hyper parameters: Current learning rate is 0.004231550440081246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32256/60000][Iteration 6818][Wall Clock 632.986333973s] Trained 128 records in 0.080956168 seconds. Throughput is 1581.1025 records/second. Loss is 0.10542061. Sequential31006cbd's hyper parameters: Current learning rate is 0.00423119235000423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32384/60000][Iteration 6819][Wall Clock 633.069384599s] Trained 128 records in 0.083050626 seconds. Throughput is 1541.2286 records/second. Loss is 0.12909691. Sequential31006cbd's hyper parameters: Current learning rate is 0.004230834320528008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32512/60000][Iteration 6820][Wall Clock 633.149509026s] Trained 128 records in 0.080124427 seconds. Throughput is 1597.5153 records/second. Loss is 0.25566432. Sequential31006cbd's hyper parameters: Current learning rate is 0.004230476351637194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32640/60000][Iteration 6821][Wall Clock 633.23248174s] Trained 128 records in 0.082972714 seconds. Throughput is 1542.6759 records/second. Loss is 0.18454343. Sequential31006cbd's hyper parameters: Current learning rate is 0.004230118443316413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32768/60000][Iteration 6822][Wall Clock 633.324161919s] Trained 128 records in 0.091680179 seconds. Throughput is 1396.1578 records/second. Loss is 0.12312839. Sequential31006cbd's hyper parameters: Current learning rate is 0.004229760595550291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:10 INFO  DistriOptimizer$:408 - [Epoch 15 32896/60000][Iteration 6823][Wall Clock 633.397971305s] Trained 128 records in 0.073809386 seconds. Throughput is 1734.1968 records/second. Loss is 0.16699862. Sequential31006cbd's hyper parameters: Current learning rate is 0.004229402808323465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33024/60000][Iteration 6824][Wall Clock 633.48733675s] Trained 128 records in 0.089365445 seconds. Throughput is 1432.3209 records/second. Loss is 0.1011973. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042290450816205695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33152/60000][Iteration 6825][Wall Clock 633.570033824s] Trained 128 records in 0.082697074 seconds. Throughput is 1547.8179 records/second. Loss is 0.3119281. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042286874154262525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33280/60000][Iteration 6826][Wall Clock 633.653208641s] Trained 128 records in 0.083174817 seconds. Throughput is 1538.9274 records/second. Loss is 0.17701815. Sequential31006cbd's hyper parameters: Current learning rate is 0.004228329809725158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33408/60000][Iteration 6827][Wall Clock 633.741129602s] Trained 128 records in 0.087920961 seconds. Throughput is 1455.853 records/second. Loss is 0.25822753. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042279722645019455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33536/60000][Iteration 6828][Wall Clock 633.818045149s] Trained 128 records in 0.076915547 seconds. Throughput is 1664.1628 records/second. Loss is 0.1516844. Sequential31006cbd's hyper parameters: Current learning rate is 0.00422761477974127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33664/60000][Iteration 6829][Wall Clock 633.902562396s] Trained 128 records in 0.084517247 seconds. Throughput is 1514.4838 records/second. Loss is 0.12734354. Sequential31006cbd's hyper parameters: Current learning rate is 0.004227257355427798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33792/60000][Iteration 6830][Wall Clock 634.00625138s] Trained 128 records in 0.103688984 seconds. Throughput is 1234.4609 records/second. Loss is 0.1580572. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042268999915462. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 33920/60000][Iteration 6831][Wall Clock 634.080039125s] Trained 128 records in 0.073787745 seconds. Throughput is 1734.7054 records/second. Loss is 0.21740851. Sequential31006cbd's hyper parameters: Current learning rate is 0.004226542688081149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 34048/60000][Iteration 6832][Wall Clock 634.157051308s] Trained 128 records in 0.077012183 seconds. Throughput is 1662.0747 records/second. Loss is 0.11803622. Sequential31006cbd's hyper parameters: Current learning rate is 0.004226185445017327. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 34176/60000][Iteration 6833][Wall Clock 634.234259679s] Trained 128 records in 0.077208371 seconds. Throughput is 1657.8513 records/second. Loss is 0.0987668. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042258282623394185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 34304/60000][Iteration 6834][Wall Clock 634.319382265s] Trained 128 records in 0.085122586 seconds. Throughput is 1503.7137 records/second. Loss is 0.15329032. Sequential31006cbd's hyper parameters: Current learning rate is 0.004225471140032113. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:11 INFO  DistriOptimizer$:408 - [Epoch 15 34432/60000][Iteration 6835][Wall Clock 634.40092986s] Trained 128 records in 0.081547595 seconds. Throughput is 1569.6355 records/second. Loss is 0.1670135. Sequential31006cbd's hyper parameters: Current learning rate is 0.004225114078080109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 34560/60000][Iteration 6836][Wall Clock 634.488216533s] Trained 128 records in 0.087286673 seconds. Throughput is 1466.4324 records/second. Loss is 0.088780366. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042247570764681035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 34688/60000][Iteration 6837][Wall Clock 634.569075053s] Trained 128 records in 0.08085852 seconds. Throughput is 1583.0118 records/second. Loss is 0.17943919. Sequential31006cbd's hyper parameters: Current learning rate is 0.004224400135180805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 34816/60000][Iteration 6838][Wall Clock 634.652678644s] Trained 128 records in 0.083603591 seconds. Throughput is 1531.0347 records/second. Loss is 0.1996504. Sequential31006cbd's hyper parameters: Current learning rate is 0.004224043254202923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 34944/60000][Iteration 6839][Wall Clock 634.752164838s] Trained 128 records in 0.099486194 seconds. Throughput is 1286.6107 records/second. Loss is 0.14623716. Sequential31006cbd's hyper parameters: Current learning rate is 0.004223686433519175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35072/60000][Iteration 6840][Wall Clock 634.840071551s] Trained 128 records in 0.087906713 seconds. Throughput is 1456.0891 records/second. Loss is 0.14134215. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042233296731142836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35200/60000][Iteration 6841][Wall Clock 634.937447431s] Trained 128 records in 0.09737588 seconds. Throughput is 1314.4939 records/second. Loss is 0.2100982. Sequential31006cbd's hyper parameters: Current learning rate is 0.004222972972972972. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35328/60000][Iteration 6842][Wall Clock 635.049673721s] Trained 128 records in 0.11222629 seconds. Throughput is 1140.5527 records/second. Loss is 0.16481194. Sequential31006cbd's hyper parameters: Current learning rate is 0.004222616333079977. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35456/60000][Iteration 6843][Wall Clock 635.137422393s] Trained 128 records in 0.087748672 seconds. Throughput is 1458.7115 records/second. Loss is 0.19906208. Sequential31006cbd's hyper parameters: Current learning rate is 0.00422225975342003. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35584/60000][Iteration 6844][Wall Clock 635.234917519s] Trained 128 records in 0.097495126 seconds. Throughput is 1312.8862 records/second. Loss is 0.13295817. Sequential31006cbd's hyper parameters: Current learning rate is 0.004221903233977878. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35712/60000][Iteration 6845][Wall Clock 635.317010652s] Trained 128 records in 0.082093133 seconds. Throughput is 1559.2047 records/second. Loss is 0.1867834. Sequential31006cbd's hyper parameters: Current learning rate is 0.004221546774738264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:12 INFO  DistriOptimizer$:408 - [Epoch 15 35840/60000][Iteration 6846][Wall Clock 635.407807198s] Trained 128 records in 0.090796546 seconds. Throughput is 1409.7452 records/second. Loss is 0.17735928. Sequential31006cbd's hyper parameters: Current learning rate is 0.004221190375685944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 35968/60000][Iteration 6847][Wall Clock 635.491674487s] Trained 128 records in 0.083867289 seconds. Throughput is 1526.2208 records/second. Loss is 0.25309342. Sequential31006cbd's hyper parameters: Current learning rate is 0.004220834036805673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36096/60000][Iteration 6848][Wall Clock 635.60840107s] Trained 128 records in 0.116726583 seconds. Throughput is 1096.5797 records/second. Loss is 0.20011196. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042204777580822144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36224/60000][Iteration 6849][Wall Clock 635.699697545s] Trained 128 records in 0.091296475 seconds. Throughput is 1402.0258 records/second. Loss is 0.1734323. Sequential31006cbd's hyper parameters: Current learning rate is 0.004220121539500337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36352/60000][Iteration 6850][Wall Clock 635.789211217s] Trained 128 records in 0.089513672 seconds. Throughput is 1429.9491 records/second. Loss is 0.14814474. Sequential31006cbd's hyper parameters: Current learning rate is 0.004219765381044814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36480/60000][Iteration 6851][Wall Clock 635.909456816s] Trained 128 records in 0.120245599 seconds. Throughput is 1064.488 records/second. Loss is 0.25823987. Sequential31006cbd's hyper parameters: Current learning rate is 0.004219409282700422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36608/60000][Iteration 6852][Wall Clock 635.990055826s] Trained 128 records in 0.08059901 seconds. Throughput is 1588.1089 records/second. Loss is 0.12721437. Sequential31006cbd's hyper parameters: Current learning rate is 0.004219053244451945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36736/60000][Iteration 6853][Wall Clock 636.069676192s] Trained 128 records in 0.079620366 seconds. Throughput is 1607.6288 records/second. Loss is 0.15364367. Sequential31006cbd's hyper parameters: Current learning rate is 0.004218697266284171. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36864/60000][Iteration 6854][Wall Clock 636.147276308s] Trained 128 records in 0.077600116 seconds. Throughput is 1649.482 records/second. Loss is 0.14964962. Sequential31006cbd's hyper parameters: Current learning rate is 0.004218341348181895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 36992/60000][Iteration 6855][Wall Clock 636.228240523s] Trained 128 records in 0.080964215 seconds. Throughput is 1580.9453 records/second. Loss is 0.08832062. Sequential31006cbd's hyper parameters: Current learning rate is 0.004217985490129914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 37120/60000][Iteration 6856][Wall Clock 636.318070207s] Trained 128 records in 0.089829684 seconds. Throughput is 1424.9187 records/second. Loss is 0.114746414. Sequential31006cbd's hyper parameters: Current learning rate is 0.004217629692113032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:13 INFO  DistriOptimizer$:408 - [Epoch 15 37248/60000][Iteration 6857][Wall Clock 636.39955417s] Trained 128 records in 0.081483963 seconds. Throughput is 1570.8613 records/second. Loss is 0.25031248. Sequential31006cbd's hyper parameters: Current learning rate is 0.004217273954116059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 37376/60000][Iteration 6858][Wall Clock 636.475521381s] Trained 128 records in 0.075967211 seconds. Throughput is 1684.9375 records/second. Loss is 0.18443379. Sequential31006cbd's hyper parameters: Current learning rate is 0.004216918276123808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 37504/60000][Iteration 6859][Wall Clock 636.554366598s] Trained 128 records in 0.078845217 seconds. Throughput is 1623.434 records/second. Loss is 0.1452077. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042165626581211. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 37632/60000][Iteration 6860][Wall Clock 636.629905603s] Trained 128 records in 0.075539005 seconds. Throughput is 1694.4888 records/second. Loss is 0.13669814. Sequential31006cbd's hyper parameters: Current learning rate is 0.004216207100092756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 37760/60000][Iteration 6861][Wall Clock 636.706053146s] Trained 128 records in 0.076147543 seconds. Throughput is 1680.9473 records/second. Loss is 0.18542603. Sequential31006cbd's hyper parameters: Current learning rate is 0.004215851602023609. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 37888/60000][Iteration 6862][Wall Clock 636.798162565s] Trained 128 records in 0.092109419 seconds. Throughput is 1389.6516 records/second. Loss is 0.1851009. Sequential31006cbd's hyper parameters: Current learning rate is 0.00421549616389849. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38016/60000][Iteration 6863][Wall Clock 636.872767346s] Trained 128 records in 0.074604781 seconds. Throughput is 1715.7078 records/second. Loss is 0.23007306. Sequential31006cbd's hyper parameters: Current learning rate is 0.004215140785702243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38144/60000][Iteration 6864][Wall Clock 636.948674813s] Trained 128 records in 0.075907467 seconds. Throughput is 1686.2635 records/second. Loss is 0.21729527. Sequential31006cbd's hyper parameters: Current learning rate is 0.004214785467419708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38272/60000][Iteration 6865][Wall Clock 637.024324102s] Trained 128 records in 0.075649289 seconds. Throughput is 1692.0186 records/second. Loss is 0.097708076. Sequential31006cbd's hyper parameters: Current learning rate is 0.004214430209035739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38400/60000][Iteration 6866][Wall Clock 637.105742349s] Trained 128 records in 0.081418247 seconds. Throughput is 1572.1292 records/second. Loss is 0.16344807. Sequential31006cbd's hyper parameters: Current learning rate is 0.004214075010535188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38528/60000][Iteration 6867][Wall Clock 637.202085353s] Trained 128 records in 0.096343004 seconds. Throughput is 1328.5863 records/second. Loss is 0.20183244. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042137198719029165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38656/60000][Iteration 6868][Wall Clock 637.294649783s] Trained 128 records in 0.09256443 seconds. Throughput is 1382.8207 records/second. Loss is 0.2686991. Sequential31006cbd's hyper parameters: Current learning rate is 0.004213364793123789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:14 INFO  DistriOptimizer$:408 - [Epoch 15 38784/60000][Iteration 6869][Wall Clock 637.372842898s] Trained 128 records in 0.078193115 seconds. Throughput is 1636.9728 records/second. Loss is 0.12732966. Sequential31006cbd's hyper parameters: Current learning rate is 0.004213009774182676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 38912/60000][Iteration 6870][Wall Clock 637.460263843s] Trained 128 records in 0.087420945 seconds. Throughput is 1464.1799 records/second. Loss is 0.14995435. Sequential31006cbd's hyper parameters: Current learning rate is 0.004212654815064453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39040/60000][Iteration 6871][Wall Clock 637.545405866s] Trained 128 records in 0.085142023 seconds. Throughput is 1503.3704 records/second. Loss is 0.19698432. Sequential31006cbd's hyper parameters: Current learning rate is 0.004212299915754001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39168/60000][Iteration 6872][Wall Clock 637.622115494s] Trained 128 records in 0.076709628 seconds. Throughput is 1668.6301 records/second. Loss is 0.12246061. Sequential31006cbd's hyper parameters: Current learning rate is 0.004211945076236206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39296/60000][Iteration 6873][Wall Clock 637.717800722s] Trained 128 records in 0.095685228 seconds. Throughput is 1337.7195 records/second. Loss is 0.20845652. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042115902964959566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39424/60000][Iteration 6874][Wall Clock 637.830064655s] Trained 128 records in 0.112263933 seconds. Throughput is 1140.1703 records/second. Loss is 0.22565466. Sequential31006cbd's hyper parameters: Current learning rate is 0.004211235576518151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39552/60000][Iteration 6875][Wall Clock 637.933582829s] Trained 128 records in 0.103518174 seconds. Throughput is 1236.4979 records/second. Loss is 0.16278066. Sequential31006cbd's hyper parameters: Current learning rate is 0.004210880916287687. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39680/60000][Iteration 6876][Wall Clock 638.019440297s] Trained 128 records in 0.085857468 seconds. Throughput is 1490.843 records/second. Loss is 0.11705159. Sequential31006cbd's hyper parameters: Current learning rate is 0.004210526315789474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39808/60000][Iteration 6877][Wall Clock 638.126895827s] Trained 128 records in 0.10745553 seconds. Throughput is 1191.1904 records/second. Loss is 0.13174975. Sequential31006cbd's hyper parameters: Current learning rate is 0.004210171775008421. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 39936/60000][Iteration 6878][Wall Clock 638.216831505s] Trained 128 records in 0.089935678 seconds. Throughput is 1423.2394 records/second. Loss is 0.14671645. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042098172939294435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 40064/60000][Iteration 6879][Wall Clock 638.2940812s] Trained 128 records in 0.077249695 seconds. Throughput is 1656.9644 records/second. Loss is 0.14725871. Sequential31006cbd's hyper parameters: Current learning rate is 0.004209462872537464. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:15 INFO  DistriOptimizer$:408 - [Epoch 15 40192/60000][Iteration 6880][Wall Clock 638.368325705s] Trained 128 records in 0.074244505 seconds. Throughput is 1724.0333 records/second. Loss is 0.24539056. Sequential31006cbd's hyper parameters: Current learning rate is 0.004209108510817409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 40320/60000][Iteration 6881][Wall Clock 638.447717198s] Trained 128 records in 0.079391493 seconds. Throughput is 1612.2634 records/second. Loss is 0.17910798. Sequential31006cbd's hyper parameters: Current learning rate is 0.004208754208754209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 40448/60000][Iteration 6882][Wall Clock 638.520330155s] Trained 128 records in 0.072612957 seconds. Throughput is 1762.7709 records/second. Loss is 0.21561745. Sequential31006cbd's hyper parameters: Current learning rate is 0.004208399966332801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 40576/60000][Iteration 6883][Wall Clock 638.592592386s] Trained 128 records in 0.072262231 seconds. Throughput is 1771.3265 records/second. Loss is 0.16053815. Sequential31006cbd's hyper parameters: Current learning rate is 0.004208045783538125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 40704/60000][Iteration 6884][Wall Clock 638.668082803s] Trained 128 records in 0.075490417 seconds. Throughput is 1695.5795 records/second. Loss is 0.13462009. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042076916603551295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 40832/60000][Iteration 6885][Wall Clock 638.742754313s] Trained 128 records in 0.07467151 seconds. Throughput is 1714.1746 records/second. Loss is 0.12819785. Sequential31006cbd's hyper parameters: Current learning rate is 0.004207337596768764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 40960/60000][Iteration 6886][Wall Clock 638.818496903s] Trained 128 records in 0.07574259 seconds. Throughput is 1689.9343 records/second. Loss is 0.091211766. Sequential31006cbd's hyper parameters: Current learning rate is 0.004206983592763989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41088/60000][Iteration 6887][Wall Clock 638.890518163s] Trained 128 records in 0.07202126 seconds. Throughput is 1777.2529 records/second. Loss is 0.09248638. Sequential31006cbd's hyper parameters: Current learning rate is 0.004206629648325761. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41216/60000][Iteration 6888][Wall Clock 638.964289447s] Trained 128 records in 0.073771284 seconds. Throughput is 1735.0925 records/second. Loss is 0.1811801. Sequential31006cbd's hyper parameters: Current learning rate is 0.004206275763439051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41344/60000][Iteration 6889][Wall Clock 639.036471971s] Trained 128 records in 0.072182524 seconds. Throughput is 1773.2825 records/second. Loss is 0.18978223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0042059219380888285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41472/60000][Iteration 6890][Wall Clock 639.120492777s] Trained 128 records in 0.084020806 seconds. Throughput is 1523.4321 records/second. Loss is 0.20237955. Sequential31006cbd's hyper parameters: Current learning rate is 0.004205568172260072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41600/60000][Iteration 6891][Wall Clock 639.198350939s] Trained 128 records in 0.077858162 seconds. Throughput is 1644.0151 records/second. Loss is 0.22944388. Sequential31006cbd's hyper parameters: Current learning rate is 0.004205214465937763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41728/60000][Iteration 6892][Wall Clock 639.280407848s] Trained 128 records in 0.082056909 seconds. Throughput is 1559.8931 records/second. Loss is 0.12944065. Sequential31006cbd's hyper parameters: Current learning rate is 0.004204860819106888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:16 INFO  DistriOptimizer$:408 - [Epoch 15 41856/60000][Iteration 6893][Wall Clock 639.372866946s] Trained 128 records in 0.092459098 seconds. Throughput is 1384.396 records/second. Loss is 0.15069005. Sequential31006cbd's hyper parameters: Current learning rate is 0.004204507231752439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 41984/60000][Iteration 6894][Wall Clock 639.45181849s] Trained 128 records in 0.078951544 seconds. Throughput is 1621.2476 records/second. Loss is 0.1907359. Sequential31006cbd's hyper parameters: Current learning rate is 0.004204153703859413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42112/60000][Iteration 6895][Wall Clock 639.540579491s] Trained 128 records in 0.088761001 seconds. Throughput is 1442.0747 records/second. Loss is 0.18829238. Sequential31006cbd's hyper parameters: Current learning rate is 0.004203800235412813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42240/60000][Iteration 6896][Wall Clock 639.620433485s] Trained 128 records in 0.079853994 seconds. Throughput is 1602.9254 records/second. Loss is 0.1339542. Sequential31006cbd's hyper parameters: Current learning rate is 0.004203446826397646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42368/60000][Iteration 6897][Wall Clock 639.697605279s] Trained 128 records in 0.077171794 seconds. Throughput is 1658.6371 records/second. Loss is 0.24975215. Sequential31006cbd's hyper parameters: Current learning rate is 0.004203093476798924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42496/60000][Iteration 6898][Wall Clock 639.775319263s] Trained 128 records in 0.077713984 seconds. Throughput is 1647.0653 records/second. Loss is 0.107241. Sequential31006cbd's hyper parameters: Current learning rate is 0.004202740186601665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42624/60000][Iteration 6899][Wall Clock 639.879035698s] Trained 128 records in 0.103716435 seconds. Throughput is 1234.1343 records/second. Loss is 0.14081933. Sequential31006cbd's hyper parameters: Current learning rate is 0.00420238695579089. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42752/60000][Iteration 6900][Wall Clock 639.957536135s] Trained 128 records in 0.078500437 seconds. Throughput is 1630.5642 records/second. Loss is 0.16773398. Sequential31006cbd's hyper parameters: Current learning rate is 0.004202033784351625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 42880/60000][Iteration 6901][Wall Clock 640.03377288s] Trained 128 records in 0.076236745 seconds. Throughput is 1678.9803 records/second. Loss is 0.17917456. Sequential31006cbd's hyper parameters: Current learning rate is 0.004201680672268908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 43008/60000][Iteration 6902][Wall Clock 640.113864485s] Trained 128 records in 0.080091605 seconds. Throughput is 1598.17 records/second. Loss is 0.15062252. Sequential31006cbd's hyper parameters: Current learning rate is 0.004201327619527771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 43136/60000][Iteration 6903][Wall Clock 640.192907627s] Trained 128 records in 0.079043142 seconds. Throughput is 1619.3688 records/second. Loss is 0.1579679. Sequential31006cbd's hyper parameters: Current learning rate is 0.004200974626113259. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 43264/60000][Iteration 6904][Wall Clock 640.269004951s] Trained 128 records in 0.076097324 seconds. Throughput is 1682.0565 records/second. Loss is 0.106396854. Sequential31006cbd's hyper parameters: Current learning rate is 0.004200621692010417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 43392/60000][Iteration 6905][Wall Clock 640.34801386s] Trained 128 records in 0.079008909 seconds. Throughput is 1620.0706 records/second. Loss is 0.22075543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004200268817204302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:17 INFO  DistriOptimizer$:408 - [Epoch 15 43520/60000][Iteration 6906][Wall Clock 640.422703314s] Trained 128 records in 0.074689454 seconds. Throughput is 1713.7627 records/second. Loss is 0.19440922. Sequential31006cbd's hyper parameters: Current learning rate is 0.004199916001679966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 43648/60000][Iteration 6907][Wall Clock 640.503816748s] Trained 128 records in 0.081113434 seconds. Throughput is 1578.037 records/second. Loss is 0.16280812. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041995632454224765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 43776/60000][Iteration 6908][Wall Clock 640.584852481s] Trained 128 records in 0.081035733 seconds. Throughput is 1579.55 records/second. Loss is 0.21308362. Sequential31006cbd's hyper parameters: Current learning rate is 0.004199210548416897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 43904/60000][Iteration 6909][Wall Clock 640.663062667s] Trained 128 records in 0.078210186 seconds. Throughput is 1636.6155 records/second. Loss is 0.15124264. Sequential31006cbd's hyper parameters: Current learning rate is 0.004198857910648304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44032/60000][Iteration 6910][Wall Clock 640.734108424s] Trained 128 records in 0.071045757 seconds. Throughput is 1801.6558 records/second. Loss is 0.13972402. Sequential31006cbd's hyper parameters: Current learning rate is 0.004198505332101771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44160/60000][Iteration 6911][Wall Clock 640.810389204s] Trained 128 records in 0.07628078 seconds. Throughput is 1678.0111 records/second. Loss is 0.20570374. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041981528127623844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44288/60000][Iteration 6912][Wall Clock 640.890800057s] Trained 128 records in 0.080410853 seconds. Throughput is 1591.825 records/second. Loss is 0.21525376. Sequential31006cbd's hyper parameters: Current learning rate is 0.004197800352615229. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44416/60000][Iteration 6913][Wall Clock 640.969704951s] Trained 128 records in 0.078904894 seconds. Throughput is 1622.206 records/second. Loss is 0.2265369. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041974479516454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44544/60000][Iteration 6914][Wall Clock 641.045343954s] Trained 128 records in 0.075639003 seconds. Throughput is 1692.2487 records/second. Loss is 0.1608486. Sequential31006cbd's hyper parameters: Current learning rate is 0.004197095609837992. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44672/60000][Iteration 6915][Wall Clock 641.140665274s] Trained 128 records in 0.09532132 seconds. Throughput is 1342.8265 records/second. Loss is 0.31370962. Sequential31006cbd's hyper parameters: Current learning rate is 0.004196743327178109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44800/60000][Iteration 6916][Wall Clock 641.232851155s] Trained 128 records in 0.092185881 seconds. Throughput is 1388.4989 records/second. Loss is 0.12034496. Sequential31006cbd's hyper parameters: Current learning rate is 0.00419639110365086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 44928/60000][Iteration 6917][Wall Clock 641.313661293s] Trained 128 records in 0.080810138 seconds. Throughput is 1583.9597 records/second. Loss is 0.121052034. Sequential31006cbd's hyper parameters: Current learning rate is 0.004196038939241357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:18 INFO  DistriOptimizer$:408 - [Epoch 15 45056/60000][Iteration 6918][Wall Clock 641.392373309s] Trained 128 records in 0.078712016 seconds. Throughput is 1626.1812 records/second. Loss is 0.1627954. Sequential31006cbd's hyper parameters: Current learning rate is 0.004195686833934715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45184/60000][Iteration 6919][Wall Clock 641.468381942s] Trained 128 records in 0.076008633 seconds. Throughput is 1684.0193 records/second. Loss is 0.1638425. Sequential31006cbd's hyper parameters: Current learning rate is 0.004195334787716059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45312/60000][Iteration 6920][Wall Clock 641.553605492s] Trained 128 records in 0.08522355 seconds. Throughput is 1501.9323 records/second. Loss is 0.12755644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004194982800570518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45440/60000][Iteration 6921][Wall Clock 641.634244318s] Trained 128 records in 0.080638826 seconds. Throughput is 1587.3247 records/second. Loss is 0.2386379. Sequential31006cbd's hyper parameters: Current learning rate is 0.004194630872483221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45568/60000][Iteration 6922][Wall Clock 641.72019361s] Trained 128 records in 0.085949292 seconds. Throughput is 1489.2501 records/second. Loss is 0.18275239. Sequential31006cbd's hyper parameters: Current learning rate is 0.004194279003439309. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45696/60000][Iteration 6923][Wall Clock 641.80171678s] Trained 128 records in 0.08152317 seconds. Throughput is 1570.1057 records/second. Loss is 0.12984847. Sequential31006cbd's hyper parameters: Current learning rate is 0.004193927193423922. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45824/60000][Iteration 6924][Wall Clock 641.905169337s] Trained 128 records in 0.103452557 seconds. Throughput is 1237.2821 records/second. Loss is 0.14273208. Sequential31006cbd's hyper parameters: Current learning rate is 0.00419357544242221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 45952/60000][Iteration 6925][Wall Clock 641.987523084s] Trained 128 records in 0.082353747 seconds. Throughput is 1554.2705 records/second. Loss is 0.15833683. Sequential31006cbd's hyper parameters: Current learning rate is 0.004193223750419322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 46080/60000][Iteration 6926][Wall Clock 642.074689877s] Trained 128 records in 0.087166793 seconds. Throughput is 1468.4491 records/second. Loss is 0.24913901. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041928721174004195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 46208/60000][Iteration 6927][Wall Clock 642.157555226s] Trained 128 records in 0.082865349 seconds. Throughput is 1544.6746 records/second. Loss is 0.12997176. Sequential31006cbd's hyper parameters: Current learning rate is 0.004192520543350662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 46336/60000][Iteration 6928][Wall Clock 642.235692251s] Trained 128 records in 0.078137025 seconds. Throughput is 1638.1478 records/second. Loss is 0.10100055. Sequential31006cbd's hyper parameters: Current learning rate is 0.00419216902825522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 46464/60000][Iteration 6929][Wall Clock 642.315649877s] Trained 128 records in 0.079957626 seconds. Throughput is 1600.8479 records/second. Loss is 0.14103113. Sequential31006cbd's hyper parameters: Current learning rate is 0.004191817572099262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:19 INFO  DistriOptimizer$:408 - [Epoch 15 46592/60000][Iteration 6930][Wall Clock 642.394247379s] Trained 128 records in 0.078597502 seconds. Throughput is 1628.5505 records/second. Loss is 0.1668626. Sequential31006cbd's hyper parameters: Current learning rate is 0.004191466174867969. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 46720/60000][Iteration 6931][Wall Clock 642.467387589s] Trained 128 records in 0.07314021 seconds. Throughput is 1750.0634 records/second. Loss is 0.22507119. Sequential31006cbd's hyper parameters: Current learning rate is 0.004191114836546521. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 46848/60000][Iteration 6932][Wall Clock 642.549893775s] Trained 128 records in 0.082506186 seconds. Throughput is 1551.3988 records/second. Loss is 0.1773207. Sequential31006cbd's hyper parameters: Current learning rate is 0.004190763557120107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 46976/60000][Iteration 6933][Wall Clock 642.619741796s] Trained 128 records in 0.069848021 seconds. Throughput is 1832.55 records/second. Loss is 0.08777364. Sequential31006cbd's hyper parameters: Current learning rate is 0.004190412336573919. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47104/60000][Iteration 6934][Wall Clock 642.69492567s] Trained 128 records in 0.075183874 seconds. Throughput is 1702.4927 records/second. Loss is 0.22941911. Sequential31006cbd's hyper parameters: Current learning rate is 0.004190061174893153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47232/60000][Iteration 6935][Wall Clock 642.77867036s] Trained 128 records in 0.08374469 seconds. Throughput is 1528.4551 records/second. Loss is 0.19544184. Sequential31006cbd's hyper parameters: Current learning rate is 0.004189710072063014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47360/60000][Iteration 6936][Wall Clock 642.863471222s] Trained 128 records in 0.084800862 seconds. Throughput is 1509.4186 records/second. Loss is 0.13233015. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041893590280687055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47488/60000][Iteration 6937][Wall Clock 642.94487801s] Trained 128 records in 0.081406788 seconds. Throughput is 1572.3505 records/second. Loss is 0.1826659. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041890080428954425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47616/60000][Iteration 6938][Wall Clock 643.024625457s] Trained 128 records in 0.079747447 seconds. Throughput is 1605.0671 records/second. Loss is 0.1462868. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041886571165284416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47744/60000][Iteration 6939][Wall Clock 643.105541278s] Trained 128 records in 0.080915821 seconds. Throughput is 1581.8909 records/second. Loss is 0.20410615. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041883062489529235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 47872/60000][Iteration 6940][Wall Clock 643.187707129s] Trained 128 records in 0.082165851 seconds. Throughput is 1557.8248 records/second. Loss is 0.13134469. Sequential31006cbd's hyper parameters: Current learning rate is 0.004187955440154116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 48000/60000][Iteration 6941][Wall Clock 643.273988525s] Trained 128 records in 0.086281396 seconds. Throughput is 1483.518 records/second. Loss is 0.087460704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004187604690117253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:20 INFO  DistriOptimizer$:408 - [Epoch 15 48128/60000][Iteration 6942][Wall Clock 643.35412517s] Trained 128 records in 0.080136645 seconds. Throughput is 1597.2719 records/second. Loss is 0.17563882. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041872539988275686. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 48256/60000][Iteration 6943][Wall Clock 643.43178994s] Trained 128 records in 0.07766477 seconds. Throughput is 1648.1089 records/second. Loss is 0.2140916. Sequential31006cbd's hyper parameters: Current learning rate is 0.004186903366270307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 48384/60000][Iteration 6944][Wall Clock 643.505360674s] Trained 128 records in 0.073570734 seconds. Throughput is 1739.8223 records/second. Loss is 0.23041461. Sequential31006cbd's hyper parameters: Current learning rate is 0.004186552792430712. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 48512/60000][Iteration 6945][Wall Clock 643.581813441s] Trained 128 records in 0.076452767 seconds. Throughput is 1674.2363 records/second. Loss is 0.15882939. Sequential31006cbd's hyper parameters: Current learning rate is 0.004186202277294039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 48640/60000][Iteration 6946][Wall Clock 643.661194159s] Trained 128 records in 0.079380718 seconds. Throughput is 1612.4822 records/second. Loss is 0.15035394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004185851820845542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 48768/60000][Iteration 6947][Wall Clock 643.737411823s] Trained 128 records in 0.076217664 seconds. Throughput is 1679.4006 records/second. Loss is 0.23552345. Sequential31006cbd's hyper parameters: Current learning rate is 0.004185501423070484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 48896/60000][Iteration 6948][Wall Clock 643.815222138s] Trained 128 records in 0.077810315 seconds. Throughput is 1645.0261 records/second. Loss is 0.25104567. Sequential31006cbd's hyper parameters: Current learning rate is 0.004185151083954131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49024/60000][Iteration 6949][Wall Clock 643.89129223s] Trained 128 records in 0.076070092 seconds. Throughput is 1682.6587 records/second. Loss is 0.13117637. Sequential31006cbd's hyper parameters: Current learning rate is 0.004184800803481754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49152/60000][Iteration 6950][Wall Clock 643.971076024s] Trained 128 records in 0.079783794 seconds. Throughput is 1604.3358 records/second. Loss is 0.17930464. Sequential31006cbd's hyper parameters: Current learning rate is 0.004184450581638631. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49280/60000][Iteration 6951][Wall Clock 644.047294325s] Trained 128 records in 0.076218301 seconds. Throughput is 1679.3867 records/second. Loss is 0.1268548. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041841004184100415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49408/60000][Iteration 6952][Wall Clock 644.116946037s] Trained 128 records in 0.069651712 seconds. Throughput is 1837.715 records/second. Loss is 0.17140159. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041837503137812735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49536/60000][Iteration 6953][Wall Clock 644.193154416s] Trained 128 records in 0.076208379 seconds. Throughput is 1679.6055 records/second. Loss is 0.21333879. Sequential31006cbd's hyper parameters: Current learning rate is 0.004183400267737617. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49664/60000][Iteration 6954][Wall Clock 644.268435834s] Trained 128 records in 0.075281418 seconds. Throughput is 1700.2867 records/second. Loss is 0.15057538. Sequential31006cbd's hyper parameters: Current learning rate is 0.004183050280264369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49792/60000][Iteration 6955][Wall Clock 644.343063593s] Trained 128 records in 0.074627759 seconds. Throughput is 1715.1796 records/second. Loss is 0.13109839. Sequential31006cbd's hyper parameters: Current learning rate is 0.004182700351346829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:21 INFO  DistriOptimizer$:408 - [Epoch 15 49920/60000][Iteration 6956][Wall Clock 644.418330898s] Trained 128 records in 0.075267305 seconds. Throughput is 1700.6056 records/second. Loss is 0.10213239. Sequential31006cbd's hyper parameters: Current learning rate is 0.004182350480970306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50048/60000][Iteration 6957][Wall Clock 644.507528935s] Trained 128 records in 0.089198037 seconds. Throughput is 1435.0092 records/second. Loss is 0.20823382. Sequential31006cbd's hyper parameters: Current learning rate is 0.004182000669120107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50176/60000][Iteration 6958][Wall Clock 644.597802889s] Trained 128 records in 0.090273954 seconds. Throughput is 1417.9062 records/second. Loss is 0.16510616. Sequential31006cbd's hyper parameters: Current learning rate is 0.004181650915781551. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50304/60000][Iteration 6959][Wall Clock 644.683766386s] Trained 128 records in 0.085963497 seconds. Throughput is 1489.0042 records/second. Loss is 0.117086515. Sequential31006cbd's hyper parameters: Current learning rate is 0.004181301220939956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50432/60000][Iteration 6960][Wall Clock 644.767889133s] Trained 128 records in 0.084122747 seconds. Throughput is 1521.586 records/second. Loss is 0.12490815. Sequential31006cbd's hyper parameters: Current learning rate is 0.004180951584580651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50560/60000][Iteration 6961][Wall Clock 644.849197682s] Trained 128 records in 0.081308549 seconds. Throughput is 1574.2501 records/second. Loss is 0.0894486. Sequential31006cbd's hyper parameters: Current learning rate is 0.004180602006688963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50688/60000][Iteration 6962][Wall Clock 644.928037315s] Trained 128 records in 0.078839633 seconds. Throughput is 1623.549 records/second. Loss is 0.19346282. Sequential31006cbd's hyper parameters: Current learning rate is 0.00418025248725023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50816/60000][Iteration 6963][Wall Clock 645.008129018s] Trained 128 records in 0.080091703 seconds. Throughput is 1598.1681 records/second. Loss is 0.1866565. Sequential31006cbd's hyper parameters: Current learning rate is 0.004179903026249791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 50944/60000][Iteration 6964][Wall Clock 645.090306789s] Trained 128 records in 0.082177771 seconds. Throughput is 1557.5988 records/second. Loss is 0.19906983. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041795536236729925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 51072/60000][Iteration 6965][Wall Clock 645.162666807s] Trained 128 records in 0.072360018 seconds. Throughput is 1768.9327 records/second. Loss is 0.18134454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004179204279505182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 51200/60000][Iteration 6966][Wall Clock 645.238270745s] Trained 128 records in 0.075603938 seconds. Throughput is 1693.0334 records/second. Loss is 0.15771383. Sequential31006cbd's hyper parameters: Current learning rate is 0.004178854993731718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 51328/60000][Iteration 6967][Wall Clock 645.319271218s] Trained 128 records in 0.081000473 seconds. Throughput is 1580.2378 records/second. Loss is 0.23471181. Sequential31006cbd's hyper parameters: Current learning rate is 0.004178505766337957. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:22 INFO  DistriOptimizer$:408 - [Epoch 15 51456/60000][Iteration 6968][Wall Clock 645.3981638s] Trained 128 records in 0.078892582 seconds. Throughput is 1622.4592 records/second. Loss is 0.10524595. Sequential31006cbd's hyper parameters: Current learning rate is 0.004178156597309268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 51584/60000][Iteration 6969][Wall Clock 645.477280558s] Trained 128 records in 0.079116758 seconds. Throughput is 1617.8619 records/second. Loss is 0.263146. Sequential31006cbd's hyper parameters: Current learning rate is 0.004177807486631016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 51712/60000][Iteration 6970][Wall Clock 645.551526257s] Trained 128 records in 0.074245699 seconds. Throughput is 1724.0056 records/second. Loss is 0.1361615. Sequential31006cbd's hyper parameters: Current learning rate is 0.004177458434288578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 51840/60000][Iteration 6971][Wall Clock 645.626913602s] Trained 128 records in 0.075387345 seconds. Throughput is 1697.8977 records/second. Loss is 0.20317784. Sequential31006cbd's hyper parameters: Current learning rate is 0.004177109440267335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 51968/60000][Iteration 6972][Wall Clock 645.704829869s] Trained 128 records in 0.077916267 seconds. Throughput is 1642.7892 records/second. Loss is 0.16412267. Sequential31006cbd's hyper parameters: Current learning rate is 0.004176760504552669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52096/60000][Iteration 6973][Wall Clock 645.783056642s] Trained 128 records in 0.078226773 seconds. Throughput is 1636.2684 records/second. Loss is 0.17564228. Sequential31006cbd's hyper parameters: Current learning rate is 0.00417641162712997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52224/60000][Iteration 6974][Wall Clock 645.873176136s] Trained 128 records in 0.090119494 seconds. Throughput is 1420.3364 records/second. Loss is 0.08655332. Sequential31006cbd's hyper parameters: Current learning rate is 0.004176062807984632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52352/60000][Iteration 6975][Wall Clock 645.968680634s] Trained 128 records in 0.095504498 seconds. Throughput is 1340.251 records/second. Loss is 0.18709746. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041757140471020545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52480/60000][Iteration 6976][Wall Clock 646.068341951s] Trained 128 records in 0.099661317 seconds. Throughput is 1284.3499 records/second. Loss is 0.252749. Sequential31006cbd's hyper parameters: Current learning rate is 0.004175365344467641. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52608/60000][Iteration 6977][Wall Clock 646.142156824s] Trained 128 records in 0.073814873 seconds. Throughput is 1734.0677 records/second. Loss is 0.16143166. Sequential31006cbd's hyper parameters: Current learning rate is 0.004175016700066801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52736/60000][Iteration 6978][Wall Clock 646.217453712s] Trained 128 records in 0.075296888 seconds. Throughput is 1699.9375 records/second. Loss is 0.24848746. Sequential31006cbd's hyper parameters: Current learning rate is 0.004174668113884946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52864/60000][Iteration 6979][Wall Clock 646.293254574s] Trained 128 records in 0.075800862 seconds. Throughput is 1688.6353 records/second. Loss is 0.22145161. Sequential31006cbd's hyper parameters: Current learning rate is 0.004174319585907497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:23 INFO  DistriOptimizer$:408 - [Epoch 15 52992/60000][Iteration 6980][Wall Clock 646.369802288s] Trained 128 records in 0.076547714 seconds. Throughput is 1672.1597 records/second. Loss is 0.16172677. Sequential31006cbd's hyper parameters: Current learning rate is 0.004173971116119876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53120/60000][Iteration 6981][Wall Clock 646.453308609s] Trained 128 records in 0.083506321 seconds. Throughput is 1532.818 records/second. Loss is 0.12530951. Sequential31006cbd's hyper parameters: Current learning rate is 0.004173622704507513. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53248/60000][Iteration 6982][Wall Clock 646.537381421s] Trained 128 records in 0.084072812 seconds. Throughput is 1522.4897 records/second. Loss is 0.11562544. Sequential31006cbd's hyper parameters: Current learning rate is 0.004173274351055838. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53376/60000][Iteration 6983][Wall Clock 646.638639899s] Trained 128 records in 0.101258478 seconds. Throughput is 1264.0917 records/second. Loss is 0.16428702. Sequential31006cbd's hyper parameters: Current learning rate is 0.004172926055750293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53504/60000][Iteration 6984][Wall Clock 646.71033894s] Trained 128 records in 0.071699041 seconds. Throughput is 1785.2401 records/second. Loss is 0.11274335. Sequential31006cbd's hyper parameters: Current learning rate is 0.004172577818576316. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53632/60000][Iteration 6985][Wall Clock 646.798357206s] Trained 128 records in 0.088018266 seconds. Throughput is 1454.2435 records/second. Loss is 0.18121158. Sequential31006cbd's hyper parameters: Current learning rate is 0.00417222963951936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53760/60000][Iteration 6986][Wall Clock 646.87939826s] Trained 128 records in 0.081041054 seconds. Throughput is 1579.4464 records/second. Loss is 0.18750404. Sequential31006cbd's hyper parameters: Current learning rate is 0.004171881518564872. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 53888/60000][Iteration 6987][Wall Clock 646.964037721s] Trained 128 records in 0.084639461 seconds. Throughput is 1512.297 records/second. Loss is 0.18407181. Sequential31006cbd's hyper parameters: Current learning rate is 0.004171533455698315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 54016/60000][Iteration 6988][Wall Clock 647.04572309s] Trained 128 records in 0.081685369 seconds. Throughput is 1566.988 records/second. Loss is 0.15827475. Sequential31006cbd's hyper parameters: Current learning rate is 0.004171185450905147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 54144/60000][Iteration 6989][Wall Clock 647.121688559s] Trained 128 records in 0.075965469 seconds. Throughput is 1684.9761 records/second. Loss is 0.17782098. Sequential31006cbd's hyper parameters: Current learning rate is 0.004170837504170837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 54272/60000][Iteration 6990][Wall Clock 647.194247704s] Trained 128 records in 0.072559145 seconds. Throughput is 1764.078 records/second. Loss is 0.12583408. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041704896154808576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 54400/60000][Iteration 6991][Wall Clock 647.271931374s] Trained 128 records in 0.07768367 seconds. Throughput is 1647.7079 records/second. Loss is 0.19154453. Sequential31006cbd's hyper parameters: Current learning rate is 0.004170141784820684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:24 INFO  DistriOptimizer$:408 - [Epoch 15 54528/60000][Iteration 6992][Wall Clock 647.354431109s] Trained 128 records in 0.082499735 seconds. Throughput is 1551.5201 records/second. Loss is 0.18884978. Sequential31006cbd's hyper parameters: Current learning rate is 0.004169794012175799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 54656/60000][Iteration 6993][Wall Clock 647.437211383s] Trained 128 records in 0.082780274 seconds. Throughput is 1546.2621 records/second. Loss is 0.29742807. Sequential31006cbd's hyper parameters: Current learning rate is 0.004169446297531688. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 54784/60000][Iteration 6994][Wall Clock 647.518526885s] Trained 128 records in 0.081315502 seconds. Throughput is 1574.1156 records/second. Loss is 0.072376445. Sequential31006cbd's hyper parameters: Current learning rate is 0.004169098640873843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 54912/60000][Iteration 6995][Wall Clock 647.597028373s] Trained 128 records in 0.078501488 seconds. Throughput is 1630.5424 records/second. Loss is 0.12705037. Sequential31006cbd's hyper parameters: Current learning rate is 0.00416875104218776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55040/60000][Iteration 6996][Wall Clock 647.683063173s] Trained 128 records in 0.0860348 seconds. Throughput is 1487.7701 records/second. Loss is 0.21408644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004168403501458941. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55168/60000][Iteration 6997][Wall Clock 647.778818992s] Trained 128 records in 0.095755819 seconds. Throughput is 1336.7334 records/second. Loss is 0.15547541. Sequential31006cbd's hyper parameters: Current learning rate is 0.004168056018672891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55296/60000][Iteration 6998][Wall Clock 647.885173343s] Trained 128 records in 0.106354351 seconds. Throughput is 1203.5239 records/second. Loss is 0.121287316. Sequential31006cbd's hyper parameters: Current learning rate is 0.00416770859381512. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55424/60000][Iteration 6999][Wall Clock 647.997044351s] Trained 128 records in 0.111871008 seconds. Throughput is 1144.1749 records/second. Loss is 0.20634335. Sequential31006cbd's hyper parameters: Current learning rate is 0.004167361226871145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55552/60000][Iteration 7000][Wall Clock 648.093808071s] Trained 128 records in 0.09676372 seconds. Throughput is 1322.8098 records/second. Loss is 0.13709635. Sequential31006cbd's hyper parameters: Current learning rate is 0.004167013917826486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55680/60000][Iteration 7001][Wall Clock 648.169714564s] Trained 128 records in 0.075906493 seconds. Throughput is 1686.2853 records/second. Loss is 0.17062563. Sequential31006cbd's hyper parameters: Current learning rate is 0.004166666666666666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55808/60000][Iteration 7002][Wall Clock 648.253650009s] Trained 128 records in 0.083935445 seconds. Throughput is 1524.9814 records/second. Loss is 0.20134763. Sequential31006cbd's hyper parameters: Current learning rate is 0.004166319473377218. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:25 INFO  DistriOptimizer$:408 - [Epoch 15 55936/60000][Iteration 7003][Wall Clock 648.329678793s] Trained 128 records in 0.076028784 seconds. Throughput is 1683.5729 records/second. Loss is 0.17134424. Sequential31006cbd's hyper parameters: Current learning rate is 0.004165972337943675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56064/60000][Iteration 7004][Wall Clock 648.405577584s] Trained 128 records in 0.075898791 seconds. Throughput is 1686.4564 records/second. Loss is 0.124229416. Sequential31006cbd's hyper parameters: Current learning rate is 0.004165625260351579. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56192/60000][Iteration 7005][Wall Clock 648.481569036s] Trained 128 records in 0.075991452 seconds. Throughput is 1684.4 records/second. Loss is 0.17842196. Sequential31006cbd's hyper parameters: Current learning rate is 0.004165278240586471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56320/60000][Iteration 7006][Wall Clock 648.559342741s] Trained 128 records in 0.077773705 seconds. Throughput is 1645.8004 records/second. Loss is 0.1255415. Sequential31006cbd's hyper parameters: Current learning rate is 0.004164931278633903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56448/60000][Iteration 7007][Wall Clock 648.633785818s] Trained 128 records in 0.074443077 seconds. Throughput is 1719.4346 records/second. Loss is 0.14892758. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041645843744794265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56576/60000][Iteration 7008][Wall Clock 648.713143657s] Trained 128 records in 0.079357839 seconds. Throughput is 1612.9471 records/second. Loss is 0.16973613. Sequential31006cbd's hyper parameters: Current learning rate is 0.004164237528108604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56704/60000][Iteration 7009][Wall Clock 648.81014791s] Trained 128 records in 0.097004253 seconds. Throughput is 1319.5298 records/second. Loss is 0.20447817. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041638907395069955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56832/60000][Iteration 7010][Wall Clock 648.899108046s] Trained 128 records in 0.088960136 seconds. Throughput is 1438.8468 records/second. Loss is 0.13817579. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041635440086601715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 56960/60000][Iteration 7011][Wall Clock 648.971909855s] Trained 128 records in 0.072801809 seconds. Throughput is 1758.1981 records/second. Loss is 0.16495064. Sequential31006cbd's hyper parameters: Current learning rate is 0.004163197335553705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 57088/60000][Iteration 7012][Wall Clock 649.045561336s] Trained 128 records in 0.073651481 seconds. Throughput is 1737.9149 records/second. Loss is 0.16543566. Sequential31006cbd's hyper parameters: Current learning rate is 0.004162850720173175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 57216/60000][Iteration 7013][Wall Clock 649.126746719s] Trained 128 records in 0.081185383 seconds. Throughput is 1576.6384 records/second. Loss is 0.15062344. Sequential31006cbd's hyper parameters: Current learning rate is 0.004162504162504162. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 57344/60000][Iteration 7014][Wall Clock 649.202831965s] Trained 128 records in 0.076085246 seconds. Throughput is 1682.3235 records/second. Loss is 0.24220896. Sequential31006cbd's hyper parameters: Current learning rate is 0.004162157662532257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 57472/60000][Iteration 7015][Wall Clock 649.275598657s] Trained 128 records in 0.072766692 seconds. Throughput is 1759.0466 records/second. Loss is 0.16242494. Sequential31006cbd's hyper parameters: Current learning rate is 0.00416181122024305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:26 INFO  DistriOptimizer$:408 - [Epoch 15 57600/60000][Iteration 7016][Wall Clock 649.348821154s] Trained 128 records in 0.073222497 seconds. Throughput is 1748.0967 records/second. Loss is 0.19288914. Sequential31006cbd's hyper parameters: Current learning rate is 0.004161464835622139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 57728/60000][Iteration 7017][Wall Clock 649.434918987s] Trained 128 records in 0.086097833 seconds. Throughput is 1486.6808 records/second. Loss is 0.19871381. Sequential31006cbd's hyper parameters: Current learning rate is 0.004161118508655127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 57856/60000][Iteration 7018][Wall Clock 649.520704122s] Trained 128 records in 0.085785135 seconds. Throughput is 1492.1 records/second. Loss is 0.1896194. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041607722393276194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 57984/60000][Iteration 7019][Wall Clock 649.606271648s] Trained 128 records in 0.085567526 seconds. Throughput is 1495.8945 records/second. Loss is 0.21420613. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041604260276252285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58112/60000][Iteration 7020][Wall Clock 649.685411975s] Trained 128 records in 0.079140327 seconds. Throughput is 1617.3802 records/second. Loss is 0.17144868. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041600798735335716. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58240/60000][Iteration 7021][Wall Clock 649.75898101s] Trained 128 records in 0.073569035 seconds. Throughput is 1739.8624 records/second. Loss is 0.18104342. Sequential31006cbd's hyper parameters: Current learning rate is 0.00415973377703827. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58368/60000][Iteration 7022][Wall Clock 649.838754032s] Trained 128 records in 0.079773022 seconds. Throughput is 1604.5525 records/second. Loss is 0.20399219. Sequential31006cbd's hyper parameters: Current learning rate is 0.004159387738124947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58496/60000][Iteration 7023][Wall Clock 649.917025061s] Trained 128 records in 0.078271029 seconds. Throughput is 1635.3433 records/second. Loss is 0.20419577. Sequential31006cbd's hyper parameters: Current learning rate is 0.004159041756779239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58624/60000][Iteration 7024][Wall Clock 650.000008992s] Trained 128 records in 0.082983931 seconds. Throughput is 1542.4673 records/second. Loss is 0.26108345. Sequential31006cbd's hyper parameters: Current learning rate is 0.004158695832986775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58752/60000][Iteration 7025][Wall Clock 650.080372025s] Trained 128 records in 0.080363033 seconds. Throughput is 1592.7721 records/second. Loss is 0.17389175. Sequential31006cbd's hyper parameters: Current learning rate is 0.004158349966733201. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 58880/60000][Iteration 7026][Wall Clock 650.154183771s] Trained 128 records in 0.073811746 seconds. Throughput is 1734.1414 records/second. Loss is 0.12447716. Sequential31006cbd's hyper parameters: Current learning rate is 0.004158004158004157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 59008/60000][Iteration 7027][Wall Clock 650.22374473s] Trained 128 records in 0.069560959 seconds. Throughput is 1840.1127 records/second. Loss is 0.08871477. Sequential31006cbd's hyper parameters: Current learning rate is 0.004157658406785299. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 59136/60000][Iteration 7028][Wall Clock 650.29564521s] Trained 128 records in 0.07190048 seconds. Throughput is 1780.2385 records/second. Loss is 0.21753234. Sequential31006cbd's hyper parameters: Current learning rate is 0.004157312713062277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:27 INFO  DistriOptimizer$:408 - [Epoch 15 59264/60000][Iteration 7029][Wall Clock 650.370854506s] Trained 128 records in 0.075209296 seconds. Throughput is 1701.9172 records/second. Loss is 0.12564993. Sequential31006cbd's hyper parameters: Current learning rate is 0.004156967076820752. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:408 - [Epoch 15 59392/60000][Iteration 7030][Wall Clock 650.447430122s] Trained 128 records in 0.076575616 seconds. Throughput is 1671.5504 records/second. Loss is 0.20476621. Sequential31006cbd's hyper parameters: Current learning rate is 0.004156621498046388. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:408 - [Epoch 15 59520/60000][Iteration 7031][Wall Clock 650.529670276s] Trained 128 records in 0.082240154 seconds. Throughput is 1556.4172 records/second. Loss is 0.11565704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004156275976724855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:408 - [Epoch 15 59648/60000][Iteration 7032][Wall Clock 650.617054511s] Trained 128 records in 0.087384235 seconds. Throughput is 1464.7952 records/second. Loss is 0.095165014. Sequential31006cbd's hyper parameters: Current learning rate is 0.004155930512841825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:408 - [Epoch 15 59776/60000][Iteration 7033][Wall Clock 650.698934855s] Trained 128 records in 0.081880344 seconds. Throughput is 1563.2567 records/second. Loss is 0.18539482. Sequential31006cbd's hyper parameters: Current learning rate is 0.004155585106382979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:408 - [Epoch 15 59904/60000][Iteration 7034][Wall Clock 650.777957958s] Trained 128 records in 0.079023103 seconds. Throughput is 1619.7795 records/second. Loss is 0.2130566. Sequential31006cbd's hyper parameters: Current learning rate is 0.004155239757333998. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:408 - [Epoch 15 60032/60000][Iteration 7035][Wall Clock 650.860364734s] Trained 128 records in 0.082406776 seconds. Throughput is 1553.2704 records/second. Loss is 0.13357526. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041548944656805715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:28 INFO  DistriOptimizer$:452 - [Epoch 15 60032/60000][Iteration 7035][Wall Clock 650.860364734s] Epoch finished. Wall clock time is 651993.775705 ms
2019-10-24 00:08:28 INFO  DistriOptimizer$:111 - [Epoch 15 60032/60000][Iteration 7035][Wall Clock 650.860364734s] Validate model...
2019-10-24 00:08:29 INFO  DistriOptimizer$:178 - [Epoch 15 60032/60000][Iteration 7035][Wall Clock 650.860364734s] validate model throughput is 11959.081 records/second
2019-10-24 00:08:29 INFO  DistriOptimizer$:181 - [Epoch 15 60032/60000][Iteration 7035][Wall Clock 650.860364734s] Top1Accuracy is Accuracy(correct: 9532, count: 10000, accuracy: 0.9532)
2019-10-24 00:08:29 INFO  DistriOptimizer$:221 - [Wall Clock 651.993775705s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:08:29 INFO  DistriOptimizer$:226 - [Wall Clock 651.993775705s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 128/60000][Iteration 7036][Wall Clock 652.07893521s] Trained 128 records in 0.085159505 seconds. Throughput is 1503.0619 records/second. Loss is 0.173913. Sequential31006cbd's hyper parameters: Current learning rate is 0.004154549231408392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 256/60000][Iteration 7037][Wall Clock 652.160354504s] Trained 128 records in 0.081419294 seconds. Throughput is 1572.1089 records/second. Loss is 0.09473695. Sequential31006cbd's hyper parameters: Current learning rate is 0.004154204054503157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 384/60000][Iteration 7038][Wall Clock 652.241074398s] Trained 128 records in 0.080719894 seconds. Throughput is 1585.7305 records/second. Loss is 0.108005375. Sequential31006cbd's hyper parameters: Current learning rate is 0.004153858934950569. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 512/60000][Iteration 7039][Wall Clock 652.322070989s] Trained 128 records in 0.080996591 seconds. Throughput is 1580.3135 records/second. Loss is 0.11864893. Sequential31006cbd's hyper parameters: Current learning rate is 0.004153513872736335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 640/60000][Iteration 7040][Wall Clock 652.399466553s] Trained 128 records in 0.077395564 seconds. Throughput is 1653.8416 records/second. Loss is 0.11325285. Sequential31006cbd's hyper parameters: Current learning rate is 0.004153168867846167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 768/60000][Iteration 7041][Wall Clock 652.476821473s] Trained 128 records in 0.07735492 seconds. Throughput is 1654.7104 records/second. Loss is 0.16759822. Sequential31006cbd's hyper parameters: Current learning rate is 0.00415282392026578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:29 INFO  DistriOptimizer$:408 - [Epoch 16 896/60000][Iteration 7042][Wall Clock 652.552165329s] Trained 128 records in 0.075343856 seconds. Throughput is 1698.8778 records/second. Loss is 0.1549134. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041524790299808986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1024/60000][Iteration 7043][Wall Clock 652.622106633s] Trained 128 records in 0.069941304 seconds. Throughput is 1830.106 records/second. Loss is 0.09756747. Sequential31006cbd's hyper parameters: Current learning rate is 0.004152134196977246. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1152/60000][Iteration 7044][Wall Clock 652.699724802s] Trained 128 records in 0.077618169 seconds. Throughput is 1649.0985 records/second. Loss is 0.15365349. Sequential31006cbd's hyper parameters: Current learning rate is 0.004151789421240555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1280/60000][Iteration 7045][Wall Clock 652.785911175s] Trained 128 records in 0.086186373 seconds. Throughput is 1485.1536 records/second. Loss is 0.14637324. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041514447027565585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1408/60000][Iteration 7046][Wall Clock 652.878778103s] Trained 128 records in 0.092866928 seconds. Throughput is 1378.3163 records/second. Loss is 0.14869408. Sequential31006cbd's hyper parameters: Current learning rate is 0.004151100041511001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1536/60000][Iteration 7047][Wall Clock 652.975724844s] Trained 128 records in 0.096946741 seconds. Throughput is 1320.3126 records/second. Loss is 0.17618284. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041507554374896225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1664/60000][Iteration 7048][Wall Clock 653.059011285s] Trained 128 records in 0.083286441 seconds. Throughput is 1536.8647 records/second. Loss is 0.2861612. Sequential31006cbd's hyper parameters: Current learning rate is 0.004150410890678177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1792/60000][Iteration 7049][Wall Clock 653.13163368s] Trained 128 records in 0.072622395 seconds. Throughput is 1762.5416 records/second. Loss is 0.2272951. Sequential31006cbd's hyper parameters: Current learning rate is 0.004150066401062417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 1920/60000][Iteration 7050][Wall Clock 653.208557355s] Trained 128 records in 0.076923675 seconds. Throughput is 1663.987 records/second. Loss is 0.17939824. Sequential31006cbd's hyper parameters: Current learning rate is 0.004149721968628102. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 2048/60000][Iteration 7051][Wall Clock 653.28959153s] Trained 128 records in 0.081034175 seconds. Throughput is 1579.5804 records/second. Loss is 0.13471788. Sequential31006cbd's hyper parameters: Current learning rate is 0.004149377593360996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 2176/60000][Iteration 7052][Wall Clock 653.375702944s] Trained 128 records in 0.086111414 seconds. Throughput is 1486.4464 records/second. Loss is 0.24022833. Sequential31006cbd's hyper parameters: Current learning rate is 0.004149033275246868. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 2304/60000][Iteration 7053][Wall Clock 653.461295073s] Trained 128 records in 0.085592129 seconds. Throughput is 1495.4646 records/second. Loss is 0.17681605. Sequential31006cbd's hyper parameters: Current learning rate is 0.00414868901427149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:30 INFO  DistriOptimizer$:408 - [Epoch 16 2432/60000][Iteration 7054][Wall Clock 653.539045476s] Trained 128 records in 0.077750403 seconds. Throughput is 1646.2938 records/second. Loss is 0.21839358. Sequential31006cbd's hyper parameters: Current learning rate is 0.004148344810420642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 2560/60000][Iteration 7055][Wall Clock 653.616769019s] Trained 128 records in 0.077723543 seconds. Throughput is 1646.8627 records/second. Loss is 0.18240033. Sequential31006cbd's hyper parameters: Current learning rate is 0.004148000663680106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 2688/60000][Iteration 7056][Wall Clock 653.692779234s] Trained 128 records in 0.076010215 seconds. Throughput is 1683.9843 records/second. Loss is 0.14914006. Sequential31006cbd's hyper parameters: Current learning rate is 0.00414765657403567. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 2816/60000][Iteration 7057][Wall Clock 653.769580118s] Trained 128 records in 0.076800884 seconds. Throughput is 1666.6475 records/second. Loss is 0.15126756. Sequential31006cbd's hyper parameters: Current learning rate is 0.004147312541473125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 2944/60000][Iteration 7058][Wall Clock 653.849787099s] Trained 128 records in 0.080206981 seconds. Throughput is 1595.871 records/second. Loss is 0.13985828. Sequential31006cbd's hyper parameters: Current learning rate is 0.00414696856597827. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3072/60000][Iteration 7059][Wall Clock 653.933550786s] Trained 128 records in 0.083763687 seconds. Throughput is 1528.1084 records/second. Loss is 0.16387871. Sequential31006cbd's hyper parameters: Current learning rate is 0.004146624647536905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3200/60000][Iteration 7060][Wall Clock 654.016759127s] Trained 128 records in 0.083208341 seconds. Throughput is 1538.3074 records/second. Loss is 0.118918404. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041462807861348365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3328/60000][Iteration 7061][Wall Clock 654.103764562s] Trained 128 records in 0.087005435 seconds. Throughput is 1471.1725 records/second. Loss is 0.14830253. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041459369817578775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3456/60000][Iteration 7062][Wall Clock 654.19802319s] Trained 128 records in 0.094258628 seconds. Throughput is 1357.9658 records/second. Loss is 0.15178981. Sequential31006cbd's hyper parameters: Current learning rate is 0.004145593234391841. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3584/60000][Iteration 7063][Wall Clock 654.272299739s] Trained 128 records in 0.074276549 seconds. Throughput is 1723.2894 records/second. Loss is 0.22624452. Sequential31006cbd's hyper parameters: Current learning rate is 0.00414524954402255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3712/60000][Iteration 7064][Wall Clock 654.34669382s] Trained 128 records in 0.074394081 seconds. Throughput is 1720.5669 records/second. Loss is 0.087477826. Sequential31006cbd's hyper parameters: Current learning rate is 0.004144905910635828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3840/60000][Iteration 7065][Wall Clock 654.423683495s] Trained 128 records in 0.076989675 seconds. Throughput is 1662.5607 records/second. Loss is 0.1878777. Sequential31006cbd's hyper parameters: Current learning rate is 0.004144562334217507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 3968/60000][Iteration 7066][Wall Clock 654.495942717s] Trained 128 records in 0.072259222 seconds. Throughput is 1771.4001 records/second. Loss is 0.2445941. Sequential31006cbd's hyper parameters: Current learning rate is 0.004144218814753418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:31 INFO  DistriOptimizer$:408 - [Epoch 16 4096/60000][Iteration 7067][Wall Clock 654.572141034s] Trained 128 records in 0.076198317 seconds. Throughput is 1679.8271 records/second. Loss is 0.18000454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004143875352229405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4224/60000][Iteration 7068][Wall Clock 654.654558256s] Trained 128 records in 0.082417222 seconds. Throughput is 1553.0735 records/second. Loss is 0.19379455. Sequential31006cbd's hyper parameters: Current learning rate is 0.004143531946631308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4352/60000][Iteration 7069][Wall Clock 654.743076259s] Trained 128 records in 0.088518003 seconds. Throughput is 1446.0336 records/second. Loss is 0.1481924. Sequential31006cbd's hyper parameters: Current learning rate is 0.004143188597944979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4480/60000][Iteration 7070][Wall Clock 654.827099511s] Trained 128 records in 0.084023252 seconds. Throughput is 1523.3878 records/second. Loss is 0.16306736. Sequential31006cbd's hyper parameters: Current learning rate is 0.004142845306156268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4608/60000][Iteration 7071][Wall Clock 654.91993882s] Trained 128 records in 0.092839309 seconds. Throughput is 1378.7263 records/second. Loss is 0.22238135. Sequential31006cbd's hyper parameters: Current learning rate is 0.004142502071251036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4736/60000][Iteration 7072][Wall Clock 655.014014664s] Trained 128 records in 0.094075844 seconds. Throughput is 1360.6044 records/second. Loss is 0.20123231. Sequential31006cbd's hyper parameters: Current learning rate is 0.004142158893215143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4864/60000][Iteration 7073][Wall Clock 655.090424s] Trained 128 records in 0.076409336 seconds. Throughput is 1675.188 records/second. Loss is 0.18257521. Sequential31006cbd's hyper parameters: Current learning rate is 0.00414181577203446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 4992/60000][Iteration 7074][Wall Clock 655.163475661s] Trained 128 records in 0.073051661 seconds. Throughput is 1752.1847 records/second. Loss is 0.18211453. Sequential31006cbd's hyper parameters: Current learning rate is 0.004141472707694856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 5120/60000][Iteration 7075][Wall Clock 655.260620546s] Trained 128 records in 0.097144885 seconds. Throughput is 1317.6195 records/second. Loss is 0.14962621. Sequential31006cbd's hyper parameters: Current learning rate is 0.004141129700182209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 5248/60000][Iteration 7076][Wall Clock 655.337880103s] Trained 128 records in 0.077259557 seconds. Throughput is 1656.753 records/second. Loss is 0.2302507. Sequential31006cbd's hyper parameters: Current learning rate is 0.004140786749482402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 5376/60000][Iteration 7077][Wall Clock 655.412432883s] Trained 128 records in 0.07455278 seconds. Throughput is 1716.9044 records/second. Loss is 0.2356984. Sequential31006cbd's hyper parameters: Current learning rate is 0.004140443855581318. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 5504/60000][Iteration 7078][Wall Clock 655.496587766s] Trained 128 records in 0.084154883 seconds. Throughput is 1521.005 records/second. Loss is 0.14646189. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041401010184648505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:32 INFO  DistriOptimizer$:408 - [Epoch 16 5632/60000][Iteration 7079][Wall Clock 655.572499269s] Trained 128 records in 0.075911503 seconds. Throughput is 1686.1741 records/second. Loss is 0.1586873. Sequential31006cbd's hyper parameters: Current learning rate is 0.004139758238118894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 5760/60000][Iteration 7080][Wall Clock 655.64524689s] Trained 128 records in 0.072747621 seconds. Throughput is 1759.5078 records/second. Loss is 0.14813435. Sequential31006cbd's hyper parameters: Current learning rate is 0.004139415514529348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 5888/60000][Iteration 7081][Wall Clock 655.721911294s] Trained 128 records in 0.076664404 seconds. Throughput is 1669.6145 records/second. Loss is 0.21929887. Sequential31006cbd's hyper parameters: Current learning rate is 0.004139072847682119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6016/60000][Iteration 7082][Wall Clock 655.803598262s] Trained 128 records in 0.081686968 seconds. Throughput is 1566.9574 records/second. Loss is 0.18483135. Sequential31006cbd's hyper parameters: Current learning rate is 0.004138730237563116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6144/60000][Iteration 7083][Wall Clock 655.886462834s] Trained 128 records in 0.082864572 seconds. Throughput is 1544.6891 records/second. Loss is 0.1997473. Sequential31006cbd's hyper parameters: Current learning rate is 0.004138387684158251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6272/60000][Iteration 7084][Wall Clock 655.968014247s] Trained 128 records in 0.081551413 seconds. Throughput is 1569.562 records/second. Loss is 0.11523707. Sequential31006cbd's hyper parameters: Current learning rate is 0.004138045187453448. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6400/60000][Iteration 7085][Wall Clock 656.08939019s] Trained 128 records in 0.121375943 seconds. Throughput is 1054.5747 records/second. Loss is 0.16178033. Sequential31006cbd's hyper parameters: Current learning rate is 0.004137702747434624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6528/60000][Iteration 7086][Wall Clock 656.175373011s] Trained 128 records in 0.085982821 seconds. Throughput is 1488.6694 records/second. Loss is 0.18274772. Sequential31006cbd's hyper parameters: Current learning rate is 0.004137360364087713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6656/60000][Iteration 7087][Wall Clock 656.257435212s] Trained 128 records in 0.082062201 seconds. Throughput is 1559.7925 records/second. Loss is 0.22560233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041370180373986425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6784/60000][Iteration 7088][Wall Clock 656.337466845s] Trained 128 records in 0.080031633 seconds. Throughput is 1599.3676 records/second. Loss is 0.16225065. Sequential31006cbd's hyper parameters: Current learning rate is 0.004136675767353356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 6912/60000][Iteration 7089][Wall Clock 656.410244787s] Trained 128 records in 0.072777942 seconds. Throughput is 1758.7747 records/second. Loss is 0.1520348. Sequential31006cbd's hyper parameters: Current learning rate is 0.00413633355393779. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 7040/60000][Iteration 7090][Wall Clock 656.48863775s] Trained 128 records in 0.078392963 seconds. Throughput is 1632.7997 records/second. Loss is 0.29772767. Sequential31006cbd's hyper parameters: Current learning rate is 0.004135991397137894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:33 INFO  DistriOptimizer$:408 - [Epoch 16 7168/60000][Iteration 7091][Wall Clock 656.57451365s] Trained 128 records in 0.0858759 seconds. Throughput is 1490.523 records/second. Loss is 0.11730952. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041356492969396195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 7296/60000][Iteration 7092][Wall Clock 656.65418098s] Trained 128 records in 0.07966733 seconds. Throughput is 1606.6812 records/second. Loss is 0.12422316. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041353072533289225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 7424/60000][Iteration 7093][Wall Clock 656.734007623s] Trained 128 records in 0.079826643 seconds. Throughput is 1603.4746 records/second. Loss is 0.16273944. Sequential31006cbd's hyper parameters: Current learning rate is 0.004134965266291763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 7552/60000][Iteration 7094][Wall Clock 656.817596033s] Trained 128 records in 0.08358841 seconds. Throughput is 1531.3129 records/second. Loss is 0.26702377. Sequential31006cbd's hyper parameters: Current learning rate is 0.004134623335814107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 7680/60000][Iteration 7095][Wall Clock 656.896576313s] Trained 128 records in 0.07898028 seconds. Throughput is 1620.6577 records/second. Loss is 0.13980675. Sequential31006cbd's hyper parameters: Current learning rate is 0.004134281461881925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 7808/60000][Iteration 7096][Wall Clock 656.974941292s] Trained 128 records in 0.078364979 seconds. Throughput is 1633.3828 records/second. Loss is 0.17860693. Sequential31006cbd's hyper parameters: Current learning rate is 0.00413393964448119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 7936/60000][Iteration 7097][Wall Clock 657.063907695s] Trained 128 records in 0.088966403 seconds. Throughput is 1438.7455 records/second. Loss is 0.15160157. Sequential31006cbd's hyper parameters: Current learning rate is 0.004133597883597883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 8064/60000][Iteration 7098][Wall Clock 657.146645131s] Trained 128 records in 0.082737436 seconds. Throughput is 1547.0626 records/second. Loss is 0.19626729. Sequential31006cbd's hyper parameters: Current learning rate is 0.004133256179217988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 8192/60000][Iteration 7099][Wall Clock 657.236972322s] Trained 128 records in 0.090327191 seconds. Throughput is 1417.0706 records/second. Loss is 0.1304751. Sequential31006cbd's hyper parameters: Current learning rate is 0.004132914531327492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 8320/60000][Iteration 7100][Wall Clock 657.316755073s] Trained 128 records in 0.079782751 seconds. Throughput is 1604.3567 records/second. Loss is 0.16606918. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041325729399123885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 8448/60000][Iteration 7101][Wall Clock 657.395397698s] Trained 128 records in 0.078642625 seconds. Throughput is 1627.6161 records/second. Loss is 0.19653504. Sequential31006cbd's hyper parameters: Current learning rate is 0.004132231404958678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 8576/60000][Iteration 7102][Wall Clock 657.48691343s] Trained 128 records in 0.091515732 seconds. Throughput is 1398.6666 records/second. Loss is 0.066369094. Sequential31006cbd's hyper parameters: Current learning rate is 0.004131889926452359. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:34 INFO  DistriOptimizer$:408 - [Epoch 16 8704/60000][Iteration 7103][Wall Clock 657.565670222s] Trained 128 records in 0.078756792 seconds. Throughput is 1625.2566 records/second. Loss is 0.18427043. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041315485043794415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 8832/60000][Iteration 7104][Wall Clock 657.642757101s] Trained 128 records in 0.077086879 seconds. Throughput is 1660.4641 records/second. Loss is 0.19651201. Sequential31006cbd's hyper parameters: Current learning rate is 0.004131207138725936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 8960/60000][Iteration 7105][Wall Clock 657.715462416s] Trained 128 records in 0.072705315 seconds. Throughput is 1760.5316 records/second. Loss is 0.14883217. Sequential31006cbd's hyper parameters: Current learning rate is 0.004130865829477859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9088/60000][Iteration 7106][Wall Clock 657.799729756s] Trained 128 records in 0.08426734 seconds. Throughput is 1518.9752 records/second. Loss is 0.14023721. Sequential31006cbd's hyper parameters: Current learning rate is 0.004130524576621231. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9216/60000][Iteration 7107][Wall Clock 657.888353046s] Trained 128 records in 0.08862329 seconds. Throughput is 1444.3156 records/second. Loss is 0.24148093. Sequential31006cbd's hyper parameters: Current learning rate is 0.004130183380142078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9344/60000][Iteration 7108][Wall Clock 657.976493905s] Trained 128 records in 0.088140859 seconds. Throughput is 1452.221 records/second. Loss is 0.19614197. Sequential31006cbd's hyper parameters: Current learning rate is 0.004129842240026431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9472/60000][Iteration 7109][Wall Clock 658.056019637s] Trained 128 records in 0.079525732 seconds. Throughput is 1609.542 records/second. Loss is 0.11779477. Sequential31006cbd's hyper parameters: Current learning rate is 0.004129501156260324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9600/60000][Iteration 7110][Wall Clock 658.141687772s] Trained 128 records in 0.085668135 seconds. Throughput is 1494.1378 records/second. Loss is 0.1483478. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041291601288297956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9728/60000][Iteration 7111][Wall Clock 658.234361643s] Trained 128 records in 0.092673871 seconds. Throughput is 1381.1876 records/second. Loss is 0.18945757. Sequential31006cbd's hyper parameters: Current learning rate is 0.004128819157720892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9856/60000][Iteration 7112][Wall Clock 658.312193055s] Trained 128 records in 0.077831412 seconds. Throughput is 1644.5802 records/second. Loss is 0.12386323. Sequential31006cbd's hyper parameters: Current learning rate is 0.00412847824291966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 9984/60000][Iteration 7113][Wall Clock 658.389824877s] Trained 128 records in 0.077631822 seconds. Throughput is 1648.8083 records/second. Loss is 0.18066694. Sequential31006cbd's hyper parameters: Current learning rate is 0.004128137384412153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 10112/60000][Iteration 7114][Wall Clock 658.468413053s] Trained 128 records in 0.078588176 seconds. Throughput is 1628.7438 records/second. Loss is 0.13021237. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041277965821844296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:35 INFO  DistriOptimizer$:408 - [Epoch 16 10240/60000][Iteration 7115][Wall Clock 658.556603495s] Trained 128 records in 0.088190442 seconds. Throughput is 1451.4044 records/second. Loss is 0.1187447. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041274558362225525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 10368/60000][Iteration 7116][Wall Clock 658.641720636s] Trained 128 records in 0.085117141 seconds. Throughput is 1503.8099 records/second. Loss is 0.11355139. Sequential31006cbd's hyper parameters: Current learning rate is 0.004127115146512587. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 10496/60000][Iteration 7117][Wall Clock 658.716710467s] Trained 128 records in 0.074989831 seconds. Throughput is 1706.8981 records/second. Loss is 0.14993483. Sequential31006cbd's hyper parameters: Current learning rate is 0.004126774513040607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 10624/60000][Iteration 7118][Wall Clock 658.791189761s] Trained 128 records in 0.074479294 seconds. Throughput is 1718.5984 records/second. Loss is 0.1536838. Sequential31006cbd's hyper parameters: Current learning rate is 0.004126433935792688. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 10752/60000][Iteration 7119][Wall Clock 658.870128891s] Trained 128 records in 0.07893913 seconds. Throughput is 1621.5024 records/second. Loss is 0.23942795. Sequential31006cbd's hyper parameters: Current learning rate is 0.00412609341475491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 10880/60000][Iteration 7120][Wall Clock 658.956374967s] Trained 128 records in 0.086246076 seconds. Throughput is 1484.1255 records/second. Loss is 0.1926401. Sequential31006cbd's hyper parameters: Current learning rate is 0.00412575294991336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11008/60000][Iteration 7121][Wall Clock 659.037799184s] Trained 128 records in 0.081424217 seconds. Throughput is 1572.0139 records/second. Loss is 0.13619673. Sequential31006cbd's hyper parameters: Current learning rate is 0.004125412541254125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11136/60000][Iteration 7122][Wall Clock 659.118834066s] Trained 128 records in 0.081034882 seconds. Throughput is 1579.5667 records/second. Loss is 0.25684083. Sequential31006cbd's hyper parameters: Current learning rate is 0.004125072188763303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11264/60000][Iteration 7123][Wall Clock 659.212726588s] Trained 128 records in 0.093892522 seconds. Throughput is 1363.2609 records/second. Loss is 0.13842458. Sequential31006cbd's hyper parameters: Current learning rate is 0.004124731892426992. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11392/60000][Iteration 7124][Wall Clock 659.286083374s] Trained 128 records in 0.073356786 seconds. Throughput is 1744.8965 records/second. Loss is 0.11039387. Sequential31006cbd's hyper parameters: Current learning rate is 0.004124391652231297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11520/60000][Iteration 7125][Wall Clock 659.363460384s] Trained 128 records in 0.07737701 seconds. Throughput is 1654.2382 records/second. Loss is 0.20999306. Sequential31006cbd's hyper parameters: Current learning rate is 0.004124051468162322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11648/60000][Iteration 7126][Wall Clock 659.436787172s] Trained 128 records in 0.073326788 seconds. Throughput is 1745.6104 records/second. Loss is 0.22308624. Sequential31006cbd's hyper parameters: Current learning rate is 0.004123711340206186. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:36 INFO  DistriOptimizer$:408 - [Epoch 16 11776/60000][Iteration 7127][Wall Clock 659.510119505s] Trained 128 records in 0.073332333 seconds. Throughput is 1745.4784 records/second. Loss is 0.10091167. Sequential31006cbd's hyper parameters: Current learning rate is 0.004123371268349002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 11904/60000][Iteration 7128][Wall Clock 659.587145093s] Trained 128 records in 0.077025588 seconds. Throughput is 1661.7855 records/second. Loss is 0.1421644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004123031252576895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12032/60000][Iteration 7129][Wall Clock 659.668737586s] Trained 128 records in 0.081592493 seconds. Throughput is 1568.7717 records/second. Loss is 0.16592747. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041226912928759895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12160/60000][Iteration 7130][Wall Clock 659.743544451s] Trained 128 records in 0.074806865 seconds. Throughput is 1711.073 records/second. Loss is 0.20551935. Sequential31006cbd's hyper parameters: Current learning rate is 0.004122351389232418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12288/60000][Iteration 7131][Wall Clock 659.819465757s] Trained 128 records in 0.075921306 seconds. Throughput is 1685.9563 records/second. Loss is 0.21546963. Sequential31006cbd's hyper parameters: Current learning rate is 0.004122011541632316. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12416/60000][Iteration 7132][Wall Clock 659.916078516s] Trained 128 records in 0.096612759 seconds. Throughput is 1324.8768 records/second. Loss is 0.22767621. Sequential31006cbd's hyper parameters: Current learning rate is 0.004121671750061825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12544/60000][Iteration 7133][Wall Clock 660.005385727s] Trained 128 records in 0.089307211 seconds. Throughput is 1433.2549 records/second. Loss is 0.17071414. Sequential31006cbd's hyper parameters: Current learning rate is 0.004121332014507088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12672/60000][Iteration 7134][Wall Clock 660.085927277s] Trained 128 records in 0.08054155 seconds. Throughput is 1589.2418 records/second. Loss is 0.21358337. Sequential31006cbd's hyper parameters: Current learning rate is 0.004120992334954257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12800/60000][Iteration 7135][Wall Clock 660.167791505s] Trained 128 records in 0.081864228 seconds. Throughput is 1563.5645 records/second. Loss is 0.18525633. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041206527113894845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 12928/60000][Iteration 7136][Wall Clock 660.242263878s] Trained 128 records in 0.074472373 seconds. Throughput is 1718.7582 records/second. Loss is 0.09099393. Sequential31006cbd's hyper parameters: Current learning rate is 0.004120313143798929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 13056/60000][Iteration 7137][Wall Clock 660.331393489s] Trained 128 records in 0.089129611 seconds. Throughput is 1436.1108 records/second. Loss is 0.16065863. Sequential31006cbd's hyper parameters: Current learning rate is 0.004119973632168754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 13184/60000][Iteration 7138][Wall Clock 660.418661404s] Trained 128 records in 0.087267915 seconds. Throughput is 1466.7476 records/second. Loss is 0.08998366. Sequential31006cbd's hyper parameters: Current learning rate is 0.004119634176485128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:37 INFO  DistriOptimizer$:408 - [Epoch 16 13312/60000][Iteration 7139][Wall Clock 660.49914147s] Trained 128 records in 0.080480066 seconds. Throughput is 1590.4559 records/second. Loss is 0.08703475. Sequential31006cbd's hyper parameters: Current learning rate is 0.004119294776734223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 13440/60000][Iteration 7140][Wall Clock 660.581776628s] Trained 128 records in 0.082635158 seconds. Throughput is 1548.9775 records/second. Loss is 0.14563301. Sequential31006cbd's hyper parameters: Current learning rate is 0.004118955432902216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 13568/60000][Iteration 7141][Wall Clock 660.65976557s] Trained 128 records in 0.077988942 seconds. Throughput is 1641.2583 records/second. Loss is 0.209485. Sequential31006cbd's hyper parameters: Current learning rate is 0.004118616144975288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 13696/60000][Iteration 7142][Wall Clock 660.745972517s] Trained 128 records in 0.086206947 seconds. Throughput is 1484.7991 records/second. Loss is 0.11442999. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041182769129396255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 13824/60000][Iteration 7143][Wall Clock 660.824013922s] Trained 128 records in 0.078041405 seconds. Throughput is 1640.155 records/second. Loss is 0.13294244. Sequential31006cbd's hyper parameters: Current learning rate is 0.00411793773678142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 13952/60000][Iteration 7144][Wall Clock 660.899862319s] Trained 128 records in 0.075848397 seconds. Throughput is 1687.5768 records/second. Loss is 0.122289345. Sequential31006cbd's hyper parameters: Current learning rate is 0.004117598616486864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14080/60000][Iteration 7145][Wall Clock 660.976828556s] Trained 128 records in 0.076966237 seconds. Throughput is 1663.067 records/second. Loss is 0.24538343. Sequential31006cbd's hyper parameters: Current learning rate is 0.004117259552042161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14208/60000][Iteration 7146][Wall Clock 661.056828711s] Trained 128 records in 0.080000155 seconds. Throughput is 1599.997 records/second. Loss is 0.1907408. Sequential31006cbd's hyper parameters: Current learning rate is 0.004116920543433511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14336/60000][Iteration 7147][Wall Clock 661.136888526s] Trained 128 records in 0.080059815 seconds. Throughput is 1598.8047 records/second. Loss is 0.26264778. Sequential31006cbd's hyper parameters: Current learning rate is 0.004116581590647127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14464/60000][Iteration 7148][Wall Clock 661.22268522s] Trained 128 records in 0.085796694 seconds. Throughput is 1491.899 records/second. Loss is 0.12542102. Sequential31006cbd's hyper parameters: Current learning rate is 0.004116242693669218. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14592/60000][Iteration 7149][Wall Clock 661.298506337s] Trained 128 records in 0.075821117 seconds. Throughput is 1688.1841 records/second. Loss is 0.1442602. Sequential31006cbd's hyper parameters: Current learning rate is 0.004115903852486006. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14720/60000][Iteration 7150][Wall Clock 661.376398605s] Trained 128 records in 0.077892268 seconds. Throughput is 1643.2954 records/second. Loss is 0.07377301. Sequential31006cbd's hyper parameters: Current learning rate is 0.00411556506708371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14848/60000][Iteration 7151][Wall Clock 661.457008301s] Trained 128 records in 0.080609696 seconds. Throughput is 1587.8983 records/second. Loss is 0.21067601. Sequential31006cbd's hyper parameters: Current learning rate is 0.004115226337448559. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:38 INFO  DistriOptimizer$:408 - [Epoch 16 14976/60000][Iteration 7152][Wall Clock 661.533917472s] Trained 128 records in 0.076909171 seconds. Throughput is 1664.3009 records/second. Loss is 0.20783818. Sequential31006cbd's hyper parameters: Current learning rate is 0.004114887663566784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15104/60000][Iteration 7153][Wall Clock 661.614553204s] Trained 128 records in 0.080635732 seconds. Throughput is 1587.3856 records/second. Loss is 0.15314586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004114549045424621. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15232/60000][Iteration 7154][Wall Clock 661.692978527s] Trained 128 records in 0.078425323 seconds. Throughput is 1632.1259 records/second. Loss is 0.16642925. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041142104830083105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15360/60000][Iteration 7155][Wall Clock 661.771785942s] Trained 128 records in 0.078807415 seconds. Throughput is 1624.2126 records/second. Loss is 0.13001987. Sequential31006cbd's hyper parameters: Current learning rate is 0.004113871976304097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15488/60000][Iteration 7156][Wall Clock 661.847325533s] Trained 128 records in 0.075539591 seconds. Throughput is 1694.4757 records/second. Loss is 0.19736147. Sequential31006cbd's hyper parameters: Current learning rate is 0.004113533525298231. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15616/60000][Iteration 7157][Wall Clock 661.927234787s] Trained 128 records in 0.079909254 seconds. Throughput is 1601.8169 records/second. Loss is 0.13673295. Sequential31006cbd's hyper parameters: Current learning rate is 0.004113195129976966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15744/60000][Iteration 7158][Wall Clock 662.007536764s] Trained 128 records in 0.080301977 seconds. Throughput is 1593.9832 records/second. Loss is 0.1103518. Sequential31006cbd's hyper parameters: Current learning rate is 0.004112856790326561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 15872/60000][Iteration 7159][Wall Clock 662.08647523s] Trained 128 records in 0.078938466 seconds. Throughput is 1621.5161 records/second. Loss is 0.13082704. Sequential31006cbd's hyper parameters: Current learning rate is 0.004112518506333279. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 16000/60000][Iteration 7160][Wall Clock 662.161968598s] Trained 128 records in 0.075493368 seconds. Throughput is 1695.5132 records/second. Loss is 0.16117625. Sequential31006cbd's hyper parameters: Current learning rate is 0.004112180277983387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 16128/60000][Iteration 7161][Wall Clock 662.239836939s] Trained 128 records in 0.077868341 seconds. Throughput is 1643.8003 records/second. Loss is 0.13018599. Sequential31006cbd's hyper parameters: Current learning rate is 0.004111842105263158. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 16256/60000][Iteration 7162][Wall Clock 662.321862149s] Trained 128 records in 0.08202521 seconds. Throughput is 1560.4958 records/second. Loss is 0.15172583. Sequential31006cbd's hyper parameters: Current learning rate is 0.004111503988158869. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 16384/60000][Iteration 7163][Wall Clock 662.40760425s] Trained 128 records in 0.085742101 seconds. Throughput is 1492.8489 records/second. Loss is 0.12588148. Sequential31006cbd's hyper parameters: Current learning rate is 0.004111165926656799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:39 INFO  DistriOptimizer$:408 - [Epoch 16 16512/60000][Iteration 7164][Wall Clock 662.487735877s] Trained 128 records in 0.080131627 seconds. Throughput is 1597.3718 records/second. Loss is 0.335181. Sequential31006cbd's hyper parameters: Current learning rate is 0.004110827920743238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 16640/60000][Iteration 7165][Wall Clock 662.573997006s] Trained 128 records in 0.086261129 seconds. Throughput is 1483.8665 records/second. Loss is 0.205697. Sequential31006cbd's hyper parameters: Current learning rate is 0.004110489970404472. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 16768/60000][Iteration 7166][Wall Clock 662.667211007s] Trained 128 records in 0.093214001 seconds. Throughput is 1373.1843 records/second. Loss is 0.17415452. Sequential31006cbd's hyper parameters: Current learning rate is 0.004110152075626799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 16896/60000][Iteration 7167][Wall Clock 662.753990316s] Trained 128 records in 0.086779309 seconds. Throughput is 1475.006 records/second. Loss is 0.12655604. Sequential31006cbd's hyper parameters: Current learning rate is 0.004109814236396514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17024/60000][Iteration 7168][Wall Clock 662.83164238s] Trained 128 records in 0.077652064 seconds. Throughput is 1648.3785 records/second. Loss is 0.20761421. Sequential31006cbd's hyper parameters: Current learning rate is 0.004109476452699926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17152/60000][Iteration 7169][Wall Clock 662.904457659s] Trained 128 records in 0.072815279 seconds. Throughput is 1757.8729 records/second. Loss is 0.23642378. Sequential31006cbd's hyper parameters: Current learning rate is 0.00410913872452334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17280/60000][Iteration 7170][Wall Clock 662.981417837s] Trained 128 records in 0.076960178 seconds. Throughput is 1663.1979 records/second. Loss is 0.16520683. Sequential31006cbd's hyper parameters: Current learning rate is 0.00410880105185307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17408/60000][Iteration 7171][Wall Clock 663.060191837s] Trained 128 records in 0.078774 seconds. Throughput is 1624.9016 records/second. Loss is 0.18113686. Sequential31006cbd's hyper parameters: Current learning rate is 0.004108463434675432. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17536/60000][Iteration 7172][Wall Clock 663.136912172s] Trained 128 records in 0.076720335 seconds. Throughput is 1668.3973 records/second. Loss is 0.17978886. Sequential31006cbd's hyper parameters: Current learning rate is 0.004108125872976748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17664/60000][Iteration 7173][Wall Clock 663.220604488s] Trained 128 records in 0.083692316 seconds. Throughput is 1529.4115 records/second. Loss is 0.087378375. Sequential31006cbd's hyper parameters: Current learning rate is 0.004107788366743345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17792/60000][Iteration 7174][Wall Clock 663.295133361s] Trained 128 records in 0.074528873 seconds. Throughput is 1717.4552 records/second. Loss is 0.10855142. Sequential31006cbd's hyper parameters: Current learning rate is 0.004107450915961554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 17920/60000][Iteration 7175][Wall Clock 663.367387334s] Trained 128 records in 0.072253973 seconds. Throughput is 1771.5289 records/second. Loss is 0.29151258. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041071135206177094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 18048/60000][Iteration 7176][Wall Clock 663.443584562s] Trained 128 records in 0.076197228 seconds. Throughput is 1679.8511 records/second. Loss is 0.19079357. Sequential31006cbd's hyper parameters: Current learning rate is 0.004106776180698152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:40 INFO  DistriOptimizer$:408 - [Epoch 16 18176/60000][Iteration 7177][Wall Clock 663.529786313s] Trained 128 records in 0.086201751 seconds. Throughput is 1484.8887 records/second. Loss is 0.12508939. Sequential31006cbd's hyper parameters: Current learning rate is 0.004106438896189225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 18304/60000][Iteration 7178][Wall Clock 663.611752505s] Trained 128 records in 0.081966192 seconds. Throughput is 1561.6195 records/second. Loss is 0.13197543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004106101667077277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 18432/60000][Iteration 7179][Wall Clock 663.692789741s] Trained 128 records in 0.081037236 seconds. Throughput is 1579.5208 records/second. Loss is 0.17508353. Sequential31006cbd's hyper parameters: Current learning rate is 0.004105764493348662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 18560/60000][Iteration 7180][Wall Clock 663.778542804s] Trained 128 records in 0.085753063 seconds. Throughput is 1492.6581 records/second. Loss is 0.14999121. Sequential31006cbd's hyper parameters: Current learning rate is 0.004105427374989736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 18688/60000][Iteration 7181][Wall Clock 663.855459389s] Trained 128 records in 0.076916585 seconds. Throughput is 1664.1405 records/second. Loss is 0.17206103. Sequential31006cbd's hyper parameters: Current learning rate is 0.004105090311986864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 18816/60000][Iteration 7182][Wall Clock 663.93438096s] Trained 128 records in 0.078921571 seconds. Throughput is 1621.8633 records/second. Loss is 0.2049604. Sequential31006cbd's hyper parameters: Current learning rate is 0.00410475330432641. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 18944/60000][Iteration 7183][Wall Clock 664.012826244s] Trained 128 records in 0.078445284 seconds. Throughput is 1631.7106 records/second. Loss is 0.09574726. Sequential31006cbd's hyper parameters: Current learning rate is 0.004104416351994746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 19072/60000][Iteration 7184][Wall Clock 664.093833163s] Trained 128 records in 0.081006919 seconds. Throughput is 1580.1119 records/second. Loss is 0.17657289. Sequential31006cbd's hyper parameters: Current learning rate is 0.004104079454978248. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 19200/60000][Iteration 7185][Wall Clock 664.174931047s] Trained 128 records in 0.081097884 seconds. Throughput is 1578.3396 records/second. Loss is 0.13998279. Sequential31006cbd's hyper parameters: Current learning rate is 0.0041037426132632965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 19328/60000][Iteration 7186][Wall Clock 664.257916883s] Trained 128 records in 0.082985836 seconds. Throughput is 1542.4319 records/second. Loss is 0.1676256. Sequential31006cbd's hyper parameters: Current learning rate is 0.004103405826836274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 19456/60000][Iteration 7187][Wall Clock 664.341424927s] Trained 128 records in 0.083508044 seconds. Throughput is 1532.7865 records/second. Loss is 0.20171925. Sequential31006cbd's hyper parameters: Current learning rate is 0.004103069095683571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 19584/60000][Iteration 7188][Wall Clock 664.423229817s] Trained 128 records in 0.08180489 seconds. Throughput is 1564.6987 records/second. Loss is 0.15620121. Sequential31006cbd's hyper parameters: Current learning rate is 0.004102732419791581. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:41 INFO  DistriOptimizer$:408 - [Epoch 16 19712/60000][Iteration 7189][Wall Clock 664.514164701s] Trained 128 records in 0.090934884 seconds. Throughput is 1407.6006 records/second. Loss is 0.15669993. Sequential31006cbd's hyper parameters: Current learning rate is 0.004102395799146702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 19840/60000][Iteration 7190][Wall Clock 664.590471277s] Trained 128 records in 0.076306576 seconds. Throughput is 1677.444 records/second. Loss is 0.26773736. Sequential31006cbd's hyper parameters: Current learning rate is 0.004102059233735335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 19968/60000][Iteration 7191][Wall Clock 664.665015298s] Trained 128 records in 0.074544021 seconds. Throughput is 1717.1062 records/second. Loss is 0.12185301. Sequential31006cbd's hyper parameters: Current learning rate is 0.004101722723543888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20096/60000][Iteration 7192][Wall Clock 664.740435987s] Trained 128 records in 0.075420689 seconds. Throughput is 1697.147 records/second. Loss is 0.12149353. Sequential31006cbd's hyper parameters: Current learning rate is 0.004101386268558773. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20224/60000][Iteration 7193][Wall Clock 664.825851724s] Trained 128 records in 0.085415737 seconds. Throughput is 1498.5529 records/second. Loss is 0.337261. Sequential31006cbd's hyper parameters: Current learning rate is 0.004101049868766404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20352/60000][Iteration 7194][Wall Clock 664.905476188s] Trained 128 records in 0.079624464 seconds. Throughput is 1607.5461 records/second. Loss is 0.16986379. Sequential31006cbd's hyper parameters: Current learning rate is 0.004100713524153202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20480/60000][Iteration 7195][Wall Clock 664.982715963s] Trained 128 records in 0.077239775 seconds. Throughput is 1657.1772 records/second. Loss is 0.09917374. Sequential31006cbd's hyper parameters: Current learning rate is 0.004100377234705593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20608/60000][Iteration 7196][Wall Clock 665.062523909s] Trained 128 records in 0.079807946 seconds. Throughput is 1603.8503 records/second. Loss is 0.14918435. Sequential31006cbd's hyper parameters: Current learning rate is 0.004100041000410004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20736/60000][Iteration 7197][Wall Clock 665.147691184s] Trained 128 records in 0.085167275 seconds. Throughput is 1502.9247 records/second. Loss is 0.16037956. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040997048212528696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20864/60000][Iteration 7198][Wall Clock 665.231839341s] Trained 128 records in 0.084148157 seconds. Throughput is 1521.1267 records/second. Loss is 0.13417706. Sequential31006cbd's hyper parameters: Current learning rate is 0.004099368697220628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 20992/60000][Iteration 7199][Wall Clock 665.312427778s] Trained 128 records in 0.080588437 seconds. Throughput is 1588.3171 records/second. Loss is 0.20803653. Sequential31006cbd's hyper parameters: Current learning rate is 0.004099032628299721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 21120/60000][Iteration 7200][Wall Clock 665.388540589s] Trained 128 records in 0.076112811 seconds. Throughput is 1681.7142 records/second. Loss is 0.17017895. Sequential31006cbd's hyper parameters: Current learning rate is 0.004098696614476597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 21248/60000][Iteration 7201][Wall Clock 665.467903111s] Trained 128 records in 0.079362522 seconds. Throughput is 1612.852 records/second. Loss is 0.22424297. Sequential31006cbd's hyper parameters: Current learning rate is 0.004098360655737704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:42 INFO  DistriOptimizer$:408 - [Epoch 16 21376/60000][Iteration 7202][Wall Clock 665.551020953s] Trained 128 records in 0.083117842 seconds. Throughput is 1539.9822 records/second. Loss is 0.14861158. Sequential31006cbd's hyper parameters: Current learning rate is 0.004098024752069503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 21504/60000][Iteration 7203][Wall Clock 665.630041602s] Trained 128 records in 0.079020649 seconds. Throughput is 1619.8297 records/second. Loss is 0.16619138. Sequential31006cbd's hyper parameters: Current learning rate is 0.004097688903458449. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 21632/60000][Iteration 7204][Wall Clock 665.705318235s] Trained 128 records in 0.075276633 seconds. Throughput is 1700.3948 records/second. Loss is 0.23235555. Sequential31006cbd's hyper parameters: Current learning rate is 0.004097353109891011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 21760/60000][Iteration 7205][Wall Clock 665.783053512s] Trained 128 records in 0.077735277 seconds. Throughput is 1646.6141 records/second. Loss is 0.15189478. Sequential31006cbd's hyper parameters: Current learning rate is 0.004097017371353654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 21888/60000][Iteration 7206][Wall Clock 665.868264854s] Trained 128 records in 0.085211342 seconds. Throughput is 1502.1475 records/second. Loss is 0.15322368. Sequential31006cbd's hyper parameters: Current learning rate is 0.004096681687832855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22016/60000][Iteration 7207][Wall Clock 665.953743344s] Trained 128 records in 0.08547849 seconds. Throughput is 1497.4528 records/second. Loss is 0.2258644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004096346059315091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22144/60000][Iteration 7208][Wall Clock 666.04751486s] Trained 128 records in 0.093771516 seconds. Throughput is 1365.02 records/second. Loss is 0.13641302. Sequential31006cbd's hyper parameters: Current learning rate is 0.004096010485786844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22272/60000][Iteration 7209][Wall Clock 666.140744991s] Trained 128 records in 0.093230131 seconds. Throughput is 1372.9468 records/second. Loss is 0.120812535. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040956749672346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22400/60000][Iteration 7210][Wall Clock 666.234815092s] Trained 128 records in 0.094070101 seconds. Throughput is 1360.6874 records/second. Loss is 0.19018781. Sequential31006cbd's hyper parameters: Current learning rate is 0.004095339503644852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22528/60000][Iteration 7211][Wall Clock 666.318226696s] Trained 128 records in 0.083411604 seconds. Throughput is 1534.5587 records/second. Loss is 0.20300227. Sequential31006cbd's hyper parameters: Current learning rate is 0.004095004095004095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22656/60000][Iteration 7212][Wall Clock 666.399282094s] Trained 128 records in 0.081055398 seconds. Throughput is 1579.167 records/second. Loss is 0.17332242. Sequential31006cbd's hyper parameters: Current learning rate is 0.004094668741298829. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:43 INFO  DistriOptimizer$:408 - [Epoch 16 22784/60000][Iteration 7213][Wall Clock 666.480783049s] Trained 128 records in 0.081500955 seconds. Throughput is 1570.5337 records/second. Loss is 0.19333005. Sequential31006cbd's hyper parameters: Current learning rate is 0.004094333442515558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 22912/60000][Iteration 7214][Wall Clock 666.558512381s] Trained 128 records in 0.077729332 seconds. Throughput is 1646.7401 records/second. Loss is 0.13059461. Sequential31006cbd's hyper parameters: Current learning rate is 0.004093998198640793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23040/60000][Iteration 7215][Wall Clock 666.643828645s] Trained 128 records in 0.085316264 seconds. Throughput is 1500.3002 records/second. Loss is 0.20210473. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040936630096610445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23168/60000][Iteration 7216][Wall Clock 666.721475322s] Trained 128 records in 0.077646677 seconds. Throughput is 1648.4929 records/second. Loss is 0.25037262. Sequential31006cbd's hyper parameters: Current learning rate is 0.004093327875562832. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23296/60000][Iteration 7217][Wall Clock 666.802534941s] Trained 128 records in 0.081059619 seconds. Throughput is 1579.0846 records/second. Loss is 0.10660766. Sequential31006cbd's hyper parameters: Current learning rate is 0.004092992796332679. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23424/60000][Iteration 7218][Wall Clock 666.897139175s] Trained 128 records in 0.094604234 seconds. Throughput is 1353.005 records/second. Loss is 0.14909074. Sequential31006cbd's hyper parameters: Current learning rate is 0.004092657771957109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23552/60000][Iteration 7219][Wall Clock 666.977803256s] Trained 128 records in 0.080664081 seconds. Throughput is 1586.8276 records/second. Loss is 0.17697781. Sequential31006cbd's hyper parameters: Current learning rate is 0.004092322802422655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23680/60000][Iteration 7220][Wall Clock 667.057924499s] Trained 128 records in 0.080121243 seconds. Throughput is 1597.5789 records/second. Loss is 0.21368474. Sequential31006cbd's hyper parameters: Current learning rate is 0.004091987887715852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23808/60000][Iteration 7221][Wall Clock 667.135496083s] Trained 128 records in 0.077571584 seconds. Throughput is 1650.0887 records/second. Loss is 0.2732608. Sequential31006cbd's hyper parameters: Current learning rate is 0.004091653027823241. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 23936/60000][Iteration 7222][Wall Clock 667.217341282s] Trained 128 records in 0.081845199 seconds. Throughput is 1563.928 records/second. Loss is 0.1861423. Sequential31006cbd's hyper parameters: Current learning rate is 0.004091318222731364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 24064/60000][Iteration 7223][Wall Clock 667.319555491s] Trained 128 records in 0.102214209 seconds. Throughput is 1252.2721 records/second. Loss is 0.26486248. Sequential31006cbd's hyper parameters: Current learning rate is 0.004090983472426772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 24192/60000][Iteration 7224][Wall Clock 667.40334352s] Trained 128 records in 0.083788029 seconds. Throughput is 1527.6646 records/second. Loss is 0.10688977. Sequential31006cbd's hyper parameters: Current learning rate is 0.004090648776896015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:44 INFO  DistriOptimizer$:408 - [Epoch 16 24320/60000][Iteration 7225][Wall Clock 667.490244749s] Trained 128 records in 0.086901229 seconds. Throughput is 1472.9365 records/second. Loss is 0.18017693. Sequential31006cbd's hyper parameters: Current learning rate is 0.004090314136125654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 24448/60000][Iteration 7226][Wall Clock 667.571009751s] Trained 128 records in 0.080765002 seconds. Throughput is 1584.8448 records/second. Loss is 0.1376093. Sequential31006cbd's hyper parameters: Current learning rate is 0.004089979550102249. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 24576/60000][Iteration 7227][Wall Clock 667.652686929s] Trained 128 records in 0.081677178 seconds. Throughput is 1567.1453 records/second. Loss is 0.20756395. Sequential31006cbd's hyper parameters: Current learning rate is 0.004089645018812368. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 24704/60000][Iteration 7228][Wall Clock 667.733942227s] Trained 128 records in 0.081255298 seconds. Throughput is 1575.282 records/second. Loss is 0.16420618. Sequential31006cbd's hyper parameters: Current learning rate is 0.004089310542242578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 24832/60000][Iteration 7229][Wall Clock 667.815484478s] Trained 128 records in 0.081542251 seconds. Throughput is 1569.7383 records/second. Loss is 0.22236064. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040889761203794575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 24960/60000][Iteration 7230][Wall Clock 667.897598165s] Trained 128 records in 0.082113687 seconds. Throughput is 1558.8143 records/second. Loss is 0.17748928. Sequential31006cbd's hyper parameters: Current learning rate is 0.004088641753209584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25088/60000][Iteration 7231][Wall Clock 667.975620896s] Trained 128 records in 0.078022731 seconds. Throughput is 1640.5475 records/second. Loss is 0.119068116. Sequential31006cbd's hyper parameters: Current learning rate is 0.004088307440719542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25216/60000][Iteration 7232][Wall Clock 668.056917741s] Trained 128 records in 0.081296845 seconds. Throughput is 1574.4768 records/second. Loss is 0.15723136. Sequential31006cbd's hyper parameters: Current learning rate is 0.00408797318289592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25344/60000][Iteration 7233][Wall Clock 668.13579333s] Trained 128 records in 0.078875589 seconds. Throughput is 1622.8088 records/second. Loss is 0.19135308. Sequential31006cbd's hyper parameters: Current learning rate is 0.004087638979725311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25472/60000][Iteration 7234][Wall Clock 668.214218089s] Trained 128 records in 0.078424759 seconds. Throughput is 1632.1376 records/second. Loss is 0.14916965. Sequential31006cbd's hyper parameters: Current learning rate is 0.00408730483119431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25600/60000][Iteration 7235][Wall Clock 668.291804849s] Trained 128 records in 0.07758676 seconds. Throughput is 1649.766 records/second. Loss is 0.106329694. Sequential31006cbd's hyper parameters: Current learning rate is 0.004086970737289521. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25728/60000][Iteration 7236][Wall Clock 668.371831592s] Trained 128 records in 0.080026743 seconds. Throughput is 1599.4652 records/second. Loss is 0.14299504. Sequential31006cbd's hyper parameters: Current learning rate is 0.004086636697997548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:45 INFO  DistriOptimizer$:408 - [Epoch 16 25856/60000][Iteration 7237][Wall Clock 668.451264047s] Trained 128 records in 0.079432455 seconds. Throughput is 1611.432 records/second. Loss is 0.18430966. Sequential31006cbd's hyper parameters: Current learning rate is 0.004086302713305002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 25984/60000][Iteration 7238][Wall Clock 668.551885263s] Trained 128 records in 0.100621216 seconds. Throughput is 1272.0975 records/second. Loss is 0.14701171. Sequential31006cbd's hyper parameters: Current learning rate is 0.004085968783198496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26112/60000][Iteration 7239][Wall Clock 668.638674473s] Trained 128 records in 0.08678921 seconds. Throughput is 1474.8376 records/second. Loss is 0.114740394. Sequential31006cbd's hyper parameters: Current learning rate is 0.004085634907664651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26240/60000][Iteration 7240][Wall Clock 668.715279019s] Trained 128 records in 0.076604546 seconds. Throughput is 1670.9192 records/second. Loss is 0.17878035. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040853010866900895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26368/60000][Iteration 7241][Wall Clock 668.8013496s] Trained 128 records in 0.086070581 seconds. Throughput is 1487.1516 records/second. Loss is 0.10792823. Sequential31006cbd's hyper parameters: Current learning rate is 0.004084967320261437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26496/60000][Iteration 7242][Wall Clock 668.881188387s] Trained 128 records in 0.079838787 seconds. Throughput is 1603.2307 records/second. Loss is 0.17151281. Sequential31006cbd's hyper parameters: Current learning rate is 0.00408463360836533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26624/60000][Iteration 7243][Wall Clock 668.965502192s] Trained 128 records in 0.084313805 seconds. Throughput is 1518.1382 records/second. Loss is 0.11106031. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040842999509884004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26752/60000][Iteration 7244][Wall Clock 669.035836852s] Trained 128 records in 0.07033466 seconds. Throughput is 1819.871 records/second. Loss is 0.16824678. Sequential31006cbd's hyper parameters: Current learning rate is 0.004083966348117292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 26880/60000][Iteration 7245][Wall Clock 669.109901811s] Trained 128 records in 0.074064959 seconds. Throughput is 1728.2125 records/second. Loss is 0.3301759. Sequential31006cbd's hyper parameters: Current learning rate is 0.004083632799738647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 27008/60000][Iteration 7246][Wall Clock 669.196821438s] Trained 128 records in 0.086919627 seconds. Throughput is 1472.6248 records/second. Loss is 0.11485794. Sequential31006cbd's hyper parameters: Current learning rate is 0.004083299305839118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 27136/60000][Iteration 7247][Wall Clock 669.292304367s] Trained 128 records in 0.095482929 seconds. Throughput is 1340.5537 records/second. Loss is 0.14758891. Sequential31006cbd's hyper parameters: Current learning rate is 0.004082965866405356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 27264/60000][Iteration 7248][Wall Clock 669.383190919s] Trained 128 records in 0.090886552 seconds. Throughput is 1408.3491 records/second. Loss is 0.22981581. Sequential31006cbd's hyper parameters: Current learning rate is 0.004082632481424022. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:46 INFO  DistriOptimizer$:408 - [Epoch 16 27392/60000][Iteration 7249][Wall Clock 669.499710335s] Trained 128 records in 0.116519416 seconds. Throughput is 1098.5294 records/second. Loss is 0.20437919. Sequential31006cbd's hyper parameters: Current learning rate is 0.004082299150881776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 27520/60000][Iteration 7250][Wall Clock 669.579551093s] Trained 128 records in 0.079840758 seconds. Throughput is 1603.1912 records/second. Loss is 0.13916256. Sequential31006cbd's hyper parameters: Current learning rate is 0.004081965874765288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 27648/60000][Iteration 7251][Wall Clock 669.670921432s] Trained 128 records in 0.091370339 seconds. Throughput is 1400.8923 records/second. Loss is 0.18389934. Sequential31006cbd's hyper parameters: Current learning rate is 0.004081632653061224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 27776/60000][Iteration 7252][Wall Clock 669.750290302s] Trained 128 records in 0.07936887 seconds. Throughput is 1612.723 records/second. Loss is 0.1650334. Sequential31006cbd's hyper parameters: Current learning rate is 0.004081299485756264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 27904/60000][Iteration 7253][Wall Clock 669.85315133s] Trained 128 records in 0.102861028 seconds. Throughput is 1244.3975 records/second. Loss is 0.13039178. Sequential31006cbd's hyper parameters: Current learning rate is 0.004080966372837088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28032/60000][Iteration 7254][Wall Clock 669.95603137s] Trained 128 records in 0.10288004 seconds. Throughput is 1244.1675 records/second. Loss is 0.17657423. Sequential31006cbd's hyper parameters: Current learning rate is 0.004080633314290378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28160/60000][Iteration 7255][Wall Clock 670.036271307s] Trained 128 records in 0.080239937 seconds. Throughput is 1595.2156 records/second. Loss is 0.16154423. Sequential31006cbd's hyper parameters: Current learning rate is 0.004080300310102824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28288/60000][Iteration 7256][Wall Clock 670.108251657s] Trained 128 records in 0.07198035 seconds. Throughput is 1778.2631 records/second. Loss is 0.13300744. Sequential31006cbd's hyper parameters: Current learning rate is 0.004079967360261118. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28416/60000][Iteration 7257][Wall Clock 670.188366408s] Trained 128 records in 0.080114751 seconds. Throughput is 1597.7083 records/second. Loss is 0.09682577. Sequential31006cbd's hyper parameters: Current learning rate is 0.004079634464751959. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28544/60000][Iteration 7258][Wall Clock 670.266874714s] Trained 128 records in 0.078508306 seconds. Throughput is 1630.4008 records/second. Loss is 0.12554157. Sequential31006cbd's hyper parameters: Current learning rate is 0.004079301623562046. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28672/60000][Iteration 7259][Wall Clock 670.348980398s] Trained 128 records in 0.082105684 seconds. Throughput is 1558.9664 records/second. Loss is 0.14105445. Sequential31006cbd's hyper parameters: Current learning rate is 0.004078968836678088. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28800/60000][Iteration 7260][Wall Clock 670.427743702s] Trained 128 records in 0.078763304 seconds. Throughput is 1625.1222 records/second. Loss is 0.23001873. Sequential31006cbd's hyper parameters: Current learning rate is 0.004078636104086793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:47 INFO  DistriOptimizer$:408 - [Epoch 16 28928/60000][Iteration 7261][Wall Clock 670.502820841s] Trained 128 records in 0.075077139 seconds. Throughput is 1704.9131 records/second. Loss is 0.14557621. Sequential31006cbd's hyper parameters: Current learning rate is 0.004078303425774878. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29056/60000][Iteration 7262][Wall Clock 670.578240697s] Trained 128 records in 0.075419856 seconds. Throughput is 1697.1658 records/second. Loss is 0.12167312. Sequential31006cbd's hyper parameters: Current learning rate is 0.004077970801729059. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29184/60000][Iteration 7263][Wall Clock 670.657200978s] Trained 128 records in 0.078960281 seconds. Throughput is 1621.0681 records/second. Loss is 0.21956915. Sequential31006cbd's hyper parameters: Current learning rate is 0.004077638231936063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29312/60000][Iteration 7264][Wall Clock 670.73445828s] Trained 128 records in 0.077257302 seconds. Throughput is 1656.8013 records/second. Loss is 0.107602164. Sequential31006cbd's hyper parameters: Current learning rate is 0.004077305716382614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29440/60000][Iteration 7265][Wall Clock 670.806530367s] Trained 128 records in 0.072072087 seconds. Throughput is 1775.9996 records/second. Loss is 0.11547004. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040769732550554475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29568/60000][Iteration 7266][Wall Clock 670.884382243s] Trained 128 records in 0.077851876 seconds. Throughput is 1644.148 records/second. Loss is 0.2301416. Sequential31006cbd's hyper parameters: Current learning rate is 0.004076640847941296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29696/60000][Iteration 7267][Wall Clock 670.96841575s] Trained 128 records in 0.084033507 seconds. Throughput is 1523.202 records/second. Loss is 0.092855714. Sequential31006cbd's hyper parameters: Current learning rate is 0.004076308495026904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29824/60000][Iteration 7268][Wall Clock 671.052013556s] Trained 128 records in 0.083597806 seconds. Throughput is 1531.1406 records/second. Loss is 0.20449209. Sequential31006cbd's hyper parameters: Current learning rate is 0.004075976196299013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 29952/60000][Iteration 7269][Wall Clock 671.129756991s] Trained 128 records in 0.077743435 seconds. Throughput is 1646.4413 records/second. Loss is 0.115980454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004075643951744376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 30080/60000][Iteration 7270][Wall Clock 671.219457564s] Trained 128 records in 0.089700573 seconds. Throughput is 1426.9697 records/second. Loss is 0.12029999. Sequential31006cbd's hyper parameters: Current learning rate is 0.004075311761349743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 30208/60000][Iteration 7271][Wall Clock 671.318826637s] Trained 128 records in 0.099369073 seconds. Throughput is 1288.1272 records/second. Loss is 0.14807156. Sequential31006cbd's hyper parameters: Current learning rate is 0.004074979625101875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 30336/60000][Iteration 7272][Wall Clock 671.404456096s] Trained 128 records in 0.085629459 seconds. Throughput is 1494.8127 records/second. Loss is 0.25800776. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040746475429875315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:48 INFO  DistriOptimizer$:408 - [Epoch 16 30464/60000][Iteration 7273][Wall Clock 671.484913028s] Trained 128 records in 0.080456932 seconds. Throughput is 1590.9132 records/second. Loss is 0.17271505. Sequential31006cbd's hyper parameters: Current learning rate is 0.004074315514993481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 30592/60000][Iteration 7274][Wall Clock 671.562172576s] Trained 128 records in 0.077259548 seconds. Throughput is 1656.7532 records/second. Loss is 0.22605017. Sequential31006cbd's hyper parameters: Current learning rate is 0.004073983541106494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 30720/60000][Iteration 7275][Wall Clock 671.666436195s] Trained 128 records in 0.104263619 seconds. Throughput is 1227.6573 records/second. Loss is 0.1557758. Sequential31006cbd's hyper parameters: Current learning rate is 0.004073651621313346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 30848/60000][Iteration 7276][Wall Clock 671.752015746s] Trained 128 records in 0.085579551 seconds. Throughput is 1495.6844 records/second. Loss is 0.2120916. Sequential31006cbd's hyper parameters: Current learning rate is 0.004073319755600814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 30976/60000][Iteration 7277][Wall Clock 671.831622007s] Trained 128 records in 0.079606261 seconds. Throughput is 1607.9138 records/second. Loss is 0.11863719. Sequential31006cbd's hyper parameters: Current learning rate is 0.004072987943955686. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31104/60000][Iteration 7278][Wall Clock 671.910284011s] Trained 128 records in 0.078662004 seconds. Throughput is 1627.2152 records/second. Loss is 0.18059549. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040726561863647474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31232/60000][Iteration 7279][Wall Clock 671.988076916s] Trained 128 records in 0.077792905 seconds. Throughput is 1645.3943 records/second. Loss is 0.181794. Sequential31006cbd's hyper parameters: Current learning rate is 0.004072324482814791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31360/60000][Iteration 7280][Wall Clock 672.062854662s] Trained 128 records in 0.074777746 seconds. Throughput is 1711.7393 records/second. Loss is 0.13819596. Sequential31006cbd's hyper parameters: Current learning rate is 0.004071992833292614. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31488/60000][Iteration 7281][Wall Clock 672.135415817s] Trained 128 records in 0.072561155 seconds. Throughput is 1764.0293 records/second. Loss is 0.11289184. Sequential31006cbd's hyper parameters: Current learning rate is 0.004071661237785016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31616/60000][Iteration 7282][Wall Clock 672.21366655s] Trained 128 records in 0.078250733 seconds. Throughput is 1635.7673 records/second. Loss is 0.18949103. Sequential31006cbd's hyper parameters: Current learning rate is 0.004071329696278805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31744/60000][Iteration 7283][Wall Clock 672.2926403s] Trained 128 records in 0.07897375 seconds. Throughput is 1620.7917 records/second. Loss is 0.13519761. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040709982087607875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 31872/60000][Iteration 7284][Wall Clock 672.374373686s] Trained 128 records in 0.081733386 seconds. Throughput is 1566.0675 records/second. Loss is 0.10321809. Sequential31006cbd's hyper parameters: Current learning rate is 0.004070666775217781. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:49 INFO  DistriOptimizer$:408 - [Epoch 16 32000/60000][Iteration 7285][Wall Clock 672.451624322s] Trained 128 records in 0.077250636 seconds. Throughput is 1656.9442 records/second. Loss is 0.085545436. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040703353956366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32128/60000][Iteration 7286][Wall Clock 672.527626619s] Trained 128 records in 0.076002297 seconds. Throughput is 1684.1595 records/second. Loss is 0.14472622. Sequential31006cbd's hyper parameters: Current learning rate is 0.004070004070004071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32256/60000][Iteration 7287][Wall Clock 672.603258617s] Trained 128 records in 0.075631998 seconds. Throughput is 1692.4054 records/second. Loss is 0.14372124. Sequential31006cbd's hyper parameters: Current learning rate is 0.004069672798307016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32384/60000][Iteration 7288][Wall Clock 672.678513282s] Trained 128 records in 0.075254665 seconds. Throughput is 1700.8912 records/second. Loss is 0.1464132. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040693415805322704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32512/60000][Iteration 7289][Wall Clock 672.758179192s] Trained 128 records in 0.07966591 seconds. Throughput is 1606.7098 records/second. Loss is 0.14188984. Sequential31006cbd's hyper parameters: Current learning rate is 0.004069010416666666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32640/60000][Iteration 7290][Wall Clock 672.832044901s] Trained 128 records in 0.073865709 seconds. Throughput is 1732.8744 records/second. Loss is 0.15838584. Sequential31006cbd's hyper parameters: Current learning rate is 0.004068679306697047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32768/60000][Iteration 7291][Wall Clock 672.907825149s] Trained 128 records in 0.075780248 seconds. Throughput is 1689.0945 records/second. Loss is 0.17687549. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040683482506102524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 32896/60000][Iteration 7292][Wall Clock 673.022578406s] Trained 128 records in 0.114753257 seconds. Throughput is 1115.4368 records/second. Loss is 0.16032621. Sequential31006cbd's hyper parameters: Current learning rate is 0.004068017248393133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 33024/60000][Iteration 7293][Wall Clock 673.100958415s] Trained 128 records in 0.078380009 seconds. Throughput is 1633.0695 records/second. Loss is 0.21566056. Sequential31006cbd's hyper parameters: Current learning rate is 0.004067686300032541. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 33152/60000][Iteration 7294][Wall Clock 673.187173756s] Trained 128 records in 0.086215341 seconds. Throughput is 1484.6545 records/second. Loss is 0.10361962. Sequential31006cbd's hyper parameters: Current learning rate is 0.004067355405515334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 33280/60000][Iteration 7295][Wall Clock 673.273509432s] Trained 128 records in 0.086335676 seconds. Throughput is 1482.5853 records/second. Loss is 0.12674828. Sequential31006cbd's hyper parameters: Current learning rate is 0.004067024564828371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 33408/60000][Iteration 7296][Wall Clock 673.359043674s] Trained 128 records in 0.085534242 seconds. Throughput is 1496.4767 records/second. Loss is 0.15235831. Sequential31006cbd's hyper parameters: Current learning rate is 0.004066693777958519. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:50 INFO  DistriOptimizer$:408 - [Epoch 16 33536/60000][Iteration 7297][Wall Clock 673.444646444s] Trained 128 records in 0.08560277 seconds. Throughput is 1495.2788 records/second. Loss is 0.1397334. Sequential31006cbd's hyper parameters: Current learning rate is 0.004066363044892648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 33664/60000][Iteration 7298][Wall Clock 673.540580803s] Trained 128 records in 0.095934359 seconds. Throughput is 1334.2456 records/second. Loss is 0.13107695. Sequential31006cbd's hyper parameters: Current learning rate is 0.004066032365617631. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 33792/60000][Iteration 7299][Wall Clock 673.635949261s] Trained 128 records in 0.095368458 seconds. Throughput is 1342.1628 records/second. Loss is 0.15047789. Sequential31006cbd's hyper parameters: Current learning rate is 0.004065701740120345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 33920/60000][Iteration 7300][Wall Clock 673.730281846s] Trained 128 records in 0.094332585 seconds. Throughput is 1356.9012 records/second. Loss is 0.14801893. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040653711683876735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34048/60000][Iteration 7301][Wall Clock 673.803656988s] Trained 128 records in 0.073375142 seconds. Throughput is 1744.46 records/second. Loss is 0.16123402. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040650406504065045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34176/60000][Iteration 7302][Wall Clock 673.891341952s] Trained 128 records in 0.087684964 seconds. Throughput is 1459.7714 records/second. Loss is 0.1230959. Sequential31006cbd's hyper parameters: Current learning rate is 0.004064710186163726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34304/60000][Iteration 7303][Wall Clock 673.96788269s] Trained 128 records in 0.076540738 seconds. Throughput is 1672.312 records/second. Loss is 0.22482373. Sequential31006cbd's hyper parameters: Current learning rate is 0.004064379775646236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34432/60000][Iteration 7304][Wall Clock 674.046360898s] Trained 128 records in 0.078478208 seconds. Throughput is 1631.026 records/second. Loss is 0.16995683. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040640494188409326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34560/60000][Iteration 7305][Wall Clock 674.121508002s] Trained 128 records in 0.075147104 seconds. Throughput is 1703.3257 records/second. Loss is 0.15981069. Sequential31006cbd's hyper parameters: Current learning rate is 0.004063719115734721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34688/60000][Iteration 7306][Wall Clock 674.198357632s] Trained 128 records in 0.07684963 seconds. Throughput is 1665.5903 records/second. Loss is 0.10621256. Sequential31006cbd's hyper parameters: Current learning rate is 0.004063388866314506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34816/60000][Iteration 7307][Wall Clock 674.287056643s] Trained 128 records in 0.088699011 seconds. Throughput is 1443.0825 records/second. Loss is 0.19014835. Sequential31006cbd's hyper parameters: Current learning rate is 0.004063058670567203. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 34944/60000][Iteration 7308][Wall Clock 674.365141088s] Trained 128 records in 0.078084445 seconds. Throughput is 1639.2509 records/second. Loss is 0.14960527. Sequential31006cbd's hyper parameters: Current learning rate is 0.004062728528479727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:51 INFO  DistriOptimizer$:408 - [Epoch 16 35072/60000][Iteration 7309][Wall Clock 674.441183555s] Trained 128 records in 0.076042467 seconds. Throughput is 1683.27 records/second. Loss is 0.13259947. Sequential31006cbd's hyper parameters: Current learning rate is 0.004062398440038999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35200/60000][Iteration 7310][Wall Clock 674.520638039s] Trained 128 records in 0.079454484 seconds. Throughput is 1610.9852 records/second. Loss is 0.20211813. Sequential31006cbd's hyper parameters: Current learning rate is 0.004062068405231944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35328/60000][Iteration 7311][Wall Clock 674.601231682s] Trained 128 records in 0.080593643 seconds. Throughput is 1588.2146 records/second. Loss is 0.16845143. Sequential31006cbd's hyper parameters: Current learning rate is 0.004061738424045492. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35456/60000][Iteration 7312][Wall Clock 674.679274004s] Trained 128 records in 0.078042322 seconds. Throughput is 1640.1357 records/second. Loss is 0.17885113. Sequential31006cbd's hyper parameters: Current learning rate is 0.004061408496466574. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35584/60000][Iteration 7313][Wall Clock 674.759099713s] Trained 128 records in 0.079825709 seconds. Throughput is 1603.4935 records/second. Loss is 0.21736039. Sequential31006cbd's hyper parameters: Current learning rate is 0.004061078622482131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35712/60000][Iteration 7314][Wall Clock 674.841103179s] Trained 128 records in 0.082003466 seconds. Throughput is 1560.9097 records/second. Loss is 0.16801256. Sequential31006cbd's hyper parameters: Current learning rate is 0.004060748802079103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35840/60000][Iteration 7315][Wall Clock 674.916432587s] Trained 128 records in 0.075329408 seconds. Throughput is 1699.2036 records/second. Loss is 0.1648232. Sequential31006cbd's hyper parameters: Current learning rate is 0.004060419035244437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 35968/60000][Iteration 7316][Wall Clock 674.991236368s] Trained 128 records in 0.074803781 seconds. Throughput is 1711.1434 records/second. Loss is 0.18102919. Sequential31006cbd's hyper parameters: Current learning rate is 0.004060089321965083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 36096/60000][Iteration 7317][Wall Clock 675.072902378s] Trained 128 records in 0.08166601 seconds. Throughput is 1567.3596 records/second. Loss is 0.10990646. Sequential31006cbd's hyper parameters: Current learning rate is 0.004059759662227996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 36224/60000][Iteration 7318][Wall Clock 675.168311929s] Trained 128 records in 0.095409551 seconds. Throughput is 1341.5848 records/second. Loss is 0.07640197. Sequential31006cbd's hyper parameters: Current learning rate is 0.004059430056020135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 36352/60000][Iteration 7319][Wall Clock 675.261125336s] Trained 128 records in 0.092813407 seconds. Throughput is 1379.1111 records/second. Loss is 0.17208189. Sequential31006cbd's hyper parameters: Current learning rate is 0.004059100503328463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 36480/60000][Iteration 7320][Wall Clock 675.341135695s] Trained 128 records in 0.080010359 seconds. Throughput is 1599.7928 records/second. Loss is 0.13447873. Sequential31006cbd's hyper parameters: Current learning rate is 0.004058771004139946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:52 INFO  DistriOptimizer$:408 - [Epoch 16 36608/60000][Iteration 7321][Wall Clock 675.429814782s] Trained 128 records in 0.088679087 seconds. Throughput is 1443.4067 records/second. Loss is 0.24629782. Sequential31006cbd's hyper parameters: Current learning rate is 0.004058441558441559. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 36736/60000][Iteration 7322][Wall Clock 675.519578128s] Trained 128 records in 0.089763346 seconds. Throughput is 1425.9718 records/second. Loss is 0.18393953. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040581121662202745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 36864/60000][Iteration 7323][Wall Clock 675.607208684s] Trained 128 records in 0.087630556 seconds. Throughput is 1460.6777 records/second. Loss is 0.12252675. Sequential31006cbd's hyper parameters: Current learning rate is 0.004057782827463074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 36992/60000][Iteration 7324][Wall Clock 675.686658111s] Trained 128 records in 0.079449427 seconds. Throughput is 1611.0876 records/second. Loss is 0.17977709. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040574535421569425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37120/60000][Iteration 7325][Wall Clock 675.766008161s] Trained 128 records in 0.07935005 seconds. Throughput is 1613.1056 records/second. Loss is 0.19945586. Sequential31006cbd's hyper parameters: Current learning rate is 0.004057124310288867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37248/60000][Iteration 7326][Wall Clock 675.864238437s] Trained 128 records in 0.098230276 seconds. Throughput is 1303.0607 records/second. Loss is 0.19011913. Sequential31006cbd's hyper parameters: Current learning rate is 0.004056795131845842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37376/60000][Iteration 7327][Wall Clock 675.935578001s] Trained 128 records in 0.071339564 seconds. Throughput is 1794.2358 records/second. Loss is 0.1323934. Sequential31006cbd's hyper parameters: Current learning rate is 0.004056466006814863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37504/60000][Iteration 7328][Wall Clock 676.007216435s] Trained 128 records in 0.071638434 seconds. Throughput is 1786.7504 records/second. Loss is 0.13235249. Sequential31006cbd's hyper parameters: Current learning rate is 0.004056136935182932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37632/60000][Iteration 7329][Wall Clock 676.081487176s] Trained 128 records in 0.074270741 seconds. Throughput is 1723.4243 records/second. Loss is 0.180154. Sequential31006cbd's hyper parameters: Current learning rate is 0.004055807916937054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37760/60000][Iteration 7330][Wall Clock 676.154763458s] Trained 128 records in 0.073276282 seconds. Throughput is 1746.8135 records/second. Loss is 0.200554. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040554789520642395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 37888/60000][Iteration 7331][Wall Clock 676.234785846s] Trained 128 records in 0.080022388 seconds. Throughput is 1599.5524 records/second. Loss is 0.15013844. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040551500405515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 38016/60000][Iteration 7332][Wall Clock 676.321655105s] Trained 128 records in 0.086869259 seconds. Throughput is 1473.4786 records/second. Loss is 0.14291276. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040548211823858565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 38144/60000][Iteration 7333][Wall Clock 676.400815416s] Trained 128 records in 0.079160311 seconds. Throughput is 1616.9719 records/second. Loss is 0.16258632. Sequential31006cbd's hyper parameters: Current learning rate is 0.00405449237755433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:53 INFO  DistriOptimizer$:408 - [Epoch 16 38272/60000][Iteration 7334][Wall Clock 676.482498313s] Trained 128 records in 0.081682897 seconds. Throughput is 1567.0355 records/second. Loss is 0.23539504. Sequential31006cbd's hyper parameters: Current learning rate is 0.004054163626043947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 38400/60000][Iteration 7335][Wall Clock 676.562697364s] Trained 128 records in 0.080199051 seconds. Throughput is 1596.0289 records/second. Loss is 0.10570271. Sequential31006cbd's hyper parameters: Current learning rate is 0.004053834927841738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 38528/60000][Iteration 7336][Wall Clock 676.638546106s] Trained 128 records in 0.075848742 seconds. Throughput is 1687.5692 records/second. Loss is 0.23143283. Sequential31006cbd's hyper parameters: Current learning rate is 0.004053506282934738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 38656/60000][Iteration 7337][Wall Clock 676.708421359s] Trained 128 records in 0.069875253 seconds. Throughput is 1831.8359 records/second. Loss is 0.15138778. Sequential31006cbd's hyper parameters: Current learning rate is 0.004053177691309987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 38784/60000][Iteration 7338][Wall Clock 676.783193623s] Trained 128 records in 0.074772264 seconds. Throughput is 1711.8647 records/second. Loss is 0.2357187. Sequential31006cbd's hyper parameters: Current learning rate is 0.004052849152954527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 38912/60000][Iteration 7339][Wall Clock 676.867731393s] Trained 128 records in 0.08453777 seconds. Throughput is 1514.1162 records/second. Loss is 0.25958467. Sequential31006cbd's hyper parameters: Current learning rate is 0.004052520667855406. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39040/60000][Iteration 7340][Wall Clock 676.954269335s] Trained 128 records in 0.086537942 seconds. Throughput is 1479.12 records/second. Loss is 0.19209312. Sequential31006cbd's hyper parameters: Current learning rate is 0.004052192235999676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39168/60000][Iteration 7341][Wall Clock 677.035574729s] Trained 128 records in 0.081305394 seconds. Throughput is 1574.3113 records/second. Loss is 0.19820015. Sequential31006cbd's hyper parameters: Current learning rate is 0.004051863857374392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39296/60000][Iteration 7342][Wall Clock 677.118652658s] Trained 128 records in 0.083077929 seconds. Throughput is 1540.722 records/second. Loss is 0.064230636. Sequential31006cbd's hyper parameters: Current learning rate is 0.004051535531966615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39424/60000][Iteration 7343][Wall Clock 677.213974542s] Trained 128 records in 0.095321884 seconds. Throughput is 1342.8186 records/second. Loss is 0.20439065. Sequential31006cbd's hyper parameters: Current learning rate is 0.00405120725976341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39552/60000][Iteration 7344][Wall Clock 677.30686409s] Trained 128 records in 0.092889548 seconds. Throughput is 1377.9807 records/second. Loss is 0.09404575. Sequential31006cbd's hyper parameters: Current learning rate is 0.004050879040751842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39680/60000][Iteration 7345][Wall Clock 677.384450071s] Trained 128 records in 0.077585981 seconds. Throughput is 1649.7826 records/second. Loss is 0.18661673. Sequential31006cbd's hyper parameters: Current learning rate is 0.00405055087491899. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:54 INFO  DistriOptimizer$:408 - [Epoch 16 39808/60000][Iteration 7346][Wall Clock 677.47227613s] Trained 128 records in 0.087826059 seconds. Throughput is 1457.4263 records/second. Loss is 0.2078583. Sequential31006cbd's hyper parameters: Current learning rate is 0.004050222762251923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 39936/60000][Iteration 7347][Wall Clock 677.556055718s] Trained 128 records in 0.083779588 seconds. Throughput is 1527.8185 records/second. Loss is 0.1462491. Sequential31006cbd's hyper parameters: Current learning rate is 0.004049894702737729. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40064/60000][Iteration 7348][Wall Clock 677.645098688s] Trained 128 records in 0.08904297 seconds. Throughput is 1437.5082 records/second. Loss is 0.23136178. Sequential31006cbd's hyper parameters: Current learning rate is 0.004049566696363489. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40192/60000][Iteration 7349][Wall Clock 677.72464405s] Trained 128 records in 0.079545362 seconds. Throughput is 1609.1447 records/second. Loss is 0.12722452. Sequential31006cbd's hyper parameters: Current learning rate is 0.004049238743116294. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40320/60000][Iteration 7350][Wall Clock 677.801906387s] Trained 128 records in 0.077262337 seconds. Throughput is 1656.6934 records/second. Loss is 0.1715391. Sequential31006cbd's hyper parameters: Current learning rate is 0.004048910842983237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40448/60000][Iteration 7351][Wall Clock 677.881702988s] Trained 128 records in 0.079796601 seconds. Throughput is 1604.0784 records/second. Loss is 0.11814453. Sequential31006cbd's hyper parameters: Current learning rate is 0.004048582995951418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40576/60000][Iteration 7352][Wall Clock 677.975457558s] Trained 128 records in 0.09375457 seconds. Throughput is 1365.2668 records/second. Loss is 0.1742216. Sequential31006cbd's hyper parameters: Current learning rate is 0.004048255202007934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40704/60000][Iteration 7353][Wall Clock 678.047156863s] Trained 128 records in 0.071699305 seconds. Throughput is 1785.2334 records/second. Loss is 0.17405306. Sequential31006cbd's hyper parameters: Current learning rate is 0.004047927461139896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40832/60000][Iteration 7354][Wall Clock 678.122215577s] Trained 128 records in 0.075058714 seconds. Throughput is 1705.3317 records/second. Loss is 0.11818939. Sequential31006cbd's hyper parameters: Current learning rate is 0.004047599773334413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 40960/60000][Iteration 7355][Wall Clock 678.198694446s] Trained 128 records in 0.076478869 seconds. Throughput is 1673.6649 records/second. Loss is 0.2184295. Sequential31006cbd's hyper parameters: Current learning rate is 0.004047272138578598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 41088/60000][Iteration 7356][Wall Clock 678.272308756s] Trained 128 records in 0.07361431 seconds. Throughput is 1738.7925 records/second. Loss is 0.2111719. Sequential31006cbd's hyper parameters: Current learning rate is 0.004046944556859571. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 41216/60000][Iteration 7357][Wall Clock 678.347699753s] Trained 128 records in 0.075390997 seconds. Throughput is 1697.8156 records/second. Loss is 0.19648385. Sequential31006cbd's hyper parameters: Current learning rate is 0.004046617028164455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:55 INFO  DistriOptimizer$:408 - [Epoch 16 41344/60000][Iteration 7358][Wall Clock 678.419520432s] Trained 128 records in 0.071820679 seconds. Throughput is 1782.2166 records/second. Loss is 0.20765741. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040462895524803755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 41472/60000][Iteration 7359][Wall Clock 678.500441784s] Trained 128 records in 0.080921352 seconds. Throughput is 1581.7827 records/second. Loss is 0.16865836. Sequential31006cbd's hyper parameters: Current learning rate is 0.004045962129794465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 41600/60000][Iteration 7360][Wall Clock 678.576436909s] Trained 128 records in 0.075995125 seconds. Throughput is 1684.3186 records/second. Loss is 0.1411008. Sequential31006cbd's hyper parameters: Current learning rate is 0.004045634760093859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 41728/60000][Iteration 7361][Wall Clock 678.656714005s] Trained 128 records in 0.080277096 seconds. Throughput is 1594.4773 records/second. Loss is 0.21425761. Sequential31006cbd's hyper parameters: Current learning rate is 0.004045307443365696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 41856/60000][Iteration 7362][Wall Clock 678.737565538s] Trained 128 records in 0.080851533 seconds. Throughput is 1583.1487 records/second. Loss is 0.15791997. Sequential31006cbd's hyper parameters: Current learning rate is 0.00404498017959712. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 41984/60000][Iteration 7363][Wall Clock 678.817478666s] Trained 128 records in 0.079913128 seconds. Throughput is 1601.7394 records/second. Loss is 0.12698178. Sequential31006cbd's hyper parameters: Current learning rate is 0.004044652968775279. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42112/60000][Iteration 7364][Wall Clock 678.898251136s] Trained 128 records in 0.08077247 seconds. Throughput is 1584.6984 records/second. Loss is 0.14687538. Sequential31006cbd's hyper parameters: Current learning rate is 0.004044325810887326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42240/60000][Iteration 7365][Wall Clock 678.986292497s] Trained 128 records in 0.088041361 seconds. Throughput is 1453.8622 records/second. Loss is 0.09339216. Sequential31006cbd's hyper parameters: Current learning rate is 0.004043998705920413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42368/60000][Iteration 7366][Wall Clock 679.070017457s] Trained 128 records in 0.08372496 seconds. Throughput is 1528.8153 records/second. Loss is 0.23935041. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040436716538617065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42496/60000][Iteration 7367][Wall Clock 679.149276352s] Trained 128 records in 0.079258895 seconds. Throughput is 1614.9607 records/second. Loss is 0.14978847. Sequential31006cbd's hyper parameters: Current learning rate is 0.004043344654698366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42624/60000][Iteration 7368][Wall Clock 679.230199087s] Trained 128 records in 0.080922735 seconds. Throughput is 1581.7557 records/second. Loss is 0.1894938. Sequential31006cbd's hyper parameters: Current learning rate is 0.004043017708417564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42752/60000][Iteration 7369][Wall Clock 679.320194241s] Trained 128 records in 0.089995154 seconds. Throughput is 1422.2988 records/second. Loss is 0.21432321. Sequential31006cbd's hyper parameters: Current learning rate is 0.004042690815006468. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 42880/60000][Iteration 7370][Wall Clock 679.400934918s] Trained 128 records in 0.080740677 seconds. Throughput is 1585.3224 records/second. Loss is 0.20462833. Sequential31006cbd's hyper parameters: Current learning rate is 0.00404236397445226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:56 INFO  DistriOptimizer$:408 - [Epoch 16 43008/60000][Iteration 7371][Wall Clock 679.484075383s] Trained 128 records in 0.083140465 seconds. Throughput is 1539.5632 records/second. Loss is 0.13122407. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040420371867421175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43136/60000][Iteration 7372][Wall Clock 679.583121201s] Trained 128 records in 0.099045818 seconds. Throughput is 1292.3312 records/second. Loss is 0.16784741. Sequential31006cbd's hyper parameters: Current learning rate is 0.004041710451863229. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43264/60000][Iteration 7373][Wall Clock 679.671157942s] Trained 128 records in 0.088036741 seconds. Throughput is 1453.9385 records/second. Loss is 0.10824226. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040413837698027805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43392/60000][Iteration 7374][Wall Clock 679.747596263s] Trained 128 records in 0.076438321 seconds. Throughput is 1674.5527 records/second. Loss is 0.13053823. Sequential31006cbd's hyper parameters: Current learning rate is 0.004041057140547967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43520/60000][Iteration 7375][Wall Clock 679.819259512s] Trained 128 records in 0.071663249 seconds. Throughput is 1786.1318 records/second. Loss is 0.14886138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040407305640859864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43648/60000][Iteration 7376][Wall Clock 679.897041468s] Trained 128 records in 0.077781956 seconds. Throughput is 1645.626 records/second. Loss is 0.15523869. Sequential31006cbd's hyper parameters: Current learning rate is 0.00404040404040404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43776/60000][Iteration 7377][Wall Clock 679.982420313s] Trained 128 records in 0.085378845 seconds. Throughput is 1499.2003 records/second. Loss is 0.13448621. Sequential31006cbd's hyper parameters: Current learning rate is 0.004040077569489335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 43904/60000][Iteration 7378][Wall Clock 680.060895655s] Trained 128 records in 0.078475342 seconds. Throughput is 1631.0856 records/second. Loss is 0.15651815. Sequential31006cbd's hyper parameters: Current learning rate is 0.004039751151329078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 44032/60000][Iteration 7379][Wall Clock 680.141797793s] Trained 128 records in 0.080902138 seconds. Throughput is 1582.1584 records/second. Loss is 0.15211985. Sequential31006cbd's hyper parameters: Current learning rate is 0.004039424785910487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 44160/60000][Iteration 7380][Wall Clock 680.22059235s] Trained 128 records in 0.078794557 seconds. Throughput is 1624.4778 records/second. Loss is 0.106338285. Sequential31006cbd's hyper parameters: Current learning rate is 0.004039098473220777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 44288/60000][Iteration 7381][Wall Clock 680.298606115s] Trained 128 records in 0.078013765 seconds. Throughput is 1640.7361 records/second. Loss is 0.19319326. Sequential31006cbd's hyper parameters: Current learning rate is 0.004038772213247173. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 44416/60000][Iteration 7382][Wall Clock 680.376825711s] Trained 128 records in 0.078219596 seconds. Throughput is 1636.4187 records/second. Loss is 0.24834831. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040384460059769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:57 INFO  DistriOptimizer$:408 - [Epoch 16 44544/60000][Iteration 7383][Wall Clock 680.454465104s] Trained 128 records in 0.077639393 seconds. Throughput is 1648.6476 records/second. Loss is 0.21750368. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040381198513971895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 44672/60000][Iteration 7384][Wall Clock 680.533302731s] Trained 128 records in 0.078837627 seconds. Throughput is 1623.5902 records/second. Loss is 0.13486099. Sequential31006cbd's hyper parameters: Current learning rate is 0.004037793749495275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 44800/60000][Iteration 7385][Wall Clock 680.608584693s] Trained 128 records in 0.075281962 seconds. Throughput is 1700.2745 records/second. Loss is 0.18402924. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040374677002583985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 44928/60000][Iteration 7386][Wall Clock 680.692569492s] Trained 128 records in 0.083984799 seconds. Throughput is 1524.0853 records/second. Loss is 0.19694543. Sequential31006cbd's hyper parameters: Current learning rate is 0.004037141703673798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45056/60000][Iteration 7387][Wall Clock 680.781250906s] Trained 128 records in 0.088681414 seconds. Throughput is 1443.3689 records/second. Loss is 0.1446595. Sequential31006cbd's hyper parameters: Current learning rate is 0.004036815759728726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45184/60000][Iteration 7388][Wall Clock 680.856099725s] Trained 128 records in 0.074848819 seconds. Throughput is 1710.1139 records/second. Loss is 0.06878543. Sequential31006cbd's hyper parameters: Current learning rate is 0.00403648986841043. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45312/60000][Iteration 7389][Wall Clock 680.958840017s] Trained 128 records in 0.102740292 seconds. Throughput is 1245.8597 records/second. Loss is 0.11118464. Sequential31006cbd's hyper parameters: Current learning rate is 0.004036164029706167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45440/60000][Iteration 7390][Wall Clock 681.044023744s] Trained 128 records in 0.085183727 seconds. Throughput is 1502.6344 records/second. Loss is 0.20884866. Sequential31006cbd's hyper parameters: Current learning rate is 0.004035838243603196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45568/60000][Iteration 7391][Wall Clock 681.1142833s] Trained 128 records in 0.070259556 seconds. Throughput is 1821.8163 records/second. Loss is 0.18947197. Sequential31006cbd's hyper parameters: Current learning rate is 0.004035512510088782. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45696/60000][Iteration 7392][Wall Clock 681.188976029s] Trained 128 records in 0.074692729 seconds. Throughput is 1713.6876 records/second. Loss is 0.10966826. Sequential31006cbd's hyper parameters: Current learning rate is 0.004035186829150189. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45824/60000][Iteration 7393][Wall Clock 681.264941661s] Trained 128 records in 0.075965632 seconds. Throughput is 1684.9724 records/second. Loss is 0.121805705. Sequential31006cbd's hyper parameters: Current learning rate is 0.004034861200774694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 45952/60000][Iteration 7394][Wall Clock 681.347522149s] Trained 128 records in 0.082580488 seconds. Throughput is 1550.003 records/second. Loss is 0.14812571. Sequential31006cbd's hyper parameters: Current learning rate is 0.004034535624949568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:58 INFO  DistriOptimizer$:408 - [Epoch 16 46080/60000][Iteration 7395][Wall Clock 681.441775485s] Trained 128 records in 0.094253336 seconds. Throughput is 1358.0421 records/second. Loss is 0.09762232. Sequential31006cbd's hyper parameters: Current learning rate is 0.004034210101662094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46208/60000][Iteration 7396][Wall Clock 681.52877306s] Trained 128 records in 0.086997575 seconds. Throughput is 1471.3054 records/second. Loss is 0.093552314. Sequential31006cbd's hyper parameters: Current learning rate is 0.004033884630899556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46336/60000][Iteration 7397][Wall Clock 681.609211745s] Trained 128 records in 0.080438685 seconds. Throughput is 1591.274 records/second. Loss is 0.11775066. Sequential31006cbd's hyper parameters: Current learning rate is 0.004033559212649242. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46464/60000][Iteration 7398][Wall Clock 681.694116229s] Trained 128 records in 0.084904484 seconds. Throughput is 1507.5764 records/second. Loss is 0.20280062. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040332338468984435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46592/60000][Iteration 7399][Wall Clock 681.771016616s] Trained 128 records in 0.076900387 seconds. Throughput is 1664.491 records/second. Loss is 0.1355056. Sequential31006cbd's hyper parameters: Current learning rate is 0.004032908533634457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46720/60000][Iteration 7400][Wall Clock 681.843978831s] Trained 128 records in 0.072962215 seconds. Throughput is 1754.3326 records/second. Loss is 0.2168862. Sequential31006cbd's hyper parameters: Current learning rate is 0.004032583272844584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46848/60000][Iteration 7401][Wall Clock 681.918928415s] Trained 128 records in 0.074949584 seconds. Throughput is 1707.8147 records/second. Loss is 0.11188773. Sequential31006cbd's hyper parameters: Current learning rate is 0.004032258064516129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 46976/60000][Iteration 7402][Wall Clock 681.999719257s] Trained 128 records in 0.080790842 seconds. Throughput is 1584.338 records/second. Loss is 0.12144592. Sequential31006cbd's hyper parameters: Current learning rate is 0.004031932908636401. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 47104/60000][Iteration 7403][Wall Clock 682.084084339s] Trained 128 records in 0.084365082 seconds. Throughput is 1517.2153 records/second. Loss is 0.21549976. Sequential31006cbd's hyper parameters: Current learning rate is 0.004031607805192711. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 47232/60000][Iteration 7404][Wall Clock 682.163327164s] Trained 128 records in 0.079242825 seconds. Throughput is 1615.2882 records/second. Loss is 0.1693992. Sequential31006cbd's hyper parameters: Current learning rate is 0.004031282754172378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 47360/60000][Iteration 7405][Wall Clock 682.241654005s] Trained 128 records in 0.078326841 seconds. Throughput is 1634.178 records/second. Loss is 0.14059988. Sequential31006cbd's hyper parameters: Current learning rate is 0.004030957755562721. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 47488/60000][Iteration 7406][Wall Clock 682.316986219s] Trained 128 records in 0.075332214 seconds. Throughput is 1699.1403 records/second. Loss is 0.13078438. Sequential31006cbd's hyper parameters: Current learning rate is 0.004030632809351068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 47616/60000][Iteration 7407][Wall Clock 682.394412132s] Trained 128 records in 0.077425913 seconds. Throughput is 1653.1934 records/second. Loss is 0.18654263. Sequential31006cbd's hyper parameters: Current learning rate is 0.004030307915524746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:08:59 INFO  DistriOptimizer$:408 - [Epoch 16 47744/60000][Iteration 7408][Wall Clock 682.46856176s] Trained 128 records in 0.074149628 seconds. Throughput is 1726.2393 records/second. Loss is 0.102382645. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040299830740710895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 47872/60000][Iteration 7409][Wall Clock 682.54431643s] Trained 128 records in 0.07575467 seconds. Throughput is 1689.6648 records/second. Loss is 0.15407352. Sequential31006cbd's hyper parameters: Current learning rate is 0.004029658284977433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48000/60000][Iteration 7410][Wall Clock 682.623638794s] Trained 128 records in 0.079322364 seconds. Throughput is 1613.6686 records/second. Loss is 0.13773395. Sequential31006cbd's hyper parameters: Current learning rate is 0.004029333548231123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48128/60000][Iteration 7411][Wall Clock 682.707805186s] Trained 128 records in 0.084166392 seconds. Throughput is 1520.797 records/second. Loss is 0.095718145. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040290088638195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48256/60000][Iteration 7412][Wall Clock 682.794399958s] Trained 128 records in 0.086594772 seconds. Throughput is 1478.1492 records/second. Loss is 0.14725529. Sequential31006cbd's hyper parameters: Current learning rate is 0.004028684231729918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48384/60000][Iteration 7413][Wall Clock 682.879580522s] Trained 128 records in 0.085180564 seconds. Throughput is 1502.6902 records/second. Loss is 0.11246035. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040283596519497256. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48512/60000][Iteration 7414][Wall Clock 682.959678211s] Trained 128 records in 0.080097689 seconds. Throughput is 1598.0486 records/second. Loss is 0.15821639. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040280351244662855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48640/60000][Iteration 7415][Wall Clock 683.040800847s] Trained 128 records in 0.081122636 seconds. Throughput is 1577.858 records/second. Loss is 0.10984045. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040277106492669565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48768/60000][Iteration 7416][Wall Clock 683.117469012s] Trained 128 records in 0.076668165 seconds. Throughput is 1669.5326 records/second. Loss is 0.20616229. Sequential31006cbd's hyper parameters: Current learning rate is 0.004027386226339105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 48896/60000][Iteration 7417][Wall Clock 683.196842265s] Trained 128 records in 0.079373253 seconds. Throughput is 1612.6339 records/second. Loss is 0.23215263. Sequential31006cbd's hyper parameters: Current learning rate is 0.004027061855670103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 49024/60000][Iteration 7418][Wall Clock 683.291351335s] Trained 128 records in 0.09450907 seconds. Throughput is 1354.3673 records/second. Loss is 0.13517539. Sequential31006cbd's hyper parameters: Current learning rate is 0.004026737537247322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 49152/60000][Iteration 7419][Wall Clock 683.37692948s] Trained 128 records in 0.085578145 seconds. Throughput is 1495.709 records/second. Loss is 0.0929319. Sequential31006cbd's hyper parameters: Current learning rate is 0.004026413271058142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:00 INFO  DistriOptimizer$:408 - [Epoch 16 49280/60000][Iteration 7420][Wall Clock 683.462770523s] Trained 128 records in 0.085841043 seconds. Throughput is 1491.1282 records/second. Loss is 0.11928648. Sequential31006cbd's hyper parameters: Current learning rate is 0.004026089057089943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 49408/60000][Iteration 7421][Wall Clock 683.549725704s] Trained 128 records in 0.086955181 seconds. Throughput is 1472.0227 records/second. Loss is 0.16935878. Sequential31006cbd's hyper parameters: Current learning rate is 0.004025764895330113. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 49536/60000][Iteration 7422][Wall Clock 683.630668743s] Trained 128 records in 0.080943039 seconds. Throughput is 1581.3589 records/second. Loss is 0.14620705. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040254407857660416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 49664/60000][Iteration 7423][Wall Clock 683.710980095s] Trained 128 records in 0.080311352 seconds. Throughput is 1593.7971 records/second. Loss is 0.21218623. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040251167283851235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 49792/60000][Iteration 7424][Wall Clock 683.806562638s] Trained 128 records in 0.095582543 seconds. Throughput is 1339.1566 records/second. Loss is 0.16678485. Sequential31006cbd's hyper parameters: Current learning rate is 0.004024792723174756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 49920/60000][Iteration 7425][Wall Clock 683.884822876s] Trained 128 records in 0.078260238 seconds. Throughput is 1635.5688 records/second. Loss is 0.19591936. Sequential31006cbd's hyper parameters: Current learning rate is 0.004024468770122344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 50048/60000][Iteration 7426][Wall Clock 683.968402986s] Trained 128 records in 0.08358011 seconds. Throughput is 1531.465 records/second. Loss is 0.23251374. Sequential31006cbd's hyper parameters: Current learning rate is 0.004024144869215291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 50176/60000][Iteration 7427][Wall Clock 684.060639858s] Trained 128 records in 0.092236872 seconds. Throughput is 1387.7314 records/second. Loss is 0.104404785. Sequential31006cbd's hyper parameters: Current learning rate is 0.004023821020441011. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 50304/60000][Iteration 7428][Wall Clock 684.145328217s] Trained 128 records in 0.084688359 seconds. Throughput is 1511.4238 records/second. Loss is 0.13478096. Sequential31006cbd's hyper parameters: Current learning rate is 0.004023497223786915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 50432/60000][Iteration 7429][Wall Clock 684.226348636s] Trained 128 records in 0.081020419 seconds. Throughput is 1579.8486 records/second. Loss is 0.19688553. Sequential31006cbd's hyper parameters: Current learning rate is 0.004023173479240426. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 50560/60000][Iteration 7430][Wall Clock 684.308320006s] Trained 128 records in 0.08197137 seconds. Throughput is 1561.5209 records/second. Loss is 0.22067885. Sequential31006cbd's hyper parameters: Current learning rate is 0.004022849786788961. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:01 INFO  DistriOptimizer$:408 - [Epoch 16 50688/60000][Iteration 7431][Wall Clock 684.396034056s] Trained 128 records in 0.08771405 seconds. Throughput is 1459.2872 records/second. Loss is 0.10617949. Sequential31006cbd's hyper parameters: Current learning rate is 0.004022526146419952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 50816/60000][Iteration 7432][Wall Clock 684.471138653s] Trained 128 records in 0.075104597 seconds. Throughput is 1704.2899 records/second. Loss is 0.16256426. Sequential31006cbd's hyper parameters: Current learning rate is 0.004022202558120826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 50944/60000][Iteration 7433][Wall Clock 684.549313866s] Trained 128 records in 0.078175213 seconds. Throughput is 1637.3477 records/second. Loss is 0.1340822. Sequential31006cbd's hyper parameters: Current learning rate is 0.004021879021879022. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51072/60000][Iteration 7434][Wall Clock 684.628210585s] Trained 128 records in 0.078896719 seconds. Throughput is 1622.3743 records/second. Loss is 0.1637009. Sequential31006cbd's hyper parameters: Current learning rate is 0.004021555537681975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51200/60000][Iteration 7435][Wall Clock 684.704364053s] Trained 128 records in 0.076153468 seconds. Throughput is 1680.8165 records/second. Loss is 0.13767017. Sequential31006cbd's hyper parameters: Current learning rate is 0.00402123210551713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51328/60000][Iteration 7436][Wall Clock 684.788423765s] Trained 128 records in 0.084059712 seconds. Throughput is 1522.727 records/second. Loss is 0.16327624. Sequential31006cbd's hyper parameters: Current learning rate is 0.004020908725371934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51456/60000][Iteration 7437][Wall Clock 684.874255661s] Trained 128 records in 0.085831896 seconds. Throughput is 1491.2871 records/second. Loss is 0.12965229. Sequential31006cbd's hyper parameters: Current learning rate is 0.004020585397233837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51584/60000][Iteration 7438][Wall Clock 684.948954493s] Trained 128 records in 0.074698832 seconds. Throughput is 1713.5475 records/second. Loss is 0.099058144. Sequential31006cbd's hyper parameters: Current learning rate is 0.004020262121090295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51712/60000][Iteration 7439][Wall Clock 685.026709797s] Trained 128 records in 0.077755304 seconds. Throughput is 1646.19 records/second. Loss is 0.14889646. Sequential31006cbd's hyper parameters: Current learning rate is 0.004019938896928766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51840/60000][Iteration 7440][Wall Clock 685.109885594s] Trained 128 records in 0.083175797 seconds. Throughput is 1538.9093 records/second. Loss is 0.15366429. Sequential31006cbd's hyper parameters: Current learning rate is 0.004019615724736715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 51968/60000][Iteration 7441][Wall Clock 685.185185541s] Trained 128 records in 0.075299947 seconds. Throughput is 1699.8684 records/second. Loss is 0.14685085. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040192926045016075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 52096/60000][Iteration 7442][Wall Clock 685.257706672s] Trained 128 records in 0.072521131 seconds. Throughput is 1765.0029 records/second. Loss is 0.16160214. Sequential31006cbd's hyper parameters: Current learning rate is 0.004018969536210916. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 52224/60000][Iteration 7443][Wall Clock 685.33718429s] Trained 128 records in 0.079477618 seconds. Throughput is 1610.5164 records/second. Loss is 0.21490595. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040186465198521135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:02 INFO  DistriOptimizer$:408 - [Epoch 16 52352/60000][Iteration 7444][Wall Clock 685.42083255s] Trained 128 records in 0.08364826 seconds. Throughput is 1530.2172 records/second. Loss is 0.17028454. Sequential31006cbd's hyper parameters: Current learning rate is 0.004018323555412682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 52480/60000][Iteration 7445][Wall Clock 685.502336857s] Trained 128 records in 0.081504307 seconds. Throughput is 1570.4691 records/second. Loss is 0.11148254. Sequential31006cbd's hyper parameters: Current learning rate is 0.004018000642880102. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 52608/60000][Iteration 7446][Wall Clock 685.59889455s] Trained 128 records in 0.096557693 seconds. Throughput is 1325.6323 records/second. Loss is 0.18447469. Sequential31006cbd's hyper parameters: Current learning rate is 0.004017677782241865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 52736/60000][Iteration 7447][Wall Clock 685.702801756s] Trained 128 records in 0.103907206 seconds. Throughput is 1231.8684 records/second. Loss is 0.1327731. Sequential31006cbd's hyper parameters: Current learning rate is 0.004017354973485457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 52864/60000][Iteration 7448][Wall Clock 685.781946536s] Trained 128 records in 0.07914478 seconds. Throughput is 1617.2892 records/second. Loss is 0.18057764. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040170322165983775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 52992/60000][Iteration 7449][Wall Clock 685.854461842s] Trained 128 records in 0.072515306 seconds. Throughput is 1765.1445 records/second. Loss is 0.17942202. Sequential31006cbd's hyper parameters: Current learning rate is 0.004016709511568123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53120/60000][Iteration 7450][Wall Clock 685.929531335s] Trained 128 records in 0.075069493 seconds. Throughput is 1705.0868 records/second. Loss is 0.18753785. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040163868583822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53248/60000][Iteration 7451][Wall Clock 686.007866232s] Trained 128 records in 0.078334897 seconds. Throughput is 1634.0099 records/second. Loss is 0.18165681. Sequential31006cbd's hyper parameters: Current learning rate is 0.004016064257028112. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53376/60000][Iteration 7452][Wall Clock 686.085808132s] Trained 128 records in 0.0779419 seconds. Throughput is 1642.2489 records/second. Loss is 0.11177155. Sequential31006cbd's hyper parameters: Current learning rate is 0.004015741707493374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53504/60000][Iteration 7453][Wall Clock 686.166754663s] Trained 128 records in 0.080946531 seconds. Throughput is 1581.2908 records/second. Loss is 0.19992092. Sequential31006cbd's hyper parameters: Current learning rate is 0.004015419209765499. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53632/60000][Iteration 7454][Wall Clock 686.24578219s] Trained 128 records in 0.079027527 seconds. Throughput is 1619.6888 records/second. Loss is 0.1808362. Sequential31006cbd's hyper parameters: Current learning rate is 0.004015096763832008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53760/60000][Iteration 7455][Wall Clock 686.321556515s] Trained 128 records in 0.075774325 seconds. Throughput is 1689.2264 records/second. Loss is 0.12699313. Sequential31006cbd's hyper parameters: Current learning rate is 0.004014774369680424. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:03 INFO  DistriOptimizer$:408 - [Epoch 16 53888/60000][Iteration 7456][Wall Clock 686.405146824s] Trained 128 records in 0.083590309 seconds. Throughput is 1531.2781 records/second. Loss is 0.20043528. Sequential31006cbd's hyper parameters: Current learning rate is 0.004014452027298274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54016/60000][Iteration 7457][Wall Clock 686.485408504s] Trained 128 records in 0.08026168 seconds. Throughput is 1594.7836 records/second. Loss is 0.17701675. Sequential31006cbd's hyper parameters: Current learning rate is 0.004014129736673089. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54144/60000][Iteration 7458][Wall Clock 686.563029412s] Trained 128 records in 0.077620908 seconds. Throughput is 1649.0402 records/second. Loss is 0.19301718. Sequential31006cbd's hyper parameters: Current learning rate is 0.004013807497792406. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54272/60000][Iteration 7459][Wall Clock 686.660347885s] Trained 128 records in 0.097318473 seconds. Throughput is 1315.2693 records/second. Loss is 0.15338612. Sequential31006cbd's hyper parameters: Current learning rate is 0.004013485310643763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54400/60000][Iteration 7460][Wall Clock 686.753159978s] Trained 128 records in 0.092812093 seconds. Throughput is 1379.1306 records/second. Loss is 0.114452004. Sequential31006cbd's hyper parameters: Current learning rate is 0.004013163175214704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54528/60000][Iteration 7461][Wall Clock 686.832255704s] Trained 128 records in 0.079095726 seconds. Throughput is 1618.2922 records/second. Loss is 0.14579666. Sequential31006cbd's hyper parameters: Current learning rate is 0.004012841091492777. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54656/60000][Iteration 7462][Wall Clock 686.91436326s] Trained 128 records in 0.082107556 seconds. Throughput is 1558.9308 records/second. Loss is 0.08712174. Sequential31006cbd's hyper parameters: Current learning rate is 0.004012519059465532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54784/60000][Iteration 7463][Wall Clock 686.995396714s] Trained 128 records in 0.081033454 seconds. Throughput is 1579.5945 records/second. Loss is 0.1451239. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040121970791205264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 54912/60000][Iteration 7464][Wall Clock 687.073200379s] Trained 128 records in 0.077803665 seconds. Throughput is 1645.1667 records/second. Loss is 0.13052522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040118751504453175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 55040/60000][Iteration 7465][Wall Clock 687.153579313s] Trained 128 records in 0.080378934 seconds. Throughput is 1592.457 records/second. Loss is 0.13847324. Sequential31006cbd's hyper parameters: Current learning rate is 0.004011553273427471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 55168/60000][Iteration 7466][Wall Clock 687.228942391s] Trained 128 records in 0.075363078 seconds. Throughput is 1698.4445 records/second. Loss is 0.09887802. Sequential31006cbd's hyper parameters: Current learning rate is 0.004011231448054552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 55296/60000][Iteration 7467][Wall Clock 687.30775446s] Trained 128 records in 0.078812069 seconds. Throughput is 1624.1167 records/second. Loss is 0.137545. Sequential31006cbd's hyper parameters: Current learning rate is 0.004010909674314135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:04 INFO  DistriOptimizer$:408 - [Epoch 16 55424/60000][Iteration 7468][Wall Clock 687.383833202s] Trained 128 records in 0.076078742 seconds. Throughput is 1682.4673 records/second. Loss is 0.16175616. Sequential31006cbd's hyper parameters: Current learning rate is 0.004010587952193791. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 55552/60000][Iteration 7469][Wall Clock 687.467935541s] Trained 128 records in 0.084102339 seconds. Throughput is 1521.9553 records/second. Loss is 0.17066005. Sequential31006cbd's hyper parameters: Current learning rate is 0.004010266281681104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 55680/60000][Iteration 7470][Wall Clock 687.543452908s] Trained 128 records in 0.075517367 seconds. Throughput is 1694.9744 records/second. Loss is 0.07991094. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040099446627636535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 55808/60000][Iteration 7471][Wall Clock 687.615791674s] Trained 128 records in 0.072338766 seconds. Throughput is 1769.4523 records/second. Loss is 0.14494558. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040096230954290305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 55936/60000][Iteration 7472][Wall Clock 687.710843787s] Trained 128 records in 0.095052113 seconds. Throughput is 1346.6296 records/second. Loss is 0.20426644. Sequential31006cbd's hyper parameters: Current learning rate is 0.004009301579664822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56064/60000][Iteration 7473][Wall Clock 687.792168499s] Trained 128 records in 0.081324712 seconds. Throughput is 1573.9374 records/second. Loss is 0.114935726. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040089801154586276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56192/60000][Iteration 7474][Wall Clock 687.869552836s] Trained 128 records in 0.077384337 seconds. Throughput is 1654.0814 records/second. Loss is 0.17995334. Sequential31006cbd's hyper parameters: Current learning rate is 0.004008658702798044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56320/60000][Iteration 7475][Wall Clock 687.945684031s] Trained 128 records in 0.076131195 seconds. Throughput is 1681.3082 records/second. Loss is 0.12116033. Sequential31006cbd's hyper parameters: Current learning rate is 0.004008337341670675. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56448/60000][Iteration 7476][Wall Clock 688.022457319s] Trained 128 records in 0.076773288 seconds. Throughput is 1667.2466 records/second. Loss is 0.1453483. Sequential31006cbd's hyper parameters: Current learning rate is 0.004008016032064128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56576/60000][Iteration 7477][Wall Clock 688.103685062s] Trained 128 records in 0.081227743 seconds. Throughput is 1575.8163 records/second. Loss is 0.14376612. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040076947739660146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56704/60000][Iteration 7478][Wall Clock 688.184522683s] Trained 128 records in 0.080837621 seconds. Throughput is 1583.4211 records/second. Loss is 0.14205047. Sequential31006cbd's hyper parameters: Current learning rate is 0.00400737356736395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56832/60000][Iteration 7479][Wall Clock 688.26721343s] Trained 128 records in 0.082690747 seconds. Throughput is 1547.9362 records/second. Loss is 0.16450694. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040070524122455525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 56960/60000][Iteration 7480][Wall Clock 688.35946839s] Trained 128 records in 0.09225496 seconds. Throughput is 1387.4594 records/second. Loss is 0.1447597. Sequential31006cbd's hyper parameters: Current learning rate is 0.004006731308598446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:05 INFO  DistriOptimizer$:408 - [Epoch 16 57088/60000][Iteration 7481][Wall Clock 688.446503822s] Trained 128 records in 0.087035432 seconds. Throughput is 1470.6654 records/second. Loss is 0.11508638. Sequential31006cbd's hyper parameters: Current learning rate is 0.004006410256410257. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57216/60000][Iteration 7482][Wall Clock 688.535278503s] Trained 128 records in 0.088774681 seconds. Throughput is 1441.8525 records/second. Loss is 0.09839016. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040060892556686165. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57344/60000][Iteration 7483][Wall Clock 688.607706719s] Trained 128 records in 0.072428216 seconds. Throughput is 1767.267 records/second. Loss is 0.14675988. Sequential31006cbd's hyper parameters: Current learning rate is 0.004005768306361159. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57472/60000][Iteration 7484][Wall Clock 688.687538274s] Trained 128 records in 0.079831555 seconds. Throughput is 1603.376 records/second. Loss is 0.14013737. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040054474084755265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57600/60000][Iteration 7485][Wall Clock 688.766329864s] Trained 128 records in 0.07879159 seconds. Throughput is 1624.539 records/second. Loss is 0.18861414. Sequential31006cbd's hyper parameters: Current learning rate is 0.004005126561999359. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57728/60000][Iteration 7486][Wall Clock 688.846119302s] Trained 128 records in 0.079789438 seconds. Throughput is 1604.2224 records/second. Loss is 0.21140686. Sequential31006cbd's hyper parameters: Current learning rate is 0.004004805766920304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57856/60000][Iteration 7487][Wall Clock 688.928171348s] Trained 128 records in 0.082052046 seconds. Throughput is 1559.9855 records/second. Loss is 0.106578685. Sequential31006cbd's hyper parameters: Current learning rate is 0.004004485023226013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 57984/60000][Iteration 7488][Wall Clock 689.006952965s] Trained 128 records in 0.078781617 seconds. Throughput is 1624.7445 records/second. Loss is 0.09187618. Sequential31006cbd's hyper parameters: Current learning rate is 0.004004164330904141. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 58112/60000][Iteration 7489][Wall Clock 689.079549108s] Trained 128 records in 0.072596143 seconds. Throughput is 1763.1792 records/second. Loss is 0.2737742. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040038436899423446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 58240/60000][Iteration 7490][Wall Clock 689.154496923s] Trained 128 records in 0.074947815 seconds. Throughput is 1707.8551 records/second. Loss is 0.123685285. Sequential31006cbd's hyper parameters: Current learning rate is 0.004003523100328289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 58368/60000][Iteration 7491][Wall Clock 689.22927501s] Trained 128 records in 0.074778087 seconds. Throughput is 1711.7314 records/second. Loss is 0.17457429. Sequential31006cbd's hyper parameters: Current learning rate is 0.0040032025620496394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 58496/60000][Iteration 7492][Wall Clock 689.303090632s] Trained 128 records in 0.073815622 seconds. Throughput is 1734.0503 records/second. Loss is 0.19237787. Sequential31006cbd's hyper parameters: Current learning rate is 0.004002882075094068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:06 INFO  DistriOptimizer$:408 - [Epoch 16 58624/60000][Iteration 7493][Wall Clock 689.376549521s] Trained 128 records in 0.073458889 seconds. Throughput is 1742.4713 records/second. Loss is 0.1936219. Sequential31006cbd's hyper parameters: Current learning rate is 0.004002561639449247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 58752/60000][Iteration 7494][Wall Clock 689.451410818s] Trained 128 records in 0.074861297 seconds. Throughput is 1709.8289 records/second. Loss is 0.13147856. Sequential31006cbd's hyper parameters: Current learning rate is 0.004002241255102857. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 58880/60000][Iteration 7495][Wall Clock 689.532601303s] Trained 128 records in 0.081190485 seconds. Throughput is 1576.5394 records/second. Loss is 0.17116605. Sequential31006cbd's hyper parameters: Current learning rate is 0.00400192092204258. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59008/60000][Iteration 7496][Wall Clock 689.60612543s] Trained 128 records in 0.073524127 seconds. Throughput is 1740.9252 records/second. Loss is 0.11546871. Sequential31006cbd's hyper parameters: Current learning rate is 0.004001600640256103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59136/60000][Iteration 7497][Wall Clock 689.69601326s] Trained 128 records in 0.08988783 seconds. Throughput is 1423.9971 records/second. Loss is 0.23768054. Sequential31006cbd's hyper parameters: Current learning rate is 0.004001280409731114. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59264/60000][Iteration 7498][Wall Clock 689.783583585s] Trained 128 records in 0.087570325 seconds. Throughput is 1461.6824 records/second. Loss is 0.19110243. Sequential31006cbd's hyper parameters: Current learning rate is 0.004000960230455309. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59392/60000][Iteration 7499][Wall Clock 689.880873481s] Trained 128 records in 0.097289896 seconds. Throughput is 1315.6556 records/second. Loss is 0.22477825. Sequential31006cbd's hyper parameters: Current learning rate is 0.004000640102416387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59520/60000][Iteration 7500][Wall Clock 689.974108939s] Trained 128 records in 0.093235458 seconds. Throughput is 1372.8683 records/second. Loss is 0.11674892. Sequential31006cbd's hyper parameters: Current learning rate is 0.004000320025602048. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59648/60000][Iteration 7501][Wall Clock 690.079754972s] Trained 128 records in 0.105646033 seconds. Throughput is 1211.593 records/second. Loss is 0.13569267. Sequential31006cbd's hyper parameters: Current learning rate is 0.004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59776/60000][Iteration 7502][Wall Clock 690.168887944s] Trained 128 records in 0.089132972 seconds. Throughput is 1436.0566 records/second. Loss is 0.19391595. Sequential31006cbd's hyper parameters: Current learning rate is 0.003999680025597952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 59904/60000][Iteration 7503][Wall Clock 690.260818808s] Trained 128 records in 0.091930864 seconds. Throughput is 1392.3506 records/second. Loss is 0.14308289. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039993601023836185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:408 - [Epoch 16 60032/60000][Iteration 7504][Wall Clock 690.341322104s] Trained 128 records in 0.080503296 seconds. Throughput is 1589.9971 records/second. Loss is 0.17252985. Sequential31006cbd's hyper parameters: Current learning rate is 0.003999040230344717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:07 INFO  DistriOptimizer$:452 - [Epoch 16 60032/60000][Iteration 7504][Wall Clock 690.341322104s] Epoch finished. Wall clock time is 691421.595607 ms
2019-10-24 00:09:07 INFO  DistriOptimizer$:111 - [Epoch 16 60032/60000][Iteration 7504][Wall Clock 690.341322104s] Validate model...
2019-10-24 00:09:08 INFO  DistriOptimizer$:178 - [Epoch 16 60032/60000][Iteration 7504][Wall Clock 690.341322104s] validate model throughput is 12202.802 records/second
2019-10-24 00:09:08 INFO  DistriOptimizer$:181 - [Epoch 16 60032/60000][Iteration 7504][Wall Clock 690.341322104s] Top1Accuracy is Accuracy(correct: 9546, count: 10000, accuracy: 0.9546)
2019-10-24 00:09:08 INFO  DistriOptimizer$:221 - [Wall Clock 691.421595607s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:09:08 INFO  DistriOptimizer$:226 - [Wall Clock 691.421595607s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:09:08 INFO  DistriOptimizer$:408 - [Epoch 17 128/60000][Iteration 7505][Wall Clock 691.507389511s] Trained 128 records in 0.085793904 seconds. Throughput is 1491.9475 records/second. Loss is 0.10595624. Sequential31006cbd's hyper parameters: Current learning rate is 0.00399872040946897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:08 INFO  DistriOptimizer$:408 - [Epoch 17 256/60000][Iteration 7506][Wall Clock 691.577413889s] Trained 128 records in 0.070024378 seconds. Throughput is 1827.9348 records/second. Loss is 0.16156612. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039984006397441015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 384/60000][Iteration 7507][Wall Clock 691.655682644s] Trained 128 records in 0.078268755 seconds. Throughput is 1635.3909 records/second. Loss is 0.11164233. Sequential31006cbd's hyper parameters: Current learning rate is 0.003998080921157845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 512/60000][Iteration 7508][Wall Clock 691.741801507s] Trained 128 records in 0.086118863 seconds. Throughput is 1486.3179 records/second. Loss is 0.1618361. Sequential31006cbd's hyper parameters: Current learning rate is 0.003997761253697929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 640/60000][Iteration 7509][Wall Clock 691.816384988s] Trained 128 records in 0.074583481 seconds. Throughput is 1716.1978 records/second. Loss is 0.1897292. Sequential31006cbd's hyper parameters: Current learning rate is 0.003997441637352095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 768/60000][Iteration 7510][Wall Clock 691.894503484s] Trained 128 records in 0.078118496 seconds. Throughput is 1638.5364 records/second. Loss is 0.16061193. Sequential31006cbd's hyper parameters: Current learning rate is 0.003997122072108082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 896/60000][Iteration 7511][Wall Clock 691.974056777s] Trained 128 records in 0.079553293 seconds. Throughput is 1608.9844 records/second. Loss is 0.14261548. Sequential31006cbd's hyper parameters: Current learning rate is 0.003996802557953637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1024/60000][Iteration 7512][Wall Clock 692.058913575s] Trained 128 records in 0.084856798 seconds. Throughput is 1508.4236 records/second. Loss is 0.2032943. Sequential31006cbd's hyper parameters: Current learning rate is 0.003996483094876508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1152/60000][Iteration 7513][Wall Clock 692.140499928s] Trained 128 records in 0.081586353 seconds. Throughput is 1568.8898 records/second. Loss is 0.119522884. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039961636828644495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1280/60000][Iteration 7514][Wall Clock 692.229189166s] Trained 128 records in 0.088689238 seconds. Throughput is 1443.2416 records/second. Loss is 0.2487615. Sequential31006cbd's hyper parameters: Current learning rate is 0.003995844321905219. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1408/60000][Iteration 7515][Wall Clock 692.306054083s] Trained 128 records in 0.076864917 seconds. Throughput is 1665.259 records/second. Loss is 0.123683035. Sequential31006cbd's hyper parameters: Current learning rate is 0.003995525011986575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1536/60000][Iteration 7516][Wall Clock 692.390532538s] Trained 128 records in 0.084478455 seconds. Throughput is 1515.1793 records/second. Loss is 0.12816828. Sequential31006cbd's hyper parameters: Current learning rate is 0.003995205753096284. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1664/60000][Iteration 7517][Wall Clock 692.474297186s] Trained 128 records in 0.083764648 seconds. Throughput is 1528.091 records/second. Loss is 0.21160811. Sequential31006cbd's hyper parameters: Current learning rate is 0.003994886545222115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:09 INFO  DistriOptimizer$:408 - [Epoch 17 1792/60000][Iteration 7518][Wall Clock 692.552838535s] Trained 128 records in 0.078541349 seconds. Throughput is 1629.7148 records/second. Loss is 0.16622008. Sequential31006cbd's hyper parameters: Current learning rate is 0.003994567388351841. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 1920/60000][Iteration 7519][Wall Clock 692.62700102s] Trained 128 records in 0.074162485 seconds. Throughput is 1725.9401 records/second. Loss is 0.14529684. Sequential31006cbd's hyper parameters: Current learning rate is 0.003994248282473239. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2048/60000][Iteration 7520][Wall Clock 692.720644541s] Trained 128 records in 0.093643521 seconds. Throughput is 1366.8857 records/second. Loss is 0.071899. Sequential31006cbd's hyper parameters: Current learning rate is 0.003993929227574087. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2176/60000][Iteration 7521][Wall Clock 692.808705325s] Trained 128 records in 0.088060784 seconds. Throughput is 1453.5415 records/second. Loss is 0.066200316. Sequential31006cbd's hyper parameters: Current learning rate is 0.003993610223642172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2304/60000][Iteration 7522][Wall Clock 692.888985205s] Trained 128 records in 0.08027988 seconds. Throughput is 1594.4219 records/second. Loss is 0.13042437. Sequential31006cbd's hyper parameters: Current learning rate is 0.003993291270665282. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2432/60000][Iteration 7523][Wall Clock 692.966111337s] Trained 128 records in 0.077126132 seconds. Throughput is 1659.6191 records/second. Loss is 0.17143849. Sequential31006cbd's hyper parameters: Current learning rate is 0.003992972368631209. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2560/60000][Iteration 7524][Wall Clock 693.04213719s] Trained 128 records in 0.076025853 seconds. Throughput is 1683.6378 records/second. Loss is 0.1411982. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039926535175277495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2688/60000][Iteration 7525][Wall Clock 693.125605222s] Trained 128 records in 0.083468032 seconds. Throughput is 1533.5212 records/second. Loss is 0.16553527. Sequential31006cbd's hyper parameters: Current learning rate is 0.003992334717342702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2816/60000][Iteration 7526][Wall Clock 693.200785222s] Trained 128 records in 0.07518 seconds. Throughput is 1702.5804 records/second. Loss is 0.1299634. Sequential31006cbd's hyper parameters: Current learning rate is 0.003992015968063873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 2944/60000][Iteration 7527][Wall Clock 693.278353738s] Trained 128 records in 0.077568516 seconds. Throughput is 1650.154 records/second. Loss is 0.21373007. Sequential31006cbd's hyper parameters: Current learning rate is 0.003991697269679067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 3072/60000][Iteration 7528][Wall Clock 693.353627852s] Trained 128 records in 0.075274114 seconds. Throughput is 1700.4517 records/second. Loss is 0.0769888. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039913786221761. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 3200/60000][Iteration 7529][Wall Clock 693.439726625s] Trained 128 records in 0.086098773 seconds. Throughput is 1486.6646 records/second. Loss is 0.1709601. Sequential31006cbd's hyper parameters: Current learning rate is 0.003991060025542783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 3328/60000][Iteration 7530][Wall Clock 693.515195267s] Trained 128 records in 0.075468642 seconds. Throughput is 1696.0686 records/second. Loss is 0.15854907. Sequential31006cbd's hyper parameters: Current learning rate is 0.003990741479766941. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:10 INFO  DistriOptimizer$:408 - [Epoch 17 3456/60000][Iteration 7531][Wall Clock 693.5912218s] Trained 128 records in 0.076026533 seconds. Throughput is 1683.6227 records/second. Loss is 0.21784836. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039904229848363925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 3584/60000][Iteration 7532][Wall Clock 693.666785019s] Trained 128 records in 0.075563219 seconds. Throughput is 1693.9458 records/second. Loss is 0.20727837. Sequential31006cbd's hyper parameters: Current learning rate is 0.003990104540738968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 3712/60000][Iteration 7533][Wall Clock 693.749297095s] Trained 128 records in 0.082512076 seconds. Throughput is 1551.2881 records/second. Loss is 0.23119189. Sequential31006cbd's hyper parameters: Current learning rate is 0.003989786147462496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 3840/60000][Iteration 7534][Wall Clock 693.827601784s] Trained 128 records in 0.078304689 seconds. Throughput is 1634.6404 records/second. Loss is 0.20828566. Sequential31006cbd's hyper parameters: Current learning rate is 0.003989467804994814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 3968/60000][Iteration 7535][Wall Clock 693.900551426s] Trained 128 records in 0.072949642 seconds. Throughput is 1754.6351 records/second. Loss is 0.23614064. Sequential31006cbd's hyper parameters: Current learning rate is 0.003989149513323759. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4096/60000][Iteration 7536][Wall Clock 693.981701624s] Trained 128 records in 0.081150198 seconds. Throughput is 1577.3221 records/second. Loss is 0.1942107. Sequential31006cbd's hyper parameters: Current learning rate is 0.003988831272437176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4224/60000][Iteration 7537][Wall Clock 694.061403415s] Trained 128 records in 0.079701791 seconds. Throughput is 1605.9866 records/second. Loss is 0.17592673. Sequential31006cbd's hyper parameters: Current learning rate is 0.00398851308232291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4352/60000][Iteration 7538][Wall Clock 694.142864164s] Trained 128 records in 0.081460749 seconds. Throughput is 1571.3088 records/second. Loss is 0.13668653. Sequential31006cbd's hyper parameters: Current learning rate is 0.003988194942968812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4480/60000][Iteration 7539][Wall Clock 694.22063719s] Trained 128 records in 0.077773026 seconds. Throughput is 1645.8148 records/second. Loss is 0.15841852. Sequential31006cbd's hyper parameters: Current learning rate is 0.003987876854362737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4608/60000][Iteration 7540][Wall Clock 694.309537026s] Trained 128 records in 0.088899836 seconds. Throughput is 1439.8226 records/second. Loss is 0.16752002. Sequential31006cbd's hyper parameters: Current learning rate is 0.003987558816492543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4736/60000][Iteration 7541][Wall Clock 694.391924325s] Trained 128 records in 0.082387299 seconds. Throughput is 1553.6376 records/second. Loss is 0.15345068. Sequential31006cbd's hyper parameters: Current learning rate is 0.003987240829346092. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4864/60000][Iteration 7542][Wall Clock 694.471170261s] Trained 128 records in 0.079245936 seconds. Throughput is 1615.2249 records/second. Loss is 0.19416174. Sequential31006cbd's hyper parameters: Current learning rate is 0.003986922892911251. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:11 INFO  DistriOptimizer$:408 - [Epoch 17 4992/60000][Iteration 7543][Wall Clock 694.550033265s] Trained 128 records in 0.078863004 seconds. Throughput is 1623.0677 records/second. Loss is 0.20839769. Sequential31006cbd's hyper parameters: Current learning rate is 0.003986605007175889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5120/60000][Iteration 7544][Wall Clock 694.62792327s] Trained 128 records in 0.077890005 seconds. Throughput is 1643.343 records/second. Loss is 0.14803252. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039862871721278795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5248/60000][Iteration 7545][Wall Clock 694.708345599s] Trained 128 records in 0.080422329 seconds. Throughput is 1591.5978 records/second. Loss is 0.11776714. Sequential31006cbd's hyper parameters: Current learning rate is 0.003985969387755102. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5376/60000][Iteration 7546][Wall Clock 694.830818756s] Trained 128 records in 0.122473157 seconds. Throughput is 1045.127 records/second. Loss is 0.13268551. Sequential31006cbd's hyper parameters: Current learning rate is 0.003985651654045436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5504/60000][Iteration 7547][Wall Clock 694.941971473s] Trained 128 records in 0.111152717 seconds. Throughput is 1151.5688 records/second. Loss is 0.11594525. Sequential31006cbd's hyper parameters: Current learning rate is 0.003985333970986769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5632/60000][Iteration 7548][Wall Clock 695.020555075s] Trained 128 records in 0.078583602 seconds. Throughput is 1628.8385 records/second. Loss is 0.14690736. Sequential31006cbd's hyper parameters: Current learning rate is 0.003985016338566988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5760/60000][Iteration 7549][Wall Clock 695.099382336s] Trained 128 records in 0.078827261 seconds. Throughput is 1623.8037 records/second. Loss is 0.169019. Sequential31006cbd's hyper parameters: Current learning rate is 0.003984698756773988. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 5888/60000][Iteration 7550][Wall Clock 695.188751246s] Trained 128 records in 0.08936891 seconds. Throughput is 1432.2654 records/second. Loss is 0.14382088. Sequential31006cbd's hyper parameters: Current learning rate is 0.003984381225595665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 6016/60000][Iteration 7551][Wall Clock 695.276230903s] Trained 128 records in 0.087479657 seconds. Throughput is 1463.1973 records/second. Loss is 0.16827533. Sequential31006cbd's hyper parameters: Current learning rate is 0.003984063745019921. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 6144/60000][Iteration 7552][Wall Clock 695.358770842s] Trained 128 records in 0.082539939 seconds. Throughput is 1550.7644 records/second. Loss is 0.1555979. Sequential31006cbd's hyper parameters: Current learning rate is 0.003983746315034659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 6272/60000][Iteration 7553][Wall Clock 695.430878956s] Trained 128 records in 0.072108114 seconds. Throughput is 1775.1123 records/second. Loss is 0.12768346. Sequential31006cbd's hyper parameters: Current learning rate is 0.003983428935627789. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 6400/60000][Iteration 7554][Wall Clock 695.506377055s] Trained 128 records in 0.075498099 seconds. Throughput is 1695.407 records/second. Loss is 0.14880869. Sequential31006cbd's hyper parameters: Current learning rate is 0.003983111606787222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:12 INFO  DistriOptimizer$:408 - [Epoch 17 6528/60000][Iteration 7555][Wall Clock 695.589200645s] Trained 128 records in 0.08282359 seconds. Throughput is 1545.4534 records/second. Loss is 0.14871474. Sequential31006cbd's hyper parameters: Current learning rate is 0.003982794328500876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 6656/60000][Iteration 7556][Wall Clock 695.661000489s] Trained 128 records in 0.071799844 seconds. Throughput is 1782.7336 records/second. Loss is 0.22631264. Sequential31006cbd's hyper parameters: Current learning rate is 0.00398247710075667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 6784/60000][Iteration 7557][Wall Clock 695.733736081s] Trained 128 records in 0.072735592 seconds. Throughput is 1759.7987 records/second. Loss is 0.13717467. Sequential31006cbd's hyper parameters: Current learning rate is 0.00398215992354253. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 6912/60000][Iteration 7558][Wall Clock 695.809278938s] Trained 128 records in 0.075542857 seconds. Throughput is 1694.4023 records/second. Loss is 0.1405713. Sequential31006cbd's hyper parameters: Current learning rate is 0.003981842796846381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7040/60000][Iteration 7559][Wall Clock 695.89166824s] Trained 128 records in 0.082389302 seconds. Throughput is 1553.5997 records/second. Loss is 0.1521365. Sequential31006cbd's hyper parameters: Current learning rate is 0.003981525720656155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7168/60000][Iteration 7560][Wall Clock 695.974672547s] Trained 128 records in 0.083004307 seconds. Throughput is 1542.0887 records/second. Loss is 0.1495546. Sequential31006cbd's hyper parameters: Current learning rate is 0.00398120869495979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7296/60000][Iteration 7561][Wall Clock 696.053039774s] Trained 128 records in 0.078367227 seconds. Throughput is 1633.3358 records/second. Loss is 0.12663595. Sequential31006cbd's hyper parameters: Current learning rate is 0.003980891719745223. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7424/60000][Iteration 7562][Wall Clock 696.13586573s] Trained 128 records in 0.082825956 seconds. Throughput is 1545.4092 records/second. Loss is 0.249399. Sequential31006cbd's hyper parameters: Current learning rate is 0.003980574795000399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7552/60000][Iteration 7563][Wall Clock 696.214298382s] Trained 128 records in 0.078432652 seconds. Throughput is 1631.9734 records/second. Loss is 0.19043347. Sequential31006cbd's hyper parameters: Current learning rate is 0.003980257920713263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7680/60000][Iteration 7564][Wall Clock 696.291906255s] Trained 128 records in 0.077607873 seconds. Throughput is 1649.3173 records/second. Loss is 0.18350807. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039799410968717665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7808/60000][Iteration 7565][Wall Clock 696.395138232s] Trained 128 records in 0.103231977 seconds. Throughput is 1239.9259 records/second. Loss is 0.16386011. Sequential31006cbd's hyper parameters: Current learning rate is 0.003979624323463864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 7936/60000][Iteration 7566][Wall Clock 696.468446669s] Trained 128 records in 0.073308437 seconds. Throughput is 1746.0472 records/second. Loss is 0.24097289. Sequential31006cbd's hyper parameters: Current learning rate is 0.003979307600477517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:13 INFO  DistriOptimizer$:408 - [Epoch 17 8064/60000][Iteration 7567][Wall Clock 696.543650555s] Trained 128 records in 0.075203886 seconds. Throughput is 1702.0397 records/second. Loss is 0.12224741. Sequential31006cbd's hyper parameters: Current learning rate is 0.003978990927900684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8192/60000][Iteration 7568][Wall Clock 696.619111252s] Trained 128 records in 0.075460697 seconds. Throughput is 1696.2473 records/second. Loss is 0.107695736. Sequential31006cbd's hyper parameters: Current learning rate is 0.003978674305721334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8320/60000][Iteration 7569][Wall Clock 696.69971942s] Trained 128 records in 0.080608168 seconds. Throughput is 1587.9285 records/second. Loss is 0.2248129. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039783577339274345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8448/60000][Iteration 7570][Wall Clock 696.774810571s] Trained 128 records in 0.075091151 seconds. Throughput is 1704.595 records/second. Loss is 0.16434206. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039780412125069615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8576/60000][Iteration 7571][Wall Clock 696.866455746s] Trained 128 records in 0.091645175 seconds. Throughput is 1396.6912 records/second. Loss is 0.2304285. Sequential31006cbd's hyper parameters: Current learning rate is 0.003977724741447891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8704/60000][Iteration 7572][Wall Clock 696.946657144s] Trained 128 records in 0.080201398 seconds. Throughput is 1595.9822 records/second. Loss is 0.102663584. Sequential31006cbd's hyper parameters: Current learning rate is 0.003977408320738208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8832/60000][Iteration 7573][Wall Clock 697.017026654s] Trained 128 records in 0.07036951 seconds. Throughput is 1818.9696 records/second. Loss is 0.21758415. Sequential31006cbd's hyper parameters: Current learning rate is 0.003977091950365892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 8960/60000][Iteration 7574][Wall Clock 697.093573209s] Trained 128 records in 0.076546555 seconds. Throughput is 1672.1849 records/second. Loss is 0.1591125. Sequential31006cbd's hyper parameters: Current learning rate is 0.003976775630318937. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 9088/60000][Iteration 7575][Wall Clock 697.175375132s] Trained 128 records in 0.081801923 seconds. Throughput is 1564.7554 records/second. Loss is 0.12665337. Sequential31006cbd's hyper parameters: Current learning rate is 0.003976459360585335. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 9216/60000][Iteration 7576][Wall Clock 697.252513698s] Trained 128 records in 0.077138566 seconds. Throughput is 1659.3516 records/second. Loss is 0.19417258. Sequential31006cbd's hyper parameters: Current learning rate is 0.003976143141153081. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 9344/60000][Iteration 7577][Wall Clock 697.331665954s] Trained 128 records in 0.079152256 seconds. Throughput is 1617.1365 records/second. Loss is 0.2017535. Sequential31006cbd's hyper parameters: Current learning rate is 0.003975826972010178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 9472/60000][Iteration 7578][Wall Clock 697.4063139s] Trained 128 records in 0.074647946 seconds. Throughput is 1714.7156 records/second. Loss is 0.14654304. Sequential31006cbd's hyper parameters: Current learning rate is 0.003975510853144629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 9600/60000][Iteration 7579][Wall Clock 697.480601179s] Trained 128 records in 0.074287279 seconds. Throughput is 1723.0406 records/second. Loss is 0.18429247. Sequential31006cbd's hyper parameters: Current learning rate is 0.003975194784544443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:14 INFO  DistriOptimizer$:408 - [Epoch 17 9728/60000][Iteration 7580][Wall Clock 697.561868074s] Trained 128 records in 0.081266895 seconds. Throughput is 1575.0571 records/second. Loss is 0.18193051. Sequential31006cbd's hyper parameters: Current learning rate is 0.003974878766197631. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 9856/60000][Iteration 7581][Wall Clock 697.643323835s] Trained 128 records in 0.081455761 seconds. Throughput is 1571.4052 records/second. Loss is 0.12818328. Sequential31006cbd's hyper parameters: Current learning rate is 0.00397456279809221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 9984/60000][Iteration 7582][Wall Clock 697.720101705s] Trained 128 records in 0.07677787 seconds. Throughput is 1667.1471 records/second. Loss is 0.17339014. Sequential31006cbd's hyper parameters: Current learning rate is 0.003974246880216199. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10112/60000][Iteration 7583][Wall Clock 697.798082028s] Trained 128 records in 0.077980323 seconds. Throughput is 1641.4397 records/second. Loss is 0.12903905. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039739310125576225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10240/60000][Iteration 7584][Wall Clock 697.878157087s] Trained 128 records in 0.080075059 seconds. Throughput is 1598.5002 records/second. Loss is 0.114394635. Sequential31006cbd's hyper parameters: Current learning rate is 0.003973615195104505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10368/60000][Iteration 7585][Wall Clock 697.961348669s] Trained 128 records in 0.083191582 seconds. Throughput is 1538.6172 records/second. Loss is 0.13856539. Sequential31006cbd's hyper parameters: Current learning rate is 0.003973299427844882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10496/60000][Iteration 7586][Wall Clock 698.041776469s] Trained 128 records in 0.0804278 seconds. Throughput is 1591.4895 records/second. Loss is 0.14943697. Sequential31006cbd's hyper parameters: Current learning rate is 0.003972983710766785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10624/60000][Iteration 7587][Wall Clock 698.117745258s] Trained 128 records in 0.075968789 seconds. Throughput is 1684.9025 records/second. Loss is 0.1784601. Sequential31006cbd's hyper parameters: Current learning rate is 0.003972668043858255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10752/60000][Iteration 7588][Wall Clock 698.19640626s] Trained 128 records in 0.078661002 seconds. Throughput is 1627.2358 records/second. Loss is 0.1468403. Sequential31006cbd's hyper parameters: Current learning rate is 0.003972352427107332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 10880/60000][Iteration 7589][Wall Clock 698.27569892s] Trained 128 records in 0.07929266 seconds. Throughput is 1614.273 records/second. Loss is 0.13627513. Sequential31006cbd's hyper parameters: Current learning rate is 0.003972036860502065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 11008/60000][Iteration 7590][Wall Clock 698.366434348s] Trained 128 records in 0.090735428 seconds. Throughput is 1410.6948 records/second. Loss is 0.19521639. Sequential31006cbd's hyper parameters: Current learning rate is 0.003971721344030502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 11136/60000][Iteration 7591][Wall Clock 698.440460383s] Trained 128 records in 0.074026035 seconds. Throughput is 1729.1215 records/second. Loss is 0.14476682. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039714058776807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:15 INFO  DistriOptimizer$:408 - [Epoch 17 11264/60000][Iteration 7592][Wall Clock 698.514021714s] Trained 128 records in 0.073561331 seconds. Throughput is 1740.0446 records/second. Loss is 0.18739027. Sequential31006cbd's hyper parameters: Current learning rate is 0.003971090461440711. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 11392/60000][Iteration 7593][Wall Clock 698.595173297s] Trained 128 records in 0.081151583 seconds. Throughput is 1577.2952 records/second. Loss is 0.09777418. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039707750952986025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 11520/60000][Iteration 7594][Wall Clock 698.66908195s] Trained 128 records in 0.073908653 seconds. Throughput is 1731.8677 records/second. Loss is 0.105653115. Sequential31006cbd's hyper parameters: Current learning rate is 0.003970459779242436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 11648/60000][Iteration 7595][Wall Clock 698.746244652s] Trained 128 records in 0.077162702 seconds. Throughput is 1658.8324 records/second. Loss is 0.15374003. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039701445132602825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 11776/60000][Iteration 7596][Wall Clock 698.834300721s] Trained 128 records in 0.088056069 seconds. Throughput is 1453.6193 records/second. Loss is 0.14110726. Sequential31006cbd's hyper parameters: Current learning rate is 0.003969829297340214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 11904/60000][Iteration 7597][Wall Clock 698.912789574s] Trained 128 records in 0.078488853 seconds. Throughput is 1630.8048 records/second. Loss is 0.089438945. Sequential31006cbd's hyper parameters: Current learning rate is 0.003969514131470308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12032/60000][Iteration 7598][Wall Clock 698.987998527s] Trained 128 records in 0.075208953 seconds. Throughput is 1701.925 records/second. Loss is 0.21880963. Sequential31006cbd's hyper parameters: Current learning rate is 0.003969199015638644. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12160/60000][Iteration 7599][Wall Clock 699.058505295s] Trained 128 records in 0.070506768 seconds. Throughput is 1815.4286 records/second. Loss is 0.11871721. Sequential31006cbd's hyper parameters: Current learning rate is 0.003968883949833307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12288/60000][Iteration 7600][Wall Clock 699.134457535s] Trained 128 records in 0.07595224 seconds. Throughput is 1685.2697 records/second. Loss is 0.14121747. Sequential31006cbd's hyper parameters: Current learning rate is 0.003968568934042385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12416/60000][Iteration 7601][Wall Clock 699.21184441s] Trained 128 records in 0.077386875 seconds. Throughput is 1654.0272 records/second. Loss is 0.07856474. Sequential31006cbd's hyper parameters: Current learning rate is 0.003968253968253968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12544/60000][Iteration 7602][Wall Clock 699.293753962s] Trained 128 records in 0.081909552 seconds. Throughput is 1562.6993 records/second. Loss is 0.15397848. Sequential31006cbd's hyper parameters: Current learning rate is 0.003967939052456154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12672/60000][Iteration 7603][Wall Clock 699.378930278s] Trained 128 records in 0.085176316 seconds. Throughput is 1502.7651 records/second. Loss is 0.12500915. Sequential31006cbd's hyper parameters: Current learning rate is 0.003967624186637042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12800/60000][Iteration 7604][Wall Clock 699.454146895s] Trained 128 records in 0.075216617 seconds. Throughput is 1701.7517 records/second. Loss is 0.11744626. Sequential31006cbd's hyper parameters: Current learning rate is 0.003967309370784734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:16 INFO  DistriOptimizer$:408 - [Epoch 17 12928/60000][Iteration 7605][Wall Clock 699.527868361s] Trained 128 records in 0.073721466 seconds. Throughput is 1736.2649 records/second. Loss is 0.11682959. Sequential31006cbd's hyper parameters: Current learning rate is 0.003966994604887337. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13056/60000][Iteration 7606][Wall Clock 699.630624936s] Trained 128 records in 0.102756575 seconds. Throughput is 1245.6624 records/second. Loss is 0.24605533. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039666798889329636. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13184/60000][Iteration 7607][Wall Clock 699.733051543s] Trained 128 records in 0.102426607 seconds. Throughput is 1249.6753 records/second. Loss is 0.16244608. Sequential31006cbd's hyper parameters: Current learning rate is 0.003966365222909725. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13312/60000][Iteration 7608][Wall Clock 699.815752982s] Trained 128 records in 0.082701439 seconds. Throughput is 1547.7361 records/second. Loss is 0.16086303. Sequential31006cbd's hyper parameters: Current learning rate is 0.003966050606805743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13440/60000][Iteration 7609][Wall Clock 699.893912167s] Trained 128 records in 0.078159185 seconds. Throughput is 1637.6835 records/second. Loss is 0.19713913. Sequential31006cbd's hyper parameters: Current learning rate is 0.003965736040609137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13568/60000][Iteration 7610][Wall Clock 699.975099471s] Trained 128 records in 0.081187304 seconds. Throughput is 1576.6013 records/second. Loss is 0.21776442. Sequential31006cbd's hyper parameters: Current learning rate is 0.003965421524308035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13696/60000][Iteration 7611][Wall Clock 700.049152989s] Trained 128 records in 0.074053518 seconds. Throughput is 1728.4796 records/second. Loss is 0.08541729. Sequential31006cbd's hyper parameters: Current learning rate is 0.003965107057890563. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13824/60000][Iteration 7612][Wall Clock 700.123665272s] Trained 128 records in 0.074512283 seconds. Throughput is 1717.8376 records/second. Loss is 0.15393233. Sequential31006cbd's hyper parameters: Current learning rate is 0.003964792641344858. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 13952/60000][Iteration 7613][Wall Clock 700.202398754s] Trained 128 records in 0.078733482 seconds. Throughput is 1625.7378 records/second. Loss is 0.07567826. Sequential31006cbd's hyper parameters: Current learning rate is 0.003964478274659055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 14080/60000][Iteration 7614][Wall Clock 700.281797225s] Trained 128 records in 0.079398471 seconds. Throughput is 1612.1218 records/second. Loss is 0.18301487. Sequential31006cbd's hyper parameters: Current learning rate is 0.003964163957821295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 14208/60000][Iteration 7615][Wall Clock 700.360244948s] Trained 128 records in 0.078447723 seconds. Throughput is 1631.6599 records/second. Loss is 0.26641488. Sequential31006cbd's hyper parameters: Current learning rate is 0.003963849690819724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 14336/60000][Iteration 7616][Wall Clock 700.440891057s] Trained 128 records in 0.080646109 seconds. Throughput is 1587.1813 records/second. Loss is 0.1796148. Sequential31006cbd's hyper parameters: Current learning rate is 0.003963535473642489. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:17 INFO  DistriOptimizer$:408 - [Epoch 17 14464/60000][Iteration 7617][Wall Clock 700.519442213s] Trained 128 records in 0.078551156 seconds. Throughput is 1629.5114 records/second. Loss is 0.17211737. Sequential31006cbd's hyper parameters: Current learning rate is 0.003963221306277742. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 14592/60000][Iteration 7618][Wall Clock 700.594176804s] Trained 128 records in 0.074734591 seconds. Throughput is 1712.7277 records/second. Loss is 0.09207925. Sequential31006cbd's hyper parameters: Current learning rate is 0.00396290718871364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 14720/60000][Iteration 7619][Wall Clock 700.680412356s] Trained 128 records in 0.086235552 seconds. Throughput is 1484.3066 records/second. Loss is 0.1573789. Sequential31006cbd's hyper parameters: Current learning rate is 0.003962593120938342. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 14848/60000][Iteration 7620][Wall Clock 700.760898969s] Trained 128 records in 0.080486613 seconds. Throughput is 1590.3267 records/second. Loss is 0.16735774. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039622791029400115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 14976/60000][Iteration 7621][Wall Clock 700.853027449s] Trained 128 records in 0.09212848 seconds. Throughput is 1389.3641 records/second. Loss is 0.21198629. Sequential31006cbd's hyper parameters: Current learning rate is 0.003961965134706815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15104/60000][Iteration 7622][Wall Clock 700.935136862s] Trained 128 records in 0.082109413 seconds. Throughput is 1558.8955 records/second. Loss is 0.24466893. Sequential31006cbd's hyper parameters: Current learning rate is 0.003961651216226924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15232/60000][Iteration 7623][Wall Clock 701.029610135s] Trained 128 records in 0.094473273 seconds. Throughput is 1354.8806 records/second. Loss is 0.13281679. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039613373474885125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15360/60000][Iteration 7624][Wall Clock 701.112087494s] Trained 128 records in 0.082477359 seconds. Throughput is 1551.941 records/second. Loss is 0.25606182. Sequential31006cbd's hyper parameters: Current learning rate is 0.003961023528479758. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15488/60000][Iteration 7625][Wall Clock 701.192120558s] Trained 128 records in 0.080033064 seconds. Throughput is 1599.339 records/second. Loss is 0.16379762. Sequential31006cbd's hyper parameters: Current learning rate is 0.003960709759188847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15616/60000][Iteration 7626][Wall Clock 701.273906197s] Trained 128 records in 0.081785639 seconds. Throughput is 1565.0669 records/second. Loss is 0.117920436. Sequential31006cbd's hyper parameters: Current learning rate is 0.00396039603960396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15744/60000][Iteration 7627][Wall Clock 701.356516478s] Trained 128 records in 0.082610281 seconds. Throughput is 1549.444 records/second. Loss is 0.13296746. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039600823697132905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 15872/60000][Iteration 7628][Wall Clock 701.449387582s] Trained 128 records in 0.092871104 seconds. Throughput is 1378.2543 records/second. Loss is 0.19125438. Sequential31006cbd's hyper parameters: Current learning rate is 0.003959768749505028. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:18 INFO  DistriOptimizer$:408 - [Epoch 17 16000/60000][Iteration 7629][Wall Clock 701.529834965s] Trained 128 records in 0.080447383 seconds. Throughput is 1591.102 records/second. Loss is 0.08982446. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039594551789673745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16128/60000][Iteration 7630][Wall Clock 701.612709785s] Trained 128 records in 0.08287482 seconds. Throughput is 1544.498 records/second. Loss is 0.13269159. Sequential31006cbd's hyper parameters: Current learning rate is 0.003959141658088526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16256/60000][Iteration 7631][Wall Clock 701.701144671s] Trained 128 records in 0.088434886 seconds. Throughput is 1447.3927 records/second. Loss is 0.13452446. Sequential31006cbd's hyper parameters: Current learning rate is 0.003958828186856691. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16384/60000][Iteration 7632][Wall Clock 701.786222846s] Trained 128 records in 0.085078175 seconds. Throughput is 1504.4987 records/second. Loss is 0.17569487. Sequential31006cbd's hyper parameters: Current learning rate is 0.003958514765260074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16512/60000][Iteration 7633][Wall Clock 701.859026878s] Trained 128 records in 0.072804032 seconds. Throughput is 1758.1443 records/second. Loss is 0.1478811. Sequential31006cbd's hyper parameters: Current learning rate is 0.003958201393286891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16640/60000][Iteration 7634][Wall Clock 701.93767863s] Trained 128 records in 0.078651752 seconds. Throughput is 1627.4272 records/second. Loss is 0.21394622. Sequential31006cbd's hyper parameters: Current learning rate is 0.003957888070925354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16768/60000][Iteration 7635][Wall Clock 702.02271997s] Trained 128 records in 0.08504134 seconds. Throughput is 1505.1504 records/second. Loss is 0.120679185. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039575747981636855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 16896/60000][Iteration 7636][Wall Clock 702.09789185s] Trained 128 records in 0.07517188 seconds. Throughput is 1702.7644 records/second. Loss is 0.15287688. Sequential31006cbd's hyper parameters: Current learning rate is 0.003957261574990107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 17024/60000][Iteration 7637][Wall Clock 702.175781544s] Trained 128 records in 0.077889694 seconds. Throughput is 1643.3496 records/second. Loss is 0.1848865. Sequential31006cbd's hyper parameters: Current learning rate is 0.003956948401392846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 17152/60000][Iteration 7638][Wall Clock 702.255448241s] Trained 128 records in 0.079666697 seconds. Throughput is 1606.694 records/second. Loss is 0.14496043. Sequential31006cbd's hyper parameters: Current learning rate is 0.003956635277360133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 17280/60000][Iteration 7639][Wall Clock 702.342053951s] Trained 128 records in 0.08660571 seconds. Throughput is 1477.9625 records/second. Loss is 0.14337742. Sequential31006cbd's hyper parameters: Current learning rate is 0.003956322202880202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 17408/60000][Iteration 7640][Wall Clock 702.429221145s] Trained 128 records in 0.087167194 seconds. Throughput is 1468.4424 records/second. Loss is 0.20425831. Sequential31006cbd's hyper parameters: Current learning rate is 0.003956009177941293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:19 INFO  DistriOptimizer$:408 - [Epoch 17 17536/60000][Iteration 7641][Wall Clock 702.508799418s] Trained 128 records in 0.079578273 seconds. Throughput is 1608.4792 records/second. Loss is 0.095508575. Sequential31006cbd's hyper parameters: Current learning rate is 0.003955696202531646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 17664/60000][Iteration 7642][Wall Clock 702.586262042s] Trained 128 records in 0.077462624 seconds. Throughput is 1652.4099 records/second. Loss is 0.1950823. Sequential31006cbd's hyper parameters: Current learning rate is 0.003955383276639506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 17792/60000][Iteration 7643][Wall Clock 702.665629003s] Trained 128 records in 0.079366961 seconds. Throughput is 1612.7618 records/second. Loss is 0.14726183. Sequential31006cbd's hyper parameters: Current learning rate is 0.003955070400253125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 17920/60000][Iteration 7644][Wall Clock 702.745457318s] Trained 128 records in 0.079828315 seconds. Throughput is 1603.441 records/second. Loss is 0.15149061. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039547575733607536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18048/60000][Iteration 7645][Wall Clock 702.826149018s] Trained 128 records in 0.0806917 seconds. Throughput is 1586.2845 records/second. Loss is 0.15288419. Sequential31006cbd's hyper parameters: Current learning rate is 0.003954444795950648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18176/60000][Iteration 7646][Wall Clock 702.916402679s] Trained 128 records in 0.090253661 seconds. Throughput is 1418.2251 records/second. Loss is 0.15605742. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039541320680110716. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18304/60000][Iteration 7647][Wall Clock 702.999524766s] Trained 128 records in 0.083122087 seconds. Throughput is 1539.9036 records/second. Loss is 0.15333447. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039538193895302855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18432/60000][Iteration 7648][Wall Clock 703.085811264s] Trained 128 records in 0.086286498 seconds. Throughput is 1483.4302 records/second. Loss is 0.15417737. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039535067604965606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18560/60000][Iteration 7649][Wall Clock 703.159332262s] Trained 128 records in 0.073520998 seconds. Throughput is 1740.9993 records/second. Loss is 0.15999496. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039531941808981655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18688/60000][Iteration 7650][Wall Clock 703.241207571s] Trained 128 records in 0.081875309 seconds. Throughput is 1563.3529 records/second. Loss is 0.20267788. Sequential31006cbd's hyper parameters: Current learning rate is 0.003952881650723378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18816/60000][Iteration 7651][Wall Clock 703.325659234s] Trained 128 records in 0.084451663 seconds. Throughput is 1515.6599 records/second. Loss is 0.18949726. Sequential31006cbd's hyper parameters: Current learning rate is 0.003952569169960474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 18944/60000][Iteration 7652][Wall Clock 703.418473044s] Trained 128 records in 0.09281381 seconds. Throughput is 1379.1051 records/second. Loss is 0.20569086. Sequential31006cbd's hyper parameters: Current learning rate is 0.00395225673859774. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:20 INFO  DistriOptimizer$:408 - [Epoch 17 19072/60000][Iteration 7653][Wall Clock 703.499558993s] Trained 128 records in 0.081085949 seconds. Throughput is 1578.5719 records/second. Loss is 0.10768099. Sequential31006cbd's hyper parameters: Current learning rate is 0.003951944356623459. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19200/60000][Iteration 7654][Wall Clock 703.594836803s] Trained 128 records in 0.09527781 seconds. Throughput is 1343.4398 records/second. Loss is 0.16136727. Sequential31006cbd's hyper parameters: Current learning rate is 0.003951632024025923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19328/60000][Iteration 7655][Wall Clock 703.672187773s] Trained 128 records in 0.07735097 seconds. Throughput is 1654.795 records/second. Loss is 0.19346309. Sequential31006cbd's hyper parameters: Current learning rate is 0.003951319740793425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19456/60000][Iteration 7656][Wall Clock 703.74904762s] Trained 128 records in 0.076859847 seconds. Throughput is 1665.3689 records/second. Loss is 0.21446115. Sequential31006cbd's hyper parameters: Current learning rate is 0.003951007506914263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19584/60000][Iteration 7657][Wall Clock 703.840452829s] Trained 128 records in 0.091405209 seconds. Throughput is 1400.3579 records/second. Loss is 0.14095655. Sequential31006cbd's hyper parameters: Current learning rate is 0.003950695322376738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19712/60000][Iteration 7658][Wall Clock 703.912263286s] Trained 128 records in 0.071810457 seconds. Throughput is 1782.4703 records/second. Loss is 0.20155549. Sequential31006cbd's hyper parameters: Current learning rate is 0.003950383187169155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19840/60000][Iteration 7659][Wall Clock 703.985336082s] Trained 128 records in 0.073072796 seconds. Throughput is 1751.6779 records/second. Loss is 0.13933769. Sequential31006cbd's hyper parameters: Current learning rate is 0.003950071101279823. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 19968/60000][Iteration 7660][Wall Clock 704.06504858s] Trained 128 records in 0.079712498 seconds. Throughput is 1605.7709 records/second. Loss is 0.1194929. Sequential31006cbd's hyper parameters: Current learning rate is 0.003949759064697054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 20096/60000][Iteration 7661][Wall Clock 704.14115535s] Trained 128 records in 0.07610677 seconds. Throughput is 1681.8477 records/second. Loss is 0.1561523. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039494470774091624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 20224/60000][Iteration 7662][Wall Clock 704.214142666s] Trained 128 records in 0.072987316 seconds. Throughput is 1753.7294 records/second. Loss is 0.15042359. Sequential31006cbd's hyper parameters: Current learning rate is 0.003949135139404471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 20352/60000][Iteration 7663][Wall Clock 704.296700862s] Trained 128 records in 0.082558196 seconds. Throughput is 1550.4215 records/second. Loss is 0.120440535. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039488232506713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 20480/60000][Iteration 7664][Wall Clock 704.394560145s] Trained 128 records in 0.097859283 seconds. Throughput is 1308.0006 records/second. Loss is 0.119223975. Sequential31006cbd's hyper parameters: Current learning rate is 0.003948511411197978. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:21 INFO  DistriOptimizer$:408 - [Epoch 17 20608/60000][Iteration 7665][Wall Clock 704.489464932s] Trained 128 records in 0.094904787 seconds. Throughput is 1348.7201 records/second. Loss is 0.12273167. Sequential31006cbd's hyper parameters: Current learning rate is 0.003948199620972837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 20736/60000][Iteration 7666][Wall Clock 704.570292271s] Trained 128 records in 0.080827339 seconds. Throughput is 1583.6226 records/second. Loss is 0.19493726. Sequential31006cbd's hyper parameters: Current learning rate is 0.003947887879984208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 20864/60000][Iteration 7667][Wall Clock 704.655425121s] Trained 128 records in 0.08513285 seconds. Throughput is 1503.5323 records/second. Loss is 0.09499507. Sequential31006cbd's hyper parameters: Current learning rate is 0.003947576188220433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 20992/60000][Iteration 7668][Wall Clock 704.73355224s] Trained 128 records in 0.078127119 seconds. Throughput is 1638.3556 records/second. Loss is 0.19739078. Sequential31006cbd's hyper parameters: Current learning rate is 0.00394726454566985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21120/60000][Iteration 7669][Wall Clock 704.813232042s] Trained 128 records in 0.079679802 seconds. Throughput is 1606.4297 records/second. Loss is 0.16123459. Sequential31006cbd's hyper parameters: Current learning rate is 0.003946952952320808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21248/60000][Iteration 7670][Wall Clock 704.902733821s] Trained 128 records in 0.089501779 seconds. Throughput is 1430.1393 records/second. Loss is 0.22739187. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039466414081616545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21376/60000][Iteration 7671][Wall Clock 704.990130231s] Trained 128 records in 0.08739641 seconds. Throughput is 1464.591 records/second. Loss is 0.16157347. Sequential31006cbd's hyper parameters: Current learning rate is 0.003946329913180742. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21504/60000][Iteration 7672][Wall Clock 705.084432727s] Trained 128 records in 0.094302496 seconds. Throughput is 1357.3341 records/second. Loss is 0.18972023. Sequential31006cbd's hyper parameters: Current learning rate is 0.003946018467366427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21632/60000][Iteration 7673][Wall Clock 705.164614557s] Trained 128 records in 0.08018183 seconds. Throughput is 1596.3717 records/second. Loss is 0.13853599. Sequential31006cbd's hyper parameters: Current learning rate is 0.003945707070707071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21760/60000][Iteration 7674][Wall Clock 705.240811677s] Trained 128 records in 0.07619712 seconds. Throughput is 1679.8535 records/second. Loss is 0.16574728. Sequential31006cbd's hyper parameters: Current learning rate is 0.003945395723191036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 21888/60000][Iteration 7675][Wall Clock 705.315642713s] Trained 128 records in 0.074831036 seconds. Throughput is 1710.5201 records/second. Loss is 0.19180171. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039450844248066904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 22016/60000][Iteration 7676][Wall Clock 705.401179189s] Trained 128 records in 0.085536476 seconds. Throughput is 1496.4376 records/second. Loss is 0.21922153. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039447731755424065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:22 INFO  DistriOptimizer$:408 - [Epoch 17 22144/60000][Iteration 7677][Wall Clock 705.494116858s] Trained 128 records in 0.092937669 seconds. Throughput is 1377.2671 records/second. Loss is 0.11266029. Sequential31006cbd's hyper parameters: Current learning rate is 0.003944461975386557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 22272/60000][Iteration 7678][Wall Clock 705.579036515s] Trained 128 records in 0.084919657 seconds. Throughput is 1507.3071 records/second. Loss is 0.22485487. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039441508243275225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 22400/60000][Iteration 7679][Wall Clock 705.671404041s] Trained 128 records in 0.092367526 seconds. Throughput is 1385.7684 records/second. Loss is 0.1634825. Sequential31006cbd's hyper parameters: Current learning rate is 0.003943839722353683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 22528/60000][Iteration 7680][Wall Clock 705.749458664s] Trained 128 records in 0.078054623 seconds. Throughput is 1639.8773 records/second. Loss is 0.18887341. Sequential31006cbd's hyper parameters: Current learning rate is 0.003943528669453427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 22656/60000][Iteration 7681][Wall Clock 705.829366625s] Trained 128 records in 0.079907961 seconds. Throughput is 1601.8429 records/second. Loss is 0.12680468. Sequential31006cbd's hyper parameters: Current learning rate is 0.003943217665615142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 22784/60000][Iteration 7682][Wall Clock 705.92230236s] Trained 128 records in 0.092935735 seconds. Throughput is 1377.2959 records/second. Loss is 0.20573393. Sequential31006cbd's hyper parameters: Current learning rate is 0.003942906710827222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 22912/60000][Iteration 7683][Wall Clock 705.999317332s] Trained 128 records in 0.077014972 seconds. Throughput is 1662.0144 records/second. Loss is 0.13941126. Sequential31006cbd's hyper parameters: Current learning rate is 0.003942595805078063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23040/60000][Iteration 7684][Wall Clock 706.076255436s] Trained 128 records in 0.076938104 seconds. Throughput is 1663.6749 records/second. Loss is 0.117658384. Sequential31006cbd's hyper parameters: Current learning rate is 0.003942284948356067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23168/60000][Iteration 7685][Wall Clock 706.148252572s] Trained 128 records in 0.071997136 seconds. Throughput is 1777.8485 records/second. Loss is 0.10430432. Sequential31006cbd's hyper parameters: Current learning rate is 0.003941974140649637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23296/60000][Iteration 7686][Wall Clock 706.224080921s] Trained 128 records in 0.075828349 seconds. Throughput is 1688.023 records/second. Loss is 0.14743654. Sequential31006cbd's hyper parameters: Current learning rate is 0.003941663381947182. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23424/60000][Iteration 7687][Wall Clock 706.296070191s] Trained 128 records in 0.07198927 seconds. Throughput is 1778.0428 records/second. Loss is 0.17927368. Sequential31006cbd's hyper parameters: Current learning rate is 0.003941352672237111. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23552/60000][Iteration 7688][Wall Clock 706.378283987s] Trained 128 records in 0.082213796 seconds. Throughput is 1556.9163 records/second. Loss is 0.12029354. Sequential31006cbd's hyper parameters: Current learning rate is 0.003941042011507843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23680/60000][Iteration 7689][Wall Clock 706.466842395s] Trained 128 records in 0.088558408 seconds. Throughput is 1445.3738 records/second. Loss is 0.17798524. Sequential31006cbd's hyper parameters: Current learning rate is 0.003940731399747792. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:23 INFO  DistriOptimizer$:408 - [Epoch 17 23808/60000][Iteration 7690][Wall Clock 706.543741731s] Trained 128 records in 0.076899336 seconds. Throughput is 1664.5138 records/second. Loss is 0.1561073. Sequential31006cbd's hyper parameters: Current learning rate is 0.003940420836945386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 23936/60000][Iteration 7691][Wall Clock 706.620952723s] Trained 128 records in 0.077210992 seconds. Throughput is 1657.795 records/second. Loss is 0.15664724. Sequential31006cbd's hyper parameters: Current learning rate is 0.003940110323089046. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24064/60000][Iteration 7692][Wall Clock 706.696045014s] Trained 128 records in 0.075092291 seconds. Throughput is 1704.5691 records/second. Loss is 0.16825502. Sequential31006cbd's hyper parameters: Current learning rate is 0.003939799858167206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24192/60000][Iteration 7693][Wall Clock 706.771184852s] Trained 128 records in 0.075139838 seconds. Throughput is 1703.4906 records/second. Loss is 0.13248235. Sequential31006cbd's hyper parameters: Current learning rate is 0.003939489442168295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24320/60000][Iteration 7694][Wall Clock 706.846536472s] Trained 128 records in 0.07535162 seconds. Throughput is 1698.7028 records/second. Loss is 0.16500674. Sequential31006cbd's hyper parameters: Current learning rate is 0.003939179075080753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24448/60000][Iteration 7695][Wall Clock 706.926143774s] Trained 128 records in 0.079607302 seconds. Throughput is 1607.8927 records/second. Loss is 0.13271506. Sequential31006cbd's hyper parameters: Current learning rate is 0.00393886875689302. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24576/60000][Iteration 7696][Wall Clock 707.006539302s] Trained 128 records in 0.080395528 seconds. Throughput is 1592.1284 records/second. Loss is 0.17669545. Sequential31006cbd's hyper parameters: Current learning rate is 0.003938558487593541. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24704/60000][Iteration 7697][Wall Clock 707.091343551s] Trained 128 records in 0.084804249 seconds. Throughput is 1509.3583 records/second. Loss is 0.1040577. Sequential31006cbd's hyper parameters: Current learning rate is 0.003938248267170762. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24832/60000][Iteration 7698][Wall Clock 707.170732808s] Trained 128 records in 0.079389257 seconds. Throughput is 1612.3088 records/second. Loss is 0.14368138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039379380956131365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 24960/60000][Iteration 7699][Wall Clock 707.243000586s] Trained 128 records in 0.072267778 seconds. Throughput is 1771.1904 records/second. Loss is 0.16072214. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039376279729091196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 25088/60000][Iteration 7700][Wall Clock 707.332100185s] Trained 128 records in 0.089099599 seconds. Throughput is 1436.5945 records/second. Loss is 0.14261878. Sequential31006cbd's hyper parameters: Current learning rate is 0.003937317899047169. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 25216/60000][Iteration 7701][Wall Clock 707.421642445s] Trained 128 records in 0.08954226 seconds. Throughput is 1429.4926 records/second. Loss is 0.25212812. Sequential31006cbd's hyper parameters: Current learning rate is 0.003937007874015748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:24 INFO  DistriOptimizer$:408 - [Epoch 17 25344/60000][Iteration 7702][Wall Clock 707.50401733s] Trained 128 records in 0.082374885 seconds. Throughput is 1553.8717 records/second. Loss is 0.22325608. Sequential31006cbd's hyper parameters: Current learning rate is 0.003936697897803322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 25472/60000][Iteration 7703][Wall Clock 707.591186571s] Trained 128 records in 0.087169241 seconds. Throughput is 1468.408 records/second. Loss is 0.09936618. Sequential31006cbd's hyper parameters: Current learning rate is 0.003936387970398363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 25600/60000][Iteration 7704][Wall Clock 707.669165078s] Trained 128 records in 0.077978507 seconds. Throughput is 1641.4779 records/second. Loss is 0.1269219. Sequential31006cbd's hyper parameters: Current learning rate is 0.003936078091789341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 25728/60000][Iteration 7705][Wall Clock 707.745661793s] Trained 128 records in 0.076496715 seconds. Throughput is 1673.2745 records/second. Loss is 0.19433114. Sequential31006cbd's hyper parameters: Current learning rate is 0.003935768261964736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 25856/60000][Iteration 7706][Wall Clock 707.829861873s] Trained 128 records in 0.08420008 seconds. Throughput is 1520.1886 records/second. Loss is 0.1914797. Sequential31006cbd's hyper parameters: Current learning rate is 0.003935458480913026. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 25984/60000][Iteration 7707][Wall Clock 707.907722845s] Trained 128 records in 0.077860972 seconds. Throughput is 1643.9558 records/second. Loss is 0.09701523. Sequential31006cbd's hyper parameters: Current learning rate is 0.003935148748622698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26112/60000][Iteration 7708][Wall Clock 708.003572677s] Trained 128 records in 0.095849832 seconds. Throughput is 1335.4222 records/second. Loss is 0.13969052. Sequential31006cbd's hyper parameters: Current learning rate is 0.003934839065082238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26240/60000][Iteration 7709][Wall Clock 708.0811434s] Trained 128 records in 0.077570723 seconds. Throughput is 1650.1072 records/second. Loss is 0.14570463. Sequential31006cbd's hyper parameters: Current learning rate is 0.003934529430280139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26368/60000][Iteration 7710][Wall Clock 708.168484696s] Trained 128 records in 0.087341296 seconds. Throughput is 1465.5153 records/second. Loss is 0.13166496. Sequential31006cbd's hyper parameters: Current learning rate is 0.003934219844204894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26496/60000][Iteration 7711][Wall Clock 708.248043604s] Trained 128 records in 0.079558908 seconds. Throughput is 1608.8707 records/second. Loss is 0.11203815. Sequential31006cbd's hyper parameters: Current learning rate is 0.003933910306845004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26624/60000][Iteration 7712][Wall Clock 708.325885935s] Trained 128 records in 0.077842331 seconds. Throughput is 1644.3495 records/second. Loss is 0.23642325. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039336008181889695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26752/60000][Iteration 7713][Wall Clock 708.404930102s] Trained 128 records in 0.079044167 seconds. Throughput is 1619.3478 records/second. Loss is 0.12913889. Sequential31006cbd's hyper parameters: Current learning rate is 0.003933291378225299. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:25 INFO  DistriOptimizer$:408 - [Epoch 17 26880/60000][Iteration 7714][Wall Clock 708.48329649s] Trained 128 records in 0.078366388 seconds. Throughput is 1633.3533 records/second. Loss is 0.141337. Sequential31006cbd's hyper parameters: Current learning rate is 0.003932981986942499. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27008/60000][Iteration 7715][Wall Clock 708.566314617s] Trained 128 records in 0.083018127 seconds. Throughput is 1541.832 records/second. Loss is 0.17137879. Sequential31006cbd's hyper parameters: Current learning rate is 0.003932672644329086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27136/60000][Iteration 7716][Wall Clock 708.647936362s] Trained 128 records in 0.081621745 seconds. Throughput is 1568.2096 records/second. Loss is 0.1664303. Sequential31006cbd's hyper parameters: Current learning rate is 0.003932363350373574. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27264/60000][Iteration 7717][Wall Clock 708.729831106s] Trained 128 records in 0.081894744 seconds. Throughput is 1562.9819 records/second. Loss is 0.12489012. Sequential31006cbd's hyper parameters: Current learning rate is 0.003932054105064486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27392/60000][Iteration 7718][Wall Clock 708.801998345s] Trained 128 records in 0.072167239 seconds. Throughput is 1773.658 records/second. Loss is 0.07874535. Sequential31006cbd's hyper parameters: Current learning rate is 0.003931744908390344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27520/60000][Iteration 7719][Wall Clock 708.879418999s] Trained 128 records in 0.077420654 seconds. Throughput is 1653.3057 records/second. Loss is 0.14934896. Sequential31006cbd's hyper parameters: Current learning rate is 0.003931435760339676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27648/60000][Iteration 7720][Wall Clock 708.958061539s] Trained 128 records in 0.07864254 seconds. Throughput is 1627.6178 records/second. Loss is 0.106345125. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039311266609010145. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27776/60000][Iteration 7721][Wall Clock 709.070042013s] Trained 128 records in 0.111980474 seconds. Throughput is 1143.0564 records/second. Loss is 0.14076933. Sequential31006cbd's hyper parameters: Current learning rate is 0.003930817610062893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 27904/60000][Iteration 7722][Wall Clock 709.161762623s] Trained 128 records in 0.09172061 seconds. Throughput is 1395.5424 records/second. Loss is 0.16194455. Sequential31006cbd's hyper parameters: Current learning rate is 0.003930508607813851. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 28032/60000][Iteration 7723][Wall Clock 709.252559238s] Trained 128 records in 0.090796615 seconds. Throughput is 1409.7443 records/second. Loss is 0.19145322. Sequential31006cbd's hyper parameters: Current learning rate is 0.003930199654142431. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 28160/60000][Iteration 7724][Wall Clock 709.343750089s] Trained 128 records in 0.091190851 seconds. Throughput is 1403.6495 records/second. Loss is 0.13705793. Sequential31006cbd's hyper parameters: Current learning rate is 0.003929890749037177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 28288/60000][Iteration 7725][Wall Clock 709.42766424s] Trained 128 records in 0.083914151 seconds. Throughput is 1525.3684 records/second. Loss is 0.10051661. Sequential31006cbd's hyper parameters: Current learning rate is 0.003929581892486639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:26 INFO  DistriOptimizer$:408 - [Epoch 17 28416/60000][Iteration 7726][Wall Clock 709.506802099s] Trained 128 records in 0.079137859 seconds. Throughput is 1617.4307 records/second. Loss is 0.1804534. Sequential31006cbd's hyper parameters: Current learning rate is 0.003929273084479372. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 28544/60000][Iteration 7727][Wall Clock 709.587287177s] Trained 128 records in 0.080485078 seconds. Throughput is 1590.3569 records/second. Loss is 0.18963386. Sequential31006cbd's hyper parameters: Current learning rate is 0.003928964325003928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 28672/60000][Iteration 7728][Wall Clock 709.674224157s] Trained 128 records in 0.08693698 seconds. Throughput is 1472.3308 records/second. Loss is 0.14630577. Sequential31006cbd's hyper parameters: Current learning rate is 0.003928655614048873. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 28800/60000][Iteration 7729][Wall Clock 709.759163275s] Trained 128 records in 0.084939118 seconds. Throughput is 1506.9618 records/second. Loss is 0.2080626. Sequential31006cbd's hyper parameters: Current learning rate is 0.003928346951602765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 28928/60000][Iteration 7730][Wall Clock 709.831651229s] Trained 128 records in 0.072487954 seconds. Throughput is 1765.8107 records/second. Loss is 0.2075343. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039280383376541755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29056/60000][Iteration 7731][Wall Clock 709.912837193s] Trained 128 records in 0.081185964 seconds. Throughput is 1576.6272 records/second. Loss is 0.2111156. Sequential31006cbd's hyper parameters: Current learning rate is 0.003927729772191673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29184/60000][Iteration 7732][Wall Clock 709.993350466s] Trained 128 records in 0.080513273 seconds. Throughput is 1589.7999 records/second. Loss is 0.11763772. Sequential31006cbd's hyper parameters: Current learning rate is 0.003927421255203833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29312/60000][Iteration 7733][Wall Clock 710.075130915s] Trained 128 records in 0.081780449 seconds. Throughput is 1565.1663 records/second. Loss is 0.07954699. Sequential31006cbd's hyper parameters: Current learning rate is 0.003927112786679233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29440/60000][Iteration 7734][Wall Clock 710.158316966s] Trained 128 records in 0.083186051 seconds. Throughput is 1538.7195 records/second. Loss is 0.1460204. Sequential31006cbd's hyper parameters: Current learning rate is 0.003926804366606456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29568/60000][Iteration 7735][Wall Clock 710.25264884s] Trained 128 records in 0.094331874 seconds. Throughput is 1356.9114 records/second. Loss is 0.11038625. Sequential31006cbd's hyper parameters: Current learning rate is 0.003926495994974085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29696/60000][Iteration 7736][Wall Clock 710.340327192s] Trained 128 records in 0.087678352 seconds. Throughput is 1459.8815 records/second. Loss is 0.19629778. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039261876717707105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29824/60000][Iteration 7737][Wall Clock 710.42014248s] Trained 128 records in 0.079815288 seconds. Throughput is 1603.7028 records/second. Loss is 0.15228373. Sequential31006cbd's hyper parameters: Current learning rate is 0.003925879396984924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:27 INFO  DistriOptimizer$:408 - [Epoch 17 29952/60000][Iteration 7738][Wall Clock 710.50087049s] Trained 128 records in 0.08072801 seconds. Throughput is 1585.5712 records/second. Loss is 0.1392287. Sequential31006cbd's hyper parameters: Current learning rate is 0.003925571170605323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30080/60000][Iteration 7739][Wall Clock 710.578031785s] Trained 128 records in 0.077161295 seconds. Throughput is 1658.8627 records/second. Loss is 0.24469948. Sequential31006cbd's hyper parameters: Current learning rate is 0.003925262992620505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30208/60000][Iteration 7740][Wall Clock 710.66238201s] Trained 128 records in 0.084350225 seconds. Throughput is 1517.4825 records/second. Loss is 0.12797523. Sequential31006cbd's hyper parameters: Current learning rate is 0.003924954863019075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30336/60000][Iteration 7741][Wall Clock 710.743915886s] Trained 128 records in 0.081533876 seconds. Throughput is 1569.8995 records/second. Loss is 0.2372339. Sequential31006cbd's hyper parameters: Current learning rate is 0.003924646781789639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30464/60000][Iteration 7742][Wall Clock 710.819721845s] Trained 128 records in 0.075805959 seconds. Throughput is 1688.5215 records/second. Loss is 0.14487007. Sequential31006cbd's hyper parameters: Current learning rate is 0.003924338748920807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30592/60000][Iteration 7743][Wall Clock 710.896653091s] Trained 128 records in 0.076931246 seconds. Throughput is 1663.8234 records/second. Loss is 0.16823725. Sequential31006cbd's hyper parameters: Current learning rate is 0.003924030764401193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30720/60000][Iteration 7744][Wall Clock 710.989399693s] Trained 128 records in 0.092746602 seconds. Throughput is 1380.1045 records/second. Loss is 0.23167056. Sequential31006cbd's hyper parameters: Current learning rate is 0.003923722828219415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30848/60000][Iteration 7745][Wall Clock 711.086946986s] Trained 128 records in 0.097547293 seconds. Throughput is 1312.1841 records/second. Loss is 0.12565687. Sequential31006cbd's hyper parameters: Current learning rate is 0.003923414940364093. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 30976/60000][Iteration 7746][Wall Clock 711.181919348s] Trained 128 records in 0.094972362 seconds. Throughput is 1347.7605 records/second. Loss is 0.12809145. Sequential31006cbd's hyper parameters: Current learning rate is 0.003923107100823852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 31104/60000][Iteration 7747][Wall Clock 711.280809676s] Trained 128 records in 0.098890328 seconds. Throughput is 1294.3632 records/second. Loss is 0.1296528. Sequential31006cbd's hyper parameters: Current learning rate is 0.003922799309587321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 31232/60000][Iteration 7748][Wall Clock 711.35399592s] Trained 128 records in 0.073186244 seconds. Throughput is 1748.9626 records/second. Loss is 0.12990996. Sequential31006cbd's hyper parameters: Current learning rate is 0.003922491566643131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 31360/60000][Iteration 7749][Wall Clock 711.424089741s] Trained 128 records in 0.070093821 seconds. Throughput is 1826.1239 records/second. Loss is 0.14389467. Sequential31006cbd's hyper parameters: Current learning rate is 0.003922183871979919. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:28 INFO  DistriOptimizer$:408 - [Epoch 17 31488/60000][Iteration 7750][Wall Clock 711.498405082s] Trained 128 records in 0.074315341 seconds. Throughput is 1722.39 records/second. Loss is 0.21268633. Sequential31006cbd's hyper parameters: Current learning rate is 0.00392187622558632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 31616/60000][Iteration 7751][Wall Clock 711.572590369s] Trained 128 records in 0.074185287 seconds. Throughput is 1725.4094 records/second. Loss is 0.1591993. Sequential31006cbd's hyper parameters: Current learning rate is 0.00392156862745098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 31744/60000][Iteration 7752][Wall Clock 711.650199891s] Trained 128 records in 0.077609522 seconds. Throughput is 1649.2821 records/second. Loss is 0.19267836. Sequential31006cbd's hyper parameters: Current learning rate is 0.003921261077562544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 31872/60000][Iteration 7753][Wall Clock 711.726956341s] Trained 128 records in 0.07675645 seconds. Throughput is 1667.6123 records/second. Loss is 0.19179673. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039209535759096616. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32000/60000][Iteration 7754][Wall Clock 711.802116425s] Trained 128 records in 0.075160084 seconds. Throughput is 1703.0316 records/second. Loss is 0.082799435. Sequential31006cbd's hyper parameters: Current learning rate is 0.003920646122480984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32128/60000][Iteration 7755][Wall Clock 711.878235095s] Trained 128 records in 0.07611867 seconds. Throughput is 1681.5848 records/second. Loss is 0.18609098. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039203387172651715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32256/60000][Iteration 7756][Wall Clock 711.952651296s] Trained 128 records in 0.074416201 seconds. Throughput is 1720.0557 records/second. Loss is 0.20456089. Sequential31006cbd's hyper parameters: Current learning rate is 0.003920031360250882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32384/60000][Iteration 7757][Wall Clock 712.036156072s] Trained 128 records in 0.083504776 seconds. Throughput is 1532.8466 records/second. Loss is 0.12869154. Sequential31006cbd's hyper parameters: Current learning rate is 0.00391972405142678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32512/60000][Iteration 7758][Wall Clock 712.111561754s] Trained 128 records in 0.075405682 seconds. Throughput is 1697.4849 records/second. Loss is 0.13584606. Sequential31006cbd's hyper parameters: Current learning rate is 0.003919416790781532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32640/60000][Iteration 7759][Wall Clock 712.198023443s] Trained 128 records in 0.086461689 seconds. Throughput is 1480.4246 records/second. Loss is 0.22930238. Sequential31006cbd's hyper parameters: Current learning rate is 0.003919109578303809. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32768/60000][Iteration 7760][Wall Clock 712.280435549s] Trained 128 records in 0.082412106 seconds. Throughput is 1553.1698 records/second. Loss is 0.13441172. Sequential31006cbd's hyper parameters: Current learning rate is 0.003918802413982287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 32896/60000][Iteration 7761][Wall Clock 712.369119423s] Trained 128 records in 0.088683874 seconds. Throughput is 1443.329 records/second. Loss is 0.18018222. Sequential31006cbd's hyper parameters: Current learning rate is 0.003918495297805642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 33024/60000][Iteration 7762][Wall Clock 712.442723346s] Trained 128 records in 0.073603923 seconds. Throughput is 1739.0378 records/second. Loss is 0.26400524. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039181882297625575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:29 INFO  DistriOptimizer$:408 - [Epoch 17 33152/60000][Iteration 7763][Wall Clock 712.518554994s] Trained 128 records in 0.075831648 seconds. Throughput is 1687.9495 records/second. Loss is 0.1530888. Sequential31006cbd's hyper parameters: Current learning rate is 0.003917881209841718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 33280/60000][Iteration 7764][Wall Clock 712.596778896s] Trained 128 records in 0.078223902 seconds. Throughput is 1636.3286 records/second. Loss is 0.16041669. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039175742380318105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 33408/60000][Iteration 7765][Wall Clock 712.672041779s] Trained 128 records in 0.075262883 seconds. Throughput is 1700.7056 records/second. Loss is 0.21219063. Sequential31006cbd's hyper parameters: Current learning rate is 0.003917267314321529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 33536/60000][Iteration 7766][Wall Clock 712.757087197s] Trained 128 records in 0.085045418 seconds. Throughput is 1505.0781 records/second. Loss is 0.15461928. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039169604386995694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 33664/60000][Iteration 7767][Wall Clock 712.85948105s] Trained 128 records in 0.102393853 seconds. Throughput is 1250.0751 records/second. Loss is 0.1851515. Sequential31006cbd's hyper parameters: Current learning rate is 0.003916653611154629. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 33792/60000][Iteration 7768][Wall Clock 712.939067221s] Trained 128 records in 0.079586171 seconds. Throughput is 1608.3196 records/second. Loss is 0.14605574. Sequential31006cbd's hyper parameters: Current learning rate is 0.003916346831675414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 33920/60000][Iteration 7769][Wall Clock 713.016671173s] Trained 128 records in 0.077603952 seconds. Throughput is 1649.4005 records/second. Loss is 0.27824724. Sequential31006cbd's hyper parameters: Current learning rate is 0.003916040100250626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 34048/60000][Iteration 7770][Wall Clock 713.095927951s] Trained 128 records in 0.079256778 seconds. Throughput is 1615.0038 records/second. Loss is 0.26384988. Sequential31006cbd's hyper parameters: Current learning rate is 0.00391573341686898. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 34176/60000][Iteration 7771][Wall Clock 713.171494848s] Trained 128 records in 0.075566897 seconds. Throughput is 1693.8634 records/second. Loss is 0.10856728. Sequential31006cbd's hyper parameters: Current learning rate is 0.003915426781519185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 34304/60000][Iteration 7772][Wall Clock 713.261389418s] Trained 128 records in 0.08989457 seconds. Throughput is 1423.8903 records/second. Loss is 0.16041487. Sequential31006cbd's hyper parameters: Current learning rate is 0.003915120194189962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 34432/60000][Iteration 7773][Wall Clock 713.341412441s] Trained 128 records in 0.080023023 seconds. Throughput is 1599.5397 records/second. Loss is 0.15200341. Sequential31006cbd's hyper parameters: Current learning rate is 0.003914813654870028. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 34560/60000][Iteration 7774][Wall Clock 713.419582455s] Trained 128 records in 0.078170014 seconds. Throughput is 1637.4564 records/second. Loss is 0.15083046. Sequential31006cbd's hyper parameters: Current learning rate is 0.003914507163548109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:30 INFO  DistriOptimizer$:408 - [Epoch 17 34688/60000][Iteration 7775][Wall Clock 713.497601842s] Trained 128 records in 0.078019387 seconds. Throughput is 1640.6178 records/second. Loss is 0.12876722. Sequential31006cbd's hyper parameters: Current learning rate is 0.003914200720212932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 34816/60000][Iteration 7776][Wall Clock 713.570907683s] Trained 128 records in 0.073305841 seconds. Throughput is 1746.1093 records/second. Loss is 0.16730131. Sequential31006cbd's hyper parameters: Current learning rate is 0.003913894324853229. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 34944/60000][Iteration 7777][Wall Clock 713.650404318s] Trained 128 records in 0.079496635 seconds. Throughput is 1610.131 records/second. Loss is 0.107976794. Sequential31006cbd's hyper parameters: Current learning rate is 0.003913587977457733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35072/60000][Iteration 7778][Wall Clock 713.728142259s] Trained 128 records in 0.077737941 seconds. Throughput is 1646.5576 records/second. Loss is 0.16557732. Sequential31006cbd's hyper parameters: Current learning rate is 0.003913281678015183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35200/60000][Iteration 7779][Wall Clock 713.82286831s] Trained 128 records in 0.094726051 seconds. Throughput is 1351.265 records/second. Loss is 0.186614. Sequential31006cbd's hyper parameters: Current learning rate is 0.003912975426514321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35328/60000][Iteration 7780][Wall Clock 713.90374803s] Trained 128 records in 0.08087972 seconds. Throughput is 1582.597 records/second. Loss is 0.15833844. Sequential31006cbd's hyper parameters: Current learning rate is 0.003912669222943892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35456/60000][Iteration 7781][Wall Clock 713.987689176s] Trained 128 records in 0.083941146 seconds. Throughput is 1524.8779 records/second. Loss is 0.11777344. Sequential31006cbd's hyper parameters: Current learning rate is 0.003912363067292645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35584/60000][Iteration 7782][Wall Clock 714.070738322s] Trained 128 records in 0.083049146 seconds. Throughput is 1541.256 records/second. Loss is 0.087209076. Sequential31006cbd's hyper parameters: Current learning rate is 0.003912056959549331. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35712/60000][Iteration 7783][Wall Clock 714.154538952s] Trained 128 records in 0.08380063 seconds. Throughput is 1527.4348 records/second. Loss is 0.2755317. Sequential31006cbd's hyper parameters: Current learning rate is 0.003911750899702707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35840/60000][Iteration 7784][Wall Clock 714.233291667s] Trained 128 records in 0.078752715 seconds. Throughput is 1625.3408 records/second. Loss is 0.20107248. Sequential31006cbd's hyper parameters: Current learning rate is 0.003911444887741532. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 35968/60000][Iteration 7785][Wall Clock 714.327101232s] Trained 128 records in 0.093809565 seconds. Throughput is 1364.4664 records/second. Loss is 0.13130689. Sequential31006cbd's hyper parameters: Current learning rate is 0.003911138923654568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 36096/60000][Iteration 7786][Wall Clock 714.404865706s] Trained 128 records in 0.077764474 seconds. Throughput is 1645.9958 records/second. Loss is 0.15401186. Sequential31006cbd's hyper parameters: Current learning rate is 0.003910833007430582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:31 INFO  DistriOptimizer$:408 - [Epoch 17 36224/60000][Iteration 7787][Wall Clock 714.478919998s] Trained 128 records in 0.074054292 seconds. Throughput is 1728.4615 records/second. Loss is 0.12902936. Sequential31006cbd's hyper parameters: Current learning rate is 0.003910527139058345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 36352/60000][Iteration 7788][Wall Clock 714.54791367s] Trained 128 records in 0.068993672 seconds. Throughput is 1855.2426 records/second. Loss is 0.23990376. Sequential31006cbd's hyper parameters: Current learning rate is 0.003910221318526628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 36480/60000][Iteration 7789][Wall Clock 714.626157203s] Trained 128 records in 0.078243533 seconds. Throughput is 1635.918 records/second. Loss is 0.116061784. Sequential31006cbd's hyper parameters: Current learning rate is 0.00390991554582421. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 36608/60000][Iteration 7790][Wall Clock 714.709670082s] Trained 128 records in 0.083512879 seconds. Throughput is 1532.6978 records/second. Loss is 0.14622249. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039096098209398696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 36736/60000][Iteration 7791][Wall Clock 714.787929936s] Trained 128 records in 0.078259854 seconds. Throughput is 1635.5768 records/second. Loss is 0.15554997. Sequential31006cbd's hyper parameters: Current learning rate is 0.003909304143862393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 36864/60000][Iteration 7792][Wall Clock 714.86538535s] Trained 128 records in 0.077455414 seconds. Throughput is 1652.5636 records/second. Loss is 0.10934122. Sequential31006cbd's hyper parameters: Current learning rate is 0.003908998514580564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 36992/60000][Iteration 7793][Wall Clock 714.941322248s] Trained 128 records in 0.075936898 seconds. Throughput is 1685.6101 records/second. Loss is 0.14276972. Sequential31006cbd's hyper parameters: Current learning rate is 0.003908692933083178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37120/60000][Iteration 7794][Wall Clock 715.013378214s] Trained 128 records in 0.072055966 seconds. Throughput is 1776.397 records/second. Loss is 0.1351806. Sequential31006cbd's hyper parameters: Current learning rate is 0.003908387399359024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37248/60000][Iteration 7795][Wall Clock 715.090585267s] Trained 128 records in 0.077207053 seconds. Throughput is 1657.8796 records/second. Loss is 0.21902262. Sequential31006cbd's hyper parameters: Current learning rate is 0.003908081913396905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37376/60000][Iteration 7796][Wall Clock 715.178261506s] Trained 128 records in 0.087676239 seconds. Throughput is 1459.9166 records/second. Loss is 0.16513011. Sequential31006cbd's hyper parameters: Current learning rate is 0.003907776475185619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37504/60000][Iteration 7797][Wall Clock 715.250153025s] Trained 128 records in 0.071891519 seconds. Throughput is 1780.4604 records/second. Loss is 0.1510902. Sequential31006cbd's hyper parameters: Current learning rate is 0.003907471084713973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37632/60000][Iteration 7798][Wall Clock 715.336467999s] Trained 128 records in 0.086314974 seconds. Throughput is 1482.9408 records/second. Loss is 0.11775404. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039071657419707745. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37760/60000][Iteration 7799][Wall Clock 715.422413263s] Trained 128 records in 0.085945264 seconds. Throughput is 1489.32 records/second. Loss is 0.14191145. Sequential31006cbd's hyper parameters: Current learning rate is 0.003906860446944835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:32 INFO  DistriOptimizer$:408 - [Epoch 17 37888/60000][Iteration 7800][Wall Clock 715.496905167s] Trained 128 records in 0.074491904 seconds. Throughput is 1718.3075 records/second. Loss is 0.18119621. Sequential31006cbd's hyper parameters: Current learning rate is 0.003906555199624971. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38016/60000][Iteration 7801][Wall Clock 715.576531583s] Trained 128 records in 0.079626416 seconds. Throughput is 1607.5067 records/second. Loss is 0.14991525. Sequential31006cbd's hyper parameters: Current learning rate is 0.00390625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38144/60000][Iteration 7802][Wall Clock 715.660121845s] Trained 128 records in 0.083590262 seconds. Throughput is 1531.2788 records/second. Loss is 0.15215904. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039059448480587454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38272/60000][Iteration 7803][Wall Clock 715.749578801s] Trained 128 records in 0.089456956 seconds. Throughput is 1430.8558 records/second. Loss is 0.31046784. Sequential31006cbd's hyper parameters: Current learning rate is 0.003905639743790033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38400/60000][Iteration 7804][Wall Clock 715.828613628s] Trained 128 records in 0.079034827 seconds. Throughput is 1619.5392 records/second. Loss is 0.1597009. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039053346871826917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38528/60000][Iteration 7805][Wall Clock 715.919144613s] Trained 128 records in 0.090530985 seconds. Throughput is 1413.8806 records/second. Loss is 0.19283772. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039050296782255547. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38656/60000][Iteration 7806][Wall Clock 715.994100015s] Trained 128 records in 0.074955402 seconds. Throughput is 1707.6821 records/second. Loss is 0.15072009. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039047247169074584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38784/60000][Iteration 7807][Wall Clock 716.07009085s] Trained 128 records in 0.075990835 seconds. Throughput is 1684.4137 records/second. Loss is 0.1133869. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039044198032172415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 38912/60000][Iteration 7808][Wall Clock 716.1477378s] Trained 128 records in 0.07764695 seconds. Throughput is 1648.4872 records/second. Loss is 0.19253327. Sequential31006cbd's hyper parameters: Current learning rate is 0.00390411493714375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 39040/60000][Iteration 7809][Wall Clock 716.236764454s] Trained 128 records in 0.089026654 seconds. Throughput is 1437.7717 records/second. Loss is 0.17604214. Sequential31006cbd's hyper parameters: Current learning rate is 0.003903810118675827. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 39168/60000][Iteration 7810][Wall Clock 716.318231871s] Trained 128 records in 0.081467417 seconds. Throughput is 1571.1802 records/second. Loss is 0.15261246. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039035053478023267. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 39296/60000][Iteration 7811][Wall Clock 716.401294205s] Trained 128 records in 0.083062334 seconds. Throughput is 1541.0114 records/second. Loss is 0.23673908. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039032006245120995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:33 INFO  DistriOptimizer$:408 - [Epoch 17 39424/60000][Iteration 7812][Wall Clock 716.500839893s] Trained 128 records in 0.099545688 seconds. Throughput is 1285.8418 records/second. Loss is 0.13303229. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039028959487940056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 39552/60000][Iteration 7813][Wall Clock 716.577554784s] Trained 128 records in 0.076714891 seconds. Throughput is 1668.5157 records/second. Loss is 0.20841613. Sequential31006cbd's hyper parameters: Current learning rate is 0.003902591320636903. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 39680/60000][Iteration 7814][Wall Clock 716.65439237s] Trained 128 records in 0.076837586 seconds. Throughput is 1665.8514 records/second. Loss is 0.11655085. Sequential31006cbd's hyper parameters: Current learning rate is 0.003902286740029658. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 39808/60000][Iteration 7815][Wall Clock 716.734506464s] Trained 128 records in 0.080114094 seconds. Throughput is 1597.7213 records/second. Loss is 0.19710954. Sequential31006cbd's hyper parameters: Current learning rate is 0.003901982206961136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 39936/60000][Iteration 7816][Wall Clock 716.808282319s] Trained 128 records in 0.073775855 seconds. Throughput is 1734.9849 records/second. Loss is 0.16671722. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039016777214202106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40064/60000][Iteration 7817][Wall Clock 716.885009925s] Trained 128 records in 0.076727606 seconds. Throughput is 1668.2391 records/second. Loss is 0.18186443. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039013732833957553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40192/60000][Iteration 7818][Wall Clock 716.959700808s] Trained 128 records in 0.074690883 seconds. Throughput is 1713.7299 records/second. Loss is 0.15200731. Sequential31006cbd's hyper parameters: Current learning rate is 0.003901068892876648. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40320/60000][Iteration 7819][Wall Clock 717.033196254s] Trained 128 records in 0.073495446 seconds. Throughput is 1741.6045 records/second. Loss is 0.13860291. Sequential31006cbd's hyper parameters: Current learning rate is 0.003900764549851771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40448/60000][Iteration 7820][Wall Clock 717.107284704s] Trained 128 records in 0.07408845 seconds. Throughput is 1727.6648 records/second. Loss is 0.14779566. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039004602543100085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40576/60000][Iteration 7821][Wall Clock 717.192988725s] Trained 128 records in 0.085704021 seconds. Throughput is 1493.5122 records/second. Loss is 0.17918077. Sequential31006cbd's hyper parameters: Current learning rate is 0.0039001560062402497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40704/60000][Iteration 7822][Wall Clock 717.293091018s] Trained 128 records in 0.100102293 seconds. Throughput is 1278.692 records/second. Loss is 0.14699191. Sequential31006cbd's hyper parameters: Current learning rate is 0.003899851805631386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40832/60000][Iteration 7823][Wall Clock 717.37543487s] Trained 128 records in 0.082343852 seconds. Throughput is 1554.4573 records/second. Loss is 0.111980125. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038995476524723133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:34 INFO  DistriOptimizer$:408 - [Epoch 17 40960/60000][Iteration 7824][Wall Clock 717.459209734s] Trained 128 records in 0.083774864 seconds. Throughput is 1527.9045 records/second. Loss is 0.099755436. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038992435467519303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41088/60000][Iteration 7825][Wall Clock 717.54396602s] Trained 128 records in 0.084756286 seconds. Throughput is 1510.2125 records/second. Loss is 0.15712331. Sequential31006cbd's hyper parameters: Current learning rate is 0.003898939488459139. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41216/60000][Iteration 7826][Wall Clock 717.619971541s] Trained 128 records in 0.076005521 seconds. Throughput is 1684.0883 records/second. Loss is 0.1492806. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038986354775828454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41344/60000][Iteration 7827][Wall Clock 717.706364307s] Trained 128 records in 0.086392766 seconds. Throughput is 1481.6055 records/second. Loss is 0.1575156. Sequential31006cbd's hyper parameters: Current learning rate is 0.00389833151411196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41472/60000][Iteration 7828][Wall Clock 717.787549248s] Trained 128 records in 0.081184941 seconds. Throughput is 1576.6471 records/second. Loss is 0.1431475. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038980275980353934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41600/60000][Iteration 7829][Wall Clock 717.868556924s] Trained 128 records in 0.081007676 seconds. Throughput is 1580.0972 records/second. Loss is 0.17506373. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038977237293420647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41728/60000][Iteration 7830][Wall Clock 717.948046884s] Trained 128 records in 0.07948996 seconds. Throughput is 1610.2662 records/second. Loss is 0.14306486. Sequential31006cbd's hyper parameters: Current learning rate is 0.00389741990802089. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41856/60000][Iteration 7831][Wall Clock 718.03158324s] Trained 128 records in 0.083536356 seconds. Throughput is 1532.267 records/second. Loss is 0.12964287. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038971161340607954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 41984/60000][Iteration 7832][Wall Clock 718.111280059s] Trained 128 records in 0.079696819 seconds. Throughput is 1606.0867 records/second. Loss is 0.12923902. Sequential31006cbd's hyper parameters: Current learning rate is 0.003896812407450705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 42112/60000][Iteration 7833][Wall Clock 718.18705131s] Trained 128 records in 0.075771251 seconds. Throughput is 1689.295 records/second. Loss is 0.2290462. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038965087281795517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 42240/60000][Iteration 7834][Wall Clock 718.266523177s] Trained 128 records in 0.079471867 seconds. Throughput is 1610.6329 records/second. Loss is 0.18453905. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038962050962362657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 42368/60000][Iteration 7835][Wall Clock 718.341297125s] Trained 128 records in 0.074773948 seconds. Throughput is 1711.8262 records/second. Loss is 0.20776458. Sequential31006cbd's hyper parameters: Current learning rate is 0.003895901511609787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:35 INFO  DistriOptimizer$:408 - [Epoch 17 42496/60000][Iteration 7836][Wall Clock 718.422932531s] Trained 128 records in 0.081635406 seconds. Throughput is 1567.9471 records/second. Loss is 0.12700292. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038955979742890533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 42624/60000][Iteration 7837][Wall Clock 718.510447654s] Trained 128 records in 0.087515123 seconds. Throughput is 1462.6044 records/second. Loss is 0.17517887. Sequential31006cbd's hyper parameters: Current learning rate is 0.00389529448426301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 42752/60000][Iteration 7838][Wall Clock 718.594335463s] Trained 128 records in 0.083887809 seconds. Throughput is 1525.8475 records/second. Loss is 0.09863752. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038949910415206042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 42880/60000][Iteration 7839][Wall Clock 718.665955007s] Trained 128 records in 0.071619544 seconds. Throughput is 1787.2218 records/second. Loss is 0.13453561. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038946876460507866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43008/60000][Iteration 7840][Wall Clock 718.748922465s] Trained 128 records in 0.082967458 seconds. Throughput is 1542.7736 records/second. Loss is 0.20032464. Sequential31006cbd's hyper parameters: Current learning rate is 0.003894384297842511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43136/60000][Iteration 7841][Wall Clock 718.823225439s] Trained 128 records in 0.074302974 seconds. Throughput is 1722.6768 records/second. Loss is 0.149014. Sequential31006cbd's hyper parameters: Current learning rate is 0.003894080996884735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43264/60000][Iteration 7842][Wall Clock 718.904681275s] Trained 128 records in 0.081455836 seconds. Throughput is 1571.4037 records/second. Loss is 0.13134275. Sequential31006cbd's hyper parameters: Current learning rate is 0.00389377774316642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43392/60000][Iteration 7843][Wall Clock 718.985248863s] Trained 128 records in 0.080567588 seconds. Throughput is 1588.7281 records/second. Loss is 0.18802124. Sequential31006cbd's hyper parameters: Current learning rate is 0.00389347453667653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43520/60000][Iteration 7844][Wall Clock 719.060446613s] Trained 128 records in 0.07519775 seconds. Throughput is 1702.1786 records/second. Loss is 0.21410954. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038931713774040333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43648/60000][Iteration 7845][Wall Clock 719.136024563s] Trained 128 records in 0.07557795 seconds. Throughput is 1693.6156 records/second. Loss is 0.20316304. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038928682653379012. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43776/60000][Iteration 7846][Wall Clock 719.217060759s] Trained 128 records in 0.081036196 seconds. Throughput is 1579.5411 records/second. Loss is 0.110607564. Sequential31006cbd's hyper parameters: Current learning rate is 0.003892565200467108. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 43904/60000][Iteration 7847][Wall Clock 719.297243585s] Trained 128 records in 0.080182826 seconds. Throughput is 1596.3518 records/second. Loss is 0.2068995. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038922621827806314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 44032/60000][Iteration 7848][Wall Clock 719.374104647s] Trained 128 records in 0.076861062 seconds. Throughput is 1665.3427 records/second. Loss is 0.2075204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038919592122674557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:36 INFO  DistriOptimizer$:408 - [Epoch 17 44160/60000][Iteration 7849][Wall Clock 719.454124101s] Trained 128 records in 0.080019454 seconds. Throughput is 1599.6111 records/second. Loss is 0.12779771. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038916562889165624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 44288/60000][Iteration 7850][Wall Clock 719.53209993s] Trained 128 records in 0.077975829 seconds. Throughput is 1641.5343 records/second. Loss is 0.08015657. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038913534127169433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 44416/60000][Iteration 7851][Wall Clock 719.610517876s] Trained 128 records in 0.078417946 seconds. Throughput is 1632.2793 records/second. Loss is 0.2051757. Sequential31006cbd's hyper parameters: Current learning rate is 0.003891050583657587. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 44544/60000][Iteration 7852][Wall Clock 719.684872203s] Trained 128 records in 0.074354327 seconds. Throughput is 1721.4868 records/second. Loss is 0.12314723. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038907478017274925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 44672/60000][Iteration 7853][Wall Clock 719.767695768s] Trained 128 records in 0.082823565 seconds. Throughput is 1545.4539 records/second. Loss is 0.18529476. Sequential31006cbd's hyper parameters: Current learning rate is 0.003890445066915655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 44800/60000][Iteration 7854][Wall Clock 719.851393518s] Trained 128 records in 0.08369775 seconds. Throughput is 1529.3123 records/second. Loss is 0.10871241. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038901423792110797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 44928/60000][Iteration 7855][Wall Clock 719.933357299s] Trained 128 records in 0.081963781 seconds. Throughput is 1561.6654 records/second. Loss is 0.1596049. Sequential31006cbd's hyper parameters: Current learning rate is 0.003889839738602769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 45056/60000][Iteration 7856][Wall Clock 720.022639223s] Trained 128 records in 0.089281924 seconds. Throughput is 1433.6609 records/second. Loss is 0.057729352. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038895371450797353. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 45184/60000][Iteration 7857][Wall Clock 720.10046811s] Trained 128 records in 0.077828887 seconds. Throughput is 1644.6337 records/second. Loss is 0.1894811. Sequential31006cbd's hyper parameters: Current learning rate is 0.003889234598630989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 45312/60000][Iteration 7858][Wall Clock 720.185132527s] Trained 128 records in 0.084664417 seconds. Throughput is 1511.8512 records/second. Loss is 0.14770019. Sequential31006cbd's hyper parameters: Current learning rate is 0.003888932099245547. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 45440/60000][Iteration 7859][Wall Clock 720.267541823s] Trained 128 records in 0.082409296 seconds. Throughput is 1553.2229 records/second. Loss is 0.2352995. Sequential31006cbd's hyper parameters: Current learning rate is 0.003888629646912428. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 45568/60000][Iteration 7860][Wall Clock 720.348693146s] Trained 128 records in 0.081151323 seconds. Throughput is 1577.3003 records/second. Loss is 0.18129581. Sequential31006cbd's hyper parameters: Current learning rate is 0.003888327241620655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:37 INFO  DistriOptimizer$:408 - [Epoch 17 45696/60000][Iteration 7861][Wall Clock 720.431552996s] Trained 128 records in 0.08285985 seconds. Throughput is 1544.7771 records/second. Loss is 0.15291788. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038880248833592533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 45824/60000][Iteration 7862][Wall Clock 720.511906372s] Trained 128 records in 0.080353376 seconds. Throughput is 1592.9635 records/second. Loss is 0.1531842. Sequential31006cbd's hyper parameters: Current learning rate is 0.003887722572117254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 45952/60000][Iteration 7863][Wall Clock 720.593632992s] Trained 128 records in 0.08172662 seconds. Throughput is 1566.1971 records/second. Loss is 0.14114174. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038874203078836885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46080/60000][Iteration 7864][Wall Clock 720.68764521s] Trained 128 records in 0.094012218 seconds. Throughput is 1361.5251 records/second. Loss is 0.19982764. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038871180906475938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46208/60000][Iteration 7865][Wall Clock 720.781706029s] Trained 128 records in 0.094060819 seconds. Throughput is 1360.8217 records/second. Loss is 0.19812903. Sequential31006cbd's hyper parameters: Current learning rate is 0.00388681592039801. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46336/60000][Iteration 7866][Wall Clock 720.858481803s] Trained 128 records in 0.076775774 seconds. Throughput is 1667.1925 records/second. Loss is 0.11457983. Sequential31006cbd's hyper parameters: Current learning rate is 0.003886513797123979. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46464/60000][Iteration 7867][Wall Clock 720.942858681s] Trained 128 records in 0.084376878 seconds. Throughput is 1517.0033 records/second. Loss is 0.17916466. Sequential31006cbd's hyper parameters: Current learning rate is 0.00388621172081455. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46592/60000][Iteration 7868][Wall Clock 721.028473223s] Trained 128 records in 0.085614542 seconds. Throughput is 1495.0731 records/second. Loss is 0.16133107. Sequential31006cbd's hyper parameters: Current learning rate is 0.00388590969145877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46720/60000][Iteration 7869][Wall Clock 721.110617933s] Trained 128 records in 0.08214471 seconds. Throughput is 1558.2258 records/second. Loss is 0.11521872. Sequential31006cbd's hyper parameters: Current learning rate is 0.003885607709045695. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46848/60000][Iteration 7870][Wall Clock 721.197790472s] Trained 128 records in 0.087172539 seconds. Throughput is 1468.3523 records/second. Loss is 0.205953. Sequential31006cbd's hyper parameters: Current learning rate is 0.003885305773564379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 46976/60000][Iteration 7871][Wall Clock 721.278728688s] Trained 128 records in 0.080938216 seconds. Throughput is 1581.4532 records/second. Loss is 0.1314792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038850038850038854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 47104/60000][Iteration 7872][Wall Clock 721.375202278s] Trained 128 records in 0.09647359 seconds. Throughput is 1326.788 records/second. Loss is 0.16323726. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038847020433532744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:38 INFO  DistriOptimizer$:408 - [Epoch 17 47232/60000][Iteration 7873][Wall Clock 721.463125394s] Trained 128 records in 0.087923116 seconds. Throughput is 1455.8174 records/second. Loss is 0.1846611. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038844002486016164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 47360/60000][Iteration 7874][Wall Clock 721.543978019s] Trained 128 records in 0.080852625 seconds. Throughput is 1583.1273 records/second. Loss is 0.18093923. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038840985007379783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 47488/60000][Iteration 7875][Wall Clock 721.632331299s] Trained 128 records in 0.08835328 seconds. Throughput is 1448.7294 records/second. Loss is 0.12436775. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038837967997514375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 47616/60000][Iteration 7876][Wall Clock 721.717300222s] Trained 128 records in 0.084968923 seconds. Throughput is 1506.4331 records/second. Loss is 0.18211517. Sequential31006cbd's hyper parameters: Current learning rate is 0.003883495145631068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 47744/60000][Iteration 7877][Wall Clock 721.80259485s] Trained 128 records in 0.085294628 seconds. Throughput is 1500.6807 records/second. Loss is 0.17117102. Sequential31006cbd's hyper parameters: Current learning rate is 0.003883193538365952. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 47872/60000][Iteration 7878][Wall Clock 721.890969887s] Trained 128 records in 0.088375037 seconds. Throughput is 1448.3728 records/second. Loss is 0.13042471. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038828919779451735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 48000/60000][Iteration 7879][Wall Clock 721.98401666s] Trained 128 records in 0.093046773 seconds. Throughput is 1375.6522 records/second. Loss is 0.073522374. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038825904643578196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 48128/60000][Iteration 7880][Wall Clock 722.069233386s] Trained 128 records in 0.085216726 seconds. Throughput is 1502.0526 records/second. Loss is 0.15747969. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038822889975929807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 48256/60000][Iteration 7881][Wall Clock 722.149452407s] Trained 128 records in 0.080219021 seconds. Throughput is 1595.6315 records/second. Loss is 0.18106194. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038819875776397515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 48384/60000][Iteration 7882][Wall Clock 722.230325733s] Trained 128 records in 0.080873326 seconds. Throughput is 1582.722 records/second. Loss is 0.092812896. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038816862044872293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 48512/60000][Iteration 7883][Wall Clock 722.331007393s] Trained 128 records in 0.10068166 seconds. Throughput is 1271.3337 records/second. Loss is 0.17419809. Sequential31006cbd's hyper parameters: Current learning rate is 0.003881384878124515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:39 INFO  DistriOptimizer$:408 - [Epoch 17 48640/60000][Iteration 7884][Wall Clock 722.409035838s] Trained 128 records in 0.078028445 seconds. Throughput is 1640.4274 records/second. Loss is 0.12744057. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038810835985407127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 48768/60000][Iteration 7885][Wall Clock 722.484167074s] Trained 128 records in 0.075131236 seconds. Throughput is 1703.6855 records/second. Loss is 0.15186748. Sequential31006cbd's hyper parameters: Current learning rate is 0.00388078236572493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 48896/60000][Iteration 7886][Wall Clock 722.57338727s] Trained 128 records in 0.089220196 seconds. Throughput is 1434.6527 records/second. Loss is 0.14373043. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038804811796662787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49024/60000][Iteration 7887][Wall Clock 722.656272613s] Trained 128 records in 0.082885343 seconds. Throughput is 1544.302 records/second. Loss is 0.10071935. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038801800403538717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49152/60000][Iteration 7888][Wall Clock 722.739194079s] Trained 128 records in 0.082921466 seconds. Throughput is 1543.6293 records/second. Loss is 0.114484906. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038798789477768295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49280/60000][Iteration 7889][Wall Clock 722.822282021s] Trained 128 records in 0.083087942 seconds. Throughput is 1540.5364 records/second. Loss is 0.20611927. Sequential31006cbd's hyper parameters: Current learning rate is 0.00387957790192427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49408/60000][Iteration 7890][Wall Clock 722.926751099s] Trained 128 records in 0.104469078 seconds. Throughput is 1225.2429 records/second. Loss is 0.17785664. Sequential31006cbd's hyper parameters: Current learning rate is 0.003879276902785321. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49536/60000][Iteration 7891][Wall Clock 723.011005909s] Trained 128 records in 0.08425481 seconds. Throughput is 1519.2012 records/second. Loss is 0.15472567. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038789759503491074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49664/60000][Iteration 7892][Wall Clock 723.099275898s] Trained 128 records in 0.088269989 seconds. Throughput is 1450.0966 records/second. Loss is 0.18137763. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038786750446047633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49792/60000][Iteration 7893][Wall Clock 723.191525645s] Trained 128 records in 0.092249747 seconds. Throughput is 1387.5377 records/second. Loss is 0.072450235. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038783741855414207. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 49920/60000][Iteration 7894][Wall Clock 723.281202924s] Trained 128 records in 0.089677279 seconds. Throughput is 1427.3403 records/second. Loss is 0.19338554. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038780733731482203. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 50048/60000][Iteration 7895][Wall Clock 723.380633159s] Trained 128 records in 0.099430235 seconds. Throughput is 1287.3348 records/second. Loss is 0.21910943. Sequential31006cbd's hyper parameters: Current learning rate is 0.003877772607414301. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:40 INFO  DistriOptimizer$:408 - [Epoch 17 50176/60000][Iteration 7896][Wall Clock 723.465673489s] Trained 128 records in 0.08504033 seconds. Throughput is 1505.1682 records/second. Loss is 0.123994455. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038774718883288093. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 50304/60000][Iteration 7897][Wall Clock 723.552276282s] Trained 128 records in 0.086602793 seconds. Throughput is 1478.0125 records/second. Loss is 0.1777463. Sequential31006cbd's hyper parameters: Current learning rate is 0.003877171215880893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 50432/60000][Iteration 7898][Wall Clock 723.652919262s] Trained 128 records in 0.10064298 seconds. Throughput is 1271.8224 records/second. Loss is 0.14576223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038768705900597035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 50560/60000][Iteration 7899][Wall Clock 723.769685519s] Trained 128 records in 0.116766257 seconds. Throughput is 1096.207 records/second. Loss is 0.15732192. Sequential31006cbd's hyper parameters: Current learning rate is 0.003876570010854396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 50688/60000][Iteration 7900][Wall Clock 723.853605121s] Trained 128 records in 0.083919602 seconds. Throughput is 1525.2694 records/second. Loss is 0.1912539. Sequential31006cbd's hyper parameters: Current learning rate is 0.003876269478254128. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 50816/60000][Iteration 7901][Wall Clock 723.950177203s] Trained 128 records in 0.096572082 seconds. Throughput is 1325.4348 records/second. Loss is 0.14477019. Sequential31006cbd's hyper parameters: Current learning rate is 0.003875968992248062. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 50944/60000][Iteration 7902][Wall Clock 724.049941015s] Trained 128 records in 0.099763812 seconds. Throughput is 1283.0304 records/second. Loss is 0.12891652. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038756685528253624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 51072/60000][Iteration 7903][Wall Clock 724.152046262s] Trained 128 records in 0.102105247 seconds. Throughput is 1253.6085 records/second. Loss is 0.15249632. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038753681599751977. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 51200/60000][Iteration 7904][Wall Clock 724.23501734s] Trained 128 records in 0.082971078 seconds. Throughput is 1542.7062 records/second. Loss is 0.066743344. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038750678136867398. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 51328/60000][Iteration 7905][Wall Clock 724.32050737s] Trained 128 records in 0.08549003 seconds. Throughput is 1497.2506 records/second. Loss is 0.2060075. Sequential31006cbd's hyper parameters: Current learning rate is 0.003874767513949163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:41 INFO  DistriOptimizer$:408 - [Epoch 17 51456/60000][Iteration 7906][Wall Clock 724.402944684s] Trained 128 records in 0.082437314 seconds. Throughput is 1552.695 records/second. Loss is 0.1159377. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038744672607516463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 51584/60000][Iteration 7907][Wall Clock 724.492747692s] Trained 128 records in 0.089803008 seconds. Throughput is 1425.3419 records/second. Loss is 0.23152666. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038741670540833723. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 51712/60000][Iteration 7908][Wall Clock 724.571769061s] Trained 128 records in 0.079021369 seconds. Throughput is 1619.815 records/second. Loss is 0.13920066. Sequential31006cbd's hyper parameters: Current learning rate is 0.003873866893933524. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 51840/60000][Iteration 7909][Wall Clock 724.666474283s] Trained 128 records in 0.094705222 seconds. Throughput is 1351.5621 records/second. Loss is 0.1082723. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038735667802912922. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 51968/60000][Iteration 7910][Wall Clock 724.755529009s] Trained 128 records in 0.089054726 seconds. Throughput is 1437.3185 records/second. Loss is 0.14888555. Sequential31006cbd's hyper parameters: Current learning rate is 0.003873266713145867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52096/60000][Iteration 7911][Wall Clock 724.845110277s] Trained 128 records in 0.089581268 seconds. Throughput is 1428.8702 records/second. Loss is 0.22346254. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038729666924864447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52224/60000][Iteration 7912][Wall Clock 724.937684513s] Trained 128 records in 0.092574236 seconds. Throughput is 1382.6741 records/second. Loss is 0.13047901. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038726667183022227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52352/60000][Iteration 7913][Wall Clock 725.014627892s] Trained 128 records in 0.076943379 seconds. Throughput is 1663.5609 records/second. Loss is 0.13514146. Sequential31006cbd's hyper parameters: Current learning rate is 0.003872366790582404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52480/60000][Iteration 7914][Wall Clock 725.104807233s] Trained 128 records in 0.090179341 seconds. Throughput is 1419.3938 records/second. Loss is 0.118744746. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038720669093161926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52608/60000][Iteration 7915][Wall Clock 725.209168827s] Trained 128 records in 0.104361594 seconds. Throughput is 1226.5049 records/second. Loss is 0.072764695. Sequential31006cbd's hyper parameters: Current learning rate is 0.003871767074492799. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52736/60000][Iteration 7916][Wall Clock 725.298702906s] Trained 128 records in 0.089534079 seconds. Throughput is 1429.6232 records/second. Loss is 0.1306872. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038714672861014324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:42 INFO  DistriOptimizer$:408 - [Epoch 17 52864/60000][Iteration 7917][Wall Clock 725.377642025s] Trained 128 records in 0.078939119 seconds. Throughput is 1621.5028 records/second. Loss is 0.113404945. Sequential31006cbd's hyper parameters: Current learning rate is 0.00387116754413131. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 52992/60000][Iteration 7918][Wall Clock 725.483244118s] Trained 128 records in 0.105602093 seconds. Throughput is 1212.0972 records/second. Loss is 0.14191204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038708678485716496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53120/60000][Iteration 7919][Wall Clock 725.554684698s] Trained 128 records in 0.07144058 seconds. Throughput is 1791.6989 records/second. Loss is 0.13970703. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038705681994116734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53248/60000][Iteration 7920][Wall Clock 725.630065399s] Trained 128 records in 0.075380701 seconds. Throughput is 1698.0475 records/second. Loss is 0.14826414. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038702685966406068. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53376/60000][Iteration 7921][Wall Clock 725.706779041s] Trained 128 records in 0.076713642 seconds. Throughput is 1668.5428 records/second. Loss is 0.13186726. Sequential31006cbd's hyper parameters: Current learning rate is 0.003869969040247678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53504/60000][Iteration 7922][Wall Clock 725.783382765s] Trained 128 records in 0.076603724 seconds. Throughput is 1670.937 records/second. Loss is 0.16753614. Sequential31006cbd's hyper parameters: Current learning rate is 0.003869669530222119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53632/60000][Iteration 7923][Wall Clock 725.867249858s] Trained 128 records in 0.083867093 seconds. Throughput is 1526.2244 records/second. Loss is 0.14403108. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038693700665531653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53760/60000][Iteration 7924][Wall Clock 725.943121999s] Trained 128 records in 0.075872141 seconds. Throughput is 1687.0488 records/second. Loss is 0.16480693. Sequential31006cbd's hyper parameters: Current learning rate is 0.003869070649230055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 53888/60000][Iteration 7925][Wall Clock 726.021891294s] Trained 128 records in 0.078769295 seconds. Throughput is 1624.9987 records/second. Loss is 0.19613555. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038687712782420306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 54016/60000][Iteration 7926][Wall Clock 726.100817477s] Trained 128 records in 0.078926183 seconds. Throughput is 1621.7686 records/second. Loss is 0.20937318. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038684719535783366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 54144/60000][Iteration 7927][Wall Clock 726.175194177s] Trained 128 records in 0.0743767 seconds. Throughput is 1720.969 records/second. Loss is 0.18534926. Sequential31006cbd's hyper parameters: Current learning rate is 0.003868172675228222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 54272/60000][Iteration 7928][Wall Clock 726.249798416s] Trained 128 records in 0.074604239 seconds. Throughput is 1715.7203 records/second. Loss is 0.21937643. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038678734431809394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 54400/60000][Iteration 7929][Wall Clock 726.325271647s] Trained 128 records in 0.075473231 seconds. Throughput is 1695.9655 records/second. Loss is 0.1254285. Sequential31006cbd's hyper parameters: Current learning rate is 0.003867574257425742. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:43 INFO  DistriOptimizer$:408 - [Epoch 17 54528/60000][Iteration 7930][Wall Clock 726.410106205s] Trained 128 records in 0.084834558 seconds. Throughput is 1508.8191 records/second. Loss is 0.17795083. Sequential31006cbd's hyper parameters: Current learning rate is 0.003867275117951891. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 54656/60000][Iteration 7931][Wall Clock 726.486462971s] Trained 128 records in 0.076356766 seconds. Throughput is 1676.3412 records/second. Loss is 0.1469328. Sequential31006cbd's hyper parameters: Current learning rate is 0.003866976024748646. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 54784/60000][Iteration 7932][Wall Clock 726.559448975s] Trained 128 records in 0.072986004 seconds. Throughput is 1753.7609 records/second. Loss is 0.18387726. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038666769778052746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 54912/60000][Iteration 7933][Wall Clock 726.631204129s] Trained 128 records in 0.071755154 seconds. Throughput is 1783.844 records/second. Loss is 0.17750254. Sequential31006cbd's hyper parameters: Current learning rate is 0.003866377977111042. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55040/60000][Iteration 7934][Wall Clock 726.709967765s] Trained 128 records in 0.078763636 seconds. Throughput is 1625.1155 records/second. Loss is 0.23317046. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038660790226552233. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55168/60000][Iteration 7935][Wall Clock 726.790016236s] Trained 128 records in 0.080048471 seconds. Throughput is 1599.0311 records/second. Loss is 0.075475544. Sequential31006cbd's hyper parameters: Current learning rate is 0.003865780114427091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55296/60000][Iteration 7936][Wall Clock 726.86161721s] Trained 128 records in 0.071600974 seconds. Throughput is 1787.6852 records/second. Loss is 0.19806585. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038654812524159263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55424/60000][Iteration 7937][Wall Clock 726.937863338s] Trained 128 records in 0.076246128 seconds. Throughput is 1678.7738 records/second. Loss is 0.13129789. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038651824366110078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55552/60000][Iteration 7938][Wall Clock 727.016277944s] Trained 128 records in 0.078414606 seconds. Throughput is 1632.349 records/second. Loss is 0.18254715. Sequential31006cbd's hyper parameters: Current learning rate is 0.003864883667001623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55680/60000][Iteration 7939][Wall Clock 727.095626259s] Trained 128 records in 0.079348315 seconds. Throughput is 1613.1406 records/second. Loss is 0.14483684. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038645849435770597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55808/60000][Iteration 7940][Wall Clock 727.177144715s] Trained 128 records in 0.081518456 seconds. Throughput is 1570.1965 records/second. Loss is 0.13663988. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038642862663266094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 55936/60000][Iteration 7941][Wall Clock 727.268213737s] Trained 128 records in 0.091069022 seconds. Throughput is 1405.5273 records/second. Loss is 0.21399145. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038639876352395673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 56064/60000][Iteration 7942][Wall Clock 727.3436034s] Trained 128 records in 0.075389663 seconds. Throughput is 1697.8456 records/second. Loss is 0.14472479. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038636890503052313. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:44 INFO  DistriOptimizer$:408 - [Epoch 17 56192/60000][Iteration 7943][Wall Clock 727.418754613s] Trained 128 records in 0.075151213 seconds. Throughput is 1703.2327 records/second. Loss is 0.15735534. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038633905115129036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 56320/60000][Iteration 7944][Wall Clock 727.494587234s] Trained 128 records in 0.075832621 seconds. Throughput is 1687.928 records/second. Loss is 0.2385597. Sequential31006cbd's hyper parameters: Current learning rate is 0.003863092018851889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 56448/60000][Iteration 7945][Wall Clock 727.578251876s] Trained 128 records in 0.083664642 seconds. Throughput is 1529.9175 records/second. Loss is 0.095065765. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038627935723114957. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 56576/60000][Iteration 7946][Wall Clock 727.659697685s] Trained 128 records in 0.081445809 seconds. Throughput is 1571.5972 records/second. Loss is 0.16509883. Sequential31006cbd's hyper parameters: Current learning rate is 0.003862495171881035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 56704/60000][Iteration 7947][Wall Clock 727.742571251s] Trained 128 records in 0.082873566 seconds. Throughput is 1544.5214 records/second. Loss is 0.12958378. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038621968175498226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 56832/60000][Iteration 7948][Wall Clock 727.825966591s] Trained 128 records in 0.08339534 seconds. Throughput is 1534.8579 records/second. Loss is 0.15605804. Sequential31006cbd's hyper parameters: Current learning rate is 0.003861898509307175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 56960/60000][Iteration 7949][Wall Clock 727.922495681s] Trained 128 records in 0.09652909 seconds. Throughput is 1326.0251 records/second. Loss is 0.19346812. Sequential31006cbd's hyper parameters: Current learning rate is 0.003861600247142416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 57088/60000][Iteration 7950][Wall Clock 728.026464249s] Trained 128 records in 0.103968568 seconds. Throughput is 1231.1414 records/second. Loss is 0.17514536. Sequential31006cbd's hyper parameters: Current learning rate is 0.003861302031044868. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 57216/60000][Iteration 7951][Wall Clock 728.11397056s] Trained 128 records in 0.087506311 seconds. Throughput is 1462.7517 records/second. Loss is 0.17649765. Sequential31006cbd's hyper parameters: Current learning rate is 0.003861003861003861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 57344/60000][Iteration 7952][Wall Clock 728.199287286s] Trained 128 records in 0.085316726 seconds. Throughput is 1500.292 records/second. Loss is 0.12745821. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038607057370087247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 57472/60000][Iteration 7953][Wall Clock 728.277052146s] Trained 128 records in 0.07776486 seconds. Throughput is 1645.9877 records/second. Loss is 0.11917925. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038604076590487957. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 57600/60000][Iteration 7954][Wall Clock 728.353990284s] Trained 128 records in 0.076938138 seconds. Throughput is 1663.6743 records/second. Loss is 0.12948954. Sequential31006cbd's hyper parameters: Current learning rate is 0.00386010962711341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:45 INFO  DistriOptimizer$:408 - [Epoch 17 57728/60000][Iteration 7955][Wall Clock 728.428964874s] Trained 128 records in 0.07497459 seconds. Throughput is 1707.2451 records/second. Loss is 0.12559366. Sequential31006cbd's hyper parameters: Current learning rate is 0.00385981164119191. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 57856/60000][Iteration 7956][Wall Clock 728.506168256s] Trained 128 records in 0.077203382 seconds. Throughput is 1657.9584 records/second. Loss is 0.11945877. Sequential31006cbd's hyper parameters: Current learning rate is 0.003859513701273639. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 57984/60000][Iteration 7957][Wall Clock 728.588409427s] Trained 128 records in 0.082241171 seconds. Throughput is 1556.3981 records/second. Loss is 0.1095704. Sequential31006cbd's hyper parameters: Current learning rate is 0.003859215807347947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58112/60000][Iteration 7958][Wall Clock 728.67389944s] Trained 128 records in 0.085490013 seconds. Throughput is 1497.251 records/second. Loss is 0.13092685. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038589179594041827. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58240/60000][Iteration 7959][Wall Clock 728.75283345s] Trained 128 records in 0.07893401 seconds. Throughput is 1621.6078 records/second. Loss is 0.24277806. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038586201574317023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58368/60000][Iteration 7960][Wall Clock 728.838925912s] Trained 128 records in 0.086092462 seconds. Throughput is 1486.7736 records/second. Loss is 0.17328927. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038583224014198626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58496/60000][Iteration 7961][Wall Clock 728.913564384s] Trained 128 records in 0.074638472 seconds. Throughput is 1714.9333 records/second. Loss is 0.11949195. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038580246913580245. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58624/60000][Iteration 7962][Wall Clock 728.987744149s] Trained 128 records in 0.074179765 seconds. Throughput is 1725.5378 records/second. Loss is 0.11134717. Sequential31006cbd's hyper parameters: Current learning rate is 0.003857727027235553. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58752/60000][Iteration 7963][Wall Clock 729.0700108s] Trained 128 records in 0.082266651 seconds. Throughput is 1555.916 records/second. Loss is 0.10372511. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038574294090418146. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 58880/60000][Iteration 7964][Wall Clock 729.151043598s] Trained 128 records in 0.081032798 seconds. Throughput is 1579.6073 records/second. Loss is 0.12413076. Sequential31006cbd's hyper parameters: Current learning rate is 0.003857131836766181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 59008/60000][Iteration 7965][Wall Clock 729.234685768s] Trained 128 records in 0.08364217 seconds. Throughput is 1530.3285 records/second. Loss is 0.15432906. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038568343103980254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 59136/60000][Iteration 7966][Wall Clock 729.318832998s] Trained 128 records in 0.08414723 seconds. Throughput is 1521.1433 records/second. Loss is 0.17875841. Sequential31006cbd's hyper parameters: Current learning rate is 0.003856536829926726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:46 INFO  DistriOptimizer$:408 - [Epoch 17 59264/60000][Iteration 7967][Wall Clock 729.423726566s] Trained 128 records in 0.104893568 seconds. Throughput is 1220.2845 records/second. Loss is 0.23084776. Sequential31006cbd's hyper parameters: Current learning rate is 0.003856239395341662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:408 - [Epoch 17 59392/60000][Iteration 7968][Wall Clock 729.504053302s] Trained 128 records in 0.080326736 seconds. Throughput is 1593.4918 records/second. Loss is 0.107089154. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038559420066322206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:408 - [Epoch 17 59520/60000][Iteration 7969][Wall Clock 729.586787845s] Trained 128 records in 0.082734543 seconds. Throughput is 1547.1168 records/second. Loss is 0.13306378. Sequential31006cbd's hyper parameters: Current learning rate is 0.003855644663787785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:408 - [Epoch 17 59648/60000][Iteration 7970][Wall Clock 729.676177412s] Trained 128 records in 0.089389567 seconds. Throughput is 1431.9344 records/second. Loss is 0.13083914. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038553473667977487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:408 - [Epoch 17 59776/60000][Iteration 7971][Wall Clock 729.753467364s] Trained 128 records in 0.077289952 seconds. Throughput is 1656.1014 records/second. Loss is 0.21301508. Sequential31006cbd's hyper parameters: Current learning rate is 0.003855050115651503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:408 - [Epoch 17 59904/60000][Iteration 7972][Wall Clock 729.842849547s] Trained 128 records in 0.089382183 seconds. Throughput is 1432.0527 records/second. Loss is 0.07167473. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038547529103384478. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:408 - [Epoch 17 60032/60000][Iteration 7973][Wall Clock 729.923945199s] Trained 128 records in 0.081095652 seconds. Throughput is 1578.383 records/second. Loss is 0.13370746. Sequential31006cbd's hyper parameters: Current learning rate is 0.00385445575084798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:47 INFO  DistriOptimizer$:452 - [Epoch 17 60032/60000][Iteration 7973][Wall Clock 729.923945199s] Epoch finished. Wall clock time is 731004.832968 ms
2019-10-24 00:09:47 INFO  DistriOptimizer$:111 - [Epoch 17 60032/60000][Iteration 7973][Wall Clock 729.923945199s] Validate model...
2019-10-24 00:09:48 INFO  DistriOptimizer$:178 - [Epoch 17 60032/60000][Iteration 7973][Wall Clock 729.923945199s] validate model throughput is 12032.526 records/second
2019-10-24 00:09:48 INFO  DistriOptimizer$:181 - [Epoch 17 60032/60000][Iteration 7973][Wall Clock 729.923945199s] Top1Accuracy is Accuracy(correct: 9557, count: 10000, accuracy: 0.9557)
2019-10-24 00:09:48 INFO  DistriOptimizer$:221 - [Wall Clock 731.004832968s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:09:48 INFO  DistriOptimizer$:226 - [Wall Clock 731.004832968s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 128/60000][Iteration 7974][Wall Clock 731.100818122s] Trained 128 records in 0.095985154 seconds. Throughput is 1333.5396 records/second. Loss is 0.14711918. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038541586371695063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 256/60000][Iteration 7975][Wall Clock 731.175676413s] Trained 128 records in 0.074858291 seconds. Throughput is 1709.8973 records/second. Loss is 0.13573548. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038538615692924306. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 384/60000][Iteration 7976][Wall Clock 731.25229324s] Trained 128 records in 0.076616827 seconds. Throughput is 1670.6514 records/second. Loss is 0.17474425. Sequential31006cbd's hyper parameters: Current learning rate is 0.003853564547206166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 512/60000][Iteration 7977][Wall Clock 731.332064339s] Trained 128 records in 0.079771099 seconds. Throughput is 1604.5911 records/second. Loss is 0.14865234. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038532675709001232. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 640/60000][Iteration 7978][Wall Clock 731.407543887s] Trained 128 records in 0.075479548 seconds. Throughput is 1695.8237 records/second. Loss is 0.15371753. Sequential31006cbd's hyper parameters: Current learning rate is 0.00385297064036372. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 768/60000][Iteration 7979][Wall Clock 731.486057155s] Trained 128 records in 0.078513268 seconds. Throughput is 1630.2977 records/second. Loss is 0.12889306. Sequential31006cbd's hyper parameters: Current learning rate is 0.003852673755586377. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:48 INFO  DistriOptimizer$:408 - [Epoch 18 896/60000][Iteration 7980][Wall Clock 731.561815086s] Trained 128 records in 0.075757931 seconds. Throughput is 1689.5922 records/second. Loss is 0.130275. Sequential31006cbd's hyper parameters: Current learning rate is 0.003852376916557516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1024/60000][Iteration 7981][Wall Clock 731.64037086s] Trained 128 records in 0.078555774 seconds. Throughput is 1629.4155 records/second. Loss is 0.13430633. Sequential31006cbd's hyper parameters: Current learning rate is 0.003852080123266564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1152/60000][Iteration 7982][Wall Clock 731.733075307s] Trained 128 records in 0.092704447 seconds. Throughput is 1380.732 records/second. Loss is 0.09455702. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038517833757029506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1280/60000][Iteration 7983][Wall Clock 731.811706978s] Trained 128 records in 0.078631671 seconds. Throughput is 1627.8429 records/second. Loss is 0.11483792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038514866738561084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1408/60000][Iteration 7984][Wall Clock 731.893014329s] Trained 128 records in 0.081307351 seconds. Throughput is 1574.2734 records/second. Loss is 0.1907239. Sequential31006cbd's hyper parameters: Current learning rate is 0.003851190017715474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1536/60000][Iteration 7985][Wall Clock 731.97038849s] Trained 128 records in 0.077374161 seconds. Throughput is 1654.2991 records/second. Loss is 0.20340264. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038508934072704866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1664/60000][Iteration 7986][Wall Clock 732.050493724s] Trained 128 records in 0.080105234 seconds. Throughput is 1597.8981 records/second. Loss is 0.105542496. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038505968425105895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1792/60000][Iteration 7987][Wall Clock 732.129570436s] Trained 128 records in 0.079076712 seconds. Throughput is 1618.6813 records/second. Loss is 0.139411. Sequential31006cbd's hyper parameters: Current learning rate is 0.003850300323425227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 1920/60000][Iteration 7988][Wall Clock 732.2039942s] Trained 128 records in 0.074423764 seconds. Throughput is 1719.8807 records/second. Loss is 0.13834524. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038500038500038497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 2048/60000][Iteration 7989][Wall Clock 732.279512006s] Trained 128 records in 0.075517806 seconds. Throughput is 1694.9646 records/second. Loss is 0.15855284. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038497074222359103. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 2176/60000][Iteration 7990][Wall Clock 732.361789124s] Trained 128 records in 0.082277118 seconds. Throughput is 1555.718 records/second. Loss is 0.17292948. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038494110401108626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 2304/60000][Iteration 7991][Wall Clock 732.453538906s] Trained 128 records in 0.091749782 seconds. Throughput is 1395.0988 records/second. Loss is 0.10360685. Sequential31006cbd's hyper parameters: Current learning rate is 0.003849114703618168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:49 INFO  DistriOptimizer$:408 - [Epoch 18 2432/60000][Iteration 7992][Wall Clock 732.528724118s] Trained 128 records in 0.075185212 seconds. Throughput is 1702.4625 records/second. Loss is 0.10085886. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038488184127472864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 2560/60000][Iteration 7993][Wall Clock 732.607423826s] Trained 128 records in 0.078699708 seconds. Throughput is 1626.4355 records/second. Loss is 0.18260068. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038485221674876852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 2688/60000][Iteration 7994][Wall Clock 732.684821844s] Trained 128 records in 0.077398018 seconds. Throughput is 1653.7892 records/second. Loss is 0.12244983. Sequential31006cbd's hyper parameters: Current learning rate is 0.003848225967828831. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 2816/60000][Iteration 7995][Wall Clock 732.765605895s] Trained 128 records in 0.080784051 seconds. Throughput is 1584.4712 records/second. Loss is 0.16775504. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038479298137601976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 2944/60000][Iteration 7996][Wall Clock 732.844149947s] Trained 128 records in 0.078544052 seconds. Throughput is 1629.6588 records/second. Loss is 0.16672446. Sequential31006cbd's hyper parameters: Current learning rate is 0.003847633705271258. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3072/60000][Iteration 7997][Wall Clock 732.920753999s] Trained 128 records in 0.076604052 seconds. Throughput is 1670.9298 records/second. Loss is 0.31690517. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038473376423514925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3200/60000][Iteration 7998][Wall Clock 732.993168998s] Trained 128 records in 0.072414999 seconds. Throughput is 1767.5896 records/second. Loss is 0.12849784. Sequential31006cbd's hyper parameters: Current learning rate is 0.003847041624990382. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3328/60000][Iteration 7999][Wall Clock 733.076043331s] Trained 128 records in 0.082874333 seconds. Throughput is 1544.5071 records/second. Loss is 0.14143895. Sequential31006cbd's hyper parameters: Current learning rate is 0.003846745653177412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3456/60000][Iteration 8000][Wall Clock 733.143066213s] Trained 128 records in 0.067022882 seconds. Throughput is 1909.7955 records/second. Loss is 0.13521552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038464497269020694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3584/60000][Iteration 8001][Wall Clock 733.213987891s] Trained 128 records in 0.070921678 seconds. Throughput is 1804.808 records/second. Loss is 0.16650225. Sequential31006cbd's hyper parameters: Current learning rate is 0.003846153846153846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3712/60000][Iteration 8002][Wall Clock 733.297597189s] Trained 128 records in 0.083609298 seconds. Throughput is 1530.9302 records/second. Loss is 0.16075985. Sequential31006cbd's hyper parameters: Current learning rate is 0.003845858010922237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3840/60000][Iteration 8003][Wall Clock 733.383679955s] Trained 128 records in 0.086082766 seconds. Throughput is 1486.9412 records/second. Loss is 0.18030873. Sequential31006cbd's hyper parameters: Current learning rate is 0.003845562221196739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 3968/60000][Iteration 8004][Wall Clock 733.464427065s] Trained 128 records in 0.08074711 seconds. Throughput is 1585.196 records/second. Loss is 0.12744412. Sequential31006cbd's hyper parameters: Current learning rate is 0.003845266476966854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:50 INFO  DistriOptimizer$:408 - [Epoch 18 4096/60000][Iteration 8005][Wall Clock 733.544079281s] Trained 128 records in 0.079652216 seconds. Throughput is 1606.9861 records/second. Loss is 0.13968371. Sequential31006cbd's hyper parameters: Current learning rate is 0.003844970778222086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4224/60000][Iteration 8006][Wall Clock 733.61595901s] Trained 128 records in 0.071879729 seconds. Throughput is 1780.7524 records/second. Loss is 0.1752665. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038446751249519417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4352/60000][Iteration 8007][Wall Clock 733.690726657s] Trained 128 records in 0.074767647 seconds. Throughput is 1711.9703 records/second. Loss is 0.15739588. Sequential31006cbd's hyper parameters: Current learning rate is 0.003844379517145932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4480/60000][Iteration 8008][Wall Clock 733.767691494s] Trained 128 records in 0.076964837 seconds. Throughput is 1663.097 records/second. Loss is 0.23013073. Sequential31006cbd's hyper parameters: Current learning rate is 0.003844083954793573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4608/60000][Iteration 8009][Wall Clock 733.842452905s] Trained 128 records in 0.074761411 seconds. Throughput is 1712.1132 records/second. Loss is 0.17987052. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038437884378843784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4736/60000][Iteration 8010][Wall Clock 733.924673207s] Trained 128 records in 0.082220302 seconds. Throughput is 1556.7931 records/second. Loss is 0.13632454. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038434929664078717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4864/60000][Iteration 8011][Wall Clock 734.0014054s] Trained 128 records in 0.076732193 seconds. Throughput is 1668.1394 records/second. Loss is 0.16502619. Sequential31006cbd's hyper parameters: Current learning rate is 0.003843197540353574. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 4992/60000][Iteration 8012][Wall Clock 734.079810692s] Trained 128 records in 0.078405292 seconds. Throughput is 1632.5428 records/second. Loss is 0.105722144. Sequential31006cbd's hyper parameters: Current learning rate is 0.003842902159711014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 5120/60000][Iteration 8013][Wall Clock 734.156487884s] Trained 128 records in 0.076677192 seconds. Throughput is 1669.336 records/second. Loss is 0.14024836. Sequential31006cbd's hyper parameters: Current learning rate is 0.00384260682446972. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 5248/60000][Iteration 8014][Wall Clock 734.230714243s] Trained 128 records in 0.074226359 seconds. Throughput is 1724.4548 records/second. Loss is 0.12955025. Sequential31006cbd's hyper parameters: Current learning rate is 0.003842311534619227. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 5376/60000][Iteration 8015][Wall Clock 734.302519117s] Trained 128 records in 0.071804874 seconds. Throughput is 1782.6088 records/second. Loss is 0.2533397. Sequential31006cbd's hyper parameters: Current learning rate is 0.00384201629014907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 5504/60000][Iteration 8016][Wall Clock 734.377590196s] Trained 128 records in 0.075071079 seconds. Throughput is 1705.0507 records/second. Loss is 0.1548081. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038417210910487902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 5632/60000][Iteration 8017][Wall Clock 734.4563639s] Trained 128 records in 0.078773704 seconds. Throughput is 1624.9077 records/second. Loss is 0.1685828. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038414259373079286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:51 INFO  DistriOptimizer$:408 - [Epoch 18 5760/60000][Iteration 8018][Wall Clock 734.533447767s] Trained 128 records in 0.077083867 seconds. Throughput is 1660.5292 records/second. Loss is 0.16782624. Sequential31006cbd's hyper parameters: Current learning rate is 0.003841130828916033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 5888/60000][Iteration 8019][Wall Clock 734.608995107s] Trained 128 records in 0.07554734 seconds. Throughput is 1694.3019 records/second. Loss is 0.17126797. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038408357658626514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6016/60000][Iteration 8020][Wall Clock 734.685696663s] Trained 128 records in 0.076701556 seconds. Throughput is 1668.8057 records/second. Loss is 0.15319349. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038405407481373376. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6144/60000][Iteration 8021][Wall Clock 734.764020706s] Trained 128 records in 0.078324043 seconds. Throughput is 1634.2363 records/second. Loss is 0.1601687. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038402457757296467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6272/60000][Iteration 8022][Wall Clock 734.839467501s] Trained 128 records in 0.075446795 seconds. Throughput is 1696.5599 records/second. Loss is 0.14590396. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038399508486291374. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6400/60000][Iteration 8023][Wall Clock 734.916916611s] Trained 128 records in 0.07744911 seconds. Throughput is 1652.6981 records/second. Loss is 0.16810785. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038396559668253723. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6528/60000][Iteration 8024][Wall Clock 734.992120437s] Trained 128 records in 0.075203826 seconds. Throughput is 1702.041 records/second. Loss is 0.13583873. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038393611303079167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6656/60000][Iteration 8025][Wall Clock 735.074111658s] Trained 128 records in 0.081991221 seconds. Throughput is 1561.1428 records/second. Loss is 0.17872316. Sequential31006cbd's hyper parameters: Current learning rate is 0.003839066339066339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6784/60000][Iteration 8026][Wall Clock 735.167974505s] Trained 128 records in 0.093862847 seconds. Throughput is 1363.6919 records/second. Loss is 0.11324531. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038387715930902114. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 6912/60000][Iteration 8027][Wall Clock 735.245023577s] Trained 128 records in 0.077049072 seconds. Throughput is 1661.279 records/second. Loss is 0.1981113. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038384768923691082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 7040/60000][Iteration 8028][Wall Clock 735.321937752s] Trained 128 records in 0.076914175 seconds. Throughput is 1664.1925 records/second. Loss is 0.100470364. Sequential31006cbd's hyper parameters: Current learning rate is 0.003838182236892607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 7168/60000][Iteration 8029][Wall Clock 735.401290474s] Trained 128 records in 0.079352722 seconds. Throughput is 1613.0511 records/second. Loss is 0.13698965. Sequential31006cbd's hyper parameters: Current learning rate is 0.003837887626650292. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 7296/60000][Iteration 8030][Wall Clock 735.473775095s] Trained 128 records in 0.072484621 seconds. Throughput is 1765.8918 records/second. Loss is 0.24350005. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038375930616317442. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:52 INFO  DistriOptimizer$:408 - [Epoch 18 7424/60000][Iteration 8031][Wall Clock 735.55083267s] Trained 128 records in 0.077057575 seconds. Throughput is 1661.0956 records/second. Loss is 0.1046934. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038372985418265544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 7552/60000][Iteration 8032][Wall Clock 735.631525719s] Trained 128 records in 0.080693049 seconds. Throughput is 1586.258 records/second. Loss is 0.24206223. Sequential31006cbd's hyper parameters: Current learning rate is 0.003837004067224311. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 7680/60000][Iteration 8033][Wall Clock 735.711451635s] Trained 128 records in 0.079925916 seconds. Throughput is 1601.483 records/second. Loss is 0.11645953. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038367096378146104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 7808/60000][Iteration 8034][Wall Clock 735.792821304s] Trained 128 records in 0.081369669 seconds. Throughput is 1573.0677 records/second. Loss is 0.12029679. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038364152535870478. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 7936/60000][Iteration 8035][Wall Clock 735.869157841s] Trained 128 records in 0.076336537 seconds. Throughput is 1676.7854 records/second. Loss is 0.15025163. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038361209145312265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8064/60000][Iteration 8036][Wall Clock 735.947405001s] Trained 128 records in 0.07824716 seconds. Throughput is 1635.8422 records/second. Loss is 0.15536061. Sequential31006cbd's hyper parameters: Current learning rate is 0.003835826620636747. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8192/60000][Iteration 8037][Wall Clock 736.020394444s] Trained 128 records in 0.072989443 seconds. Throughput is 1753.6783 records/second. Loss is 0.08428914. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038355323718932185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8320/60000][Iteration 8038][Wall Clock 736.096699983s] Trained 128 records in 0.076305539 seconds. Throughput is 1677.4667 records/second. Loss is 0.14735311. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038352381682902506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8448/60000][Iteration 8039][Wall Clock 736.176577207s] Trained 128 records in 0.079877224 seconds. Throughput is 1602.4592 records/second. Loss is 0.21532257. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038349440098174566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8576/60000][Iteration 8040][Wall Clock 736.251114722s] Trained 128 records in 0.074537515 seconds. Throughput is 1717.2561 records/second. Loss is 0.10074727. Sequential31006cbd's hyper parameters: Current learning rate is 0.003834649896464453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8704/60000][Iteration 8041][Wall Clock 736.32865077s] Trained 128 records in 0.077536048 seconds. Throughput is 1650.8451 records/second. Loss is 0.17769344. Sequential31006cbd's hyper parameters: Current learning rate is 0.003834355828220859. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8832/60000][Iteration 8042][Wall Clock 736.410414657s] Trained 128 records in 0.081763887 seconds. Throughput is 1565.4833 records/second. Loss is 0.1059663. Sequential31006cbd's hyper parameters: Current learning rate is 0.003834061805076298. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:53 INFO  DistriOptimizer$:408 - [Epoch 18 8960/60000][Iteration 8043][Wall Clock 736.492741378s] Trained 128 records in 0.082326721 seconds. Throughput is 1554.7808 records/second. Loss is 0.241359. Sequential31006cbd's hyper parameters: Current learning rate is 0.003833767827020396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9088/60000][Iteration 8044][Wall Clock 736.576766283s] Trained 128 records in 0.084024905 seconds. Throughput is 1523.3578 records/second. Loss is 0.16559759. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038334738940427816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9216/60000][Iteration 8045][Wall Clock 736.660317823s] Trained 128 records in 0.08355154 seconds. Throughput is 1531.9885 records/second. Loss is 0.18751472. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038331800061330882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9344/60000][Iteration 8046][Wall Clock 736.739502629s] Trained 128 records in 0.079184806 seconds. Throughput is 1616.4717 records/second. Loss is 0.09185719. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038328861632809506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9472/60000][Iteration 8047][Wall Clock 736.826423899s] Trained 128 records in 0.08692127 seconds. Throughput is 1472.597 records/second. Loss is 0.18108138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038325923654760076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9600/60000][Iteration 8048][Wall Clock 736.913074251s] Trained 128 records in 0.086650352 seconds. Throughput is 1477.2012 records/second. Loss is 0.08914717. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038322986127079023. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9728/60000][Iteration 8049][Wall Clock 736.990662842s] Trained 128 records in 0.077588591 seconds. Throughput is 1649.7272 records/second. Loss is 0.12683706. Sequential31006cbd's hyper parameters: Current learning rate is 0.003832004904966278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9856/60000][Iteration 8050][Wall Clock 737.067062701s] Trained 128 records in 0.076399859 seconds. Throughput is 1675.3959 records/second. Loss is 0.14789203. Sequential31006cbd's hyper parameters: Current learning rate is 0.003831711242240785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 9984/60000][Iteration 8051][Wall Clock 737.156597041s] Trained 128 records in 0.08953434 seconds. Throughput is 1429.619 records/second. Loss is 0.11836326. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038314176245210726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 10112/60000][Iteration 8052][Wall Clock 737.236134278s] Trained 128 records in 0.079537237 seconds. Throughput is 1609.3092 records/second. Loss is 0.1952047. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038311240517967973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 10240/60000][Iteration 8053][Wall Clock 737.311738591s] Trained 128 records in 0.075604313 seconds. Throughput is 1693.0251 records/second. Loss is 0.14716692. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038308305240576154. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 10368/60000][Iteration 8054][Wall Clock 737.390369882s] Trained 128 records in 0.078631291 seconds. Throughput is 1627.8507 records/second. Loss is 0.18328366. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038305370412931895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:54 INFO  DistriOptimizer$:408 - [Epoch 18 10496/60000][Iteration 8055][Wall Clock 737.46830669s] Trained 128 records in 0.077936808 seconds. Throughput is 1642.3562 records/second. Loss is 0.14540806. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038302436034931817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 10624/60000][Iteration 8056][Wall Clock 737.561427776s] Trained 128 records in 0.093121086 seconds. Throughput is 1374.5543 records/second. Loss is 0.11919518. Sequential31006cbd's hyper parameters: Current learning rate is 0.003829950210647262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 10752/60000][Iteration 8057][Wall Clock 737.643535668s] Trained 128 records in 0.082107892 seconds. Throughput is 1558.9244 records/second. Loss is 0.21263558. Sequential31006cbd's hyper parameters: Current learning rate is 0.003829656862745098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 10880/60000][Iteration 8058][Wall Clock 737.719634286s] Trained 128 records in 0.076098618 seconds. Throughput is 1682.0278 records/second. Loss is 0.20743954. Sequential31006cbd's hyper parameters: Current learning rate is 0.003829363559776365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11008/60000][Iteration 8059][Wall Clock 737.795440557s] Trained 128 records in 0.075806271 seconds. Throughput is 1688.5148 records/second. Loss is 0.27181357. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038290703017307397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11136/60000][Iteration 8060][Wall Clock 737.873145372s] Trained 128 records in 0.077704815 seconds. Throughput is 1647.2595 records/second. Loss is 0.098112255. Sequential31006cbd's hyper parameters: Current learning rate is 0.003828777088597902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11264/60000][Iteration 8061][Wall Clock 737.951499857s] Trained 128 records in 0.078354485 seconds. Throughput is 1633.6014 records/second. Loss is 0.11327703. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038284839203675345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11392/60000][Iteration 8062][Wall Clock 738.026778005s] Trained 128 records in 0.075278148 seconds. Throughput is 1700.3606 records/second. Loss is 0.1700507. Sequential31006cbd's hyper parameters: Current learning rate is 0.003828190797029324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11520/60000][Iteration 8063][Wall Clock 738.102023369s] Trained 128 records in 0.075245364 seconds. Throughput is 1701.1014 records/second. Loss is 0.14590847. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038278977185729596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11648/60000][Iteration 8064][Wall Clock 738.180373228s] Trained 128 records in 0.078349859 seconds. Throughput is 1633.6979 records/second. Loss is 0.20233047. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038276046849881344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11776/60000][Iteration 8065][Wall Clock 738.262184981s] Trained 128 records in 0.081811753 seconds. Throughput is 1564.5674 records/second. Loss is 0.07694201. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038273116962645438. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 11904/60000][Iteration 8066][Wall Clock 738.336140214s] Trained 128 records in 0.073955233 seconds. Throughput is 1730.7769 records/second. Loss is 0.30077562. Sequential31006cbd's hyper parameters: Current learning rate is 0.003827018752391887. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 12032/60000][Iteration 8067][Wall Clock 738.414256153s] Trained 128 records in 0.078115939 seconds. Throughput is 1638.59 records/second. Loss is 0.19032665. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038267258533598654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:55 INFO  DistriOptimizer$:408 - [Epoch 18 12160/60000][Iteration 8068][Wall Clock 738.502513521s] Trained 128 records in 0.088257368 seconds. Throughput is 1450.3038 records/second. Loss is 0.19304131. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038264329991581844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 12288/60000][Iteration 8069][Wall Clock 738.585710653s] Trained 128 records in 0.083197132 seconds. Throughput is 1538.5145 records/second. Loss is 0.17991841. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038261401897765534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 12416/60000][Iteration 8070][Wall Clock 738.664209931s] Trained 128 records in 0.078499278 seconds. Throughput is 1630.5883 records/second. Loss is 0.12219536. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038258474252046825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 12544/60000][Iteration 8071][Wall Clock 738.745373929s] Trained 128 records in 0.081163998 seconds. Throughput is 1577.054 records/second. Loss is 0.1288552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038255547054322878. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 12672/60000][Iteration 8072][Wall Clock 738.824693333s] Trained 128 records in 0.079319404 seconds. Throughput is 1613.7288 records/second. Loss is 0.20451155. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038252620304490854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 12800/60000][Iteration 8073][Wall Clock 738.906509123s] Trained 128 records in 0.08181579 seconds. Throughput is 1564.4902 records/second. Loss is 0.16915424. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038249694002447984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 12928/60000][Iteration 8074][Wall Clock 738.984408954s] Trained 128 records in 0.077899831 seconds. Throughput is 1643.1359 records/second. Loss is 0.18601811. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038246768148091485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 13056/60000][Iteration 8075][Wall Clock 739.062417654s] Trained 128 records in 0.0780087 seconds. Throughput is 1640.8427 records/second. Loss is 0.15167564. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038243842741318653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 13184/60000][Iteration 8076][Wall Clock 739.155168882s] Trained 128 records in 0.092751228 seconds. Throughput is 1380.0356 records/second. Loss is 0.15959613. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038240917782026767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 13312/60000][Iteration 8077][Wall Clock 739.245793833s] Trained 128 records in 0.090624951 seconds. Throughput is 1412.4146 records/second. Loss is 0.08333282. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038237993270113188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 13440/60000][Iteration 8078][Wall Clock 739.324257132s] Trained 128 records in 0.078463299 seconds. Throughput is 1631.3359 records/second. Loss is 0.20710588. Sequential31006cbd's hyper parameters: Current learning rate is 0.003823506920547526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 13568/60000][Iteration 8079][Wall Clock 739.400930998s] Trained 128 records in 0.076673866 seconds. Throughput is 1669.4084 records/second. Loss is 0.19015594. Sequential31006cbd's hyper parameters: Current learning rate is 0.00382321455880104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:56 INFO  DistriOptimizer$:408 - [Epoch 18 13696/60000][Iteration 8080][Wall Clock 739.481753112s] Trained 128 records in 0.080822114 seconds. Throughput is 1583.7249 records/second. Loss is 0.106809855. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038229222417616024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 13824/60000][Iteration 8081][Wall Clock 739.563435903s] Trained 128 records in 0.081682791 seconds. Throughput is 1567.0375 records/second. Loss is 0.15201491. Sequential31006cbd's hyper parameters: Current learning rate is 0.00382262996941896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 13952/60000][Iteration 8082][Wall Clock 739.642754465s] Trained 128 records in 0.079318562 seconds. Throughput is 1613.7458 records/second. Loss is 0.19332811. Sequential31006cbd's hyper parameters: Current learning rate is 0.003822337741762862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14080/60000][Iteration 8083][Wall Clock 739.720514129s] Trained 128 records in 0.077759664 seconds. Throughput is 1646.0977 records/second. Loss is 0.21892858. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038220455587830607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14208/60000][Iteration 8084][Wall Clock 739.79622633s] Trained 128 records in 0.075712201 seconds. Throughput is 1690.6125 records/second. Loss is 0.10698669. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038217534204693115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14336/60000][Iteration 8085][Wall Clock 739.872145493s] Trained 128 records in 0.075919163 seconds. Throughput is 1686.0038 records/second. Loss is 0.1566479. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038214613268113726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14464/60000][Iteration 8086][Wall Clock 739.956010114s] Trained 128 records in 0.083864621 seconds. Throughput is 1526.2693 records/second. Loss is 0.13761002. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038211692777990066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14592/60000][Iteration 8087][Wall Clock 740.037190852s] Trained 128 records in 0.081180738 seconds. Throughput is 1576.7288 records/second. Loss is 0.10805823. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038208772734219776. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14720/60000][Iteration 8088][Wall Clock 740.117897416s] Trained 128 records in 0.080706564 seconds. Throughput is 1585.9924 records/second. Loss is 0.09177458. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038205853136700544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14848/60000][Iteration 8089][Wall Clock 740.194612292s] Trained 128 records in 0.076714876 seconds. Throughput is 1668.5161 records/second. Loss is 0.10005337. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038202933985330067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 14976/60000][Iteration 8090][Wall Clock 740.275717587s] Trained 128 records in 0.081105295 seconds. Throughput is 1578.1954 records/second. Loss is 0.19276412. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038200015280006115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 15104/60000][Iteration 8091][Wall Clock 740.351855252s] Trained 128 records in 0.076137665 seconds. Throughput is 1681.1654 records/second. Loss is 0.19565389. Sequential31006cbd's hyper parameters: Current learning rate is 0.003819709702062643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 15232/60000][Iteration 8092][Wall Clock 740.432612171s] Trained 128 records in 0.080756919 seconds. Throughput is 1585.0035 records/second. Loss is 0.12096894. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038194179207088844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:57 INFO  DistriOptimizer$:408 - [Epoch 18 15360/60000][Iteration 8093][Wall Clock 740.515526243s] Trained 128 records in 0.082914072 seconds. Throughput is 1543.767 records/second. Loss is 0.09372644. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038191261839291167. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 15488/60000][Iteration 8094][Wall Clock 740.611423591s] Trained 128 records in 0.095897348 seconds. Throughput is 1334.7606 records/second. Loss is 0.16106516. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038188344917131295. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 15616/60000][Iteration 8095][Wall Clock 740.700148427s] Trained 128 records in 0.088724836 seconds. Throughput is 1442.6626 records/second. Loss is 0.2653107. Sequential31006cbd's hyper parameters: Current learning rate is 0.00381854284405071. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 15744/60000][Iteration 8096][Wall Clock 740.785333953s] Trained 128 records in 0.085185526 seconds. Throughput is 1502.6027 records/second. Loss is 0.17107053. Sequential31006cbd's hyper parameters: Current learning rate is 0.003818251240931654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 15872/60000][Iteration 8097][Wall Clock 740.86641258s] Trained 128 records in 0.081078627 seconds. Throughput is 1578.7145 records/second. Loss is 0.14315073. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038179596823457542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16000/60000][Iteration 8098][Wall Clock 740.944090241s] Trained 128 records in 0.077677661 seconds. Throughput is 1647.8354 records/second. Loss is 0.17381983. Sequential31006cbd's hyper parameters: Current learning rate is 0.003817668168282813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16128/60000][Iteration 8099][Wall Clock 741.023803922s] Trained 128 records in 0.079713681 seconds. Throughput is 1605.747 records/second. Loss is 0.12838696. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038173766987326307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16256/60000][Iteration 8100][Wall Clock 741.102757453s] Trained 128 records in 0.078953531 seconds. Throughput is 1621.2067 records/second. Loss is 0.07037538. Sequential31006cbd's hyper parameters: Current learning rate is 0.003817085273685014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16384/60000][Iteration 8101][Wall Clock 741.175998188s] Trained 128 records in 0.073240735 seconds. Throughput is 1747.6614 records/second. Loss is 0.109774634. Sequential31006cbd's hyper parameters: Current learning rate is 0.003816793893129771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16512/60000][Iteration 8102][Wall Clock 741.258668478s] Trained 128 records in 0.08267029 seconds. Throughput is 1548.3193 records/second. Loss is 0.29080945. Sequential31006cbd's hyper parameters: Current learning rate is 0.003816502557056713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16640/60000][Iteration 8103][Wall Clock 741.329470341s] Trained 128 records in 0.070801863 seconds. Throughput is 1807.862 records/second. Loss is 0.12774187. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038162112654556556. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16768/60000][Iteration 8104][Wall Clock 741.402996456s] Trained 128 records in 0.073526115 seconds. Throughput is 1740.878 records/second. Loss is 0.14549643. Sequential31006cbd's hyper parameters: Current learning rate is 0.003815920018316416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:58 INFO  DistriOptimizer$:408 - [Epoch 18 16896/60000][Iteration 8105][Wall Clock 741.477842676s] Trained 128 records in 0.07484622 seconds. Throughput is 1710.1731 records/second. Loss is 0.11777341. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038156288156288155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17024/60000][Iteration 8106][Wall Clock 741.553409746s] Trained 128 records in 0.07556707 seconds. Throughput is 1693.8596 records/second. Loss is 0.07092606. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038153376573826785. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17152/60000][Iteration 8107][Wall Clock 741.638912693s] Trained 128 records in 0.085502947 seconds. Throughput is 1497.0244 records/second. Loss is 0.13513663. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038150465435678317. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17280/60000][Iteration 8108][Wall Clock 741.720281567s] Trained 128 records in 0.081368874 seconds. Throughput is 1573.0831 records/second. Loss is 0.19865659. Sequential31006cbd's hyper parameters: Current learning rate is 0.003814755474174105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17408/60000][Iteration 8109][Wall Clock 741.800721108s] Trained 128 records in 0.080439541 seconds. Throughput is 1591.2573 records/second. Loss is 0.12539583. Sequential31006cbd's hyper parameters: Current learning rate is 0.003814464449191334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17536/60000][Iteration 8110][Wall Clock 741.877367355s] Trained 128 records in 0.076646247 seconds. Throughput is 1670.01 records/second. Loss is 0.11728963. Sequential31006cbd's hyper parameters: Current learning rate is 0.003814173468609352. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17664/60000][Iteration 8111][Wall Clock 741.95635541s] Trained 128 records in 0.078988055 seconds. Throughput is 1620.4983 records/second. Loss is 0.16580202. Sequential31006cbd's hyper parameters: Current learning rate is 0.003813882532418002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17792/60000][Iteration 8112][Wall Clock 742.034996894s] Trained 128 records in 0.078641484 seconds. Throughput is 1627.6398 records/second. Loss is 0.108947664. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038135916406071236. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 17920/60000][Iteration 8113][Wall Clock 742.110589566s] Trained 128 records in 0.075592672 seconds. Throughput is 1693.2858 records/second. Loss is 0.17342985. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038133007931665653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 18048/60000][Iteration 8114][Wall Clock 742.187586953s] Trained 128 records in 0.076997387 seconds. Throughput is 1662.3942 records/second. Loss is 0.20280628. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038130099900861737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 18176/60000][Iteration 8115][Wall Clock 742.269897101s] Trained 128 records in 0.082310148 seconds. Throughput is 1555.0938 records/second. Loss is 0.1209402. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038127192313558034. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 18304/60000][Iteration 8116][Wall Clock 742.348227976s] Trained 128 records in 0.078330875 seconds. Throughput is 1634.0939 records/second. Loss is 0.106868304. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038124285169653066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 18432/60000][Iteration 8117][Wall Clock 742.427496221s] Trained 128 records in 0.079268245 seconds. Throughput is 1614.7701 records/second. Loss is 0.09681597. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038121378469045445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:09:59 INFO  DistriOptimizer$:408 - [Epoch 18 18560/60000][Iteration 8118][Wall Clock 742.501771257s] Trained 128 records in 0.074275036 seconds. Throughput is 1723.3246 records/second. Loss is 0.12781832. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038118472211633755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 18688/60000][Iteration 8119][Wall Clock 742.610715796s] Trained 128 records in 0.108944539 seconds. Throughput is 1174.9097 records/second. Loss is 0.092623785. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038115566397316663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 18816/60000][Iteration 8120][Wall Clock 742.719118054s] Trained 128 records in 0.108402258 seconds. Throughput is 1180.7872 records/second. Loss is 0.11690692. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038112661025992835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 18944/60000][Iteration 8121][Wall Clock 742.797838916s] Trained 128 records in 0.078720862 seconds. Throughput is 1625.9985 records/second. Loss is 0.12927791. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038109756097560975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19072/60000][Iteration 8122][Wall Clock 742.881499426s] Trained 128 records in 0.08366051 seconds. Throughput is 1529.993 records/second. Loss is 0.14154647. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038106851611919824. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19200/60000][Iteration 8123][Wall Clock 742.9671365s] Trained 128 records in 0.085637074 seconds. Throughput is 1494.6797 records/second. Loss is 0.17512412. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038103947568968147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19328/60000][Iteration 8124][Wall Clock 743.061388402s] Trained 128 records in 0.094251902 seconds. Throughput is 1358.0627 records/second. Loss is 0.19728382. Sequential31006cbd's hyper parameters: Current learning rate is 0.003810104396860474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19456/60000][Iteration 8125][Wall Clock 743.14182486s] Trained 128 records in 0.080436458 seconds. Throughput is 1591.3181 records/second. Loss is 0.11836642. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038098140810728437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19584/60000][Iteration 8126][Wall Clock 743.219358566s] Trained 128 records in 0.077533706 seconds. Throughput is 1650.8949 records/second. Loss is 0.17727223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038095238095238095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19712/60000][Iteration 8127][Wall Clock 743.297152055s] Trained 128 records in 0.077793489 seconds. Throughput is 1645.382 records/second. Loss is 0.1722155. Sequential31006cbd's hyper parameters: Current learning rate is 0.003809233582203261. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19840/60000][Iteration 8128][Wall Clock 743.383532689s] Trained 128 records in 0.086380634 seconds. Throughput is 1481.8137 records/second. Loss is 0.1724581. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038089433991010894. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:00 INFO  DistriOptimizer$:408 - [Epoch 18 19968/60000][Iteration 8129][Wall Clock 743.483685237s] Trained 128 records in 0.100152548 seconds. Throughput is 1278.0504 records/second. Loss is 0.1486125. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038086532602071904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20096/60000][Iteration 8130][Wall Clock 743.562244147s] Trained 128 records in 0.07855891 seconds. Throughput is 1629.3506 records/second. Loss is 0.1464603. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038083631655114634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20224/60000][Iteration 8131][Wall Clock 743.644512504s] Trained 128 records in 0.082268357 seconds. Throughput is 1555.8838 records/second. Loss is 0.25298488. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038080731150038076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20352/60000][Iteration 8132][Wall Clock 743.726955107s] Trained 128 records in 0.082442603 seconds. Throughput is 1552.5953 records/second. Loss is 0.22633843. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038077831086741304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20480/60000][Iteration 8133][Wall Clock 743.807080689s] Trained 128 records in 0.080125582 seconds. Throughput is 1597.4922 records/second. Loss is 0.17975174. Sequential31006cbd's hyper parameters: Current learning rate is 0.003807493146512336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20608/60000][Iteration 8134][Wall Clock 743.885988475s] Trained 128 records in 0.078907786 seconds. Throughput is 1622.1466 records/second. Loss is 0.18520822. Sequential31006cbd's hyper parameters: Current learning rate is 0.003807203228508338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20736/60000][Iteration 8135][Wall Clock 743.965433832s] Trained 128 records in 0.079445357 seconds. Throughput is 1611.1704 records/second. Loss is 0.112742305. Sequential31006cbd's hyper parameters: Current learning rate is 0.003806913354652048. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20864/60000][Iteration 8136][Wall Clock 744.046611028s] Trained 128 records in 0.081177196 seconds. Throughput is 1576.7975 records/second. Loss is 0.22496511. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038066235249333844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 20992/60000][Iteration 8137][Wall Clock 744.127789928s] Trained 128 records in 0.0811789 seconds. Throughput is 1576.7643 records/second. Loss is 0.2657732. Sequential31006cbd's hyper parameters: Current learning rate is 0.003806333739342265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 21120/60000][Iteration 8138][Wall Clock 744.205326919s] Trained 128 records in 0.077536991 seconds. Throughput is 1650.825 records/second. Loss is 0.13040385. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038060439978686153. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 21248/60000][Iteration 8139][Wall Clock 744.294967199s] Trained 128 records in 0.08964028 seconds. Throughput is 1427.9294 records/second. Loss is 0.12975198. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038057543005023593. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 21376/60000][Iteration 8140][Wall Clock 744.373268427s] Trained 128 records in 0.078301228 seconds. Throughput is 1634.7125 records/second. Loss is 0.17663105. Sequential31006cbd's hyper parameters: Current learning rate is 0.003805464647233427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:01 INFO  DistriOptimizer$:408 - [Epoch 18 21504/60000][Iteration 8141][Wall Clock 744.452563543s] Trained 128 records in 0.079295116 seconds. Throughput is 1614.223 records/second. Loss is 0.12651339. Sequential31006cbd's hyper parameters: Current learning rate is 0.00380517503805175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 21632/60000][Iteration 8142][Wall Clock 744.530351998s] Trained 128 records in 0.077788455 seconds. Throughput is 1645.4884 records/second. Loss is 0.14169586. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038048854729472643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 21760/60000][Iteration 8143][Wall Clock 744.608850776s] Trained 128 records in 0.078498778 seconds. Throughput is 1630.5986 records/second. Loss is 0.15971498. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038045959519099073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 21888/60000][Iteration 8144][Wall Clock 744.70010721s] Trained 128 records in 0.091256434 seconds. Throughput is 1402.6409 records/second. Loss is 0.17870243. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038043064749296203. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22016/60000][Iteration 8145][Wall Clock 744.785076623s] Trained 128 records in 0.084969413 seconds. Throughput is 1506.4244 records/second. Loss is 0.18997648. Sequential31006cbd's hyper parameters: Current learning rate is 0.003804017041996348. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22144/60000][Iteration 8146][Wall Clock 744.864020455s] Trained 128 records in 0.078943832 seconds. Throughput is 1621.4059 records/second. Loss is 0.22431225. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038037276531000383. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22272/60000][Iteration 8147][Wall Clock 744.948698315s] Trained 128 records in 0.08467786 seconds. Throughput is 1511.6112 records/second. Loss is 0.14674151. Sequential31006cbd's hyper parameters: Current learning rate is 0.003803438308230641. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22400/60000][Iteration 8148][Wall Clock 745.03326315s] Trained 128 records in 0.084564835 seconds. Throughput is 1513.6315 records/second. Loss is 0.18040504. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038031490073781086. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22528/60000][Iteration 8149][Wall Clock 745.113291664s] Trained 128 records in 0.080028514 seconds. Throughput is 1599.4299 records/second. Loss is 0.11167891. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038028597505324006. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22656/60000][Iteration 8150][Wall Clock 745.189267462s] Trained 128 records in 0.075975798 seconds. Throughput is 1684.7471 records/second. Loss is 0.11881631. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038025705376834736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22784/60000][Iteration 8151][Wall Clock 745.265570719s] Trained 128 records in 0.076303257 seconds. Throughput is 1677.5168 records/second. Loss is 0.09296684. Sequential31006cbd's hyper parameters: Current learning rate is 0.003802281368821293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 22912/60000][Iteration 8152][Wall Clock 745.345275887s] Trained 128 records in 0.079705168 seconds. Throughput is 1605.9183 records/second. Loss is 0.20934445. Sequential31006cbd's hyper parameters: Current learning rate is 0.003801992243935822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 23040/60000][Iteration 8153][Wall Clock 745.426035984s] Trained 128 records in 0.080760097 seconds. Throughput is 1584.941 records/second. Loss is 0.24928254. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038017031630170318. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:02 INFO  DistriOptimizer$:408 - [Epoch 18 23168/60000][Iteration 8154][Wall Clock 745.510480848s] Trained 128 records in 0.084444864 seconds. Throughput is 1515.7819 records/second. Loss is 0.13485594. Sequential31006cbd's hyper parameters: Current learning rate is 0.003801414126054892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 23296/60000][Iteration 8155][Wall Clock 745.583361159s] Trained 128 records in 0.072880311 seconds. Throughput is 1756.3042 records/second. Loss is 0.18731678. Sequential31006cbd's hyper parameters: Current learning rate is 0.00380112513303938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 23424/60000][Iteration 8156][Wall Clock 745.659607115s] Trained 128 records in 0.076245956 seconds. Throughput is 1678.7776 records/second. Loss is 0.12470518. Sequential31006cbd's hyper parameters: Current learning rate is 0.003800836183960471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 23552/60000][Iteration 8157][Wall Clock 745.740296376s] Trained 128 records in 0.080689261 seconds. Throughput is 1586.3325 records/second. Loss is 0.10937857. Sequential31006cbd's hyper parameters: Current learning rate is 0.003800547278808149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 23680/60000][Iteration 8158][Wall Clock 745.820005474s] Trained 128 records in 0.079709098 seconds. Throughput is 1605.8392 records/second. Loss is 0.13509545. Sequential31006cbd's hyper parameters: Current learning rate is 0.0038002584175723946. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 23808/60000][Iteration 8159][Wall Clock 745.899868786s] Trained 128 records in 0.079863312 seconds. Throughput is 1602.7385 records/second. Loss is 0.27171457. Sequential31006cbd's hyper parameters: Current learning rate is 0.003799969600243198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 23936/60000][Iteration 8160][Wall Clock 745.983304949s] Trained 128 records in 0.083436163 seconds. Throughput is 1534.107 records/second. Loss is 0.11741471. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037996808268105477. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 24064/60000][Iteration 8161][Wall Clock 746.068515296s] Trained 128 records in 0.085210347 seconds. Throughput is 1502.165 records/second. Loss is 0.062318455. Sequential31006cbd's hyper parameters: Current learning rate is 0.003799392097264438. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 24192/60000][Iteration 8162][Wall Clock 746.15286721s] Trained 128 records in 0.084351914 seconds. Throughput is 1517.4523 records/second. Loss is 0.2541804. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037991034115948635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 24320/60000][Iteration 8163][Wall Clock 746.233601657s] Trained 128 records in 0.080734447 seconds. Throughput is 1585.4447 records/second. Loss is 0.28080517. Sequential31006cbd's hyper parameters: Current learning rate is 0.003798814769791825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 24448/60000][Iteration 8164][Wall Clock 746.315441065s] Trained 128 records in 0.081839408 seconds. Throughput is 1564.0387 records/second. Loss is 0.16360939. Sequential31006cbd's hyper parameters: Current learning rate is 0.003798526171845324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 24576/60000][Iteration 8165][Wall Clock 746.393586244s] Trained 128 records in 0.078145179 seconds. Throughput is 1637.9769 records/second. Loss is 0.09487645. Sequential31006cbd's hyper parameters: Current learning rate is 0.003798237617745366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:03 INFO  DistriOptimizer$:408 - [Epoch 18 24704/60000][Iteration 8166][Wall Clock 746.473268382s] Trained 128 records in 0.079682138 seconds. Throughput is 1606.3826 records/second. Loss is 0.13091552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037979491074819596. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 24832/60000][Iteration 8167][Wall Clock 746.553039517s] Trained 128 records in 0.079771135 seconds. Throughput is 1604.5905 records/second. Loss is 0.16234654. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037976606410451163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 24960/60000][Iteration 8168][Wall Clock 746.639645175s] Trained 128 records in 0.086605658 seconds. Throughput is 1477.9634 records/second. Loss is 0.12818807. Sequential31006cbd's hyper parameters: Current learning rate is 0.00379737221842485. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25088/60000][Iteration 8169][Wall Clock 746.744851864s] Trained 128 records in 0.105206689 seconds. Throughput is 1216.6527 records/second. Loss is 0.19470952. Sequential31006cbd's hyper parameters: Current learning rate is 0.003797083839611178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25216/60000][Iteration 8170][Wall Clock 746.826334874s] Trained 128 records in 0.08148301 seconds. Throughput is 1570.8796 records/second. Loss is 0.16170685. Sequential31006cbd's hyper parameters: Current learning rate is 0.003796795504594123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25344/60000][Iteration 8171][Wall Clock 746.907442094s] Trained 128 records in 0.08110722 seconds. Throughput is 1578.1578 records/second. Loss is 0.1340927. Sequential31006cbd's hyper parameters: Current learning rate is 0.003796507213363705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25472/60000][Iteration 8172][Wall Clock 746.982322788s] Trained 128 records in 0.074880694 seconds. Throughput is 1709.3857 records/second. Loss is 0.08754923. Sequential31006cbd's hyper parameters: Current learning rate is 0.003796218965909954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25600/60000][Iteration 8173][Wall Clock 747.059882843s] Trained 128 records in 0.077560055 seconds. Throughput is 1650.3341 records/second. Loss is 0.12683749. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037959307622228967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25728/60000][Iteration 8174][Wall Clock 747.135177202s] Trained 128 records in 0.075294359 seconds. Throughput is 1699.9945 records/second. Loss is 0.22027776. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037956426022925684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25856/60000][Iteration 8175][Wall Clock 747.211454708s] Trained 128 records in 0.076277506 seconds. Throughput is 1678.0831 records/second. Loss is 0.19084786. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037953544861090024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 25984/60000][Iteration 8176][Wall Clock 747.285089893s] Trained 128 records in 0.073635185 seconds. Throughput is 1738.2994 records/second. Loss is 0.14886777. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037950664136622396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 26112/60000][Iteration 8177][Wall Clock 747.360192547s] Trained 128 records in 0.075102654 seconds. Throughput is 1704.3339 records/second. Loss is 0.10038304. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037947783849423193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:04 INFO  DistriOptimizer$:408 - [Epoch 18 26240/60000][Iteration 8178][Wall Clock 747.439328476s] Trained 128 records in 0.079135929 seconds. Throughput is 1617.4701 records/second. Loss is 0.14355463. Sequential31006cbd's hyper parameters: Current learning rate is 0.003794490399939288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 26368/60000][Iteration 8179][Wall Clock 747.517916557s] Trained 128 records in 0.078588081 seconds. Throughput is 1628.7456 records/second. Loss is 0.09566803. Sequential31006cbd's hyper parameters: Current learning rate is 0.003794202458643193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 26496/60000][Iteration 8180][Wall Clock 747.609922966s] Trained 128 records in 0.092006409 seconds. Throughput is 1391.2074 records/second. Loss is 0.19237506. Sequential31006cbd's hyper parameters: Current learning rate is 0.003793914561044085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 26624/60000][Iteration 8181][Wall Clock 747.685307736s] Trained 128 records in 0.07538477 seconds. Throughput is 1697.9556 records/second. Loss is 0.13288313. Sequential31006cbd's hyper parameters: Current learning rate is 0.003793626707132018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 26752/60000][Iteration 8182][Wall Clock 747.787400214s] Trained 128 records in 0.102092478 seconds. Throughput is 1253.7653 records/second. Loss is 0.26083368. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037933388968970486. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 26880/60000][Iteration 8183][Wall Clock 747.870070064s] Trained 128 records in 0.08266985 seconds. Throughput is 1548.3275 records/second. Loss is 0.18190522. Sequential31006cbd's hyper parameters: Current learning rate is 0.003793051130329237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27008/60000][Iteration 8184][Wall Clock 747.963612601s] Trained 128 records in 0.093542537 seconds. Throughput is 1368.3615 records/second. Loss is 0.17187643. Sequential31006cbd's hyper parameters: Current learning rate is 0.003792763407418645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27136/60000][Iteration 8185][Wall Clock 748.040249738s] Trained 128 records in 0.076637137 seconds. Throughput is 1670.2086 records/second. Loss is 0.22021663. Sequential31006cbd's hyper parameters: Current learning rate is 0.00379247572815534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27264/60000][Iteration 8186][Wall Clock 748.119260817s] Trained 128 records in 0.079011079 seconds. Throughput is 1620.0259 records/second. Loss is 0.08827227. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037921880925293897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27392/60000][Iteration 8187][Wall Clock 748.20326996s] Trained 128 records in 0.084009143 seconds. Throughput is 1523.6437 records/second. Loss is 0.14610912. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037919005005308663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27520/60000][Iteration 8188][Wall Clock 748.280783225s] Trained 128 records in 0.077513265 seconds. Throughput is 1651.3303 records/second. Loss is 0.12887034. Sequential31006cbd's hyper parameters: Current learning rate is 0.003791612952149844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27648/60000][Iteration 8189][Wall Clock 748.354683747s] Trained 128 records in 0.073900522 seconds. Throughput is 1732.0581 records/second. Loss is 0.13394292. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037913254473764028. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27776/60000][Iteration 8190][Wall Clock 748.431652345s] Trained 128 records in 0.076968598 seconds. Throughput is 1663.0159 records/second. Loss is 0.17808926. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037910379862006213. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:05 INFO  DistriOptimizer$:408 - [Epoch 18 27904/60000][Iteration 8191][Wall Clock 748.510809155s] Trained 128 records in 0.07915681 seconds. Throughput is 1617.0435 records/second. Loss is 0.13011406. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037907505686125857. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28032/60000][Iteration 8192][Wall Clock 748.591189505s] Trained 128 records in 0.08038035 seconds. Throughput is 1592.429 records/second. Loss is 0.10956739. Sequential31006cbd's hyper parameters: Current learning rate is 0.00379046319460238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28160/60000][Iteration 8193][Wall Clock 748.677737353s] Trained 128 records in 0.086547848 seconds. Throughput is 1478.9507 records/second. Loss is 0.11707105. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037901758641600974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28288/60000][Iteration 8194][Wall Clock 748.783220515s] Trained 128 records in 0.105483162 seconds. Throughput is 1213.4639 records/second. Loss is 0.14920157. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037898885772758278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28416/60000][Iteration 8195][Wall Clock 748.867011899s] Trained 128 records in 0.083791384 seconds. Throughput is 1527.6034 records/second. Loss is 0.17588568. Sequential31006cbd's hyper parameters: Current learning rate is 0.00378960133393967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28544/60000][Iteration 8196][Wall Clock 748.942925003s] Trained 128 records in 0.075913104 seconds. Throughput is 1686.1384 records/second. Loss is 0.24250287. Sequential31006cbd's hyper parameters: Current learning rate is 0.00378931413414172. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28672/60000][Iteration 8197][Wall Clock 749.018201845s] Trained 128 records in 0.075276842 seconds. Throughput is 1700.3901 records/second. Loss is 0.16888928. Sequential31006cbd's hyper parameters: Current learning rate is 0.003789026977872083. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28800/60000][Iteration 8198][Wall Clock 749.092598724s] Trained 128 records in 0.074396879 seconds. Throughput is 1720.5023 records/second. Loss is 0.18196905. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037887398651208605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 28928/60000][Iteration 8199][Wall Clock 749.165644018s] Trained 128 records in 0.073045294 seconds. Throughput is 1752.3375 records/second. Loss is 0.118840046. Sequential31006cbd's hyper parameters: Current learning rate is 0.003788452795878163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 29056/60000][Iteration 8200][Wall Clock 749.249948976s] Trained 128 records in 0.084304958 seconds. Throughput is 1518.2974 records/second. Loss is 0.13719551. Sequential31006cbd's hyper parameters: Current learning rate is 0.003788165770134101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 29184/60000][Iteration 8201][Wall Clock 749.325233924s] Trained 128 records in 0.075284948 seconds. Throughput is 1700.207 records/second. Loss is 0.10574173. Sequential31006cbd's hyper parameters: Current learning rate is 0.003787878787878788. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 29312/60000][Iteration 8202][Wall Clock 749.417379598s] Trained 128 records in 0.092145674 seconds. Throughput is 1389.1049 records/second. Loss is 0.20977445. Sequential31006cbd's hyper parameters: Current learning rate is 0.003787591849102341. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:06 INFO  DistriOptimizer$:408 - [Epoch 18 29440/60000][Iteration 8203][Wall Clock 749.500775145s] Trained 128 records in 0.083395547 seconds. Throughput is 1534.8541 records/second. Loss is 0.10776074. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037873049537948795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 29568/60000][Iteration 8204][Wall Clock 749.583445079s] Trained 128 records in 0.082669934 seconds. Throughput is 1548.3258 records/second. Loss is 0.15737347. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037870181019465272. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 29696/60000][Iteration 8205][Wall Clock 749.659580854s] Trained 128 records in 0.076135775 seconds. Throughput is 1681.207 records/second. Loss is 0.24187484. Sequential31006cbd's hyper parameters: Current learning rate is 0.00378673129354741. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 29824/60000][Iteration 8206][Wall Clock 749.754708292s] Trained 128 records in 0.095127438 seconds. Throughput is 1345.5634 records/second. Loss is 0.13321531. Sequential31006cbd's hyper parameters: Current learning rate is 0.003786444528587656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 29952/60000][Iteration 8207][Wall Clock 749.859396622s] Trained 128 records in 0.10468833 seconds. Throughput is 1222.6769 records/second. Loss is 0.23378329. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037861578070573984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30080/60000][Iteration 8208][Wall Clock 749.943323914s] Trained 128 records in 0.083927292 seconds. Throughput is 1525.1296 records/second. Loss is 0.16654171. Sequential31006cbd's hyper parameters: Current learning rate is 0.003785871128946771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30208/60000][Iteration 8209][Wall Clock 750.028131244s] Trained 128 records in 0.08480733 seconds. Throughput is 1509.3035 records/second. Loss is 0.26635438. Sequential31006cbd's hyper parameters: Current learning rate is 0.003785584494245911. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30336/60000][Iteration 8210][Wall Clock 750.102313358s] Trained 128 records in 0.074182114 seconds. Throughput is 1725.4833 records/second. Loss is 0.10790767. Sequential31006cbd's hyper parameters: Current learning rate is 0.003785297902944962. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30464/60000][Iteration 8211][Wall Clock 750.193212608s] Trained 128 records in 0.09089925 seconds. Throughput is 1408.1525 records/second. Loss is 0.1247039. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037850113550340647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30592/60000][Iteration 8212][Wall Clock 750.270718416s] Trained 128 records in 0.077505808 seconds. Throughput is 1651.4893 records/second. Loss is 0.22069436. Sequential31006cbd's hyper parameters: Current learning rate is 0.003784724850503369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30720/60000][Iteration 8213][Wall Clock 750.377577006s] Trained 128 records in 0.10685859 seconds. Throughput is 1197.8447 records/second. Loss is 0.17437749. Sequential31006cbd's hyper parameters: Current learning rate is 0.003784438389343021. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:07 INFO  DistriOptimizer$:408 - [Epoch 18 30848/60000][Iteration 8214][Wall Clock 750.458432145s] Trained 128 records in 0.080855139 seconds. Throughput is 1583.0781 records/second. Loss is 0.13040896. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037841519715431774. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 30976/60000][Iteration 8215][Wall Clock 750.537898903s] Trained 128 records in 0.079466758 seconds. Throughput is 1610.7363 records/second. Loss is 0.10559995. Sequential31006cbd's hyper parameters: Current learning rate is 0.003783865597093991. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31104/60000][Iteration 8216][Wall Clock 750.621158343s] Trained 128 records in 0.08325944 seconds. Throughput is 1537.3632 records/second. Loss is 0.07926577. Sequential31006cbd's hyper parameters: Current learning rate is 0.003783579265985623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31232/60000][Iteration 8217][Wall Clock 750.70239892s] Trained 128 records in 0.081240577 seconds. Throughput is 1575.5673 records/second. Loss is 0.19957568. Sequential31006cbd's hyper parameters: Current learning rate is 0.003783292978208232. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31360/60000][Iteration 8218][Wall Clock 750.785192478s] Trained 128 records in 0.082793558 seconds. Throughput is 1546.014 records/second. Loss is 0.1287021. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037830067337519865. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31488/60000][Iteration 8219][Wall Clock 750.884191303s] Trained 128 records in 0.098998825 seconds. Throughput is 1292.9447 records/second. Loss is 0.12522186. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037827205326070507. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31616/60000][Iteration 8220][Wall Clock 750.960323619s] Trained 128 records in 0.076132316 seconds. Throughput is 1681.2834 records/second. Loss is 0.17993492. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037824343747635976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31744/60000][Iteration 8221][Wall Clock 751.044349629s] Trained 128 records in 0.08402601 seconds. Throughput is 1523.3379 records/second. Loss is 0.1252533. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037821482602118004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 31872/60000][Iteration 8222][Wall Clock 751.120586217s] Trained 128 records in 0.076236588 seconds. Throughput is 1678.9838 records/second. Loss is 0.17342383. Sequential31006cbd's hyper parameters: Current learning rate is 0.003781862188941835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 32000/60000][Iteration 8223][Wall Clock 751.203227006s] Trained 128 records in 0.082640789 seconds. Throughput is 1548.872 records/second. Loss is 0.3004521. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037815761609438815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 32128/60000][Iteration 8224][Wall Clock 751.288306537s] Trained 128 records in 0.085079531 seconds. Throughput is 1504.4747 records/second. Loss is 0.18260309. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037812901762081224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 32256/60000][Iteration 8225][Wall Clock 751.36638376s] Trained 128 records in 0.078077223 seconds. Throughput is 1639.4026 records/second. Loss is 0.18162552. Sequential31006cbd's hyper parameters: Current learning rate is 0.003781004234724743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:08 INFO  DistriOptimizer$:408 - [Epoch 18 32384/60000][Iteration 8226][Wall Clock 751.456800467s] Trained 128 records in 0.090416707 seconds. Throughput is 1415.6676 records/second. Loss is 0.12175555. Sequential31006cbd's hyper parameters: Current learning rate is 0.003780718336483932. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 32512/60000][Iteration 8227][Wall Clock 751.553523425s] Trained 128 records in 0.096722958 seconds. Throughput is 1323.3673 records/second. Loss is 0.07624251. Sequential31006cbd's hyper parameters: Current learning rate is 0.003780432481475881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 32640/60000][Iteration 8228][Wall Clock 751.670743897s] Trained 128 records in 0.117220472 seconds. Throughput is 1091.9595 records/second. Loss is 0.19529283. Sequential31006cbd's hyper parameters: Current learning rate is 0.003780146669690784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 32768/60000][Iteration 8229][Wall Clock 751.785575628s] Trained 128 records in 0.114831731 seconds. Throughput is 1114.6744 records/second. Loss is 0.15956743. Sequential31006cbd's hyper parameters: Current learning rate is 0.003779860901118839. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 32896/60000][Iteration 8230][Wall Clock 751.886745512s] Trained 128 records in 0.101169884 seconds. Throughput is 1265.1986 records/second. Loss is 0.14040098. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037795751757502454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33024/60000][Iteration 8231][Wall Clock 751.965194311s] Trained 128 records in 0.078448799 seconds. Throughput is 1631.6375 records/second. Loss is 0.1882475. Sequential31006cbd's hyper parameters: Current learning rate is 0.003779289493575208. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33152/60000][Iteration 8232][Wall Clock 752.081152338s] Trained 128 records in 0.115958027 seconds. Throughput is 1103.8477 records/second. Loss is 0.12229723. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037790038545839314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33280/60000][Iteration 8233][Wall Clock 752.164622173s] Trained 128 records in 0.083469835 seconds. Throughput is 1533.488 records/second. Loss is 0.11911081. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037787182587666265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33408/60000][Iteration 8234][Wall Clock 752.250173992s] Trained 128 records in 0.085551819 seconds. Throughput is 1496.1692 records/second. Loss is 0.17344944. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037784327061135036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33536/60000][Iteration 8235][Wall Clock 752.3316229s] Trained 128 records in 0.081448908 seconds. Throughput is 1571.5374 records/second. Loss is 0.14326857. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037781471966147804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33664/60000][Iteration 8236][Wall Clock 752.407760181s] Trained 128 records in 0.076137281 seconds. Throughput is 1681.1737 records/second. Loss is 0.12712967. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037778617302606722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:09 INFO  DistriOptimizer$:408 - [Epoch 18 33792/60000][Iteration 8237][Wall Clock 752.486520586s] Trained 128 records in 0.078760405 seconds. Throughput is 1625.182 records/second. Loss is 0.19677806. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037775763070414027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 33920/60000][Iteration 8238][Wall Clock 752.575556274s] Trained 128 records in 0.089035688 seconds. Throughput is 1437.6257 records/second. Loss is 0.17395143. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037772909269471935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34048/60000][Iteration 8239][Wall Clock 752.675449829s] Trained 128 records in 0.099893555 seconds. Throughput is 1281.3639 records/second. Loss is 0.1825844. Sequential31006cbd's hyper parameters: Current learning rate is 0.003777005589968273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34176/60000][Iteration 8240][Wall Clock 752.753310512s] Trained 128 records in 0.077860683 seconds. Throughput is 1643.9619 records/second. Loss is 0.17423302. Sequential31006cbd's hyper parameters: Current learning rate is 0.003776720296094871. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34304/60000][Iteration 8241][Wall Clock 752.839208714s] Trained 128 records in 0.085898202 seconds. Throughput is 1490.1359 records/second. Loss is 0.15489483. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037764350453172203. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34432/60000][Iteration 8242][Wall Clock 752.918908201s] Trained 128 records in 0.079699487 seconds. Throughput is 1606.033 records/second. Loss is 0.120777756. Sequential31006cbd's hyper parameters: Current learning rate is 0.003776149837625557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34560/60000][Iteration 8243][Wall Clock 752.998393862s] Trained 128 records in 0.079485661 seconds. Throughput is 1610.3533 records/second. Loss is 0.1585519. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037758646730101193. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34688/60000][Iteration 8244][Wall Clock 753.105766215s] Trained 128 records in 0.107372353 seconds. Throughput is 1192.1133 records/second. Loss is 0.14337493. Sequential31006cbd's hyper parameters: Current learning rate is 0.003775579551461149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34816/60000][Iteration 8245][Wall Clock 753.205286375s] Trained 128 records in 0.09952016 seconds. Throughput is 1286.1715 records/second. Loss is 0.11180392. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037752944729688917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 34944/60000][Iteration 8246][Wall Clock 753.287167721s] Trained 128 records in 0.081881346 seconds. Throughput is 1563.2377 records/second. Loss is 0.10424532. Sequential31006cbd's hyper parameters: Current learning rate is 0.003775009437523594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 35072/60000][Iteration 8247][Wall Clock 753.39170533s] Trained 128 records in 0.104537609 seconds. Throughput is 1224.4397 records/second. Loss is 0.14121294. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037747244451155067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:10 INFO  DistriOptimizer$:408 - [Epoch 18 35200/60000][Iteration 8248][Wall Clock 753.488799616s] Trained 128 records in 0.097094286 seconds. Throughput is 1318.3063 records/second. Loss is 0.11935467. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037744394957348834. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 35328/60000][Iteration 8249][Wall Clock 753.572796953s] Trained 128 records in 0.083997337 seconds. Throughput is 1523.8578 records/second. Loss is 0.18614954. Sequential31006cbd's hyper parameters: Current learning rate is 0.00377415458937198. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 35456/60000][Iteration 8250][Wall Clock 753.665233811s] Trained 128 records in 0.092436858 seconds. Throughput is 1384.729 records/second. Loss is 0.10366207. Sequential31006cbd's hyper parameters: Current learning rate is 0.003773869726017058. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 35584/60000][Iteration 8251][Wall Clock 753.755034065s] Trained 128 records in 0.089800254 seconds. Throughput is 1425.3857 records/second. Loss is 0.15241817. Sequential31006cbd's hyper parameters: Current learning rate is 0.003773584905660377. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 35712/60000][Iteration 8252][Wall Clock 753.83277764s] Trained 128 records in 0.077743575 seconds. Throughput is 1646.4384 records/second. Loss is 0.10140698. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037733001282922044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 35840/60000][Iteration 8253][Wall Clock 753.944521735s] Trained 128 records in 0.111744095 seconds. Throughput is 1145.4744 records/second. Loss is 0.23415951. Sequential31006cbd's hyper parameters: Current learning rate is 0.003773015393902807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 35968/60000][Iteration 8254][Wall Clock 754.05114425s] Trained 128 records in 0.106622515 seconds. Throughput is 1200.497 records/second. Loss is 0.15007445. Sequential31006cbd's hyper parameters: Current learning rate is 0.003772730702482457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 36096/60000][Iteration 8255][Wall Clock 754.138744231s] Trained 128 records in 0.087599981 seconds. Throughput is 1461.1876 records/second. Loss is 0.18180957. Sequential31006cbd's hyper parameters: Current learning rate is 0.003772446054021427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 36224/60000][Iteration 8256][Wall Clock 754.226172617s] Trained 128 records in 0.087428386 seconds. Throughput is 1464.0554 records/second. Loss is 0.14210597. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037721614485099965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 36352/60000][Iteration 8257][Wall Clock 754.32299771s] Trained 128 records in 0.096825093 seconds. Throughput is 1321.9713 records/second. Loss is 0.15592766. Sequential31006cbd's hyper parameters: Current learning rate is 0.003771876885938443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:11 INFO  DistriOptimizer$:408 - [Epoch 18 36480/60000][Iteration 8258][Wall Clock 754.413475578s] Trained 128 records in 0.090477868 seconds. Throughput is 1414.7106 records/second. Loss is 0.15468492. Sequential31006cbd's hyper parameters: Current learning rate is 0.003771592366297051. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 36608/60000][Iteration 8259][Wall Clock 754.499761261s] Trained 128 records in 0.086285683 seconds. Throughput is 1483.4443 records/second. Loss is 0.14223225. Sequential31006cbd's hyper parameters: Current learning rate is 0.003771307889576105. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 36736/60000][Iteration 8260][Wall Clock 754.579717439s] Trained 128 records in 0.079956178 seconds. Throughput is 1600.8768 records/second. Loss is 0.17608304. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037710234557658947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 36864/60000][Iteration 8261][Wall Clock 754.658071121s] Trained 128 records in 0.078353682 seconds. Throughput is 1633.6182 records/second. Loss is 0.13538283. Sequential31006cbd's hyper parameters: Current learning rate is 0.003770739064856712. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 36992/60000][Iteration 8262][Wall Clock 754.737219263s] Trained 128 records in 0.079148142 seconds. Throughput is 1617.2205 records/second. Loss is 0.20291409. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037704547168388508. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37120/60000][Iteration 8263][Wall Clock 754.809721313s] Trained 128 records in 0.07250205 seconds. Throughput is 1765.4674 records/second. Loss is 0.17821215. Sequential31006cbd's hyper parameters: Current learning rate is 0.003770170411702609. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37248/60000][Iteration 8264][Wall Clock 754.896833653s] Trained 128 records in 0.08711234 seconds. Throughput is 1469.3671 records/second. Loss is 0.1594244. Sequential31006cbd's hyper parameters: Current learning rate is 0.003769886149438287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37376/60000][Iteration 8265][Wall Clock 755.007849033s] Trained 128 records in 0.11101538 seconds. Throughput is 1152.9934 records/second. Loss is 0.17945835. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037696019300361883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37504/60000][Iteration 8266][Wall Clock 755.125865518s] Trained 128 records in 0.118016485 seconds. Throughput is 1084.5942 records/second. Loss is 0.14703974. Sequential31006cbd's hyper parameters: Current learning rate is 0.003769317753486619. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37632/60000][Iteration 8267][Wall Clock 755.218842511s] Trained 128 records in 0.092976993 seconds. Throughput is 1376.6847 records/second. Loss is 0.1291109. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037690336197798886. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37760/60000][Iteration 8268][Wall Clock 755.297685461s] Trained 128 records in 0.07884295 seconds. Throughput is 1623.4806 records/second. Loss is 0.1762925. Sequential31006cbd's hyper parameters: Current learning rate is 0.003768749528906309. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 37888/60000][Iteration 8269][Wall Clock 755.390369951s] Trained 128 records in 0.09268449 seconds. Throughput is 1381.0293 records/second. Loss is 0.14882672. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037684654808561955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:12 INFO  DistriOptimizer$:408 - [Epoch 18 38016/60000][Iteration 8270][Wall Clock 755.470613927s] Trained 128 records in 0.080243976 seconds. Throughput is 1595.1354 records/second. Loss is 0.1243284. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037681814756198653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38144/60000][Iteration 8271][Wall Clock 755.548018364s] Trained 128 records in 0.077404437 seconds. Throughput is 1653.652 records/second. Loss is 0.14740773. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037678975131876413. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38272/60000][Iteration 8272][Wall Clock 755.628793694s] Trained 128 records in 0.08077533 seconds. Throughput is 1584.6423 records/second. Loss is 0.04568509. Sequential31006cbd's hyper parameters: Current learning rate is 0.003767613593549845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38400/60000][Iteration 8273][Wall Clock 755.715176766s] Trained 128 records in 0.086383072 seconds. Throughput is 1481.7717 records/second. Loss is 0.10291166. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037673297166968055. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38528/60000][Iteration 8274][Wall Clock 755.7936185s] Trained 128 records in 0.078441734 seconds. Throughput is 1631.7844 records/second. Loss is 0.23361598. Sequential31006cbd's hyper parameters: Current learning rate is 0.00376704588261885. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38656/60000][Iteration 8275][Wall Clock 755.868695519s] Trained 128 records in 0.075077019 seconds. Throughput is 1704.9159 records/second. Loss is 0.16401355. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037667620913063135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38784/60000][Iteration 8276][Wall Clock 755.947238873s] Trained 128 records in 0.078543354 seconds. Throughput is 1629.6731 records/second. Loss is 0.11598891. Sequential31006cbd's hyper parameters: Current learning rate is 0.003766478342749529. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 38912/60000][Iteration 8277][Wall Clock 756.032571866s] Trained 128 records in 0.085332993 seconds. Throughput is 1500.006 records/second. Loss is 0.19705757. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037661946369388372. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 39040/60000][Iteration 8278][Wall Clock 756.120346241s] Trained 128 records in 0.087774375 seconds. Throughput is 1458.2844 records/second. Loss is 0.13223472. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037659109738645774. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 39168/60000][Iteration 8279][Wall Clock 756.204864914s] Trained 128 records in 0.084518673 seconds. Throughput is 1514.4583 records/second. Loss is 0.1252713. Sequential31006cbd's hyper parameters: Current learning rate is 0.003765627353517096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 39296/60000][Iteration 8280][Wall Clock 756.284091448s] Trained 128 records in 0.079226534 seconds. Throughput is 1615.6204 records/second. Loss is 0.15004343. Sequential31006cbd's hyper parameters: Current learning rate is 0.003765343775886738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 39424/60000][Iteration 8281][Wall Clock 756.363366025s] Trained 128 records in 0.079274577 seconds. Throughput is 1614.6411 records/second. Loss is 0.12359571. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037650602409638554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:13 INFO  DistriOptimizer$:408 - [Epoch 18 39552/60000][Iteration 8282][Wall Clock 756.470943772s] Trained 128 records in 0.107577747 seconds. Throughput is 1189.8372 records/second. Loss is 0.13327429. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037647767487387998. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 39680/60000][Iteration 8283][Wall Clock 756.586797115s] Trained 128 records in 0.115853343 seconds. Throughput is 1104.8451 records/second. Loss is 0.10302575. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037644932992019274. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 39808/60000][Iteration 8284][Wall Clock 756.702764526s] Trained 128 records in 0.115967411 seconds. Throughput is 1103.7584 records/second. Loss is 0.29115242. Sequential31006cbd's hyper parameters: Current learning rate is 0.003764209892343597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 39936/60000][Iteration 8285][Wall Clock 756.800899074s] Trained 128 records in 0.098134548 seconds. Throughput is 1304.3317 records/second. Loss is 0.14268495. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037639265281541705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40064/60000][Iteration 8286][Wall Clock 756.88007237s] Trained 128 records in 0.079173296 seconds. Throughput is 1616.7067 records/second. Loss is 0.12209868. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037636432066240123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40192/60000][Iteration 8287][Wall Clock 756.956170077s] Trained 128 records in 0.076097707 seconds. Throughput is 1682.0481 records/second. Loss is 0.1761075. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037633599277434896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40320/60000][Iteration 8288][Wall Clock 757.046244167s] Trained 128 records in 0.09007409 seconds. Throughput is 1421.0524 records/second. Loss is 0.14089334. Sequential31006cbd's hyper parameters: Current learning rate is 0.003763076691502973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40448/60000][Iteration 8289][Wall Clock 757.125952444s] Trained 128 records in 0.079708277 seconds. Throughput is 1605.8558 records/second. Loss is 0.19316325. Sequential31006cbd's hyper parameters: Current learning rate is 0.003762793497892835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40576/60000][Iteration 8290][Wall Clock 757.210268105s] Trained 128 records in 0.084315661 seconds. Throughput is 1518.1047 records/second. Loss is 0.16623935. Sequential31006cbd's hyper parameters: Current learning rate is 0.003762510346903454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40704/60000][Iteration 8291][Wall Clock 757.288106003s] Trained 128 records in 0.077837898 seconds. Throughput is 1644.4431 records/second. Loss is 0.23224384. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037622272385252065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40832/60000][Iteration 8292][Wall Clock 757.367680056s] Trained 128 records in 0.079574053 seconds. Throughput is 1608.5645 records/second. Loss is 0.12349391. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037619441727484767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:14 INFO  DistriOptimizer$:408 - [Epoch 18 40960/60000][Iteration 8293][Wall Clock 757.456745194s] Trained 128 records in 0.089065138 seconds. Throughput is 1437.1505 records/second. Loss is 0.18717858. Sequential31006cbd's hyper parameters: Current learning rate is 0.003761661149563647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41088/60000][Iteration 8294][Wall Clock 757.539399395s] Trained 128 records in 0.082654201 seconds. Throughput is 1548.6206 records/second. Loss is 0.08393674. Sequential31006cbd's hyper parameters: Current learning rate is 0.003761378168961108. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41216/60000][Iteration 8295][Wall Clock 757.614471865s] Trained 128 records in 0.07507247 seconds. Throughput is 1705.0192 records/second. Loss is 0.11917893. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037610952309312467. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41344/60000][Iteration 8296][Wall Clock 757.711119185s] Trained 128 records in 0.09664732 seconds. Throughput is 1324.403 records/second. Loss is 0.14844313. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037608123354644606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41472/60000][Iteration 8297][Wall Clock 757.797983079s] Trained 128 records in 0.086863894 seconds. Throughput is 1473.5697 records/second. Loss is 0.23361278. Sequential31006cbd's hyper parameters: Current learning rate is 0.003760529482551143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41600/60000][Iteration 8298][Wall Clock 757.870654297s] Trained 128 records in 0.072671218 seconds. Throughput is 1761.3575 records/second. Loss is 0.10021177. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037602466721816954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41728/60000][Iteration 8299][Wall Clock 757.952070064s] Trained 128 records in 0.081415767 seconds. Throughput is 1572.1771 records/second. Loss is 0.1332016. Sequential31006cbd's hyper parameters: Current learning rate is 0.003759963904346518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41856/60000][Iteration 8300][Wall Clock 758.042703474s] Trained 128 records in 0.09063341 seconds. Throughput is 1412.2828 records/second. Loss is 0.06624028. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037596811790360177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 41984/60000][Iteration 8301][Wall Clock 758.128768997s] Trained 128 records in 0.086065523 seconds. Throughput is 1487.239 records/second. Loss is 0.20145528. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037593984962406013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 42112/60000][Iteration 8302][Wall Clock 758.220921232s] Trained 128 records in 0.092152235 seconds. Throughput is 1389.0059 records/second. Loss is 0.10893299. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037591158559506805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 42240/60000][Iteration 8303][Wall Clock 758.297670844s] Trained 128 records in 0.076749612 seconds. Throughput is 1667.7607 records/second. Loss is 0.20910746. Sequential31006cbd's hyper parameters: Current learning rate is 0.003758833258156668. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 42368/60000][Iteration 8304][Wall Clock 758.374980659s] Trained 128 records in 0.077309815 seconds. Throughput is 1655.6759 records/second. Loss is 0.15002112. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037585507028489815. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:15 INFO  DistriOptimizer$:408 - [Epoch 18 42496/60000][Iteration 8305][Wall Clock 758.450147099s] Trained 128 records in 0.07516644 seconds. Throughput is 1702.8876 records/second. Loss is 0.17312759. Sequential31006cbd's hyper parameters: Current learning rate is 0.00375826819001804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 42624/60000][Iteration 8306][Wall Clock 758.528631012s] Trained 128 records in 0.078483913 seconds. Throughput is 1630.9076 records/second. Loss is 0.10730302. Sequential31006cbd's hyper parameters: Current learning rate is 0.003757985719654265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 42752/60000][Iteration 8307][Wall Clock 758.605997199s] Trained 128 records in 0.077366187 seconds. Throughput is 1654.4695 records/second. Loss is 0.20739323. Sequential31006cbd's hyper parameters: Current learning rate is 0.003757703291748084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 42880/60000][Iteration 8308][Wall Clock 758.697715221s] Trained 128 records in 0.091718022 seconds. Throughput is 1395.5817 records/second. Loss is 0.14363636. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037574209062899225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43008/60000][Iteration 8309][Wall Clock 758.804524128s] Trained 128 records in 0.106808907 seconds. Throughput is 1198.4019 records/second. Loss is 0.11991317. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037571385632702136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43136/60000][Iteration 8310][Wall Clock 758.894836949s] Trained 128 records in 0.090312821 seconds. Throughput is 1417.2959 records/second. Loss is 0.13442785. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037568562626793893. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43264/60000][Iteration 8311][Wall Clock 758.979347058s] Trained 128 records in 0.084510109 seconds. Throughput is 1514.6117 records/second. Loss is 0.18038356. Sequential31006cbd's hyper parameters: Current learning rate is 0.003756574004507889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43392/60000][Iteration 8312][Wall Clock 759.060732486s] Trained 128 records in 0.081385428 seconds. Throughput is 1572.7632 records/second. Loss is 0.16973415. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037562917887461493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43520/60000][Iteration 8313][Wall Clock 759.142130646s] Trained 128 records in 0.08139816 seconds. Throughput is 1572.5171 records/second. Loss is 0.19895686. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037560096153846155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43648/60000][Iteration 8314][Wall Clock 759.232932216s] Trained 128 records in 0.09080157 seconds. Throughput is 1409.6674 records/second. Loss is 0.12998195. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037557274844137304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43776/60000][Iteration 8315][Wall Clock 759.34338514s] Trained 128 records in 0.110452924 seconds. Throughput is 1158.8647 records/second. Loss is 0.29416332. Sequential31006cbd's hyper parameters: Current learning rate is 0.003755445395823945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:16 INFO  DistriOptimizer$:408 - [Epoch 18 43904/60000][Iteration 8316][Wall Clock 759.434882839s] Trained 128 records in 0.091497699 seconds. Throughput is 1398.9423 records/second. Loss is 0.09471629. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037551633496057074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44032/60000][Iteration 8317][Wall Clock 759.519987076s] Trained 128 records in 0.085104237 seconds. Throughput is 1504.038 records/second. Loss is 0.110631354. Sequential31006cbd's hyper parameters: Current learning rate is 0.003754881345749475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44160/60000][Iteration 8318][Wall Clock 759.61809329s] Trained 128 records in 0.098106214 seconds. Throughput is 1304.7084 records/second. Loss is 0.16575485. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037545993842457008. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44288/60000][Iteration 8319][Wall Clock 759.701043303s] Trained 128 records in 0.082950013 seconds. Throughput is 1543.098 records/second. Loss is 0.22356887. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037543174650848474. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44416/60000][Iteration 8320][Wall Clock 759.835510051s] Trained 128 records in 0.134466748 seconds. Throughput is 951.90814 records/second. Loss is 0.1611456. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037540355882573766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44544/60000][Iteration 8321][Wall Clock 759.962435569s] Trained 128 records in 0.126925518 seconds. Throughput is 1008.4655 records/second. Loss is 0.1636503. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037537537537537537. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44672/60000][Iteration 8322][Wall Clock 760.051482464s] Trained 128 records in 0.089046895 seconds. Throughput is 1437.4448 records/second. Loss is 0.095809214. Sequential31006cbd's hyper parameters: Current learning rate is 0.003753471961564447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44800/60000][Iteration 8323][Wall Clock 760.148170387s] Trained 128 records in 0.096687923 seconds. Throughput is 1323.8468 records/second. Loss is 0.16784662. Sequential31006cbd's hyper parameters: Current learning rate is 0.003753190211679928. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 44928/60000][Iteration 8324][Wall Clock 760.251538597s] Trained 128 records in 0.10336821 seconds. Throughput is 1238.2917 records/second. Loss is 0.19380751. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037529085040906704. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 45056/60000][Iteration 8325][Wall Clock 760.335497445s] Trained 128 records in 0.083958848 seconds. Throughput is 1524.5564 records/second. Loss is 0.14220591. Sequential31006cbd's hyper parameters: Current learning rate is 0.003752626838787151. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:17 INFO  DistriOptimizer$:408 - [Epoch 18 45184/60000][Iteration 8326][Wall Clock 760.416092618s] Trained 128 records in 0.080595173 seconds. Throughput is 1588.1844 records/second. Loss is 0.28513393. Sequential31006cbd's hyper parameters: Current learning rate is 0.00375234521575985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 45312/60000][Iteration 8327][Wall Clock 760.502106611s] Trained 128 records in 0.086013993 seconds. Throughput is 1488.1299 records/second. Loss is 0.1822713. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037520636349992497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 45440/60000][Iteration 8328][Wall Clock 760.581832232s] Trained 128 records in 0.079725621 seconds. Throughput is 1605.5065 records/second. Loss is 0.14284542. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037517820964958356. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 45568/60000][Iteration 8329][Wall Clock 760.665566124s] Trained 128 records in 0.083733892 seconds. Throughput is 1528.6522 records/second. Loss is 0.15979314. Sequential31006cbd's hyper parameters: Current learning rate is 0.003751500600240096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 45696/60000][Iteration 8330][Wall Clock 760.746728376s] Trained 128 records in 0.081162252 seconds. Throughput is 1577.0879 records/second. Loss is 0.20793587. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037512191462225225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 45824/60000][Iteration 8331][Wall Clock 760.830382524s] Trained 128 records in 0.083654148 seconds. Throughput is 1530.1094 records/second. Loss is 0.17400594. Sequential31006cbd's hyper parameters: Current learning rate is 0.003750937734433608. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 45952/60000][Iteration 8332][Wall Clock 760.909383951s] Trained 128 records in 0.079001427 seconds. Throughput is 1620.2239 records/second. Loss is 0.15451498. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037506563648638516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 46080/60000][Iteration 8333][Wall Clock 760.983513464s] Trained 128 records in 0.074129513 seconds. Throughput is 1726.7076 records/second. Loss is 0.18432057. Sequential31006cbd's hyper parameters: Current learning rate is 0.00375037503750375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 46208/60000][Iteration 8334][Wall Clock 761.065244929s] Trained 128 records in 0.081731465 seconds. Throughput is 1566.1042 records/second. Loss is 0.11564985. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037500937523438087. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 46336/60000][Iteration 8335][Wall Clock 761.152103442s] Trained 128 records in 0.086858513 seconds. Throughput is 1473.661 records/second. Loss is 0.13133737. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037498125093745308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 46464/60000][Iteration 8336][Wall Clock 761.243199726s] Trained 128 records in 0.091096284 seconds. Throughput is 1405.1067 records/second. Loss is 0.13651924. Sequential31006cbd's hyper parameters: Current learning rate is 0.003749531308586427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 46592/60000][Iteration 8337][Wall Clock 761.317611999s] Trained 128 records in 0.074412273 seconds. Throughput is 1720.1464 records/second. Loss is 0.17243837. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037492501499700056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:18 INFO  DistriOptimizer$:408 - [Epoch 18 46720/60000][Iteration 8338][Wall Clock 761.397553943s] Trained 128 records in 0.079941944 seconds. Throughput is 1601.162 records/second. Loss is 0.18911627. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037489690335157835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 46848/60000][Iteration 8339][Wall Clock 761.477827046s] Trained 128 records in 0.080273103 seconds. Throughput is 1594.5564 records/second. Loss is 0.17749958. Sequential31006cbd's hyper parameters: Current learning rate is 0.003748687959214275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 46976/60000][Iteration 8340][Wall Clock 761.558007623s] Trained 128 records in 0.080180577 seconds. Throughput is 1596.3966 records/second. Loss is 0.10440597. Sequential31006cbd's hyper parameters: Current learning rate is 0.003748406927056001. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47104/60000][Iteration 8341][Wall Clock 761.636085673s] Trained 128 records in 0.07807805 seconds. Throughput is 1639.3853 records/second. Loss is 0.13617703. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037481259370314842. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47232/60000][Iteration 8342][Wall Clock 761.717700798s] Trained 128 records in 0.081615125 seconds. Throughput is 1568.3367 records/second. Loss is 0.13328928. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037478449891312493. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47360/60000][Iteration 8343][Wall Clock 761.798349939s] Trained 128 records in 0.080649141 seconds. Throughput is 1587.1217 records/second. Loss is 0.20424771. Sequential31006cbd's hyper parameters: Current learning rate is 0.003747564083345825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47488/60000][Iteration 8344][Wall Clock 761.902181653s] Trained 128 records in 0.103831714 seconds. Throughput is 1232.764 records/second. Loss is 0.22077914. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037472832196657423. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47616/60000][Iteration 8345][Wall Clock 761.994240351s] Trained 128 records in 0.092058698 seconds. Throughput is 1390.4172 records/second. Loss is 0.12049111. Sequential31006cbd's hyper parameters: Current learning rate is 0.003747002398081535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47744/60000][Iteration 8346][Wall Clock 762.077089672s] Trained 128 records in 0.082849321 seconds. Throughput is 1544.9734 records/second. Loss is 0.112527415. Sequential31006cbd's hyper parameters: Current learning rate is 0.003746721618583739. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 47872/60000][Iteration 8347][Wall Clock 762.179673664s] Trained 128 records in 0.102583992 seconds. Throughput is 1247.758 records/second. Loss is 0.10984519. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037464408811628954. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 48000/60000][Iteration 8348][Wall Clock 762.266520697s] Trained 128 records in 0.086847033 seconds. Throughput is 1473.8558 records/second. Loss is 0.16968985. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037461601858095454. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 48128/60000][Iteration 8349][Wall Clock 762.351340971s] Trained 128 records in 0.084820274 seconds. Throughput is 1509.0732 records/second. Loss is 0.10857605. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037458795325142347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:19 INFO  DistriOptimizer$:408 - [Epoch 18 48256/60000][Iteration 8350][Wall Clock 762.442847497s] Trained 128 records in 0.091506526 seconds. Throughput is 1398.8074 records/second. Loss is 0.13378268. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037455989212675104. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 48384/60000][Iteration 8351][Wall Clock 762.523634239s] Trained 128 records in 0.080786742 seconds. Throughput is 1584.4183 records/second. Loss is 0.16015545. Sequential31006cbd's hyper parameters: Current learning rate is 0.003745318352059925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 48512/60000][Iteration 8352][Wall Clock 762.610558089s] Trained 128 records in 0.08692385 seconds. Throughput is 1472.5532 records/second. Loss is 0.16500048. Sequential31006cbd's hyper parameters: Current learning rate is 0.003745037824882031. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 48640/60000][Iteration 8353][Wall Clock 762.694519087s] Trained 128 records in 0.083960998 seconds. Throughput is 1524.5175 records/second. Loss is 0.16763633. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037447573397243862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 48768/60000][Iteration 8354][Wall Clock 762.769780626s] Trained 128 records in 0.075261539 seconds. Throughput is 1700.7358 records/second. Loss is 0.20719367. Sequential31006cbd's hyper parameters: Current learning rate is 0.003744476896577548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 48896/60000][Iteration 8355][Wall Clock 762.855193906s] Trained 128 records in 0.08541328 seconds. Throughput is 1498.5961 records/second. Loss is 0.13488753. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037441964954320808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49024/60000][Iteration 8356][Wall Clock 762.945145226s] Trained 128 records in 0.08995132 seconds. Throughput is 1422.9918 records/second. Loss is 0.13192526. Sequential31006cbd's hyper parameters: Current learning rate is 0.003743916136278547. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49152/60000][Iteration 8357][Wall Clock 763.022673403s] Trained 128 records in 0.077528177 seconds. Throughput is 1651.0126 records/second. Loss is 0.16782871. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037436358191075174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49280/60000][Iteration 8358][Wall Clock 763.102676121s] Trained 128 records in 0.080002718 seconds. Throughput is 1599.9457 records/second. Loss is 0.18343183. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037433555439095605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49408/60000][Iteration 8359][Wall Clock 763.185914638s] Trained 128 records in 0.083238517 seconds. Throughput is 1537.7496 records/second. Loss is 0.13274515. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037430753106752514. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49536/60000][Iteration 8360][Wall Clock 763.266361441s] Trained 128 records in 0.080446803 seconds. Throughput is 1591.1136 records/second. Loss is 0.11516402. Sequential31006cbd's hyper parameters: Current learning rate is 0.003742795119395164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49664/60000][Iteration 8361][Wall Clock 763.363532988s] Trained 128 records in 0.097171547 seconds. Throughput is 1317.258 records/second. Loss is 0.11050458. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037425149700598802. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:20 INFO  DistriOptimizer$:408 - [Epoch 18 49792/60000][Iteration 8362][Wall Clock 763.44792289s] Trained 128 records in 0.084389902 seconds. Throughput is 1516.7692 records/second. Loss is 0.09753469. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037422348626599804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 49920/60000][Iteration 8363][Wall Clock 763.514657081s] Trained 128 records in 0.066734191 seconds. Throughput is 1918.0574 records/second. Loss is 0.18685712. Sequential31006cbd's hyper parameters: Current learning rate is 0.00374195479718605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50048/60000][Iteration 8364][Wall Clock 763.61456041s] Trained 128 records in 0.099903329 seconds. Throughput is 1281.2385 records/second. Loss is 0.16505106. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037416747736286763. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50176/60000][Iteration 8365][Wall Clock 763.712954879s] Trained 128 records in 0.098394469 seconds. Throughput is 1300.8861 records/second. Loss is 0.17630452. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037413947919784497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50304/60000][Iteration 8366][Wall Clock 763.792393363s] Trained 128 records in 0.079438484 seconds. Throughput is 1611.3097 records/second. Loss is 0.2171205. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037411148522259632. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50432/60000][Iteration 8367][Wall Clock 763.874271246s] Trained 128 records in 0.081877883 seconds. Throughput is 1563.3038 records/second. Loss is 0.16047165. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037408349543618137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50560/60000][Iteration 8368][Wall Clock 763.95561353s] Trained 128 records in 0.081342284 seconds. Throughput is 1573.5973 records/second. Loss is 0.1714308. Sequential31006cbd's hyper parameters: Current learning rate is 0.003740555098376599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50688/60000][Iteration 8369][Wall Clock 764.064781538s] Trained 128 records in 0.109168008 seconds. Throughput is 1172.5046 records/second. Loss is 0.16715565. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037402752842609216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50816/60000][Iteration 8370][Wall Clock 764.178057609s] Trained 128 records in 0.113276071 seconds. Throughput is 1129.9827 records/second. Loss is 0.10834779. Sequential31006cbd's hyper parameters: Current learning rate is 0.003739995512005386. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 50944/60000][Iteration 8371][Wall Clock 764.256775373s] Trained 128 records in 0.078717764 seconds. Throughput is 1626.0625 records/second. Loss is 0.21947475. Sequential31006cbd's hyper parameters: Current learning rate is 0.003739715781600598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 51072/60000][Iteration 8372][Wall Clock 764.340801471s] Trained 128 records in 0.084026098 seconds. Throughput is 1523.3362 records/second. Loss is 0.11686991. Sequential31006cbd's hyper parameters: Current learning rate is 0.00373943609303717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:21 INFO  DistriOptimizer$:408 - [Epoch 18 51200/60000][Iteration 8373][Wall Clock 764.422795551s] Trained 128 records in 0.08199408 seconds. Throughput is 1561.0884 records/second. Loss is 0.16913947. Sequential31006cbd's hyper parameters: Current learning rate is 0.003739156446305713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 51328/60000][Iteration 8374][Wall Clock 764.5254858s] Trained 128 records in 0.102690249 seconds. Throughput is 1246.4669 records/second. Loss is 0.15542273. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037388768413968445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 51456/60000][Iteration 8375][Wall Clock 764.604935272s] Trained 128 records in 0.079449472 seconds. Throughput is 1611.0868 records/second. Loss is 0.13849995. Sequential31006cbd's hyper parameters: Current learning rate is 0.003738597278301181. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 51584/60000][Iteration 8376][Wall Clock 764.699791029s] Trained 128 records in 0.094855757 seconds. Throughput is 1349.4174 records/second. Loss is 0.14834666. Sequential31006cbd's hyper parameters: Current learning rate is 0.003738317757009346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 51712/60000][Iteration 8377][Wall Clock 764.779810564s] Trained 128 records in 0.080019535 seconds. Throughput is 1599.6094 records/second. Loss is 0.17293802. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037380382775119613. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 51840/60000][Iteration 8378][Wall Clock 764.867151486s] Trained 128 records in 0.087340922 seconds. Throughput is 1465.5215 records/second. Loss is 0.1121247. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037377588397996563. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 51968/60000][Iteration 8379][Wall Clock 764.955995028s] Trained 128 records in 0.088843542 seconds. Throughput is 1440.735 records/second. Loss is 0.12623796. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037374794438630584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 52096/60000][Iteration 8380][Wall Clock 765.039449649s] Trained 128 records in 0.083454621 seconds. Throughput is 1533.7676 records/second. Loss is 0.14122483. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037372000896928018. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 52224/60000][Iteration 8381][Wall Clock 765.118059368s] Trained 128 records in 0.078609719 seconds. Throughput is 1628.2974 records/second. Loss is 0.17945337. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037369207772795215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 52352/60000][Iteration 8382][Wall Clock 765.223748162s] Trained 128 records in 0.105688794 seconds. Throughput is 1211.1028 records/second. Loss is 0.18612416. Sequential31006cbd's hyper parameters: Current learning rate is 0.003736641506613855. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 52480/60000][Iteration 8383][Wall Clock 765.310978949s] Trained 128 records in 0.087230787 seconds. Throughput is 1467.3718 records/second. Loss is 0.09432102. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037363622776864446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:22 INFO  DistriOptimizer$:408 - [Epoch 18 52608/60000][Iteration 8384][Wall Clock 765.392576879s] Trained 128 records in 0.08159793 seconds. Throughput is 1568.6672 records/second. Loss is 0.22930633. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037360830904879325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 52736/60000][Iteration 8385][Wall Clock 765.473251137s] Trained 128 records in 0.080674258 seconds. Throughput is 1586.6274 records/second. Loss is 0.09039369. Sequential31006cbd's hyper parameters: Current learning rate is 0.003735803945008966. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 52864/60000][Iteration 8386][Wall Clock 765.550391155s] Trained 128 records in 0.077140018 seconds. Throughput is 1659.3203 records/second. Loss is 0.12509054. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037355248412401943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 52992/60000][Iteration 8387][Wall Clock 765.660260852s] Trained 128 records in 0.109869697 seconds. Throughput is 1165.0165 records/second. Loss is 0.09173939. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037352457791722696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53120/60000][Iteration 8388][Wall Clock 765.746783823s] Trained 128 records in 0.086522971 seconds. Throughput is 1479.3759 records/second. Loss is 0.15841189. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037349667587958466. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53248/60000][Iteration 8389][Wall Clock 765.826623882s] Trained 128 records in 0.079840059 seconds. Throughput is 1603.2053 records/second. Loss is 0.1630599. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037346877801015836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53376/60000][Iteration 8390][Wall Clock 765.908083007s] Trained 128 records in 0.081459125 seconds. Throughput is 1571.3402 records/second. Loss is 0.12472536. Sequential31006cbd's hyper parameters: Current learning rate is 0.00373440884308014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53504/60000][Iteration 8391][Wall Clock 765.996315454s] Trained 128 records in 0.088232447 seconds. Throughput is 1450.7134 records/second. Loss is 0.21404701. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037341299477221808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53632/60000][Iteration 8392][Wall Clock 766.07568931s] Trained 128 records in 0.079373856 seconds. Throughput is 1612.6216 records/second. Loss is 0.11911063. Sequential31006cbd's hyper parameters: Current learning rate is 0.00373385109401837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53760/60000][Iteration 8393][Wall Clock 766.16317739s] Trained 128 records in 0.08748808 seconds. Throughput is 1463.0565 records/second. Loss is 0.29584143. Sequential31006cbd's hyper parameters: Current learning rate is 0.003733572281959379. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 53888/60000][Iteration 8394][Wall Clock 766.26727691s] Trained 128 records in 0.10409952 seconds. Throughput is 1229.5927 records/second. Loss is 0.14709377. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037332935115358765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:23 INFO  DistriOptimizer$:408 - [Epoch 18 54016/60000][Iteration 8395][Wall Clock 766.35834555s] Trained 128 records in 0.09106864 seconds. Throughput is 1405.5332 records/second. Loss is 0.15378532. Sequential31006cbd's hyper parameters: Current learning rate is 0.00373301478273854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54144/60000][Iteration 8396][Wall Clock 766.479024702s] Trained 128 records in 0.120679152 seconds. Throughput is 1060.6637 records/second. Loss is 0.13718246. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037327360955580436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54272/60000][Iteration 8397][Wall Clock 766.54846532s] Trained 128 records in 0.069440618 seconds. Throughput is 1843.3015 records/second. Loss is 0.15403506. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037324574499850707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54400/60000][Iteration 8398][Wall Clock 766.62424598s] Trained 128 records in 0.07578066 seconds. Throughput is 1689.0853 records/second. Loss is 0.12881914. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037321788460103005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54528/60000][Iteration 8399][Wall Clock 766.701440228s] Trained 128 records in 0.077194248 seconds. Throughput is 1658.1545 records/second. Loss is 0.19464567. Sequential31006cbd's hyper parameters: Current learning rate is 0.003731900283624422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54656/60000][Iteration 8400][Wall Clock 766.798823682s] Trained 128 records in 0.097383454 seconds. Throughput is 1314.3916 records/second. Loss is 0.14979482. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037316217628181204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54784/60000][Iteration 8401][Wall Clock 766.88434604s] Trained 128 records in 0.085522358 seconds. Throughput is 1496.6846 records/second. Loss is 0.12468493. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037313432835820895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 54912/60000][Iteration 8402][Wall Clock 766.961565315s] Trained 128 records in 0.077219275 seconds. Throughput is 1657.6172 records/second. Loss is 0.1654027. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037310648459070216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 55040/60000][Iteration 8403][Wall Clock 767.039443452s] Trained 128 records in 0.077878137 seconds. Throughput is 1643.5934 records/second. Loss is 0.25230744. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037307864497836143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 55168/60000][Iteration 8404][Wall Clock 767.111001639s] Trained 128 records in 0.071558187 seconds. Throughput is 1788.7542 records/second. Loss is 0.13621244. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037305080952025668. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 55296/60000][Iteration 8405][Wall Clock 767.184326686s] Trained 128 records in 0.073325047 seconds. Throughput is 1745.6519 records/second. Loss is 0.16452378. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037302297821545805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 55424/60000][Iteration 8406][Wall Clock 767.264800084s] Trained 128 records in 0.080473398 seconds. Throughput is 1590.5876 records/second. Loss is 0.08448076. Sequential31006cbd's hyper parameters: Current learning rate is 0.003729951510630362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 55552/60000][Iteration 8407][Wall Clock 767.34582558s] Trained 128 records in 0.081025496 seconds. Throughput is 1579.7496 records/second. Loss is 0.075050086. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037296732806206176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:24 INFO  DistriOptimizer$:408 - [Epoch 18 55680/60000][Iteration 8408][Wall Clock 767.427918404s] Trained 128 records in 0.082092824 seconds. Throughput is 1559.2106 records/second. Loss is 0.18656161. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037293950921160586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 55808/60000][Iteration 8409][Wall Clock 767.505723988s] Trained 128 records in 0.077805584 seconds. Throughput is 1645.1261 records/second. Loss is 0.1426164. Sequential31006cbd's hyper parameters: Current learning rate is 0.003729116945107399. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 55936/60000][Iteration 8410][Wall Clock 767.584169254s] Trained 128 records in 0.078445266 seconds. Throughput is 1631.711 records/second. Loss is 0.19560817. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037288388395853534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56064/60000][Iteration 8411][Wall Clock 767.660782593s] Trained 128 records in 0.076613339 seconds. Throughput is 1670.7274 records/second. Loss is 0.10496665. Sequential31006cbd's hyper parameters: Current learning rate is 0.003728560775540641. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56192/60000][Iteration 8412][Wall Clock 767.762700149s] Trained 128 records in 0.101917556 seconds. Throughput is 1255.9171 records/second. Loss is 0.14420786. Sequential31006cbd's hyper parameters: Current learning rate is 0.003728282752963985. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56320/60000][Iteration 8413][Wall Clock 767.8594137s] Trained 128 records in 0.096713551 seconds. Throughput is 1323.496 records/second. Loss is 0.08605466. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037280047718461075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56448/60000][Iteration 8414][Wall Clock 767.935043966s] Trained 128 records in 0.075630266 seconds. Throughput is 1692.4442 records/second. Loss is 0.12515739. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037277268321777384. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56576/60000][Iteration 8415][Wall Clock 768.018543309s] Trained 128 records in 0.083499343 seconds. Throughput is 1532.9462 records/second. Loss is 0.25014356. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037274489339496047. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56704/60000][Iteration 8416][Wall Clock 768.106866068s] Trained 128 records in 0.088322759 seconds. Throughput is 1449.2301 records/second. Loss is 0.085748926. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037271710771524416. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56832/60000][Iteration 8417][Wall Clock 768.194365229s] Trained 128 records in 0.087499161 seconds. Throughput is 1462.8711 records/second. Loss is 0.17519593. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037268932617769823. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 56960/60000][Iteration 8418][Wall Clock 768.275097371s] Trained 128 records in 0.080732142 seconds. Throughput is 1585.4899 records/second. Loss is 0.09031578. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037266154878139676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:25 INFO  DistriOptimizer$:408 - [Epoch 18 57088/60000][Iteration 8419][Wall Clock 768.361534597s] Trained 128 records in 0.086437226 seconds. Throughput is 1480.8435 records/second. Loss is 0.08903195. Sequential31006cbd's hyper parameters: Current learning rate is 0.003726337755254136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57216/60000][Iteration 8420][Wall Clock 768.449916673s] Trained 128 records in 0.088382076 seconds. Throughput is 1448.2574 records/second. Loss is 0.13532312. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037260600640882328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57344/60000][Iteration 8421][Wall Clock 768.546549794s] Trained 128 records in 0.096633121 seconds. Throughput is 1324.5975 records/second. Loss is 0.19602965. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037257824143070045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57472/60000][Iteration 8422][Wall Clock 768.638616831s] Trained 128 records in 0.092067037 seconds. Throughput is 1390.2913 records/second. Loss is 0.16720785. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037255048059011996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57600/60000][Iteration 8423][Wall Clock 768.720462407s] Trained 128 records in 0.081845576 seconds. Throughput is 1563.9209 records/second. Loss is 0.123430334. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037252272388615705. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57728/60000][Iteration 8424][Wall Clock 768.814656265s] Trained 128 records in 0.094193858 seconds. Throughput is 1358.8997 records/second. Loss is 0.21460584. Sequential31006cbd's hyper parameters: Current learning rate is 0.003724949713178872. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57856/60000][Iteration 8425][Wall Clock 768.906044557s] Trained 128 records in 0.091388292 seconds. Throughput is 1400.6171 records/second. Loss is 0.110056184. Sequential31006cbd's hyper parameters: Current learning rate is 0.003724672228843862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 57984/60000][Iteration 8426][Wall Clock 768.987300938s] Trained 128 records in 0.081256381 seconds. Throughput is 1575.2609 records/second. Loss is 0.09882176. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037243947858473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 58112/60000][Iteration 8427][Wall Clock 769.082790489s] Trained 128 records in 0.095489551 seconds. Throughput is 1340.4608 records/second. Loss is 0.27466404. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037241173841799495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 58240/60000][Iteration 8428][Wall Clock 769.192118859s] Trained 128 records in 0.10932837 seconds. Throughput is 1170.7849 records/second. Loss is 0.16140638. Sequential31006cbd's hyper parameters: Current learning rate is 0.003723840023832576. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 58368/60000][Iteration 8429][Wall Clock 769.27607766s] Trained 128 records in 0.083958801 seconds. Throughput is 1524.5573 records/second. Loss is 0.09220124. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037235627047959487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:26 INFO  DistriOptimizer$:408 - [Epoch 18 58496/60000][Iteration 8430][Wall Clock 769.354394893s] Trained 128 records in 0.078317233 seconds. Throughput is 1634.3785 records/second. Loss is 0.1612078. Sequential31006cbd's hyper parameters: Current learning rate is 0.003723285427060838. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 58624/60000][Iteration 8431][Wall Clock 769.436347255s] Trained 128 records in 0.081952362 seconds. Throughput is 1561.8829 records/second. Loss is 0.14758115. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037230081906180195. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 58752/60000][Iteration 8432][Wall Clock 769.519519435s] Trained 128 records in 0.08317218 seconds. Throughput is 1538.9762 records/second. Loss is 0.19467154. Sequential31006cbd's hyper parameters: Current learning rate is 0.003722730995458268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 58880/60000][Iteration 8433][Wall Clock 769.626889177s] Trained 128 records in 0.107369742 seconds. Throughput is 1192.1422 records/second. Loss is 0.10206982. Sequential31006cbd's hyper parameters: Current learning rate is 0.003722453841572365. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59008/60000][Iteration 8434][Wall Clock 769.709141674s] Trained 128 records in 0.082252497 seconds. Throughput is 1556.1838 records/second. Loss is 0.16040647. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037221767289510902. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59136/60000][Iteration 8435][Wall Clock 769.790394289s] Trained 128 records in 0.081252615 seconds. Throughput is 1575.334 records/second. Loss is 0.18561989. Sequential31006cbd's hyper parameters: Current learning rate is 0.003721899657585232. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59264/60000][Iteration 8436][Wall Clock 769.871857801s] Trained 128 records in 0.081463512 seconds. Throughput is 1571.2557 records/second. Loss is 0.103756964. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037216226274655747. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59392/60000][Iteration 8437][Wall Clock 769.957156167s] Trained 128 records in 0.085298366 seconds. Throughput is 1500.6149 records/second. Loss is 0.20030358. Sequential31006cbd's hyper parameters: Current learning rate is 0.003721345638582912. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59520/60000][Iteration 8438][Wall Clock 770.043929804s] Trained 128 records in 0.086773637 seconds. Throughput is 1475.1024 records/second. Loss is 0.15778235. Sequential31006cbd's hyper parameters: Current learning rate is 0.003721068690928034. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59648/60000][Iteration 8439][Wall Clock 770.154790164s] Trained 128 records in 0.11086036 seconds. Throughput is 1154.6056 records/second. Loss is 0.15462607. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037207917844917404. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59776/60000][Iteration 8440][Wall Clock 770.245872558s] Trained 128 records in 0.091082394 seconds. Throughput is 1405.321 records/second. Loss is 0.16186379. Sequential31006cbd's hyper parameters: Current learning rate is 0.003720514919264826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 59904/60000][Iteration 8441][Wall Clock 770.326258529s] Trained 128 records in 0.080385971 seconds. Throughput is 1592.3177 records/second. Loss is 0.1459276. Sequential31006cbd's hyper parameters: Current learning rate is 0.003720238095238095. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:408 - [Epoch 18 60032/60000][Iteration 8442][Wall Clock 770.407483551s] Trained 128 records in 0.081225022 seconds. Throughput is 1575.869 records/second. Loss is 0.16893633. Sequential31006cbd's hyper parameters: Current learning rate is 0.003719961312402351. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:27 INFO  DistriOptimizer$:452 - [Epoch 18 60032/60000][Iteration 8442][Wall Clock 770.407483551s] Epoch finished. Wall clock time is 771501.903916 ms
2019-10-24 00:10:27 INFO  DistriOptimizer$:111 - [Epoch 18 60032/60000][Iteration 8442][Wall Clock 770.407483551s] Validate model...
2019-10-24 00:10:28 INFO  DistriOptimizer$:178 - [Epoch 18 60032/60000][Iteration 8442][Wall Clock 770.407483551s] validate model throughput is 12164.332 records/second
2019-10-24 00:10:28 INFO  DistriOptimizer$:181 - [Epoch 18 60032/60000][Iteration 8442][Wall Clock 770.407483551s] Top1Accuracy is Accuracy(correct: 9568, count: 10000, accuracy: 0.9568)
2019-10-24 00:10:28 INFO  DistriOptimizer$:221 - [Wall Clock 771.501903916s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:10:28 INFO  DistriOptimizer$:226 - [Wall Clock 771.501903916s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 128/60000][Iteration 8443][Wall Clock 771.604000991s] Trained 128 records in 0.102097075 seconds. Throughput is 1253.7089 records/second. Loss is 0.082926735. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037196845707484004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 256/60000][Iteration 8444][Wall Clock 771.686235382s] Trained 128 records in 0.082234391 seconds. Throughput is 1556.5264 records/second. Loss is 0.14200063. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037194078702670534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 384/60000][Iteration 8445][Wall Clock 771.763533848s] Trained 128 records in 0.077298466 seconds. Throughput is 1655.9191 records/second. Loss is 0.13034552. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037191312109491224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 512/60000][Iteration 8446][Wall Clock 771.844497772s] Trained 128 records in 0.080963924 seconds. Throughput is 1580.951 records/second. Loss is 0.16975176. Sequential31006cbd's hyper parameters: Current learning rate is 0.003718854592785422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 640/60000][Iteration 8447][Wall Clock 771.945922858s] Trained 128 records in 0.101425086 seconds. Throughput is 1262.0151 records/second. Loss is 0.22021715. Sequential31006cbd's hyper parameters: Current learning rate is 0.003718578015766771. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 768/60000][Iteration 8448][Wall Clock 772.066683106s] Trained 128 records in 0.120760248 seconds. Throughput is 1059.9514 records/second. Loss is 0.118331306. Sequential31006cbd's hyper parameters: Current learning rate is 0.003718301479883989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 896/60000][Iteration 8449][Wall Clock 772.146939686s] Trained 128 records in 0.08025658 seconds. Throughput is 1594.8848 records/second. Loss is 0.20324229. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037180249851279. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 1024/60000][Iteration 8450][Wall Clock 772.225617463s] Trained 128 records in 0.078677777 seconds. Throughput is 1626.8889 records/second. Loss is 0.1663973. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037177485314893303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 1152/60000][Iteration 8451][Wall Clock 772.313766334s] Trained 128 records in 0.088148871 seconds. Throughput is 1452.089 records/second. Loss is 0.10527909. Sequential31006cbd's hyper parameters: Current learning rate is 0.003717472118959107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 1280/60000][Iteration 8452][Wall Clock 772.392891192s] Trained 128 records in 0.079124858 seconds. Throughput is 1617.6964 records/second. Loss is 0.15911752. Sequential31006cbd's hyper parameters: Current learning rate is 0.003717195747528065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 1408/60000][Iteration 8453][Wall Clock 772.479944081s] Trained 128 records in 0.087052889 seconds. Throughput is 1470.3705 records/second. Loss is 0.16728367. Sequential31006cbd's hyper parameters: Current learning rate is 0.003716919417187035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:29 INFO  DistriOptimizer$:408 - [Epoch 19 1536/60000][Iteration 8454][Wall Clock 772.557456101s] Trained 128 records in 0.07751202 seconds. Throughput is 1651.3568 records/second. Loss is 0.24296945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037166431279268566. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 1664/60000][Iteration 8455][Wall Clock 772.639274512s] Trained 128 records in 0.081818411 seconds. Throughput is 1564.4401 records/second. Loss is 0.097893514. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037163668797383673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 1792/60000][Iteration 8456][Wall Clock 772.721782796s] Trained 128 records in 0.082508284 seconds. Throughput is 1551.3594 records/second. Loss is 0.24574268. Sequential31006cbd's hyper parameters: Current learning rate is 0.003716090672612412. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 1920/60000][Iteration 8457][Wall Clock 772.81361672s] Trained 128 records in 0.091833924 seconds. Throughput is 1393.8204 records/second. Loss is 0.15347798. Sequential31006cbd's hyper parameters: Current learning rate is 0.003715814506539833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2048/60000][Iteration 8458][Wall Clock 772.894296558s] Trained 128 records in 0.080679838 seconds. Throughput is 1586.5177 records/second. Loss is 0.14401801. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037155383815114813. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2176/60000][Iteration 8459][Wall Clock 772.972151389s] Trained 128 records in 0.077854831 seconds. Throughput is 1644.0854 records/second. Loss is 0.17732102. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037152622975182045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2304/60000][Iteration 8460][Wall Clock 773.052181513s] Trained 128 records in 0.080030124 seconds. Throughput is 1599.3978 records/second. Loss is 0.21065488. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037149862545508587. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2432/60000][Iteration 8461][Wall Clock 773.143181299s] Trained 128 records in 0.090999786 seconds. Throughput is 1406.5967 records/second. Loss is 0.17764015. Sequential31006cbd's hyper parameters: Current learning rate is 0.003714710252600297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2560/60000][Iteration 8462][Wall Clock 773.222021116s] Trained 128 records in 0.078839817 seconds. Throughput is 1623.5452 records/second. Loss is 0.13183446. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037144342916573805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2688/60000][Iteration 8463][Wall Clock 773.320976948s] Trained 128 records in 0.098955832 seconds. Throughput is 1293.5063 records/second. Loss is 0.24237841. Sequential31006cbd's hyper parameters: Current learning rate is 0.00371415837171297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2816/60000][Iteration 8464][Wall Clock 773.406657007s] Trained 128 records in 0.085680059 seconds. Throughput is 1493.9298 records/second. Loss is 0.18526159. Sequential31006cbd's hyper parameters: Current learning rate is 0.003713882492757929. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 2944/60000][Iteration 8465][Wall Clock 773.480825263s] Trained 128 records in 0.074168256 seconds. Throughput is 1725.8057 records/second. Loss is 0.15683845. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037136066547831252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:30 INFO  DistriOptimizer$:408 - [Epoch 19 3072/60000][Iteration 8466][Wall Clock 773.563477423s] Trained 128 records in 0.08265216 seconds. Throughput is 1548.6589 records/second. Loss is 0.1378785. Sequential31006cbd's hyper parameters: Current learning rate is 0.003713330857779428. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3200/60000][Iteration 8467][Wall Clock 773.647641498s] Trained 128 records in 0.084164075 seconds. Throughput is 1520.8389 records/second. Loss is 0.10473361. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037130551017377097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3328/60000][Iteration 8468][Wall Clock 773.735072845s] Trained 128 records in 0.087431347 seconds. Throughput is 1464.0057 records/second. Loss is 0.20113797. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037127793866488456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3456/60000][Iteration 8469][Wall Clock 773.819777371s] Trained 128 records in 0.084704526 seconds. Throughput is 1511.1353 records/second. Loss is 0.14444095. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037125037125037125. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3584/60000][Iteration 8470][Wall Clock 773.903680842s] Trained 128 records in 0.083903471 seconds. Throughput is 1525.5626 records/second. Loss is 0.15358043. Sequential31006cbd's hyper parameters: Current learning rate is 0.003712228079293192. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3712/60000][Iteration 8471][Wall Clock 773.997147357s] Trained 128 records in 0.093466515 seconds. Throughput is 1369.4745 records/second. Loss is 0.15137596. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037119524870081666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3840/60000][Iteration 8472][Wall Clock 774.0873351s] Trained 128 records in 0.090187743 seconds. Throughput is 1419.2616 records/second. Loss is 0.11299038. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037116769356395217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 3968/60000][Iteration 8473][Wall Clock 774.174329541s] Trained 128 records in 0.086994441 seconds. Throughput is 1471.3584 records/second. Loss is 0.13191348. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037114014251781475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 4096/60000][Iteration 8474][Wall Clock 774.249730396s] Trained 128 records in 0.075400855 seconds. Throughput is 1697.5935 records/second. Loss is 0.13017517. Sequential31006cbd's hyper parameters: Current learning rate is 0.003711125955614933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 4224/60000][Iteration 8475][Wall Clock 774.332867476s] Trained 128 records in 0.08313708 seconds. Throughput is 1539.6259 records/second. Loss is 0.15985495. Sequential31006cbd's hyper parameters: Current learning rate is 0.003710850526940775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 4352/60000][Iteration 8476][Wall Clock 774.410112862s] Trained 128 records in 0.077245386 seconds. Throughput is 1657.0569 records/second. Loss is 0.16693473. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037105751391465673. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:31 INFO  DistriOptimizer$:408 - [Epoch 19 4480/60000][Iteration 8477][Wall Clock 774.489621601s] Trained 128 records in 0.079508739 seconds. Throughput is 1609.886 records/second. Loss is 0.12744182. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037102997922232117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 4608/60000][Iteration 8478][Wall Clock 774.567690189s] Trained 128 records in 0.078068588 seconds. Throughput is 1639.5839 records/second. Loss is 0.15074834. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037100244861616085. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 4736/60000][Iteration 8479][Wall Clock 774.646765886s] Trained 128 records in 0.079075697 seconds. Throughput is 1618.7021 records/second. Loss is 0.14428777. Sequential31006cbd's hyper parameters: Current learning rate is 0.003709749220952664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 4864/60000][Iteration 8480][Wall Clock 774.722519618s] Trained 128 records in 0.075753732 seconds. Throughput is 1689.6857 records/second. Loss is 0.17736119. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037094739965872836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 4992/60000][Iteration 8481][Wall Clock 774.801445826s] Trained 128 records in 0.078926208 seconds. Throughput is 1621.7681 records/second. Loss is 0.11787495. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037091988130563795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5120/60000][Iteration 8482][Wall Clock 774.882418294s] Trained 128 records in 0.080972468 seconds. Throughput is 1580.7842 records/second. Loss is 0.07731141. Sequential31006cbd's hyper parameters: Current learning rate is 0.003708923670350864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5248/60000][Iteration 8483][Wall Clock 774.956903874s] Trained 128 records in 0.07448558 seconds. Throughput is 1718.4535 records/second. Loss is 0.11994006. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037086485684616525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5376/60000][Iteration 8484][Wall Clock 775.032844427s] Trained 128 records in 0.075940553 seconds. Throughput is 1685.529 records/second. Loss is 0.19876793. Sequential31006cbd's hyper parameters: Current learning rate is 0.003708373507379663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5504/60000][Iteration 8485][Wall Clock 775.124934068s] Trained 128 records in 0.092089641 seconds. Throughput is 1389.9501 records/second. Loss is 0.0996176. Sequential31006cbd's hyper parameters: Current learning rate is 0.003708098487095817. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5632/60000][Iteration 8486][Wall Clock 775.212029198s] Trained 128 records in 0.08709513 seconds. Throughput is 1469.6575 records/second. Loss is 0.1527545. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037078235076010383. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5760/60000][Iteration 8487][Wall Clock 775.289676392s] Trained 128 records in 0.077647194 seconds. Throughput is 1648.4819 records/second. Loss is 0.21984616. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037075485688862525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 5888/60000][Iteration 8488][Wall Clock 775.368453109s] Trained 128 records in 0.078776717 seconds. Throughput is 1624.8456 records/second. Loss is 0.06887771. Sequential31006cbd's hyper parameters: Current learning rate is 0.003707273670942389. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 6016/60000][Iteration 8489][Wall Clock 775.458186578s] Trained 128 records in 0.089733469 seconds. Throughput is 1426.4467 records/second. Loss is 0.24196765. Sequential31006cbd's hyper parameters: Current learning rate is 0.00370699881376038. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:32 INFO  DistriOptimizer$:408 - [Epoch 19 6144/60000][Iteration 8490][Wall Clock 775.537755902s] Trained 128 records in 0.079569324 seconds. Throughput is 1608.6602 records/second. Loss is 0.10576935. Sequential31006cbd's hyper parameters: Current learning rate is 0.003706723997331159. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 6272/60000][Iteration 8491][Wall Clock 775.614541503s] Trained 128 records in 0.076785601 seconds. Throughput is 1666.9792 records/second. Loss is 0.09403469. Sequential31006cbd's hyper parameters: Current learning rate is 0.003706449221645663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 6400/60000][Iteration 8492][Wall Clock 775.701700073s] Trained 128 records in 0.08715857 seconds. Throughput is 1468.5876 records/second. Loss is 0.09549162. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037061744866948338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 6528/60000][Iteration 8493][Wall Clock 775.815052665s] Trained 128 records in 0.113352592 seconds. Throughput is 1129.2198 records/second. Loss is 0.08517508. Sequential31006cbd's hyper parameters: Current learning rate is 0.003705899792469611. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 6656/60000][Iteration 8494][Wall Clock 775.918419965s] Trained 128 records in 0.1033673 seconds. Throughput is 1238.3026 records/second. Loss is 0.13101119. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037056251389609427. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 6784/60000][Iteration 8495][Wall Clock 776.000499172s] Trained 128 records in 0.082079207 seconds. Throughput is 1559.4692 records/second. Loss is 0.08602445. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037053505261597742. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 6912/60000][Iteration 8496][Wall Clock 776.08406453s] Trained 128 records in 0.083565358 seconds. Throughput is 1531.7352 records/second. Loss is 0.22794333. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037050759540570586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 7040/60000][Iteration 8497][Wall Clock 776.168012083s] Trained 128 records in 0.083947553 seconds. Throughput is 1524.7615 records/second. Loss is 0.09269203. Sequential31006cbd's hyper parameters: Current learning rate is 0.003704801422643746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 7168/60000][Iteration 8498][Wall Clock 776.246940112s] Trained 128 records in 0.078928029 seconds. Throughput is 1621.7306 records/second. Loss is 0.1694838. Sequential31006cbd's hyper parameters: Current learning rate is 0.003704526931910795. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 7296/60000][Iteration 8499][Wall Clock 776.318867178s] Trained 128 records in 0.071927066 seconds. Throughput is 1779.5806 records/second. Loss is 0.19279537. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037042524818491625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 7424/60000][Iteration 8500][Wall Clock 776.400545665s] Trained 128 records in 0.081678487 seconds. Throughput is 1567.1201 records/second. Loss is 0.2669944. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037039780724498115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:33 INFO  DistriOptimizer$:408 - [Epoch 19 7552/60000][Iteration 8501][Wall Clock 776.481873245s] Trained 128 records in 0.08132758 seconds. Throughput is 1573.8818 records/second. Loss is 0.14822817. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037037037037037034. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 7680/60000][Iteration 8502][Wall Clock 776.55804791s] Trained 128 records in 0.076174665 seconds. Throughput is 1680.3488 records/second. Loss is 0.18198179. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037034293756018073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 7808/60000][Iteration 8503][Wall Clock 776.639924317s] Trained 128 records in 0.081876407 seconds. Throughput is 1563.3319 records/second. Loss is 0.17772613. Sequential31006cbd's hyper parameters: Current learning rate is 0.003703155088135091. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 7936/60000][Iteration 8504][Wall Clock 776.727703949s] Trained 128 records in 0.087779632 seconds. Throughput is 1458.197 records/second. Loss is 0.069009915. Sequential31006cbd's hyper parameters: Current learning rate is 0.003702880841294527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8064/60000][Iteration 8505][Wall Clock 776.812967896s] Trained 128 records in 0.085263947 seconds. Throughput is 1501.2207 records/second. Loss is 0.13985454. Sequential31006cbd's hyper parameters: Current learning rate is 0.00370260663507109. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8192/60000][Iteration 8506][Wall Clock 776.909626448s] Trained 128 records in 0.096658552 seconds. Throughput is 1324.2491 records/second. Loss is 0.25213343. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037023324694557573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8320/60000][Iteration 8507][Wall Clock 776.982248733s] Trained 128 records in 0.072622285 seconds. Throughput is 1762.5444 records/second. Loss is 0.14663433. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037020583444395084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8448/60000][Iteration 8508][Wall Clock 777.054989919s] Trained 128 records in 0.072741186 seconds. Throughput is 1759.6633 records/second. Loss is 0.14575882. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037017842600133265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8576/60000][Iteration 8509][Wall Clock 777.130548249s] Trained 128 records in 0.07555833 seconds. Throughput is 1694.0555 records/second. Loss is 0.1457129. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037015102161681965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8704/60000][Iteration 8510][Wall Clock 777.210327759s] Trained 128 records in 0.07977951 seconds. Throughput is 1604.4219 records/second. Loss is 0.13852258. Sequential31006cbd's hyper parameters: Current learning rate is 0.003701236212895107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8832/60000][Iteration 8511][Wall Clock 777.286101991s] Trained 128 records in 0.075774232 seconds. Throughput is 1689.2286 records/second. Loss is 0.21977256. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037009622501850484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 8960/60000][Iteration 8512][Wall Clock 777.362460142s] Trained 128 records in 0.076358151 seconds. Throughput is 1676.3108 records/second. Loss is 0.16313541. Sequential31006cbd's hyper parameters: Current learning rate is 0.003700688328029013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 9088/60000][Iteration 8513][Wall Clock 777.442412266s] Trained 128 records in 0.079952124 seconds. Throughput is 1600.9581 records/second. Loss is 0.08832837. Sequential31006cbd's hyper parameters: Current learning rate is 0.003700414446417999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:34 INFO  DistriOptimizer$:408 - [Epoch 19 9216/60000][Iteration 8514][Wall Clock 777.52193028s] Trained 128 records in 0.079518014 seconds. Throughput is 1609.6981 records/second. Loss is 0.1196129. Sequential31006cbd's hyper parameters: Current learning rate is 0.0037001406053430025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 9344/60000][Iteration 8515][Wall Clock 777.642926922s] Trained 128 records in 0.120996642 seconds. Throughput is 1057.8806 records/second. Loss is 0.14076161. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036998668047950275. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 9472/60000][Iteration 8516][Wall Clock 777.75107744s] Trained 128 records in 0.108150518 seconds. Throughput is 1183.5356 records/second. Loss is 0.2767271. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036995930447650755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 9600/60000][Iteration 8517][Wall Clock 777.840234729s] Trained 128 records in 0.089157289 seconds. Throughput is 1435.665 records/second. Loss is 0.2322283. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036993193252441554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 9728/60000][Iteration 8518][Wall Clock 777.925886623s] Trained 128 records in 0.085651894 seconds. Throughput is 1494.421 records/second. Loss is 0.101010375. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036990456462232743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 9856/60000][Iteration 8519][Wall Clock 778.028772033s] Trained 128 records in 0.10288541 seconds. Throughput is 1244.1025 records/second. Loss is 0.16218641. Sequential31006cbd's hyper parameters: Current learning rate is 0.003698772007693446. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 9984/60000][Iteration 8520][Wall Clock 778.117063066s] Trained 128 records in 0.088291033 seconds. Throughput is 1449.7509 records/second. Loss is 0.16370958. Sequential31006cbd's hyper parameters: Current learning rate is 0.003698498409645684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 10112/60000][Iteration 8521][Wall Clock 778.198434461s] Trained 128 records in 0.081371395 seconds. Throughput is 1573.0343 records/second. Loss is 0.13457155. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036982248520710057. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 10240/60000][Iteration 8522][Wall Clock 778.279951354s] Trained 128 records in 0.081516893 seconds. Throughput is 1570.2267 records/second. Loss is 0.16415855. Sequential31006cbd's hyper parameters: Current learning rate is 0.003697951334960432. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 10368/60000][Iteration 8523][Wall Clock 778.366890856s] Trained 128 records in 0.086939502 seconds. Throughput is 1472.2882 records/second. Loss is 0.16406095. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036976778583049843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 10496/60000][Iteration 8524][Wall Clock 778.462702453s] Trained 128 records in 0.095811597 seconds. Throughput is 1335.9552 records/second. Loss is 0.139786. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036974044220956888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:35 INFO  DistriOptimizer$:408 - [Epoch 19 10624/60000][Iteration 8525][Wall Clock 778.542376372s] Trained 128 records in 0.079673919 seconds. Throughput is 1606.5483 records/second. Loss is 0.17287306. Sequential31006cbd's hyper parameters: Current learning rate is 0.003697131026323573. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 10752/60000][Iteration 8526][Wall Clock 778.616281679s] Trained 128 records in 0.073905307 seconds. Throughput is 1731.946 records/second. Loss is 0.15469962. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036968576709796672. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 10880/60000][Iteration 8527][Wall Clock 778.694240356s] Trained 128 records in 0.077958677 seconds. Throughput is 1641.8954 records/second. Loss is 0.09806919. Sequential31006cbd's hyper parameters: Current learning rate is 0.003696584356055005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11008/60000][Iteration 8528][Wall Clock 778.777385458s] Trained 128 records in 0.083145102 seconds. Throughput is 1539.4773 records/second. Loss is 0.15689635. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036963110815406226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11136/60000][Iteration 8529][Wall Clock 778.859880738s] Trained 128 records in 0.08249528 seconds. Throughput is 1551.6039 records/second. Loss is 0.09903611. Sequential31006cbd's hyper parameters: Current learning rate is 0.003696037847427558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11264/60000][Iteration 8530][Wall Clock 778.937685568s] Trained 128 records in 0.07780483 seconds. Throughput is 1645.142 records/second. Loss is 0.12871952. Sequential31006cbd's hyper parameters: Current learning rate is 0.003695764653706852. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11392/60000][Iteration 8531][Wall Clock 779.017850741s] Trained 128 records in 0.080165173 seconds. Throughput is 1596.7034 records/second. Loss is 0.18706447. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036954915003695487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11520/60000][Iteration 8532][Wall Clock 779.098694526s] Trained 128 records in 0.080843785 seconds. Throughput is 1583.3004 records/second. Loss is 0.06869957. Sequential31006cbd's hyper parameters: Current learning rate is 0.003695218387406696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11648/60000][Iteration 8533][Wall Clock 779.184974271s] Trained 128 records in 0.086279745 seconds. Throughput is 1483.5464 records/second. Loss is 0.19348419. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036949453148093403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11776/60000][Iteration 8534][Wall Clock 779.272355448s] Trained 128 records in 0.087381177 seconds. Throughput is 1464.8464 records/second. Loss is 0.12864766. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036946722825685363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 11904/60000][Iteration 8535][Wall Clock 779.359512997s] Trained 128 records in 0.087157549 seconds. Throughput is 1468.6049 records/second. Loss is 0.19865055. Sequential31006cbd's hyper parameters: Current learning rate is 0.003694399290675336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:36 INFO  DistriOptimizer$:408 - [Epoch 19 12032/60000][Iteration 8536][Wall Clock 779.446548067s] Trained 128 records in 0.08703507 seconds. Throughput is 1470.6716 records/second. Loss is 0.13877007. Sequential31006cbd's hyper parameters: Current learning rate is 0.003694126339120798. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12160/60000][Iteration 8537][Wall Clock 779.544181748s] Trained 128 records in 0.097633681 seconds. Throughput is 1311.023 records/second. Loss is 0.09601763. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036938534278959808. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12288/60000][Iteration 8538][Wall Clock 779.627384663s] Trained 128 records in 0.083202915 seconds. Throughput is 1538.4077 records/second. Loss is 0.11842997. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036935805569919484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12416/60000][Iteration 8539][Wall Clock 779.699593775s] Trained 128 records in 0.072209112 seconds. Throughput is 1772.6295 records/second. Loss is 0.09858793. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036933077263997635. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12544/60000][Iteration 8540][Wall Clock 779.792022478s] Trained 128 records in 0.092428703 seconds. Throughput is 1384.8512 records/second. Loss is 0.14400053. Sequential31006cbd's hyper parameters: Current learning rate is 0.003693034936110496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12672/60000][Iteration 8541][Wall Clock 779.876384661s] Trained 128 records in 0.084362183 seconds. Throughput is 1517.2675 records/second. Loss is 0.1599935. Sequential31006cbd's hyper parameters: Current learning rate is 0.003692762186115214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12800/60000][Iteration 8542][Wall Clock 779.972916562s] Trained 128 records in 0.096531901 seconds. Throughput is 1325.9866 records/second. Loss is 0.12943189. Sequential31006cbd's hyper parameters: Current learning rate is 0.003692489476404992. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 12928/60000][Iteration 8543][Wall Clock 780.055839283s] Trained 128 records in 0.082922721 seconds. Throughput is 1543.606 records/second. Loss is 0.14950341. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036922168069709054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 13056/60000][Iteration 8544][Wall Clock 780.135983187s] Trained 128 records in 0.080143904 seconds. Throughput is 1597.1271 records/second. Loss is 0.16743143. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036919441778040314. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 13184/60000][Iteration 8545][Wall Clock 780.214333316s] Trained 128 records in 0.078350129 seconds. Throughput is 1633.6923 records/second. Loss is 0.15895024. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036916715888954516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 13312/60000][Iteration 8546][Wall Clock 780.296738705s] Trained 128 records in 0.082405389 seconds. Throughput is 1553.2965 records/second. Loss is 0.067186974. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036913990402362494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 13440/60000][Iteration 8547][Wall Clock 780.38042851s] Trained 128 records in 0.083689805 seconds. Throughput is 1529.4575 records/second. Loss is 0.16213965. Sequential31006cbd's hyper parameters: Current learning rate is 0.003691126531817511. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:37 INFO  DistriOptimizer$:408 - [Epoch 19 13568/60000][Iteration 8548][Wall Clock 780.462861554s] Trained 128 records in 0.082433044 seconds. Throughput is 1552.7754 records/second. Loss is 0.11688981. Sequential31006cbd's hyper parameters: Current learning rate is 0.003690854063630324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 13696/60000][Iteration 8549][Wall Clock 780.547625314s] Trained 128 records in 0.08476376 seconds. Throughput is 1510.0793 records/second. Loss is 0.14369297. Sequential31006cbd's hyper parameters: Current learning rate is 0.003690581635665781. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 13824/60000][Iteration 8550][Wall Clock 780.627860911s] Trained 128 records in 0.080235597 seconds. Throughput is 1595.3019 records/second. Loss is 0.18030432. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036903092479149756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 13952/60000][Iteration 8551][Wall Clock 780.705257863s] Trained 128 records in 0.077396952 seconds. Throughput is 1653.8119 records/second. Loss is 0.23677939. Sequential31006cbd's hyper parameters: Current learning rate is 0.003690036900369004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14080/60000][Iteration 8552][Wall Clock 780.783203651s] Trained 128 records in 0.077945788 seconds. Throughput is 1642.1669 records/second. Loss is 0.16558963. Sequential31006cbd's hyper parameters: Current learning rate is 0.003689764593018965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14208/60000][Iteration 8553][Wall Clock 780.866537635s] Trained 128 records in 0.083333984 seconds. Throughput is 1535.988 records/second. Loss is 0.19906986. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036894923258559624. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14336/60000][Iteration 8554][Wall Clock 780.945951913s] Trained 128 records in 0.079414278 seconds. Throughput is 1611.8008 records/second. Loss is 0.07610398. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036892200988710984. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14464/60000][Iteration 8555][Wall Clock 781.028178061s] Trained 128 records in 0.082226148 seconds. Throughput is 1556.6824 records/second. Loss is 0.06751071. Sequential31006cbd's hyper parameters: Current learning rate is 0.003688947912055482. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14592/60000][Iteration 8556][Wall Clock 781.106075025s] Trained 128 records in 0.077896964 seconds. Throughput is 1643.1962 records/second. Loss is 0.1621795. Sequential31006cbd's hyper parameters: Current learning rate is 0.003688675765400221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14720/60000][Iteration 8557][Wall Clock 781.186481359s] Trained 128 records in 0.080406334 seconds. Throughput is 1591.9144 records/second. Loss is 0.10698657. Sequential31006cbd's hyper parameters: Current learning rate is 0.00368840365889643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14848/60000][Iteration 8558][Wall Clock 781.267294312s] Trained 128 records in 0.080812953 seconds. Throughput is 1583.9045 records/second. Loss is 0.14953768. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036881315925352213. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 14976/60000][Iteration 8559][Wall Clock 781.371558725s] Trained 128 records in 0.104264413 seconds. Throughput is 1227.648 records/second. Loss is 0.16974303. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036878595663077155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:38 INFO  DistriOptimizer$:408 - [Epoch 19 15104/60000][Iteration 8560][Wall Clock 781.45603445s] Trained 128 records in 0.084475725 seconds. Throughput is 1515.2281 records/second. Loss is 0.11237527. Sequential31006cbd's hyper parameters: Current learning rate is 0.00368758758020503. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 15232/60000][Iteration 8561][Wall Clock 781.54372705s] Trained 128 records in 0.0876926 seconds. Throughput is 1459.6442 records/second. Loss is 0.21517512. Sequential31006cbd's hyper parameters: Current learning rate is 0.003687315634218289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 15360/60000][Iteration 8562][Wall Clock 781.625540188s] Trained 128 records in 0.081813138 seconds. Throughput is 1564.5408 records/second. Loss is 0.12720887. Sequential31006cbd's hyper parameters: Current learning rate is 0.003687043728338618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 15488/60000][Iteration 8563][Wall Clock 781.701333637s] Trained 128 records in 0.075793449 seconds. Throughput is 1688.8002 records/second. Loss is 0.16725576. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036867718625571448. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 15616/60000][Iteration 8564][Wall Clock 781.784236172s] Trained 128 records in 0.082902535 seconds. Throughput is 1543.9817 records/second. Loss is 0.20433994. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036865000368650003. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 15744/60000][Iteration 8565][Wall Clock 781.865284712s] Trained 128 records in 0.08104854 seconds. Throughput is 1579.3005 records/second. Loss is 0.09684223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036862282512533174. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 15872/60000][Iteration 8566][Wall Clock 781.974071399s] Trained 128 records in 0.108786687 seconds. Throughput is 1176.6145 records/second. Loss is 0.1309115. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036859565057132324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 16000/60000][Iteration 8567][Wall Clock 782.069397639s] Trained 128 records in 0.09532624 seconds. Throughput is 1342.7573 records/second. Loss is 0.18008143. Sequential31006cbd's hyper parameters: Current learning rate is 0.003685684800235884. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 16128/60000][Iteration 8568][Wall Clock 782.155791929s] Trained 128 records in 0.08639429 seconds. Throughput is 1481.5795 records/second. Loss is 0.16470832. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036854131348124123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 16256/60000][Iteration 8569][Wall Clock 782.230112468s] Trained 128 records in 0.074320539 seconds. Throughput is 1722.2695 records/second. Loss is 0.100880906. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036851415094339623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 16384/60000][Iteration 8570][Wall Clock 782.312001821s] Trained 128 records in 0.081889353 seconds. Throughput is 1563.0847 records/second. Loss is 0.18676749. Sequential31006cbd's hyper parameters: Current learning rate is 0.00368486992409168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 16512/60000][Iteration 8571][Wall Clock 782.391122841s] Trained 128 records in 0.07912102 seconds. Throughput is 1617.7748 records/second. Loss is 0.13638905. Sequential31006cbd's hyper parameters: Current learning rate is 0.003684598378776713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:39 INFO  DistriOptimizer$:408 - [Epoch 19 16640/60000][Iteration 8572][Wall Clock 782.464255156s] Trained 128 records in 0.073132315 seconds. Throughput is 1750.2523 records/second. Loss is 0.1770209. Sequential31006cbd's hyper parameters: Current learning rate is 0.003684326873480215. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 16768/60000][Iteration 8573][Wall Clock 782.557727913s] Trained 128 records in 0.093472757 seconds. Throughput is 1369.3829 records/second. Loss is 0.14734547. Sequential31006cbd's hyper parameters: Current learning rate is 0.003684055408193339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 16896/60000][Iteration 8574][Wall Clock 782.659292651s] Trained 128 records in 0.101564738 seconds. Throughput is 1260.2799 records/second. Loss is 0.16101262. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036837839829072425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17024/60000][Iteration 8575][Wall Clock 782.736071139s] Trained 128 records in 0.076778488 seconds. Throughput is 1667.1337 records/second. Loss is 0.15187837. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036835125976130835. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17152/60000][Iteration 8576][Wall Clock 782.825020846s] Trained 128 records in 0.088949707 seconds. Throughput is 1439.0154 records/second. Loss is 0.11028808. Sequential31006cbd's hyper parameters: Current learning rate is 0.003683241252302026. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17280/60000][Iteration 8577][Wall Clock 782.904366268s] Trained 128 records in 0.079345422 seconds. Throughput is 1613.1996 records/second. Loss is 0.15173773. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036829699469652323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17408/60000][Iteration 8578][Wall Clock 782.98472763s] Trained 128 records in 0.080361362 seconds. Throughput is 1592.8053 records/second. Loss is 0.1914486. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036826986815938724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17536/60000][Iteration 8579][Wall Clock 783.066754625s] Trained 128 records in 0.082026995 seconds. Throughput is 1560.4619 records/second. Loss is 0.1843206. Sequential31006cbd's hyper parameters: Current learning rate is 0.003682427456179113. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17664/60000][Iteration 8580][Wall Clock 783.145330642s] Trained 128 records in 0.078576017 seconds. Throughput is 1628.9958 records/second. Loss is 0.1650793. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036821562707121296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17792/60000][Iteration 8581][Wall Clock 783.226109549s] Trained 128 records in 0.080778907 seconds. Throughput is 1584.5721 records/second. Loss is 0.14255089. Sequential31006cbd's hyper parameters: Current learning rate is 0.003681885125184094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 17920/60000][Iteration 8582][Wall Clock 783.302368433s] Trained 128 records in 0.076258884 seconds. Throughput is 1678.493 records/second. Loss is 0.23811501. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036816140195861866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 18048/60000][Iteration 8583][Wall Clock 783.379349525s] Trained 128 records in 0.076981092 seconds. Throughput is 1662.746 records/second. Loss is 0.17025444. Sequential31006cbd's hyper parameters: Current learning rate is 0.003681342953909586. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:40 INFO  DistriOptimizer$:408 - [Epoch 19 18176/60000][Iteration 8584][Wall Clock 783.457554943s] Trained 128 records in 0.078205418 seconds. Throughput is 1636.7152 records/second. Loss is 0.21277073. Sequential31006cbd's hyper parameters: Current learning rate is 0.003681071928145476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 18304/60000][Iteration 8585][Wall Clock 783.535779198s] Trained 128 records in 0.078224255 seconds. Throughput is 1636.321 records/second. Loss is 0.11092092. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036808009422850414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 18432/60000][Iteration 8586][Wall Clock 783.616349199s] Trained 128 records in 0.080570001 seconds. Throughput is 1588.6807 records/second. Loss is 0.18458246. Sequential31006cbd's hyper parameters: Current learning rate is 0.00368052999631947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 18560/60000][Iteration 8587][Wall Clock 783.6957309s] Trained 128 records in 0.079381701 seconds. Throughput is 1612.4623 records/second. Loss is 0.1228009. Sequential31006cbd's hyper parameters: Current learning rate is 0.003680259090239953. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 18688/60000][Iteration 8588][Wall Clock 783.770170459s] Trained 128 records in 0.074439559 seconds. Throughput is 1719.5159 records/second. Loss is 0.18711688. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036799882240376833. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 18816/60000][Iteration 8589][Wall Clock 783.845165798s] Trained 128 records in 0.074995339 seconds. Throughput is 1706.7727 records/second. Loss is 0.16673155. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036797173977038563. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 18944/60000][Iteration 8590][Wall Clock 783.922671427s] Trained 128 records in 0.077505629 seconds. Throughput is 1651.493 records/second. Loss is 0.14369428. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036794466112296713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19072/60000][Iteration 8591][Wall Clock 784.001839351s] Trained 128 records in 0.079167924 seconds. Throughput is 1616.8164 records/second. Loss is 0.12057318. Sequential31006cbd's hyper parameters: Current learning rate is 0.003679175864606328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19200/60000][Iteration 8592][Wall Clock 784.095846182s] Trained 128 records in 0.094006831 seconds. Throughput is 1361.6031 records/second. Loss is 0.1186146. Sequential31006cbd's hyper parameters: Current learning rate is 0.003678905157825031. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19328/60000][Iteration 8593][Wall Clock 784.172689489s] Trained 128 records in 0.076843307 seconds. Throughput is 1665.7274 records/second. Loss is 0.09249809. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036786344908769867. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19456/60000][Iteration 8594][Wall Clock 784.246138337s] Trained 128 records in 0.073448848 seconds. Throughput is 1742.7094 records/second. Loss is 0.11241774. Sequential31006cbd's hyper parameters: Current learning rate is 0.003678363863753402. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19584/60000][Iteration 8595][Wall Clock 784.331190331s] Trained 128 records in 0.085051994 seconds. Throughput is 1504.9618 records/second. Loss is 0.17442825. Sequential31006cbd's hyper parameters: Current learning rate is 0.003678093276445491. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19712/60000][Iteration 8596][Wall Clock 784.426484926s] Trained 128 records in 0.095294595 seconds. Throughput is 1343.2031 records/second. Loss is 0.112794474. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036778227289444645. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:41 INFO  DistriOptimizer$:408 - [Epoch 19 19840/60000][Iteration 8597][Wall Clock 784.502722263s] Trained 128 records in 0.076237337 seconds. Throughput is 1678.9674 records/second. Loss is 0.14879182. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036775522212415417. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 19968/60000][Iteration 8598][Wall Clock 784.580992144s] Trained 128 records in 0.078269881 seconds. Throughput is 1635.3672 records/second. Loss is 0.14008683. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036772817533279397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20096/60000][Iteration 8599][Wall Clock 784.655630759s] Trained 128 records in 0.074638615 seconds. Throughput is 1714.93 records/second. Loss is 0.09518783. Sequential31006cbd's hyper parameters: Current learning rate is 0.003677011325194882. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20224/60000][Iteration 8600][Wall Clock 784.746125769s] Trained 128 records in 0.09049501 seconds. Throughput is 1414.4426 records/second. Loss is 0.18659419. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036767409368335907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20352/60000][Iteration 8601][Wall Clock 784.82413357s] Trained 128 records in 0.078007801 seconds. Throughput is 1640.8615 records/second. Loss is 0.18367991. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036764705882352945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20480/60000][Iteration 8602][Wall Clock 784.902918349s] Trained 128 records in 0.078784779 seconds. Throughput is 1624.6793 records/second. Loss is 0.09846799. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036762002793912212. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20608/60000][Iteration 8603][Wall Clock 784.984412469s] Trained 128 records in 0.08149412 seconds. Throughput is 1570.6654 records/second. Loss is 0.2961807. Sequential31006cbd's hyper parameters: Current learning rate is 0.003675930010292604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20736/60000][Iteration 8604][Wall Clock 785.061531188s] Trained 128 records in 0.077118719 seconds. Throughput is 1659.7787 records/second. Loss is 0.14766413. Sequential31006cbd's hyper parameters: Current learning rate is 0.003675659780930677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20864/60000][Iteration 8605][Wall Clock 785.139750618s] Trained 128 records in 0.07821943 seconds. Throughput is 1636.4221 records/second. Loss is 0.15595174. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036753895912966772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 20992/60000][Iteration 8606][Wall Clock 785.218201973s] Trained 128 records in 0.078451355 seconds. Throughput is 1631.5842 records/second. Loss is 0.14368775. Sequential31006cbd's hyper parameters: Current learning rate is 0.003675119441381845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 21120/60000][Iteration 8607][Wall Clock 785.289212462s] Trained 128 records in 0.071010489 seconds. Throughput is 1802.5507 records/second. Loss is 0.12684767. Sequential31006cbd's hyper parameters: Current learning rate is 0.003674849331177422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 21248/60000][Iteration 8608][Wall Clock 785.365359039s] Trained 128 records in 0.076146577 seconds. Throughput is 1680.9685 records/second. Loss is 0.09094444. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036745792606746527. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 21376/60000][Iteration 8609][Wall Clock 785.440282636s] Trained 128 records in 0.074923597 seconds. Throughput is 1708.407 records/second. Loss is 0.15474409. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036743092298647854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:42 INFO  DistriOptimizer$:408 - [Epoch 19 21504/60000][Iteration 8610][Wall Clock 785.511990522s] Trained 128 records in 0.071707886 seconds. Throughput is 1785.0198 records/second. Loss is 0.105367295. Sequential31006cbd's hyper parameters: Current learning rate is 0.00367403923873907. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 21632/60000][Iteration 8611][Wall Clock 785.584861839s] Trained 128 records in 0.072871317 seconds. Throughput is 1756.521 records/second. Loss is 0.09948143. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036737692872887582. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 21760/60000][Iteration 8612][Wall Clock 785.657152916s] Trained 128 records in 0.072291077 seconds. Throughput is 1770.6196 records/second. Loss is 0.1850191. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036734993755051064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 21888/60000][Iteration 8613][Wall Clock 785.742874541s] Trained 128 records in 0.085721625 seconds. Throughput is 1493.2054 records/second. Loss is 0.11733231. Sequential31006cbd's hyper parameters: Current learning rate is 0.003673229503379371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22016/60000][Iteration 8614][Wall Clock 785.830548727s] Trained 128 records in 0.087674186 seconds. Throughput is 1459.9508 records/second. Loss is 0.09261496. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036729596709028137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22144/60000][Iteration 8615][Wall Clock 785.910929242s] Trained 128 records in 0.080380515 seconds. Throughput is 1592.4258 records/second. Loss is 0.13035093. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036726898780666956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22272/60000][Iteration 8616][Wall Clock 786.012598859s] Trained 128 records in 0.101669617 seconds. Throughput is 1258.9799 records/second. Loss is 0.097887754. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036724201248622846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22400/60000][Iteration 8617][Wall Clock 786.106454105s] Trained 128 records in 0.093855246 seconds. Throughput is 1363.8022 records/second. Loss is 0.1416595. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036721504112808456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22528/60000][Iteration 8618][Wall Clock 786.18970303s] Trained 128 records in 0.083248925 seconds. Throughput is 1537.5574 records/second. Loss is 0.08319409. Sequential31006cbd's hyper parameters: Current learning rate is 0.003671880737313652. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22656/60000][Iteration 8619][Wall Clock 786.282466108s] Trained 128 records in 0.092763078 seconds. Throughput is 1379.8593 records/second. Loss is 0.099935375. Sequential31006cbd's hyper parameters: Current learning rate is 0.003671611102951975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22784/60000][Iteration 8620][Wall Clock 786.356491087s] Trained 128 records in 0.074024979 seconds. Throughput is 1729.1461 records/second. Loss is 0.19121987. Sequential31006cbd's hyper parameters: Current learning rate is 0.003671341508187092. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:43 INFO  DistriOptimizer$:408 - [Epoch 19 22912/60000][Iteration 8621][Wall Clock 786.442201386s] Trained 128 records in 0.085710299 seconds. Throughput is 1493.4027 records/second. Loss is 0.13442114. Sequential31006cbd's hyper parameters: Current learning rate is 0.003671071953010279. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23040/60000][Iteration 8622][Wall Clock 786.518777479s] Trained 128 records in 0.076576093 seconds. Throughput is 1671.54 records/second. Loss is 0.17692852. Sequential31006cbd's hyper parameters: Current learning rate is 0.003670802437412818. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23168/60000][Iteration 8623][Wall Clock 786.591006937s] Trained 128 records in 0.072229458 seconds. Throughput is 1772.1301 records/second. Loss is 0.25823388. Sequential31006cbd's hyper parameters: Current learning rate is 0.003670532961385993. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23296/60000][Iteration 8624][Wall Clock 786.667636002s] Trained 128 records in 0.076629065 seconds. Throughput is 1670.3845 records/second. Loss is 0.16421719. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036702635249210892. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23424/60000][Iteration 8625][Wall Clock 786.764114697s] Trained 128 records in 0.096478695 seconds. Throughput is 1326.7178 records/second. Loss is 0.2150171. Sequential31006cbd's hyper parameters: Current learning rate is 0.003669994128009395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23552/60000][Iteration 8626][Wall Clock 786.845345909s] Trained 128 records in 0.081231212 seconds. Throughput is 1575.7489 records/second. Loss is 0.13336265. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036697247706422016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23680/60000][Iteration 8627][Wall Clock 786.931172112s] Trained 128 records in 0.085826203 seconds. Throughput is 1491.386 records/second. Loss is 0.12936647. Sequential31006cbd's hyper parameters: Current learning rate is 0.003669455452810803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23808/60000][Iteration 8628][Wall Clock 787.044002931s] Trained 128 records in 0.112830819 seconds. Throughput is 1134.4419 records/second. Loss is 0.18613629. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036691861745064944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 23936/60000][Iteration 8629][Wall Clock 787.138441406s] Trained 128 records in 0.094438475 seconds. Throughput is 1355.3798 records/second. Loss is 0.17586938. Sequential31006cbd's hyper parameters: Current learning rate is 0.003668916935720575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 24064/60000][Iteration 8630][Wall Clock 787.236829566s] Trained 128 records in 0.09838816 seconds. Throughput is 1300.9696 records/second. Loss is 0.28966525. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036686477364443466. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 24192/60000][Iteration 8631][Wall Clock 787.311965788s] Trained 128 records in 0.075136222 seconds. Throughput is 1703.5725 records/second. Loss is 0.11224571. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036683785766691126. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 24320/60000][Iteration 8632][Wall Clock 787.387874805s] Trained 128 records in 0.075909017 seconds. Throughput is 1686.2291 records/second. Loss is 0.1875303. Sequential31006cbd's hyper parameters: Current learning rate is 0.003668109456386178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:44 INFO  DistriOptimizer$:408 - [Epoch 19 24448/60000][Iteration 8633][Wall Clock 787.475740865s] Trained 128 records in 0.08786606 seconds. Throughput is 1456.7627 records/second. Loss is 0.15015018. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036678403755868545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 24576/60000][Iteration 8634][Wall Clock 787.55693325s] Trained 128 records in 0.081192385 seconds. Throughput is 1576.5026 records/second. Loss is 0.10387571. Sequential31006cbd's hyper parameters: Current learning rate is 0.003667571334262451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 24704/60000][Iteration 8635][Wall Clock 787.636709737s] Trained 128 records in 0.079776487 seconds. Throughput is 1604.4828 records/second. Loss is 0.20537308. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036673023324042837. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 24832/60000][Iteration 8636][Wall Clock 787.715824227s] Trained 128 records in 0.07911449 seconds. Throughput is 1617.9084 records/second. Loss is 0.17323646. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036670333700036667. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 24960/60000][Iteration 8637][Wall Clock 787.791332655s] Trained 128 records in 0.075508428 seconds. Throughput is 1695.1749 records/second. Loss is 0.24415946. Sequential31006cbd's hyper parameters: Current learning rate is 0.003666764447051922. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25088/60000][Iteration 8638][Wall Clock 787.872941066s] Trained 128 records in 0.081608411 seconds. Throughput is 1568.4657 records/second. Loss is 0.09890766. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036664955635403677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25216/60000][Iteration 8639][Wall Clock 787.947246045s] Trained 128 records in 0.074304979 seconds. Throughput is 1722.6302 records/second. Loss is 0.09288842. Sequential31006cbd's hyper parameters: Current learning rate is 0.003666226719460332. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25344/60000][Iteration 8640][Wall Clock 788.021574865s] Trained 128 records in 0.07432882 seconds. Throughput is 1722.0778 records/second. Loss is 0.12301421. Sequential31006cbd's hyper parameters: Current learning rate is 0.003665957914803138. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25472/60000][Iteration 8641][Wall Clock 788.098348375s] Trained 128 records in 0.07677351 seconds. Throughput is 1667.2417 records/second. Loss is 0.17511016. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036656891495601175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25600/60000][Iteration 8642][Wall Clock 788.184914462s] Trained 128 records in 0.086566087 seconds. Throughput is 1478.639 records/second. Loss is 0.19628751. Sequential31006cbd's hyper parameters: Current learning rate is 0.003665420423722601. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25728/60000][Iteration 8643][Wall Clock 788.284595547s] Trained 128 records in 0.099681085 seconds. Throughput is 1284.0951 records/second. Loss is 0.14206089. Sequential31006cbd's hyper parameters: Current learning rate is 0.003665151737281923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25856/60000][Iteration 8644][Wall Clock 788.356603502s] Trained 128 records in 0.072007955 seconds. Throughput is 1777.5814 records/second. Loss is 0.14355585. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036648830902294214. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:45 INFO  DistriOptimizer$:408 - [Epoch 19 25984/60000][Iteration 8645][Wall Clock 788.427297615s] Trained 128 records in 0.070694113 seconds. Throughput is 1810.6176 records/second. Loss is 0.26411527. Sequential31006cbd's hyper parameters: Current learning rate is 0.003664614482556435. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26112/60000][Iteration 8646][Wall Clock 788.505569362s] Trained 128 records in 0.078271747 seconds. Throughput is 1635.3282 records/second. Loss is 0.17668697. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036643459142543054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26240/60000][Iteration 8647][Wall Clock 788.584148684s] Trained 128 records in 0.078579322 seconds. Throughput is 1628.9272 records/second. Loss is 0.08024233. Sequential31006cbd's hyper parameters: Current learning rate is 0.003664077385314378. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26368/60000][Iteration 8648][Wall Clock 788.663208672s] Trained 128 records in 0.079059988 seconds. Throughput is 1619.0238 records/second. Loss is 0.13920125. Sequential31006cbd's hyper parameters: Current learning rate is 0.003663808895727999. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26496/60000][Iteration 8649][Wall Clock 788.742741894s] Trained 128 records in 0.079533222 seconds. Throughput is 1609.3904 records/second. Loss is 0.14849344. Sequential31006cbd's hyper parameters: Current learning rate is 0.003663540445486518. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26624/60000][Iteration 8650][Wall Clock 788.824480605s] Trained 128 records in 0.081738711 seconds. Throughput is 1565.9655 records/second. Loss is 0.13677025. Sequential31006cbd's hyper parameters: Current learning rate is 0.003663272034581288. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26752/60000][Iteration 8651][Wall Clock 788.906423098s] Trained 128 records in 0.081942493 seconds. Throughput is 1562.0712 records/second. Loss is 0.22260466. Sequential31006cbd's hyper parameters: Current learning rate is 0.003663003663003663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 26880/60000][Iteration 8652][Wall Clock 788.975639163s] Trained 128 records in 0.069216065 seconds. Throughput is 1849.2816 records/second. Loss is 0.1601856. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036627353307450007. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 27008/60000][Iteration 8653][Wall Clock 789.051446934s] Trained 128 records in 0.075807771 seconds. Throughput is 1688.4812 records/second. Loss is 0.10263799. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036624670377966594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 27136/60000][Iteration 8654][Wall Clock 789.128034787s] Trained 128 records in 0.076587853 seconds. Throughput is 1671.2832 records/second. Loss is 0.20817196. Sequential31006cbd's hyper parameters: Current learning rate is 0.003662198784150004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 27264/60000][Iteration 8655][Wall Clock 789.202917656s] Trained 128 records in 0.074882869 seconds. Throughput is 1709.3362 records/second. Loss is 0.1573541. Sequential31006cbd's hyper parameters: Current learning rate is 0.003661930569796396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 27392/60000][Iteration 8656][Wall Clock 789.288243753s] Trained 128 records in 0.085326097 seconds. Throughput is 1500.1272 records/second. Loss is 0.2412172. Sequential31006cbd's hyper parameters: Current learning rate is 0.003661662394727206. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 27520/60000][Iteration 8657][Wall Clock 789.375310747s] Trained 128 records in 0.087066994 seconds. Throughput is 1470.1323 records/second. Loss is 0.08988016. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036613942589338016. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:46 INFO  DistriOptimizer$:408 - [Epoch 19 27648/60000][Iteration 8658][Wall Clock 789.462167799s] Trained 128 records in 0.086857052 seconds. Throughput is 1473.6858 records/second. Loss is 0.16634601. Sequential31006cbd's hyper parameters: Current learning rate is 0.003661126162407557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 27776/60000][Iteration 8659][Wall Clock 789.544470131s] Trained 128 records in 0.082302332 seconds. Throughput is 1555.2415 records/second. Loss is 0.15373594. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036608581051398447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 27904/60000][Iteration 8660][Wall Clock 789.62987163s] Trained 128 records in 0.085401499 seconds. Throughput is 1498.8027 records/second. Loss is 0.21338317. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036605900871220444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28032/60000][Iteration 8661][Wall Clock 789.709506151s] Trained 128 records in 0.079634521 seconds. Throughput is 1607.3431 records/second. Loss is 0.17306545. Sequential31006cbd's hyper parameters: Current learning rate is 0.003660322108345534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28160/60000][Iteration 8662][Wall Clock 789.792251384s] Trained 128 records in 0.082745233 seconds. Throughput is 1546.917 records/second. Loss is 0.107395984. Sequential31006cbd's hyper parameters: Current learning rate is 0.003660054168801698. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28288/60000][Iteration 8663][Wall Clock 789.874495621s] Trained 128 records in 0.082244237 seconds. Throughput is 1556.34 records/second. Loss is 0.16991526. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036597862684819207. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28416/60000][Iteration 8664][Wall Clock 789.957808727s] Trained 128 records in 0.083313106 seconds. Throughput is 1536.3729 records/second. Loss is 0.12927157. Sequential31006cbd's hyper parameters: Current learning rate is 0.003659518407377589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28544/60000][Iteration 8665][Wall Clock 790.032192799s] Trained 128 records in 0.074384072 seconds. Throughput is 1720.7986 records/second. Loss is 0.18082738. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036592505854800934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28672/60000][Iteration 8666][Wall Clock 790.112943888s] Trained 128 records in 0.080751089 seconds. Throughput is 1585.1179 records/second. Loss is 0.17475215. Sequential31006cbd's hyper parameters: Current learning rate is 0.003658982802780827. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28800/60000][Iteration 8667][Wall Clock 790.210760332s] Trained 128 records in 0.097816444 seconds. Throughput is 1308.5734 records/second. Loss is 0.12706786. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036587150592711838. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 28928/60000][Iteration 8668][Wall Clock 790.304360078s] Trained 128 records in 0.093599746 seconds. Throughput is 1367.5251 records/second. Loss is 0.1316544. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036584473549425623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 29056/60000][Iteration 8669][Wall Clock 790.371548909s] Trained 128 records in 0.067188831 seconds. Throughput is 1905.0786 records/second. Loss is 0.0940318. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036581796897863623. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:47 INFO  DistriOptimizer$:408 - [Epoch 19 29184/60000][Iteration 8670][Wall Clock 790.455603819s] Trained 128 records in 0.08405491 seconds. Throughput is 1522.8141 records/second. Loss is 0.21129826. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036579120637939863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 29312/60000][Iteration 8671][Wall Clock 790.544889073s] Trained 128 records in 0.089285254 seconds. Throughput is 1433.6074 records/second. Loss is 0.10675312. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036576444769568397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 29440/60000][Iteration 8672][Wall Clock 790.623601501s] Trained 128 records in 0.078712428 seconds. Throughput is 1626.1727 records/second. Loss is 0.12519878. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036573769292663296. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 29568/60000][Iteration 8673][Wall Clock 790.704590244s] Trained 128 records in 0.080988743 seconds. Throughput is 1580.4666 records/second. Loss is 0.1551633. Sequential31006cbd's hyper parameters: Current learning rate is 0.003657109420713868. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 29696/60000][Iteration 8674][Wall Clock 790.785291511s] Trained 128 records in 0.080701267 seconds. Throughput is 1586.0964 records/second. Loss is 0.1388044. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036568419512908647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 29824/60000][Iteration 8675][Wall Clock 790.872596293s] Trained 128 records in 0.087304782 seconds. Throughput is 1466.1282 records/second. Loss is 0.19247107. Sequential31006cbd's hyper parameters: Current learning rate is 0.003656574520988738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 29952/60000][Iteration 8676][Wall Clock 790.946793447s] Trained 128 records in 0.074197154 seconds. Throughput is 1725.1337 records/second. Loss is 0.10988625. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036563071297989027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 30080/60000][Iteration 8677][Wall Clock 791.036547738s] Trained 128 records in 0.089754291 seconds. Throughput is 1426.1157 records/second. Loss is 0.15186411. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036560397777127816. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 30208/60000][Iteration 8678][Wall Clock 791.163685494s] Trained 128 records in 0.127137756 seconds. Throughput is 1006.782 records/second. Loss is 0.11951563. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036557724647217956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 30336/60000][Iteration 8679][Wall Clock 791.252354002s] Trained 128 records in 0.088668508 seconds. Throughput is 1443.579 records/second. Loss is 0.1454796. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036555051908173713. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 30464/60000][Iteration 8680][Wall Clock 791.355377184s] Trained 128 records in 0.103023182 seconds. Throughput is 1242.4388 records/second. Loss is 0.2240203. Sequential31006cbd's hyper parameters: Current learning rate is 0.003655237955990935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:48 INFO  DistriOptimizer$:408 - [Epoch 19 30592/60000][Iteration 8681][Wall Clock 791.439470772s] Trained 128 records in 0.084093588 seconds. Throughput is 1522.1138 records/second. Loss is 0.18186995. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036549707602339184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 30720/60000][Iteration 8682][Wall Clock 791.529926235s] Trained 128 records in 0.090455463 seconds. Throughput is 1415.061 records/second. Loss is 0.12405434. Sequential31006cbd's hyper parameters: Current learning rate is 0.003654703603537753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 30848/60000][Iteration 8683][Wall Clock 791.622540646s] Trained 128 records in 0.092614411 seconds. Throughput is 1382.0743 records/second. Loss is 0.14207372. Sequential31006cbd's hyper parameters: Current learning rate is 0.003654436485893875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 30976/60000][Iteration 8684][Wall Clock 791.699085939s] Trained 128 records in 0.076545293 seconds. Throughput is 1672.2126 records/second. Loss is 0.1308713. Sequential31006cbd's hyper parameters: Current learning rate is 0.003654169407293722. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31104/60000][Iteration 8685][Wall Clock 791.779626739s] Trained 128 records in 0.0805408 seconds. Throughput is 1589.2566 records/second. Loss is 0.20458509. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036539023677287343. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31232/60000][Iteration 8686][Wall Clock 791.854000316s] Trained 128 records in 0.074373577 seconds. Throughput is 1721.0413 records/second. Loss is 0.22890824. Sequential31006cbd's hyper parameters: Current learning rate is 0.003653635367190354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31360/60000][Iteration 8687][Wall Clock 791.928822086s] Trained 128 records in 0.07482177 seconds. Throughput is 1710.732 records/second. Loss is 0.19615799. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036533684056700277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31488/60000][Iteration 8688][Wall Clock 792.003662808s] Trained 128 records in 0.074840722 seconds. Throughput is 1710.2988 records/second. Loss is 0.1125989. Sequential31006cbd's hyper parameters: Current learning rate is 0.003653101483159202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31616/60000][Iteration 8689][Wall Clock 792.075453094s] Trained 128 records in 0.071790286 seconds. Throughput is 1782.9711 records/second. Loss is 0.18567233. Sequential31006cbd's hyper parameters: Current learning rate is 0.003652834599649328. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31744/60000][Iteration 8690][Wall Clock 792.15218667s] Trained 128 records in 0.076733576 seconds. Throughput is 1668.1095 records/second. Loss is 0.20612529. Sequential31006cbd's hyper parameters: Current learning rate is 0.003652567755131858. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 31872/60000][Iteration 8691][Wall Clock 792.243945975s] Trained 128 records in 0.091759305 seconds. Throughput is 1394.954 records/second. Loss is 0.049936052. Sequential31006cbd's hyper parameters: Current learning rate is 0.003652300949598247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 32000/60000][Iteration 8692][Wall Clock 792.339837672s] Trained 128 records in 0.095891697 seconds. Throughput is 1334.8392 records/second. Loss is 0.22942203. Sequential31006cbd's hyper parameters: Current learning rate is 0.003652034183039953. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:49 INFO  DistriOptimizer$:408 - [Epoch 19 32128/60000][Iteration 8693][Wall Clock 792.418434412s] Trained 128 records in 0.07859674 seconds. Throughput is 1628.5663 records/second. Loss is 0.25084406. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036517674554484366. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 32256/60000][Iteration 8694][Wall Clock 792.514309687s] Trained 128 records in 0.095875275 seconds. Throughput is 1335.0679 records/second. Loss is 0.17173877. Sequential31006cbd's hyper parameters: Current learning rate is 0.003651500766815161. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 32384/60000][Iteration 8695][Wall Clock 792.596289399s] Trained 128 records in 0.081979712 seconds. Throughput is 1561.3618 records/second. Loss is 0.15802509. Sequential31006cbd's hyper parameters: Current learning rate is 0.00365123411713159. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 32512/60000][Iteration 8696][Wall Clock 792.672109051s] Trained 128 records in 0.075819652 seconds. Throughput is 1688.2167 records/second. Loss is 0.15089156. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036509675063891934. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 32640/60000][Iteration 8697][Wall Clock 792.744251125s] Trained 128 records in 0.072142074 seconds. Throughput is 1774.2767 records/second. Loss is 0.1981019. Sequential31006cbd's hyper parameters: Current learning rate is 0.003650700934579439. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 32768/60000][Iteration 8698][Wall Clock 792.817252388s] Trained 128 records in 0.073001263 seconds. Throughput is 1753.3943 records/second. Loss is 0.14162269. Sequential31006cbd's hyper parameters: Current learning rate is 0.003650434401693802. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 32896/60000][Iteration 8699][Wall Clock 792.891323132s] Trained 128 records in 0.074070744 seconds. Throughput is 1728.0776 records/second. Loss is 0.13138926. Sequential31006cbd's hyper parameters: Current learning rate is 0.003650167907723755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33024/60000][Iteration 8700][Wall Clock 792.968358529s] Trained 128 records in 0.077035397 seconds. Throughput is 1661.5739 records/second. Loss is 0.19864464. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036499014526607783. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33152/60000][Iteration 8701][Wall Clock 793.043211006s] Trained 128 records in 0.074852477 seconds. Throughput is 1710.0303 records/second. Loss is 0.17438765. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036496350364963502. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33280/60000][Iteration 8702][Wall Clock 793.128594536s] Trained 128 records in 0.08538353 seconds. Throughput is 1499.1182 records/second. Loss is 0.16718069. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036493686592219544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33408/60000][Iteration 8703][Wall Clock 793.211210018s] Trained 128 records in 0.082615482 seconds. Throughput is 1549.3464 records/second. Loss is 0.14742477. Sequential31006cbd's hyper parameters: Current learning rate is 0.003649102320829076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33536/60000][Iteration 8704][Wall Clock 793.29694493s] Trained 128 records in 0.085734912 seconds. Throughput is 1492.9741 records/second. Loss is 0.13606426. Sequential31006cbd's hyper parameters: Current learning rate is 0.003648836021309202. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33664/60000][Iteration 8705][Wall Clock 793.385552304s] Trained 128 records in 0.088607374 seconds. Throughput is 1444.5751 records/second. Loss is 0.16083354. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036485697606538237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:50 INFO  DistriOptimizer$:408 - [Epoch 19 33792/60000][Iteration 8706][Wall Clock 793.460805946s] Trained 128 records in 0.075253642 seconds. Throughput is 1700.9143 records/second. Loss is 0.16191512. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036483035388544327. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 33920/60000][Iteration 8707][Wall Clock 793.532898028s] Trained 128 records in 0.072092082 seconds. Throughput is 1775.5071 records/second. Loss is 0.13884303. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036480373559025243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34048/60000][Iteration 8708][Wall Clock 793.613093264s] Trained 128 records in 0.080195236 seconds. Throughput is 1596.1049 records/second. Loss is 0.1321427. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036477712117895965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34176/60000][Iteration 8709][Wall Clock 793.695625709s] Trained 128 records in 0.082532445 seconds. Throughput is 1550.9053 records/second. Loss is 0.12732528. Sequential31006cbd's hyper parameters: Current learning rate is 0.003647505106507149. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34304/60000][Iteration 8710][Wall Clock 793.776805514s] Trained 128 records in 0.081179805 seconds. Throughput is 1576.7468 records/second. Loss is 0.16132239. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036472390400466848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34432/60000][Iteration 8711][Wall Clock 793.854393617s] Trained 128 records in 0.077588103 seconds. Throughput is 1649.7374 records/second. Loss is 0.13859111. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036469730123997084. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34560/60000][Iteration 8712][Wall Clock 793.939790208s] Trained 128 records in 0.085396591 seconds. Throughput is 1498.8889 records/second. Loss is 0.145042. Sequential31006cbd's hyper parameters: Current learning rate is 0.003646707023557727. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34688/60000][Iteration 8713][Wall Clock 794.02387869s] Trained 128 records in 0.084088482 seconds. Throughput is 1522.206 records/second. Loss is 0.20702103. Sequential31006cbd's hyper parameters: Current learning rate is 0.003646441073512252. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34816/60000][Iteration 8714][Wall Clock 794.104713321s] Trained 128 records in 0.080834631 seconds. Throughput is 1583.4796 records/second. Loss is 0.13419457. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036461751622547944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 34944/60000][Iteration 8715][Wall Clock 794.183949114s] Trained 128 records in 0.079235793 seconds. Throughput is 1615.4315 records/second. Loss is 0.30030233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036459092897768706. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 35072/60000][Iteration 8716][Wall Clock 794.264416081s] Trained 128 records in 0.080466967 seconds. Throughput is 1590.715 records/second. Loss is 0.13445318. Sequential31006cbd's hyper parameters: Current learning rate is 0.003645643456069996. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 35200/60000][Iteration 8717][Wall Clock 794.367925028s] Trained 128 records in 0.103508947 seconds. Throughput is 1236.608 records/second. Loss is 0.17060617. Sequential31006cbd's hyper parameters: Current learning rate is 0.003645377661125693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:51 INFO  DistriOptimizer$:408 - [Epoch 19 35328/60000][Iteration 8718][Wall Clock 794.470736422s] Trained 128 records in 0.102811394 seconds. Throughput is 1244.9982 records/second. Loss is 0.13579246. Sequential31006cbd's hyper parameters: Current learning rate is 0.003645111904935481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 35456/60000][Iteration 8719][Wall Clock 794.553636557s] Trained 128 records in 0.082900135 seconds. Throughput is 1544.0264 records/second. Loss is 0.13549656. Sequential31006cbd's hyper parameters: Current learning rate is 0.003644846187490888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 35584/60000][Iteration 8720][Wall Clock 794.619860805s] Trained 128 records in 0.066224248 seconds. Throughput is 1932.8268 records/second. Loss is 0.12758896. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036445805087834387. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 35712/60000][Iteration 8721][Wall Clock 794.699291096s] Trained 128 records in 0.079430291 seconds. Throughput is 1611.476 records/second. Loss is 0.1219472. Sequential31006cbd's hyper parameters: Current learning rate is 0.003644314868804665. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 35840/60000][Iteration 8722][Wall Clock 794.773997154s] Trained 128 records in 0.074706058 seconds. Throughput is 1713.3818 records/second. Loss is 0.1835554. Sequential31006cbd's hyper parameters: Current learning rate is 0.003644049267546097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 35968/60000][Iteration 8723][Wall Clock 794.849467659s] Trained 128 records in 0.075470505 seconds. Throughput is 1696.0267 records/second. Loss is 0.11647132. Sequential31006cbd's hyper parameters: Current learning rate is 0.003643783704999271. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36096/60000][Iteration 8724][Wall Clock 794.924670108s] Trained 128 records in 0.075202449 seconds. Throughput is 1702.0721 records/second. Loss is 0.19328791. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036435181811557238. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36224/60000][Iteration 8725][Wall Clock 795.000133263s] Trained 128 records in 0.075463155 seconds. Throughput is 1696.192 records/second. Loss is 0.11627885. Sequential31006cbd's hyper parameters: Current learning rate is 0.003643252696006995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36352/60000][Iteration 8726][Wall Clock 795.079492999s] Trained 128 records in 0.079359736 seconds. Throughput is 1612.9087 records/second. Loss is 0.11829658. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036429872495446266. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36480/60000][Iteration 8727][Wall Clock 795.160010102s] Trained 128 records in 0.080517103 seconds. Throughput is 1589.7244 records/second. Loss is 0.18644333. Sequential31006cbd's hyper parameters: Current learning rate is 0.003642721841760163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36608/60000][Iteration 8728][Wall Clock 795.250197632s] Trained 128 records in 0.09018753 seconds. Throughput is 1419.265 records/second. Loss is 0.111484736. Sequential31006cbd's hyper parameters: Current learning rate is 0.003642456472645152. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36736/60000][Iteration 8729][Wall Clock 795.333368541s] Trained 128 records in 0.083170909 seconds. Throughput is 1538.9998 records/second. Loss is 0.1600076. Sequential31006cbd's hyper parameters: Current learning rate is 0.003642191142191142. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:52 INFO  DistriOptimizer$:408 - [Epoch 19 36864/60000][Iteration 8730][Wall Clock 795.412152111s] Trained 128 records in 0.07878357 seconds. Throughput is 1624.7042 records/second. Loss is 0.18573838. Sequential31006cbd's hyper parameters: Current learning rate is 0.003641925850389686. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 36992/60000][Iteration 8731][Wall Clock 795.490393114s] Trained 128 records in 0.078241003 seconds. Throughput is 1635.9708 records/second. Loss is 0.09203331. Sequential31006cbd's hyper parameters: Current learning rate is 0.003641660597232338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37120/60000][Iteration 8732][Wall Clock 795.564573223s] Trained 128 records in 0.074180109 seconds. Throughput is 1725.5299 records/second. Loss is 0.15594712. Sequential31006cbd's hyper parameters: Current learning rate is 0.003641395382710655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37248/60000][Iteration 8733][Wall Clock 795.639560898s] Trained 128 records in 0.074987675 seconds. Throughput is 1706.9473 records/second. Loss is 0.12664518. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036411302068161955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37376/60000][Iteration 8734][Wall Clock 795.72450978s] Trained 128 records in 0.084948882 seconds. Throughput is 1506.7885 records/second. Loss is 0.11861855. Sequential31006cbd's hyper parameters: Current learning rate is 0.003640865069540523. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37504/60000][Iteration 8735][Wall Clock 795.80490801s] Trained 128 records in 0.08039823 seconds. Throughput is 1592.0748 records/second. Loss is 0.0916778. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036405999708751997. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37632/60000][Iteration 8736][Wall Clock 795.879691054s] Trained 128 records in 0.074783044 seconds. Throughput is 1711.618 records/second. Loss is 0.16149668. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036403349108117948. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37760/60000][Iteration 8737][Wall Clock 795.964099765s] Trained 128 records in 0.084408711 seconds. Throughput is 1516.4313 records/second. Loss is 0.1892358. Sequential31006cbd's hyper parameters: Current learning rate is 0.003640069889341875. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 37888/60000][Iteration 8738][Wall Clock 796.047349191s] Trained 128 records in 0.083249426 seconds. Throughput is 1537.5481 records/second. Loss is 0.11893655. Sequential31006cbd's hyper parameters: Current learning rate is 0.003639804906457014. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 38016/60000][Iteration 8739][Wall Clock 796.122532249s] Trained 128 records in 0.075183058 seconds. Throughput is 1702.5112 records/second. Loss is 0.11815503. Sequential31006cbd's hyper parameters: Current learning rate is 0.003639539962148784. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 38144/60000][Iteration 8740][Wall Clock 796.197939579s] Trained 128 records in 0.07540733 seconds. Throughput is 1697.4476 records/second. Loss is 0.14705476. Sequential31006cbd's hyper parameters: Current learning rate is 0.003639275056408764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 38272/60000][Iteration 8741][Wall Clock 796.275634612s] Trained 128 records in 0.077695033 seconds. Throughput is 1647.4669 records/second. Loss is 0.14141521. Sequential31006cbd's hyper parameters: Current learning rate is 0.00363901018922853. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 38400/60000][Iteration 8742][Wall Clock 796.371029015s] Trained 128 records in 0.095394403 seconds. Throughput is 1341.7979 records/second. Loss is 0.201673. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036387453605996657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:53 INFO  DistriOptimizer$:408 - [Epoch 19 38528/60000][Iteration 8743][Wall Clock 796.452251747s] Trained 128 records in 0.081222732 seconds. Throughput is 1575.9135 records/second. Loss is 0.15758477. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036384805705137534. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 38656/60000][Iteration 8744][Wall Clock 796.546723208s] Trained 128 records in 0.094471461 seconds. Throughput is 1354.9065 records/second. Loss is 0.1836471. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036382158189623807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 38784/60000][Iteration 8745][Wall Clock 796.617126447s] Trained 128 records in 0.070403239 seconds. Throughput is 1818.0981 records/second. Loss is 0.17167377. Sequential31006cbd's hyper parameters: Current learning rate is 0.003637951105937136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 38912/60000][Iteration 8746][Wall Clock 796.697343279s] Trained 128 records in 0.080216832 seconds. Throughput is 1595.675 records/second. Loss is 0.13821971. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036376864314296106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39040/60000][Iteration 8747][Wall Clock 796.778316976s] Trained 128 records in 0.080973697 seconds. Throughput is 1580.7601 records/second. Loss is 0.16389887. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036374217954313983. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39168/60000][Iteration 8748][Wall Clock 796.858667881s] Trained 128 records in 0.080350905 seconds. Throughput is 1593.0126 records/second. Loss is 0.076180294. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036371571979340947. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39296/60000][Iteration 8749][Wall Clock 796.934960739s] Trained 128 records in 0.076292858 seconds. Throughput is 1677.7455 records/second. Loss is 0.14199123. Sequential31006cbd's hyper parameters: Current learning rate is 0.003636892638929299. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39424/60000][Iteration 8750][Wall Clock 797.013998633s] Trained 128 records in 0.079037894 seconds. Throughput is 1619.4763 records/second. Loss is 0.193324. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036366281184086117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39552/60000][Iteration 8751][Wall Clock 797.098771809s] Trained 128 records in 0.084773176 seconds. Throughput is 1509.9116 records/second. Loss is 0.10987962. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036363636363636364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39680/60000][Iteration 8752][Wall Clock 797.177600432s] Trained 128 records in 0.078828623 seconds. Throughput is 1623.7756 records/second. Loss is 0.15423763. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036360991927859793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39808/60000][Iteration 8753][Wall Clock 797.274272519s] Trained 128 records in 0.096672087 seconds. Throughput is 1324.0637 records/second. Loss is 0.15385923. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036358347876672484. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 39936/60000][Iteration 8754][Wall Clock 797.371861394s] Trained 128 records in 0.097588875 seconds. Throughput is 1311.6249 records/second. Loss is 0.14753385. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036355704209990545. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:54 INFO  DistriOptimizer$:408 - [Epoch 19 40064/60000][Iteration 8755][Wall Clock 797.450949615s] Trained 128 records in 0.079088221 seconds. Throughput is 1618.4459 records/second. Loss is 0.11760506. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036353060927730115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40192/60000][Iteration 8756][Wall Clock 797.535485381s] Trained 128 records in 0.084535766 seconds. Throughput is 1514.1521 records/second. Loss is 0.17428565. Sequential31006cbd's hyper parameters: Current learning rate is 0.003635041802980734. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40320/60000][Iteration 8757][Wall Clock 797.609325296s] Trained 128 records in 0.073839915 seconds. Throughput is 1733.4797 records/second. Loss is 0.16199714. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036347775516138415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40448/60000][Iteration 8758][Wall Clock 797.696921703s] Trained 128 records in 0.087596407 seconds. Throughput is 1461.2471 records/second. Loss is 0.17505276. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036345133386639526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40576/60000][Iteration 8759][Wall Clock 797.783283995s] Trained 128 records in 0.086362292 seconds. Throughput is 1482.1283 records/second. Loss is 0.116724566. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036342491641226924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40704/60000][Iteration 8760][Wall Clock 797.883132111s] Trained 128 records in 0.099848116 seconds. Throughput is 1281.9471 records/second. Loss is 0.11187792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036339850279816844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40832/60000][Iteration 8761][Wall Clock 797.964529349s] Trained 128 records in 0.081397238 seconds. Throughput is 1572.535 records/second. Loss is 0.09804865. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036337209302325585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 40960/60000][Iteration 8762][Wall Clock 798.039314007s] Trained 128 records in 0.074784658 seconds. Throughput is 1711.5809 records/second. Loss is 0.15175268. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036334568708669425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 41088/60000][Iteration 8763][Wall Clock 798.121365695s] Trained 128 records in 0.082051688 seconds. Throughput is 1559.9923 records/second. Loss is 0.19701329. Sequential31006cbd's hyper parameters: Current learning rate is 0.003633192849876471. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 41216/60000][Iteration 8764][Wall Clock 798.198576405s] Trained 128 records in 0.07721071 seconds. Throughput is 1657.8011 records/second. Loss is 0.10427649. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036329288672527793. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 41344/60000][Iteration 8765][Wall Clock 798.277783638s] Trained 128 records in 0.079207233 seconds. Throughput is 1616.014 records/second. Loss is 0.10118038. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036326649229875036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 41472/60000][Iteration 8766][Wall Clock 798.358322563s] Trained 128 records in 0.080538925 seconds. Throughput is 1589.2936 records/second. Loss is 0.18959726. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036324010170722845. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:55 INFO  DistriOptimizer$:408 - [Epoch 19 41600/60000][Iteration 8767][Wall Clock 798.448474119s] Trained 128 records in 0.090151556 seconds. Throughput is 1419.8313 records/second. Loss is 0.11342261. Sequential31006cbd's hyper parameters: Current learning rate is 0.003632137149498765. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 41728/60000][Iteration 8768][Wall Clock 798.526454339s] Trained 128 records in 0.07798022 seconds. Throughput is 1641.4419 records/second. Loss is 0.20075709. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036318733202585895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 41856/60000][Iteration 8769][Wall Clock 798.600337253s] Trained 128 records in 0.073882914 seconds. Throughput is 1732.471 records/second. Loss is 0.17902789. Sequential31006cbd's hyper parameters: Current learning rate is 0.003631609529343405. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 41984/60000][Iteration 8770][Wall Clock 798.678022614s] Trained 128 records in 0.077685361 seconds. Throughput is 1647.672 records/second. Loss is 0.21786904. Sequential31006cbd's hyper parameters: Current learning rate is 0.003631345776744862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42112/60000][Iteration 8771][Wall Clock 798.753801293s] Trained 128 records in 0.075778679 seconds. Throughput is 1689.1295 records/second. Loss is 0.09657636. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036310820624546117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42240/60000][Iteration 8772][Wall Clock 798.832230336s] Trained 128 records in 0.078429043 seconds. Throughput is 1632.0485 records/second. Loss is 0.12595755. Sequential31006cbd's hyper parameters: Current learning rate is 0.003630818386464309. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42368/60000][Iteration 8773][Wall Clock 798.903110931s] Trained 128 records in 0.070880595 seconds. Throughput is 1805.854 records/second. Loss is 0.0992119. Sequential31006cbd's hyper parameters: Current learning rate is 0.003630554748765611. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42496/60000][Iteration 8774][Wall Clock 798.984362086s] Trained 128 records in 0.081251155 seconds. Throughput is 1575.3623 records/second. Loss is 0.17204274. Sequential31006cbd's hyper parameters: Current learning rate is 0.003630291149350178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42624/60000][Iteration 8775][Wall Clock 799.071890658s] Trained 128 records in 0.087528572 seconds. Throughput is 1462.3796 records/second. Loss is 0.12069151. Sequential31006cbd's hyper parameters: Current learning rate is 0.00363002758820967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42752/60000][Iteration 8776][Wall Clock 799.169965934s] Trained 128 records in 0.098075276 seconds. Throughput is 1305.1199 records/second. Loss is 0.22746517. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036297640653357535. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 42880/60000][Iteration 8777][Wall Clock 799.278012897s] Trained 128 records in 0.108046963 seconds. Throughput is 1184.67 records/second. Loss is 0.15202154. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036295005807200926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:56 INFO  DistriOptimizer$:408 - [Epoch 19 43008/60000][Iteration 8778][Wall Clock 799.370324931s] Trained 128 records in 0.092312034 seconds. Throughput is 1386.6014 records/second. Loss is 0.22441864. Sequential31006cbd's hyper parameters: Current learning rate is 0.003629237134354359. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43136/60000][Iteration 8779][Wall Clock 799.478789492s] Trained 128 records in 0.108464561 seconds. Throughput is 1180.109 records/second. Loss is 0.18288982. Sequential31006cbd's hyper parameters: Current learning rate is 0.003628973726230222. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43264/60000][Iteration 8780][Wall Clock 799.557528782s] Trained 128 records in 0.07873929 seconds. Throughput is 1625.6178 records/second. Loss is 0.1276743. Sequential31006cbd's hyper parameters: Current learning rate is 0.003628710356339357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43392/60000][Iteration 8781][Wall Clock 799.644814759s] Trained 128 records in 0.087285977 seconds. Throughput is 1466.444 records/second. Loss is 0.12701693. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036284470246734394. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43520/60000][Iteration 8782][Wall Clock 799.72253871s] Trained 128 records in 0.077723951 seconds. Throughput is 1646.854 records/second. Loss is 0.21282527. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036281837312241495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43648/60000][Iteration 8783][Wall Clock 799.80752054s] Trained 128 records in 0.08498183 seconds. Throughput is 1506.2043 records/second. Loss is 0.14278466. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036279204759831663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43776/60000][Iteration 8784][Wall Clock 799.89114918s] Trained 128 records in 0.08362864 seconds. Throughput is 1530.5762 records/second. Loss is 0.10129734. Sequential31006cbd's hyper parameters: Current learning rate is 0.003627657258942175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 43904/60000][Iteration 8785][Wall Clock 799.972812925s] Trained 128 records in 0.081663745 seconds. Throughput is 1567.4031 records/second. Loss is 0.1145043. Sequential31006cbd's hyper parameters: Current learning rate is 0.003627394080092861. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 44032/60000][Iteration 8786][Wall Clock 800.054129564s] Trained 128 records in 0.081316639 seconds. Throughput is 1574.0935 records/second. Loss is 0.23554623. Sequential31006cbd's hyper parameters: Current learning rate is 0.003627130939426913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 44160/60000][Iteration 8787][Wall Clock 800.154587304s] Trained 128 records in 0.10045774 seconds. Throughput is 1274.1676 records/second. Loss is 0.14998992. Sequential31006cbd's hyper parameters: Current learning rate is 0.003626867836936022. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 44288/60000][Iteration 8788][Wall Clock 800.245543192s] Trained 128 records in 0.090955888 seconds. Throughput is 1407.2755 records/second. Loss is 0.08301756. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036266047726118806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 44416/60000][Iteration 8789][Wall Clock 800.328959509s] Trained 128 records in 0.083416317 seconds. Throughput is 1534.4719 records/second. Loss is 0.122012556. Sequential31006cbd's hyper parameters: Current learning rate is 0.003626341746446185. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:57 INFO  DistriOptimizer$:408 - [Epoch 19 44544/60000][Iteration 8790][Wall Clock 800.415451768s] Trained 128 records in 0.086492259 seconds. Throughput is 1479.9012 records/second. Loss is 0.14956272. Sequential31006cbd's hyper parameters: Current learning rate is 0.003626078758430633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 44672/60000][Iteration 8791][Wall Clock 800.49604654s] Trained 128 records in 0.080594772 seconds. Throughput is 1588.1924 records/second. Loss is 0.08291182. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036258158085569255. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 44800/60000][Iteration 8792][Wall Clock 800.58484501s] Trained 128 records in 0.08879847 seconds. Throughput is 1441.4663 records/second. Loss is 0.095919594. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036255528968167647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 44928/60000][Iteration 8793][Wall Clock 800.667507451s] Trained 128 records in 0.082662441 seconds. Throughput is 1548.4663 records/second. Loss is 0.23809472. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036252900232018564. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45056/60000][Iteration 8794][Wall Clock 800.745190028s] Trained 128 records in 0.077682577 seconds. Throughput is 1647.7311 records/second. Loss is 0.16098887. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036250271877039074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45184/60000][Iteration 8795][Wall Clock 800.833616458s] Trained 128 records in 0.08842643 seconds. Throughput is 1447.531 records/second. Loss is 0.1779784. Sequential31006cbd's hyper parameters: Current learning rate is 0.00362476439031463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45312/60000][Iteration 8796][Wall Clock 800.915762162s] Trained 128 records in 0.082145704 seconds. Throughput is 1558.2068 records/second. Loss is 0.099326245. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036245016310257334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45440/60000][Iteration 8797][Wall Clock 800.99432367s] Trained 128 records in 0.078561508 seconds. Throughput is 1629.2966 records/second. Loss is 0.096734464. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036242389098289363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45568/60000][Iteration 8798][Wall Clock 801.07361685s] Trained 128 records in 0.07929318 seconds. Throughput is 1614.2625 records/second. Loss is 0.10139872. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036239762267159525. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45696/60000][Iteration 8799][Wall Clock 801.15949221s] Trained 128 records in 0.08587536 seconds. Throughput is 1490.5322 records/second. Loss is 0.09301752. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036237135816785046. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45824/60000][Iteration 8800][Wall Clock 801.243316029s] Trained 128 records in 0.083823819 seconds. Throughput is 1527.0122 records/second. Loss is 0.11198522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036234509747083117. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 45952/60000][Iteration 8801][Wall Clock 801.319527234s] Trained 128 records in 0.076211205 seconds. Throughput is 1679.543 records/second. Loss is 0.091577426. Sequential31006cbd's hyper parameters: Current learning rate is 0.003623188405797102. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:58 INFO  DistriOptimizer$:408 - [Epoch 19 46080/60000][Iteration 8802][Wall Clock 801.40219656s] Trained 128 records in 0.082669326 seconds. Throughput is 1548.3373 records/second. Loss is 0.1081827. Sequential31006cbd's hyper parameters: Current learning rate is 0.003622925874936599. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46208/60000][Iteration 8803][Wall Clock 801.485966626s] Trained 128 records in 0.083770066 seconds. Throughput is 1527.9921 records/second. Loss is 0.12454665. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036226633821185334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46336/60000][Iteration 8804][Wall Clock 801.578557992s] Trained 128 records in 0.092591366 seconds. Throughput is 1382.4183 records/second. Loss is 0.13892844. Sequential31006cbd's hyper parameters: Current learning rate is 0.003622400927334637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46464/60000][Iteration 8805][Wall Clock 801.678351985s] Trained 128 records in 0.099793993 seconds. Throughput is 1282.6423 records/second. Loss is 0.15516171. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036221385105766443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46592/60000][Iteration 8806][Wall Clock 801.755793296s] Trained 128 records in 0.077441311 seconds. Throughput is 1652.8645 records/second. Loss is 0.21618. Sequential31006cbd's hyper parameters: Current learning rate is 0.003621876131836291. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46720/60000][Iteration 8807][Wall Clock 801.837737455s] Trained 128 records in 0.081944159 seconds. Throughput is 1562.0393 records/second. Loss is 0.099836394. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036216137911053163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46848/60000][Iteration 8808][Wall Clock 801.916395393s] Trained 128 records in 0.078657938 seconds. Throughput is 1627.2992 records/second. Loss is 0.2272073. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036213514883754617. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 46976/60000][Iteration 8809][Wall Clock 802.003096147s] Trained 128 records in 0.086700754 seconds. Throughput is 1476.3424 records/second. Loss is 0.21728382. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036210892236384707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 47104/60000][Iteration 8810][Wall Clock 802.078873021s] Trained 128 records in 0.075776874 seconds. Throughput is 1689.1697 records/second. Loss is 0.08855729. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036208269968860886. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 47232/60000][Iteration 8811][Wall Clock 802.155870384s] Trained 128 records in 0.076997363 seconds. Throughput is 1662.3947 records/second. Loss is 0.2277584. Sequential31006cbd's hyper parameters: Current learning rate is 0.003620564808110065. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 47360/60000][Iteration 8812][Wall Clock 802.23123087s] Trained 128 records in 0.075360486 seconds. Throughput is 1698.5029 records/second. Loss is 0.11755641. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036203026573021504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 47488/60000][Iteration 8813][Wall Clock 802.305638036s] Trained 128 records in 0.074407166 seconds. Throughput is 1720.2644 records/second. Loss is 0.076585494. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036200405444540974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:10:59 INFO  DistriOptimizer$:408 - [Epoch 19 47616/60000][Iteration 8814][Wall Clock 802.380326003s] Trained 128 records in 0.074687967 seconds. Throughput is 1713.7969 records/second. Loss is 0.15115522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036197784695576633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 47744/60000][Iteration 8815][Wall Clock 802.466635361s] Trained 128 records in 0.086309358 seconds. Throughput is 1483.0374 records/second. Loss is 0.100602455. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036195164326046038. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 47872/60000][Iteration 8816][Wall Clock 802.544495049s] Trained 128 records in 0.077859688 seconds. Throughput is 1643.983 records/second. Loss is 0.14847115. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036192544335866814. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48000/60000][Iteration 8817][Wall Clock 802.625978452s] Trained 128 records in 0.081483403 seconds. Throughput is 1570.8721 records/second. Loss is 0.22592725. Sequential31006cbd's hyper parameters: Current learning rate is 0.003618992472495657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48128/60000][Iteration 8818][Wall Clock 802.707839787s] Trained 128 records in 0.081861335 seconds. Throughput is 1563.6198 records/second. Loss is 0.108035006. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036187305493232975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48256/60000][Iteration 8819][Wall Clock 802.779837091s] Trained 128 records in 0.071997304 seconds. Throughput is 1777.8442 records/second. Loss is 0.13811326. Sequential31006cbd's hyper parameters: Current learning rate is 0.003618468664061369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48384/60000][Iteration 8820][Wall Clock 802.869587372s] Trained 128 records in 0.089750281 seconds. Throughput is 1426.1793 records/second. Loss is 0.16653481. Sequential31006cbd's hyper parameters: Current learning rate is 0.003618206816701643. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48512/60000][Iteration 8821][Wall Clock 802.96121955s] Trained 128 records in 0.091632178 seconds. Throughput is 1396.8892 records/second. Loss is 0.14592226. Sequential31006cbd's hyper parameters: Current learning rate is 0.00361794500723589. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48640/60000][Iteration 8822][Wall Clock 803.043121254s] Trained 128 records in 0.081901704 seconds. Throughput is 1562.849 records/second. Loss is 0.11658119. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036176832356558863. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48768/60000][Iteration 8823][Wall Clock 803.117384699s] Trained 128 records in 0.074263445 seconds. Throughput is 1723.5936 records/second. Loss is 0.15042126. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036174215019534072. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 48896/60000][Iteration 8824][Wall Clock 803.195204691s] Trained 128 records in 0.077819992 seconds. Throughput is 1644.8215 records/second. Loss is 0.30000368. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036171598061202344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 49024/60000][Iteration 8825][Wall Clock 803.271728163s] Trained 128 records in 0.076523472 seconds. Throughput is 1672.6893 records/second. Loss is 0.13198984. Sequential31006cbd's hyper parameters: Current learning rate is 0.003616898148148148. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 49152/60000][Iteration 8826][Wall Clock 803.347455537s] Trained 128 records in 0.075727374 seconds. Throughput is 1690.2738 records/second. Loss is 0.10969566. Sequential31006cbd's hyper parameters: Current learning rate is 0.003616636528028933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:00 INFO  DistriOptimizer$:408 - [Epoch 19 49280/60000][Iteration 8827][Wall Clock 803.426827374s] Trained 128 records in 0.079371837 seconds. Throughput is 1612.6626 records/second. Loss is 0.23451146. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036163749457543757. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 49408/60000][Iteration 8828][Wall Clock 803.509579664s] Trained 128 records in 0.08275229 seconds. Throughput is 1546.785 records/second. Loss is 0.11270581. Sequential31006cbd's hyper parameters: Current learning rate is 0.003616113401316265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 49536/60000][Iteration 8829][Wall Clock 803.58811047s] Trained 128 records in 0.078530806 seconds. Throughput is 1629.9337 records/second. Loss is 0.18744826. Sequential31006cbd's hyper parameters: Current learning rate is 0.003615851894706393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 49664/60000][Iteration 8830][Wall Clock 803.671405241s] Trained 128 records in 0.083294771 seconds. Throughput is 1536.711 records/second. Loss is 0.1316402. Sequential31006cbd's hyper parameters: Current learning rate is 0.003615590425916552. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 49792/60000][Iteration 8831][Wall Clock 803.758429656s] Trained 128 records in 0.087024415 seconds. Throughput is 1470.8517 records/second. Loss is 0.13452718. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036153289949385397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 49920/60000][Iteration 8832][Wall Clock 803.833319098s] Trained 128 records in 0.074889442 seconds. Throughput is 1709.1862 records/second. Loss is 0.23538059. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036150676017641533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50048/60000][Iteration 8833][Wall Clock 803.930659372s] Trained 128 records in 0.097340274 seconds. Throughput is 1314.9747 records/second. Loss is 0.13489392. Sequential31006cbd's hyper parameters: Current learning rate is 0.003614806246385194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50176/60000][Iteration 8834][Wall Clock 804.019025154s] Trained 128 records in 0.088365782 seconds. Throughput is 1448.5245 records/second. Loss is 0.1361405. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036145449287934644. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50304/60000][Iteration 8835][Wall Clock 804.105312203s] Trained 128 records in 0.086287049 seconds. Throughput is 1483.4208 records/second. Loss is 0.23331316. Sequential31006cbd's hyper parameters: Current learning rate is 0.003614283648980772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50432/60000][Iteration 8836][Wall Clock 804.183822121s] Trained 128 records in 0.078509918 seconds. Throughput is 1630.3672 records/second. Loss is 0.10358264. Sequential31006cbd's hyper parameters: Current learning rate is 0.003614022406938923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50560/60000][Iteration 8837][Wall Clock 804.264072624s] Trained 128 records in 0.080250503 seconds. Throughput is 1595.0056 records/second. Loss is 0.13754189. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036137612026597285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50688/60000][Iteration 8838][Wall Clock 804.343859211s] Trained 128 records in 0.079786587 seconds. Throughput is 1604.2798 records/second. Loss is 0.10787068. Sequential31006cbd's hyper parameters: Current learning rate is 0.003613500036135. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:01 INFO  DistriOptimizer$:408 - [Epoch 19 50816/60000][Iteration 8839][Wall Clock 804.419341415s] Trained 128 records in 0.075482204 seconds. Throughput is 1695.7639 records/second. Loss is 0.19158731. Sequential31006cbd's hyper parameters: Current learning rate is 0.003613238907356555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 50944/60000][Iteration 8840][Wall Clock 804.530109058s] Trained 128 records in 0.110767643 seconds. Throughput is 1155.5721 records/second. Loss is 0.10432969. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036129778163162076. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51072/60000][Iteration 8841][Wall Clock 804.632904671s] Trained 128 records in 0.102795613 seconds. Throughput is 1245.1893 records/second. Loss is 0.10565141. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036127167630057807. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51200/60000][Iteration 8842][Wall Clock 804.741559088s] Trained 128 records in 0.108654417 seconds. Throughput is 1178.0469 records/second. Loss is 0.2293311. Sequential31006cbd's hyper parameters: Current learning rate is 0.003612455747417094. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51328/60000][Iteration 8843][Wall Clock 804.830642416s] Trained 128 records in 0.089083328 seconds. Throughput is 1436.8569 records/second. Loss is 0.14866239. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036121947695419735. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51456/60000][Iteration 8844][Wall Clock 804.90882616s] Trained 128 records in 0.078183744 seconds. Throughput is 1637.1691 records/second. Loss is 0.13095868. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036119338293722457. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51584/60000][Iteration 8845][Wall Clock 804.989416519s] Trained 128 records in 0.080590359 seconds. Throughput is 1588.2793 records/second. Loss is 0.12819016. Sequential31006cbd's hyper parameters: Current learning rate is 0.00361167292689974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51712/60000][Iteration 8846][Wall Clock 805.064346696s] Trained 128 records in 0.074930177 seconds. Throughput is 1708.2571 records/second. Loss is 0.1807025. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036114120621162874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51840/60000][Iteration 8847][Wall Clock 805.141084858s] Trained 128 records in 0.076738162 seconds. Throughput is 1668.0096 records/second. Loss is 0.13453884. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036111512350137224. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 51968/60000][Iteration 8848][Wall Clock 805.22825882s] Trained 128 records in 0.087173962 seconds. Throughput is 1468.3284 records/second. Loss is 0.19930036. Sequential31006cbd's hyper parameters: Current learning rate is 0.003610890445583881. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 52096/60000][Iteration 8849][Wall Clock 805.305296737s] Trained 128 records in 0.077037917 seconds. Throughput is 1661.5195 records/second. Loss is 0.1253829. Sequential31006cbd's hyper parameters: Current learning rate is 0.003610629693818602. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:02 INFO  DistriOptimizer$:408 - [Epoch 19 52224/60000][Iteration 8850][Wall Clock 805.385883465s] Trained 128 records in 0.080586728 seconds. Throughput is 1588.3508 records/second. Loss is 0.13198045. Sequential31006cbd's hyper parameters: Current learning rate is 0.003610368979709726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 52352/60000][Iteration 8851][Wall Clock 805.466871727s] Trained 128 records in 0.080988262 seconds. Throughput is 1580.4758 records/second. Loss is 0.11927211. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036101083032490976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 52480/60000][Iteration 8852][Wall Clock 805.547827283s] Trained 128 records in 0.080955556 seconds. Throughput is 1581.1144 records/second. Loss is 0.07729408. Sequential31006cbd's hyper parameters: Current learning rate is 0.003609847664428561. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 52608/60000][Iteration 8853][Wall Clock 805.625121593s] Trained 128 records in 0.07729431 seconds. Throughput is 1656.008 records/second. Loss is 0.092672735. Sequential31006cbd's hyper parameters: Current learning rate is 0.003609587063239965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 52736/60000][Iteration 8854][Wall Clock 805.704529028s] Trained 128 records in 0.079407435 seconds. Throughput is 1611.9397 records/second. Loss is 0.15214306. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036093264996751606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 52864/60000][Iteration 8855][Wall Clock 805.784159063s] Trained 128 records in 0.079630035 seconds. Throughput is 1607.4337 records/second. Loss is 0.066034675. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036090659737259994. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 52992/60000][Iteration 8856][Wall Clock 805.859482685s] Trained 128 records in 0.075323622 seconds. Throughput is 1699.3342 records/second. Loss is 0.1216858. Sequential31006cbd's hyper parameters: Current learning rate is 0.003608805485384338. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53120/60000][Iteration 8857][Wall Clock 805.942128094s] Trained 128 records in 0.082645409 seconds. Throughput is 1548.7854 records/second. Loss is 0.17605749. Sequential31006cbd's hyper parameters: Current learning rate is 0.003608545034642032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53248/60000][Iteration 8858][Wall Clock 806.018829925s] Trained 128 records in 0.076701831 seconds. Throughput is 1668.7999 records/second. Loss is 0.12773705. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036082846214909436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53376/60000][Iteration 8859][Wall Clock 806.096002632s] Trained 128 records in 0.077172707 seconds. Throughput is 1658.6176 records/second. Loss is 0.1536991. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036080242459229322. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53504/60000][Iteration 8860][Wall Clock 806.174858955s] Trained 128 records in 0.078856323 seconds. Throughput is 1623.2052 records/second. Loss is 0.1811866. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036077639079298653. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53632/60000][Iteration 8861][Wall Clock 806.255191732s] Trained 128 records in 0.080332777 seconds. Throughput is 1593.372 records/second. Loss is 0.21092409. Sequential31006cbd's hyper parameters: Current learning rate is 0.003607503607503607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53760/60000][Iteration 8862][Wall Clock 806.342977839s] Trained 128 records in 0.087786107 seconds. Throughput is 1458.0895 records/second. Loss is 0.12239699. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036072433446360293. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:03 INFO  DistriOptimizer$:408 - [Epoch 19 53888/60000][Iteration 8863][Wall Clock 806.42160656s] Trained 128 records in 0.078628721 seconds. Throughput is 1627.9039 records/second. Loss is 0.12504345. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036069831193190015. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54016/60000][Iteration 8864][Wall Clock 806.498359718s] Trained 128 records in 0.076753158 seconds. Throughput is 1667.684 records/second. Loss is 0.14999372. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036067229315443986. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54144/60000][Iteration 8865][Wall Clock 806.584220081s] Trained 128 records in 0.085860363 seconds. Throughput is 1490.7926 records/second. Loss is 0.24444525. Sequential31006cbd's hyper parameters: Current learning rate is 0.003606462781304097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54272/60000][Iteration 8866][Wall Clock 806.671991142s] Trained 128 records in 0.087771061 seconds. Throughput is 1458.3395 records/second. Loss is 0.11032775. Sequential31006cbd's hyper parameters: Current learning rate is 0.003606202668589975. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54400/60000][Iteration 8867][Wall Clock 806.791593803s] Trained 128 records in 0.119602661 seconds. Throughput is 1070.2103 records/second. Loss is 0.13216326. Sequential31006cbd's hyper parameters: Current learning rate is 0.003605942593393913. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54528/60000][Iteration 8868][Wall Clock 806.917138231s] Trained 128 records in 0.125544428 seconds. Throughput is 1019.5594 records/second. Loss is 0.1073504. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036056825557077956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54656/60000][Iteration 8869][Wall Clock 807.003243731s] Trained 128 records in 0.0861055 seconds. Throughput is 1486.5485 records/second. Loss is 0.21304362. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036054225555235075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54784/60000][Iteration 8870][Wall Clock 807.085604363s] Trained 128 records in 0.082360632 seconds. Throughput is 1554.1405 records/second. Loss is 0.08624625. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036051625928329367. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 54912/60000][Iteration 8871][Wall Clock 807.159784162s] Trained 128 records in 0.074179799 seconds. Throughput is 1725.5372 records/second. Loss is 0.13894822. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036049026676279743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 55040/60000][Iteration 8872][Wall Clock 807.231093783s] Trained 128 records in 0.071309621 seconds. Throughput is 1794.9893 records/second. Loss is 0.1842804. Sequential31006cbd's hyper parameters: Current learning rate is 0.003604642779900512. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 55168/60000][Iteration 8873][Wall Clock 807.31420716s] Trained 128 records in 0.083113377 seconds. Throughput is 1540.065 records/second. Loss is 0.15921746. Sequential31006cbd's hyper parameters: Current learning rate is 0.003604382929642445. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:04 INFO  DistriOptimizer$:408 - [Epoch 19 55296/60000][Iteration 8874][Wall Clock 807.401534143s] Trained 128 records in 0.087326983 seconds. Throughput is 1465.7555 records/second. Loss is 0.14864886. Sequential31006cbd's hyper parameters: Current learning rate is 0.003604123116845671. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 55424/60000][Iteration 8875][Wall Clock 807.484541281s] Trained 128 records in 0.083007138 seconds. Throughput is 1542.0361 records/second. Loss is 0.1421428. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036038633415020906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 55552/60000][Iteration 8876][Wall Clock 807.562126606s] Trained 128 records in 0.077585325 seconds. Throughput is 1649.7965 records/second. Loss is 0.09941454. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036036036036036032. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 55680/60000][Iteration 8877][Wall Clock 807.640636771s] Trained 128 records in 0.078510165 seconds. Throughput is 1630.3622 records/second. Loss is 0.08920955. Sequential31006cbd's hyper parameters: Current learning rate is 0.003603343903142116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 55808/60000][Iteration 8878][Wall Clock 807.720006095s] Trained 128 records in 0.079369324 seconds. Throughput is 1612.7137 records/second. Loss is 0.26180485. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036030842401095333. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 55936/60000][Iteration 8879][Wall Clock 807.799474543s] Trained 128 records in 0.079468448 seconds. Throughput is 1610.702 records/second. Loss is 0.21517389. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036028246144977666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56064/60000][Iteration 8880][Wall Clock 807.871979918s] Trained 128 records in 0.072505375 seconds. Throughput is 1765.3864 records/second. Loss is 0.12722857. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036025650262987243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56192/60000][Iteration 8881][Wall Clock 807.946382144s] Trained 128 records in 0.074402226 seconds. Throughput is 1720.3785 records/second. Loss is 0.085867524. Sequential31006cbd's hyper parameters: Current learning rate is 0.003602305475504323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56320/60000][Iteration 8882][Wall Clock 808.023083353s] Trained 128 records in 0.076701209 seconds. Throughput is 1668.8134 records/second. Loss is 0.15446329. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036020459621064764. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56448/60000][Iteration 8883][Wall Clock 808.124419339s] Trained 128 records in 0.101335986 seconds. Throughput is 1263.1248 records/second. Loss is 0.1815492. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036017864860971045. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56576/60000][Iteration 8884][Wall Clock 808.204483228s] Trained 128 records in 0.080063889 seconds. Throughput is 1598.7233 records/second. Loss is 0.20197976. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036015270474681264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56704/60000][Iteration 8885][Wall Clock 808.28385181s] Trained 128 records in 0.079368582 seconds. Throughput is 1612.7288 records/second. Loss is 0.14163095. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036012676462114663. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:05 INFO  DistriOptimizer$:408 - [Epoch 19 56832/60000][Iteration 8886][Wall Clock 808.372333365s] Trained 128 records in 0.088481555 seconds. Throughput is 1446.6293 records/second. Loss is 0.13285229. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036010082823190494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 56960/60000][Iteration 8887][Wall Clock 808.449912092s] Trained 128 records in 0.077578727 seconds. Throughput is 1649.9369 records/second. Loss is 0.17625242. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036007489557828027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57088/60000][Iteration 8888][Wall Clock 808.526575569s] Trained 128 records in 0.076663477 seconds. Throughput is 1669.6346 records/second. Loss is 0.14320649. Sequential31006cbd's hyper parameters: Current learning rate is 0.0036004896665946568. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57216/60000][Iteration 8889][Wall Clock 808.605263857s] Trained 128 records in 0.078688288 seconds. Throughput is 1626.6716 records/second. Loss is 0.2067384. Sequential31006cbd's hyper parameters: Current learning rate is 0.003600230414746544. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57344/60000][Iteration 8890][Wall Clock 808.685486947s] Trained 128 records in 0.08022309 seconds. Throughput is 1595.5505 records/second. Loss is 0.19362316. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035999712002303982. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57472/60000][Iteration 8891][Wall Clock 808.7652392s] Trained 128 records in 0.079752253 seconds. Throughput is 1604.9703 records/second. Loss is 0.15750208. Sequential31006cbd's hyper parameters: Current learning rate is 0.003599712023038157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57600/60000][Iteration 8892][Wall Clock 808.847635714s] Trained 128 records in 0.082396514 seconds. Throughput is 1553.4637 records/second. Loss is 0.13136387. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035994528831617594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57728/60000][Iteration 8893][Wall Clock 808.929192045s] Trained 128 records in 0.081556331 seconds. Throughput is 1569.4674 records/second. Loss is 0.22790712. Sequential31006cbd's hyper parameters: Current learning rate is 0.003599193780593147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57856/60000][Iteration 8894][Wall Clock 809.004933974s] Trained 128 records in 0.075741929 seconds. Throughput is 1689.949 records/second. Loss is 0.13537186. Sequential31006cbd's hyper parameters: Current learning rate is 0.003598934715324264. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 57984/60000][Iteration 8895][Wall Clock 809.087112435s] Trained 128 records in 0.082178461 seconds. Throughput is 1557.5858 records/second. Loss is 0.15500543. Sequential31006cbd's hyper parameters: Current learning rate is 0.003598675687347056. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 58112/60000][Iteration 8896][Wall Clock 809.173771751s] Trained 128 records in 0.086659316 seconds. Throughput is 1477.0483 records/second. Loss is 0.21420029. Sequential31006cbd's hyper parameters: Current learning rate is 0.003598416696653473. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 58240/60000][Iteration 8897][Wall Clock 809.25526346s] Trained 128 records in 0.081491709 seconds. Throughput is 1570.7119 records/second. Loss is 0.13417637. Sequential31006cbd's hyper parameters: Current learning rate is 0.003598157743235463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:06 INFO  DistriOptimizer$:408 - [Epoch 19 58368/60000][Iteration 8898][Wall Clock 809.340760202s] Trained 128 records in 0.085496742 seconds. Throughput is 1497.1332 records/second. Loss is 0.13357408. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035978988270849825. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 58496/60000][Iteration 8899][Wall Clock 809.419461728s] Trained 128 records in 0.078701526 seconds. Throughput is 1626.398 records/second. Loss is 0.099641316. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035976399481939844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 58624/60000][Iteration 8900][Wall Clock 809.507500534s] Trained 128 records in 0.088038806 seconds. Throughput is 1453.9043 records/second. Loss is 0.2651719. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035973811065544287. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 58752/60000][Iteration 8901][Wall Clock 809.589071544s] Trained 128 records in 0.08157101 seconds. Throughput is 1569.1849 records/second. Loss is 0.10744352. Sequential31006cbd's hyper parameters: Current learning rate is 0.003597122302158273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 58880/60000][Iteration 8902][Wall Clock 809.672435121s] Trained 128 records in 0.083363577 seconds. Throughput is 1535.4427 records/second. Loss is 0.1727502. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035968635349974826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59008/60000][Iteration 8903][Wall Clock 809.756570313s] Trained 128 records in 0.084135192 seconds. Throughput is 1521.3611 records/second. Loss is 0.13867342. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035966048050640196. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59136/60000][Iteration 8904][Wall Clock 809.837341063s] Trained 128 records in 0.08077075 seconds. Throughput is 1584.732 records/second. Loss is 0.08692287. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035963461123498523. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59264/60000][Iteration 8905][Wall Clock 809.927053129s] Trained 128 records in 0.089712066 seconds. Throughput is 1426.7869 records/second. Loss is 0.09404504. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035960874568469504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59392/60000][Iteration 8906][Wall Clock 810.009154985s] Trained 128 records in 0.082101856 seconds. Throughput is 1559.039 records/second. Loss is 0.1282064. Sequential31006cbd's hyper parameters: Current learning rate is 0.003595828838547285. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59520/60000][Iteration 8907][Wall Clock 810.090770658s] Trained 128 records in 0.081615673 seconds. Throughput is 1568.3263 records/second. Loss is 0.16827454. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035955702574428303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59648/60000][Iteration 8908][Wall Clock 810.173798932s] Trained 128 records in 0.083028274 seconds. Throughput is 1541.6436 records/second. Loss is 0.17268531. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035953117135255628. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59776/60000][Iteration 8909][Wall Clock 810.259384726s] Trained 128 records in 0.085585794 seconds. Throughput is 1495.5753 records/second. Loss is 0.08807921. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035950532067874604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:07 INFO  DistriOptimizer$:408 - [Epoch 19 59904/60000][Iteration 8910][Wall Clock 810.342391204s] Trained 128 records in 0.083006478 seconds. Throughput is 1542.0483 records/second. Loss is 0.17679405. Sequential31006cbd's hyper parameters: Current learning rate is 0.003594794737220505. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:08 INFO  DistriOptimizer$:408 - [Epoch 19 60032/60000][Iteration 8911][Wall Clock 810.426516029s] Trained 128 records in 0.084124825 seconds. Throughput is 1521.5485 records/second. Loss is 0.20520909. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035945363048166786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:08 INFO  DistriOptimizer$:452 - [Epoch 19 60032/60000][Iteration 8911][Wall Clock 810.426516029s] Epoch finished. Wall clock time is 811540.030306 ms
2019-10-24 00:11:08 INFO  DistriOptimizer$:111 - [Epoch 19 60032/60000][Iteration 8911][Wall Clock 810.426516029s] Validate model...
2019-10-24 00:11:08 INFO  DistriOptimizer$:178 - [Epoch 19 60032/60000][Iteration 8911][Wall Clock 810.426516029s] validate model throughput is 11950.805 records/second
2019-10-24 00:11:08 INFO  DistriOptimizer$:181 - [Epoch 19 60032/60000][Iteration 8911][Wall Clock 810.426516029s] Top1Accuracy is Accuracy(correct: 9577, count: 10000, accuracy: 0.9577)
2019-10-24 00:11:08 INFO  DistriOptimizer$:221 - [Wall Clock 811.540030306s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:11:08 INFO  DistriOptimizer$:226 - [Wall Clock 811.540030306s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 128/60000][Iteration 8912][Wall Clock 811.633523274s] Trained 128 records in 0.093492968 seconds. Throughput is 1369.0869 records/second. Loss is 0.14506611. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035942779095679677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 256/60000][Iteration 8913][Wall Clock 811.717997533s] Trained 128 records in 0.084474259 seconds. Throughput is 1515.2545 records/second. Loss is 0.20659913. Sequential31006cbd's hyper parameters: Current learning rate is 0.00359401955146636. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 384/60000][Iteration 8914][Wall Clock 811.792683262s] Trained 128 records in 0.074685729 seconds. Throughput is 1713.8481 records/second. Loss is 0.102765925. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035937612305038447. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 512/60000][Iteration 8915][Wall Clock 811.875925154s] Trained 128 records in 0.083241892 seconds. Throughput is 1537.6873 records/second. Loss is 0.082015075. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035935029466724164. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 640/60000][Iteration 8916][Wall Clock 811.993969944s] Trained 128 records in 0.11804479 seconds. Throughput is 1084.3341 records/second. Loss is 0.100040905. Sequential31006cbd's hyper parameters: Current learning rate is 0.003593244699964067. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 768/60000][Iteration 8917][Wall Clock 812.083447138s] Trained 128 records in 0.089477194 seconds. Throughput is 1430.5321 records/second. Loss is 0.12957086. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035929864903707963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 896/60000][Iteration 8918][Wall Clock 812.159390445s] Trained 128 records in 0.075943307 seconds. Throughput is 1685.4679 records/second. Loss is 0.16976164. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035927283178846013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 1024/60000][Iteration 8919][Wall Clock 812.236505833s] Trained 128 records in 0.077115388 seconds. Throughput is 1659.8503 records/second. Loss is 0.21181273. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035924701824974854. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 1152/60000][Iteration 8920][Wall Clock 812.316030776s] Trained 128 records in 0.079524943 seconds. Throughput is 1609.5579 records/second. Loss is 0.099236906. Sequential31006cbd's hyper parameters: Current learning rate is 0.003592212084201451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 1280/60000][Iteration 8921][Wall Clock 812.396562955s] Trained 128 records in 0.080532179 seconds. Throughput is 1589.4268 records/second. Loss is 0.15893202. Sequential31006cbd's hyper parameters: Current learning rate is 0.003591954022988506. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 1408/60000][Iteration 8922][Wall Clock 812.470814505s] Trained 128 records in 0.07425155 seconds. Throughput is 1723.8698 records/second. Loss is 0.1957877. Sequential31006cbd's hyper parameters: Current learning rate is 0.003591695998850657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:09 INFO  DistriOptimizer$:408 - [Epoch 20 1536/60000][Iteration 8923][Wall Clock 812.547199502s] Trained 128 records in 0.076384997 seconds. Throughput is 1675.7217 records/second. Loss is 0.10433951. Sequential31006cbd's hyper parameters: Current learning rate is 0.003591438011779917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 1664/60000][Iteration 8924][Wall Clock 812.628196187s] Trained 128 records in 0.080996685 seconds. Throughput is 1580.3116 records/second. Loss is 0.11768067. Sequential31006cbd's hyper parameters: Current learning rate is 0.003591180061768297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 1792/60000][Iteration 8925][Wall Clock 812.708288067s] Trained 128 records in 0.08009188 seconds. Throughput is 1598.1646 records/second. Loss is 0.16811737. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035909221488078136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 1920/60000][Iteration 8926][Wall Clock 812.790806959s] Trained 128 records in 0.082518892 seconds. Throughput is 1551.16 records/second. Loss is 0.09224415. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035906642728904844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2048/60000][Iteration 8927][Wall Clock 812.86859091s] Trained 128 records in 0.077783951 seconds. Throughput is 1645.5837 records/second. Loss is 0.09225592. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035904064340083297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2176/60000][Iteration 8928][Wall Clock 812.955412371s] Trained 128 records in 0.086821461 seconds. Throughput is 1474.2899 records/second. Loss is 0.13340801. Sequential31006cbd's hyper parameters: Current learning rate is 0.003590148632153371. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2304/60000][Iteration 8929][Wall Clock 813.041634321s] Trained 128 records in 0.08622195 seconds. Throughput is 1484.5408 records/second. Loss is 0.13599874. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035898908673176336. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2432/60000][Iteration 8930][Wall Clock 813.12243349s] Trained 128 records in 0.080799169 seconds. Throughput is 1584.1747 records/second. Loss is 0.24658345. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035896331394931437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2560/60000][Iteration 8931][Wall Clock 813.200556709s] Trained 128 records in 0.078123219 seconds. Throughput is 1638.4374 records/second. Loss is 0.1124076. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035893754486719313. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2688/60000][Iteration 8932][Wall Clock 813.279955847s] Trained 128 records in 0.079399138 seconds. Throughput is 1612.1082 records/second. Loss is 0.2093764. Sequential31006cbd's hyper parameters: Current learning rate is 0.003589117794846027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2816/60000][Iteration 8933][Wall Clock 813.361617976s] Trained 128 records in 0.081662129 seconds. Throughput is 1567.4341 records/second. Loss is 0.14359295. Sequential31006cbd's hyper parameters: Current learning rate is 0.003588860178007465. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 2944/60000][Iteration 8934][Wall Clock 813.45623497s] Trained 128 records in 0.094616994 seconds. Throughput is 1352.8225 records/second. Loss is 0.25497052. Sequential31006cbd's hyper parameters: Current learning rate is 0.003588602598148281. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:10 INFO  DistriOptimizer$:408 - [Epoch 20 3072/60000][Iteration 8935][Wall Clock 813.529544094s] Trained 128 records in 0.073309124 seconds. Throughput is 1746.031 records/second. Loss is 0.14916046. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035883450552605133. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3200/60000][Iteration 8936][Wall Clock 813.603436577s] Trained 128 records in 0.073892483 seconds. Throughput is 1732.2466 records/second. Loss is 0.20559615. Sequential31006cbd's hyper parameters: Current learning rate is 0.003588087549336204. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3328/60000][Iteration 8937][Wall Clock 813.68168697s] Trained 128 records in 0.078250393 seconds. Throughput is 1635.7745 records/second. Loss is 0.23683347. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035878300803673935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3456/60000][Iteration 8938][Wall Clock 813.762161898s] Trained 128 records in 0.080474928 seconds. Throughput is 1590.5575 records/second. Loss is 0.15415336. Sequential31006cbd's hyper parameters: Current learning rate is 0.003587572648346129. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3584/60000][Iteration 8939][Wall Clock 813.842493369s] Trained 128 records in 0.080331471 seconds. Throughput is 1593.3978 records/second. Loss is 0.09165278. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035873152532644565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3712/60000][Iteration 8940][Wall Clock 813.925341478s] Trained 128 records in 0.082848109 seconds. Throughput is 1544.996 records/second. Loss is 0.18931192. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035870578951144273. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3840/60000][Iteration 8941][Wall Clock 814.007672633s] Trained 128 records in 0.082331155 seconds. Throughput is 1554.6969 records/second. Loss is 0.20441476. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035868005738880914. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 3968/60000][Iteration 8942][Wall Clock 814.087417861s] Trained 128 records in 0.079745228 seconds. Throughput is 1605.1118 records/second. Loss is 0.16493277. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035865432895775054. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 4096/60000][Iteration 8943][Wall Clock 814.1616404s] Trained 128 records in 0.074222539 seconds. Throughput is 1724.5435 records/second. Loss is 0.15325363. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035862860421747235. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 4224/60000][Iteration 8944][Wall Clock 814.237219606s] Trained 128 records in 0.075579206 seconds. Throughput is 1693.5875 records/second. Loss is 0.15976644. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035860288316718063. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 4352/60000][Iteration 8945][Wall Clock 814.312741387s] Trained 128 records in 0.075521781 seconds. Throughput is 1694.8752 records/second. Loss is 0.11803277. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035857716580608144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 4480/60000][Iteration 8946][Wall Clock 814.390614167s] Trained 128 records in 0.07787278 seconds. Throughput is 1643.7065 records/second. Loss is 0.14173374. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035855145213338113. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 4608/60000][Iteration 8947][Wall Clock 814.467249618s] Trained 128 records in 0.076635451 seconds. Throughput is 1670.2452 records/second. Loss is 0.14067942. Sequential31006cbd's hyper parameters: Current learning rate is 0.003585257421482862. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:11 INFO  DistriOptimizer$:408 - [Epoch 20 4736/60000][Iteration 8948][Wall Clock 814.547989604s] Trained 128 records in 0.080739986 seconds. Throughput is 1585.3359 records/second. Loss is 0.13726059. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035850003585000357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 4864/60000][Iteration 8949][Wall Clock 814.626398645s] Trained 128 records in 0.078409041 seconds. Throughput is 1632.4648 records/second. Loss is 0.15740132. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035847433323774017. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 4992/60000][Iteration 8950][Wall Clock 814.716716205s] Trained 128 records in 0.09031756 seconds. Throughput is 1417.2216 records/second. Loss is 0.17420276. Sequential31006cbd's hyper parameters: Current learning rate is 0.003584486343107033. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5120/60000][Iteration 8951][Wall Clock 814.804804727s] Trained 128 records in 0.088088522 seconds. Throughput is 1453.0837 records/second. Loss is 0.07031725. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035842293906810036. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5248/60000][Iteration 8952][Wall Clock 814.886286856s] Trained 128 records in 0.081482129 seconds. Throughput is 1570.8966 records/second. Loss is 0.094850846. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035839724750913915. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5376/60000][Iteration 8953][Wall Clock 814.968604644s] Trained 128 records in 0.082317788 seconds. Throughput is 1554.9496 records/second. Loss is 0.26348677. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035837155963302754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5504/60000][Iteration 8954][Wall Clock 815.044051171s] Trained 128 records in 0.075446527 seconds. Throughput is 1696.5659 records/second. Loss is 0.18336749. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035834587543897363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5632/60000][Iteration 8955][Wall Clock 815.122947036s] Trained 128 records in 0.078895865 seconds. Throughput is 1622.3917 records/second. Loss is 0.13182093. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035832019492618604. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5760/60000][Iteration 8956][Wall Clock 815.203281854s] Trained 128 records in 0.080334818 seconds. Throughput is 1593.3315 records/second. Loss is 0.20165935. Sequential31006cbd's hyper parameters: Current learning rate is 0.003582945180938731. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 5888/60000][Iteration 8957][Wall Clock 815.276934371s] Trained 128 records in 0.073652517 seconds. Throughput is 1737.8905 records/second. Loss is 0.12493507. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035826884494124392. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 6016/60000][Iteration 8958][Wall Clock 815.354912444s] Trained 128 records in 0.077978073 seconds. Throughput is 1641.487 records/second. Loss is 0.21716115. Sequential31006cbd's hyper parameters: Current learning rate is 0.003582431754675073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 6144/60000][Iteration 8959][Wall Clock 815.432947991s] Trained 128 records in 0.078035547 seconds. Throughput is 1640.2781 records/second. Loss is 0.14323802. Sequential31006cbd's hyper parameters: Current learning rate is 0.003582175096718728. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:12 INFO  DistriOptimizer$:408 - [Epoch 20 6272/60000][Iteration 8960][Wall Clock 815.54273015s] Trained 128 records in 0.109782159 seconds. Throughput is 1165.9453 records/second. Loss is 0.184151. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035819184755354967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 6400/60000][Iteration 8961][Wall Clock 815.630852058s] Trained 128 records in 0.088121908 seconds. Throughput is 1452.5333 records/second. Loss is 0.1703429. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035816618911174787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 6528/60000][Iteration 8962][Wall Clock 815.705686002s] Trained 128 records in 0.074833944 seconds. Throughput is 1710.4537 records/second. Loss is 0.12278198. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035814053434567723. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 6656/60000][Iteration 8963][Wall Clock 815.790398294s] Trained 128 records in 0.084712292 seconds. Throughput is 1510.9968 records/second. Loss is 0.1270731. Sequential31006cbd's hyper parameters: Current learning rate is 0.003581148832545481. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 6784/60000][Iteration 8964][Wall Clock 815.862751444s] Trained 128 records in 0.07235315 seconds. Throughput is 1769.1007 records/second. Loss is 0.13724737. Sequential31006cbd's hyper parameters: Current learning rate is 0.003580892358375707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 6912/60000][Iteration 8965][Wall Clock 815.938933803s] Trained 128 records in 0.076182359 seconds. Throughput is 1680.1791 records/second. Loss is 0.15422085. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035806359209395585. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7040/60000][Iteration 8966][Wall Clock 816.015490688s] Trained 128 records in 0.076556885 seconds. Throughput is 1671.9594 records/second. Loss is 0.08204098. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035803795202291443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7168/60000][Iteration 8967][Wall Clock 816.096409799s] Trained 128 records in 0.080919111 seconds. Throughput is 1581.8267 records/second. Loss is 0.11940752. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035801231562365746. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7296/60000][Iteration 8968][Wall Clock 816.194901194s] Trained 128 records in 0.098491395 seconds. Throughput is 1299.606 records/second. Loss is 0.13413979. Sequential31006cbd's hyper parameters: Current learning rate is 0.003579866828953963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7424/60000][Iteration 8969][Wall Clock 816.288878851s] Trained 128 records in 0.093977657 seconds. Throughput is 1362.0259 records/second. Loss is 0.2410441. Sequential31006cbd's hyper parameters: Current learning rate is 0.003579610538373425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7552/60000][Iteration 8970][Wall Clock 816.368440065s] Trained 128 records in 0.079561214 seconds. Throughput is 1608.8242 records/second. Loss is 0.122945815. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035793542844870787. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7680/60000][Iteration 8971][Wall Clock 816.465289124s] Trained 128 records in 0.096849059 seconds. Throughput is 1321.6442 records/second. Loss is 0.1102138. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035790980672870437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:13 INFO  DistriOptimizer$:408 - [Epoch 20 7808/60000][Iteration 8972][Wall Clock 816.553537973s] Trained 128 records in 0.088248849 seconds. Throughput is 1450.4438 records/second. Loss is 0.10644302. Sequential31006cbd's hyper parameters: Current learning rate is 0.003578841886765443. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 7936/60000][Iteration 8973][Wall Clock 816.634300758s] Trained 128 records in 0.080762785 seconds. Throughput is 1584.8883 records/second. Loss is 0.20930111. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035785857429144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8064/60000][Iteration 8974][Wall Clock 816.722208002s] Trained 128 records in 0.087907244 seconds. Throughput is 1456.0802 records/second. Loss is 0.13149706. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035783296357260433. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8192/60000][Iteration 8975][Wall Clock 816.813895516s] Trained 128 records in 0.091687514 seconds. Throughput is 1396.0461 records/second. Loss is 0.13944328. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035780735651924998. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8320/60000][Iteration 8976][Wall Clock 816.899144245s] Trained 128 records in 0.085248729 seconds. Throughput is 1501.4886 records/second. Loss is 0.0560442. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035778175313059034. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8448/60000][Iteration 8977][Wall Clock 816.983707171s] Trained 128 records in 0.084562926 seconds. Throughput is 1513.6656 records/second. Loss is 0.22449866. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035775615340583856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8576/60000][Iteration 8978][Wall Clock 817.064943716s] Trained 128 records in 0.081236545 seconds. Throughput is 1575.6455 records/second. Loss is 0.092161715. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035773055734420836. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8704/60000][Iteration 8979][Wall Clock 817.147330705s] Trained 128 records in 0.082386989 seconds. Throughput is 1553.6434 records/second. Loss is 0.22565165. Sequential31006cbd's hyper parameters: Current learning rate is 0.003577049649449134. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8832/60000][Iteration 8980][Wall Clock 817.228553333s] Trained 128 records in 0.081222628 seconds. Throughput is 1575.9154 records/second. Loss is 0.1738298. Sequential31006cbd's hyper parameters: Current learning rate is 0.003576793762071679. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 8960/60000][Iteration 8981][Wall Clock 817.30699003s] Trained 128 records in 0.078436697 seconds. Throughput is 1631.8893 records/second. Loss is 0.0963788. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035765379113018594. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 9088/60000][Iteration 8982][Wall Clock 817.390670627s] Trained 128 records in 0.083680597 seconds. Throughput is 1529.6257 records/second. Loss is 0.182551. Sequential31006cbd's hyper parameters: Current learning rate is 0.003576282097131822. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 9216/60000][Iteration 8983][Wall Clock 817.481002208s] Trained 128 records in 0.090331581 seconds. Throughput is 1417.0016 records/second. Loss is 0.10771615. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035760263195537116. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:14 INFO  DistriOptimizer$:408 - [Epoch 20 9344/60000][Iteration 8984][Wall Clock 817.576948469s] Trained 128 records in 0.095946261 seconds. Throughput is 1334.0802 records/second. Loss is 0.12057634. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035757705785596796. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 9472/60000][Iteration 8985][Wall Clock 817.652905567s] Trained 128 records in 0.075957098 seconds. Throughput is 1685.1619 records/second. Loss is 0.07867651. Sequential31006cbd's hyper parameters: Current learning rate is 0.003575514874141876. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 9600/60000][Iteration 8986][Wall Clock 817.745633492s] Trained 128 records in 0.092727925 seconds. Throughput is 1380.3824 records/second. Loss is 0.15481566. Sequential31006cbd's hyper parameters: Current learning rate is 0.003575259206292456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 9728/60000][Iteration 8987][Wall Clock 817.824824151s] Trained 128 records in 0.079190659 seconds. Throughput is 1616.3523 records/second. Loss is 0.13772877. Sequential31006cbd's hyper parameters: Current learning rate is 0.003575003575003575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 9856/60000][Iteration 8988][Wall Clock 817.897461573s] Trained 128 records in 0.072637422 seconds. Throughput is 1762.177 records/second. Loss is 0.11026369. Sequential31006cbd's hyper parameters: Current learning rate is 0.003574747980267391. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 9984/60000][Iteration 8989][Wall Clock 817.96979726s] Trained 128 records in 0.072335687 seconds. Throughput is 1769.5276 records/second. Loss is 0.15948889. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035744924220760654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10112/60000][Iteration 8990][Wall Clock 818.048027348s] Trained 128 records in 0.078230088 seconds. Throughput is 1636.1991 records/second. Loss is 0.22678116. Sequential31006cbd's hyper parameters: Current learning rate is 0.00357423690042176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10240/60000][Iteration 8991][Wall Clock 818.125686682s] Trained 128 records in 0.077659334 seconds. Throughput is 1648.2244 records/second. Loss is 0.10878677. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035739814152966403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10368/60000][Iteration 8992][Wall Clock 818.199757795s] Trained 128 records in 0.074071113 seconds. Throughput is 1728.0692 records/second. Loss is 0.11031313. Sequential31006cbd's hyper parameters: Current learning rate is 0.003573725966692874. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10496/60000][Iteration 8993][Wall Clock 818.282995046s] Trained 128 records in 0.083237251 seconds. Throughput is 1537.773 records/second. Loss is 0.20489645. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035734705546026303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10624/60000][Iteration 8994][Wall Clock 818.379935428s] Trained 128 records in 0.096940382 seconds. Throughput is 1320.3992 records/second. Loss is 0.17864165. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035732151790180806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10752/60000][Iteration 8995][Wall Clock 818.454514948s] Trained 128 records in 0.07457952 seconds. Throughput is 1716.2888 records/second. Loss is 0.070507444. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035729598399313993. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:15 INFO  DistriOptimizer$:408 - [Epoch 20 10880/60000][Iteration 8996][Wall Clock 818.543349894s] Trained 128 records in 0.088834946 seconds. Throughput is 1440.8744 records/second. Loss is 0.12232942. Sequential31006cbd's hyper parameters: Current learning rate is 0.003572704537334762. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11008/60000][Iteration 8997][Wall Clock 818.627860413s] Trained 128 records in 0.084510519 seconds. Throughput is 1514.6044 records/second. Loss is 0.13849537. Sequential31006cbd's hyper parameters: Current learning rate is 0.003572449271220349. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11136/60000][Iteration 8998][Wall Clock 818.703435837s] Trained 128 records in 0.075575424 seconds. Throughput is 1693.6722 records/second. Loss is 0.23376945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035721940415803385. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11264/60000][Iteration 8999][Wall Clock 818.781753863s] Trained 128 records in 0.078318026 seconds. Throughput is 1634.3618 records/second. Loss is 0.12422867. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035719388484069157. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11392/60000][Iteration 9000][Wall Clock 818.861071244s] Trained 128 records in 0.079317381 seconds. Throughput is 1613.7698 records/second. Loss is 0.16644357. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035716836916922633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11520/60000][Iteration 9001][Wall Clock 818.938125563s] Trained 128 records in 0.077054319 seconds. Throughput is 1661.1658 records/second. Loss is 0.18577719. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035714285714285718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11648/60000][Iteration 9002][Wall Clock 819.011051048s] Trained 128 records in 0.072925485 seconds. Throughput is 1755.2163 records/second. Loss is 0.155989. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035711734876080277. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11776/60000][Iteration 9003][Wall Clock 819.089965774s] Trained 128 records in 0.078914726 seconds. Throughput is 1622.004 records/second. Loss is 0.15060009. Sequential31006cbd's hyper parameters: Current learning rate is 0.003570918440222826. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 11904/60000][Iteration 9004][Wall Clock 819.16551334s] Trained 128 records in 0.075547566 seconds. Throughput is 1694.2968 records/second. Loss is 0.17740902. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035706634292651572. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 12032/60000][Iteration 9005][Wall Clock 819.248003936s] Trained 128 records in 0.082490596 seconds. Throughput is 1551.6921 records/second. Loss is 0.21816698. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035704084547272205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 12160/60000][Iteration 9006][Wall Clock 819.325098585s] Trained 128 records in 0.077094649 seconds. Throughput is 1660.2968 records/second. Loss is 0.14527717. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035701535166012136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 12288/60000][Iteration 9007][Wall Clock 819.397772689s] Trained 128 records in 0.072674104 seconds. Throughput is 1761.2876 records/second. Loss is 0.12455256. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035698986148793373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 12416/60000][Iteration 9008][Wall Clock 819.469861893s] Trained 128 records in 0.072089204 seconds. Throughput is 1775.578 records/second. Loss is 0.13411644. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035696437495537944. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:16 INFO  DistriOptimizer$:408 - [Epoch 20 12544/60000][Iteration 9009][Wall Clock 819.544032916s] Trained 128 records in 0.074171023 seconds. Throughput is 1725.7413 records/second. Loss is 0.06861952. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035693889206167904. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 12672/60000][Iteration 9010][Wall Clock 819.623026384s] Trained 128 records in 0.078993468 seconds. Throughput is 1620.3871 records/second. Loss is 0.20990536. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035691341280605325. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 12800/60000][Iteration 9011][Wall Clock 819.712031698s] Trained 128 records in 0.089005314 seconds. Throughput is 1438.1163 records/second. Loss is 0.0857922. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035688793718772305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 12928/60000][Iteration 9012][Wall Clock 819.794826346s] Trained 128 records in 0.082794648 seconds. Throughput is 1545.9935 records/second. Loss is 0.10616557. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035686246520590967. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13056/60000][Iteration 9013][Wall Clock 819.901488001s] Trained 128 records in 0.106661655 seconds. Throughput is 1200.0564 records/second. Loss is 0.13303423. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035683699685983444. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13184/60000][Iteration 9014][Wall Clock 819.983833334s] Trained 128 records in 0.082345333 seconds. Throughput is 1554.4292 records/second. Loss is 0.12229929. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035681153214871908. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13312/60000][Iteration 9015][Wall Clock 820.066316728s] Trained 128 records in 0.082483394 seconds. Throughput is 1551.8275 records/second. Loss is 0.18426804. Sequential31006cbd's hyper parameters: Current learning rate is 0.003567860710717853. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13440/60000][Iteration 9016][Wall Clock 820.145434806s] Trained 128 records in 0.079118078 seconds. Throughput is 1617.835 records/second. Loss is 0.17581144. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035676061362825548. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13568/60000][Iteration 9017][Wall Clock 820.22531097s] Trained 128 records in 0.079876164 seconds. Throughput is 1602.4806 records/second. Loss is 0.08573392. Sequential31006cbd's hyper parameters: Current learning rate is 0.003567351598173516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13696/60000][Iteration 9018][Wall Clock 820.312383263s] Trained 128 records in 0.087072293 seconds. Throughput is 1470.0428 records/second. Loss is 0.14900997. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035670970963829637. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13824/60000][Iteration 9019][Wall Clock 820.407478921s] Trained 128 records in 0.095095658 seconds. Throughput is 1346.0131 records/second. Loss is 0.1661505. Sequential31006cbd's hyper parameters: Current learning rate is 0.003566842630903124. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:17 INFO  DistriOptimizer$:408 - [Epoch 20 13952/60000][Iteration 9020][Wall Clock 820.48448495s] Trained 128 records in 0.077006029 seconds. Throughput is 1662.2075 records/second. Loss is 0.13756937. Sequential31006cbd's hyper parameters: Current learning rate is 0.003566588201726229. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14080/60000][Iteration 9021][Wall Clock 820.565280033s] Trained 128 records in 0.080795083 seconds. Throughput is 1584.2549 records/second. Loss is 0.1518754. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035663338088445075. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14208/60000][Iteration 9022][Wall Clock 820.644158948s] Trained 128 records in 0.078878915 seconds. Throughput is 1622.7404 records/second. Loss is 0.117174685. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035660794522501963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14336/60000][Iteration 9023][Wall Clock 820.721013046s] Trained 128 records in 0.076854098 seconds. Throughput is 1665.4935 records/second. Loss is 0.15878251. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035658251319355297. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14464/60000][Iteration 9024][Wall Clock 820.797164468s] Trained 128 records in 0.076151422 seconds. Throughput is 1680.8616 records/second. Loss is 0.15464765. Sequential31006cbd's hyper parameters: Current learning rate is 0.003565570847892748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14592/60000][Iteration 9025][Wall Clock 820.870638996s] Trained 128 records in 0.073474528 seconds. Throughput is 1742.1003 records/second. Loss is 0.28383622. Sequential31006cbd's hyper parameters: Current learning rate is 0.00356531660011409. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14720/60000][Iteration 9026][Wall Clock 820.947761263s] Trained 128 records in 0.077122267 seconds. Throughput is 1659.7023 records/second. Loss is 0.24014139. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035650623885918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14848/60000][Iteration 9027][Wall Clock 821.030007214s] Trained 128 records in 0.082245951 seconds. Throughput is 1556.3076 records/second. Loss is 0.17073074. Sequential31006cbd's hyper parameters: Current learning rate is 0.003564808213318123. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 14976/60000][Iteration 9028][Wall Clock 821.123648241s] Trained 128 records in 0.093641027 seconds. Throughput is 1366.9222 records/second. Loss is 0.08588541. Sequential31006cbd's hyper parameters: Current learning rate is 0.003564554074285307. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 15104/60000][Iteration 9029][Wall Clock 821.20289591s] Trained 128 records in 0.079247669 seconds. Throughput is 1615.1895 records/second. Loss is 0.17028674. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035642999714856002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 15232/60000][Iteration 9030][Wall Clock 821.28706037s] Trained 128 records in 0.08416446 seconds. Throughput is 1520.8319 records/second. Loss is 0.1467067. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035640459049112554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 15360/60000][Iteration 9031][Wall Clock 821.370404707s] Trained 128 records in 0.083344337 seconds. Throughput is 1535.7971 records/second. Loss is 0.079981364. Sequential31006cbd's hyper parameters: Current learning rate is 0.003563791874554526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 15488/60000][Iteration 9032][Wall Clock 821.44397024s] Trained 128 records in 0.073565533 seconds. Throughput is 1739.9452 records/second. Loss is 0.14359972. Sequential31006cbd's hyper parameters: Current learning rate is 0.003563537880407669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:18 INFO  DistriOptimizer$:408 - [Epoch 20 15616/60000][Iteration 9033][Wall Clock 821.521407519s] Trained 128 records in 0.077437279 seconds. Throughput is 1652.9506 records/second. Loss is 0.062468942. Sequential31006cbd's hyper parameters: Current learning rate is 0.003563283922462942. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 15744/60000][Iteration 9034][Wall Clock 821.59664008s] Trained 128 records in 0.075232561 seconds. Throughput is 1701.391 records/second. Loss is 0.25767195. Sequential31006cbd's hyper parameters: Current learning rate is 0.003563030000712606. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 15872/60000][Iteration 9035][Wall Clock 821.672593412s] Trained 128 records in 0.075953332 seconds. Throughput is 1685.2452 records/second. Loss is 0.10309283. Sequential31006cbd's hyper parameters: Current learning rate is 0.003562776115148924. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16000/60000][Iteration 9036][Wall Clock 821.749293452s] Trained 128 records in 0.07670004 seconds. Throughput is 1668.8387 records/second. Loss is 0.09012049. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035625222657641605. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16128/60000][Iteration 9037][Wall Clock 821.834210135s] Trained 128 records in 0.084916683 seconds. Throughput is 1507.3599 records/second. Loss is 0.13460736. Sequential31006cbd's hyper parameters: Current learning rate is 0.003562268452550584. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16256/60000][Iteration 9038][Wall Clock 821.909192982s] Trained 128 records in 0.074982847 seconds. Throughput is 1707.0571 records/second. Loss is 0.14350337. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035620146755004625. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16384/60000][Iteration 9039][Wall Clock 822.001991087s] Trained 128 records in 0.092798105 seconds. Throughput is 1379.3385 records/second. Loss is 0.21996991. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035617609346060694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16512/60000][Iteration 9040][Wall Clock 822.104973006s] Trained 128 records in 0.102981919 seconds. Throughput is 1242.9366 records/second. Loss is 0.19480234. Sequential31006cbd's hyper parameters: Current learning rate is 0.003561507229859676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16640/60000][Iteration 9041][Wall Clock 822.193781328s] Trained 128 records in 0.088808322 seconds. Throughput is 1441.3064 records/second. Loss is 0.06878479. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035612535612535618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16768/60000][Iteration 9042][Wall Clock 822.286916574s] Trained 128 records in 0.093135246 seconds. Throughput is 1374.3455 records/second. Loss is 0.098181725. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035609999287800013. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 16896/60000][Iteration 9043][Wall Clock 822.365971199s] Trained 128 records in 0.079054625 seconds. Throughput is 1619.1337 records/second. Loss is 0.12185034. Sequential31006cbd's hyper parameters: Current learning rate is 0.003560746332431278. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 17024/60000][Iteration 9044][Wall Clock 822.441438137s] Trained 128 records in 0.075466938 seconds. Throughput is 1696.1069 records/second. Loss is 0.17639276. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035604927721996724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:19 INFO  DistriOptimizer$:408 - [Epoch 20 17152/60000][Iteration 9045][Wall Clock 822.521939222s] Trained 128 records in 0.080501085 seconds. Throughput is 1590.0406 records/second. Loss is 0.08443442. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035602392480774707. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 17280/60000][Iteration 9046][Wall Clock 822.595548587s] Trained 128 records in 0.073609365 seconds. Throughput is 1738.9092 records/second. Loss is 0.12647757. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035599857600569595. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 17408/60000][Iteration 9047][Wall Clock 822.672126471s] Trained 128 records in 0.076577884 seconds. Throughput is 1671.5009 records/second. Loss is 0.08850905. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035597323081304286. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 17536/60000][Iteration 9048][Wall Clock 822.756210157s] Trained 128 records in 0.084083686 seconds. Throughput is 1522.293 records/second. Loss is 0.094116196. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035594788922901684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 17664/60000][Iteration 9049][Wall Clock 822.832919911s] Trained 128 records in 0.076709754 seconds. Throughput is 1668.6274 records/second. Loss is 0.1478096. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035592255125284737. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 17792/60000][Iteration 9050][Wall Clock 822.913017215s] Trained 128 records in 0.080097304 seconds. Throughput is 1598.0563 records/second. Loss is 0.16268337. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035589721688376397. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 17920/60000][Iteration 9051][Wall Clock 822.996502471s] Trained 128 records in 0.083485256 seconds. Throughput is 1533.205 records/second. Loss is 0.09854978. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035587188612099642. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18048/60000][Iteration 9052][Wall Clock 823.068128522s] Trained 128 records in 0.071626051 seconds. Throughput is 1787.0592 records/second. Loss is 0.23371874. Sequential31006cbd's hyper parameters: Current learning rate is 0.003558465589637748. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18176/60000][Iteration 9053][Wall Clock 823.139449073s] Trained 128 records in 0.071320551 seconds. Throughput is 1794.7142 records/second. Loss is 0.13838387. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035582123541132936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18304/60000][Iteration 9054][Wall Clock 823.217037334s] Trained 128 records in 0.077588261 seconds. Throughput is 1649.7341 records/second. Loss is 0.12611435. Sequential31006cbd's hyper parameters: Current learning rate is 0.003557959154628905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18432/60000][Iteration 9055][Wall Clock 823.293169687s] Trained 128 records in 0.076132353 seconds. Throughput is 1681.2827 records/second. Loss is 0.13186087. Sequential31006cbd's hyper parameters: Current learning rate is 0.003557705991176889. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18560/60000][Iteration 9056][Wall Clock 823.368862818s] Trained 128 records in 0.075693131 seconds. Throughput is 1691.0386 records/second. Loss is 0.23150085. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035574528637495554. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18688/60000][Iteration 9057][Wall Clock 823.44721608s] Trained 128 records in 0.078353262 seconds. Throughput is 1633.627 records/second. Loss is 0.2697883. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035571997723392143. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:20 INFO  DistriOptimizer$:408 - [Epoch 20 18816/60000][Iteration 9058][Wall Clock 823.521124114s] Trained 128 records in 0.073908034 seconds. Throughput is 1731.8822 records/second. Loss is 0.19474548. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035569467169381803. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 18944/60000][Iteration 9059][Wall Clock 823.595067981s] Trained 128 records in 0.073943867 seconds. Throughput is 1731.0428 records/second. Loss is 0.13091773. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035566936975387677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19072/60000][Iteration 9060][Wall Clock 823.668022587s] Trained 128 records in 0.072954606 seconds. Throughput is 1754.5157 records/second. Loss is 0.13857001. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035564407141332956. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19200/60000][Iteration 9061][Wall Clock 823.757138796s] Trained 128 records in 0.089116209 seconds. Throughput is 1436.3268 records/second. Loss is 0.11433038. Sequential31006cbd's hyper parameters: Current learning rate is 0.003556187766714082. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19328/60000][Iteration 9062][Wall Clock 823.833005021s] Trained 128 records in 0.075866225 seconds. Throughput is 1687.1803 records/second. Loss is 0.14514409. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035559348552734516. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19456/60000][Iteration 9063][Wall Clock 823.942224881s] Trained 128 records in 0.10921986 seconds. Throughput is 1171.9481 records/second. Loss is 0.18801439. Sequential31006cbd's hyper parameters: Current learning rate is 0.003555681979803726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19584/60000][Iteration 9064][Wall Clock 824.02658005s] Trained 128 records in 0.084355169 seconds. Throughput is 1517.3937 records/second. Loss is 0.13231689. Sequential31006cbd's hyper parameters: Current learning rate is 0.003555429140297234. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19712/60000][Iteration 9065][Wall Clock 824.111422021s] Trained 128 records in 0.084841971 seconds. Throughput is 1508.6873 records/second. Loss is 0.096618354. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035551763367463025. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19840/60000][Iteration 9066][Wall Clock 824.199682666s] Trained 128 records in 0.088260645 seconds. Throughput is 1450.25 records/second. Loss is 0.13113266. Sequential31006cbd's hyper parameters: Current learning rate is 0.003554923569143263. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 19968/60000][Iteration 9067][Wall Clock 824.276118387s] Trained 128 records in 0.076435721 seconds. Throughput is 1674.6096 records/second. Loss is 0.18123452. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035546708374804494. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 20096/60000][Iteration 9068][Wall Clock 824.356688904s] Trained 128 records in 0.080570517 seconds. Throughput is 1588.6704 records/second. Loss is 0.17988516. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035544181417501955. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 20224/60000][Iteration 9069][Wall Clock 824.43348774s] Trained 128 records in 0.076798836 seconds. Throughput is 1666.692 records/second. Loss is 0.1421076. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035541654819448393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:21 INFO  DistriOptimizer$:408 - [Epoch 20 20352/60000][Iteration 9070][Wall Clock 824.519577618s] Trained 128 records in 0.086089878 seconds. Throughput is 1486.8182 records/second. Loss is 0.14544435. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035539128580567205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 20480/60000][Iteration 9071][Wall Clock 824.613945659s] Trained 128 records in 0.094368041 seconds. Throughput is 1356.3914 records/second. Loss is 0.12980436. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035536602700781805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 20608/60000][Iteration 9072][Wall Clock 824.694697675s] Trained 128 records in 0.080752016 seconds. Throughput is 1585.0997 records/second. Loss is 0.16601503. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035534077180015633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 20736/60000][Iteration 9073][Wall Clock 824.774443393s] Trained 128 records in 0.079745718 seconds. Throughput is 1605.1019 records/second. Loss is 0.12400147. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035531552018192155. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 20864/60000][Iteration 9074][Wall Clock 824.845986352s] Trained 128 records in 0.071542959 seconds. Throughput is 1789.1349 records/second. Loss is 0.12669078. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035529027215234848. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 20992/60000][Iteration 9075][Wall Clock 824.914971271s] Trained 128 records in 0.068984919 seconds. Throughput is 1855.478 records/second. Loss is 0.16867456. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035526502771067218. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21120/60000][Iteration 9076][Wall Clock 824.99242912s] Trained 128 records in 0.077457849 seconds. Throughput is 1652.5116 records/second. Loss is 0.12459412. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035523978685612786. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21248/60000][Iteration 9077][Wall Clock 825.070565612s] Trained 128 records in 0.078136492 seconds. Throughput is 1638.159 records/second. Loss is 0.12778923. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035521454958795115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21376/60000][Iteration 9078][Wall Clock 825.145900888s] Trained 128 records in 0.075335276 seconds. Throughput is 1699.0712 records/second. Loss is 0.16349328. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035518931590537753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21504/60000][Iteration 9079][Wall Clock 825.224381844s] Trained 128 records in 0.078480956 seconds. Throughput is 1630.9689 records/second. Loss is 0.14439845. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035516408580764315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21632/60000][Iteration 9080][Wall Clock 825.297957808s] Trained 128 records in 0.073575964 seconds. Throughput is 1739.6985 records/second. Loss is 0.13656366. Sequential31006cbd's hyper parameters: Current learning rate is 0.003551388592939839. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21760/60000][Iteration 9081][Wall Clock 825.377326654s] Trained 128 records in 0.079368846 seconds. Throughput is 1612.7235 records/second. Loss is 0.12602022. Sequential31006cbd's hyper parameters: Current learning rate is 0.003551136363636364. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 21888/60000][Iteration 9082][Wall Clock 825.450921068s] Trained 128 records in 0.073594414 seconds. Throughput is 1739.2625 records/second. Loss is 0.15390599. Sequential31006cbd's hyper parameters: Current learning rate is 0.003550884170158369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:22 INFO  DistriOptimizer$:408 - [Epoch 20 22016/60000][Iteration 9083][Wall Clock 825.525445342s] Trained 128 records in 0.074524274 seconds. Throughput is 1717.5612 records/second. Loss is 0.1502528. Sequential31006cbd's hyper parameters: Current learning rate is 0.003550632012498225. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22144/60000][Iteration 9084][Wall Clock 825.600638062s] Trained 128 records in 0.07519272 seconds. Throughput is 1702.2925 records/second. Loss is 0.20604981. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035503798906482992. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22272/60000][Iteration 9085][Wall Clock 825.703324813s] Trained 128 records in 0.102686751 seconds. Throughput is 1246.5094 records/second. Loss is 0.09071522. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035501278046009654. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22400/60000][Iteration 9086][Wall Clock 825.802484055s] Trained 128 records in 0.099159242 seconds. Throughput is 1290.8529 records/second. Loss is 0.1619792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035498757543485976. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22528/60000][Iteration 9087][Wall Clock 825.886736525s] Trained 128 records in 0.08425247 seconds. Throughput is 1519.2433 records/second. Loss is 0.10106147. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035496237398835724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22656/60000][Iteration 9088][Wall Clock 825.972101186s] Trained 128 records in 0.085364661 seconds. Throughput is 1499.4495 records/second. Loss is 0.15345001. Sequential31006cbd's hyper parameters: Current learning rate is 0.003549371761198268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22784/60000][Iteration 9089][Wall Clock 826.055422676s] Trained 128 records in 0.08332149 seconds. Throughput is 1536.2184 records/second. Loss is 0.0734691. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035491198182850655. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 22912/60000][Iteration 9090][Wall Clock 826.141291963s] Trained 128 records in 0.085869287 seconds. Throughput is 1490.6377 records/second. Loss is 0.103014074. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035488679111363476. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 23040/60000][Iteration 9091][Wall Clock 826.226501785s] Trained 128 records in 0.085209822 seconds. Throughput is 1502.1742 records/second. Loss is 0.18501547. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035486160397444995. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 23168/60000][Iteration 9092][Wall Clock 826.301273909s] Trained 128 records in 0.074772124 seconds. Throughput is 1711.8678 records/second. Loss is 0.14340988. Sequential31006cbd's hyper parameters: Current learning rate is 0.003548364204101909. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 23296/60000][Iteration 9093][Wall Clock 826.378921673s] Trained 128 records in 0.077647764 seconds. Throughput is 1648.47 records/second. Loss is 0.112663046. Sequential31006cbd's hyper parameters: Current learning rate is 0.003548112404200965. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 23424/60000][Iteration 9094][Wall Clock 826.457862618s] Trained 128 records in 0.078940945 seconds. Throughput is 1621.4653 records/second. Loss is 0.20373408. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035478606400340595. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:23 INFO  DistriOptimizer$:408 - [Epoch 20 23552/60000][Iteration 9095][Wall Clock 826.534440064s] Trained 128 records in 0.076577446 seconds. Throughput is 1671.5104 records/second. Loss is 0.08450204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035476089115935856. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 23680/60000][Iteration 9096][Wall Clock 826.620295883s] Trained 128 records in 0.085855819 seconds. Throughput is 1490.8716 records/second. Loss is 0.17048338. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035473572188719407. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 23808/60000][Iteration 9097][Wall Clock 826.690334616s] Trained 128 records in 0.070038733 seconds. Throughput is 1827.56 records/second. Loss is 0.1624241. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035471055618615205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 23936/60000][Iteration 9098][Wall Clock 826.764493499s] Trained 128 records in 0.074158883 seconds. Throughput is 1726.0238 records/second. Loss is 0.12792386. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035468539405547283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24064/60000][Iteration 9099][Wall Clock 826.843444211s] Trained 128 records in 0.078950712 seconds. Throughput is 1621.2646 records/second. Loss is 0.12867805. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035466023549439634. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24192/60000][Iteration 9100][Wall Clock 826.920166992s] Trained 128 records in 0.076722781 seconds. Throughput is 1668.3441 records/second. Loss is 0.14242765. Sequential31006cbd's hyper parameters: Current learning rate is 0.003546350805021633. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24320/60000][Iteration 9101][Wall Clock 826.99573316s] Trained 128 records in 0.075566168 seconds. Throughput is 1693.8798 records/second. Loss is 0.21237631. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035460992907801418. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24448/60000][Iteration 9102][Wall Clock 827.072721755s] Trained 128 records in 0.076988595 seconds. Throughput is 1662.584 records/second. Loss is 0.21280529. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035458478122119. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24576/60000][Iteration 9103][Wall Clock 827.155465047s] Trained 128 records in 0.082743292 seconds. Throughput is 1546.9531 records/second. Loss is 0.14521173. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035455963693093178. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24704/60000][Iteration 9104][Wall Clock 827.227321621s] Trained 128 records in 0.071856574 seconds. Throughput is 1781.3263 records/second. Loss is 0.14067334. Sequential31006cbd's hyper parameters: Current learning rate is 0.003545344962064809. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24832/60000][Iteration 9105][Wall Clock 827.309437832s] Trained 128 records in 0.082116211 seconds. Throughput is 1558.7666 records/second. Loss is 0.08482778. Sequential31006cbd's hyper parameters: Current learning rate is 0.003545093590470788. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 24960/60000][Iteration 9106][Wall Clock 827.389966173s] Trained 128 records in 0.080528341 seconds. Throughput is 1589.5026 records/second. Loss is 0.052485175. Sequential31006cbd's hyper parameters: Current learning rate is 0.003544842254519674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:24 INFO  DistriOptimizer$:408 - [Epoch 20 25088/60000][Iteration 9107][Wall Clock 827.470464624s] Trained 128 records in 0.080498451 seconds. Throughput is 1590.0928 records/second. Loss is 0.08764091. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035445909542038846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25216/60000][Iteration 9108][Wall Clock 827.565650185s] Trained 128 records in 0.095185561 seconds. Throughput is 1344.7417 records/second. Loss is 0.121577576. Sequential31006cbd's hyper parameters: Current learning rate is 0.003544339689515843. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25344/60000][Iteration 9109][Wall Clock 827.670989596s] Trained 128 records in 0.105339411 seconds. Throughput is 1215.1198 records/second. Loss is 0.14992347. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035440884604479726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25472/60000][Iteration 9110][Wall Clock 827.758090855s] Trained 128 records in 0.087101259 seconds. Throughput is 1469.554 records/second. Loss is 0.19099587. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035438372669927. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25600/60000][Iteration 9111][Wall Clock 827.840866627s] Trained 128 records in 0.082775772 seconds. Throughput is 1546.3462 records/second. Loss is 0.16527678. Sequential31006cbd's hyper parameters: Current learning rate is 0.003543586109142452. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25728/60000][Iteration 9112][Wall Clock 827.921741539s] Trained 128 records in 0.080874912 seconds. Throughput is 1582.691 records/second. Loss is 0.16171227. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035433349868896607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25856/60000][Iteration 9113][Wall Clock 827.99228931s] Trained 128 records in 0.070547771 seconds. Throughput is 1814.3733 records/second. Loss is 0.1649724. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035430839002267575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 25984/60000][Iteration 9114][Wall Clock 828.107905029s] Trained 128 records in 0.115615719 seconds. Throughput is 1107.1158 records/second. Loss is 0.17478774. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035428328491461775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 26112/60000][Iteration 9115][Wall Clock 828.205679825s] Trained 128 records in 0.097774796 seconds. Throughput is 1309.1309 records/second. Loss is 0.18385836. Sequential31006cbd's hyper parameters: Current learning rate is 0.003542581833640357. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 26240/60000][Iteration 9116][Wall Clock 828.286919909s] Trained 128 records in 0.081240084 seconds. Throughput is 1575.577 records/second. Loss is 0.093040384. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035423308537017354. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 26368/60000][Iteration 9117][Wall Clock 828.366134915s] Trained 128 records in 0.079215006 seconds. Throughput is 1615.8555 records/second. Loss is 0.13354513. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035420799093227543. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 26496/60000][Iteration 9118][Wall Clock 828.451807711s] Trained 128 records in 0.085672796 seconds. Throughput is 1494.0565 records/second. Loss is 0.10574466. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035418290004958558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:25 INFO  DistriOptimizer$:408 - [Epoch 20 26624/60000][Iteration 9119][Wall Clock 828.529048184s] Trained 128 records in 0.077240473 seconds. Throughput is 1657.1622 records/second. Loss is 0.10374803. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035415781272134864. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 26752/60000][Iteration 9120][Wall Clock 828.610233051s] Trained 128 records in 0.081184867 seconds. Throughput is 1576.6486 records/second. Loss is 0.14101104. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035413272894680922. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 26880/60000][Iteration 9121][Wall Clock 828.687176152s] Trained 128 records in 0.076943101 seconds. Throughput is 1663.567 records/second. Loss is 0.11217651. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035410764872521247. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27008/60000][Iteration 9122][Wall Clock 828.776322957s] Trained 128 records in 0.089146805 seconds. Throughput is 1435.8339 records/second. Loss is 0.11101882. Sequential31006cbd's hyper parameters: Current learning rate is 0.003540825720558034. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27136/60000][Iteration 9123][Wall Clock 828.866577277s] Trained 128 records in 0.09025432 seconds. Throughput is 1418.2146 records/second. Loss is 0.12424735. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035405749893782754. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27264/60000][Iteration 9124][Wall Clock 828.945946767s] Trained 128 records in 0.07936949 seconds. Throughput is 1612.7103 records/second. Loss is 0.1205596. Sequential31006cbd's hyper parameters: Current learning rate is 0.003540324293705303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27392/60000][Iteration 9125][Wall Clock 829.031810769s] Trained 128 records in 0.085864002 seconds. Throughput is 1490.7295 records/second. Loss is 0.14991844. Sequential31006cbd's hyper parameters: Current learning rate is 0.003540073633531578. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27520/60000][Iteration 9126][Wall Clock 829.115007824s] Trained 128 records in 0.083197055 seconds. Throughput is 1538.516 records/second. Loss is 0.12912363. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035398230088495575. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27648/60000][Iteration 9127][Wall Clock 829.19209495s] Trained 128 records in 0.077087126 seconds. Throughput is 1660.4589 records/second. Loss is 0.10751158. Sequential31006cbd's hyper parameters: Current learning rate is 0.003539572419651706. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27776/60000][Iteration 9128][Wall Clock 829.268889195s] Trained 128 records in 0.076794245 seconds. Throughput is 1666.7916 records/second. Loss is 0.1626644. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035393218659304877. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 27904/60000][Iteration 9129][Wall Clock 829.341793009s] Trained 128 records in 0.072903814 seconds. Throughput is 1755.738 records/second. Loss is 0.16199036. Sequential31006cbd's hyper parameters: Current learning rate is 0.003539071347678369. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 28032/60000][Iteration 9130][Wall Clock 829.422317157s] Trained 128 records in 0.080524148 seconds. Throughput is 1589.5853 records/second. Loss is 0.103808165. Sequential31006cbd's hyper parameters: Current learning rate is 0.003538820864887819. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:26 INFO  DistriOptimizer$:408 - [Epoch 20 28160/60000][Iteration 9131][Wall Clock 829.512899167s] Trained 128 records in 0.09058201 seconds. Throughput is 1413.0841 records/second. Loss is 0.17916265. Sequential31006cbd's hyper parameters: Current learning rate is 0.003538570417551309. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 28288/60000][Iteration 9132][Wall Clock 829.594692407s] Trained 128 records in 0.08179324 seconds. Throughput is 1564.9215 records/second. Loss is 0.12985782. Sequential31006cbd's hyper parameters: Current learning rate is 0.003538320005661312. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 28416/60000][Iteration 9133][Wall Clock 829.667490017s] Trained 128 records in 0.07279761 seconds. Throughput is 1758.2994 records/second. Loss is 0.2608917. Sequential31006cbd's hyper parameters: Current learning rate is 0.003538069629210303. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 28544/60000][Iteration 9134][Wall Clock 829.742815383s] Trained 128 records in 0.075325366 seconds. Throughput is 1699.2948 records/second. Loss is 0.10123207. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035378192881907592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 28672/60000][Iteration 9135][Wall Clock 829.819468326s] Trained 128 records in 0.076652943 seconds. Throughput is 1669.8641 records/second. Loss is 0.14576945. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035375689825951607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 28800/60000][Iteration 9136][Wall Clock 829.89878944s] Trained 128 records in 0.079321114 seconds. Throughput is 1613.6938 records/second. Loss is 0.12048644. Sequential31006cbd's hyper parameters: Current learning rate is 0.003537318712415989. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 28928/60000][Iteration 9137][Wall Clock 829.972165649s] Trained 128 records in 0.073376209 seconds. Throughput is 1744.4347 records/second. Loss is 0.17821103. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035370684776457268. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 29056/60000][Iteration 9138][Wall Clock 830.04571463s] Trained 128 records in 0.073548981 seconds. Throughput is 1740.3368 records/second. Loss is 0.1704433. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035368182782768622. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 29184/60000][Iteration 9139][Wall Clock 830.132625732s] Trained 128 records in 0.086911102 seconds. Throughput is 1472.7692 records/second. Loss is 0.1887764. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035365681143018812. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 29312/60000][Iteration 9140][Wall Clock 830.217348579s] Trained 128 records in 0.084722847 seconds. Throughput is 1510.8086 records/second. Loss is 0.063280895. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035363179857132755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 29440/60000][Iteration 9141][Wall Clock 830.293335639s] Trained 128 records in 0.07598706 seconds. Throughput is 1684.4973 records/second. Loss is 0.15734953. Sequential31006cbd's hyper parameters: Current learning rate is 0.003536067892503536. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 29568/60000][Iteration 9142][Wall Clock 830.37839917s] Trained 128 records in 0.085063531 seconds. Throughput is 1504.7577 records/second. Loss is 0.1466557. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035358178346651583. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:27 INFO  DistriOptimizer$:408 - [Epoch 20 29696/60000][Iteration 9143][Wall Clock 830.455323384s] Trained 128 records in 0.076924214 seconds. Throughput is 1663.9755 records/second. Loss is 0.08765777. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035355678121906375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 29824/60000][Iteration 9144][Wall Clock 830.532043999s] Trained 128 records in 0.076720615 seconds. Throughput is 1668.3911 records/second. Loss is 0.14822586. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035353178250724744. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 29952/60000][Iteration 9145][Wall Clock 830.620914549s] Trained 128 records in 0.08887055 seconds. Throughput is 1440.2972 records/second. Loss is 0.1270892. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035350678733031674. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30080/60000][Iteration 9146][Wall Clock 830.702294552s] Trained 128 records in 0.081380003 seconds. Throughput is 1572.868 records/second. Loss is 0.1609157. Sequential31006cbd's hyper parameters: Current learning rate is 0.003534817956875221. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30208/60000][Iteration 9147][Wall Clock 830.782143053s] Trained 128 records in 0.079848501 seconds. Throughput is 1603.0358 records/second. Loss is 0.18528365. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035345680757811393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30336/60000][Iteration 9148][Wall Clock 830.852232625s] Trained 128 records in 0.070089572 seconds. Throughput is 1826.2346 records/second. Loss is 0.15066859. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035343182300134304. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30464/60000][Iteration 9149][Wall Clock 830.933107107s] Trained 128 records in 0.080874482 seconds. Throughput is 1582.6995 records/second. Loss is 0.074561834. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035340684195646027. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30592/60000][Iteration 9150][Wall Clock 831.011265857s] Trained 128 records in 0.07815875 seconds. Throughput is 1637.6925 records/second. Loss is 0.15035495. Sequential31006cbd's hyper parameters: Current learning rate is 0.003533818644427168. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30720/60000][Iteration 9151][Wall Clock 831.085969445s] Trained 128 records in 0.074703588 seconds. Throughput is 1713.4385 records/second. Loss is 0.14518073. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035335689045936395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30848/60000][Iteration 9152][Wall Clock 831.160101227s] Trained 128 records in 0.074131782 seconds. Throughput is 1726.6549 records/second. Loss is 0.18289232. Sequential31006cbd's hyper parameters: Current learning rate is 0.003533319200056533. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 30976/60000][Iteration 9153][Wall Clock 831.243039958s] Trained 128 records in 0.082938731 seconds. Throughput is 1543.3079 records/second. Loss is 0.15755163. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035330695308083662. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 31104/60000][Iteration 9154][Wall Clock 831.319002919s] Trained 128 records in 0.075962961 seconds. Throughput is 1685.0317 records/second. Loss is 0.112470426. Sequential31006cbd's hyper parameters: Current learning rate is 0.003532819896841659. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 31232/60000][Iteration 9155][Wall Clock 831.406496884s] Trained 128 records in 0.087493965 seconds. Throughput is 1462.9581 records/second. Loss is 0.16756892. Sequential31006cbd's hyper parameters: Current learning rate is 0.003532570298148933. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:28 INFO  DistriOptimizer$:408 - [Epoch 20 31360/60000][Iteration 9156][Wall Clock 831.491727655s] Trained 128 records in 0.085230771 seconds. Throughput is 1501.805 records/second. Loss is 0.12769006. Sequential31006cbd's hyper parameters: Current learning rate is 0.003532320734722712. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 31488/60000][Iteration 9157][Wall Clock 831.57710958s] Trained 128 records in 0.085381925 seconds. Throughput is 1499.1464 records/second. Loss is 0.17585611. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035320712065555243. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 31616/60000][Iteration 9158][Wall Clock 831.671547293s] Trained 128 records in 0.094437713 seconds. Throughput is 1355.3907 records/second. Loss is 0.091444984. Sequential31006cbd's hyper parameters: Current learning rate is 0.003531821713639895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 31744/60000][Iteration 9159][Wall Clock 831.751722808s] Trained 128 records in 0.080175515 seconds. Throughput is 1596.4974 records/second. Loss is 0.059851117. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035315722559683574. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 31872/60000][Iteration 9160][Wall Clock 831.828268677s] Trained 128 records in 0.076545869 seconds. Throughput is 1672.2 records/second. Loss is 0.20407115. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035313228335334414. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32000/60000][Iteration 9161][Wall Clock 831.904155384s] Trained 128 records in 0.075886707 seconds. Throughput is 1686.725 records/second. Loss is 0.090856835. Sequential31006cbd's hyper parameters: Current learning rate is 0.003531073446327684. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32128/60000][Iteration 9162][Wall Clock 831.978456847s] Trained 128 records in 0.074301463 seconds. Throughput is 1722.7117 records/second. Loss is 0.112088114. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035308240943436194. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32256/60000][Iteration 9163][Wall Clock 832.055988145s] Trained 128 records in 0.077531298 seconds. Throughput is 1650.9462 records/second. Loss is 0.15500204. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035305747775737895. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32384/60000][Iteration 9164][Wall Clock 832.129092773s] Trained 128 records in 0.073104628 seconds. Throughput is 1750.9152 records/second. Loss is 0.1324048. Sequential31006cbd's hyper parameters: Current learning rate is 0.003530325496010732. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32512/60000][Iteration 9165][Wall Clock 832.2208882s] Trained 128 records in 0.091795427 seconds. Throughput is 1394.4049 records/second. Loss is 0.19897401. Sequential31006cbd's hyper parameters: Current learning rate is 0.003530076249646993. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32640/60000][Iteration 9166][Wall Clock 832.314587451s] Trained 128 records in 0.093699251 seconds. Throughput is 1366.0728 records/second. Loss is 0.22635119. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035298270384751147. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32768/60000][Iteration 9167][Wall Clock 832.400562039s] Trained 128 records in 0.085974588 seconds. Throughput is 1488.812 records/second. Loss is 0.23820242. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035295778624876463. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:29 INFO  DistriOptimizer$:408 - [Epoch 20 32896/60000][Iteration 9168][Wall Clock 832.493043785s] Trained 128 records in 0.092481746 seconds. Throughput is 1384.0569 records/second. Loss is 0.12297779. Sequential31006cbd's hyper parameters: Current learning rate is 0.003529328721677137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33024/60000][Iteration 9169][Wall Clock 832.573480366s] Trained 128 records in 0.080436581 seconds. Throughput is 1591.3158 records/second. Loss is 0.14188905. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035290796160361375. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33152/60000][Iteration 9170][Wall Clock 832.647864348s] Trained 128 records in 0.074383982 seconds. Throughput is 1720.8007 records/second. Loss is 0.12988742. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035288305455572024. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33280/60000][Iteration 9171][Wall Clock 832.723367556s] Trained 128 records in 0.075503208 seconds. Throughput is 1695.2922 records/second. Loss is 0.228538. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035285815102328866. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33408/60000][Iteration 9172][Wall Clock 832.79703158s] Trained 128 records in 0.073664024 seconds. Throughput is 1737.6189 records/second. Loss is 0.1834641. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035283325100557475. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33536/60000][Iteration 9173][Wall Clock 832.877675562s] Trained 128 records in 0.080643982 seconds. Throughput is 1587.2233 records/second. Loss is 0.10396967. Sequential31006cbd's hyper parameters: Current learning rate is 0.003528083545018346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33664/60000][Iteration 9174][Wall Clock 832.956673169s] Trained 128 records in 0.078997607 seconds. Throughput is 1620.3022 records/second. Loss is 0.15393156. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035278346151132434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33792/60000][Iteration 9175][Wall Clock 833.035895384s] Trained 128 records in 0.079222215 seconds. Throughput is 1615.7084 records/second. Loss is 0.11907609. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035275857203330044. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 33920/60000][Iteration 9176][Wall Clock 833.116563915s] Trained 128 records in 0.080668531 seconds. Throughput is 1586.7402 records/second. Loss is 0.13088766. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035273368606701942. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 34048/60000][Iteration 9177][Wall Clock 833.201365775s] Trained 128 records in 0.08480186 seconds. Throughput is 1509.4009 records/second. Loss is 0.12360417. Sequential31006cbd's hyper parameters: Current learning rate is 0.003527088036117381. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 34176/60000][Iteration 9178][Wall Clock 833.287407005s] Trained 128 records in 0.08604123 seconds. Throughput is 1487.6589 records/second. Loss is 0.10714273. Sequential31006cbd's hyper parameters: Current learning rate is 0.003526839246667137. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 34304/60000][Iteration 9179][Wall Clock 833.370048671s] Trained 128 records in 0.082641666 seconds. Throughput is 1548.8555 records/second. Loss is 0.11410616. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035265904923120323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:30 INFO  DistriOptimizer$:408 - [Epoch 20 34432/60000][Iteration 9180][Wall Clock 833.453210514s] Trained 128 records in 0.083161843 seconds. Throughput is 1539.1674 records/second. Loss is 0.11118545. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035263417730446436. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 34560/60000][Iteration 9181][Wall Clock 833.534100202s] Trained 128 records in 0.080889688 seconds. Throughput is 1582.402 records/second. Loss is 0.13177925. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035260930888575456. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 34688/60000][Iteration 9182][Wall Clock 833.614027309s] Trained 128 records in 0.079927107 seconds. Throughput is 1601.4591 records/second. Loss is 0.09137668. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035258444397433188. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 34816/60000][Iteration 9183][Wall Clock 833.694439112s] Trained 128 records in 0.080411803 seconds. Throughput is 1591.806 records/second. Loss is 0.14363307. Sequential31006cbd's hyper parameters: Current learning rate is 0.003525595825694542. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 34944/60000][Iteration 9184][Wall Clock 833.772537062s] Trained 128 records in 0.07809795 seconds. Throughput is 1638.9675 records/second. Loss is 0.1303854. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035253472467038005. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35072/60000][Iteration 9185][Wall Clock 833.84995415s] Trained 128 records in 0.077417088 seconds. Throughput is 1653.3817 records/second. Loss is 0.14885125. Sequential31006cbd's hyper parameters: Current learning rate is 0.003525098702763677. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35200/60000][Iteration 9186][Wall Clock 833.923138136s] Trained 128 records in 0.073183986 seconds. Throughput is 1749.0166 records/second. Loss is 0.12792578. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035248501938667607. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35328/60000][Iteration 9187][Wall Clock 834.001025606s] Trained 128 records in 0.07788747 seconds. Throughput is 1643.3966 records/second. Loss is 0.14588219. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035246017200056393. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35456/60000][Iteration 9188][Wall Clock 834.079754838s] Trained 128 records in 0.078729232 seconds. Throughput is 1625.8256 records/second. Loss is 0.098258704. Sequential31006cbd's hyper parameters: Current learning rate is 0.003524353281172905. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35584/60000][Iteration 9189][Wall Clock 834.161359509s] Trained 128 records in 0.081604671 seconds. Throughput is 1568.5376 records/second. Loss is 0.16562605. Sequential31006cbd's hyper parameters: Current learning rate is 0.00352410487736115. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35712/60000][Iteration 9190][Wall Clock 834.251905132s] Trained 128 records in 0.090545623 seconds. Throughput is 1413.652 records/second. Loss is 0.12727624. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035238565085629714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35840/60000][Iteration 9191][Wall Clock 834.334531009s] Trained 128 records in 0.082625877 seconds. Throughput is 1549.1516 records/second. Loss is 0.17788343. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035236081747709656. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 35968/60000][Iteration 9192][Wall Clock 834.414678827s] Trained 128 records in 0.080147818 seconds. Throughput is 1597.0491 records/second. Loss is 0.14404228. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035233598759777324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:31 INFO  DistriOptimizer$:408 - [Epoch 20 36096/60000][Iteration 9193][Wall Clock 834.503892404s] Trained 128 records in 0.089213577 seconds. Throughput is 1434.7592 records/second. Loss is 0.2490125. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035231116121758736. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36224/60000][Iteration 9194][Wall Clock 834.583862228s] Trained 128 records in 0.079969824 seconds. Throughput is 1600.6038 records/second. Loss is 0.14076488. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035228633833579936. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36352/60000][Iteration 9195][Wall Clock 834.662624331s] Trained 128 records in 0.078762103 seconds. Throughput is 1625.147 records/second. Loss is 0.11823913. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035226151895166972. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36480/60000][Iteration 9196][Wall Clock 834.742131727s] Trained 128 records in 0.079507396 seconds. Throughput is 1609.9131 records/second. Loss is 0.10970744. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035223670306445925. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36608/60000][Iteration 9197][Wall Clock 834.818477459s] Trained 128 records in 0.076345732 seconds. Throughput is 1676.5835 records/second. Loss is 0.05396009. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035221189067342917. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36736/60000][Iteration 9198][Wall Clock 834.918243339s] Trained 128 records in 0.09976588 seconds. Throughput is 1283.0038 records/second. Loss is 0.1505562. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035218708177784035. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36864/60000][Iteration 9199][Wall Clock 835.023479411s] Trained 128 records in 0.105236072 seconds. Throughput is 1216.313 records/second. Loss is 0.15541384. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035216227637695453. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 36992/60000][Iteration 9200][Wall Clock 835.120321779s] Trained 128 records in 0.096842368 seconds. Throughput is 1321.7355 records/second. Loss is 0.10887362. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035213747447003308. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 37120/60000][Iteration 9201][Wall Clock 835.197497912s] Trained 128 records in 0.077176133 seconds. Throughput is 1658.5438 records/second. Loss is 0.14719792. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035211267605633804. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 37248/60000][Iteration 9202][Wall Clock 835.273283898s] Trained 128 records in 0.075785986 seconds. Throughput is 1688.9666 records/second. Loss is 0.16545074. Sequential31006cbd's hyper parameters: Current learning rate is 0.003520878811351313. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 37376/60000][Iteration 9203][Wall Clock 835.351838673s] Trained 128 records in 0.078554775 seconds. Throughput is 1629.4364 records/second. Loss is 0.11259494. Sequential31006cbd's hyper parameters: Current learning rate is 0.003520630897056753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:32 INFO  DistriOptimizer$:408 - [Epoch 20 37504/60000][Iteration 9204][Wall Clock 835.425722058s] Trained 128 records in 0.073883385 seconds. Throughput is 1732.4598 records/second. Loss is 0.17587179. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035203830176723226. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 37632/60000][Iteration 9205][Wall Clock 835.505818642s] Trained 128 records in 0.080096584 seconds. Throughput is 1598.0706 records/second. Loss is 0.13793503. Sequential31006cbd's hyper parameters: Current learning rate is 0.003520135173190651. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 37760/60000][Iteration 9206][Wall Clock 835.588794974s] Trained 128 records in 0.082976332 seconds. Throughput is 1542.6085 records/second. Loss is 0.064308584. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035198873636043647. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 37888/60000][Iteration 9207][Wall Clock 835.664429045s] Trained 128 records in 0.075634071 seconds. Throughput is 1692.359 records/second. Loss is 0.26153767. Sequential31006cbd's hyper parameters: Current learning rate is 0.003519639588906096. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38016/60000][Iteration 9208][Wall Clock 835.743552471s] Trained 128 records in 0.079123426 seconds. Throughput is 1617.7258 records/second. Loss is 0.06330609. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035193918490884772. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38144/60000][Iteration 9209][Wall Clock 835.823700897s] Trained 128 records in 0.080148426 seconds. Throughput is 1597.0369 records/second. Loss is 0.20196408. Sequential31006cbd's hyper parameters: Current learning rate is 0.003519144144144144. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38272/60000][Iteration 9210][Wall Clock 835.900092229s] Trained 128 records in 0.076391332 seconds. Throughput is 1675.5828 records/second. Loss is 0.09140184. Sequential31006cbd's hyper parameters: Current learning rate is 0.003518896474065733. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38400/60000][Iteration 9211][Wall Clock 835.977254704s] Trained 128 records in 0.077162475 seconds. Throughput is 1658.8374 records/second. Loss is 0.1788449. Sequential31006cbd's hyper parameters: Current learning rate is 0.003518648838845883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38528/60000][Iteration 9212][Wall Clock 836.061146781s] Trained 128 records in 0.083892077 seconds. Throughput is 1525.7698 records/second. Loss is 0.2162948. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035184012384772358. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38656/60000][Iteration 9213][Wall Clock 836.146111917s] Trained 128 records in 0.084965136 seconds. Throughput is 1506.5002 records/second. Loss is 0.13295083. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035181536729524347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38784/60000][Iteration 9214][Wall Clock 836.222101268s] Trained 128 records in 0.075989351 seconds. Throughput is 1684.4465 records/second. Loss is 0.15514372. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035179061422641244. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 38912/60000][Iteration 9215][Wall Clock 836.315131896s] Trained 128 records in 0.093030628 seconds. Throughput is 1375.8909 records/second. Loss is 0.114792794. Sequential31006cbd's hyper parameters: Current learning rate is 0.003517658646404953. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 39040/60000][Iteration 9216][Wall Clock 836.405250083s] Trained 128 records in 0.090118187 seconds. Throughput is 1420.357 records/second. Loss is 0.10669589. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035174111853675696. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:33 INFO  DistriOptimizer$:408 - [Epoch 20 39168/60000][Iteration 9217][Wall Clock 836.483582163s] Trained 128 records in 0.07833208 seconds. Throughput is 1634.0687 records/second. Loss is 0.12797686. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035171637591446254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 39296/60000][Iteration 9218][Wall Clock 836.552219587s] Trained 128 records in 0.068637424 seconds. Throughput is 1864.8718 records/second. Loss is 0.11413286. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035169163677287755. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 39424/60000][Iteration 9219][Wall Clock 836.630188279s] Trained 128 records in 0.077968692 seconds. Throughput is 1641.6846 records/second. Loss is 0.11589345. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035166690111126738. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 39552/60000][Iteration 9220][Wall Clock 836.723058043s] Trained 128 records in 0.092869764 seconds. Throughput is 1378.2742 records/second. Loss is 0.15925337. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035164216892889797. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 39680/60000][Iteration 9221][Wall Clock 836.808348346s] Trained 128 records in 0.085290303 seconds. Throughput is 1500.7567 records/second. Loss is 0.18967536. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035161744022503515. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 39808/60000][Iteration 9222][Wall Clock 836.895344958s] Trained 128 records in 0.086996612 seconds. Throughput is 1471.3217 records/second. Loss is 0.15116602. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035159271499894526. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 39936/60000][Iteration 9223][Wall Clock 836.979130963s] Trained 128 records in 0.083786005 seconds. Throughput is 1527.7014 records/second. Loss is 0.17488939. Sequential31006cbd's hyper parameters: Current learning rate is 0.003515679932498945. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 40064/60000][Iteration 9224][Wall Clock 837.070100567s] Trained 128 records in 0.090969604 seconds. Throughput is 1407.0634 records/second. Loss is 0.14972056. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035154327497714973. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 40192/60000][Iteration 9225][Wall Clock 837.147591098s] Trained 128 records in 0.077490531 seconds. Throughput is 1651.8147 records/second. Loss is 0.099934414. Sequential31006cbd's hyper parameters: Current learning rate is 0.003515185601799775. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 40320/60000][Iteration 9226][Wall Clock 837.224057594s] Trained 128 records in 0.076466496 seconds. Throughput is 1673.9358 records/second. Loss is 0.1893471. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035149384885764497. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 40448/60000][Iteration 9227][Wall Clock 837.304932129s] Trained 128 records in 0.080874535 seconds. Throughput is 1582.6985 records/second. Loss is 0.104955986. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035146914100941938. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 40576/60000][Iteration 9228][Wall Clock 837.389014033s] Trained 128 records in 0.084081904 seconds. Throughput is 1522.3252 records/second. Loss is 0.14145169. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035144443663456806. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:34 INFO  DistriOptimizer$:408 - [Epoch 20 40704/60000][Iteration 9229][Wall Clock 837.470904965s] Trained 128 records in 0.081890932 seconds. Throughput is 1563.0546 records/second. Loss is 0.1538626. Sequential31006cbd's hyper parameters: Current learning rate is 0.003514197357323587. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 40832/60000][Iteration 9230][Wall Clock 837.546957699s] Trained 128 records in 0.076052734 seconds. Throughput is 1683.0427 records/second. Loss is 0.08345929. Sequential31006cbd's hyper parameters: Current learning rate is 0.003513950383020592. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 40960/60000][Iteration 9231][Wall Clock 837.621620232s] Trained 128 records in 0.074662533 seconds. Throughput is 1714.3805 records/second. Loss is 0.099820346. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035137034434293743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41088/60000][Iteration 9232][Wall Clock 837.698826564s] Trained 128 records in 0.077206332 seconds. Throughput is 1657.8951 records/second. Loss is 0.08030997. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035134565385426184. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41216/60000][Iteration 9233][Wall Clock 837.776755173s] Trained 128 records in 0.077928609 seconds. Throughput is 1642.5289 records/second. Loss is 0.113101006. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035132096683530073. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41344/60000][Iteration 9234][Wall Clock 837.857942845s] Trained 128 records in 0.081187672 seconds. Throughput is 1576.594 records/second. Loss is 0.2511554. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035129628328532283. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41472/60000][Iteration 9235][Wall Clock 837.933680756s] Trained 128 records in 0.075737911 seconds. Throughput is 1690.0387 records/second. Loss is 0.19514373. Sequential31006cbd's hyper parameters: Current learning rate is 0.00351271603203597. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41600/60000][Iteration 9236][Wall Clock 838.008595634s] Trained 128 records in 0.074914878 seconds. Throughput is 1708.6058 records/second. Loss is 0.1943935. Sequential31006cbd's hyper parameters: Current learning rate is 0.003512469265893923. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41728/60000][Iteration 9237][Wall Clock 838.088699923s] Trained 128 records in 0.080104289 seconds. Throughput is 1597.9169 records/second. Loss is 0.19674248. Sequential31006cbd's hyper parameters: Current learning rate is 0.003512222534419781. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41856/60000][Iteration 9238][Wall Clock 838.165636754s] Trained 128 records in 0.076936831 seconds. Throughput is 1663.7025 records/second. Loss is 0.18324344. Sequential31006cbd's hyper parameters: Current learning rate is 0.003511975837606237. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 41984/60000][Iteration 9239][Wall Clock 838.241736067s] Trained 128 records in 0.076099313 seconds. Throughput is 1682.0126 records/second. Loss is 0.13439357. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035117291754459897. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 42112/60000][Iteration 9240][Wall Clock 838.321085437s] Trained 128 records in 0.07934937 seconds. Throughput is 1613.1193 records/second. Loss is 0.18706483. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035114825479317362. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 42240/60000][Iteration 9241][Wall Clock 838.398768089s] Trained 128 records in 0.077682652 seconds. Throughput is 1647.7295 records/second. Loss is 0.14644378. Sequential31006cbd's hyper parameters: Current learning rate is 0.00351123595505618. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:35 INFO  DistriOptimizer$:408 - [Epoch 20 42368/60000][Iteration 9242][Wall Clock 838.484598072s] Trained 128 records in 0.085829983 seconds. Throughput is 1491.3204 records/second. Loss is 0.15527444. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035109893968120216. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 42496/60000][Iteration 9243][Wall Clock 838.559367783s] Trained 128 records in 0.074769711 seconds. Throughput is 1711.9231 records/second. Loss is 0.13891338. Sequential31006cbd's hyper parameters: Current learning rate is 0.003510742873191968. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 42624/60000][Iteration 9244][Wall Clock 838.635266318s] Trained 128 records in 0.075898535 seconds. Throughput is 1686.462 records/second. Loss is 0.1754354. Sequential31006cbd's hyper parameters: Current learning rate is 0.003510496384188724. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 42752/60000][Iteration 9245][Wall Clock 838.712302879s] Trained 128 records in 0.077036561 seconds. Throughput is 1661.5487 records/second. Loss is 0.13956463. Sequential31006cbd's hyper parameters: Current learning rate is 0.003510249929795002. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 42880/60000][Iteration 9246][Wall Clock 838.793783533s] Trained 128 records in 0.081480654 seconds. Throughput is 1570.925 records/second. Loss is 0.14057082. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035100035100035097. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43008/60000][Iteration 9247][Wall Clock 838.873796311s] Trained 128 records in 0.080012778 seconds. Throughput is 1599.7445 records/second. Loss is 0.1341575. Sequential31006cbd's hyper parameters: Current learning rate is 0.003509757124806963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43136/60000][Iteration 9248][Wall Clock 838.950740249s] Trained 128 records in 0.076943938 seconds. Throughput is 1663.5488 records/second. Loss is 0.12670697. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035095107741980767. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43264/60000][Iteration 9249][Wall Clock 839.03985099s] Trained 128 records in 0.089110741 seconds. Throughput is 1436.4149 records/second. Loss is 0.14065987. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035092644581695676. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43392/60000][Iteration 9250][Wall Clock 839.125664375s] Trained 128 records in 0.085813385 seconds. Throughput is 1491.6088 records/second. Loss is 0.23873079. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035090181767141555. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43520/60000][Iteration 9251][Wall Clock 839.214120247s] Trained 128 records in 0.088455872 seconds. Throughput is 1447.0492 records/second. Loss is 0.16014017. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035087719298245615. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43648/60000][Iteration 9252][Wall Clock 839.287701858s] Trained 128 records in 0.073581611 seconds. Throughput is 1739.5651 records/second. Loss is 0.16328794. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035085257174935092. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43776/60000][Iteration 9253][Wall Clock 839.364234123s] Trained 128 records in 0.076532265 seconds. Throughput is 1672.4972 records/second. Loss is 0.09422457. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035082795397137242. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:36 INFO  DistriOptimizer$:408 - [Epoch 20 43904/60000][Iteration 9254][Wall Clock 839.444178672s] Trained 128 records in 0.079944549 seconds. Throughput is 1601.1097 records/second. Loss is 0.14897358. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035080333964779345. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44032/60000][Iteration 9255][Wall Clock 839.525198449s] Trained 128 records in 0.081019777 seconds. Throughput is 1579.8612 records/second. Loss is 0.27783182. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035077872877788694. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44160/60000][Iteration 9256][Wall Clock 839.597166604s] Trained 128 records in 0.071968155 seconds. Throughput is 1778.5645 records/second. Loss is 0.12026559. Sequential31006cbd's hyper parameters: Current learning rate is 0.00350754121360926. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44288/60000][Iteration 9257][Wall Clock 839.675909959s] Trained 128 records in 0.078743355 seconds. Throughput is 1625.534 records/second. Loss is 0.09758327. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035072951739618403. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44416/60000][Iteration 9258][Wall Clock 839.751287915s] Trained 128 records in 0.075377956 seconds. Throughput is 1698.1091 records/second. Loss is 0.14548694. Sequential31006cbd's hyper parameters: Current learning rate is 0.003507049168829347. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44544/60000][Iteration 9259][Wall Clock 839.835956065s] Trained 128 records in 0.08466815 seconds. Throughput is 1511.7845 records/second. Loss is 0.15335557. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035068031982045163. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44672/60000][Iteration 9260][Wall Clock 839.915327189s] Trained 128 records in 0.079371124 seconds. Throughput is 1612.6771 records/second. Loss is 0.16268703. Sequential31006cbd's hyper parameters: Current learning rate is 0.00350655726208009. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44800/60000][Iteration 9261][Wall Clock 839.998442881s] Trained 128 records in 0.083115692 seconds. Throughput is 1540.0221 records/second. Loss is 0.20500588. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035063113604488078. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 44928/60000][Iteration 9262][Wall Clock 840.075959431s] Trained 128 records in 0.07751655 seconds. Throughput is 1651.2603 records/second. Loss is 0.13995852. Sequential31006cbd's hyper parameters: Current learning rate is 0.003506065493303415. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 45056/60000][Iteration 9263][Wall Clock 840.157960513s] Trained 128 records in 0.082001082 seconds. Throughput is 1560.955 records/second. Loss is 0.14456497. Sequential31006cbd's hyper parameters: Current learning rate is 0.003505819660636657. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 45184/60000][Iteration 9264][Wall Clock 840.236995715s] Trained 128 records in 0.079035202 seconds. Throughput is 1619.5315 records/second. Loss is 0.17297697. Sequential31006cbd's hyper parameters: Current learning rate is 0.003505573862441282. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 45312/60000][Iteration 9265][Wall Clock 840.345868871s] Trained 128 records in 0.108873156 seconds. Throughput is 1175.68 records/second. Loss is 0.11071129. Sequential31006cbd's hyper parameters: Current learning rate is 0.003505328098710039. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:37 INFO  DistriOptimizer$:408 - [Epoch 20 45440/60000][Iteration 9266][Wall Clock 840.448187905s] Trained 128 records in 0.102319034 seconds. Throughput is 1250.9891 records/second. Loss is 0.12213245. Sequential31006cbd's hyper parameters: Current learning rate is 0.003505082369435682. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 45568/60000][Iteration 9267][Wall Clock 840.551237431s] Trained 128 records in 0.103049526 seconds. Throughput is 1242.1212 records/second. Loss is 0.16583124. Sequential31006cbd's hyper parameters: Current learning rate is 0.003504836674610963. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 45696/60000][Iteration 9268][Wall Clock 840.628665881s] Trained 128 records in 0.07742845 seconds. Throughput is 1653.139 records/second. Loss is 0.120648876. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035045910142286396. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 45824/60000][Iteration 9269][Wall Clock 840.712041186s] Trained 128 records in 0.083375305 seconds. Throughput is 1535.2268 records/second. Loss is 0.17621657. Sequential31006cbd's hyper parameters: Current learning rate is 0.003504345388281469. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 45952/60000][Iteration 9270][Wall Clock 840.792963997s] Trained 128 records in 0.080922811 seconds. Throughput is 1581.7543 records/second. Loss is 0.14994293. Sequential31006cbd's hyper parameters: Current learning rate is 0.003504099796762212. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46080/60000][Iteration 9271][Wall Clock 840.874687026s] Trained 128 records in 0.081723029 seconds. Throughput is 1566.266 records/second. Loss is 0.15192027. Sequential31006cbd's hyper parameters: Current learning rate is 0.00350385423966363. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46208/60000][Iteration 9272][Wall Clock 840.958749583s] Trained 128 records in 0.084062557 seconds. Throughput is 1522.6757 records/second. Loss is 0.16313127. Sequential31006cbd's hyper parameters: Current learning rate is 0.003503608716978488. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46336/60000][Iteration 9273][Wall Clock 841.032834062s] Trained 128 records in 0.074084479 seconds. Throughput is 1727.7574 records/second. Loss is 0.1316562. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035033632286995517. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46464/60000][Iteration 9274][Wall Clock 841.108050819s] Trained 128 records in 0.075216757 seconds. Throughput is 1701.7485 records/second. Loss is 0.17629178. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035031177748195896. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46592/60000][Iteration 9275][Wall Clock 841.197984149s] Trained 128 records in 0.08993333 seconds. Throughput is 1423.2766 records/second. Loss is 0.16735256. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035028723553313717. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46720/60000][Iteration 9276][Wall Clock 841.271161039s] Trained 128 records in 0.07317689 seconds. Throughput is 1749.1862 records/second. Loss is 0.113049045. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035026269702276708. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46848/60000][Iteration 9277][Wall Clock 841.343352898s] Trained 128 records in 0.072191859 seconds. Throughput is 1773.0532 records/second. Loss is 0.12913299. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035023816195012608. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:38 INFO  DistriOptimizer$:408 - [Epoch 20 46976/60000][Iteration 9278][Wall Clock 841.421286936s] Trained 128 records in 0.077934038 seconds. Throughput is 1642.4146 records/second. Loss is 0.06281587. Sequential31006cbd's hyper parameters: Current learning rate is 0.003502136303144918. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47104/60000][Iteration 9279][Wall Clock 841.505864916s] Trained 128 records in 0.08457798 seconds. Throughput is 1513.3964 records/second. Loss is 0.179244. Sequential31006cbd's hyper parameters: Current learning rate is 0.003501891021151422. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47232/60000][Iteration 9280][Wall Clock 841.58207702s] Trained 128 records in 0.076212104 seconds. Throughput is 1679.5233 records/second. Loss is 0.14335269. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035016457735135512. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47360/60000][Iteration 9281][Wall Clock 841.660786922s] Trained 128 records in 0.078709902 seconds. Throughput is 1626.2249 records/second. Loss is 0.20615575. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035014005602240898. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47488/60000][Iteration 9282][Wall Clock 841.736268256s] Trained 128 records in 0.075481334 seconds. Throughput is 1695.7836 records/second. Loss is 0.13909076. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035011553812758205. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47616/60000][Iteration 9283][Wall Clock 841.814761373s] Trained 128 records in 0.078493117 seconds. Throughput is 1630.7162 records/second. Loss is 0.22899483. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035009102366615323. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47744/60000][Iteration 9284][Wall Clock 841.893332051s] Trained 128 records in 0.078570678 seconds. Throughput is 1629.1064 records/second. Loss is 0.096387796. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035006651263740107. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 47872/60000][Iteration 9285][Wall Clock 841.970419395s] Trained 128 records in 0.077087344 seconds. Throughput is 1660.4542 records/second. Loss is 0.19007617. Sequential31006cbd's hyper parameters: Current learning rate is 0.003500420050406049. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 48000/60000][Iteration 9286][Wall Clock 842.057538946s] Trained 128 records in 0.087119551 seconds. Throughput is 1469.2455 records/second. Loss is 0.21685463. Sequential31006cbd's hyper parameters: Current learning rate is 0.0035001750087504373. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 48128/60000][Iteration 9287][Wall Clock 842.136168988s] Trained 128 records in 0.078630042 seconds. Throughput is 1627.8765 records/second. Loss is 0.21711239. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034999300013999718. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 48256/60000][Iteration 9288][Wall Clock 842.214721115s] Trained 128 records in 0.078552127 seconds. Throughput is 1629.4912 records/second. Loss is 0.17676736. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034996850283474487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 48384/60000][Iteration 9289][Wall Clock 842.293430471s] Trained 128 records in 0.078709356 seconds. Throughput is 1626.2361 records/second. Loss is 0.101251066. Sequential31006cbd's hyper parameters: Current learning rate is 0.003499440089585666. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 48512/60000][Iteration 9290][Wall Clock 842.378837023s] Trained 128 records in 0.085406552 seconds. Throughput is 1498.7141 records/second. Loss is 0.112112895. Sequential31006cbd's hyper parameters: Current learning rate is 0.003499195185107425. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:39 INFO  DistriOptimizer$:408 - [Epoch 20 48640/60000][Iteration 9291][Wall Clock 842.457367986s] Trained 128 records in 0.078530963 seconds. Throughput is 1629.9304 records/second. Loss is 0.16355085. Sequential31006cbd's hyper parameters: Current learning rate is 0.003498950314905528. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 48768/60000][Iteration 9292][Wall Clock 842.530118287s] Trained 128 records in 0.072750301 seconds. Throughput is 1759.4429 records/second. Loss is 0.1910373. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034987054789727802. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 48896/60000][Iteration 9293][Wall Clock 842.605485713s] Trained 128 records in 0.075367426 seconds. Throughput is 1698.3464 records/second. Loss is 0.12258793. Sequential31006cbd's hyper parameters: Current learning rate is 0.003498460677301987. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49024/60000][Iteration 9294][Wall Clock 842.68254301s] Trained 128 records in 0.077057297 seconds. Throughput is 1661.1017 records/second. Loss is 0.071339145. Sequential31006cbd's hyper parameters: Current learning rate is 0.003498215909885958. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49152/60000][Iteration 9295][Wall Clock 842.762937584s] Trained 128 records in 0.080394574 seconds. Throughput is 1592.1472 records/second. Loss is 0.14511406. Sequential31006cbd's hyper parameters: Current learning rate is 0.003497971176717504. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49280/60000][Iteration 9296][Wall Clock 842.842233876s] Trained 128 records in 0.079296292 seconds. Throughput is 1614.1991 records/second. Loss is 0.15736672. Sequential31006cbd's hyper parameters: Current learning rate is 0.003497726477789437. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49408/60000][Iteration 9297][Wall Clock 842.921489506s] Trained 128 records in 0.07925563 seconds. Throughput is 1615.0271 records/second. Loss is 0.170554. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034974818130945715. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49536/60000][Iteration 9298][Wall Clock 842.996902851s] Trained 128 records in 0.075413345 seconds. Throughput is 1697.3123 records/second. Loss is 0.20070305. Sequential31006cbd's hyper parameters: Current learning rate is 0.003497237182625726. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49664/60000][Iteration 9299][Wall Clock 843.076560453s] Trained 128 records in 0.079657602 seconds. Throughput is 1606.8774 records/second. Loss is 0.08816223. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034969925863757166. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49792/60000][Iteration 9300][Wall Clock 843.164009694s] Trained 128 records in 0.087449241 seconds. Throughput is 1463.7063 records/second. Loss is 0.1923831. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034967480243373664. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 49920/60000][Iteration 9301][Wall Clock 843.238753539s] Trained 128 records in 0.074743845 seconds. Throughput is 1712.5156 records/second. Loss is 0.14762792. Sequential31006cbd's hyper parameters: Current learning rate is 0.003496503496503496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 50048/60000][Iteration 9302][Wall Clock 843.321452577s] Trained 128 records in 0.082699038 seconds. Throughput is 1547.781 records/second. Loss is 0.077889286. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034962590028669326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:40 INFO  DistriOptimizer$:408 - [Epoch 20 50176/60000][Iteration 9303][Wall Clock 843.39566115s] Trained 128 records in 0.074208573 seconds. Throughput is 1724.8682 records/second. Loss is 0.1405852. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034960145434205004. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 50304/60000][Iteration 9304][Wall Clock 843.477579591s] Trained 128 records in 0.081918441 seconds. Throughput is 1562.5298 records/second. Loss is 0.10687115. Sequential31006cbd's hyper parameters: Current learning rate is 0.00349577011815703. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 50432/60000][Iteration 9305][Wall Clock 843.567959751s] Trained 128 records in 0.09038016 seconds. Throughput is 1416.24 records/second. Loss is 0.18611296. Sequential31006cbd's hyper parameters: Current learning rate is 0.003495525727069351. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 50560/60000][Iteration 9306][Wall Clock 843.645751132s] Trained 128 records in 0.077791381 seconds. Throughput is 1645.4265 records/second. Loss is 0.12090256. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034952813701502974. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 50688/60000][Iteration 9307][Wall Clock 843.722442323s] Trained 128 records in 0.076691191 seconds. Throughput is 1669.0314 records/second. Loss is 0.16735801. Sequential31006cbd's hyper parameters: Current learning rate is 0.003495037047392702. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 50816/60000][Iteration 9308][Wall Clock 843.800783729s] Trained 128 records in 0.078341406 seconds. Throughput is 1633.8741 records/second. Loss is 0.1500258. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034947927587894037. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 50944/60000][Iteration 9309][Wall Clock 843.880559533s] Trained 128 records in 0.079775804 seconds. Throughput is 1604.4966 records/second. Loss is 0.12383029. Sequential31006cbd's hyper parameters: Current learning rate is 0.00349454850433324. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51072/60000][Iteration 9310][Wall Clock 843.960859653s] Trained 128 records in 0.08030012 seconds. Throughput is 1594.02 records/second. Loss is 0.09022799. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034943042840170522. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51200/60000][Iteration 9311][Wall Clock 844.043400246s] Trained 128 records in 0.082540593 seconds. Throughput is 1550.7521 records/second. Loss is 0.1294857. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034940600978336828. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51328/60000][Iteration 9312][Wall Clock 844.121693615s] Trained 128 records in 0.078293369 seconds. Throughput is 1634.8767 records/second. Loss is 0.1848239. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034938159457759766. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51456/60000][Iteration 9313][Wall Clock 844.199210744s] Trained 128 records in 0.077517129 seconds. Throughput is 1651.2479 records/second. Loss is 0.15543187. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034935718278367805. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51584/60000][Iteration 9314][Wall Clock 844.277581253s] Trained 128 records in 0.078370509 seconds. Throughput is 1633.2673 records/second. Loss is 0.16874647. Sequential31006cbd's hyper parameters: Current learning rate is 0.003493327744008943. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51712/60000][Iteration 9315][Wall Clock 844.363001167s] Trained 128 records in 0.085419914 seconds. Throughput is 1498.4796 records/second. Loss is 0.08764666. Sequential31006cbd's hyper parameters: Current learning rate is 0.003493083694285315. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:41 INFO  DistriOptimizer$:408 - [Epoch 20 51840/60000][Iteration 9316][Wall Clock 844.438883134s] Trained 128 records in 0.075881967 seconds. Throughput is 1686.8303 records/second. Loss is 0.13852277. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034928396786587496. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 51968/60000][Iteration 9317][Wall Clock 844.515693692s] Trained 128 records in 0.076810558 seconds. Throughput is 1666.4375 records/second. Loss is 0.16901697. Sequential31006cbd's hyper parameters: Current learning rate is 0.003492595697122101. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52096/60000][Iteration 9318][Wall Clock 844.597850046s] Trained 128 records in 0.082156354 seconds. Throughput is 1558.0049 records/second. Loss is 0.13597077. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034923517496682262. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52224/60000][Iteration 9319][Wall Clock 844.679989931s] Trained 128 records in 0.082139885 seconds. Throughput is 1558.3173 records/second. Loss is 0.1674349. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034921078362899847. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52352/60000][Iteration 9320][Wall Clock 844.758255564s] Trained 128 records in 0.078265633 seconds. Throughput is 1635.456 records/second. Loss is 0.15943311. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034918639569802355. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52480/60000][Iteration 9321][Wall Clock 844.839376617s] Trained 128 records in 0.081121053 seconds. Throughput is 1577.8888 records/second. Loss is 0.19771126. Sequential31006cbd's hyper parameters: Current learning rate is 0.003491620111731844. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52608/60000][Iteration 9322][Wall Clock 844.920244725s] Trained 128 records in 0.080868108 seconds. Throughput is 1582.8242 records/second. Loss is 0.08775208. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034913763005376716. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52736/60000][Iteration 9323][Wall Clock 844.996255766s] Trained 128 records in 0.076011041 seconds. Throughput is 1683.966 records/second. Loss is 0.15441239. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034911325233905883. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52864/60000][Iteration 9324][Wall Clock 845.073072068s] Trained 128 records in 0.076816302 seconds. Throughput is 1666.3129 records/second. Loss is 0.09009323. Sequential31006cbd's hyper parameters: Current learning rate is 0.00349088878028346. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 52992/60000][Iteration 9325][Wall Clock 845.150022285s] Trained 128 records in 0.076950217 seconds. Throughput is 1663.4132 records/second. Loss is 0.11549083. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034906450712091598. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 53120/60000][Iteration 9326][Wall Clock 845.237349427s] Trained 128 records in 0.087327142 seconds. Throughput is 1465.7527 records/second. Loss is 0.1244214. Sequential31006cbd's hyper parameters: Current learning rate is 0.003490401396160558. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 53248/60000][Iteration 9327][Wall Clock 845.322631218s] Trained 128 records in 0.085281791 seconds. Throughput is 1500.9066 records/second. Loss is 0.17032747. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034901577551305317. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:42 INFO  DistriOptimizer$:408 - [Epoch 20 53376/60000][Iteration 9328][Wall Clock 845.412858185s] Trained 128 records in 0.090226967 seconds. Throughput is 1418.6445 records/second. Loss is 0.18882678. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034899141481119565. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 53504/60000][Iteration 9329][Wall Clock 845.489184093s] Trained 128 records in 0.076325908 seconds. Throughput is 1677.019 records/second. Loss is 0.20107187. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034896705750977106. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 53632/60000][Iteration 9330][Wall Clock 845.563487326s] Trained 128 records in 0.074303233 seconds. Throughput is 1722.6707 records/second. Loss is 0.1982533. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034894270360806756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 53760/60000][Iteration 9331][Wall Clock 845.648756435s] Trained 128 records in 0.085269109 seconds. Throughput is 1501.1298 records/second. Loss is 0.13231334. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034891835310537334. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 53888/60000][Iteration 9332][Wall Clock 845.727062727s] Trained 128 records in 0.078306292 seconds. Throughput is 1634.6068 records/second. Loss is 0.11990403. Sequential31006cbd's hyper parameters: Current learning rate is 0.003488940060009769. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54016/60000][Iteration 9333][Wall Clock 845.814001404s] Trained 128 records in 0.086938677 seconds. Throughput is 1472.3021 records/second. Loss is 0.15153202. Sequential31006cbd's hyper parameters: Current learning rate is 0.003488696622941669. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54144/60000][Iteration 9334][Wall Clock 845.895208403s] Trained 128 records in 0.081206999 seconds. Throughput is 1576.2188 records/second. Loss is 0.15686728. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034884532198423217. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54272/60000][Iteration 9335][Wall Clock 845.972691266s] Trained 128 records in 0.077482863 seconds. Throughput is 1651.9781 records/second. Loss is 0.22340289. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034882098507046187. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54400/60000][Iteration 9336][Wall Clock 846.05080214s] Trained 128 records in 0.078110874 seconds. Throughput is 1638.6963 records/second. Loss is 0.078119926. Sequential31006cbd's hyper parameters: Current learning rate is 0.003487966515521451. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54528/60000][Iteration 9337][Wall Clock 846.134163505s] Trained 128 records in 0.083361365 seconds. Throughput is 1535.4835 records/second. Loss is 0.39899513. Sequential31006cbd's hyper parameters: Current learning rate is 0.003487723214285714. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54656/60000][Iteration 9338][Wall Clock 846.20790486s] Trained 128 records in 0.073741355 seconds. Throughput is 1735.7968 records/second. Loss is 0.18087411. Sequential31006cbd's hyper parameters: Current learning rate is 0.003487479946990305. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54784/60000][Iteration 9339][Wall Clock 846.283077792s] Trained 128 records in 0.075172932 seconds. Throughput is 1702.7406 records/second. Loss is 0.14995651. Sequential31006cbd's hyper parameters: Current learning rate is 0.003487236713628121. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:43 INFO  DistriOptimizer$:408 - [Epoch 20 54912/60000][Iteration 9340][Wall Clock 846.390576084s] Trained 128 records in 0.107498292 seconds. Throughput is 1190.7166 records/second. Loss is 0.12771142. Sequential31006cbd's hyper parameters: Current learning rate is 0.003486993514192064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55040/60000][Iteration 9341][Wall Clock 846.479943054s] Trained 128 records in 0.08936697 seconds. Throughput is 1432.2965 records/second. Loss is 0.26234233. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034867503486750344. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55168/60000][Iteration 9342][Wall Clock 846.556606477s] Trained 128 records in 0.076663423 seconds. Throughput is 1669.636 records/second. Loss is 0.13878745. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034865072170699395. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55296/60000][Iteration 9343][Wall Clock 846.630820499s] Trained 128 records in 0.074214022 seconds. Throughput is 1724.7416 records/second. Loss is 0.116166726. Sequential31006cbd's hyper parameters: Current learning rate is 0.003486264119369683. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55424/60000][Iteration 9344][Wall Clock 846.705914479s] Trained 128 records in 0.07509398 seconds. Throughput is 1704.5309 records/second. Loss is 0.23956937. Sequential31006cbd's hyper parameters: Current learning rate is 0.003486021055567176. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55552/60000][Iteration 9345][Wall Clock 846.776306635s] Trained 128 records in 0.070392156 seconds. Throughput is 1818.3845 records/second. Loss is 0.12749484. Sequential31006cbd's hyper parameters: Current learning rate is 0.003485778025655326. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55680/60000][Iteration 9346][Wall Clock 846.850041933s] Trained 128 records in 0.073735298 seconds. Throughput is 1735.9393 records/second. Loss is 0.11133613. Sequential31006cbd's hyper parameters: Current learning rate is 0.003485535029627048. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55808/60000][Iteration 9347][Wall Clock 846.927809306s] Trained 128 records in 0.077767373 seconds. Throughput is 1645.9344 records/second. Loss is 0.19812286. Sequential31006cbd's hyper parameters: Current learning rate is 0.003485292067475254. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 55936/60000][Iteration 9348][Wall Clock 847.002977624s] Trained 128 records in 0.075168318 seconds. Throughput is 1702.8451 records/second. Loss is 0.16526252. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034850491391928626. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 56064/60000][Iteration 9349][Wall Clock 847.078289149s] Trained 128 records in 0.075311525 seconds. Throughput is 1699.607 records/second. Loss is 0.14303109. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034848062447727906. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 56192/60000][Iteration 9350][Wall Clock 847.155467689s] Trained 128 records in 0.07717854 seconds. Throughput is 1658.4922 records/second. Loss is 0.08383857. Sequential31006cbd's hyper parameters: Current learning rate is 0.003484563384207959. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 56320/60000][Iteration 9351][Wall Clock 847.240937125s] Trained 128 records in 0.085469436 seconds. Throughput is 1497.6113 records/second. Loss is 0.06772194. Sequential31006cbd's hyper parameters: Current learning rate is 0.003484320557491289. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 56448/60000][Iteration 9352][Wall Clock 847.321706238s] Trained 128 records in 0.080769113 seconds. Throughput is 1584.7642 records/second. Loss is 0.15677804. Sequential31006cbd's hyper parameters: Current learning rate is 0.003484077764615706. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:44 INFO  DistriOptimizer$:408 - [Epoch 20 56576/60000][Iteration 9353][Wall Clock 847.41200913s] Trained 128 records in 0.090302892 seconds. Throughput is 1417.4518 records/second. Loss is 0.12345233. Sequential31006cbd's hyper parameters: Current learning rate is 0.003483835005574136. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 56704/60000][Iteration 9354][Wall Clock 847.494688075s] Trained 128 records in 0.082678945 seconds. Throughput is 1548.1572 records/second. Loss is 0.11840768. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034835922803595066. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 56832/60000][Iteration 9355][Wall Clock 847.574809426s] Trained 128 records in 0.080121351 seconds. Throughput is 1597.5767 records/second. Loss is 0.19076632. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034833495889647487. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 56960/60000][Iteration 9356][Wall Clock 847.65172796s] Trained 128 records in 0.076918534 seconds. Throughput is 1664.0983 records/second. Loss is 0.10148376. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034831069313827935. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57088/60000][Iteration 9357][Wall Clock 847.728132182s] Trained 128 records in 0.076404222 seconds. Throughput is 1675.3 records/second. Loss is 0.08131484. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034828643076065756. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57216/60000][Iteration 9358][Wall Clock 847.800057473s] Trained 128 records in 0.071925291 seconds. Throughput is 1779.6244 records/second. Loss is 0.14089015. Sequential31006cbd's hyper parameters: Current learning rate is 0.003482621717629031. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57344/60000][Iteration 9359][Wall Clock 847.872125597s] Trained 128 records in 0.072068124 seconds. Throughput is 1776.0973 records/second. Loss is 0.15586981. Sequential31006cbd's hyper parameters: Current learning rate is 0.003482379161443098. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57472/60000][Iteration 9360][Wall Clock 847.953524684s] Trained 128 records in 0.081399087 seconds. Throughput is 1572.4991 records/second. Loss is 0.16090657. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034821366390417156. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57600/60000][Iteration 9361][Wall Clock 848.03582202s] Trained 128 records in 0.082297336 seconds. Throughput is 1555.3359 records/second. Loss is 0.12444499. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034818941504178276. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57728/60000][Iteration 9362][Wall Clock 848.111191905s] Trained 128 records in 0.075369885 seconds. Throughput is 1698.291 records/second. Loss is 0.16482088. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034816516955643753. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57856/60000][Iteration 9363][Wall Clock 848.223454877s] Trained 128 records in 0.112262972 seconds. Throughput is 1140.18 records/second. Loss is 0.19399583. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034814092744743074. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 57984/60000][Iteration 9364][Wall Clock 848.297957427s] Trained 128 records in 0.07450255 seconds. Throughput is 1718.062 records/second. Loss is 0.39229327. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034811668871405693. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:45 INFO  DistriOptimizer$:408 - [Epoch 20 58112/60000][Iteration 9365][Wall Clock 848.383992066s] Trained 128 records in 0.086034639 seconds. Throughput is 1487.7728 records/second. Loss is 0.14027032. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034809245335561127. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 58240/60000][Iteration 9366][Wall Clock 848.46397475s] Trained 128 records in 0.079982684 seconds. Throughput is 1600.3464 records/second. Loss is 0.091308035. Sequential31006cbd's hyper parameters: Current learning rate is 0.003480682213713888. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 58368/60000][Iteration 9367][Wall Clock 848.539222381s] Trained 128 records in 0.075247631 seconds. Throughput is 1701.0503 records/second. Loss is 0.15974958. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034804399276068495. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 58496/60000][Iteration 9368][Wall Clock 848.610690466s] Trained 128 records in 0.071468085 seconds. Throughput is 1791.0093 records/second. Loss is 0.16638228. Sequential31006cbd's hyper parameters: Current learning rate is 0.003480197675227953. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 58624/60000][Iteration 9369][Wall Clock 848.690439416s] Trained 128 records in 0.07974895 seconds. Throughput is 1605.0367 records/second. Loss is 0.19628671. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034799554565701557. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 58752/60000][Iteration 9370][Wall Clock 848.773072442s] Trained 128 records in 0.082633026 seconds. Throughput is 1549.0175 records/second. Loss is 0.10766748. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034797132716264177. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 58880/60000][Iteration 9371][Wall Clock 848.847005237s] Trained 128 records in 0.073932795 seconds. Throughput is 1731.302 records/second. Loss is 0.14598957. Sequential31006cbd's hyper parameters: Current learning rate is 0.003479471120389701. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59008/60000][Iteration 9372][Wall Clock 848.922360672s] Trained 128 records in 0.075355435 seconds. Throughput is 1698.6167 records/second. Loss is 0.11181187. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034792290028529678. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59136/60000][Iteration 9373][Wall Clock 849.002103119s] Trained 128 records in 0.079742447 seconds. Throughput is 1605.1677 records/second. Loss is 0.10643559. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034789869190091846. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59264/60000][Iteration 9374][Wall Clock 849.084050181s] Trained 128 records in 0.081947062 seconds. Throughput is 1561.9841 records/second. Loss is 0.11222181. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034787448688513183. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59392/60000][Iteration 9375][Wall Clock 849.171307078s] Trained 128 records in 0.087256897 seconds. Throughput is 1466.9329 records/second. Loss is 0.22760963. Sequential31006cbd's hyper parameters: Current learning rate is 0.003478502852372339. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59520/60000][Iteration 9376][Wall Clock 849.250837386s] Trained 128 records in 0.079530308 seconds. Throughput is 1609.4493 records/second. Loss is 0.086905584. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034782608695652175. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59648/60000][Iteration 9377][Wall Clock 849.340060484s] Trained 128 records in 0.089223098 seconds. Throughput is 1434.6062 records/second. Loss is 0.09589797. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034780189204229265. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:46 INFO  DistriOptimizer$:408 - [Epoch 20 59776/60000][Iteration 9378][Wall Clock 849.421446406s] Trained 128 records in 0.081385922 seconds. Throughput is 1572.7535 records/second. Loss is 0.14162077. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034777770049384434. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:47 INFO  DistriOptimizer$:408 - [Epoch 20 59904/60000][Iteration 9379][Wall Clock 849.503066751s] Trained 128 records in 0.081620345 seconds. Throughput is 1568.2365 records/second. Loss is 0.108965285. Sequential31006cbd's hyper parameters: Current learning rate is 0.003477535123104743. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:47 INFO  DistriOptimizer$:408 - [Epoch 20 60032/60000][Iteration 9380][Wall Clock 849.575962844s] Trained 128 records in 0.072896093 seconds. Throughput is 1755.924 records/second. Loss is 0.13182738. Sequential31006cbd's hyper parameters: Current learning rate is 0.0034772932749148064. Current dampening is 1.7976931348623157E308.  
2019-10-24 00:11:47 INFO  DistriOptimizer$:452 - [Epoch 20 60032/60000][Iteration 9380][Wall Clock 849.575962844s] Epoch finished. Wall clock time is 850656.278723 ms
2019-10-24 00:11:47 INFO  DistriOptimizer$:111 - [Epoch 20 60032/60000][Iteration 9380][Wall Clock 849.575962844s] Validate model...
2019-10-24 00:11:47 INFO  DistriOptimizer$:178 - [Epoch 20 60032/60000][Iteration 9380][Wall Clock 849.575962844s] validate model throughput is 12101.222 records/second
2019-10-24 00:11:47 INFO  DistriOptimizer$:181 - [Epoch 20 60032/60000][Iteration 9380][Wall Clock 849.575962844s] Top1Accuracy is Accuracy(correct: 9587, count: 10000, accuracy: 0.9587)
2019-10-24 00:11:48 INFO  DistriOptimizer$:221 - [Wall Clock 850.656278723s] Save model to /tmp/lenet5/20191023_235735
2019-10-24 00:11:48 INFO  DistriOptimizer$:226 - [Wall Clock 850.656278723s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@7a743db7 to /tmp/lenet5/20191023_235735
('Extracting', '~/bd/datasets/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.95870000124, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.999400019646, total_num: 10000, method: Top5Accuracy
Evaluated result: 0.133680984378, total_num: 157, method: Loss
