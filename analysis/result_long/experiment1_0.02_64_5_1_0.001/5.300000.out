2019-10-24 03:12:55 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-24 03:12:57 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-24 03:12:57 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-24 03:12:57 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-24 03:12:57 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-24 03:12:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-24 03:12:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-24 03:12:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-24 03:12:58 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 33949.
2019-10-24 03:12:59 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-24 03:12:59 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-24 03:12:59 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-24 03:12:59 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-24 03:12:59 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-91ba70be-8794-4250-96ef-78a3a0ce25d5
2019-10-24 03:12:59 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-24 03:12:59 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-24 03:13:00 INFO  log:192 - Logging initialized @9210ms
2019-10-24 03:13:01 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-24 03:13:01 INFO  Server:414 - Started @10240ms
2019-10-24 03:13:01 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-10-24 03:13:01 INFO  AbstractConnector:278 - Started ServerConnector@38737bdc{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2019-10-24 03:13:01 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40f3254c{/jobs,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@773125d1{/jobs/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1bc78114{/jobs/job,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d221d99{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53c3aa41{/stages,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@742b5e0c{/stages/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7851ae50{/stages/stage,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2588750c{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@505e7cc3{/stages/pool,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c1ed4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67ec7013{/storage,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1aa59f7{/storage/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22319565{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@42dbb549{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@463329e9{/environment,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1585a539{/environment/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b319051{/executors,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@245f0b83{/executors/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfc0280{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43e8ccab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@746c7f9f{/static,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@babef18{/,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2cebcb29{/api,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17757073{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60264497{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-24 03:13:02 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4041
2019-10-24 03:13:02 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:33949/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571886782819
2019-10-24 03:13:03 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:33949/files/lenet5.py with timestamp 1571886783037
2019-10-24 03:13:03 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-6845eacb-bdd0-4687-8241-d2493382e092/userFiles-cf34cc10-7c20-4eb0-9926-a2b7cf019db1/lenet5.py
2019-10-24 03:13:03 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:33949/files/bigdl-0.8.0-python-api.zip with timestamp 1571886783169
2019-10-24 03:13:03 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-6845eacb-bdd0-4687-8241-d2493382e092/userFiles-cf34cc10-7c20-4eb0-9926-a2b7cf019db1/bigdl-0.8.0-python-api.zip
2019-10-24 03:13:03 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-24 03:13:04 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 254 ms (0 ms spent in bootstraps)
2019-10-24 03:13:05 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191024031305-0353
2019-10-24 03:13:05 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44467.
2019-10-24 03:13:05 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:44467
2019-10-24 03:13:05 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-24 03:13:05 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191024031305-0353/0 on worker-20191023161329-10.164.0.15-33215 (10.164.0.15:33215) with 1 core(s)
2019-10-24 03:13:05 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191024031305-0353/0 on hostPort 10.164.0.15:33215 with 1 core(s), 1024.0 MB RAM
2019-10-24 03:13:05 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191024031305-0353/0 is now RUNNING
2019-10-24 03:13:05 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 44467, None)
2019-10-24 03:13:05 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:44467 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 44467, None)
2019-10-24 03:13:05 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 44467, None)
2019-10-24 03:13:05 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 44467, None)
2019-10-24 03:13:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22d85fc8{/metrics/json,null,AVAILABLE,@Spark}
2019-10-24 03:13:08 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.15:43354) with ID 0
2019-10-24 03:13:08 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-24 03:13:08 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.15:38243 with 413.9 MB RAM, BlockManagerId(0, 10.164.0.15, 38243, None)
2019-10-24 03:13:10 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-24 03:13:10 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-24 03:13:11 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 18
2019-10-24 03:13:11 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.02
('Extracting', '~/bd/datasets/mnist/train-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-24 03:13:19 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-24 03:13:39 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-24 03:13:40 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-24 03:13:40 INFO  DistriOptimizer$:154 - Count dataset
2019-10-24 03:13:41 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.563289411s
2019-10-24 03:13:41 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-24 03:13:41 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-24 03:13:41 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.046242777s
2019-10-24 03:13:42 INFO  DistriOptimizer$:408 - [Epoch 1 64/60000][Iteration 1][Wall Clock 0.888899212s] Trained 64 records in 0.888899212 seconds. Throughput is 71.99916 records/second. Loss is 2.3184788. Sequential2290a28's hyper parameters: Current learning rate is 0.02. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:42 INFO  DistriOptimizer$:408 - [Epoch 1 128/60000][Iteration 2][Wall Clock 1.3939658s] Trained 64 records in 0.505066588 seconds. Throughput is 126.715965 records/second. Loss is 2.2961936. Sequential2290a28's hyper parameters: Current learning rate is 0.019996000799840034. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:42 INFO  DistriOptimizer$:408 - [Epoch 1 192/60000][Iteration 3][Wall Clock 1.697881585s] Trained 64 records in 0.303915785 seconds. Throughput is 210.58464 records/second. Loss is 2.31327. Sequential2290a28's hyper parameters: Current learning rate is 0.019992003198720514. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:43 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 4][Wall Clock 2.017150278s] Trained 64 records in 0.319268693 seconds. Throughput is 200.45811 records/second. Loss is 2.3045042. Sequential2290a28's hyper parameters: Current learning rate is 0.019988007195682594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:43 INFO  DistriOptimizer$:408 - [Epoch 1 320/60000][Iteration 5][Wall Clock 2.290924183s] Trained 64 records in 0.273773905 seconds. Throughput is 233.76953 records/second. Loss is 2.296437. Sequential2290a28's hyper parameters: Current learning rate is 0.019984012789768187. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:43 INFO  DistriOptimizer$:408 - [Epoch 1 384/60000][Iteration 6][Wall Clock 2.666746983s] Trained 64 records in 0.3758228 seconds. Throughput is 170.29301 records/second. Loss is 2.3105352. Sequential2290a28's hyper parameters: Current learning rate is 0.019980019980019983. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:44 INFO  DistriOptimizer$:408 - [Epoch 1 448/60000][Iteration 7][Wall Clock 3.249378466s] Trained 64 records in 0.582631483 seconds. Throughput is 109.84645 records/second. Loss is 2.2793427. Sequential2290a28's hyper parameters: Current learning rate is 0.01997602876548142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:44 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 8][Wall Clock 3.531201495s] Trained 64 records in 0.281823029 seconds. Throughput is 227.09286 records/second. Loss is 2.290447. Sequential2290a28's hyper parameters: Current learning rate is 0.019972039145196723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:45 INFO  DistriOptimizer$:408 - [Epoch 1 576/60000][Iteration 9][Wall Clock 3.775863149s] Trained 64 records in 0.244661654 seconds. Throughput is 261.58572 records/second. Loss is 2.2925274. Sequential2290a28's hyper parameters: Current learning rate is 0.019968051118210862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:45 INFO  DistriOptimizer$:408 - [Epoch 1 640/60000][Iteration 10][Wall Clock 4.081084403s] Trained 64 records in 0.305221254 seconds. Throughput is 209.68394 records/second. Loss is 2.2802455. Sequential2290a28's hyper parameters: Current learning rate is 0.019964064683569576. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:45 INFO  DistriOptimizer$:408 - [Epoch 1 704/60000][Iteration 11][Wall Clock 4.334127989s] Trained 64 records in 0.253043586 seconds. Throughput is 252.92085 records/second. Loss is 2.3014371. Sequential2290a28's hyper parameters: Current learning rate is 0.01996007984031936. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:45 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 12][Wall Clock 4.610536514s] Trained 64 records in 0.276408525 seconds. Throughput is 231.54134 records/second. Loss is 2.284364. Sequential2290a28's hyper parameters: Current learning rate is 0.019956096587507483. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:46 INFO  DistriOptimizer$:408 - [Epoch 1 832/60000][Iteration 13][Wall Clock 5.015333742s] Trained 64 records in 0.404797228 seconds. Throughput is 158.10385 records/second. Loss is 2.2736554. Sequential2290a28's hyper parameters: Current learning rate is 0.019952114924181964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:46 INFO  DistriOptimizer$:408 - [Epoch 1 896/60000][Iteration 14][Wall Clock 5.255774949s] Trained 64 records in 0.240441207 seconds. Throughput is 266.17734 records/second. Loss is 2.2652493. Sequential2290a28's hyper parameters: Current learning rate is 0.019948134849391584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:46 INFO  DistriOptimizer$:408 - [Epoch 1 960/60000][Iteration 15][Wall Clock 5.487039096s] Trained 64 records in 0.231264147 seconds. Throughput is 276.73984 records/second. Loss is 2.260713. Sequential2290a28's hyper parameters: Current learning rate is 0.019944156362185883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:47 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 16][Wall Clock 5.84398416s] Trained 64 records in 0.356945064 seconds. Throughput is 179.2993 records/second. Loss is 2.2634068. Sequential2290a28's hyper parameters: Current learning rate is 0.019940179461615158. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:47 INFO  DistriOptimizer$:408 - [Epoch 1 1088/60000][Iteration 17][Wall Clock 6.100250217s] Trained 64 records in 0.256266057 seconds. Throughput is 249.74045 records/second. Loss is 2.2783437. Sequential2290a28's hyper parameters: Current learning rate is 0.01993620414673046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:47 INFO  DistriOptimizer$:408 - [Epoch 1 1152/60000][Iteration 18][Wall Clock 6.289733137s] Trained 64 records in 0.18948292 seconds. Throughput is 337.7613 records/second. Loss is 2.2701528. Sequential2290a28's hyper parameters: Current learning rate is 0.019932230416583614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:48 INFO  DistriOptimizer$:408 - [Epoch 1 1216/60000][Iteration 19][Wall Clock 6.703195642s] Trained 64 records in 0.413462505 seconds. Throughput is 154.79033 records/second. Loss is 2.2655993. Sequential2290a28's hyper parameters: Current learning rate is 0.01992825827022718. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:48 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 20][Wall Clock 6.997372156s] Trained 64 records in 0.294176514 seconds. Throughput is 217.55646 records/second. Loss is 2.2708116. Sequential2290a28's hyper parameters: Current learning rate is 0.019924287706714484. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:48 INFO  DistriOptimizer$:408 - [Epoch 1 1344/60000][Iteration 21][Wall Clock 7.147013989s] Trained 64 records in 0.149641833 seconds. Throughput is 427.6879 records/second. Loss is 2.2751908. Sequential2290a28's hyper parameters: Current learning rate is 0.0199203187250996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:48 INFO  DistriOptimizer$:408 - [Epoch 1 1408/60000][Iteration 22][Wall Clock 7.449712928s] Trained 64 records in 0.302698939 seconds. Throughput is 211.4312 records/second. Loss is 2.2792614. Sequential2290a28's hyper parameters: Current learning rate is 0.019916351324437365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:49 INFO  DistriOptimizer$:408 - [Epoch 1 1472/60000][Iteration 23][Wall Clock 7.790176201s] Trained 64 records in 0.340463273 seconds. Throughput is 187.97916 records/second. Loss is 2.2618275. Sequential2290a28's hyper parameters: Current learning rate is 0.019912385503783353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:49 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 24][Wall Clock 8.021653063s] Trained 64 records in 0.231476862 seconds. Throughput is 276.48553 records/second. Loss is 2.2652073. Sequential2290a28's hyper parameters: Current learning rate is 0.019908421262193908. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:49 INFO  DistriOptimizer$:408 - [Epoch 1 1600/60000][Iteration 25][Wall Clock 8.204145984s] Trained 64 records in 0.182492921 seconds. Throughput is 350.69852 records/second. Loss is 2.2537868. Sequential2290a28's hyper parameters: Current learning rate is 0.019904458598726117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:49 INFO  DistriOptimizer$:408 - [Epoch 1 1664/60000][Iteration 26][Wall Clock 8.476055s] Trained 64 records in 0.271909016 seconds. Throughput is 235.37283 records/second. Loss is 2.238367. Sequential2290a28's hyper parameters: Current learning rate is 0.019900497512437814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:49 INFO  DistriOptimizer$:408 - [Epoch 1 1728/60000][Iteration 27][Wall Clock 8.677673173s] Trained 64 records in 0.201618173 seconds. Throughput is 317.4317 records/second. Loss is 2.2498298. Sequential2290a28's hyper parameters: Current learning rate is 0.01989653800238758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:50 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 28][Wall Clock 8.839838607s] Trained 64 records in 0.162165434 seconds. Throughput is 394.6587 records/second. Loss is 2.246399. Sequential2290a28's hyper parameters: Current learning rate is 0.019892580067634773. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:50 INFO  DistriOptimizer$:408 - [Epoch 1 1856/60000][Iteration 29][Wall Clock 9.014946432s] Trained 64 records in 0.175107825 seconds. Throughput is 365.4891 records/second. Loss is 2.2316315. Sequential2290a28's hyper parameters: Current learning rate is 0.01988862370723946. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:50 INFO  DistriOptimizer$:408 - [Epoch 1 1920/60000][Iteration 30][Wall Clock 9.188533353s] Trained 64 records in 0.173586921 seconds. Throughput is 368.69138 records/second. Loss is 2.2515318. Sequential2290a28's hyper parameters: Current learning rate is 0.01988466892026248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:50 INFO  DistriOptimizer$:408 - [Epoch 1 1984/60000][Iteration 31][Wall Clock 9.432556839s] Trained 64 records in 0.244023486 seconds. Throughput is 262.26984 records/second. Loss is 2.23465. Sequential2290a28's hyper parameters: Current learning rate is 0.019880715705765408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:50 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 32][Wall Clock 9.604551198s] Trained 64 records in 0.171994359 seconds. Throughput is 372.10522 records/second. Loss is 2.24935. Sequential2290a28's hyper parameters: Current learning rate is 0.019876764062810574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:51 INFO  DistriOptimizer$:408 - [Epoch 1 2112/60000][Iteration 33][Wall Clock 9.820448525s] Trained 64 records in 0.215897327 seconds. Throughput is 296.43723 records/second. Loss is 2.2296588. Sequential2290a28's hyper parameters: Current learning rate is 0.01987281399046105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:51 INFO  DistriOptimizer$:408 - [Epoch 1 2176/60000][Iteration 34][Wall Clock 10.122844342s] Trained 64 records in 0.302395817 seconds. Throughput is 211.64314 records/second. Loss is 2.2236872. Sequential2290a28's hyper parameters: Current learning rate is 0.01986886548778065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:51 INFO  DistriOptimizer$:408 - [Epoch 1 2240/60000][Iteration 35][Wall Clock 10.370839293s] Trained 64 records in 0.247994951 seconds. Throughput is 258.06976 records/second. Loss is 2.2126462. Sequential2290a28's hyper parameters: Current learning rate is 0.019864918553833932. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:51 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 36][Wall Clock 10.528718217s] Trained 64 records in 0.157878924 seconds. Throughput is 405.37393 records/second. Loss is 2.2121441. Sequential2290a28's hyper parameters: Current learning rate is 0.0198609731876862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:52 INFO  DistriOptimizer$:408 - [Epoch 1 2368/60000][Iteration 37][Wall Clock 10.726274323s] Trained 64 records in 0.197556106 seconds. Throughput is 323.9586 records/second. Loss is 2.2378187. Sequential2290a28's hyper parameters: Current learning rate is 0.01985702938840349. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:52 INFO  DistriOptimizer$:408 - [Epoch 1 2432/60000][Iteration 38][Wall Clock 10.915067614s] Trained 64 records in 0.188793291 seconds. Throughput is 338.99512 records/second. Loss is 2.2208931. Sequential2290a28's hyper parameters: Current learning rate is 0.019853087155052608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:52 INFO  DistriOptimizer$:408 - [Epoch 1 2496/60000][Iteration 39][Wall Clock 11.096333078s] Trained 64 records in 0.181265464 seconds. Throughput is 353.07333 records/second. Loss is 2.1912138. Sequential2290a28's hyper parameters: Current learning rate is 0.01984914648670107. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:52 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 40][Wall Clock 11.404485517s] Trained 64 records in 0.308152439 seconds. Throughput is 207.68942 records/second. Loss is 2.205522. Sequential2290a28's hyper parameters: Current learning rate is 0.019845207382417147. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:52 INFO  DistriOptimizer$:408 - [Epoch 1 2624/60000][Iteration 41][Wall Clock 11.668831454s] Trained 64 records in 0.264345937 seconds. Throughput is 242.10698 records/second. Loss is 2.1800401. Sequential2290a28's hyper parameters: Current learning rate is 0.01984126984126984. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:53 INFO  DistriOptimizer$:408 - [Epoch 1 2688/60000][Iteration 42][Wall Clock 11.897832127s] Trained 64 records in 0.229000673 seconds. Throughput is 279.47516 records/second. Loss is 2.2282073. Sequential2290a28's hyper parameters: Current learning rate is 0.019837333862328905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:53 INFO  DistriOptimizer$:408 - [Epoch 1 2752/60000][Iteration 43][Wall Clock 12.132234504s] Trained 64 records in 0.234402377 seconds. Throughput is 273.0348 records/second. Loss is 2.1962736. Sequential2290a28's hyper parameters: Current learning rate is 0.019833399444664817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:53 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 44][Wall Clock 12.366770794s] Trained 64 records in 0.23453629 seconds. Throughput is 272.87888 records/second. Loss is 2.1761317. Sequential2290a28's hyper parameters: Current learning rate is 0.019829466587348802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:53 INFO  DistriOptimizer$:408 - [Epoch 1 2880/60000][Iteration 45][Wall Clock 12.606694365s] Trained 64 records in 0.239923571 seconds. Throughput is 266.75162 records/second. Loss is 2.2095144. Sequential2290a28's hyper parameters: Current learning rate is 0.019825535289452818. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:54 INFO  DistriOptimizer$:408 - [Epoch 1 2944/60000][Iteration 46][Wall Clock 12.759227465s] Trained 64 records in 0.1525331 seconds. Throughput is 419.58105 records/second. Loss is 2.173919. Sequential2290a28's hyper parameters: Current learning rate is 0.019821605550049557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:54 INFO  DistriOptimizer$:408 - [Epoch 1 3008/60000][Iteration 47][Wall Clock 12.966459225s] Trained 64 records in 0.20723176 seconds. Throughput is 308.83298 records/second. Loss is 2.1908095. Sequential2290a28's hyper parameters: Current learning rate is 0.019817677368212445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:54 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 48][Wall Clock 13.100498532s] Trained 64 records in 0.134039307 seconds. Throughput is 477.47186 records/second. Loss is 2.17991. Sequential2290a28's hyper parameters: Current learning rate is 0.01981375074301565. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:54 INFO  DistriOptimizer$:408 - [Epoch 1 3136/60000][Iteration 49][Wall Clock 13.309961985s] Trained 64 records in 0.209463453 seconds. Throughput is 305.54257 records/second. Loss is 2.197342. Sequential2290a28's hyper parameters: Current learning rate is 0.019809825673534072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:54 INFO  DistriOptimizer$:408 - [Epoch 1 3200/60000][Iteration 50][Wall Clock 13.490815705s] Trained 64 records in 0.18085372 seconds. Throughput is 353.87714 records/second. Loss is 2.1652608. Sequential2290a28's hyper parameters: Current learning rate is 0.019805902158843335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:55 INFO  DistriOptimizer$:408 - [Epoch 1 3264/60000][Iteration 51][Wall Clock 13.676183078s] Trained 64 records in 0.185367373 seconds. Throughput is 345.2603 records/second. Loss is 2.1662385. Sequential2290a28's hyper parameters: Current learning rate is 0.019801980198019802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:55 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 52][Wall Clock 13.911860999s] Trained 64 records in 0.235677921 seconds. Throughput is 271.55704 records/second. Loss is 2.1615462. Sequential2290a28's hyper parameters: Current learning rate is 0.019798059790140567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:55 INFO  DistriOptimizer$:408 - [Epoch 1 3392/60000][Iteration 53][Wall Clock 14.168713935s] Trained 64 records in 0.256852936 seconds. Throughput is 249.16983 records/second. Loss is 2.1601574. Sequential2290a28's hyper parameters: Current learning rate is 0.019794140934283454. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:55 INFO  DistriOptimizer$:408 - [Epoch 1 3456/60000][Iteration 54][Wall Clock 14.365379195s] Trained 64 records in 0.19666526 seconds. Throughput is 325.42606 records/second. Loss is 2.176111. Sequential2290a28's hyper parameters: Current learning rate is 0.019790223629527016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:55 INFO  DistriOptimizer$:408 - [Epoch 1 3520/60000][Iteration 55][Wall Clock 14.557579183s] Trained 64 records in 0.192199988 seconds. Throughput is 332.98648 records/second. Loss is 2.1779592. Sequential2290a28's hyper parameters: Current learning rate is 0.019786307874950535. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:56 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 56][Wall Clock 14.717748296s] Trained 64 records in 0.160169113 seconds. Throughput is 399.57767 records/second. Loss is 2.1281948. Sequential2290a28's hyper parameters: Current learning rate is 0.019782393669634028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:56 INFO  DistriOptimizer$:408 - [Epoch 1 3648/60000][Iteration 57][Wall Clock 14.900934553s] Trained 64 records in 0.183186257 seconds. Throughput is 349.3712 records/second. Loss is 2.1223085. Sequential2290a28's hyper parameters: Current learning rate is 0.019778481012658226. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:56 INFO  DistriOptimizer$:408 - [Epoch 1 3712/60000][Iteration 58][Wall Clock 15.10324304s] Trained 64 records in 0.202308487 seconds. Throughput is 316.34857 records/second. Loss is 2.093386. Sequential2290a28's hyper parameters: Current learning rate is 0.019774569903104607. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:56 INFO  DistriOptimizer$:408 - [Epoch 1 3776/60000][Iteration 59][Wall Clock 15.350192895s] Trained 64 records in 0.246949855 seconds. Throughput is 259.16193 records/second. Loss is 2.1288478. Sequential2290a28's hyper parameters: Current learning rate is 0.019770660340055358. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:56 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 60][Wall Clock 15.546216858s] Trained 64 records in 0.196023963 seconds. Throughput is 326.4907 records/second. Loss is 2.1056228. Sequential2290a28's hyper parameters: Current learning rate is 0.0197667523225934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:57 INFO  DistriOptimizer$:408 - [Epoch 1 3904/60000][Iteration 61][Wall Clock 15.719943044s] Trained 64 records in 0.173726186 seconds. Throughput is 368.3958 records/second. Loss is 2.122924. Sequential2290a28's hyper parameters: Current learning rate is 0.019762845849802372. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:57 INFO  DistriOptimizer$:408 - [Epoch 1 3968/60000][Iteration 62][Wall Clock 15.954979178s] Trained 64 records in 0.235036134 seconds. Throughput is 272.29855 records/second. Loss is 2.0989778. Sequential2290a28's hyper parameters: Current learning rate is 0.019758940920766646. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:57 INFO  DistriOptimizer$:408 - [Epoch 1 4032/60000][Iteration 63][Wall Clock 16.102524665s] Trained 64 records in 0.147545487 seconds. Throughput is 433.76453 records/second. Loss is 2.1231155. Sequential2290a28's hyper parameters: Current learning rate is 0.019755037534571317. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:57 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 64][Wall Clock 16.266004491s] Trained 64 records in 0.163479826 seconds. Throughput is 391.48563 records/second. Loss is 2.06352. Sequential2290a28's hyper parameters: Current learning rate is 0.019751135690302193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:57 INFO  DistriOptimizer$:408 - [Epoch 1 4160/60000][Iteration 65][Wall Clock 16.465202172s] Trained 64 records in 0.199197681 seconds. Throughput is 321.28888 records/second. Loss is 2.093298. Sequential2290a28's hyper parameters: Current learning rate is 0.019747235387045814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4224/60000][Iteration 66][Wall Clock 16.660574782s] Trained 64 records in 0.19537261 seconds. Throughput is 327.5792 records/second. Loss is 2.0711908. Sequential2290a28's hyper parameters: Current learning rate is 0.01974333662388944. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4288/60000][Iteration 67][Wall Clock 16.860120348s] Trained 64 records in 0.199545566 seconds. Throughput is 320.72876 records/second. Loss is 2.1211252. Sequential2290a28's hyper parameters: Current learning rate is 0.01973943939992104. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 68][Wall Clock 17.033724278s] Trained 64 records in 0.17360393 seconds. Throughput is 368.65524 records/second. Loss is 2.0585291. Sequential2290a28's hyper parameters: Current learning rate is 0.019735543714229326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4416/60000][Iteration 69][Wall Clock 17.184951886s] Trained 64 records in 0.151227608 seconds. Throughput is 423.20316 records/second. Loss is 2.0490756. Sequential2290a28's hyper parameters: Current learning rate is 0.01973164956590371. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4480/60000][Iteration 70][Wall Clock 17.325837177s] Trained 64 records in 0.140885291 seconds. Throughput is 454.27026 records/second. Loss is 2.0341897. Sequential2290a28's hyper parameters: Current learning rate is 0.019727756954034326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4544/60000][Iteration 71][Wall Clock 17.464648538s] Trained 64 records in 0.138811361 seconds. Throughput is 461.05734 records/second. Loss is 2.0485027. Sequential2290a28's hyper parameters: Current learning rate is 0.01972386587771203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:58 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 72][Wall Clock 17.592927374s] Trained 64 records in 0.128278836 seconds. Throughput is 498.91315 records/second. Loss is 2.0559788. Sequential2290a28's hyper parameters: Current learning rate is 0.019719976336028396. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:59 INFO  DistriOptimizer$:408 - [Epoch 1 4672/60000][Iteration 73][Wall Clock 17.742763619s] Trained 64 records in 0.149836245 seconds. Throughput is 427.13297 records/second. Loss is 2.0326133. Sequential2290a28's hyper parameters: Current learning rate is 0.019716088328075712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:59 INFO  DistriOptimizer$:408 - [Epoch 1 4736/60000][Iteration 74][Wall Clock 18.077947696s] Trained 64 records in 0.335184077 seconds. Throughput is 190.93987 records/second. Loss is 2.0290244. Sequential2290a28's hyper parameters: Current learning rate is 0.019712201852946976. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:59 INFO  DistriOptimizer$:408 - [Epoch 1 4800/60000][Iteration 75][Wall Clock 18.284817875s] Trained 64 records in 0.206870179 seconds. Throughput is 309.37277 records/second. Loss is 2.0387022. Sequential2290a28's hyper parameters: Current learning rate is 0.01970831690973591. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:13:59 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 76][Wall Clock 18.507919342s] Trained 64 records in 0.223101467 seconds. Throughput is 286.865 records/second. Loss is 2.0494366. Sequential2290a28's hyper parameters: Current learning rate is 0.01970443349753695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:00 INFO  DistriOptimizer$:408 - [Epoch 1 4928/60000][Iteration 77][Wall Clock 18.648710311s] Trained 64 records in 0.140790969 seconds. Throughput is 454.57462 records/second. Loss is 2.036053. Sequential2290a28's hyper parameters: Current learning rate is 0.01970055161544523. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:00 INFO  DistriOptimizer$:408 - [Epoch 1 4992/60000][Iteration 78][Wall Clock 18.799224041s] Trained 64 records in 0.15051373 seconds. Throughput is 425.2104 records/second. Loss is 2.0159442. Sequential2290a28's hyper parameters: Current learning rate is 0.019696671262556628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:00 INFO  DistriOptimizer$:408 - [Epoch 1 5056/60000][Iteration 79][Wall Clock 19.052542994s] Trained 64 records in 0.253318953 seconds. Throughput is 252.6459 records/second. Loss is 1.9890999. Sequential2290a28's hyper parameters: Current learning rate is 0.019692792437967704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:00 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 80][Wall Clock 19.242630108s] Trained 64 records in 0.190087114 seconds. Throughput is 336.68774 records/second. Loss is 1.9929469. Sequential2290a28's hyper parameters: Current learning rate is 0.019688915140775743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:00 INFO  DistriOptimizer$:408 - [Epoch 1 5184/60000][Iteration 81][Wall Clock 19.447006651s] Trained 64 records in 0.204376543 seconds. Throughput is 313.14746 records/second. Loss is 1.9834373. Sequential2290a28's hyper parameters: Current learning rate is 0.01968503937007874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:01 INFO  DistriOptimizer$:408 - [Epoch 1 5248/60000][Iteration 82][Wall Clock 19.759243139s] Trained 64 records in 0.312236488 seconds. Throughput is 204.97284 records/second. Loss is 1.9699652. Sequential2290a28's hyper parameters: Current learning rate is 0.0196811651249754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:01 INFO  DistriOptimizer$:408 - [Epoch 1 5312/60000][Iteration 83][Wall Clock 19.9235845s] Trained 64 records in 0.164341361 seconds. Throughput is 389.43332 records/second. Loss is 1.9217741. Sequential2290a28's hyper parameters: Current learning rate is 0.019677292404565134. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:01 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 84][Wall Clock 20.121433232s] Trained 64 records in 0.197848732 seconds. Throughput is 323.47946 records/second. Loss is 1.935688. Sequential2290a28's hyper parameters: Current learning rate is 0.019673421207948065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:01 INFO  DistriOptimizer$:408 - [Epoch 1 5440/60000][Iteration 85][Wall Clock 20.264774784s] Trained 64 records in 0.143341552 seconds. Throughput is 446.48602 records/second. Loss is 1.9780188. Sequential2290a28's hyper parameters: Current learning rate is 0.019669551534225022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:01 INFO  DistriOptimizer$:408 - [Epoch 1 5504/60000][Iteration 86][Wall Clock 20.55175672s] Trained 64 records in 0.286981936 seconds. Throughput is 223.01054 records/second. Loss is 1.9545541. Sequential2290a28's hyper parameters: Current learning rate is 0.019665683382497544. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:02 INFO  DistriOptimizer$:408 - [Epoch 1 5568/60000][Iteration 87][Wall Clock 20.745026082s] Trained 64 records in 0.193269362 seconds. Throughput is 331.14407 records/second. Loss is 1.9654078. Sequential2290a28's hyper parameters: Current learning rate is 0.019661816751867872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:02 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 88][Wall Clock 20.965403737s] Trained 64 records in 0.220377655 seconds. Throughput is 290.41058 records/second. Loss is 1.9686761. Sequential2290a28's hyper parameters: Current learning rate is 0.01965795164143896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:02 INFO  DistriOptimizer$:408 - [Epoch 1 5696/60000][Iteration 89][Wall Clock 21.206399105s] Trained 64 records in 0.240995368 seconds. Throughput is 265.56528 records/second. Loss is 1.9467536. Sequential2290a28's hyper parameters: Current learning rate is 0.019654088050314465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:02 INFO  DistriOptimizer$:408 - [Epoch 1 5760/60000][Iteration 90][Wall Clock 21.413173093s] Trained 64 records in 0.206773988 seconds. Throughput is 309.5167 records/second. Loss is 1.9004849. Sequential2290a28's hyper parameters: Current learning rate is 0.019650225977598742. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:02 INFO  DistriOptimizer$:408 - [Epoch 1 5824/60000][Iteration 91][Wall Clock 21.556522624s] Trained 64 records in 0.143349531 seconds. Throughput is 446.46118 records/second. Loss is 1.8434405. Sequential2290a28's hyper parameters: Current learning rate is 0.019646365422396856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:03 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 92][Wall Clock 21.7090579s] Trained 64 records in 0.152535276 seconds. Throughput is 419.57507 records/second. Loss is 1.9541322. Sequential2290a28's hyper parameters: Current learning rate is 0.019642506383814574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:03 INFO  DistriOptimizer$:408 - [Epoch 1 5952/60000][Iteration 93][Wall Clock 21.880460756s] Trained 64 records in 0.171402856 seconds. Throughput is 373.38934 records/second. Loss is 1.8454505. Sequential2290a28's hyper parameters: Current learning rate is 0.01963864886095837. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:03 INFO  DistriOptimizer$:408 - [Epoch 1 6016/60000][Iteration 94][Wall Clock 22.060243404s] Trained 64 records in 0.179782648 seconds. Throughput is 355.9854 records/second. Loss is 1.824751. Sequential2290a28's hyper parameters: Current learning rate is 0.019634792852935404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:03 INFO  DistriOptimizer$:408 - [Epoch 1 6080/60000][Iteration 95][Wall Clock 22.221390588s] Trained 64 records in 0.161147184 seconds. Throughput is 397.15247 records/second. Loss is 1.8551699. Sequential2290a28's hyper parameters: Current learning rate is 0.019630938358853555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:03 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 96][Wall Clock 22.398000827s] Trained 64 records in 0.176610239 seconds. Throughput is 362.37988 records/second. Loss is 1.961711. Sequential2290a28's hyper parameters: Current learning rate is 0.019627085377821395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:03 INFO  DistriOptimizer$:408 - [Epoch 1 6208/60000][Iteration 97][Wall Clock 22.553404868s] Trained 64 records in 0.155404041 seconds. Throughput is 411.82968 records/second. Loss is 1.8087182. Sequential2290a28's hyper parameters: Current learning rate is 0.01962323390894819. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:04 INFO  DistriOptimizer$:408 - [Epoch 1 6272/60000][Iteration 98][Wall Clock 22.750297729s] Trained 64 records in 0.196892861 seconds. Throughput is 325.0499 records/second. Loss is 1.8338913. Sequential2290a28's hyper parameters: Current learning rate is 0.019619383951343928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:04 INFO  DistriOptimizer$:408 - [Epoch 1 6336/60000][Iteration 99][Wall Clock 22.915256473s] Trained 64 records in 0.164958744 seconds. Throughput is 387.9758 records/second. Loss is 1.9048829. Sequential2290a28's hyper parameters: Current learning rate is 0.01961553550411926. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:04 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 100][Wall Clock 23.09678785s] Trained 64 records in 0.181531377 seconds. Throughput is 352.55615 records/second. Loss is 1.9042171. Sequential2290a28's hyper parameters: Current learning rate is 0.019611688566385566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:04 INFO  DistriOptimizer$:408 - [Epoch 1 6464/60000][Iteration 101][Wall Clock 23.221062261s] Trained 64 records in 0.124274411 seconds. Throughput is 514.9894 records/second. Loss is 1.8773482. Sequential2290a28's hyper parameters: Current learning rate is 0.0196078431372549. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:04 INFO  DistriOptimizer$:408 - [Epoch 1 6528/60000][Iteration 102][Wall Clock 23.361067004s] Trained 64 records in 0.140004743 seconds. Throughput is 457.12738 records/second. Loss is 1.8980714. Sequential2290a28's hyper parameters: Current learning rate is 0.01960399921584003. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:04 INFO  DistriOptimizer$:408 - [Epoch 1 6592/60000][Iteration 103][Wall Clock 23.507807716s] Trained 64 records in 0.146740712 seconds. Throughput is 436.14346 records/second. Loss is 1.7040617. Sequential2290a28's hyper parameters: Current learning rate is 0.01960015680125441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:05 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 104][Wall Clock 23.702295911s] Trained 64 records in 0.194488195 seconds. Throughput is 329.06882 records/second. Loss is 1.8184164. Sequential2290a28's hyper parameters: Current learning rate is 0.01959631589261219. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:05 INFO  DistriOptimizer$:408 - [Epoch 1 6720/60000][Iteration 105][Wall Clock 23.889701165s] Trained 64 records in 0.187405254 seconds. Throughput is 341.5059 records/second. Loss is 1.7996285. Sequential2290a28's hyper parameters: Current learning rate is 0.019592476489028215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:05 INFO  DistriOptimizer$:408 - [Epoch 1 6784/60000][Iteration 106][Wall Clock 24.054761239s] Trained 64 records in 0.165060074 seconds. Throughput is 387.7376 records/second. Loss is 1.8612168. Sequential2290a28's hyper parameters: Current learning rate is 0.019588638589618023. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:05 INFO  DistriOptimizer$:408 - [Epoch 1 6848/60000][Iteration 107][Wall Clock 24.247296807s] Trained 64 records in 0.192535568 seconds. Throughput is 332.40613 records/second. Loss is 1.821393. Sequential2290a28's hyper parameters: Current learning rate is 0.019584802193497845. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:05 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 108][Wall Clock 24.448095743s] Trained 64 records in 0.200798936 seconds. Throughput is 318.7268 records/second. Loss is 1.8297503. Sequential2290a28's hyper parameters: Current learning rate is 0.019580967299784608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 6976/60000][Iteration 109][Wall Clock 24.628931801s] Trained 64 records in 0.180836058 seconds. Throughput is 353.91174 records/second. Loss is 1.7474954. Sequential2290a28's hyper parameters: Current learning rate is 0.019577133907595926. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 7040/60000][Iteration 110][Wall Clock 24.795893286s] Trained 64 records in 0.166961485 seconds. Throughput is 383.32193 records/second. Loss is 1.8261105. Sequential2290a28's hyper parameters: Current learning rate is 0.019573302016050106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 7104/60000][Iteration 111][Wall Clock 24.970426214s] Trained 64 records in 0.174532928 seconds. Throughput is 366.69296 records/second. Loss is 1.7295654. Sequential2290a28's hyper parameters: Current learning rate is 0.019569471624266144. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 112][Wall Clock 25.081049297s] Trained 64 records in 0.110623083 seconds. Throughput is 578.5411 records/second. Loss is 1.7430366. Sequential2290a28's hyper parameters: Current learning rate is 0.019565642731363724. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 7232/60000][Iteration 113][Wall Clock 25.206123875s] Trained 64 records in 0.125074578 seconds. Throughput is 511.6947 records/second. Loss is 1.6914732. Sequential2290a28's hyper parameters: Current learning rate is 0.019561815336463225. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 7296/60000][Iteration 114][Wall Clock 25.367598119s] Trained 64 records in 0.161474244 seconds. Throughput is 396.34805 records/second. Loss is 1.6454341. Sequential2290a28's hyper parameters: Current learning rate is 0.019557989438685704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:06 INFO  DistriOptimizer$:408 - [Epoch 1 7360/60000][Iteration 115][Wall Clock 25.523029816s] Trained 64 records in 0.155431697 seconds. Throughput is 411.7564 records/second. Loss is 1.6245716. Sequential2290a28's hyper parameters: Current learning rate is 0.019554165037152915. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:07 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 116][Wall Clock 25.705049965s] Trained 64 records in 0.182020149 seconds. Throughput is 351.60944 records/second. Loss is 1.7346659. Sequential2290a28's hyper parameters: Current learning rate is 0.019550342130987296. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:07 INFO  DistriOptimizer$:408 - [Epoch 1 7488/60000][Iteration 117][Wall Clock 25.887980945s] Trained 64 records in 0.18293098 seconds. Throughput is 349.85873 records/second. Loss is 1.7642438. Sequential2290a28's hyper parameters: Current learning rate is 0.019546520719311962. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:07 INFO  DistriOptimizer$:408 - [Epoch 1 7552/60000][Iteration 118][Wall Clock 26.0260366s] Trained 64 records in 0.138055655 seconds. Throughput is 463.58118 records/second. Loss is 1.7083312. Sequential2290a28's hyper parameters: Current learning rate is 0.019542700801250732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:07 INFO  DistriOptimizer$:408 - [Epoch 1 7616/60000][Iteration 119][Wall Clock 26.157329668s] Trained 64 records in 0.131293068 seconds. Throughput is 487.45908 records/second. Loss is 1.6367401. Sequential2290a28's hyper parameters: Current learning rate is 0.019538882375928095. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:07 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 120][Wall Clock 26.36178837s] Trained 64 records in 0.204458702 seconds. Throughput is 313.02167 records/second. Loss is 1.6579124. Sequential2290a28's hyper parameters: Current learning rate is 0.019535065442469232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:07 INFO  DistriOptimizer$:408 - [Epoch 1 7744/60000][Iteration 121][Wall Clock 26.562586173s] Trained 64 records in 0.200797803 seconds. Throughput is 318.7286 records/second. Loss is 1.6302049. Sequential2290a28's hyper parameters: Current learning rate is 0.01953125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:08 INFO  DistriOptimizer$:408 - [Epoch 1 7808/60000][Iteration 122][Wall Clock 26.736940339s] Trained 64 records in 0.174354166 seconds. Throughput is 367.06894 records/second. Loss is 1.6830826. Sequential2290a28's hyper parameters: Current learning rate is 0.019527436047646944. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:08 INFO  DistriOptimizer$:408 - [Epoch 1 7872/60000][Iteration 123][Wall Clock 26.972785056s] Trained 64 records in 0.235844717 seconds. Throughput is 271.365 records/second. Loss is 1.6390985. Sequential2290a28's hyper parameters: Current learning rate is 0.01952362358453729. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:08 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 124][Wall Clock 27.152751844s] Trained 64 records in 0.179966788 seconds. Throughput is 355.62115 records/second. Loss is 1.778948. Sequential2290a28's hyper parameters: Current learning rate is 0.01951981260979895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:08 INFO  DistriOptimizer$:408 - [Epoch 1 8000/60000][Iteration 125][Wall Clock 27.329050878s] Trained 64 records in 0.176299034 seconds. Throughput is 363.01956 records/second. Loss is 1.7128098. Sequential2290a28's hyper parameters: Current learning rate is 0.0195160031225605. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:08 INFO  DistriOptimizer$:408 - [Epoch 1 8064/60000][Iteration 126][Wall Clock 27.574192992s] Trained 64 records in 0.245142114 seconds. Throughput is 261.07306 records/second. Loss is 1.7056319. Sequential2290a28's hyper parameters: Current learning rate is 0.019512195121951223. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:09 INFO  DistriOptimizer$:408 - [Epoch 1 8128/60000][Iteration 127][Wall Clock 27.731403266s] Trained 64 records in 0.157210274 seconds. Throughput is 407.09808 records/second. Loss is 1.6888764. Sequential2290a28's hyper parameters: Current learning rate is 0.019508388607101055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:09 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 128][Wall Clock 27.97777614s] Trained 64 records in 0.246372874 seconds. Throughput is 259.76886 records/second. Loss is 1.646879. Sequential2290a28's hyper parameters: Current learning rate is 0.019504583577140626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:09 INFO  DistriOptimizer$:408 - [Epoch 1 8256/60000][Iteration 129][Wall Clock 28.116913322s] Trained 64 records in 0.139137182 seconds. Throughput is 459.9777 records/second. Loss is 1.5363395. Sequential2290a28's hyper parameters: Current learning rate is 0.01950078003120125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:09 INFO  DistriOptimizer$:408 - [Epoch 1 8320/60000][Iteration 130][Wall Clock 28.328943117s] Trained 64 records in 0.212029795 seconds. Throughput is 301.84436 records/second. Loss is 1.6153541. Sequential2290a28's hyper parameters: Current learning rate is 0.019496977968414896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:09 INFO  DistriOptimizer$:408 - [Epoch 1 8384/60000][Iteration 131][Wall Clock 28.485866935s] Trained 64 records in 0.156923818 seconds. Throughput is 407.84122 records/second. Loss is 1.5906285. Sequential2290a28's hyper parameters: Current learning rate is 0.01949317738791423. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 132][Wall Clock 28.661957765s] Trained 64 records in 0.17609083 seconds. Throughput is 363.4488 records/second. Loss is 1.5605401. Sequential2290a28's hyper parameters: Current learning rate is 0.019489378288832588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8512/60000][Iteration 133][Wall Clock 28.787318306s] Trained 64 records in 0.125360541 seconds. Throughput is 510.5275 records/second. Loss is 1.519974. Sequential2290a28's hyper parameters: Current learning rate is 0.019485580670303974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8576/60000][Iteration 134][Wall Clock 28.983824835s] Trained 64 records in 0.196506529 seconds. Throughput is 325.68893 records/second. Loss is 1.6238027. Sequential2290a28's hyper parameters: Current learning rate is 0.019481784531463084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8640/60000][Iteration 135][Wall Clock 29.128360297s] Trained 64 records in 0.144535462 seconds. Throughput is 442.79788 records/second. Loss is 1.625848. Sequential2290a28's hyper parameters: Current learning rate is 0.019477989871445268. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 136][Wall Clock 29.286917696s] Trained 64 records in 0.158557399 seconds. Throughput is 403.6393 records/second. Loss is 1.5225365. Sequential2290a28's hyper parameters: Current learning rate is 0.019474196689386564. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8768/60000][Iteration 137][Wall Clock 29.433346176s] Trained 64 records in 0.14642848 seconds. Throughput is 437.07346 records/second. Loss is 1.560366. Sequential2290a28's hyper parameters: Current learning rate is 0.019470404984423675. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:10 INFO  DistriOptimizer$:408 - [Epoch 1 8832/60000][Iteration 138][Wall Clock 29.542024511s] Trained 64 records in 0.108678335 seconds. Throughput is 588.89386 records/second. Loss is 1.4840478. Sequential2290a28's hyper parameters: Current learning rate is 0.019466614755693983. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 8896/60000][Iteration 139][Wall Clock 29.645856755s] Trained 64 records in 0.103832244 seconds. Throughput is 616.37885 records/second. Loss is 1.5019193. Sequential2290a28's hyper parameters: Current learning rate is 0.019462826002335537. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 140][Wall Clock 29.798945479s] Trained 64 records in 0.153088724 seconds. Throughput is 418.05823 records/second. Loss is 1.5231867. Sequential2290a28's hyper parameters: Current learning rate is 0.01945903872348706. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 9024/60000][Iteration 141][Wall Clock 29.943162521s] Trained 64 records in 0.144217042 seconds. Throughput is 443.77557 records/second. Loss is 1.530797. Sequential2290a28's hyper parameters: Current learning rate is 0.019455252918287938. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 9088/60000][Iteration 142][Wall Clock 30.065338262s] Trained 64 records in 0.122175741 seconds. Throughput is 523.8356 records/second. Loss is 1.6000166. Sequential2290a28's hyper parameters: Current learning rate is 0.019451468585878234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 9152/60000][Iteration 143][Wall Clock 30.181755985s] Trained 64 records in 0.116417723 seconds. Throughput is 549.7445 records/second. Loss is 1.5054498. Sequential2290a28's hyper parameters: Current learning rate is 0.019447685725398678. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 144][Wall Clock 30.348907712s] Trained 64 records in 0.167151727 seconds. Throughput is 382.88565 records/second. Loss is 1.6446327. Sequential2290a28's hyper parameters: Current learning rate is 0.019443904335990667. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:11 INFO  DistriOptimizer$:408 - [Epoch 1 9280/60000][Iteration 145][Wall Clock 30.511059715s] Trained 64 records in 0.162152003 seconds. Throughput is 394.69138 records/second. Loss is 1.5380284. Sequential2290a28's hyper parameters: Current learning rate is 0.01944012441679627. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9344/60000][Iteration 146][Wall Clock 30.763343603s] Trained 64 records in 0.252283888 seconds. Throughput is 253.68246 records/second. Loss is 1.5175532. Sequential2290a28's hyper parameters: Current learning rate is 0.019436345966958216. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9408/60000][Iteration 147][Wall Clock 30.917808875s] Trained 64 records in 0.154465272 seconds. Throughput is 414.3326 records/second. Loss is 1.4986097. Sequential2290a28's hyper parameters: Current learning rate is 0.019432568985619902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 148][Wall Clock 31.029696813s] Trained 64 records in 0.111887938 seconds. Throughput is 572.00085 records/second. Loss is 1.3702793. Sequential2290a28's hyper parameters: Current learning rate is 0.01942879347192539. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9536/60000][Iteration 149][Wall Clock 31.13645428s] Trained 64 records in 0.106757467 seconds. Throughput is 599.4897 records/second. Loss is 1.3775855. Sequential2290a28's hyper parameters: Current learning rate is 0.019425019425019424. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9600/60000][Iteration 150][Wall Clock 31.252549615s] Trained 64 records in 0.116095335 seconds. Throughput is 551.27106 records/second. Loss is 1.4292188. Sequential2290a28's hyper parameters: Current learning rate is 0.019421246844047387. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9664/60000][Iteration 151][Wall Clock 31.372502301s] Trained 64 records in 0.119952686 seconds. Throughput is 533.5437 records/second. Loss is 1.4209675. Sequential2290a28's hyper parameters: Current learning rate is 0.019417475728155338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:12 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 152][Wall Clock 31.527365011s] Trained 64 records in 0.15486271 seconds. Throughput is 413.26926 records/second. Loss is 1.6264693. Sequential2290a28's hyper parameters: Current learning rate is 0.01941370607649. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 9792/60000][Iteration 153][Wall Clock 31.663933562s] Trained 64 records in 0.136568551 seconds. Throughput is 468.62915 records/second. Loss is 1.3654681. Sequential2290a28's hyper parameters: Current learning rate is 0.01940993788819876. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 9856/60000][Iteration 154][Wall Clock 31.832287349s] Trained 64 records in 0.168353787 seconds. Throughput is 380.15186 records/second. Loss is 1.533462. Sequential2290a28's hyper parameters: Current learning rate is 0.019406171162429653. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 9920/60000][Iteration 155][Wall Clock 31.946779767s] Trained 64 records in 0.114492418 seconds. Throughput is 558.989 records/second. Loss is 1.5145171. Sequential2290a28's hyper parameters: Current learning rate is 0.019402405898331393. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 156][Wall Clock 32.120185187s] Trained 64 records in 0.17340542 seconds. Throughput is 369.07727 records/second. Loss is 1.2527821. Sequential2290a28's hyper parameters: Current learning rate is 0.019398642095053348. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 10048/60000][Iteration 157][Wall Clock 32.249561927s] Trained 64 records in 0.12937674 seconds. Throughput is 494.67935 records/second. Loss is 1.5063726. Sequential2290a28's hyper parameters: Current learning rate is 0.01939487975174554. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 10112/60000][Iteration 158][Wall Clock 32.372667006s] Trained 64 records in 0.123105079 seconds. Throughput is 519.88104 records/second. Loss is 1.5286582. Sequential2290a28's hyper parameters: Current learning rate is 0.019391118867558656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:13 INFO  DistriOptimizer$:408 - [Epoch 1 10176/60000][Iteration 159][Wall Clock 32.481237435s] Trained 64 records in 0.108570429 seconds. Throughput is 589.4791 records/second. Loss is 1.3458182. Sequential2290a28's hyper parameters: Current learning rate is 0.019387359441644048. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 160][Wall Clock 32.57297231s] Trained 64 records in 0.091734875 seconds. Throughput is 697.66266 records/second. Loss is 1.4059774. Sequential2290a28's hyper parameters: Current learning rate is 0.01938360147315371. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10304/60000][Iteration 161][Wall Clock 32.685622396s] Trained 64 records in 0.112650086 seconds. Throughput is 568.1309 records/second. Loss is 1.3887392. Sequential2290a28's hyper parameters: Current learning rate is 0.01937984496124031. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10368/60000][Iteration 162][Wall Clock 32.81197836s] Trained 64 records in 0.126355964 seconds. Throughput is 506.50558 records/second. Loss is 1.3591193. Sequential2290a28's hyper parameters: Current learning rate is 0.01937608990505716. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10432/60000][Iteration 163][Wall Clock 32.941677797s] Trained 64 records in 0.129699437 seconds. Throughput is 493.44855 records/second. Loss is 1.3043828. Sequential2290a28's hyper parameters: Current learning rate is 0.019372336303758234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 164][Wall Clock 33.088094294s] Trained 64 records in 0.146416497 seconds. Throughput is 437.1092 records/second. Loss is 1.4753394. Sequential2290a28's hyper parameters: Current learning rate is 0.01936858415649816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10560/60000][Iteration 165][Wall Clock 33.225610704s] Trained 64 records in 0.13751641 seconds. Throughput is 465.39902 records/second. Loss is 1.5047768. Sequential2290a28's hyper parameters: Current learning rate is 0.019364833462432226. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10624/60000][Iteration 166][Wall Clock 33.373045143s] Trained 64 records in 0.147434439 seconds. Throughput is 434.09125 records/second. Loss is 1.301154. Sequential2290a28's hyper parameters: Current learning rate is 0.019361084220716362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:14 INFO  DistriOptimizer$:408 - [Epoch 1 10688/60000][Iteration 167][Wall Clock 33.507141388s] Trained 64 records in 0.134096245 seconds. Throughput is 477.26913 records/second. Loss is 1.294369. Sequential2290a28's hyper parameters: Current learning rate is 0.019357336430507164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 168][Wall Clock 33.65752111s] Trained 64 records in 0.150379722 seconds. Throughput is 425.5893 records/second. Loss is 1.2400291. Sequential2290a28's hyper parameters: Current learning rate is 0.01935359009096187. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 10816/60000][Iteration 169][Wall Clock 33.817874384s] Trained 64 records in 0.160353274 seconds. Throughput is 399.11877 records/second. Loss is 1.2378483. Sequential2290a28's hyper parameters: Current learning rate is 0.019349845201238388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 10880/60000][Iteration 170][Wall Clock 33.967552436s] Trained 64 records in 0.149678052 seconds. Throughput is 427.5844 records/second. Loss is 1.2827525. Sequential2290a28's hyper parameters: Current learning rate is 0.019346101760495258. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 10944/60000][Iteration 171][Wall Clock 34.077606216s] Trained 64 records in 0.11005378 seconds. Throughput is 581.5339 records/second. Loss is 1.4229844. Sequential2290a28's hyper parameters: Current learning rate is 0.019342359767891684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 172][Wall Clock 34.191613771s] Trained 64 records in 0.114007555 seconds. Throughput is 561.36633 records/second. Loss is 1.2153655. Sequential2290a28's hyper parameters: Current learning rate is 0.01933861922258751. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 11072/60000][Iteration 173][Wall Clock 34.362575s] Trained 64 records in 0.170961229 seconds. Throughput is 374.35388 records/second. Loss is 1.2906569. Sequential2290a28's hyper parameters: Current learning rate is 0.019334880123743233. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:15 INFO  DistriOptimizer$:408 - [Epoch 1 11136/60000][Iteration 174][Wall Clock 34.498306333s] Trained 64 records in 0.135731333 seconds. Throughput is 471.51968 records/second. Loss is 1.3665972. Sequential2290a28's hyper parameters: Current learning rate is 0.019331142470520007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:16 INFO  DistriOptimizer$:408 - [Epoch 1 11200/60000][Iteration 175][Wall Clock 34.661381265s] Trained 64 records in 0.163074932 seconds. Throughput is 392.45764 records/second. Loss is 1.3135723. Sequential2290a28's hyper parameters: Current learning rate is 0.01932740626207963. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:16 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 176][Wall Clock 34.848951695s] Trained 64 records in 0.18757043 seconds. Throughput is 341.20517 records/second. Loss is 1.3698926. Sequential2290a28's hyper parameters: Current learning rate is 0.019323671497584544. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:16 INFO  DistriOptimizer$:408 - [Epoch 1 11328/60000][Iteration 177][Wall Clock 34.99958028s] Trained 64 records in 0.150628585 seconds. Throughput is 424.88617 records/second. Loss is 1.2638888. Sequential2290a28's hyper parameters: Current learning rate is 0.01931993817619784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:16 INFO  DistriOptimizer$:408 - [Epoch 1 11392/60000][Iteration 178][Wall Clock 35.159302498s] Trained 64 records in 0.159722218 seconds. Throughput is 400.69565 records/second. Loss is 1.167262. Sequential2290a28's hyper parameters: Current learning rate is 0.019316206297083253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:16 INFO  DistriOptimizer$:408 - [Epoch 1 11456/60000][Iteration 179][Wall Clock 35.271588717s] Trained 64 records in 0.112286219 seconds. Throughput is 569.972 records/second. Loss is 1.2561554. Sequential2290a28's hyper parameters: Current learning rate is 0.019312475859405175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:16 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 180][Wall Clock 35.425277714s] Trained 64 records in 0.153688997 seconds. Throughput is 416.42538 records/second. Loss is 1.1963447. Sequential2290a28's hyper parameters: Current learning rate is 0.019308746862328634. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11584/60000][Iteration 181][Wall Clock 35.57395008s] Trained 64 records in 0.148672366 seconds. Throughput is 430.47675 records/second. Loss is 1.2318548. Sequential2290a28's hyper parameters: Current learning rate is 0.019305019305019305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11648/60000][Iteration 182][Wall Clock 35.725458578s] Trained 64 records in 0.151508498 seconds. Throughput is 422.41855 records/second. Loss is 1.1595515. Sequential2290a28's hyper parameters: Current learning rate is 0.019301293186643507. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11712/60000][Iteration 183][Wall Clock 35.850083591s] Trained 64 records in 0.124625013 seconds. Throughput is 513.5406 records/second. Loss is 1.1741579. Sequential2290a28's hyper parameters: Current learning rate is 0.0192975685063682. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 184][Wall Clock 35.966556003s] Trained 64 records in 0.116472412 seconds. Throughput is 549.4863 records/second. Loss is 1.3818802. Sequential2290a28's hyper parameters: Current learning rate is 0.01929384526336099. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11840/60000][Iteration 185][Wall Clock 36.090393097s] Trained 64 records in 0.123837094 seconds. Throughput is 516.808 records/second. Loss is 1.2192302. Sequential2290a28's hyper parameters: Current learning rate is 0.019290123456790126. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11904/60000][Iteration 186][Wall Clock 36.211422404s] Trained 64 records in 0.121029307 seconds. Throughput is 528.79755 records/second. Loss is 1.2838045. Sequential2290a28's hyper parameters: Current learning rate is 0.019286403085824494. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 11968/60000][Iteration 187][Wall Clock 36.343682979s] Trained 64 records in 0.132260575 seconds. Throughput is 483.89325 records/second. Loss is 1.1653643. Sequential2290a28's hyper parameters: Current learning rate is 0.01928268414963363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:17 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 188][Wall Clock 36.519699829s] Trained 64 records in 0.17601685 seconds. Throughput is 363.60156 records/second. Loss is 1.1489749. Sequential2290a28's hyper parameters: Current learning rate is 0.019278966647387697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12096/60000][Iteration 189][Wall Clock 36.707738559s] Trained 64 records in 0.18803873 seconds. Throughput is 340.3554 records/second. Loss is 1.0070169. Sequential2290a28's hyper parameters: Current learning rate is 0.019275250578257516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12160/60000][Iteration 190][Wall Clock 36.809428718s] Trained 64 records in 0.101690159 seconds. Throughput is 629.3628 records/second. Loss is 1.141531. Sequential2290a28's hyper parameters: Current learning rate is 0.01927153594141453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12224/60000][Iteration 191][Wall Clock 36.891855268s] Trained 64 records in 0.08242655 seconds. Throughput is 776.44885 records/second. Loss is 1.078034. Sequential2290a28's hyper parameters: Current learning rate is 0.019267822736030827. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 192][Wall Clock 37.008071053s] Trained 64 records in 0.116215785 seconds. Throughput is 550.6997 records/second. Loss is 1.1709832. Sequential2290a28's hyper parameters: Current learning rate is 0.019264110961279137. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12352/60000][Iteration 193][Wall Clock 37.171071127s] Trained 64 records in 0.163000074 seconds. Throughput is 392.63785 records/second. Loss is 1.124701. Sequential2290a28's hyper parameters: Current learning rate is 0.019260400616332822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12416/60000][Iteration 194][Wall Clock 37.339562568s] Trained 64 records in 0.168491441 seconds. Throughput is 379.84125 records/second. Loss is 1.089687. Sequential2290a28's hyper parameters: Current learning rate is 0.01925669170036588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:18 INFO  DistriOptimizer$:408 - [Epoch 1 12480/60000][Iteration 195][Wall Clock 37.483465926s] Trained 64 records in 0.143903358 seconds. Throughput is 444.74292 records/second. Loss is 1.2322989. Sequential2290a28's hyper parameters: Current learning rate is 0.019252984212552948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 196][Wall Clock 37.582297725s] Trained 64 records in 0.098831799 seconds. Throughput is 647.5648 records/second. Loss is 1.0669955. Sequential2290a28's hyper parameters: Current learning rate is 0.0192492781520693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12608/60000][Iteration 197][Wall Clock 37.681048145s] Trained 64 records in 0.09875042 seconds. Throughput is 648.0985 records/second. Loss is 1.150856. Sequential2290a28's hyper parameters: Current learning rate is 0.019245573518090843. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12672/60000][Iteration 198][Wall Clock 37.80774988s] Trained 64 records in 0.126701735 seconds. Throughput is 505.1233 records/second. Loss is 1.1563486. Sequential2290a28's hyper parameters: Current learning rate is 0.01924187030979411. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12736/60000][Iteration 199][Wall Clock 38.004900984s] Trained 64 records in 0.197151104 seconds. Throughput is 324.62408 records/second. Loss is 1.0323449. Sequential2290a28's hyper parameters: Current learning rate is 0.01923816852635629. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 200][Wall Clock 38.147633325s] Trained 64 records in 0.142732341 seconds. Throughput is 448.39172 records/second. Loss is 1.222145. Sequential2290a28's hyper parameters: Current learning rate is 0.019234468166955183. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12864/60000][Iteration 201][Wall Clock 38.286730425s] Trained 64 records in 0.1390971 seconds. Throughput is 460.11026 records/second. Loss is 1.0046186. Sequential2290a28's hyper parameters: Current learning rate is 0.019230769230769232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:19 INFO  DistriOptimizer$:408 - [Epoch 1 12928/60000][Iteration 202][Wall Clock 38.404589546s] Trained 64 records in 0.117859121 seconds. Throughput is 543.0212 records/second. Loss is 1.09154. Sequential2290a28's hyper parameters: Current learning rate is 0.019227071716977504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 12992/60000][Iteration 203][Wall Clock 38.521893125s] Trained 64 records in 0.117303579 seconds. Throughput is 545.5929 records/second. Loss is 1.0987549. Sequential2290a28's hyper parameters: Current learning rate is 0.019223375624759707. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 204][Wall Clock 38.635533682s] Trained 64 records in 0.113640557 seconds. Throughput is 563.17926 records/second. Loss is 1.0799606. Sequential2290a28's hyper parameters: Current learning rate is 0.019219680953296178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13120/60000][Iteration 205][Wall Clock 38.734692033s] Trained 64 records in 0.099158351 seconds. Throughput is 645.43225 records/second. Loss is 1.051605. Sequential2290a28's hyper parameters: Current learning rate is 0.019215987701767873. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13184/60000][Iteration 206][Wall Clock 38.877442166s] Trained 64 records in 0.142750133 seconds. Throughput is 448.33585 records/second. Loss is 1.1257915. Sequential2290a28's hyper parameters: Current learning rate is 0.01921229586935639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13248/60000][Iteration 207][Wall Clock 39.034121297s] Trained 64 records in 0.156679131 seconds. Throughput is 408.47815 records/second. Loss is 1.0445879. Sequential2290a28's hyper parameters: Current learning rate is 0.01920860545524395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 208][Wall Clock 39.165879622s] Trained 64 records in 0.131758325 seconds. Throughput is 485.7378 records/second. Loss is 1.2124448. Sequential2290a28's hyper parameters: Current learning rate is 0.019204916458613403. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13376/60000][Iteration 209][Wall Clock 39.323107646s] Trained 64 records in 0.157228024 seconds. Throughput is 407.05212 records/second. Loss is 1.0476885. Sequential2290a28's hyper parameters: Current learning rate is 0.01920122887864823. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:20 INFO  DistriOptimizer$:408 - [Epoch 1 13440/60000][Iteration 210][Wall Clock 39.473430586s] Trained 64 records in 0.15032294 seconds. Throughput is 425.75003 records/second. Loss is 1.0328475. Sequential2290a28's hyper parameters: Current learning rate is 0.01919754271453254. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13504/60000][Iteration 211][Wall Clock 39.640952636s] Trained 64 records in 0.16752205 seconds. Throughput is 382.03928 records/second. Loss is 1.0406058. Sequential2290a28's hyper parameters: Current learning rate is 0.019193857965451054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 212][Wall Clock 39.742957368s] Trained 64 records in 0.102004732 seconds. Throughput is 627.4219 records/second. Loss is 1.0516257. Sequential2290a28's hyper parameters: Current learning rate is 0.019190174630589137. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13632/60000][Iteration 213][Wall Clock 39.854998114s] Trained 64 records in 0.112040746 seconds. Throughput is 571.22076 records/second. Loss is 0.9384875. Sequential2290a28's hyper parameters: Current learning rate is 0.019186492709132773. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13696/60000][Iteration 214][Wall Clock 39.957937057s] Trained 64 records in 0.102938943 seconds. Throughput is 621.7278 records/second. Loss is 1.1773901. Sequential2290a28's hyper parameters: Current learning rate is 0.01918281220026856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13760/60000][Iteration 215][Wall Clock 40.069341644s] Trained 64 records in 0.111404587 seconds. Throughput is 574.4826 records/second. Loss is 1.0835923. Sequential2290a28's hyper parameters: Current learning rate is 0.019179133103183737. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 216][Wall Clock 40.188396618s] Trained 64 records in 0.119054974 seconds. Throughput is 537.5668 records/second. Loss is 0.9941025. Sequential2290a28's hyper parameters: Current learning rate is 0.019175455417066157. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13888/60000][Iteration 217][Wall Clock 40.322748312s] Trained 64 records in 0.134351694 seconds. Throughput is 476.36166 records/second. Loss is 1.0387796. Sequential2290a28's hyper parameters: Current learning rate is 0.0191717791411043. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:21 INFO  DistriOptimizer$:408 - [Epoch 1 13952/60000][Iteration 218][Wall Clock 40.463392922s] Trained 64 records in 0.14064461 seconds. Throughput is 455.04767 records/second. Loss is 1.0326427. Sequential2290a28's hyper parameters: Current learning rate is 0.01916810427448725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:22 INFO  DistriOptimizer$:408 - [Epoch 1 14016/60000][Iteration 219][Wall Clock 40.680338154s] Trained 64 records in 0.216945232 seconds. Throughput is 295.00534 records/second. Loss is 0.99974877. Sequential2290a28's hyper parameters: Current learning rate is 0.019164430816404752. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:22 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 220][Wall Clock 40.902161973s] Trained 64 records in 0.221823819 seconds. Throughput is 288.51724 records/second. Loss is 1.0001366. Sequential2290a28's hyper parameters: Current learning rate is 0.019160758766047135. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:22 INFO  DistriOptimizer$:408 - [Epoch 1 14144/60000][Iteration 221][Wall Clock 41.028694527s] Trained 64 records in 0.126532554 seconds. Throughput is 505.79868 records/second. Loss is 1.0257229. Sequential2290a28's hyper parameters: Current learning rate is 0.019157088122605363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:22 INFO  DistriOptimizer$:408 - [Epoch 1 14208/60000][Iteration 222][Wall Clock 41.180612558s] Trained 64 records in 0.151918031 seconds. Throughput is 421.27985 records/second. Loss is 0.9843356. Sequential2290a28's hyper parameters: Current learning rate is 0.01915341888527102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:22 INFO  DistriOptimizer$:408 - [Epoch 1 14272/60000][Iteration 223][Wall Clock 41.34056761s] Trained 64 records in 0.159955052 seconds. Throughput is 400.1124 records/second. Loss is 1.0261453. Sequential2290a28's hyper parameters: Current learning rate is 0.019149751053236307. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 224][Wall Clock 41.544218014s] Trained 64 records in 0.203650404 seconds. Throughput is 314.26404 records/second. Loss is 0.9274519. Sequential2290a28's hyper parameters: Current learning rate is 0.019146084625694046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14400/60000][Iteration 225][Wall Clock 41.700343081s] Trained 64 records in 0.156125067 seconds. Throughput is 409.92776 records/second. Loss is 0.83752835. Sequential2290a28's hyper parameters: Current learning rate is 0.019142419601837674. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14464/60000][Iteration 226][Wall Clock 41.899555118s] Trained 64 records in 0.199212037 seconds. Throughput is 321.26575 records/second. Loss is 1.1396375. Sequential2290a28's hyper parameters: Current learning rate is 0.019138755980861247. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14528/60000][Iteration 227][Wall Clock 42.036494819s] Trained 64 records in 0.136939701 seconds. Throughput is 467.35898 records/second. Loss is 1.0980195. Sequential2290a28's hyper parameters: Current learning rate is 0.019135093761959435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 228][Wall Clock 42.193066828s] Trained 64 records in 0.156572009 seconds. Throughput is 408.7576 records/second. Loss is 1.0259831. Sequential2290a28's hyper parameters: Current learning rate is 0.01913143294432753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14656/60000][Iteration 229][Wall Clock 42.349380254s] Trained 64 records in 0.156313426 seconds. Throughput is 409.4338 records/second. Loss is 1.137096. Sequential2290a28's hyper parameters: Current learning rate is 0.019127773527161437. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:23 INFO  DistriOptimizer$:408 - [Epoch 1 14720/60000][Iteration 230][Wall Clock 42.479361545s] Trained 64 records in 0.129981291 seconds. Throughput is 492.37854 records/second. Loss is 0.9754656. Sequential2290a28's hyper parameters: Current learning rate is 0.019124115509657678. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 14784/60000][Iteration 231][Wall Clock 42.638134181s] Trained 64 records in 0.158772636 seconds. Throughput is 403.09213 records/second. Loss is 1.0261438. Sequential2290a28's hyper parameters: Current learning rate is 0.019120458891013385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 232][Wall Clock 42.792514983s] Trained 64 records in 0.154380802 seconds. Throughput is 414.55933 records/second. Loss is 0.83447593. Sequential2290a28's hyper parameters: Current learning rate is 0.019116803670426306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 14912/60000][Iteration 233][Wall Clock 42.974159618s] Trained 64 records in 0.181644635 seconds. Throughput is 352.3363 records/second. Loss is 0.86119443. Sequential2290a28's hyper parameters: Current learning rate is 0.0191131498470948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 14976/60000][Iteration 234][Wall Clock 43.054656972s] Trained 64 records in 0.080497354 seconds. Throughput is 795.0572 records/second. Loss is 0.9720672. Sequential2290a28's hyper parameters: Current learning rate is 0.01910949742021785. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 15040/60000][Iteration 235][Wall Clock 43.229265433s] Trained 64 records in 0.174608461 seconds. Throughput is 366.53436 records/second. Loss is 0.939704. Sequential2290a28's hyper parameters: Current learning rate is 0.019105846388995033. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 236][Wall Clock 43.359432112s] Trained 64 records in 0.130166679 seconds. Throughput is 491.67728 records/second. Loss is 0.92144215. Sequential2290a28's hyper parameters: Current learning rate is 0.019102196752626553. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:24 INFO  DistriOptimizer$:408 - [Epoch 1 15168/60000][Iteration 237][Wall Clock 43.47351136s] Trained 64 records in 0.114079248 seconds. Throughput is 561.01355 records/second. Loss is 1.0001318. Sequential2290a28's hyper parameters: Current learning rate is 0.01909854851031322. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:25 INFO  DistriOptimizer$:408 - [Epoch 1 15232/60000][Iteration 238][Wall Clock 43.636540338s] Trained 64 records in 0.163028978 seconds. Throughput is 392.56824 records/second. Loss is 0.81527144. Sequential2290a28's hyper parameters: Current learning rate is 0.019094901661256443. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:25 INFO  DistriOptimizer$:408 - [Epoch 1 15296/60000][Iteration 239][Wall Clock 43.767421403s] Trained 64 records in 0.130881065 seconds. Throughput is 488.99356 records/second. Loss is 0.98559856. Sequential2290a28's hyper parameters: Current learning rate is 0.019091256204658267. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:25 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 240][Wall Clock 43.956346971s] Trained 64 records in 0.188925568 seconds. Throughput is 338.75775 records/second. Loss is 0.8952215. Sequential2290a28's hyper parameters: Current learning rate is 0.01908761213972132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:25 INFO  DistriOptimizer$:408 - [Epoch 1 15424/60000][Iteration 241][Wall Clock 44.177905791s] Trained 64 records in 0.22155882 seconds. Throughput is 288.86234 records/second. Loss is 0.8881808. Sequential2290a28's hyper parameters: Current learning rate is 0.019083969465648856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:25 INFO  DistriOptimizer$:408 - [Epoch 1 15488/60000][Iteration 242][Wall Clock 44.329585119s] Trained 64 records in 0.151679328 seconds. Throughput is 421.9428 records/second. Loss is 0.8491386. Sequential2290a28's hyper parameters: Current learning rate is 0.019080328181644724. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15552/60000][Iteration 243][Wall Clock 44.564664429s] Trained 64 records in 0.23507931 seconds. Throughput is 272.24857 records/second. Loss is 0.8792893. Sequential2290a28's hyper parameters: Current learning rate is 0.019076688286913394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 244][Wall Clock 44.687010226s] Trained 64 records in 0.122345797 seconds. Throughput is 523.1075 records/second. Loss is 0.83532315. Sequential2290a28's hyper parameters: Current learning rate is 0.019073049780659927. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15680/60000][Iteration 245][Wall Clock 44.786580094s] Trained 64 records in 0.099569868 seconds. Throughput is 642.7648 records/second. Loss is 0.8669967. Sequential2290a28's hyper parameters: Current learning rate is 0.01906941266209001. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15744/60000][Iteration 246][Wall Clock 44.938210835s] Trained 64 records in 0.151630741 seconds. Throughput is 422.078 records/second. Loss is 0.9302426. Sequential2290a28's hyper parameters: Current learning rate is 0.019065776930409915. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15808/60000][Iteration 247][Wall Clock 45.030473103s] Trained 64 records in 0.092262268 seconds. Throughput is 693.6747 records/second. Loss is 0.9517333. Sequential2290a28's hyper parameters: Current learning rate is 0.019062142584826535. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 248][Wall Clock 45.195136496s] Trained 64 records in 0.164663393 seconds. Throughput is 388.6717 records/second. Loss is 0.96531534. Sequential2290a28's hyper parameters: Current learning rate is 0.019058509624547363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:26 INFO  DistriOptimizer$:408 - [Epoch 1 15936/60000][Iteration 249][Wall Clock 45.326900609s] Trained 64 records in 0.131764113 seconds. Throughput is 485.71646 records/second. Loss is 1.0082394. Sequential2290a28's hyper parameters: Current learning rate is 0.019054878048780487. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16000/60000][Iteration 250][Wall Clock 45.491236788s] Trained 64 records in 0.164336179 seconds. Throughput is 389.4456 records/second. Loss is 0.95241416. Sequential2290a28's hyper parameters: Current learning rate is 0.019051247856734614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16064/60000][Iteration 251][Wall Clock 45.624238836s] Trained 64 records in 0.133002048 seconds. Throughput is 481.19562 records/second. Loss is 0.95613074. Sequential2290a28's hyper parameters: Current learning rate is 0.019047619047619046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 252][Wall Clock 45.791245132s] Trained 64 records in 0.167006296 seconds. Throughput is 383.2191 records/second. Loss is 1.0394157. Sequential2290a28's hyper parameters: Current learning rate is 0.019043991620643685. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16192/60000][Iteration 253][Wall Clock 45.899522609s] Trained 64 records in 0.108277477 seconds. Throughput is 591.074 records/second. Loss is 0.8676808. Sequential2290a28's hyper parameters: Current learning rate is 0.01904036557501904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16256/60000][Iteration 254][Wall Clock 46.042095554s] Trained 64 records in 0.142572945 seconds. Throughput is 448.89304 records/second. Loss is 0.8577379. Sequential2290a28's hyper parameters: Current learning rate is 0.019036740909956218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16320/60000][Iteration 255][Wall Clock 46.198835039s] Trained 64 records in 0.156739485 seconds. Throughput is 408.32083 records/second. Loss is 0.9607226. Sequential2290a28's hyper parameters: Current learning rate is 0.01903311762466692. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:27 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 256][Wall Clock 46.345575212s] Trained 64 records in 0.146740173 seconds. Throughput is 436.14505 records/second. Loss is 0.7597545. Sequential2290a28's hyper parameters: Current learning rate is 0.019029495718363466. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16448/60000][Iteration 257][Wall Clock 46.54593993s] Trained 64 records in 0.200364718 seconds. Throughput is 319.4175 records/second. Loss is 0.7637765. Sequential2290a28's hyper parameters: Current learning rate is 0.019025875190258754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16512/60000][Iteration 258][Wall Clock 46.686345135s] Trained 64 records in 0.140405205 seconds. Throughput is 455.82355 records/second. Loss is 0.7988197. Sequential2290a28's hyper parameters: Current learning rate is 0.019022256039566292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16576/60000][Iteration 259][Wall Clock 46.779176346s] Trained 64 records in 0.092831211 seconds. Throughput is 689.42334 records/second. Loss is 0.894318. Sequential2290a28's hyper parameters: Current learning rate is 0.01901863826550019. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 260][Wall Clock 46.861291527s] Trained 64 records in 0.082115181 seconds. Throughput is 779.393 records/second. Loss is 0.7912077. Sequential2290a28's hyper parameters: Current learning rate is 0.019015021867275148. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16704/60000][Iteration 261][Wall Clock 46.953446474s] Trained 64 records in 0.092154947 seconds. Throughput is 694.4825 records/second. Loss is 0.7246628. Sequential2290a28's hyper parameters: Current learning rate is 0.019011406844106463. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16768/60000][Iteration 262][Wall Clock 47.054217446s] Trained 64 records in 0.100770972 seconds. Throughput is 635.1035 records/second. Loss is 1.0259157. Sequential2290a28's hyper parameters: Current learning rate is 0.019007793195210038. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16832/60000][Iteration 263][Wall Clock 47.17729063s] Trained 64 records in 0.123073184 seconds. Throughput is 520.0158 records/second. Loss is 0.7938562. Sequential2290a28's hyper parameters: Current learning rate is 0.01900418091980236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 264][Wall Clock 47.278752705s] Trained 64 records in 0.101462075 seconds. Throughput is 630.7776 records/second. Loss is 0.9017032. Sequential2290a28's hyper parameters: Current learning rate is 0.019000570017100513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:28 INFO  DistriOptimizer$:408 - [Epoch 1 16960/60000][Iteration 265][Wall Clock 47.410566466s] Trained 64 records in 0.131813761 seconds. Throughput is 485.5335 records/second. Loss is 0.86062914. Sequential2290a28's hyper parameters: Current learning rate is 0.01899696048632219. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17024/60000][Iteration 266][Wall Clock 47.546551213s] Trained 64 records in 0.135984747 seconds. Throughput is 470.64102 records/second. Loss is 0.9058882. Sequential2290a28's hyper parameters: Current learning rate is 0.018993352326685663. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17088/60000][Iteration 267][Wall Clock 47.652218577s] Trained 64 records in 0.105667364 seconds. Throughput is 605.6742 records/second. Loss is 0.81715935. Sequential2290a28's hyper parameters: Current learning rate is 0.0189897455374098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 268][Wall Clock 47.74829566s] Trained 64 records in 0.096077083 seconds. Throughput is 666.1318 records/second. Loss is 0.96711266. Sequential2290a28's hyper parameters: Current learning rate is 0.01898614011771407. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17216/60000][Iteration 269][Wall Clock 47.858366958s] Trained 64 records in 0.110071298 seconds. Throughput is 581.4413 records/second. Loss is 0.94036657. Sequential2290a28's hyper parameters: Current learning rate is 0.018982536066818524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17280/60000][Iteration 270][Wall Clock 47.976666545s] Trained 64 records in 0.118299587 seconds. Throughput is 540.9993 records/second. Loss is 0.7981813. Sequential2290a28's hyper parameters: Current learning rate is 0.01897893338394382. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17344/60000][Iteration 271][Wall Clock 48.129467534s] Trained 64 records in 0.152800989 seconds. Throughput is 418.84546 records/second. Loss is 0.75071955. Sequential2290a28's hyper parameters: Current learning rate is 0.018975332068311195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 272][Wall Clock 48.258390198s] Trained 64 records in 0.128922664 seconds. Throughput is 496.4216 records/second. Loss is 0.8421498. Sequential2290a28's hyper parameters: Current learning rate is 0.01897173211914248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:29 INFO  DistriOptimizer$:408 - [Epoch 1 17472/60000][Iteration 273][Wall Clock 48.426955014s] Trained 64 records in 0.168564816 seconds. Throughput is 379.67593 records/second. Loss is 0.7839727. Sequential2290a28's hyper parameters: Current learning rate is 0.01896813353566009. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17536/60000][Iteration 274][Wall Clock 48.540182527s] Trained 64 records in 0.113227513 seconds. Throughput is 565.23364 records/second. Loss is 0.93279016. Sequential2290a28's hyper parameters: Current learning rate is 0.018964536317087048. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17600/60000][Iteration 275][Wall Clock 48.642271211s] Trained 64 records in 0.102088684 seconds. Throughput is 626.90594 records/second. Loss is 0.9022172. Sequential2290a28's hyper parameters: Current learning rate is 0.018960940462646948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 276][Wall Clock 48.769756928s] Trained 64 records in 0.127485717 seconds. Throughput is 502.017 records/second. Loss is 0.89227045. Sequential2290a28's hyper parameters: Current learning rate is 0.018957345971563982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17728/60000][Iteration 277][Wall Clock 48.870599968s] Trained 64 records in 0.10084304 seconds. Throughput is 634.64966 records/second. Loss is 0.8140618. Sequential2290a28's hyper parameters: Current learning rate is 0.01895375284306293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17792/60000][Iteration 278][Wall Clock 49.04287595s] Trained 64 records in 0.172275982 seconds. Throughput is 371.49695 records/second. Loss is 0.75025046. Sequential2290a28's hyper parameters: Current learning rate is 0.018950161076369147. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17856/60000][Iteration 279][Wall Clock 49.145124054s] Trained 64 records in 0.102248104 seconds. Throughput is 625.92847 records/second. Loss is 0.86134505. Sequential2290a28's hyper parameters: Current learning rate is 0.0189465706707086. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:30 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 280][Wall Clock 49.385954334s] Trained 64 records in 0.24083028 seconds. Throughput is 265.7473 records/second. Loss is 0.81455445. Sequential2290a28's hyper parameters: Current learning rate is 0.018942981625307824. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 17984/60000][Iteration 281][Wall Clock 49.530728581s] Trained 64 records in 0.144774247 seconds. Throughput is 442.0676 records/second. Loss is 0.8410732. Sequential2290a28's hyper parameters: Current learning rate is 0.01893939393939394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 18048/60000][Iteration 282][Wall Clock 49.644182051s] Trained 64 records in 0.11345347 seconds. Throughput is 564.1079 records/second. Loss is 0.8256288. Sequential2290a28's hyper parameters: Current learning rate is 0.01893580761219466. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 18112/60000][Iteration 283][Wall Clock 49.75174992s] Trained 64 records in 0.107567869 seconds. Throughput is 594.9732 records/second. Loss is 0.9167574. Sequential2290a28's hyper parameters: Current learning rate is 0.01893222264293828. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 284][Wall Clock 49.865791023s] Trained 64 records in 0.114041103 seconds. Throughput is 561.2012 records/second. Loss is 0.8095935. Sequential2290a28's hyper parameters: Current learning rate is 0.01892863903085368. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 18240/60000][Iteration 285][Wall Clock 50.039572112s] Trained 64 records in 0.173781089 seconds. Throughput is 368.27945 records/second. Loss is 0.81334996. Sequential2290a28's hyper parameters: Current learning rate is 0.018925056775170326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 18304/60000][Iteration 286][Wall Clock 50.256706635s] Trained 64 records in 0.217134523 seconds. Throughput is 294.74817 records/second. Loss is 0.7061244. Sequential2290a28's hyper parameters: Current learning rate is 0.01892147587511826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:31 INFO  DistriOptimizer$:408 - [Epoch 1 18368/60000][Iteration 287][Wall Clock 50.382464212s] Trained 64 records in 0.125757577 seconds. Throughput is 508.91568 records/second. Loss is 0.7532653. Sequential2290a28's hyper parameters: Current learning rate is 0.018917896329928113. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 288][Wall Clock 50.505737766s] Trained 64 records in 0.123273554 seconds. Throughput is 519.1706 records/second. Loss is 0.75115156. Sequential2290a28's hyper parameters: Current learning rate is 0.0189143181388311. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18496/60000][Iteration 289][Wall Clock 50.64295285s] Trained 64 records in 0.137215084 seconds. Throughput is 466.42105 records/second. Loss is 0.89938915. Sequential2290a28's hyper parameters: Current learning rate is 0.018910741301059. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18560/60000][Iteration 290][Wall Clock 50.755641425s] Trained 64 records in 0.112688575 seconds. Throughput is 567.9369 records/second. Loss is 0.73362356. Sequential2290a28's hyper parameters: Current learning rate is 0.018907165815844205. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18624/60000][Iteration 291][Wall Clock 50.846311172s] Trained 64 records in 0.090669747 seconds. Throughput is 705.8584 records/second. Loss is 0.7311014. Sequential2290a28's hyper parameters: Current learning rate is 0.01890359168241966. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 292][Wall Clock 50.92210402s] Trained 64 records in 0.075792848 seconds. Throughput is 844.40686 records/second. Loss is 0.6522436. Sequential2290a28's hyper parameters: Current learning rate is 0.0189000189000189. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18752/60000][Iteration 293][Wall Clock 51.034864285s] Trained 64 records in 0.112760265 seconds. Throughput is 567.5758 records/second. Loss is 0.7852977. Sequential2290a28's hyper parameters: Current learning rate is 0.01889644746787604. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18816/60000][Iteration 294][Wall Clock 51.113886411s] Trained 64 records in 0.079022126 seconds. Throughput is 809.8998 records/second. Loss is 0.8256508. Sequential2290a28's hyper parameters: Current learning rate is 0.01889287738522577. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18880/60000][Iteration 295][Wall Clock 51.251665023s] Trained 64 records in 0.137778612 seconds. Throughput is 464.51334 records/second. Loss is 0.82788694. Sequential2290a28's hyper parameters: Current learning rate is 0.018889308651303362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:32 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 296][Wall Clock 51.386027649s] Trained 64 records in 0.134362626 seconds. Throughput is 476.32294 records/second. Loss is 0.7638587. Sequential2290a28's hyper parameters: Current learning rate is 0.018885741265344667. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19008/60000][Iteration 297][Wall Clock 51.487577413s] Trained 64 records in 0.101549764 seconds. Throughput is 630.23285 records/second. Loss is 0.87082535. Sequential2290a28's hyper parameters: Current learning rate is 0.018882175226586105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19072/60000][Iteration 298][Wall Clock 51.621166809s] Trained 64 records in 0.133589396 seconds. Throughput is 479.07993 records/second. Loss is 0.7272199. Sequential2290a28's hyper parameters: Current learning rate is 0.01887861053426468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19136/60000][Iteration 299][Wall Clock 51.791901296s] Trained 64 records in 0.170734487 seconds. Throughput is 374.85104 records/second. Loss is 0.8761509. Sequential2290a28's hyper parameters: Current learning rate is 0.01887504718761797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 300][Wall Clock 51.924733598s] Trained 64 records in 0.132832302 seconds. Throughput is 481.81052 records/second. Loss is 0.62023044. Sequential2290a28's hyper parameters: Current learning rate is 0.018871485185884128. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19264/60000][Iteration 301][Wall Clock 52.047437846s] Trained 64 records in 0.122704248 seconds. Throughput is 521.57935 records/second. Loss is 0.7446901. Sequential2290a28's hyper parameters: Current learning rate is 0.018867924528301886. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19328/60000][Iteration 302][Wall Clock 52.146681644s] Trained 64 records in 0.099243798 seconds. Throughput is 644.8766 records/second. Loss is 0.8166386. Sequential2290a28's hyper parameters: Current learning rate is 0.018864365214110546. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19392/60000][Iteration 303][Wall Clock 52.300392611s] Trained 64 records in 0.153710967 seconds. Throughput is 416.36588 records/second. Loss is 0.66287583. Sequential2290a28's hyper parameters: Current learning rate is 0.01886080724254998. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:33 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 304][Wall Clock 52.411442136s] Trained 64 records in 0.111049525 seconds. Throughput is 576.31946 records/second. Loss is 0.86475146. Sequential2290a28's hyper parameters: Current learning rate is 0.018857250612860647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19520/60000][Iteration 305][Wall Clock 52.505142359s] Trained 64 records in 0.093700223 seconds. Throughput is 683.0293 records/second. Loss is 0.71943134. Sequential2290a28's hyper parameters: Current learning rate is 0.018853695324283562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19584/60000][Iteration 306][Wall Clock 52.614228198s] Trained 64 records in 0.109085839 seconds. Throughput is 586.694 records/second. Loss is 0.77782226. Sequential2290a28's hyper parameters: Current learning rate is 0.018850141376060323. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19648/60000][Iteration 307][Wall Clock 52.774550916s] Trained 64 records in 0.160322718 seconds. Throughput is 399.19485 records/second. Loss is 0.68518174. Sequential2290a28's hyper parameters: Current learning rate is 0.018846588767433097. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 308][Wall Clock 52.960603467s] Trained 64 records in 0.186052551 seconds. Throughput is 343.98883 records/second. Loss is 0.869146. Sequential2290a28's hyper parameters: Current learning rate is 0.018843037497644623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19776/60000][Iteration 309][Wall Clock 53.090057428s] Trained 64 records in 0.129453961 seconds. Throughput is 494.38428 records/second. Loss is 0.7454637. Sequential2290a28's hyper parameters: Current learning rate is 0.018839487565938205. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19840/60000][Iteration 310][Wall Clock 53.252688524s] Trained 64 records in 0.162631096 seconds. Throughput is 393.5287 records/second. Loss is 0.7945291. Sequential2290a28's hyper parameters: Current learning rate is 0.01883593897155773. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:34 INFO  DistriOptimizer$:408 - [Epoch 1 19904/60000][Iteration 311][Wall Clock 53.376574154s] Trained 64 records in 0.12388563 seconds. Throughput is 516.6055 records/second. Loss is 0.8595214. Sequential2290a28's hyper parameters: Current learning rate is 0.018832391713747645. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 312][Wall Clock 53.484148219s] Trained 64 records in 0.107574065 seconds. Throughput is 594.9389 records/second. Loss is 0.73246664. Sequential2290a28's hyper parameters: Current learning rate is 0.018828845791752966. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20032/60000][Iteration 313][Wall Clock 53.589877573s] Trained 64 records in 0.105729354 seconds. Throughput is 605.3191 records/second. Loss is 0.7538839. Sequential2290a28's hyper parameters: Current learning rate is 0.01882530120481928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20096/60000][Iteration 314][Wall Clock 53.7180089s] Trained 64 records in 0.128131327 seconds. Throughput is 499.48752 records/second. Loss is 0.73544574. Sequential2290a28's hyper parameters: Current learning rate is 0.018821757952192736. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20160/60000][Iteration 315][Wall Clock 53.841397377s] Trained 64 records in 0.123388477 seconds. Throughput is 518.687 records/second. Loss is 0.7290289. Sequential2290a28's hyper parameters: Current learning rate is 0.01881821603312006. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 316][Wall Clock 53.970576851s] Trained 64 records in 0.129179474 seconds. Throughput is 495.43472 records/second. Loss is 0.6911194. Sequential2290a28's hyper parameters: Current learning rate is 0.018814675446848544. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20288/60000][Iteration 317][Wall Clock 54.075809633s] Trained 64 records in 0.105232782 seconds. Throughput is 608.1755 records/second. Loss is 0.73605275. Sequential2290a28's hyper parameters: Current learning rate is 0.018811136192626036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20352/60000][Iteration 318][Wall Clock 54.179097332s] Trained 64 records in 0.103287699 seconds. Throughput is 619.6285 records/second. Loss is 0.7942478. Sequential2290a28's hyper parameters: Current learning rate is 0.01880759826970096. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:35 INFO  DistriOptimizer$:408 - [Epoch 1 20416/60000][Iteration 319][Wall Clock 54.341581149s] Trained 64 records in 0.162483817 seconds. Throughput is 393.8854 records/second. Loss is 0.87848747. Sequential2290a28's hyper parameters: Current learning rate is 0.0188040616773223. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 320][Wall Clock 54.463560884s] Trained 64 records in 0.121979735 seconds. Throughput is 524.6773 records/second. Loss is 0.7597942. Sequential2290a28's hyper parameters: Current learning rate is 0.018800526414739612. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20544/60000][Iteration 321][Wall Clock 54.576156954s] Trained 64 records in 0.11259607 seconds. Throughput is 568.4035 records/second. Loss is 0.7877662. Sequential2290a28's hyper parameters: Current learning rate is 0.018796992481203006. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20608/60000][Iteration 322][Wall Clock 54.695268169s] Trained 64 records in 0.119111215 seconds. Throughput is 537.3129 records/second. Loss is 0.6997049. Sequential2290a28's hyper parameters: Current learning rate is 0.018793459875963165. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20672/60000][Iteration 323][Wall Clock 54.792204612s] Trained 64 records in 0.096936443 seconds. Throughput is 660.22644 records/second. Loss is 0.7756769. Sequential2290a28's hyper parameters: Current learning rate is 0.018789928598271326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 324][Wall Clock 54.91597802s] Trained 64 records in 0.123773408 seconds. Throughput is 517.0739 records/second. Loss is 0.77975374. Sequential2290a28's hyper parameters: Current learning rate is 0.0187863986473793. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20800/60000][Iteration 325][Wall Clock 55.0406095s] Trained 64 records in 0.12463148 seconds. Throughput is 513.5139 records/second. Loss is 0.89550453. Sequential2290a28's hyper parameters: Current learning rate is 0.018782870022539446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20864/60000][Iteration 326][Wall Clock 55.125977753s] Trained 64 records in 0.085368253 seconds. Throughput is 749.69324 records/second. Loss is 0.68026894. Sequential2290a28's hyper parameters: Current learning rate is 0.018779342723004695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20928/60000][Iteration 327][Wall Clock 55.277232106s] Trained 64 records in 0.151254353 seconds. Throughput is 423.1283 records/second. Loss is 0.7388906. Sequential2290a28's hyper parameters: Current learning rate is 0.018775816748028543. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:36 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 328][Wall Clock 55.397923554s] Trained 64 records in 0.120691448 seconds. Throughput is 530.27783 records/second. Loss is 0.7957211. Sequential2290a28's hyper parameters: Current learning rate is 0.01877229209686503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:37 INFO  DistriOptimizer$:408 - [Epoch 1 21056/60000][Iteration 329][Wall Clock 55.534874354s] Trained 64 records in 0.1369508 seconds. Throughput is 467.3211 records/second. Loss is 0.6330367. Sequential2290a28's hyper parameters: Current learning rate is 0.01876876876876877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:37 INFO  DistriOptimizer$:408 - [Epoch 1 21120/60000][Iteration 330][Wall Clock 55.695246815s] Trained 64 records in 0.160372461 seconds. Throughput is 399.07098 records/second. Loss is 0.7772415. Sequential2290a28's hyper parameters: Current learning rate is 0.018765246762994934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:37 INFO  DistriOptimizer$:408 - [Epoch 1 21184/60000][Iteration 331][Wall Clock 55.8633387s] Trained 64 records in 0.168091885 seconds. Throughput is 380.74414 records/second. Loss is 0.62795246. Sequential2290a28's hyper parameters: Current learning rate is 0.018761726078799248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:37 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 332][Wall Clock 56.023434809s] Trained 64 records in 0.160096109 seconds. Throughput is 399.75986 records/second. Loss is 0.6607089. Sequential2290a28's hyper parameters: Current learning rate is 0.018758206715438003. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:37 INFO  DistriOptimizer$:408 - [Epoch 1 21312/60000][Iteration 333][Wall Clock 56.132046376s] Trained 64 records in 0.108611567 seconds. Throughput is 589.2558 records/second. Loss is 0.7263315. Sequential2290a28's hyper parameters: Current learning rate is 0.018754688672168042. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:37 INFO  DistriOptimizer$:408 - [Epoch 1 21376/60000][Iteration 334][Wall Clock 56.274609802s] Trained 64 records in 0.142563426 seconds. Throughput is 448.92297 records/second. Loss is 0.7182286. Sequential2290a28's hyper parameters: Current learning rate is 0.018751171948246766. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21440/60000][Iteration 335][Wall Clock 56.435879006s] Trained 64 records in 0.161269204 seconds. Throughput is 396.85196 records/second. Loss is 0.7432225. Sequential2290a28's hyper parameters: Current learning rate is 0.018747656542932135. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 336][Wall Clock 56.613345502s] Trained 64 records in 0.177466496 seconds. Throughput is 360.63144 records/second. Loss is 0.6622015. Sequential2290a28's hyper parameters: Current learning rate is 0.018744142455482664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21568/60000][Iteration 337][Wall Clock 56.753563281s] Trained 64 records in 0.140217779 seconds. Throughput is 456.43283 records/second. Loss is 0.7386217. Sequential2290a28's hyper parameters: Current learning rate is 0.018740629685157422. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21632/60000][Iteration 338][Wall Clock 56.909591261s] Trained 64 records in 0.15602798 seconds. Throughput is 410.18286 records/second. Loss is 0.5988406. Sequential2290a28's hyper parameters: Current learning rate is 0.01873711823121604. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21696/60000][Iteration 339][Wall Clock 57.044025127s] Trained 64 records in 0.134433866 seconds. Throughput is 476.07053 records/second. Loss is 0.61864084. Sequential2290a28's hyper parameters: Current learning rate is 0.018733608092918696. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 340][Wall Clock 57.139660577s] Trained 64 records in 0.09563545 seconds. Throughput is 669.2079 records/second. Loss is 0.63781357. Sequential2290a28's hyper parameters: Current learning rate is 0.018730099269526127. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21824/60000][Iteration 341][Wall Clock 57.266220767s] Trained 64 records in 0.12656019 seconds. Throughput is 505.6882 records/second. Loss is 0.78828657. Sequential2290a28's hyper parameters: Current learning rate is 0.018726591760299626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:38 INFO  DistriOptimizer$:408 - [Epoch 1 21888/60000][Iteration 342][Wall Clock 57.35921488s] Trained 64 records in 0.092994113 seconds. Throughput is 688.2156 records/second. Loss is 0.7938647. Sequential2290a28's hyper parameters: Current learning rate is 0.01872308556450103. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 21952/60000][Iteration 343][Wall Clock 57.509871539s] Trained 64 records in 0.150656659 seconds. Throughput is 424.80698 records/second. Loss is 0.7078389. Sequential2290a28's hyper parameters: Current learning rate is 0.018719580681392737. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 344][Wall Clock 57.61138597s] Trained 64 records in 0.101514431 seconds. Throughput is 630.4523 records/second. Loss is 0.7261621. Sequential2290a28's hyper parameters: Current learning rate is 0.018716077110237695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22080/60000][Iteration 345][Wall Clock 57.734274171s] Trained 64 records in 0.122888201 seconds. Throughput is 520.7986 records/second. Loss is 0.6403563. Sequential2290a28's hyper parameters: Current learning rate is 0.018712574850299403. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22144/60000][Iteration 346][Wall Clock 57.959075694s] Trained 64 records in 0.224801523 seconds. Throughput is 284.6956 records/second. Loss is 0.7801411. Sequential2290a28's hyper parameters: Current learning rate is 0.01870907390084191. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22208/60000][Iteration 347][Wall Clock 58.078089649s] Trained 64 records in 0.119013955 seconds. Throughput is 537.7521 records/second. Loss is 0.6507109. Sequential2290a28's hyper parameters: Current learning rate is 0.01870557426112982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 348][Wall Clock 58.171626071s] Trained 64 records in 0.093536422 seconds. Throughput is 684.22546 records/second. Loss is 0.5933273. Sequential2290a28's hyper parameters: Current learning rate is 0.018702075930428278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22336/60000][Iteration 349][Wall Clock 58.250864828s] Trained 64 records in 0.079238757 seconds. Throughput is 807.68555 records/second. Loss is 0.69590664. Sequential2290a28's hyper parameters: Current learning rate is 0.01869857890800299. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:39 INFO  DistriOptimizer$:408 - [Epoch 1 22400/60000][Iteration 350][Wall Clock 58.349528792s] Trained 64 records in 0.098663964 seconds. Throughput is 648.66644 records/second. Loss is 0.5874523. Sequential2290a28's hyper parameters: Current learning rate is 0.01869508319312021. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22464/60000][Iteration 351][Wall Clock 58.505708675s] Trained 64 records in 0.156179883 seconds. Throughput is 409.78387 records/second. Loss is 0.698586. Sequential2290a28's hyper parameters: Current learning rate is 0.018691588785046728. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 352][Wall Clock 58.59800752s] Trained 64 records in 0.092298845 seconds. Throughput is 693.3998 records/second. Loss is 0.8343025. Sequential2290a28's hyper parameters: Current learning rate is 0.018688095683049896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22592/60000][Iteration 353][Wall Clock 58.699987159s] Trained 64 records in 0.101979639 seconds. Throughput is 627.5763 records/second. Loss is 0.61441445. Sequential2290a28's hyper parameters: Current learning rate is 0.01868460388639761. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22656/60000][Iteration 354][Wall Clock 58.867919622s] Trained 64 records in 0.167932463 seconds. Throughput is 381.1056 records/second. Loss is 0.72182226. Sequential2290a28's hyper parameters: Current learning rate is 0.018681113394358306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22720/60000][Iteration 355][Wall Clock 59.011693237s] Trained 64 records in 0.143773615 seconds. Throughput is 445.14426 records/second. Loss is 0.71863586. Sequential2290a28's hyper parameters: Current learning rate is 0.018677624206200973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 356][Wall Clock 59.137026145s] Trained 64 records in 0.125332908 seconds. Throughput is 510.64005 records/second. Loss is 0.6608549. Sequential2290a28's hyper parameters: Current learning rate is 0.018674136321195144. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22848/60000][Iteration 357][Wall Clock 59.276387276s] Trained 64 records in 0.139361131 seconds. Throughput is 459.23853 records/second. Loss is 0.8544132. Sequential2290a28's hyper parameters: Current learning rate is 0.018670649738610906. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:40 INFO  DistriOptimizer$:408 - [Epoch 1 22912/60000][Iteration 358][Wall Clock 59.386475236s] Trained 64 records in 0.11008796 seconds. Throughput is 581.35333 records/second. Loss is 0.75084746. Sequential2290a28's hyper parameters: Current learning rate is 0.018667164457718873. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 22976/60000][Iteration 359][Wall Clock 59.495270926s] Trained 64 records in 0.10879569 seconds. Throughput is 588.2586 records/second. Loss is 0.70952654. Sequential2290a28's hyper parameters: Current learning rate is 0.01866368047779022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 360][Wall Clock 59.599502371s] Trained 64 records in 0.104231445 seconds. Throughput is 614.0181 records/second. Loss is 0.62639725. Sequential2290a28's hyper parameters: Current learning rate is 0.018660197798096658. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 23104/60000][Iteration 361][Wall Clock 59.73481345s] Trained 64 records in 0.135311079 seconds. Throughput is 472.98416 records/second. Loss is 0.6302583. Sequential2290a28's hyper parameters: Current learning rate is 0.018656716417910446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 23168/60000][Iteration 362][Wall Clock 59.908317464s] Trained 64 records in 0.173504014 seconds. Throughput is 368.86755 records/second. Loss is 0.6077081. Sequential2290a28's hyper parameters: Current learning rate is 0.018653236336504384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 23232/60000][Iteration 363][Wall Clock 60.107310834s] Trained 64 records in 0.19899337 seconds. Throughput is 321.61874 records/second. Loss is 0.69728845. Sequential2290a28's hyper parameters: Current learning rate is 0.01864975755315181. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 364][Wall Clock 60.25617338s] Trained 64 records in 0.148862546 seconds. Throughput is 429.92682 records/second. Loss is 0.7332196. Sequential2290a28's hyper parameters: Current learning rate is 0.018646280067126608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:41 INFO  DistriOptimizer$:408 - [Epoch 1 23360/60000][Iteration 365][Wall Clock 60.39240793s] Trained 64 records in 0.13623455 seconds. Throughput is 469.77805 records/second. Loss is 0.49761036. Sequential2290a28's hyper parameters: Current learning rate is 0.018642803877703208. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23424/60000][Iteration 366][Wall Clock 60.515862818s] Trained 64 records in 0.123454888 seconds. Throughput is 518.40796 records/second. Loss is 0.6285987. Sequential2290a28's hyper parameters: Current learning rate is 0.018639328984156572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23488/60000][Iteration 367][Wall Clock 60.654044623s] Trained 64 records in 0.138181805 seconds. Throughput is 463.15793 records/second. Loss is 0.59084046. Sequential2290a28's hyper parameters: Current learning rate is 0.018635855385762207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 368][Wall Clock 60.861453517s] Trained 64 records in 0.207408894 seconds. Throughput is 308.5692 records/second. Loss is 0.66881865. Sequential2290a28's hyper parameters: Current learning rate is 0.018632383081796162. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23616/60000][Iteration 369][Wall Clock 60.961227325s] Trained 64 records in 0.099773808 seconds. Throughput is 641.4509 records/second. Loss is 0.59457856. Sequential2290a28's hyper parameters: Current learning rate is 0.018628912071535025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23680/60000][Iteration 370][Wall Clock 61.103281535s] Trained 64 records in 0.14205421 seconds. Throughput is 450.53223 records/second. Loss is 0.6325184. Sequential2290a28's hyper parameters: Current learning rate is 0.018625442354255912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23744/60000][Iteration 371][Wall Clock 61.204612517s] Trained 64 records in 0.101330982 seconds. Throughput is 631.5936 records/second. Loss is 0.5101892. Sequential2290a28's hyper parameters: Current learning rate is 0.018621973929236497. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:42 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 372][Wall Clock 61.312100792s] Trained 64 records in 0.107488275 seconds. Throughput is 595.41376 records/second. Loss is 0.55178523. Sequential2290a28's hyper parameters: Current learning rate is 0.01861850679575498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 23872/60000][Iteration 373][Wall Clock 61.413781014s] Trained 64 records in 0.101680222 seconds. Throughput is 629.4243 records/second. Loss is 0.48754492. Sequential2290a28's hyper parameters: Current learning rate is 0.018615040953090096. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 23936/60000][Iteration 374][Wall Clock 61.555693425s] Trained 64 records in 0.141912411 seconds. Throughput is 450.9824 records/second. Loss is 0.70614415. Sequential2290a28's hyper parameters: Current learning rate is 0.018611576400521124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24000/60000][Iteration 375][Wall Clock 61.656622951s] Trained 64 records in 0.100929526 seconds. Throughput is 634.10583 records/second. Loss is 0.65648454. Sequential2290a28's hyper parameters: Current learning rate is 0.018608113137327877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 376][Wall Clock 61.771620021s] Trained 64 records in 0.11499707 seconds. Throughput is 556.53595 records/second. Loss is 0.798032. Sequential2290a28's hyper parameters: Current learning rate is 0.018604651162790697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24128/60000][Iteration 377][Wall Clock 61.873377837s] Trained 64 records in 0.101757816 seconds. Throughput is 628.94434 records/second. Loss is 0.6619679. Sequential2290a28's hyper parameters: Current learning rate is 0.018601190476190476. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24192/60000][Iteration 378][Wall Clock 61.99745816s] Trained 64 records in 0.124080323 seconds. Throughput is 515.7949 records/second. Loss is 0.64681345. Sequential2290a28's hyper parameters: Current learning rate is 0.01859773107680863. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24256/60000][Iteration 379][Wall Clock 62.11801142s] Trained 64 records in 0.12055326 seconds. Throughput is 530.8857 records/second. Loss is 0.6644904. Sequential2290a28's hyper parameters: Current learning rate is 0.01859427296392711. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 380][Wall Clock 62.224517743s] Trained 64 records in 0.106506323 seconds. Throughput is 600.90326 records/second. Loss is 0.6484545. Sequential2290a28's hyper parameters: Current learning rate is 0.018590816136828406. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 24384/60000][Iteration 381][Wall Clock 62.323825483s] Trained 64 records in 0.09930774 seconds. Throughput is 644.46136 records/second. Loss is 0.60360324. Sequential2290a28's hyper parameters: Current learning rate is 0.01858736059479554. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24448/60000][Iteration 382][Wall Clock 62.427370479s] Trained 64 records in 0.103544996 seconds. Throughput is 618.0888 records/second. Loss is 0.6936013. Sequential2290a28's hyper parameters: Current learning rate is 0.01858390633711206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24512/60000][Iteration 383][Wall Clock 62.544169925s] Trained 64 records in 0.116799446 seconds. Throughput is 547.9478 records/second. Loss is 0.5190661. Sequential2290a28's hyper parameters: Current learning rate is 0.01858045336306206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 384][Wall Clock 62.660433993s] Trained 64 records in 0.116264068 seconds. Throughput is 550.471 records/second. Loss is 0.6285599. Sequential2290a28's hyper parameters: Current learning rate is 0.01857700167193015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24640/60000][Iteration 385][Wall Clock 62.774221767s] Trained 64 records in 0.113787774 seconds. Throughput is 562.45056 records/second. Loss is 0.6139793. Sequential2290a28's hyper parameters: Current learning rate is 0.018573551263001486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24704/60000][Iteration 386][Wall Clock 62.903336593s] Trained 64 records in 0.129114826 seconds. Throughput is 495.68283 records/second. Loss is 0.77122384. Sequential2290a28's hyper parameters: Current learning rate is 0.018570102135561747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24768/60000][Iteration 387][Wall Clock 63.059489823s] Trained 64 records in 0.15615323 seconds. Throughput is 409.85382 records/second. Loss is 0.51456326. Sequential2290a28's hyper parameters: Current learning rate is 0.01856665428889714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 388][Wall Clock 63.228239492s] Trained 64 records in 0.168749669 seconds. Throughput is 379.25998 records/second. Loss is 0.6905284. Sequential2290a28's hyper parameters: Current learning rate is 0.018563207722294413. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 24896/60000][Iteration 389][Wall Clock 63.34738653s] Trained 64 records in 0.119147038 seconds. Throughput is 537.1514 records/second. Loss is 0.7007179. Sequential2290a28's hyper parameters: Current learning rate is 0.018559762435040834. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 24960/60000][Iteration 390][Wall Clock 63.47764675s] Trained 64 records in 0.13026022 seconds. Throughput is 491.32425 records/second. Loss is 0.55981886. Sequential2290a28's hyper parameters: Current learning rate is 0.018556318426424197. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 25024/60000][Iteration 391][Wall Clock 63.577665376s] Trained 64 records in 0.100018626 seconds. Throughput is 639.8808 records/second. Loss is 0.69364357. Sequential2290a28's hyper parameters: Current learning rate is 0.01855287569573284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 392][Wall Clock 63.687329228s] Trained 64 records in 0.109663852 seconds. Throughput is 583.6016 records/second. Loss is 0.78140444. Sequential2290a28's hyper parameters: Current learning rate is 0.01854943424225561. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 25152/60000][Iteration 393][Wall Clock 63.845271963s] Trained 64 records in 0.157942735 seconds. Throughput is 405.21014 records/second. Loss is 0.7441921. Sequential2290a28's hyper parameters: Current learning rate is 0.018545994065281898. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 25216/60000][Iteration 394][Wall Clock 64.020636043s] Trained 64 records in 0.17536408 seconds. Throughput is 364.95502 records/second. Loss is 0.77523434. Sequential2290a28's hyper parameters: Current learning rate is 0.018542555164101613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 25280/60000][Iteration 395][Wall Clock 64.190426402s] Trained 64 records in 0.169790359 seconds. Throughput is 376.93542 records/second. Loss is 0.47987857. Sequential2290a28's hyper parameters: Current learning rate is 0.018539117538005193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 396][Wall Clock 64.318052356s] Trained 64 records in 0.127625954 seconds. Throughput is 501.4654 records/second. Loss is 0.5568136. Sequential2290a28's hyper parameters: Current learning rate is 0.018535681186283598. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 25408/60000][Iteration 397][Wall Clock 64.45971289s] Trained 64 records in 0.141660534 seconds. Throughput is 451.78424 records/second. Loss is 0.6792266. Sequential2290a28's hyper parameters: Current learning rate is 0.018532246108228317. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 25472/60000][Iteration 398][Wall Clock 64.64710396s] Trained 64 records in 0.18739107 seconds. Throughput is 341.53174 records/second. Loss is 0.69713116. Sequential2290a28's hyper parameters: Current learning rate is 0.018528812303131373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 25536/60000][Iteration 399][Wall Clock 64.878007336s] Trained 64 records in 0.230903376 seconds. Throughput is 277.1722 records/second. Loss is 0.687784. Sequential2290a28's hyper parameters: Current learning rate is 0.01852537977028529. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 400][Wall Clock 65.000007968s] Trained 64 records in 0.122000632 seconds. Throughput is 524.58746 records/second. Loss is 0.47138292. Sequential2290a28's hyper parameters: Current learning rate is 0.018521948508983144. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 25664/60000][Iteration 401][Wall Clock 65.146517642s] Trained 64 records in 0.146509674 seconds. Throughput is 436.8312 records/second. Loss is 0.59486043. Sequential2290a28's hyper parameters: Current learning rate is 0.018518518518518517. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 25728/60000][Iteration 402][Wall Clock 65.256354489s] Trained 64 records in 0.109836847 seconds. Throughput is 582.68243 records/second. Loss is 0.4792375. Sequential2290a28's hyper parameters: Current learning rate is 0.01851508979818552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 25792/60000][Iteration 403][Wall Clock 65.380332086s] Trained 64 records in 0.123977597 seconds. Throughput is 516.2223 records/second. Loss is 0.57505167. Sequential2290a28's hyper parameters: Current learning rate is 0.018511662347278787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 404][Wall Clock 65.525307646s] Trained 64 records in 0.14497556 seconds. Throughput is 441.45374 records/second. Loss is 0.53051263. Sequential2290a28's hyper parameters: Current learning rate is 0.018508236165093468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 25920/60000][Iteration 405][Wall Clock 65.66153749s] Trained 64 records in 0.136229844 seconds. Throughput is 469.79428 records/second. Loss is 0.51157707. Sequential2290a28's hyper parameters: Current learning rate is 0.018504811250925242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 25984/60000][Iteration 406][Wall Clock 65.770850895s] Trained 64 records in 0.109313405 seconds. Throughput is 585.47253 records/second. Loss is 0.61508965. Sequential2290a28's hyper parameters: Current learning rate is 0.018501387604070305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 26048/60000][Iteration 407][Wall Clock 65.863744037s] Trained 64 records in 0.092893142 seconds. Throughput is 688.9637 records/second. Loss is 0.663325. Sequential2290a28's hyper parameters: Current learning rate is 0.01849796522382538. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 408][Wall Clock 65.985860437s] Trained 64 records in 0.1221164 seconds. Throughput is 524.09015 records/second. Loss is 0.5705263. Sequential2290a28's hyper parameters: Current learning rate is 0.018494544109487702. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 26176/60000][Iteration 409][Wall Clock 66.135717843s] Trained 64 records in 0.149857406 seconds. Throughput is 427.07266 records/second. Loss is 0.62072796. Sequential2290a28's hyper parameters: Current learning rate is 0.01849112426035503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 26240/60000][Iteration 410][Wall Clock 66.267909918s] Trained 64 records in 0.132192075 seconds. Throughput is 484.144 records/second. Loss is 0.4911428. Sequential2290a28's hyper parameters: Current learning rate is 0.018487705675725642. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26304/60000][Iteration 411][Wall Clock 66.39351984s] Trained 64 records in 0.125609922 seconds. Throughput is 509.5139 records/second. Loss is 0.61834055. Sequential2290a28's hyper parameters: Current learning rate is 0.018484288354898334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 412][Wall Clock 66.527689672s] Trained 64 records in 0.134169832 seconds. Throughput is 477.0074 records/second. Loss is 0.5030945. Sequential2290a28's hyper parameters: Current learning rate is 0.018480872297172424. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26432/60000][Iteration 413][Wall Clock 66.619644036s] Trained 64 records in 0.091954364 seconds. Throughput is 695.99744 records/second. Loss is 0.6631926. Sequential2290a28's hyper parameters: Current learning rate is 0.018477457501847747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26496/60000][Iteration 414][Wall Clock 66.732934353s] Trained 64 records in 0.113290317 seconds. Throughput is 564.9203 records/second. Loss is 0.52840257. Sequential2290a28's hyper parameters: Current learning rate is 0.018474043968224645. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26560/60000][Iteration 415][Wall Clock 66.877366503s] Trained 64 records in 0.14443215 seconds. Throughput is 443.11462 records/second. Loss is 0.44994465. Sequential2290a28's hyper parameters: Current learning rate is 0.01847063169560399. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 416][Wall Clock 67.015474358s] Trained 64 records in 0.138107855 seconds. Throughput is 463.40594 records/second. Loss is 0.6206281. Sequential2290a28's hyper parameters: Current learning rate is 0.018467220683287166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26688/60000][Iteration 417][Wall Clock 67.144113594s] Trained 64 records in 0.128639236 seconds. Throughput is 497.51538 records/second. Loss is 0.6703626. Sequential2290a28's hyper parameters: Current learning rate is 0.01846381093057607. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 26752/60000][Iteration 418][Wall Clock 67.3253967s] Trained 64 records in 0.181283106 seconds. Throughput is 353.03897 records/second. Loss is 0.61845326. Sequential2290a28's hyper parameters: Current learning rate is 0.018460402436773122. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 26816/60000][Iteration 419][Wall Clock 67.461253445s] Trained 64 records in 0.135856745 seconds. Throughput is 471.08444 records/second. Loss is 0.48822707. Sequential2290a28's hyper parameters: Current learning rate is 0.018456995201181246. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 420][Wall Clock 67.560775333s] Trained 64 records in 0.099521888 seconds. Throughput is 643.0746 records/second. Loss is 0.6820164. Sequential2290a28's hyper parameters: Current learning rate is 0.018453589223103892. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 26944/60000][Iteration 421][Wall Clock 67.695828414s] Trained 64 records in 0.135053081 seconds. Throughput is 473.88773 records/second. Loss is 0.54397786. Sequential2290a28's hyper parameters: Current learning rate is 0.01845018450184502. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 27008/60000][Iteration 422][Wall Clock 67.831976416s] Trained 64 records in 0.136148002 seconds. Throughput is 470.07666 records/second. Loss is 0.6539512. Sequential2290a28's hyper parameters: Current learning rate is 0.018446781036709093. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 27072/60000][Iteration 423][Wall Clock 67.947698876s] Trained 64 records in 0.11572246 seconds. Throughput is 553.04736 records/second. Loss is 0.54938185. Sequential2290a28's hyper parameters: Current learning rate is 0.018443378827001106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 424][Wall Clock 68.062783201s] Trained 64 records in 0.115084325 seconds. Throughput is 556.11395 records/second. Loss is 0.5621165. Sequential2290a28's hyper parameters: Current learning rate is 0.018439977872026555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 27200/60000][Iteration 425][Wall Clock 68.205495782s] Trained 64 records in 0.142712581 seconds. Throughput is 448.45383 records/second. Loss is 0.5889206. Sequential2290a28's hyper parameters: Current learning rate is 0.018436578171091445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27264/60000][Iteration 426][Wall Clock 68.365576006s] Trained 64 records in 0.160080224 seconds. Throughput is 399.79953 records/second. Loss is 0.5384338. Sequential2290a28's hyper parameters: Current learning rate is 0.018433179723502304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27328/60000][Iteration 427][Wall Clock 68.498723359s] Trained 64 records in 0.133147353 seconds. Throughput is 480.67044 records/second. Loss is 0.59010607. Sequential2290a28's hyper parameters: Current learning rate is 0.018429782528566165. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 428][Wall Clock 68.663178401s] Trained 64 records in 0.164455042 seconds. Throughput is 389.16412 records/second. Loss is 0.5730771. Sequential2290a28's hyper parameters: Current learning rate is 0.01842638658559057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27456/60000][Iteration 429][Wall Clock 68.841912598s] Trained 64 records in 0.178734197 seconds. Throughput is 358.0736 records/second. Loss is 0.5778836. Sequential2290a28's hyper parameters: Current learning rate is 0.018422991893883568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27520/60000][Iteration 430][Wall Clock 68.98702598s] Trained 64 records in 0.145113382 seconds. Throughput is 441.03445 records/second. Loss is 0.5757352. Sequential2290a28's hyper parameters: Current learning rate is 0.01841959845275373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27584/60000][Iteration 431][Wall Clock 69.080196597s] Trained 64 records in 0.093170617 seconds. Throughput is 686.9118 records/second. Loss is 0.7047367. Sequential2290a28's hyper parameters: Current learning rate is 0.018416206261510127. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 432][Wall Clock 69.191856081s] Trained 64 records in 0.111659484 seconds. Throughput is 573.1712 records/second. Loss is 0.5105766. Sequential2290a28's hyper parameters: Current learning rate is 0.018412815319462345. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 27712/60000][Iteration 433][Wall Clock 69.334082058s] Trained 64 records in 0.142225977 seconds. Throughput is 449.9881 records/second. Loss is 0.6128837. Sequential2290a28's hyper parameters: Current learning rate is 0.018409425625920472. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 27776/60000][Iteration 434][Wall Clock 69.477284058s] Trained 64 records in 0.143202 seconds. Throughput is 446.9211 records/second. Loss is 0.45314378. Sequential2290a28's hyper parameters: Current learning rate is 0.018406037180195105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 27840/60000][Iteration 435][Wall Clock 69.6035592s] Trained 64 records in 0.126275142 seconds. Throughput is 506.82977 records/second. Loss is 0.6002009. Sequential2290a28's hyper parameters: Current learning rate is 0.018402649981597352. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 436][Wall Clock 69.725697916s] Trained 64 records in 0.122138716 seconds. Throughput is 523.9944 records/second. Loss is 0.57167417. Sequential2290a28's hyper parameters: Current learning rate is 0.018399264029438825. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 27968/60000][Iteration 437][Wall Clock 69.812210676s] Trained 64 records in 0.08651276 seconds. Throughput is 739.77527 records/second. Loss is 0.47960764. Sequential2290a28's hyper parameters: Current learning rate is 0.018395879323031643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 28032/60000][Iteration 438][Wall Clock 69.934175785s] Trained 64 records in 0.121965109 seconds. Throughput is 524.74023 records/second. Loss is 0.45323348. Sequential2290a28's hyper parameters: Current learning rate is 0.018392495861688434. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 28096/60000][Iteration 439][Wall Clock 70.03387068s] Trained 64 records in 0.099694895 seconds. Throughput is 641.9587 records/second. Loss is 0.57014734. Sequential2290a28's hyper parameters: Current learning rate is 0.018389113644722326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 440][Wall Clock 70.133897591s] Trained 64 records in 0.100026911 seconds. Throughput is 639.8278 records/second. Loss is 0.532314. Sequential2290a28's hyper parameters: Current learning rate is 0.018385732671446955. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 28224/60000][Iteration 441][Wall Clock 70.23002994s] Trained 64 records in 0.096132349 seconds. Throughput is 665.74884 records/second. Loss is 0.7128733. Sequential2290a28's hyper parameters: Current learning rate is 0.01838235294117647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28288/60000][Iteration 442][Wall Clock 70.340593823s] Trained 64 records in 0.110563883 seconds. Throughput is 578.8509 records/second. Loss is 0.46961796. Sequential2290a28's hyper parameters: Current learning rate is 0.01837897445322551. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28352/60000][Iteration 443][Wall Clock 70.435522534s] Trained 64 records in 0.094928711 seconds. Throughput is 674.1901 records/second. Loss is 0.54608727. Sequential2290a28's hyper parameters: Current learning rate is 0.018375597206909223. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 444][Wall Clock 70.616649875s] Trained 64 records in 0.181127341 seconds. Throughput is 353.34256 records/second. Loss is 0.499674. Sequential2290a28's hyper parameters: Current learning rate is 0.018372221201543266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28480/60000][Iteration 445][Wall Clock 70.72979136s] Trained 64 records in 0.113141485 seconds. Throughput is 565.66345 records/second. Loss is 0.49973476. Sequential2290a28's hyper parameters: Current learning rate is 0.018368846436443792. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28544/60000][Iteration 446][Wall Clock 70.842820154s] Trained 64 records in 0.113028794 seconds. Throughput is 566.2274 records/second. Loss is 0.6331306. Sequential2290a28's hyper parameters: Current learning rate is 0.018365472910927456. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28608/60000][Iteration 447][Wall Clock 70.939629721s] Trained 64 records in 0.096809567 seconds. Throughput is 661.0917 records/second. Loss is 0.5441924. Sequential2290a28's hyper parameters: Current learning rate is 0.01836210062431142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 448][Wall Clock 71.047519074s] Trained 64 records in 0.107889353 seconds. Throughput is 593.2003 records/second. Loss is 0.43911505. Sequential2290a28's hyper parameters: Current learning rate is 0.01835872957591335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28736/60000][Iteration 449][Wall Clock 71.14267038s] Trained 64 records in 0.095151306 seconds. Throughput is 672.613 records/second. Loss is 0.6820226. Sequential2290a28's hyper parameters: Current learning rate is 0.018355359765051395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 28800/60000][Iteration 450][Wall Clock 71.228828938s] Trained 64 records in 0.086158558 seconds. Throughput is 742.8165 records/second. Loss is 0.57956755. Sequential2290a28's hyper parameters: Current learning rate is 0.018351991191044227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 28864/60000][Iteration 451][Wall Clock 71.349128999s] Trained 64 records in 0.120300061 seconds. Throughput is 532.00305 records/second. Loss is 0.54207224. Sequential2290a28's hyper parameters: Current learning rate is 0.018348623853211007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 452][Wall Clock 71.473127214s] Trained 64 records in 0.123998215 seconds. Throughput is 516.1365 records/second. Loss is 0.4972483. Sequential2290a28's hyper parameters: Current learning rate is 0.0183452577508714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 28992/60000][Iteration 453][Wall Clock 71.648341236s] Trained 64 records in 0.175214022 seconds. Throughput is 365.26758 records/second. Loss is 0.53251994. Sequential2290a28's hyper parameters: Current learning rate is 0.018341892883345562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 29056/60000][Iteration 454][Wall Clock 71.804703164s] Trained 64 records in 0.156361928 seconds. Throughput is 409.30682 records/second. Loss is 0.46352774. Sequential2290a28's hyper parameters: Current learning rate is 0.018338529249954154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 29120/60000][Iteration 455][Wall Clock 71.951501589s] Trained 64 records in 0.146798425 seconds. Throughput is 435.97195 records/second. Loss is 0.4898251. Sequential2290a28's hyper parameters: Current learning rate is 0.018335166850018337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 456][Wall Clock 72.068343527s] Trained 64 records in 0.116841938 seconds. Throughput is 547.74854 records/second. Loss is 0.62992376. Sequential2290a28's hyper parameters: Current learning rate is 0.01833180568285976. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 29248/60000][Iteration 457][Wall Clock 72.167103915s] Trained 64 records in 0.098760388 seconds. Throughput is 648.0331 records/second. Loss is 0.620989. Sequential2290a28's hyper parameters: Current learning rate is 0.018328445747800588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29312/60000][Iteration 458][Wall Clock 72.34271879s] Trained 64 records in 0.175614875 seconds. Throughput is 364.4338 records/second. Loss is 0.43066528. Sequential2290a28's hyper parameters: Current learning rate is 0.01832508704416346. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29376/60000][Iteration 459][Wall Clock 72.448043842s] Trained 64 records in 0.105325052 seconds. Throughput is 607.6427 records/second. Loss is 0.5247206. Sequential2290a28's hyper parameters: Current learning rate is 0.01832172957127153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 460][Wall Clock 72.573671843s] Trained 64 records in 0.125628001 seconds. Throughput is 509.44058 records/second. Loss is 0.39400402. Sequential2290a28's hyper parameters: Current learning rate is 0.018318373328448434. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29504/60000][Iteration 461][Wall Clock 72.675228866s] Trained 64 records in 0.101557023 seconds. Throughput is 630.1878 records/second. Loss is 0.43136406. Sequential2290a28's hyper parameters: Current learning rate is 0.018315018315018312. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29568/60000][Iteration 462][Wall Clock 72.784502746s] Trained 64 records in 0.10927388 seconds. Throughput is 585.6843 records/second. Loss is 0.5588943. Sequential2290a28's hyper parameters: Current learning rate is 0.018311664530305805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29632/60000][Iteration 463][Wall Clock 72.879989453s] Trained 64 records in 0.095486707 seconds. Throughput is 670.25037 records/second. Loss is 0.7101681. Sequential2290a28's hyper parameters: Current learning rate is 0.01830831197363603. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 464][Wall Clock 72.987429335s] Trained 64 records in 0.107439882 seconds. Throughput is 595.68195 records/second. Loss is 0.4753441. Sequential2290a28's hyper parameters: Current learning rate is 0.018304960644334616. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29760/60000][Iteration 465][Wall Clock 73.097111636s] Trained 64 records in 0.109682301 seconds. Throughput is 583.5035 records/second. Loss is 0.52485263. Sequential2290a28's hyper parameters: Current learning rate is 0.018301610541727673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29824/60000][Iteration 466][Wall Clock 73.182694763s] Trained 64 records in 0.085583127 seconds. Throughput is 747.811 records/second. Loss is 0.58989614. Sequential2290a28's hyper parameters: Current learning rate is 0.018298261665141813. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 29888/60000][Iteration 467][Wall Clock 73.270574604s] Trained 64 records in 0.087879841 seconds. Throughput is 728.2671 records/second. Loss is 0.5073654. Sequential2290a28's hyper parameters: Current learning rate is 0.018294914013904137. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 468][Wall Clock 73.360829608s] Trained 64 records in 0.090255004 seconds. Throughput is 709.1019 records/second. Loss is 0.45920694. Sequential2290a28's hyper parameters: Current learning rate is 0.018291567587342236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30016/60000][Iteration 469][Wall Clock 73.490354116s] Trained 64 records in 0.129524508 seconds. Throughput is 494.11496 records/second. Loss is 0.5521727. Sequential2290a28's hyper parameters: Current learning rate is 0.0182882223847842. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30080/60000][Iteration 470][Wall Clock 73.601193757s] Trained 64 records in 0.110839641 seconds. Throughput is 577.41077 records/second. Loss is 0.627463. Sequential2290a28's hyper parameters: Current learning rate is 0.0182848784055586. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30144/60000][Iteration 471][Wall Clock 73.747875331s] Trained 64 records in 0.146681574 seconds. Throughput is 436.31927 records/second. Loss is 0.38836566. Sequential2290a28's hyper parameters: Current learning rate is 0.018281535648994516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 472][Wall Clock 73.865575782s] Trained 64 records in 0.117700451 seconds. Throughput is 543.75323 records/second. Loss is 0.47277457. Sequential2290a28's hyper parameters: Current learning rate is 0.018278194114421494. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30272/60000][Iteration 473][Wall Clock 73.955922329s] Trained 64 records in 0.090346547 seconds. Throughput is 708.3835 records/second. Loss is 0.5751063. Sequential2290a28's hyper parameters: Current learning rate is 0.01827485380116959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30336/60000][Iteration 474][Wall Clock 74.047882701s] Trained 64 records in 0.091960372 seconds. Throughput is 695.95197 records/second. Loss is 0.45995653. Sequential2290a28's hyper parameters: Current learning rate is 0.01827151470856934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 30400/60000][Iteration 475][Wall Clock 74.208530377s] Trained 64 records in 0.160647676 seconds. Throughput is 398.38733 records/second. Loss is 0.5841711. Sequential2290a28's hyper parameters: Current learning rate is 0.018268176835951774. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 476][Wall Clock 74.376031096s] Trained 64 records in 0.167500719 seconds. Throughput is 382.08792 records/second. Loss is 0.69613206. Sequential2290a28's hyper parameters: Current learning rate is 0.018264840182648404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30528/60000][Iteration 477][Wall Clock 74.543658163s] Trained 64 records in 0.167627067 seconds. Throughput is 381.79993 records/second. Loss is 0.3802546. Sequential2290a28's hyper parameters: Current learning rate is 0.018261504747991236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30592/60000][Iteration 478][Wall Clock 74.643010827s] Trained 64 records in 0.099352664 seconds. Throughput is 644.1699 records/second. Loss is 0.44975102. Sequential2290a28's hyper parameters: Current learning rate is 0.018258170531312765. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30656/60000][Iteration 479][Wall Clock 74.742274686s] Trained 64 records in 0.099263859 seconds. Throughput is 644.7462 records/second. Loss is 0.4971654. Sequential2290a28's hyper parameters: Current learning rate is 0.018254837531945966. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 480][Wall Clock 74.844206237s] Trained 64 records in 0.101931551 seconds. Throughput is 627.8723 records/second. Loss is 0.5321944. Sequential2290a28's hyper parameters: Current learning rate is 0.01825150574922431. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30784/60000][Iteration 481][Wall Clock 74.924869517s] Trained 64 records in 0.08066328 seconds. Throughput is 793.42175 records/second. Loss is 0.7166. Sequential2290a28's hyper parameters: Current learning rate is 0.01824817518248175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30848/60000][Iteration 482][Wall Clock 75.021618381s] Trained 64 records in 0.096748864 seconds. Throughput is 661.5065 records/second. Loss is 0.5109085. Sequential2290a28's hyper parameters: Current learning rate is 0.018244845831052726. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30912/60000][Iteration 483][Wall Clock 75.123629845s] Trained 64 records in 0.102011464 seconds. Throughput is 627.3805 records/second. Loss is 0.42365614. Sequential2290a28's hyper parameters: Current learning rate is 0.018241517694272163. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 484][Wall Clock 75.255602646s] Trained 64 records in 0.131972801 seconds. Throughput is 484.9484 records/second. Loss is 0.58189595. Sequential2290a28's hyper parameters: Current learning rate is 0.018238190771475468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31040/60000][Iteration 485][Wall Clock 75.37657655s] Trained 64 records in 0.120973904 seconds. Throughput is 529.0397 records/second. Loss is 0.43949288. Sequential2290a28's hyper parameters: Current learning rate is 0.01823486506199854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31104/60000][Iteration 486][Wall Clock 75.510809795s] Trained 64 records in 0.134233245 seconds. Throughput is 476.782 records/second. Loss is 0.5370859. Sequential2290a28's hyper parameters: Current learning rate is 0.01823154056517776. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31168/60000][Iteration 487][Wall Clock 75.610841668s] Trained 64 records in 0.100031873 seconds. Throughput is 639.7961 records/second. Loss is 0.42681113. Sequential2290a28's hyper parameters: Current learning rate is 0.018228217280349984. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 488][Wall Clock 75.727508308s] Trained 64 records in 0.11666664 seconds. Throughput is 548.5716 records/second. Loss is 0.47621197. Sequential2290a28's hyper parameters: Current learning rate is 0.01822489520685256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31296/60000][Iteration 489][Wall Clock 75.821889661s] Trained 64 records in 0.094381353 seconds. Throughput is 678.10004 records/second. Loss is 0.53739274. Sequential2290a28's hyper parameters: Current learning rate is 0.018221574344023325. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31360/60000][Iteration 490][Wall Clock 75.909812198s] Trained 64 records in 0.087922537 seconds. Throughput is 727.9135 records/second. Loss is 0.61123055. Sequential2290a28's hyper parameters: Current learning rate is 0.018218254691200586. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31424/60000][Iteration 491][Wall Clock 75.998036887s] Trained 64 records in 0.088224689 seconds. Throughput is 725.42053 records/second. Loss is 0.5886749. Sequential2290a28's hyper parameters: Current learning rate is 0.01821493624772313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 492][Wall Clock 76.156909998s] Trained 64 records in 0.158873111 seconds. Throughput is 402.83722 records/second. Loss is 0.38554224. Sequential2290a28's hyper parameters: Current learning rate is 0.01821161901293025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31552/60000][Iteration 493][Wall Clock 76.309758478s] Trained 64 records in 0.15284848 seconds. Throughput is 418.7153 records/second. Loss is 0.5901636. Sequential2290a28's hyper parameters: Current learning rate is 0.01820830298616169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31616/60000][Iteration 494][Wall Clock 76.429692455s] Trained 64 records in 0.119933977 seconds. Throughput is 533.62695 records/second. Loss is 0.43898243. Sequential2290a28's hyper parameters: Current learning rate is 0.018204988166757693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31680/60000][Iteration 495][Wall Clock 76.573239954s] Trained 64 records in 0.143547499 seconds. Throughput is 445.84543 records/second. Loss is 0.61319566. Sequential2290a28's hyper parameters: Current learning rate is 0.018201674554058973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 496][Wall Clock 76.704321121s] Trained 64 records in 0.131081167 seconds. Throughput is 488.2471 records/second. Loss is 0.6518344. Sequential2290a28's hyper parameters: Current learning rate is 0.018198362147406735. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31808/60000][Iteration 497][Wall Clock 76.880958044s] Trained 64 records in 0.176636923 seconds. Throughput is 362.32516 records/second. Loss is 0.66212726. Sequential2290a28's hyper parameters: Current learning rate is 0.01819505094614265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31872/60000][Iteration 498][Wall Clock 77.072559627s] Trained 64 records in 0.191601583 seconds. Throughput is 334.02646 records/second. Loss is 0.41239014. Sequential2290a28's hyper parameters: Current learning rate is 0.01819174094960888. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 31936/60000][Iteration 499][Wall Clock 77.259250695s] Trained 64 records in 0.186691068 seconds. Throughput is 342.81235 records/second. Loss is 0.4472985. Sequential2290a28's hyper parameters: Current learning rate is 0.018188432157148056. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 500][Wall Clock 77.380139683s] Trained 64 records in 0.120888988 seconds. Throughput is 529.4113 records/second. Loss is 0.38865814. Sequential2290a28's hyper parameters: Current learning rate is 0.01818512456810329. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32064/60000][Iteration 501][Wall Clock 77.483019425s] Trained 64 records in 0.102879742 seconds. Throughput is 622.0856 records/second. Loss is 0.35866833. Sequential2290a28's hyper parameters: Current learning rate is 0.01818181818181818. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32128/60000][Iteration 502][Wall Clock 77.598588285s] Trained 64 records in 0.11556886 seconds. Throughput is 553.7824 records/second. Loss is 0.4205273. Sequential2290a28's hyper parameters: Current learning rate is 0.018178512997636793. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32192/60000][Iteration 503][Wall Clock 77.77988113s] Trained 64 records in 0.181292845 seconds. Throughput is 353.02 records/second. Loss is 0.49857306. Sequential2290a28's hyper parameters: Current learning rate is 0.01817520901490367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 504][Wall Clock 77.956507265s] Trained 64 records in 0.176626135 seconds. Throughput is 362.3473 records/second. Loss is 0.6531744. Sequential2290a28's hyper parameters: Current learning rate is 0.018171906232963837. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32320/60000][Iteration 505][Wall Clock 78.092418799s] Trained 64 records in 0.135911534 seconds. Throughput is 470.89453 records/second. Loss is 0.565167. Sequential2290a28's hyper parameters: Current learning rate is 0.018168604651162792. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 32384/60000][Iteration 506][Wall Clock 78.220352475s] Trained 64 records in 0.127933676 seconds. Throughput is 500.2592 records/second. Loss is 0.45687178. Sequential2290a28's hyper parameters: Current learning rate is 0.018165304268846504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32448/60000][Iteration 507][Wall Clock 78.320735838s] Trained 64 records in 0.100383363 seconds. Throughput is 637.55585 records/second. Loss is 0.5590347. Sequential2290a28's hyper parameters: Current learning rate is 0.018162005085361425. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 508][Wall Clock 78.471627296s] Trained 64 records in 0.150891458 seconds. Throughput is 424.14597 records/second. Loss is 0.6438308. Sequential2290a28's hyper parameters: Current learning rate is 0.018158707100054478. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32576/60000][Iteration 509][Wall Clock 78.568644187s] Trained 64 records in 0.097016891 seconds. Throughput is 659.67896 records/second. Loss is 0.6357301. Sequential2290a28's hyper parameters: Current learning rate is 0.01815541031227306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32640/60000][Iteration 510][Wall Clock 78.661664362s] Trained 64 records in 0.093020175 seconds. Throughput is 688.02277 records/second. Loss is 0.39901966. Sequential2290a28's hyper parameters: Current learning rate is 0.01815211472136504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32704/60000][Iteration 511][Wall Clock 78.777200996s] Trained 64 records in 0.115536634 seconds. Throughput is 553.9368 records/second. Loss is 0.5865968. Sequential2290a28's hyper parameters: Current learning rate is 0.018148820326678763. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 512][Wall Clock 78.883351916s] Trained 64 records in 0.10615092 seconds. Throughput is 602.91516 records/second. Loss is 0.5087175. Sequential2290a28's hyper parameters: Current learning rate is 0.018145527127563055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32832/60000][Iteration 513][Wall Clock 78.991329792s] Trained 64 records in 0.107977876 seconds. Throughput is 592.714 records/second. Loss is 0.6542399. Sequential2290a28's hyper parameters: Current learning rate is 0.018142235123367198. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32896/60000][Iteration 514][Wall Clock 79.16120952s] Trained 64 records in 0.169879728 seconds. Throughput is 376.73712 records/second. Loss is 0.45098647. Sequential2290a28's hyper parameters: Current learning rate is 0.018138944313440958. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 32960/60000][Iteration 515][Wall Clock 79.262542048s] Trained 64 records in 0.101332528 seconds. Throughput is 631.5839 records/second. Loss is 0.6323069. Sequential2290a28's hyper parameters: Current learning rate is 0.018135654697134566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 516][Wall Clock 79.353480734s] Trained 64 records in 0.090938686 seconds. Throughput is 703.7709 records/second. Loss is 0.57298714. Sequential2290a28's hyper parameters: Current learning rate is 0.01813236627379873. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33088/60000][Iteration 517][Wall Clock 79.453730488s] Trained 64 records in 0.100249754 seconds. Throughput is 638.4056 records/second. Loss is 0.43277904. Sequential2290a28's hyper parameters: Current learning rate is 0.018129079042784626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33152/60000][Iteration 518][Wall Clock 79.54567469s] Trained 64 records in 0.091944202 seconds. Throughput is 696.07434 records/second. Loss is 0.6457633. Sequential2290a28's hyper parameters: Current learning rate is 0.018125793003443903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33216/60000][Iteration 519][Wall Clock 79.645796868s] Trained 64 records in 0.100122178 seconds. Throughput is 639.21906 records/second. Loss is 0.5297664. Sequential2290a28's hyper parameters: Current learning rate is 0.018122508155128673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 520][Wall Clock 79.725969946s] Trained 64 records in 0.080173078 seconds. Throughput is 798.273 records/second. Loss is 0.39450094. Sequential2290a28's hyper parameters: Current learning rate is 0.01811922449719152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33344/60000][Iteration 521][Wall Clock 79.834450814s] Trained 64 records in 0.108480868 seconds. Throughput is 589.96576 records/second. Loss is 0.5136839. Sequential2290a28's hyper parameters: Current learning rate is 0.018115942028985504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33408/60000][Iteration 522][Wall Clock 79.932421689s] Trained 64 records in 0.097970875 seconds. Throughput is 653.2554 records/second. Loss is 0.4872106. Sequential2290a28's hyper parameters: Current learning rate is 0.018112660749864153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33472/60000][Iteration 523][Wall Clock 80.047624469s] Trained 64 records in 0.11520278 seconds. Throughput is 555.5422 records/second. Loss is 0.47601962. Sequential2290a28's hyper parameters: Current learning rate is 0.018109380659181457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 524][Wall Clock 80.158908681s] Trained 64 records in 0.111284212 seconds. Throughput is 575.10406 records/second. Loss is 0.5467051. Sequential2290a28's hyper parameters: Current learning rate is 0.01810610175629187. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 33600/60000][Iteration 525][Wall Clock 80.270489837s] Trained 64 records in 0.111581156 seconds. Throughput is 573.57355 records/second. Loss is 0.60794836. Sequential2290a28's hyper parameters: Current learning rate is 0.018102824040550327. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33664/60000][Iteration 526][Wall Clock 80.376392226s] Trained 64 records in 0.105902389 seconds. Throughput is 604.3301 records/second. Loss is 0.47629797. Sequential2290a28's hyper parameters: Current learning rate is 0.01809954751131222. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33728/60000][Iteration 527][Wall Clock 80.452826717s] Trained 64 records in 0.076434491 seconds. Throughput is 837.3183 records/second. Loss is 0.36057407. Sequential2290a28's hyper parameters: Current learning rate is 0.018096272167933407. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 528][Wall Clock 80.529594213s] Trained 64 records in 0.076767496 seconds. Throughput is 833.68616 records/second. Loss is 0.5011664. Sequential2290a28's hyper parameters: Current learning rate is 0.018092998009770222. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33856/60000][Iteration 529][Wall Clock 80.671243158s] Trained 64 records in 0.141648945 seconds. Throughput is 451.82123 records/second. Loss is 0.40765905. Sequential2290a28's hyper parameters: Current learning rate is 0.018089725036179453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33920/60000][Iteration 530][Wall Clock 80.777261913s] Trained 64 records in 0.106018755 seconds. Throughput is 603.6668 records/second. Loss is 0.4880699. Sequential2290a28's hyper parameters: Current learning rate is 0.01808645324651836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33984/60000][Iteration 531][Wall Clock 80.869135949s] Trained 64 records in 0.091874036 seconds. Throughput is 696.60596 records/second. Loss is 0.4755596. Sequential2290a28's hyper parameters: Current learning rate is 0.018083182640144663. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 532][Wall Clock 81.003661338s] Trained 64 records in 0.134525389 seconds. Throughput is 475.74664 records/second. Loss is 0.46823636. Sequential2290a28's hyper parameters: Current learning rate is 0.01807991321641656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 34112/60000][Iteration 533][Wall Clock 81.101928229s] Trained 64 records in 0.098266891 seconds. Throughput is 651.28754 records/second. Loss is 0.67277575. Sequential2290a28's hyper parameters: Current learning rate is 0.018076644974692697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 34176/60000][Iteration 534][Wall Clock 81.249059677s] Trained 64 records in 0.147131448 seconds. Throughput is 434.9852 records/second. Loss is 0.7733732. Sequential2290a28's hyper parameters: Current learning rate is 0.018073377914332188. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34240/60000][Iteration 535][Wall Clock 81.353078121s] Trained 64 records in 0.104018444 seconds. Throughput is 615.2755 records/second. Loss is 0.61430246. Sequential2290a28's hyper parameters: Current learning rate is 0.018070112034694615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 536][Wall Clock 81.447429561s] Trained 64 records in 0.09435144 seconds. Throughput is 678.315 records/second. Loss is 0.49693808. Sequential2290a28's hyper parameters: Current learning rate is 0.01806684733514002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34368/60000][Iteration 537][Wall Clock 81.539551189s] Trained 64 records in 0.092121628 seconds. Throughput is 694.7337 records/second. Loss is 0.43945324. Sequential2290a28's hyper parameters: Current learning rate is 0.018063583815028903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34432/60000][Iteration 538][Wall Clock 81.622078434s] Trained 64 records in 0.082527245 seconds. Throughput is 775.50146 records/second. Loss is 0.38237163. Sequential2290a28's hyper parameters: Current learning rate is 0.018060321473722232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34496/60000][Iteration 539][Wall Clock 81.722865459s] Trained 64 records in 0.100787025 seconds. Throughput is 635.0023 records/second. Loss is 0.37192467. Sequential2290a28's hyper parameters: Current learning rate is 0.01805706031058144. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 540][Wall Clock 81.863050377s] Trained 64 records in 0.140184918 seconds. Throughput is 456.53983 records/second. Loss is 0.44100094. Sequential2290a28's hyper parameters: Current learning rate is 0.018053800324968405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34624/60000][Iteration 541][Wall Clock 81.957528631s] Trained 64 records in 0.094478254 seconds. Throughput is 677.40454 records/second. Loss is 0.6188035. Sequential2290a28's hyper parameters: Current learning rate is 0.018050541516245487. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34688/60000][Iteration 542][Wall Clock 82.125619448s] Trained 64 records in 0.168090817 seconds. Throughput is 380.74655 records/second. Loss is 0.46624923. Sequential2290a28's hyper parameters: Current learning rate is 0.01804728388377549. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34752/60000][Iteration 543][Wall Clock 82.209846366s] Trained 64 records in 0.084226918 seconds. Throughput is 759.85205 records/second. Loss is 0.58228457. Sequential2290a28's hyper parameters: Current learning rate is 0.01804402742692169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 544][Wall Clock 82.329442158s] Trained 64 records in 0.119595792 seconds. Throughput is 535.1359 records/second. Loss is 0.31024653. Sequential2290a28's hyper parameters: Current learning rate is 0.018040772145047807. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 34880/60000][Iteration 545][Wall Clock 82.421141256s] Trained 64 records in 0.091699098 seconds. Throughput is 697.9349 records/second. Loss is 0.44308448. Sequential2290a28's hyper parameters: Current learning rate is 0.018037518037518036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 34944/60000][Iteration 546][Wall Clock 82.501617937s] Trained 64 records in 0.080476681 seconds. Throughput is 795.2615 records/second. Loss is 0.56475234. Sequential2290a28's hyper parameters: Current learning rate is 0.018034265103697024. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35008/60000][Iteration 547][Wall Clock 82.590704649s] Trained 64 records in 0.089086712 seconds. Throughput is 718.4012 records/second. Loss is 0.50806427. Sequential2290a28's hyper parameters: Current learning rate is 0.018031013342949875. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 548][Wall Clock 82.684549148s] Trained 64 records in 0.093844499 seconds. Throughput is 681.97925 records/second. Loss is 0.65135705. Sequential2290a28's hyper parameters: Current learning rate is 0.01802776275464215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35136/60000][Iteration 549][Wall Clock 82.770189468s] Trained 64 records in 0.08564032 seconds. Throughput is 747.3116 records/second. Loss is 0.46253654. Sequential2290a28's hyper parameters: Current learning rate is 0.018024513338139873. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35200/60000][Iteration 550][Wall Clock 82.854089464s] Trained 64 records in 0.083899996 seconds. Throughput is 762.8129 records/second. Loss is 0.47100145. Sequential2290a28's hyper parameters: Current learning rate is 0.01802126509280952. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35264/60000][Iteration 551][Wall Clock 82.949851341s] Trained 64 records in 0.095761877 seconds. Throughput is 668.3244 records/second. Loss is 0.47009403. Sequential2290a28's hyper parameters: Current learning rate is 0.018018018018018018. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 552][Wall Clock 83.054165814s] Trained 64 records in 0.104314473 seconds. Throughput is 613.5294 records/second. Loss is 0.4803581. Sequential2290a28's hyper parameters: Current learning rate is 0.01801477211313277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 35392/60000][Iteration 553][Wall Clock 83.177502476s] Trained 64 records in 0.123336662 seconds. Throughput is 518.9049 records/second. Loss is 0.55384445. Sequential2290a28's hyper parameters: Current learning rate is 0.018011527377521614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35456/60000][Iteration 554][Wall Clock 83.268524464s] Trained 64 records in 0.091021988 seconds. Throughput is 703.12683 records/second. Loss is 0.4141934. Sequential2290a28's hyper parameters: Current learning rate is 0.018008283810552854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35520/60000][Iteration 555][Wall Clock 83.379193956s] Trained 64 records in 0.110669492 seconds. Throughput is 578.29846 records/second. Loss is 0.5975696. Sequential2290a28's hyper parameters: Current learning rate is 0.018005041411595247. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 556][Wall Clock 83.466434664s] Trained 64 records in 0.087240708 seconds. Throughput is 733.6025 records/second. Loss is 0.58846927. Sequential2290a28's hyper parameters: Current learning rate is 0.018001800180018002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35648/60000][Iteration 557][Wall Clock 83.558784343s] Trained 64 records in 0.092349679 seconds. Throughput is 693.0181 records/second. Loss is 0.48684978. Sequential2290a28's hyper parameters: Current learning rate is 0.017998560115190784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35712/60000][Iteration 558][Wall Clock 83.657623064s] Trained 64 records in 0.098838721 seconds. Throughput is 647.5195 records/second. Loss is 0.43442476. Sequential2290a28's hyper parameters: Current learning rate is 0.017995321216483715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35776/60000][Iteration 559][Wall Clock 83.751853617s] Trained 64 records in 0.094230553 seconds. Throughput is 679.18524 records/second. Loss is 0.5440204. Sequential2290a28's hyper parameters: Current learning rate is 0.017992083483267363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 560][Wall Clock 83.844241649s] Trained 64 records in 0.092388032 seconds. Throughput is 692.7304 records/second. Loss is 0.5822962. Sequential2290a28's hyper parameters: Current learning rate is 0.017988846914912753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35904/60000][Iteration 561][Wall Clock 83.935140658s] Trained 64 records in 0.090899009 seconds. Throughput is 704.0781 records/second. Loss is 0.51453125. Sequential2290a28's hyper parameters: Current learning rate is 0.017985611510791366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 35968/60000][Iteration 562][Wall Clock 84.030000401s] Trained 64 records in 0.094859743 seconds. Throughput is 674.6803 records/second. Loss is 0.38699007. Sequential2290a28's hyper parameters: Current learning rate is 0.01798237727027513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 36032/60000][Iteration 563][Wall Clock 84.105204039s] Trained 64 records in 0.075203638 seconds. Throughput is 851.0227 records/second. Loss is 0.42932302. Sequential2290a28's hyper parameters: Current learning rate is 0.017979144192736426. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 564][Wall Clock 84.191243874s] Trained 64 records in 0.086039835 seconds. Throughput is 743.8415 records/second. Loss is 0.40445775. Sequential2290a28's hyper parameters: Current learning rate is 0.017975912277548085. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36160/60000][Iteration 565][Wall Clock 84.284148065s] Trained 64 records in 0.092904191 seconds. Throughput is 688.8818 records/second. Loss is 0.60646677. Sequential2290a28's hyper parameters: Current learning rate is 0.017972681524083392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36224/60000][Iteration 566][Wall Clock 84.378222667s] Trained 64 records in 0.094074602 seconds. Throughput is 680.31116 records/second. Loss is 0.543656. Sequential2290a28's hyper parameters: Current learning rate is 0.017969451931716084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36288/60000][Iteration 567][Wall Clock 84.460929662s] Trained 64 records in 0.082706995 seconds. Throughput is 773.81604 records/second. Loss is 0.48778105. Sequential2290a28's hyper parameters: Current learning rate is 0.017966223499820338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 568][Wall Clock 84.552950847s] Trained 64 records in 0.092021185 seconds. Throughput is 695.49207 records/second. Loss is 0.36625028. Sequential2290a28's hyper parameters: Current learning rate is 0.017962996227770794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36416/60000][Iteration 569][Wall Clock 84.640708147s] Trained 64 records in 0.0877573 seconds. Throughput is 729.28406 records/second. Loss is 0.37507862. Sequential2290a28's hyper parameters: Current learning rate is 0.01795977011494253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36480/60000][Iteration 570][Wall Clock 84.76750467s] Trained 64 records in 0.126796523 seconds. Throughput is 504.74567 records/second. Loss is 0.3983807. Sequential2290a28's hyper parameters: Current learning rate is 0.01795654516071108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36544/60000][Iteration 571][Wall Clock 84.863939949s] Trained 64 records in 0.096435279 seconds. Throughput is 663.65753 records/second. Loss is 0.47475114. Sequential2290a28's hyper parameters: Current learning rate is 0.01795332136445242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 572][Wall Clock 84.958248414s] Trained 64 records in 0.094308465 seconds. Throughput is 678.62415 records/second. Loss is 0.4597668. Sequential2290a28's hyper parameters: Current learning rate is 0.017950098725542988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36672/60000][Iteration 573][Wall Clock 85.067686011s] Trained 64 records in 0.109437597 seconds. Throughput is 584.80817 records/second. Loss is 0.47213644. Sequential2290a28's hyper parameters: Current learning rate is 0.017946877243359655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 36736/60000][Iteration 574][Wall Clock 85.165408224s] Trained 64 records in 0.097722213 seconds. Throughput is 654.91766 records/second. Loss is 0.44256976. Sequential2290a28's hyper parameters: Current learning rate is 0.01794365691727974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 36800/60000][Iteration 575][Wall Clock 85.287689948s] Trained 64 records in 0.122281724 seconds. Throughput is 523.3816 records/second. Loss is 0.52688026. Sequential2290a28's hyper parameters: Current learning rate is 0.01794043774668102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 576][Wall Clock 85.380365737s] Trained 64 records in 0.092675789 seconds. Throughput is 690.57947 records/second. Loss is 0.53817886. Sequential2290a28's hyper parameters: Current learning rate is 0.017937219730941704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 36928/60000][Iteration 577][Wall Clock 85.564366739s] Trained 64 records in 0.184001002 seconds. Throughput is 347.8242 records/second. Loss is 0.5166973. Sequential2290a28's hyper parameters: Current learning rate is 0.01793400286944046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 36992/60000][Iteration 578][Wall Clock 85.678298526s] Trained 64 records in 0.113931787 seconds. Throughput is 561.7396 records/second. Loss is 0.47927636. Sequential2290a28's hyper parameters: Current learning rate is 0.017930787161556393. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 37056/60000][Iteration 579][Wall Clock 85.796131689s] Trained 64 records in 0.117833163 seconds. Throughput is 543.1408 records/second. Loss is 0.3994066. Sequential2290a28's hyper parameters: Current learning rate is 0.017927572606669058. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 580][Wall Clock 85.904344705s] Trained 64 records in 0.108213016 seconds. Throughput is 591.4261 records/second. Loss is 0.37924808. Sequential2290a28's hyper parameters: Current learning rate is 0.017924359204158455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 37184/60000][Iteration 581][Wall Clock 86.035074607s] Trained 64 records in 0.130729902 seconds. Throughput is 489.55902 records/second. Loss is 0.40707684. Sequential2290a28's hyper parameters: Current learning rate is 0.017921146953405017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 37248/60000][Iteration 582][Wall Clock 86.138375343s] Trained 64 records in 0.103300736 seconds. Throughput is 619.5503 records/second. Loss is 0.5058161. Sequential2290a28's hyper parameters: Current learning rate is 0.017917935853789643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37312/60000][Iteration 583][Wall Clock 86.268901652s] Trained 64 records in 0.130526309 seconds. Throughput is 490.32263 records/second. Loss is 0.42024222. Sequential2290a28's hyper parameters: Current learning rate is 0.017914725904693656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 584][Wall Clock 86.418279728s] Trained 64 records in 0.149378076 seconds. Throughput is 428.44305 records/second. Loss is 0.7854233. Sequential2290a28's hyper parameters: Current learning rate is 0.017911517105498837. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37440/60000][Iteration 585][Wall Clock 86.532236029s] Trained 64 records in 0.113956301 seconds. Throughput is 561.6188 records/second. Loss is 0.555202. Sequential2290a28's hyper parameters: Current learning rate is 0.01790830945558739. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37504/60000][Iteration 586][Wall Clock 86.628751948s] Trained 64 records in 0.096515919 seconds. Throughput is 663.1031 records/second. Loss is 0.47286236. Sequential2290a28's hyper parameters: Current learning rate is 0.017905102954341987. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37568/60000][Iteration 587][Wall Clock 86.747652809s] Trained 64 records in 0.118900861 seconds. Throughput is 538.26355 records/second. Loss is 0.3726214. Sequential2290a28's hyper parameters: Current learning rate is 0.017901897601145723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 588][Wall Clock 86.846859683s] Trained 64 records in 0.099206874 seconds. Throughput is 645.1166 records/second. Loss is 0.43806154. Sequential2290a28's hyper parameters: Current learning rate is 0.017898693395382137. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37696/60000][Iteration 589][Wall Clock 86.961756915s] Trained 64 records in 0.114897232 seconds. Throughput is 557.01953 records/second. Loss is 0.52719355. Sequential2290a28's hyper parameters: Current learning rate is 0.01789549033643522. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37760/60000][Iteration 590][Wall Clock 87.05712789s] Trained 64 records in 0.095370975 seconds. Throughput is 671.06366 records/second. Loss is 0.5397228. Sequential2290a28's hyper parameters: Current learning rate is 0.017892288423689392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 37824/60000][Iteration 591][Wall Clock 87.153877783s] Trained 64 records in 0.096749893 seconds. Throughput is 661.49945 records/second. Loss is 0.52634907. Sequential2290a28's hyper parameters: Current learning rate is 0.017889087656529516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 592][Wall Clock 87.28878506s] Trained 64 records in 0.134907277 seconds. Throughput is 474.3999 records/second. Loss is 0.49897093. Sequential2290a28's hyper parameters: Current learning rate is 0.017885888034340904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 37952/60000][Iteration 593][Wall Clock 87.411452155s] Trained 64 records in 0.122667095 seconds. Throughput is 521.7373 records/second. Loss is 0.40283078. Sequential2290a28's hyper parameters: Current learning rate is 0.017882689556509297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 38016/60000][Iteration 594][Wall Clock 87.529499372s] Trained 64 records in 0.118047217 seconds. Throughput is 542.15594 records/second. Loss is 0.41792277. Sequential2290a28's hyper parameters: Current learning rate is 0.017879492222420884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 38080/60000][Iteration 595][Wall Clock 87.664284819s] Trained 64 records in 0.134785447 seconds. Throughput is 474.82874 records/second. Loss is 0.44145063. Sequential2290a28's hyper parameters: Current learning rate is 0.01787629603146228. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 596][Wall Clock 87.776877471s] Trained 64 records in 0.112592652 seconds. Throughput is 568.4208 records/second. Loss is 0.4271671. Sequential2290a28's hyper parameters: Current learning rate is 0.017873100983020553. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 38208/60000][Iteration 597][Wall Clock 87.868697005s] Trained 64 records in 0.091819534 seconds. Throughput is 697.0195 records/second. Loss is 0.3835702. Sequential2290a28's hyper parameters: Current learning rate is 0.017869907076483203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 38272/60000][Iteration 598][Wall Clock 88.013507969s] Trained 64 records in 0.144810964 seconds. Throughput is 441.9555 records/second. Loss is 0.36941248. Sequential2290a28's hyper parameters: Current learning rate is 0.017866714311238166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 38336/60000][Iteration 599][Wall Clock 88.130168027s] Trained 64 records in 0.116660058 seconds. Throughput is 548.6025 records/second. Loss is 0.40995622. Sequential2290a28's hyper parameters: Current learning rate is 0.017863522686673815. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 600][Wall Clock 88.247536451s] Trained 64 records in 0.117368424 seconds. Throughput is 545.29144 records/second. Loss is 0.47404784. Sequential2290a28's hyper parameters: Current learning rate is 0.01786033220217896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38464/60000][Iteration 601][Wall Clock 88.342421948s] Trained 64 records in 0.094885497 seconds. Throughput is 674.4972 records/second. Loss is 0.5231709. Sequential2290a28's hyper parameters: Current learning rate is 0.017857142857142856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38528/60000][Iteration 602][Wall Clock 88.481870525s] Trained 64 records in 0.139448577 seconds. Throughput is 458.95053 records/second. Loss is 0.3297273. Sequential2290a28's hyper parameters: Current learning rate is 0.017853954650955187. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38592/60000][Iteration 603][Wall Clock 88.578173842s] Trained 64 records in 0.096303317 seconds. Throughput is 664.56696 records/second. Loss is 0.51966715. Sequential2290a28's hyper parameters: Current learning rate is 0.017850767583006067. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 604][Wall Clock 88.677296752s] Trained 64 records in 0.09912291 seconds. Throughput is 645.663 records/second. Loss is 0.32856834. Sequential2290a28's hyper parameters: Current learning rate is 0.01784758165268606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38720/60000][Iteration 605][Wall Clock 88.796032816s] Trained 64 records in 0.118736064 seconds. Throughput is 539.0106 records/second. Loss is 0.3855099. Sequential2290a28's hyper parameters: Current learning rate is 0.017844396859386154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38784/60000][Iteration 606][Wall Clock 88.953114436s] Trained 64 records in 0.15708162 seconds. Throughput is 407.4315 records/second. Loss is 0.5059999. Sequential2290a28's hyper parameters: Current learning rate is 0.01784121320249777. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38848/60000][Iteration 607][Wall Clock 89.045865032s] Trained 64 records in 0.092750596 seconds. Throughput is 690.0225 records/second. Loss is 0.5106462. Sequential2290a28's hyper parameters: Current learning rate is 0.01783803068141277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 608][Wall Clock 89.129863545s] Trained 64 records in 0.083998513 seconds. Throughput is 761.9182 records/second. Loss is 0.5406393. Sequential2290a28's hyper parameters: Current learning rate is 0.017834849295523453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 38976/60000][Iteration 609][Wall Clock 89.216459383s] Trained 64 records in 0.086595838 seconds. Throughput is 739.0655 records/second. Loss is 0.42334962. Sequential2290a28's hyper parameters: Current learning rate is 0.01783166904422254. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39040/60000][Iteration 610][Wall Clock 89.289353228s] Trained 64 records in 0.072893845 seconds. Throughput is 877.9891 records/second. Loss is 0.5687032. Sequential2290a28's hyper parameters: Current learning rate is 0.017828489926903193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39104/60000][Iteration 611][Wall Clock 89.375606623s] Trained 64 records in 0.086253395 seconds. Throughput is 741.99976 records/second. Loss is 0.41844213. Sequential2290a28's hyper parameters: Current learning rate is 0.017825311942959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 612][Wall Clock 89.468898544s] Trained 64 records in 0.093291921 seconds. Throughput is 686.0187 records/second. Loss is 0.46090007. Sequential2290a28's hyper parameters: Current learning rate is 0.017822135091783996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39232/60000][Iteration 613][Wall Clock 89.609625867s] Trained 64 records in 0.140727323 seconds. Throughput is 454.78018 records/second. Loss is 0.46728185. Sequential2290a28's hyper parameters: Current learning rate is 0.01781895937277263. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39296/60000][Iteration 614][Wall Clock 89.701108159s] Trained 64 records in 0.091482292 seconds. Throughput is 699.589 records/second. Loss is 0.49655735. Sequential2290a28's hyper parameters: Current learning rate is 0.017815784785319793. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39360/60000][Iteration 615][Wall Clock 89.821386632s] Trained 64 records in 0.120278473 seconds. Throughput is 532.0986 records/second. Loss is 0.5662481. Sequential2290a28's hyper parameters: Current learning rate is 0.017812611328820806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 616][Wall Clock 89.927823272s] Trained 64 records in 0.10643664 seconds. Throughput is 601.2967 records/second. Loss is 0.37556326. Sequential2290a28's hyper parameters: Current learning rate is 0.017809439002671415. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39488/60000][Iteration 617][Wall Clock 90.029698033s] Trained 64 records in 0.101874761 seconds. Throughput is 628.22235 records/second. Loss is 0.36183292. Sequential2290a28's hyper parameters: Current learning rate is 0.017806267806267807. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39552/60000][Iteration 618][Wall Clock 90.116378678s] Trained 64 records in 0.086680645 seconds. Throughput is 738.34247 records/second. Loss is 0.3118338. Sequential2290a28's hyper parameters: Current learning rate is 0.01780309773900659. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 39616/60000][Iteration 619][Wall Clock 90.2061477s] Trained 64 records in 0.089769022 seconds. Throughput is 712.94086 records/second. Loss is 0.5008681. Sequential2290a28's hyper parameters: Current learning rate is 0.0177999288002848. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 620][Wall Clock 90.301733958s] Trained 64 records in 0.095586258 seconds. Throughput is 669.5523 records/second. Loss is 0.31075114. Sequential2290a28's hyper parameters: Current learning rate is 0.017796760989499914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 39744/60000][Iteration 621][Wall Clock 90.465346845s] Trained 64 records in 0.163612887 seconds. Throughput is 391.16724 records/second. Loss is 0.37199563. Sequential2290a28's hyper parameters: Current learning rate is 0.01779359430604982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 39808/60000][Iteration 622][Wall Clock 90.599051959s] Trained 64 records in 0.133705114 seconds. Throughput is 478.6653 records/second. Loss is 0.2753776. Sequential2290a28's hyper parameters: Current learning rate is 0.017790428749332857. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 39872/60000][Iteration 623][Wall Clock 90.733058741s] Trained 64 records in 0.134006782 seconds. Throughput is 477.58777 records/second. Loss is 0.36970234. Sequential2290a28's hyper parameters: Current learning rate is 0.017787264318747775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 624][Wall Clock 90.829744653s] Trained 64 records in 0.096685912 seconds. Throughput is 661.9372 records/second. Loss is 0.43496206. Sequential2290a28's hyper parameters: Current learning rate is 0.017784101013693758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 40000/60000][Iteration 625][Wall Clock 90.929898355s] Trained 64 records in 0.100153702 seconds. Throughput is 639.0178 records/second. Loss is 0.5063007. Sequential2290a28's hyper parameters: Current learning rate is 0.017780938833570414. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 40064/60000][Iteration 626][Wall Clock 91.034124445s] Trained 64 records in 0.10422609 seconds. Throughput is 614.0497 records/second. Loss is 0.47997528. Sequential2290a28's hyper parameters: Current learning rate is 0.017777777777777778. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 40128/60000][Iteration 627][Wall Clock 91.124709634s] Trained 64 records in 0.090585189 seconds. Throughput is 706.5173 records/second. Loss is 0.5582047. Sequential2290a28's hyper parameters: Current learning rate is 0.01777461784571632. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 628][Wall Clock 91.222848379s] Trained 64 records in 0.098138745 seconds. Throughput is 652.13794 records/second. Loss is 0.4133274. Sequential2290a28's hyper parameters: Current learning rate is 0.01777145903678692. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40256/60000][Iteration 629][Wall Clock 91.326856219s] Trained 64 records in 0.10400784 seconds. Throughput is 615.33826 records/second. Loss is 0.390952. Sequential2290a28's hyper parameters: Current learning rate is 0.017768301350390904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40320/60000][Iteration 630][Wall Clock 91.446205888s] Trained 64 records in 0.119349669 seconds. Throughput is 536.23944 records/second. Loss is 0.48958415. Sequential2290a28's hyper parameters: Current learning rate is 0.01776514478593001. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40384/60000][Iteration 631][Wall Clock 91.58626783s] Trained 64 records in 0.140061942 seconds. Throughput is 456.94067 records/second. Loss is 0.42613304. Sequential2290a28's hyper parameters: Current learning rate is 0.017761989342806397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 632][Wall Clock 91.681380767s] Trained 64 records in 0.095112937 seconds. Throughput is 672.8843 records/second. Loss is 0.54998875. Sequential2290a28's hyper parameters: Current learning rate is 0.01775883502042266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40512/60000][Iteration 633][Wall Clock 91.807824995s] Trained 64 records in 0.126444228 seconds. Throughput is 506.15198 records/second. Loss is 0.41693002. Sequential2290a28's hyper parameters: Current learning rate is 0.017755681818181816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40576/60000][Iteration 634][Wall Clock 91.919494237s] Trained 64 records in 0.111669242 seconds. Throughput is 573.1211 records/second. Loss is 0.3844049. Sequential2290a28's hyper parameters: Current learning rate is 0.017752529735487306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 40640/60000][Iteration 635][Wall Clock 92.095941262s] Trained 64 records in 0.176447025 seconds. Throughput is 362.71512 records/second. Loss is 0.48612154. Sequential2290a28's hyper parameters: Current learning rate is 0.01774937877174299. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 636][Wall Clock 92.224380914s] Trained 64 records in 0.128439652 seconds. Throughput is 498.28848 records/second. Loss is 0.35493726. Sequential2290a28's hyper parameters: Current learning rate is 0.01774622892635315. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 40768/60000][Iteration 637][Wall Clock 92.328173293s] Trained 64 records in 0.103792379 seconds. Throughput is 616.6156 records/second. Loss is 0.64042133. Sequential2290a28's hyper parameters: Current learning rate is 0.017743080198722498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 40832/60000][Iteration 638][Wall Clock 92.416574386s] Trained 64 records in 0.088401093 seconds. Throughput is 723.97296 records/second. Loss is 0.54562265. Sequential2290a28's hyper parameters: Current learning rate is 0.017739932588256166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 40896/60000][Iteration 639][Wall Clock 92.513405311s] Trained 64 records in 0.096830925 seconds. Throughput is 660.94586 records/second. Loss is 0.378808. Sequential2290a28's hyper parameters: Current learning rate is 0.017736786094359705. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 640][Wall Clock 92.606123635s] Trained 64 records in 0.092718324 seconds. Throughput is 690.2627 records/second. Loss is 0.57306474. Sequential2290a28's hyper parameters: Current learning rate is 0.017733640716439087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 41024/60000][Iteration 641][Wall Clock 92.761793s] Trained 64 records in 0.155669365 seconds. Throughput is 411.12778 records/second. Loss is 0.48245484. Sequential2290a28's hyper parameters: Current learning rate is 0.017730496453900707. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 41088/60000][Iteration 642][Wall Clock 92.861997331s] Trained 64 records in 0.100204331 seconds. Throughput is 638.69495 records/second. Loss is 0.32509863. Sequential2290a28's hyper parameters: Current learning rate is 0.01772735330615139. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 41152/60000][Iteration 643][Wall Clock 92.950744741s] Trained 64 records in 0.08874741 seconds. Throughput is 721.14777 records/second. Loss is 0.46679863. Sequential2290a28's hyper parameters: Current learning rate is 0.017724211272598368. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 644][Wall Clock 93.030135965s] Trained 64 records in 0.079391224 seconds. Throughput is 806.1344 records/second. Loss is 0.33767778. Sequential2290a28's hyper parameters: Current learning rate is 0.0177210703526493. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 41280/60000][Iteration 645][Wall Clock 93.159303708s] Trained 64 records in 0.129167743 seconds. Throughput is 495.47977 records/second. Loss is 0.6656381. Sequential2290a28's hyper parameters: Current learning rate is 0.01771793054571226. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41344/60000][Iteration 646][Wall Clock 93.312147033s] Trained 64 records in 0.152843325 seconds. Throughput is 418.72943 records/second. Loss is 0.4122663. Sequential2290a28's hyper parameters: Current learning rate is 0.01771479185119575. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41408/60000][Iteration 647][Wall Clock 93.4202935s] Trained 64 records in 0.108146467 seconds. Throughput is 591.79004 records/second. Loss is 0.48929122. Sequential2290a28's hyper parameters: Current learning rate is 0.01771165426850868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 648][Wall Clock 93.548189298s] Trained 64 records in 0.127895798 seconds. Throughput is 500.40735 records/second. Loss is 0.3494176. Sequential2290a28's hyper parameters: Current learning rate is 0.017708517797060386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41536/60000][Iteration 649][Wall Clock 93.680252498s] Trained 64 records in 0.1320632 seconds. Throughput is 484.6165 records/second. Loss is 0.50730026. Sequential2290a28's hyper parameters: Current learning rate is 0.017705382436260624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41600/60000][Iteration 650][Wall Clock 93.800780882s] Trained 64 records in 0.120528384 seconds. Throughput is 530.99524 records/second. Loss is 0.4562792. Sequential2290a28's hyper parameters: Current learning rate is 0.017702248185519562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41664/60000][Iteration 651][Wall Clock 93.907603716s] Trained 64 records in 0.106822834 seconds. Throughput is 599.12286 records/second. Loss is 0.360873. Sequential2290a28's hyper parameters: Current learning rate is 0.01769911504424779. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 652][Wall Clock 94.041482717s] Trained 64 records in 0.133879001 seconds. Throughput is 478.04358 records/second. Loss is 0.33387408. Sequential2290a28's hyper parameters: Current learning rate is 0.017695983011856306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 41792/60000][Iteration 653][Wall Clock 94.149721519s] Trained 64 records in 0.108238802 seconds. Throughput is 591.2852 records/second. Loss is 0.31190652. Sequential2290a28's hyper parameters: Current learning rate is 0.017692852087756547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 41856/60000][Iteration 654][Wall Clock 94.273744926s] Trained 64 records in 0.124023407 seconds. Throughput is 516.0316 records/second. Loss is 0.47924465. Sequential2290a28's hyper parameters: Current learning rate is 0.01768972227136034. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 41920/60000][Iteration 655][Wall Clock 94.386779938s] Trained 64 records in 0.113035012 seconds. Throughput is 566.1963 records/second. Loss is 0.3504794. Sequential2290a28's hyper parameters: Current learning rate is 0.017686593562079942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 656][Wall Clock 94.48454542s] Trained 64 records in 0.097765482 seconds. Throughput is 654.62775 records/second. Loss is 0.41181704. Sequential2290a28's hyper parameters: Current learning rate is 0.01768346595932803. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 42048/60000][Iteration 657][Wall Clock 94.588226659s] Trained 64 records in 0.103681239 seconds. Throughput is 617.2766 records/second. Loss is 0.2964502. Sequential2290a28's hyper parameters: Current learning rate is 0.01768033946251768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 42112/60000][Iteration 658][Wall Clock 94.749182234s] Trained 64 records in 0.160955575 seconds. Throughput is 397.62524 records/second. Loss is 0.4061792. Sequential2290a28's hyper parameters: Current learning rate is 0.017677214071062403. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 42176/60000][Iteration 659][Wall Clock 94.863813827s] Trained 64 records in 0.114631593 seconds. Throughput is 558.3103 records/second. Loss is 0.46669477. Sequential2290a28's hyper parameters: Current learning rate is 0.017674089784376106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 660][Wall Clock 95.04282769s] Trained 64 records in 0.179013863 seconds. Throughput is 357.51422 records/second. Loss is 0.5851303. Sequential2290a28's hyper parameters: Current learning rate is 0.017670966601873124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:16 INFO  DistriOptimizer$:408 - [Epoch 1 42304/60000][Iteration 661][Wall Clock 95.125085858s] Trained 64 records in 0.082258168 seconds. Throughput is 778.03827 records/second. Loss is 0.43870586. Sequential2290a28's hyper parameters: Current learning rate is 0.017667844522968195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42368/60000][Iteration 662][Wall Clock 95.205804965s] Trained 64 records in 0.080719107 seconds. Throughput is 792.873 records/second. Loss is 0.48266426. Sequential2290a28's hyper parameters: Current learning rate is 0.01766472354707649. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42432/60000][Iteration 663][Wall Clock 95.298023753s] Trained 64 records in 0.092218788 seconds. Throughput is 694.0018 records/second. Loss is 0.42065454. Sequential2290a28's hyper parameters: Current learning rate is 0.017661603673613562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 664][Wall Clock 95.383982898s] Trained 64 records in 0.085959145 seconds. Throughput is 744.53973 records/second. Loss is 0.44018027. Sequential2290a28's hyper parameters: Current learning rate is 0.017658484901995408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42560/60000][Iteration 665][Wall Clock 95.485488348s] Trained 64 records in 0.10150545 seconds. Throughput is 630.508 records/second. Loss is 0.45572436. Sequential2290a28's hyper parameters: Current learning rate is 0.01765536723163842. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42624/60000][Iteration 666][Wall Clock 95.623157979s] Trained 64 records in 0.137669631 seconds. Throughput is 464.881 records/second. Loss is 0.33319867. Sequential2290a28's hyper parameters: Current learning rate is 0.017652250661959402. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42688/60000][Iteration 667][Wall Clock 95.774127283s] Trained 64 records in 0.150969304 seconds. Throughput is 423.92725 records/second. Loss is 0.33002457. Sequential2290a28's hyper parameters: Current learning rate is 0.017649135192375574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 668][Wall Clock 95.936205544s] Trained 64 records in 0.162078261 seconds. Throughput is 394.87097 records/second. Loss is 0.39149314. Sequential2290a28's hyper parameters: Current learning rate is 0.01764602082230457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42816/60000][Iteration 669][Wall Clock 96.042861083s] Trained 64 records in 0.106655539 seconds. Throughput is 600.0626 records/second. Loss is 0.36940283. Sequential2290a28's hyper parameters: Current learning rate is 0.017642907551164433. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:17 INFO  DistriOptimizer$:408 - [Epoch 1 42880/60000][Iteration 670][Wall Clock 96.123333091s] Trained 64 records in 0.080472008 seconds. Throughput is 795.3076 records/second. Loss is 0.36865395. Sequential2290a28's hyper parameters: Current learning rate is 0.017639795378373613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 42944/60000][Iteration 671][Wall Clock 96.217743337s] Trained 64 records in 0.094410246 seconds. Throughput is 677.8925 records/second. Loss is 0.36179447. Sequential2290a28's hyper parameters: Current learning rate is 0.017636684303350973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 672][Wall Clock 96.339719217s] Trained 64 records in 0.12197588 seconds. Throughput is 524.6939 records/second. Loss is 0.49721813. Sequential2290a28's hyper parameters: Current learning rate is 0.01763357432551578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43072/60000][Iteration 673][Wall Clock 96.432127561s] Trained 64 records in 0.092408344 seconds. Throughput is 692.5781 records/second. Loss is 0.3836726. Sequential2290a28's hyper parameters: Current learning rate is 0.01763046544428773. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43136/60000][Iteration 674][Wall Clock 96.521218053s] Trained 64 records in 0.089090492 seconds. Throughput is 718.3707 records/second. Loss is 0.51616704. Sequential2290a28's hyper parameters: Current learning rate is 0.017627357659086903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43200/60000][Iteration 675][Wall Clock 96.661163911s] Trained 64 records in 0.139945858 seconds. Throughput is 457.3197 records/second. Loss is 0.37129146. Sequential2290a28's hyper parameters: Current learning rate is 0.017624250969333802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 676][Wall Clock 96.773835853s] Trained 64 records in 0.112671942 seconds. Throughput is 568.02075 records/second. Loss is 0.4302606. Sequential2290a28's hyper parameters: Current learning rate is 0.01762114537444934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43328/60000][Iteration 677][Wall Clock 96.860984209s] Trained 64 records in 0.087148356 seconds. Throughput is 734.3799 records/second. Loss is 0.524448. Sequential2290a28's hyper parameters: Current learning rate is 0.017618040873854827. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43392/60000][Iteration 678][Wall Clock 96.95299537s] Trained 64 records in 0.092011161 seconds. Throughput is 695.5678 records/second. Loss is 0.33892825. Sequential2290a28's hyper parameters: Current learning rate is 0.017614937466971993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43456/60000][Iteration 679][Wall Clock 97.030952736s] Trained 64 records in 0.077957366 seconds. Throughput is 820.9615 records/second. Loss is 0.46997553. Sequential2290a28's hyper parameters: Current learning rate is 0.01761183515322297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:18 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 680][Wall Clock 97.137191873s] Trained 64 records in 0.106239137 seconds. Throughput is 602.4145 records/second. Loss is 0.51352525. Sequential2290a28's hyper parameters: Current learning rate is 0.017608733932030288. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43584/60000][Iteration 681][Wall Clock 97.243979706s] Trained 64 records in 0.106787833 seconds. Throughput is 599.3192 records/second. Loss is 0.41861728. Sequential2290a28's hyper parameters: Current learning rate is 0.0176056338028169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43648/60000][Iteration 682][Wall Clock 97.366302793s] Trained 64 records in 0.122323087 seconds. Throughput is 523.2046 records/second. Loss is 0.46321848. Sequential2290a28's hyper parameters: Current learning rate is 0.01760253476500616. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43712/60000][Iteration 683][Wall Clock 97.470404283s] Trained 64 records in 0.10410149 seconds. Throughput is 614.78467 records/second. Loss is 0.3799894. Sequential2290a28's hyper parameters: Current learning rate is 0.017599436818021823. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 684][Wall Clock 97.581118745s] Trained 64 records in 0.110714462 seconds. Throughput is 578.0636 records/second. Loss is 0.48277187. Sequential2290a28's hyper parameters: Current learning rate is 0.01759633996128805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43840/60000][Iteration 685][Wall Clock 97.71158282s] Trained 64 records in 0.130464075 seconds. Throughput is 490.5565 records/second. Loss is 0.40392068. Sequential2290a28's hyper parameters: Current learning rate is 0.017593244194229415. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43904/60000][Iteration 686][Wall Clock 97.794273999s] Trained 64 records in 0.082691179 seconds. Throughput is 773.96405 records/second. Loss is 0.47314. Sequential2290a28's hyper parameters: Current learning rate is 0.01759014951627089. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 43968/60000][Iteration 687][Wall Clock 97.881009331s] Trained 64 records in 0.086735332 seconds. Throughput is 737.87695 records/second. Loss is 0.3020362. Sequential2290a28's hyper parameters: Current learning rate is 0.017587055926837847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 688][Wall Clock 97.991227202s] Trained 64 records in 0.110217871 seconds. Throughput is 580.6681 records/second. Loss is 0.46497157. Sequential2290a28's hyper parameters: Current learning rate is 0.017583963425356078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:19 INFO  DistriOptimizer$:408 - [Epoch 1 44096/60000][Iteration 689][Wall Clock 98.07521812s] Trained 64 records in 0.083990918 seconds. Throughput is 761.9872 records/second. Loss is 0.520483. Sequential2290a28's hyper parameters: Current learning rate is 0.01758087201125176. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44160/60000][Iteration 690][Wall Clock 98.166259436s] Trained 64 records in 0.091041316 seconds. Throughput is 702.97754 records/second. Loss is 0.42977113. Sequential2290a28's hyper parameters: Current learning rate is 0.017577781683951486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44224/60000][Iteration 691][Wall Clock 98.242733326s] Trained 64 records in 0.07647389 seconds. Throughput is 836.8869 records/second. Loss is 0.39110062. Sequential2290a28's hyper parameters: Current learning rate is 0.01757469244288225. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 692][Wall Clock 98.321001471s] Trained 64 records in 0.078268145 seconds. Throughput is 817.7017 records/second. Loss is 0.32010365. Sequential2290a28's hyper parameters: Current learning rate is 0.017571604287471444. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44352/60000][Iteration 693][Wall Clock 98.392116471s] Trained 64 records in 0.071115 seconds. Throughput is 899.95074 records/second. Loss is 0.37735483. Sequential2290a28's hyper parameters: Current learning rate is 0.017568517217146872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44416/60000][Iteration 694][Wall Clock 98.471233797s] Trained 64 records in 0.079117326 seconds. Throughput is 808.9252 records/second. Loss is 0.48830578. Sequential2290a28's hyper parameters: Current learning rate is 0.01756543123133673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44480/60000][Iteration 695][Wall Clock 98.562862943s] Trained 64 records in 0.091629146 seconds. Throughput is 698.4677 records/second. Loss is 0.38081262. Sequential2290a28's hyper parameters: Current learning rate is 0.017562346329469618. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 696][Wall Clock 98.668199625s] Trained 64 records in 0.105336682 seconds. Throughput is 607.5756 records/second. Loss is 0.49247926. Sequential2290a28's hyper parameters: Current learning rate is 0.01755926251097454. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44608/60000][Iteration 697][Wall Clock 98.767661957s] Trained 64 records in 0.099462332 seconds. Throughput is 643.4597 records/second. Loss is 0.30544606. Sequential2290a28's hyper parameters: Current learning rate is 0.0175561797752809. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:20 INFO  DistriOptimizer$:408 - [Epoch 1 44672/60000][Iteration 698][Wall Clock 98.956564115s] Trained 64 records in 0.188902158 seconds. Throughput is 338.79974 records/second. Loss is 0.4893379. Sequential2290a28's hyper parameters: Current learning rate is 0.017553098121818503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 44736/60000][Iteration 699][Wall Clock 99.152124485s] Trained 64 records in 0.19556037 seconds. Throughput is 327.26468 records/second. Loss is 0.5123142. Sequential2290a28's hyper parameters: Current learning rate is 0.01755001755001755. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 700][Wall Clock 99.267263263s] Trained 64 records in 0.115138778 seconds. Throughput is 555.85095 records/second. Loss is 0.40529147. Sequential2290a28's hyper parameters: Current learning rate is 0.017546938059308653. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 44864/60000][Iteration 701][Wall Clock 99.40885043s] Trained 64 records in 0.141587167 seconds. Throughput is 452.01837 records/second. Loss is 0.39017454. Sequential2290a28's hyper parameters: Current learning rate is 0.017543859649122806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 44928/60000][Iteration 702][Wall Clock 99.48479854s] Trained 64 records in 0.07594811 seconds. Throughput is 842.6806 records/second. Loss is 0.51041484. Sequential2290a28's hyper parameters: Current learning rate is 0.01754078231889142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 44992/60000][Iteration 703][Wall Clock 99.576321172s] Trained 64 records in 0.091522632 seconds. Throughput is 699.2806 records/second. Loss is 0.35671845. Sequential2290a28's hyper parameters: Current learning rate is 0.017537706068046298. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 704][Wall Clock 99.739784s] Trained 64 records in 0.163462828 seconds. Throughput is 391.5263 records/second. Loss is 0.67037344. Sequential2290a28's hyper parameters: Current learning rate is 0.01753463089601964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 45120/60000][Iteration 705][Wall Clock 99.83299045s] Trained 64 records in 0.09320645 seconds. Throughput is 686.64777 records/second. Loss is 0.42088524. Sequential2290a28's hyper parameters: Current learning rate is 0.01753155680224404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 45184/60000][Iteration 706][Wall Clock 99.957253419s] Trained 64 records in 0.124262969 seconds. Throughput is 515.0368 records/second. Loss is 0.44849065. Sequential2290a28's hyper parameters: Current learning rate is 0.017528483786152498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:21 INFO  DistriOptimizer$:408 - [Epoch 1 45248/60000][Iteration 707][Wall Clock 100.039490826s] Trained 64 records in 0.082237407 seconds. Throughput is 778.2346 records/second. Loss is 0.3608222. Sequential2290a28's hyper parameters: Current learning rate is 0.01752541184717841. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 708][Wall Clock 100.156961828s] Trained 64 records in 0.117471002 seconds. Throughput is 544.8153 records/second. Loss is 0.32445097. Sequential2290a28's hyper parameters: Current learning rate is 0.017522340984755563. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45376/60000][Iteration 709][Wall Clock 100.292023469s] Trained 64 records in 0.135061641 seconds. Throughput is 473.85773 records/second. Loss is 0.5303944. Sequential2290a28's hyper parameters: Current learning rate is 0.01751927119831815. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45440/60000][Iteration 710][Wall Clock 100.372928164s] Trained 64 records in 0.080904695 seconds. Throughput is 791.05426 records/second. Loss is 0.41108054. Sequential2290a28's hyper parameters: Current learning rate is 0.017516202487300753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45504/60000][Iteration 711][Wall Clock 100.459168172s] Trained 64 records in 0.086240008 seconds. Throughput is 742.1149 records/second. Loss is 0.4739511. Sequential2290a28's hyper parameters: Current learning rate is 0.017513134851138354. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 712][Wall Clock 100.579020054s] Trained 64 records in 0.119851882 seconds. Throughput is 533.99243 records/second. Loss is 0.33566758. Sequential2290a28's hyper parameters: Current learning rate is 0.01751006828926633. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45632/60000][Iteration 713][Wall Clock 100.700634926s] Trained 64 records in 0.121614872 seconds. Throughput is 526.2514 records/second. Loss is 0.42735282. Sequential2290a28's hyper parameters: Current learning rate is 0.01750700280112045. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45696/60000][Iteration 714][Wall Clock 100.834387119s] Trained 64 records in 0.133752193 seconds. Throughput is 478.49683 records/second. Loss is 0.34698588. Sequential2290a28's hyper parameters: Current learning rate is 0.01750393838613688. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45760/60000][Iteration 715][Wall Clock 100.934652209s] Trained 64 records in 0.10026509 seconds. Throughput is 638.30786 records/second. Loss is 0.34527996. Sequential2290a28's hyper parameters: Current learning rate is 0.01750087504375219. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 716][Wall Clock 101.009219419s] Trained 64 records in 0.07456721 seconds. Throughput is 858.2861 records/second. Loss is 0.43086037. Sequential2290a28's hyper parameters: Current learning rate is 0.017497812773403325. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:22 INFO  DistriOptimizer$:408 - [Epoch 1 45888/60000][Iteration 717][Wall Clock 101.094276325s] Trained 64 records in 0.085056906 seconds. Throughput is 752.43744 records/second. Loss is 0.43101546. Sequential2290a28's hyper parameters: Current learning rate is 0.017494751574527644. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 45952/60000][Iteration 718][Wall Clock 101.17038475s] Trained 64 records in 0.076108425 seconds. Throughput is 840.9056 records/second. Loss is 0.5505828. Sequential2290a28's hyper parameters: Current learning rate is 0.017491691446562884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46016/60000][Iteration 719][Wall Clock 101.247901968s] Trained 64 records in 0.077517218 seconds. Throughput is 825.623 records/second. Loss is 0.28677353. Sequential2290a28's hyper parameters: Current learning rate is 0.017488632388947184. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 720][Wall Clock 101.327569139s] Trained 64 records in 0.079667171 seconds. Throughput is 803.34216 records/second. Loss is 0.5679824. Sequential2290a28's hyper parameters: Current learning rate is 0.01748557440111908. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46144/60000][Iteration 721][Wall Clock 101.421748333s] Trained 64 records in 0.094179194 seconds. Throughput is 679.55566 records/second. Loss is 0.29567727. Sequential2290a28's hyper parameters: Current learning rate is 0.01748251748251748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46208/60000][Iteration 722][Wall Clock 101.513231682s] Trained 64 records in 0.091483349 seconds. Throughput is 699.5809 records/second. Loss is 0.30307606. Sequential2290a28's hyper parameters: Current learning rate is 0.017479461632581714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46272/60000][Iteration 723][Wall Clock 101.64607088s] Trained 64 records in 0.132839198 seconds. Throughput is 481.7855 records/second. Loss is 0.43127003. Sequential2290a28's hyper parameters: Current learning rate is 0.017476406850751483. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 724][Wall Clock 101.738826284s] Trained 64 records in 0.092755404 seconds. Throughput is 689.98676 records/second. Loss is 0.38527703. Sequential2290a28's hyper parameters: Current learning rate is 0.017473353136466887. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46400/60000][Iteration 725][Wall Clock 101.846559336s] Trained 64 records in 0.107733052 seconds. Throughput is 594.061 records/second. Loss is 0.42526472. Sequential2290a28's hyper parameters: Current learning rate is 0.017470300489168412. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46464/60000][Iteration 726][Wall Clock 101.951972727s] Trained 64 records in 0.105413391 seconds. Throughput is 607.1335 records/second. Loss is 0.43352216. Sequential2290a28's hyper parameters: Current learning rate is 0.017467248908296942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:23 INFO  DistriOptimizer$:408 - [Epoch 1 46528/60000][Iteration 727][Wall Clock 102.059956175s] Trained 64 records in 0.107983448 seconds. Throughput is 592.6834 records/second. Loss is 0.26321512. Sequential2290a28's hyper parameters: Current learning rate is 0.01746419839329375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 728][Wall Clock 102.224606525s] Trained 64 records in 0.16465035 seconds. Throughput is 388.70248 records/second. Loss is 0.39192462. Sequential2290a28's hyper parameters: Current learning rate is 0.01746114894360049. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46656/60000][Iteration 729][Wall Clock 102.389540436s] Trained 64 records in 0.164933911 seconds. Throughput is 388.0342 records/second. Loss is 0.51893693. Sequential2290a28's hyper parameters: Current learning rate is 0.01745810055865922. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46720/60000][Iteration 730][Wall Clock 102.512291665s] Trained 64 records in 0.122751229 seconds. Throughput is 521.3797 records/second. Loss is 0.4207713. Sequential2290a28's hyper parameters: Current learning rate is 0.017455053237912375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46784/60000][Iteration 731][Wall Clock 102.632998484s] Trained 64 records in 0.120706819 seconds. Throughput is 530.2103 records/second. Loss is 0.31235522. Sequential2290a28's hyper parameters: Current learning rate is 0.017452006980802796. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 732][Wall Clock 102.805265389s] Trained 64 records in 0.172266905 seconds. Throughput is 371.5165 records/second. Loss is 0.3900442. Sequential2290a28's hyper parameters: Current learning rate is 0.01744896178677369. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46912/60000][Iteration 733][Wall Clock 102.895324822s] Trained 64 records in 0.090059433 seconds. Throughput is 710.64185 records/second. Loss is 0.62289685. Sequential2290a28's hyper parameters: Current learning rate is 0.017445917655268667. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 46976/60000][Iteration 734][Wall Clock 103.018330224s] Trained 64 records in 0.123005402 seconds. Throughput is 520.30237 records/second. Loss is 0.32113388. Sequential2290a28's hyper parameters: Current learning rate is 0.017442874585731728. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:24 INFO  DistriOptimizer$:408 - [Epoch 1 47040/60000][Iteration 735][Wall Clock 103.102292226s] Trained 64 records in 0.083962002 seconds. Throughput is 762.2496 records/second. Loss is 0.55244356. Sequential2290a28's hyper parameters: Current learning rate is 0.017439832577607256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 736][Wall Clock 103.179962157s] Trained 64 records in 0.077669931 seconds. Throughput is 823.9997 records/second. Loss is 0.32609382. Sequential2290a28's hyper parameters: Current learning rate is 0.017436791630340016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47168/60000][Iteration 737][Wall Clock 103.26434291s] Trained 64 records in 0.084380753 seconds. Throughput is 758.4668 records/second. Loss is 0.4903738. Sequential2290a28's hyper parameters: Current learning rate is 0.017433751743375175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47232/60000][Iteration 738][Wall Clock 103.35691158s] Trained 64 records in 0.09256867 seconds. Throughput is 691.3786 records/second. Loss is 0.3137846. Sequential2290a28's hyper parameters: Current learning rate is 0.017430712916158272. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47296/60000][Iteration 739][Wall Clock 103.439913105s] Trained 64 records in 0.083001525 seconds. Throughput is 771.0702 records/second. Loss is 0.30739516. Sequential2290a28's hyper parameters: Current learning rate is 0.01742767514813524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 740][Wall Clock 103.568563257s] Trained 64 records in 0.128650152 seconds. Throughput is 497.47314 records/second. Loss is 0.64175904. Sequential2290a28's hyper parameters: Current learning rate is 0.017424638438752398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47424/60000][Iteration 741][Wall Clock 103.66959973s] Trained 64 records in 0.101036473 seconds. Throughput is 633.43463 records/second. Loss is 0.3195881. Sequential2290a28's hyper parameters: Current learning rate is 0.017421602787456445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47488/60000][Iteration 742][Wall Clock 103.842104955s] Trained 64 records in 0.172505225 seconds. Throughput is 371.00323 records/second. Loss is 0.3796851. Sequential2290a28's hyper parameters: Current learning rate is 0.017418568193694476. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:25 INFO  DistriOptimizer$:408 - [Epoch 1 47552/60000][Iteration 743][Wall Clock 104.005393223s] Trained 64 records in 0.163288268 seconds. Throughput is 391.9449 records/second. Loss is 0.4144819. Sequential2290a28's hyper parameters: Current learning rate is 0.017415534656913968. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 744][Wall Clock 104.18541424s] Trained 64 records in 0.180021017 seconds. Throughput is 355.51404 records/second. Loss is 0.32941037. Sequential2290a28's hyper parameters: Current learning rate is 0.01741250217656277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 47680/60000][Iteration 745][Wall Clock 104.351516311s] Trained 64 records in 0.166102071 seconds. Throughput is 385.30527 records/second. Loss is 0.27544597. Sequential2290a28's hyper parameters: Current learning rate is 0.017409470752089137. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 47744/60000][Iteration 746][Wall Clock 104.507183412s] Trained 64 records in 0.155667101 seconds. Throughput is 411.13376 records/second. Loss is 0.4628165. Sequential2290a28's hyper parameters: Current learning rate is 0.017406440382941687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 47808/60000][Iteration 747][Wall Clock 104.61992922s] Trained 64 records in 0.112745808 seconds. Throughput is 567.6486 records/second. Loss is 0.41610292. Sequential2290a28's hyper parameters: Current learning rate is 0.01740341106856944. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 748][Wall Clock 104.742880725s] Trained 64 records in 0.122951505 seconds. Throughput is 520.5304 records/second. Loss is 0.65472573. Sequential2290a28's hyper parameters: Current learning rate is 0.017400382808421787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 47936/60000][Iteration 749][Wall Clock 104.919960555s] Trained 64 records in 0.17707983 seconds. Throughput is 361.4189 records/second. Loss is 0.5461869. Sequential2290a28's hyper parameters: Current learning rate is 0.017397355601948505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:26 INFO  DistriOptimizer$:408 - [Epoch 1 48000/60000][Iteration 750][Wall Clock 105.025875034s] Trained 64 records in 0.105914479 seconds. Throughput is 604.2611 records/second. Loss is 0.47627506. Sequential2290a28's hyper parameters: Current learning rate is 0.017394329448599758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48064/60000][Iteration 751][Wall Clock 105.157533974s] Trained 64 records in 0.13165894 seconds. Throughput is 486.10446 records/second. Loss is 0.37347043. Sequential2290a28's hyper parameters: Current learning rate is 0.017391304347826087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 752][Wall Clock 105.381435417s] Trained 64 records in 0.223901443 seconds. Throughput is 285.84006 records/second. Loss is 0.4794141. Sequential2290a28's hyper parameters: Current learning rate is 0.017388280299078424. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48192/60000][Iteration 753][Wall Clock 105.521220701s] Trained 64 records in 0.139785284 seconds. Throughput is 457.84503 records/second. Loss is 0.45543832. Sequential2290a28's hyper parameters: Current learning rate is 0.017385257301808066. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48256/60000][Iteration 754][Wall Clock 105.670136321s] Trained 64 records in 0.14891562 seconds. Throughput is 429.7736 records/second. Loss is 0.28417382. Sequential2290a28's hyper parameters: Current learning rate is 0.01738223535546671. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48320/60000][Iteration 755][Wall Clock 105.834014236s] Trained 64 records in 0.163877915 seconds. Throughput is 390.5346 records/second. Loss is 0.33384517. Sequential2290a28's hyper parameters: Current learning rate is 0.01737921445950643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 756][Wall Clock 105.935662819s] Trained 64 records in 0.101648583 seconds. Throughput is 629.6202 records/second. Loss is 0.46403062. Sequential2290a28's hyper parameters: Current learning rate is 0.01737619461337967. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:27 INFO  DistriOptimizer$:408 - [Epoch 1 48448/60000][Iteration 757][Wall Clock 106.062135516s] Trained 64 records in 0.126472697 seconds. Throughput is 506.0381 records/second. Loss is 0.3636003. Sequential2290a28's hyper parameters: Current learning rate is 0.017373175816539264. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48512/60000][Iteration 758][Wall Clock 106.20579289s] Trained 64 records in 0.143657374 seconds. Throughput is 445.50446 records/second. Loss is 0.50724167. Sequential2290a28's hyper parameters: Current learning rate is 0.017370158068438425. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48576/60000][Iteration 759][Wall Clock 106.319619949s] Trained 64 records in 0.113827059 seconds. Throughput is 562.2565 records/second. Loss is 0.4800276. Sequential2290a28's hyper parameters: Current learning rate is 0.01736714136853074. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 760][Wall Clock 106.440306368s] Trained 64 records in 0.120686419 seconds. Throughput is 530.2999 records/second. Loss is 0.40020084. Sequential2290a28's hyper parameters: Current learning rate is 0.017364125716270187. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48704/60000][Iteration 761][Wall Clock 106.577338659s] Trained 64 records in 0.137032291 seconds. Throughput is 467.0432 records/second. Loss is 0.31762424. Sequential2290a28's hyper parameters: Current learning rate is 0.017361111111111112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48768/60000][Iteration 762][Wall Clock 106.707458453s] Trained 64 records in 0.130119794 seconds. Throughput is 491.85443 records/second. Loss is 0.36194658. Sequential2290a28's hyper parameters: Current learning rate is 0.017358097552508243. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48832/60000][Iteration 763][Wall Clock 106.810228605s] Trained 64 records in 0.102770152 seconds. Throughput is 622.7489 records/second. Loss is 0.42808437. Sequential2290a28's hyper parameters: Current learning rate is 0.017355085039916694. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 764][Wall Clock 106.898973751s] Trained 64 records in 0.088745146 seconds. Throughput is 721.1662 records/second. Loss is 0.43883073. Sequential2290a28's hyper parameters: Current learning rate is 0.01735207357279195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:28 INFO  DistriOptimizer$:408 - [Epoch 1 48960/60000][Iteration 765][Wall Clock 107.013315706s] Trained 64 records in 0.114341955 seconds. Throughput is 559.72455 records/second. Loss is 0.45446184. Sequential2290a28's hyper parameters: Current learning rate is 0.01734906315058987. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49024/60000][Iteration 766][Wall Clock 107.105664784s] Trained 64 records in 0.092349078 seconds. Throughput is 693.02264 records/second. Loss is 0.34232873. Sequential2290a28's hyper parameters: Current learning rate is 0.017346053772766695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49088/60000][Iteration 767][Wall Clock 107.203559014s] Trained 64 records in 0.09789423 seconds. Throughput is 653.76685 records/second. Loss is 0.33661097. Sequential2290a28's hyper parameters: Current learning rate is 0.01734304543877905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 768][Wall Clock 107.307143998s] Trained 64 records in 0.103584984 seconds. Throughput is 617.85016 records/second. Loss is 0.39754787. Sequential2290a28's hyper parameters: Current learning rate is 0.017340038148083926. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49216/60000][Iteration 769][Wall Clock 107.399143329s] Trained 64 records in 0.091999331 seconds. Throughput is 695.6572 records/second. Loss is 0.5376492. Sequential2290a28's hyper parameters: Current learning rate is 0.0173370319001387. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49280/60000][Iteration 770][Wall Clock 107.497923053s] Trained 64 records in 0.098779724 seconds. Throughput is 647.90625 records/second. Loss is 0.53819704. Sequential2290a28's hyper parameters: Current learning rate is 0.017334026694401112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49344/60000][Iteration 771][Wall Clock 107.587460744s] Trained 64 records in 0.089537691 seconds. Throughput is 714.78284 records/second. Loss is 0.41217473. Sequential2290a28's hyper parameters: Current learning rate is 0.017331022530329292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 772][Wall Clock 107.728614331s] Trained 64 records in 0.141153587 seconds. Throughput is 453.40683 records/second. Loss is 0.36969715. Sequential2290a28's hyper parameters: Current learning rate is 0.01732801940738174. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49472/60000][Iteration 773][Wall Clock 107.84108679s] Trained 64 records in 0.112472459 seconds. Throughput is 569.0282 records/second. Loss is 0.41921237. Sequential2290a28's hyper parameters: Current learning rate is 0.017325017325017324. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:29 INFO  DistriOptimizer$:408 - [Epoch 1 49536/60000][Iteration 774][Wall Clock 108.002297226s] Trained 64 records in 0.161210436 seconds. Throughput is 396.99664 records/second. Loss is 0.25919923. Sequential2290a28's hyper parameters: Current learning rate is 0.017322016282695304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49600/60000][Iteration 775][Wall Clock 108.1244478s] Trained 64 records in 0.122150574 seconds. Throughput is 523.9435 records/second. Loss is 0.2943803. Sequential2290a28's hyper parameters: Current learning rate is 0.017319016279875303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 776][Wall Clock 108.205370289s] Trained 64 records in 0.080922489 seconds. Throughput is 790.88025 records/second. Loss is 0.37500972. Sequential2290a28's hyper parameters: Current learning rate is 0.017316017316017316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49728/60000][Iteration 777][Wall Clock 108.314915101s] Trained 64 records in 0.109544812 seconds. Throughput is 584.2358 records/second. Loss is 0.3094908. Sequential2290a28's hyper parameters: Current learning rate is 0.01731301939058172. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49792/60000][Iteration 778][Wall Clock 108.401726451s] Trained 64 records in 0.08681135 seconds. Throughput is 737.2308 records/second. Loss is 0.30744728. Sequential2290a28's hyper parameters: Current learning rate is 0.017310022503029255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49856/60000][Iteration 779][Wall Clock 108.536434213s] Trained 64 records in 0.134707762 seconds. Throughput is 475.10254 records/second. Loss is 0.24054752. Sequential2290a28's hyper parameters: Current learning rate is 0.017307026652821047. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 780][Wall Clock 108.626766671s] Trained 64 records in 0.090332458 seconds. Throughput is 708.49396 records/second. Loss is 0.45376801. Sequential2290a28's hyper parameters: Current learning rate is 0.017304031839418584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 49984/60000][Iteration 781][Wall Clock 108.712508389s] Trained 64 records in 0.085741718 seconds. Throughput is 746.42773 records/second. Loss is 0.38145947. Sequential2290a28's hyper parameters: Current learning rate is 0.01730103806228374. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 50048/60000][Iteration 782][Wall Clock 108.815740579s] Trained 64 records in 0.10323219 seconds. Throughput is 619.9617 records/second. Loss is 0.5309765. Sequential2290a28's hyper parameters: Current learning rate is 0.017298045320878738. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:30 INFO  DistriOptimizer$:408 - [Epoch 1 50112/60000][Iteration 783][Wall Clock 108.936081874s] Trained 64 records in 0.120341295 seconds. Throughput is 531.8208 records/second. Loss is 0.2926808. Sequential2290a28's hyper parameters: Current learning rate is 0.017295053614666205. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 784][Wall Clock 109.10207023s] Trained 64 records in 0.165988356 seconds. Throughput is 385.5692 records/second. Loss is 0.43162405. Sequential2290a28's hyper parameters: Current learning rate is 0.017292062943109112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50240/60000][Iteration 785][Wall Clock 109.214568525s] Trained 64 records in 0.112498295 seconds. Throughput is 568.8975 records/second. Loss is 0.30826274. Sequential2290a28's hyper parameters: Current learning rate is 0.017289073305670817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50304/60000][Iteration 786][Wall Clock 109.325257043s] Trained 64 records in 0.110688518 seconds. Throughput is 578.1991 records/second. Loss is 0.42752194. Sequential2290a28's hyper parameters: Current learning rate is 0.01728608470181504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50368/60000][Iteration 787][Wall Clock 109.424524367s] Trained 64 records in 0.099267324 seconds. Throughput is 644.7237 records/second. Loss is 0.49319673. Sequential2290a28's hyper parameters: Current learning rate is 0.017283097131005877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 788][Wall Clock 109.53164844s] Trained 64 records in 0.107124073 seconds. Throughput is 597.43805 records/second. Loss is 0.37355897. Sequential2290a28's hyper parameters: Current learning rate is 0.017280110592707794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50496/60000][Iteration 789][Wall Clock 109.649446776s] Trained 64 records in 0.117798336 seconds. Throughput is 543.3014 records/second. Loss is 0.46030733. Sequential2290a28's hyper parameters: Current learning rate is 0.017277125086385625. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50560/60000][Iteration 790][Wall Clock 109.747503796s] Trained 64 records in 0.09805702 seconds. Throughput is 652.6815 records/second. Loss is 0.39465842. Sequential2290a28's hyper parameters: Current learning rate is 0.01727414061150458. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50624/60000][Iteration 791][Wall Clock 109.852714841s] Trained 64 records in 0.105211045 seconds. Throughput is 608.30115 records/second. Loss is 0.43515158. Sequential2290a28's hyper parameters: Current learning rate is 0.017271157167530225. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:31 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 792][Wall Clock 109.963463813s] Trained 64 records in 0.110748972 seconds. Throughput is 577.8835 records/second. Loss is 0.31275296. Sequential2290a28's hyper parameters: Current learning rate is 0.01726817475392851. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 50752/60000][Iteration 793][Wall Clock 110.086251727s] Trained 64 records in 0.122787914 seconds. Throughput is 521.22394 records/second. Loss is 0.41015226. Sequential2290a28's hyper parameters: Current learning rate is 0.017265193370165743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 50816/60000][Iteration 794][Wall Clock 110.191477381s] Trained 64 records in 0.105225654 seconds. Throughput is 608.21674 records/second. Loss is 0.41334403. Sequential2290a28's hyper parameters: Current learning rate is 0.017262213015708613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 50880/60000][Iteration 795][Wall Clock 110.282532119s] Trained 64 records in 0.091054738 seconds. Throughput is 702.8739 records/second. Loss is 0.24572334. Sequential2290a28's hyper parameters: Current learning rate is 0.01725923369002416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 796][Wall Clock 110.383428424s] Trained 64 records in 0.100896305 seconds. Throughput is 634.3146 records/second. Loss is 0.47895074. Sequential2290a28's hyper parameters: Current learning rate is 0.01725625539257981. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 51008/60000][Iteration 797][Wall Clock 110.484703375s] Trained 64 records in 0.101274951 seconds. Throughput is 631.94305 records/second. Loss is 0.33889788. Sequential2290a28's hyper parameters: Current learning rate is 0.01725327812284334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 51072/60000][Iteration 798][Wall Clock 110.599603904s] Trained 64 records in 0.114900529 seconds. Throughput is 557.00354 records/second. Loss is 0.37529916. Sequential2290a28's hyper parameters: Current learning rate is 0.017250301880282905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 51136/60000][Iteration 799][Wall Clock 110.741582225s] Trained 64 records in 0.141978321 seconds. Throughput is 450.77304 records/second. Loss is 0.44228193. Sequential2290a28's hyper parameters: Current learning rate is 0.017247326664367024. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 800][Wall Clock 110.844606415s] Trained 64 records in 0.10302419 seconds. Throughput is 621.2133 records/second. Loss is 0.23856553. Sequential2290a28's hyper parameters: Current learning rate is 0.01724435247456458. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:32 INFO  DistriOptimizer$:408 - [Epoch 1 51264/60000][Iteration 801][Wall Clock 110.965686306s] Trained 64 records in 0.121079891 seconds. Throughput is 528.5766 records/second. Loss is 0.30996835. Sequential2290a28's hyper parameters: Current learning rate is 0.01724137931034483. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51328/60000][Iteration 802][Wall Clock 111.094618338s] Trained 64 records in 0.128932032 seconds. Throughput is 496.3856 records/second. Loss is 0.18642846. Sequential2290a28's hyper parameters: Current learning rate is 0.017238407171177382. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51392/60000][Iteration 803][Wall Clock 111.191309143s] Trained 64 records in 0.096690805 seconds. Throughput is 661.9037 records/second. Loss is 0.3260906. Sequential2290a28's hyper parameters: Current learning rate is 0.01723543605653223. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 804][Wall Clock 111.285162621s] Trained 64 records in 0.093853478 seconds. Throughput is 681.914 records/second. Loss is 0.4498952. Sequential2290a28's hyper parameters: Current learning rate is 0.017232465965879715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51520/60000][Iteration 805][Wall Clock 111.383335583s] Trained 64 records in 0.098172962 seconds. Throughput is 651.91064 records/second. Loss is 0.4595018. Sequential2290a28's hyper parameters: Current learning rate is 0.017229496898690556. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51584/60000][Iteration 806][Wall Clock 111.490132897s] Trained 64 records in 0.106797314 seconds. Throughput is 599.266 records/second. Loss is 0.24139455. Sequential2290a28's hyper parameters: Current learning rate is 0.017226528854435832. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51648/60000][Iteration 807][Wall Clock 111.617270765s] Trained 64 records in 0.127137868 seconds. Throughput is 503.39053 records/second. Loss is 0.3109519. Sequential2290a28's hyper parameters: Current learning rate is 0.01722356183258698. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 808][Wall Clock 111.745691392s] Trained 64 records in 0.128420627 seconds. Throughput is 498.36234 records/second. Loss is 0.30575573. Sequential2290a28's hyper parameters: Current learning rate is 0.017220595832615808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51776/60000][Iteration 809][Wall Clock 111.840983817s] Trained 64 records in 0.095292425 seconds. Throughput is 671.6169 records/second. Loss is 0.45426002. Sequential2290a28's hyper parameters: Current learning rate is 0.01721763085399449. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51840/60000][Iteration 810][Wall Clock 111.941980977s] Trained 64 records in 0.10099716 seconds. Throughput is 633.6812 records/second. Loss is 0.38275164. Sequential2290a28's hyper parameters: Current learning rate is 0.01721466689619556. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:33 INFO  DistriOptimizer$:408 - [Epoch 1 51904/60000][Iteration 811][Wall Clock 112.014086195s] Trained 64 records in 0.072105218 seconds. Throughput is 887.59174 records/second. Loss is 0.43377644. Sequential2290a28's hyper parameters: Current learning rate is 0.017211703958691912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 812][Wall Clock 112.081522227s] Trained 64 records in 0.067436032 seconds. Throughput is 949.04755 records/second. Loss is 0.4753649. Sequential2290a28's hyper parameters: Current learning rate is 0.017208742040956806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52032/60000][Iteration 813][Wall Clock 112.167818373s] Trained 64 records in 0.086296146 seconds. Throughput is 741.63214 records/second. Loss is 0.35240042. Sequential2290a28's hyper parameters: Current learning rate is 0.017205781142463867. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52096/60000][Iteration 814][Wall Clock 112.272462298s] Trained 64 records in 0.104643925 seconds. Throughput is 611.59784 records/second. Loss is 0.3672266. Sequential2290a28's hyper parameters: Current learning rate is 0.01720282126268708. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52160/60000][Iteration 815][Wall Clock 112.35074918s] Trained 64 records in 0.078286882 seconds. Throughput is 817.5061 records/second. Loss is 0.3975441. Sequential2290a28's hyper parameters: Current learning rate is 0.01719986240110079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 816][Wall Clock 112.450197736s] Trained 64 records in 0.099448556 seconds. Throughput is 643.5488 records/second. Loss is 0.3394829. Sequential2290a28's hyper parameters: Current learning rate is 0.017196904557179708. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52288/60000][Iteration 817][Wall Clock 112.565185113s] Trained 64 records in 0.114987377 seconds. Throughput is 556.5828 records/second. Loss is 0.5024763. Sequential2290a28's hyper parameters: Current learning rate is 0.0171939477303989. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52352/60000][Iteration 818][Wall Clock 112.647552066s] Trained 64 records in 0.082366953 seconds. Throughput is 777.0107 records/second. Loss is 0.41983894. Sequential2290a28's hyper parameters: Current learning rate is 0.017190991920233798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52416/60000][Iteration 819][Wall Clock 112.718904363s] Trained 64 records in 0.071352297 seconds. Throughput is 896.9578 records/second. Loss is 0.30150953. Sequential2290a28's hyper parameters: Current learning rate is 0.017188037126160193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 820][Wall Clock 112.810254857s] Trained 64 records in 0.091350494 seconds. Throughput is 700.59827 records/second. Loss is 0.39919376. Sequential2290a28's hyper parameters: Current learning rate is 0.017185083347654236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52544/60000][Iteration 821][Wall Clock 112.896530244s] Trained 64 records in 0.086275387 seconds. Throughput is 741.81067 records/second. Loss is 0.32554334. Sequential2290a28's hyper parameters: Current learning rate is 0.01718213058419244. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:34 INFO  DistriOptimizer$:408 - [Epoch 1 52608/60000][Iteration 822][Wall Clock 113.004649802s] Trained 64 records in 0.108119558 seconds. Throughput is 591.9373 records/second. Loss is 0.47600073. Sequential2290a28's hyper parameters: Current learning rate is 0.017179178835251673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 52672/60000][Iteration 823][Wall Clock 113.100587588s] Trained 64 records in 0.095937786 seconds. Throughput is 667.099 records/second. Loss is 0.5279475. Sequential2290a28's hyper parameters: Current learning rate is 0.017176228100309172. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 824][Wall Clock 113.259719019s] Trained 64 records in 0.159131431 seconds. Throughput is 402.18326 records/second. Loss is 0.39065894. Sequential2290a28's hyper parameters: Current learning rate is 0.01717327837884252. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 52800/60000][Iteration 825][Wall Clock 113.374983607s] Trained 64 records in 0.115264588 seconds. Throughput is 555.24426 records/second. Loss is 0.19828543. Sequential2290a28's hyper parameters: Current learning rate is 0.01717032967032967. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 52864/60000][Iteration 826][Wall Clock 113.510008991s] Trained 64 records in 0.135025384 seconds. Throughput is 473.98495 records/second. Loss is 0.39108402. Sequential2290a28's hyper parameters: Current learning rate is 0.017167381974248927. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 52928/60000][Iteration 827][Wall Clock 113.636662032s] Trained 64 records in 0.126653041 seconds. Throughput is 505.3175 records/second. Loss is 0.3503939. Sequential2290a28's hyper parameters: Current learning rate is 0.017164435290078956. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 828][Wall Clock 113.733222745s] Trained 64 records in 0.096560713 seconds. Throughput is 662.7954 records/second. Loss is 0.5062076. Sequential2290a28's hyper parameters: Current learning rate is 0.017161489617298784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 53056/60000][Iteration 829][Wall Clock 113.828985313s] Trained 64 records in 0.095762568 seconds. Throughput is 668.3196 records/second. Loss is 0.38960654. Sequential2290a28's hyper parameters: Current learning rate is 0.017158544955387784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 53120/60000][Iteration 830][Wall Clock 113.913800103s] Trained 64 records in 0.08481479 seconds. Throughput is 754.5854 records/second. Loss is 0.30961204. Sequential2290a28's hyper parameters: Current learning rate is 0.0171556013038257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:35 INFO  DistriOptimizer$:408 - [Epoch 1 53184/60000][Iteration 831][Wall Clock 114.023431556s] Trained 64 records in 0.109631453 seconds. Throughput is 583.77405 records/second. Loss is 0.42912042. Sequential2290a28's hyper parameters: Current learning rate is 0.017152658662092625. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 832][Wall Clock 114.108542866s] Trained 64 records in 0.08511131 seconds. Throughput is 751.9564 records/second. Loss is 0.41530025. Sequential2290a28's hyper parameters: Current learning rate is 0.017149717029669012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53312/60000][Iteration 833][Wall Clock 114.213296846s] Trained 64 records in 0.10475398 seconds. Throughput is 610.9553 records/second. Loss is 0.6098057. Sequential2290a28's hyper parameters: Current learning rate is 0.017146776406035662. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53376/60000][Iteration 834][Wall Clock 114.391997019s] Trained 64 records in 0.178700173 seconds. Throughput is 358.14178 records/second. Loss is 0.22879046. Sequential2290a28's hyper parameters: Current learning rate is 0.01714383679067375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53440/60000][Iteration 835][Wall Clock 114.53429551s] Trained 64 records in 0.142298491 seconds. Throughput is 449.75882 records/second. Loss is 0.4311712. Sequential2290a28's hyper parameters: Current learning rate is 0.01714089818306479. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 836][Wall Clock 114.637166557s] Trained 64 records in 0.102871047 seconds. Throughput is 622.1381 records/second. Loss is 0.38197213. Sequential2290a28's hyper parameters: Current learning rate is 0.01713796058269066. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53568/60000][Iteration 837][Wall Clock 114.742718629s] Trained 64 records in 0.105552072 seconds. Throughput is 606.3358 records/second. Loss is 0.28397113. Sequential2290a28's hyper parameters: Current learning rate is 0.017135023989033583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53632/60000][Iteration 838][Wall Clock 114.896025879s] Trained 64 records in 0.15330725 seconds. Throughput is 417.46234 records/second. Loss is 0.3128742. Sequential2290a28's hyper parameters: Current learning rate is 0.01713208840157615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:36 INFO  DistriOptimizer$:408 - [Epoch 1 53696/60000][Iteration 839][Wall Clock 115.025633423s] Trained 64 records in 0.129607544 seconds. Throughput is 493.79843 records/second. Loss is 0.41610587. Sequential2290a28's hyper parameters: Current learning rate is 0.0171291538198013. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 840][Wall Clock 115.107441243s] Trained 64 records in 0.08180782 seconds. Throughput is 782.3213 records/second. Loss is 0.32409942. Sequential2290a28's hyper parameters: Current learning rate is 0.01712622024319233. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 53824/60000][Iteration 841][Wall Clock 115.220435037s] Trained 64 records in 0.112993794 seconds. Throughput is 566.4028 records/second. Loss is 0.33158457. Sequential2290a28's hyper parameters: Current learning rate is 0.01712328767123288. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 53888/60000][Iteration 842][Wall Clock 115.333647813s] Trained 64 records in 0.113212776 seconds. Throughput is 565.3072 records/second. Loss is 0.34548473. Sequential2290a28's hyper parameters: Current learning rate is 0.01712035610340695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 53952/60000][Iteration 843][Wall Clock 115.418288166s] Trained 64 records in 0.084640353 seconds. Throughput is 756.1405 records/second. Loss is 0.43120384. Sequential2290a28's hyper parameters: Current learning rate is 0.017117425539198903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 844][Wall Clock 115.526444648s] Trained 64 records in 0.108156482 seconds. Throughput is 591.7352 records/second. Loss is 0.28666025. Sequential2290a28's hyper parameters: Current learning rate is 0.017114495978093443. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 54080/60000][Iteration 845][Wall Clock 115.628101343s] Trained 64 records in 0.101656695 seconds. Throughput is 629.56995 records/second. Loss is 0.5419478. Sequential2290a28's hyper parameters: Current learning rate is 0.017111567419575632. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 54144/60000][Iteration 846][Wall Clock 115.770128734s] Trained 64 records in 0.142027391 seconds. Throughput is 450.6173 records/second. Loss is 0.43942595. Sequential2290a28's hyper parameters: Current learning rate is 0.01710863986313088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:37 INFO  DistriOptimizer$:408 - [Epoch 1 54208/60000][Iteration 847][Wall Clock 115.905941155s] Trained 64 records in 0.135812421 seconds. Throughput is 471.23822 records/second. Loss is 0.4069927. Sequential2290a28's hyper parameters: Current learning rate is 0.017105713308244955. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 848][Wall Clock 116.043210991s] Trained 64 records in 0.137269836 seconds. Throughput is 466.235 records/second. Loss is 0.37877488. Sequential2290a28's hyper parameters: Current learning rate is 0.017102787754403968. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54336/60000][Iteration 849][Wall Clock 116.131735416s] Trained 64 records in 0.088524425 seconds. Throughput is 722.9643 records/second. Loss is 0.33945623. Sequential2290a28's hyper parameters: Current learning rate is 0.01709986320109439. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54400/60000][Iteration 850][Wall Clock 116.287391122s] Trained 64 records in 0.155655706 seconds. Throughput is 411.16385 records/second. Loss is 0.3668163. Sequential2290a28's hyper parameters: Current learning rate is 0.017096939647803046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54464/60000][Iteration 851][Wall Clock 116.389163096s] Trained 64 records in 0.101771974 seconds. Throughput is 628.8568 records/second. Loss is 0.35056314. Sequential2290a28's hyper parameters: Current learning rate is 0.017094017094017096. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 852][Wall Clock 116.49452026s] Trained 64 records in 0.105357164 seconds. Throughput is 607.4575 records/second. Loss is 0.4108375. Sequential2290a28's hyper parameters: Current learning rate is 0.017091095539224065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54592/60000][Iteration 853][Wall Clock 116.590191802s] Trained 64 records in 0.095671542 seconds. Throughput is 668.95544 records/second. Loss is 0.25667793. Sequential2290a28's hyper parameters: Current learning rate is 0.017088174982911826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54656/60000][Iteration 854][Wall Clock 116.686583008s] Trained 64 records in 0.096391206 seconds. Throughput is 663.96094 records/second. Loss is 0.48017716. Sequential2290a28's hyper parameters: Current learning rate is 0.017085255424568596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54720/60000][Iteration 855][Wall Clock 116.78673494s] Trained 64 records in 0.100151932 seconds. Throughput is 639.0291 records/second. Loss is 0.31663278. Sequential2290a28's hyper parameters: Current learning rate is 0.01708233686368295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 856][Wall Clock 116.88430144s] Trained 64 records in 0.0975665 seconds. Throughput is 655.9628 records/second. Loss is 0.57963175. Sequential2290a28's hyper parameters: Current learning rate is 0.017079419299743808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:38 INFO  DistriOptimizer$:408 - [Epoch 1 54848/60000][Iteration 857][Wall Clock 116.974985252s] Trained 64 records in 0.090683812 seconds. Throughput is 705.7489 records/second. Loss is 0.45260525. Sequential2290a28's hyper parameters: Current learning rate is 0.01707650273224044. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 54912/60000][Iteration 858][Wall Clock 117.054637005s] Trained 64 records in 0.079651753 seconds. Throughput is 803.49774 records/second. Loss is 0.37753603. Sequential2290a28's hyper parameters: Current learning rate is 0.017073587160662457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 54976/60000][Iteration 859][Wall Clock 117.14567458s] Trained 64 records in 0.091037575 seconds. Throughput is 703.0065 records/second. Loss is 0.36226922. Sequential2290a28's hyper parameters: Current learning rate is 0.01707067258449983. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 860][Wall Clock 117.298227138s] Trained 64 records in 0.152552558 seconds. Throughput is 419.52753 records/second. Loss is 0.24800625. Sequential2290a28's hyper parameters: Current learning rate is 0.017067759003242877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55104/60000][Iteration 861][Wall Clock 117.45367411s] Trained 64 records in 0.155446972 seconds. Throughput is 411.71594 records/second. Loss is 0.3446696. Sequential2290a28's hyper parameters: Current learning rate is 0.017064846416382253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55168/60000][Iteration 862][Wall Clock 117.612886115s] Trained 64 records in 0.159212005 seconds. Throughput is 401.97974 records/second. Loss is 0.542405. Sequential2290a28's hyper parameters: Current learning rate is 0.017061934823408974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55232/60000][Iteration 863][Wall Clock 117.698831238s] Trained 64 records in 0.085945123 seconds. Throughput is 744.66125 records/second. Loss is 0.4016772. Sequential2290a28's hyper parameters: Current learning rate is 0.017059024223814397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 864][Wall Clock 117.779539589s] Trained 64 records in 0.080708351 seconds. Throughput is 792.97864 records/second. Loss is 0.37393343. Sequential2290a28's hyper parameters: Current learning rate is 0.017056114617090227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55360/60000][Iteration 865][Wall Clock 117.869522464s] Trained 64 records in 0.089982875 seconds. Throughput is 711.24646 records/second. Loss is 0.5211992. Sequential2290a28's hyper parameters: Current learning rate is 0.017053206002728513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:39 INFO  DistriOptimizer$:408 - [Epoch 1 55424/60000][Iteration 866][Wall Clock 117.952152427s] Trained 64 records in 0.082629963 seconds. Throughput is 774.5374 records/second. Loss is 0.24036616. Sequential2290a28's hyper parameters: Current learning rate is 0.017050298380221655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55488/60000][Iteration 867][Wall Clock 118.025927166s] Trained 64 records in 0.073774739 seconds. Throughput is 867.5056 records/second. Loss is 0.34464714. Sequential2290a28's hyper parameters: Current learning rate is 0.017047391749062394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 868][Wall Clock 118.108466163s] Trained 64 records in 0.082538997 seconds. Throughput is 775.39105 records/second. Loss is 0.54300594. Sequential2290a28's hyper parameters: Current learning rate is 0.01704448610874382. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55616/60000][Iteration 869][Wall Clock 118.20548002s] Trained 64 records in 0.097013857 seconds. Throughput is 659.6996 records/second. Loss is 0.37217522. Sequential2290a28's hyper parameters: Current learning rate is 0.017041581458759374. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55680/60000][Iteration 870][Wall Clock 118.3398038s] Trained 64 records in 0.13432378 seconds. Throughput is 476.4607 records/second. Loss is 0.2780254. Sequential2290a28's hyper parameters: Current learning rate is 0.01703867779860283. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55744/60000][Iteration 871][Wall Clock 118.41273717s] Trained 64 records in 0.07293337 seconds. Throughput is 877.5133 records/second. Loss is 0.2868907. Sequential2290a28's hyper parameters: Current learning rate is 0.017035775127768316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 872][Wall Clock 118.515313347s] Trained 64 records in 0.102576177 seconds. Throughput is 623.9266 records/second. Loss is 0.32812998. Sequential2290a28's hyper parameters: Current learning rate is 0.017032873445750298. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55872/60000][Iteration 873][Wall Clock 118.598309879s] Trained 64 records in 0.082996532 seconds. Throughput is 771.1166 records/second. Loss is 0.35935307. Sequential2290a28's hyper parameters: Current learning rate is 0.0170299727520436. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 55936/60000][Iteration 874][Wall Clock 118.715531999s] Trained 64 records in 0.11722212 seconds. Throughput is 545.97205 records/second. Loss is 0.34928268. Sequential2290a28's hyper parameters: Current learning rate is 0.017027073046143367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 56000/60000][Iteration 875][Wall Clock 118.845552412s] Trained 64 records in 0.130020413 seconds. Throughput is 492.2304 records/second. Loss is 0.31552398. Sequential2290a28's hyper parameters: Current learning rate is 0.017024174327545112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:40 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 876][Wall Clock 118.927363637s] Trained 64 records in 0.081811225 seconds. Throughput is 782.2887 records/second. Loss is 0.38009268. Sequential2290a28's hyper parameters: Current learning rate is 0.01702127659574468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56128/60000][Iteration 877][Wall Clock 119.041753524s] Trained 64 records in 0.114389887 seconds. Throughput is 559.49 records/second. Loss is 0.4093582. Sequential2290a28's hyper parameters: Current learning rate is 0.01701837985023826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56192/60000][Iteration 878][Wall Clock 119.120835704s] Trained 64 records in 0.07908218 seconds. Throughput is 809.28467 records/second. Loss is 0.29655236. Sequential2290a28's hyper parameters: Current learning rate is 0.017015484090522375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56256/60000][Iteration 879][Wall Clock 119.206696353s] Trained 64 records in 0.085860649 seconds. Throughput is 745.39386 records/second. Loss is 0.34195104. Sequential2290a28's hyper parameters: Current learning rate is 0.01701258931609391. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 880][Wall Clock 119.302161992s] Trained 64 records in 0.095465639 seconds. Throughput is 670.3983 records/second. Loss is 0.42857984. Sequential2290a28's hyper parameters: Current learning rate is 0.017009695526450076. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56384/60000][Iteration 881][Wall Clock 119.40172807s] Trained 64 records in 0.099566078 seconds. Throughput is 642.7892 records/second. Loss is 0.28819042. Sequential2290a28's hyper parameters: Current learning rate is 0.017006802721088437. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56448/60000][Iteration 882][Wall Clock 119.504493784s] Trained 64 records in 0.102765714 seconds. Throughput is 622.77576 records/second. Loss is 0.42082098. Sequential2290a28's hyper parameters: Current learning rate is 0.01700391089950689. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56512/60000][Iteration 883][Wall Clock 119.644501572s] Trained 64 records in 0.140007788 seconds. Throughput is 457.1174 records/second. Loss is 0.40549955. Sequential2290a28's hyper parameters: Current learning rate is 0.01700102006120367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 884][Wall Clock 119.751763062s] Trained 64 records in 0.10726149 seconds. Throughput is 596.67267 records/second. Loss is 0.3056458. Sequential2290a28's hyper parameters: Current learning rate is 0.016998130205677375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56640/60000][Iteration 885][Wall Clock 119.893365121s] Trained 64 records in 0.141602059 seconds. Throughput is 451.97086 records/second. Loss is 0.3824086. Sequential2290a28's hyper parameters: Current learning rate is 0.01699524133242692. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:41 INFO  DistriOptimizer$:408 - [Epoch 1 56704/60000][Iteration 886][Wall Clock 119.975980684s] Trained 64 records in 0.082615563 seconds. Throughput is 774.6724 records/second. Loss is 0.36205935. Sequential2290a28's hyper parameters: Current learning rate is 0.016992353440951572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 56768/60000][Iteration 887][Wall Clock 120.083383128s] Trained 64 records in 0.107402444 seconds. Throughput is 595.8896 records/second. Loss is 0.2820914. Sequential2290a28's hyper parameters: Current learning rate is 0.016989466530750934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 888][Wall Clock 120.187585426s] Trained 64 records in 0.104202298 seconds. Throughput is 614.1899 records/second. Loss is 0.32922396. Sequential2290a28's hyper parameters: Current learning rate is 0.016986580601324953. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 56896/60000][Iteration 889][Wall Clock 120.274019289s] Trained 64 records in 0.086433863 seconds. Throughput is 740.4505 records/second. Loss is 0.39158544. Sequential2290a28's hyper parameters: Current learning rate is 0.016983695652173912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 56960/60000][Iteration 890][Wall Clock 120.352107964s] Trained 64 records in 0.078088675 seconds. Throughput is 819.58105 records/second. Loss is 0.25905025. Sequential2290a28's hyper parameters: Current learning rate is 0.016980811682798438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 57024/60000][Iteration 891][Wall Clock 120.436780004s] Trained 64 records in 0.08467204 seconds. Throughput is 755.85754 records/second. Loss is 0.24949971. Sequential2290a28's hyper parameters: Current learning rate is 0.01697792869269949. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 892][Wall Clock 120.559390967s] Trained 64 records in 0.122610963 seconds. Throughput is 521.97614 records/second. Loss is 0.2978617. Sequential2290a28's hyper parameters: Current learning rate is 0.016975046681378374. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 57152/60000][Iteration 893][Wall Clock 120.680689296s] Trained 64 records in 0.121298329 seconds. Throughput is 527.62476 records/second. Loss is 0.26824164. Sequential2290a28's hyper parameters: Current learning rate is 0.01697216564833673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 57216/60000][Iteration 894][Wall Clock 120.788663969s] Trained 64 records in 0.107974673 seconds. Throughput is 592.7316 records/second. Loss is 0.188494. Sequential2290a28's hyper parameters: Current learning rate is 0.01696928559307653. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 57280/60000][Iteration 895][Wall Clock 120.898522727s] Trained 64 records in 0.109858758 seconds. Throughput is 582.5662 records/second. Loss is 0.4205644. Sequential2290a28's hyper parameters: Current learning rate is 0.0169664065151001. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:42 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 896][Wall Clock 120.987165779s] Trained 64 records in 0.088643052 seconds. Throughput is 721.9968 records/second. Loss is 0.4782812. Sequential2290a28's hyper parameters: Current learning rate is 0.016963528413910092. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57408/60000][Iteration 897][Wall Clock 121.076855029s] Trained 64 records in 0.08968925 seconds. Throughput is 713.57495 records/second. Loss is 0.32110775. Sequential2290a28's hyper parameters: Current learning rate is 0.016960651289009497. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57472/60000][Iteration 898][Wall Clock 121.156346564s] Trained 64 records in 0.079491535 seconds. Throughput is 805.1172 records/second. Loss is 0.31646222. Sequential2290a28's hyper parameters: Current learning rate is 0.016957775139901644. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57536/60000][Iteration 899][Wall Clock 121.268017965s] Trained 64 records in 0.111671401 seconds. Throughput is 573.11005 records/second. Loss is 0.33275843. Sequential2290a28's hyper parameters: Current learning rate is 0.0169548999660902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 900][Wall Clock 121.362392827s] Trained 64 records in 0.094374862 seconds. Throughput is 678.14667 records/second. Loss is 0.3684575. Sequential2290a28's hyper parameters: Current learning rate is 0.016952025767079167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57664/60000][Iteration 901][Wall Clock 121.494024906s] Trained 64 records in 0.131632079 seconds. Throughput is 486.20367 records/second. Loss is 0.5594286. Sequential2290a28's hyper parameters: Current learning rate is 0.01694915254237288. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57728/60000][Iteration 902][Wall Clock 121.677391582s] Trained 64 records in 0.183366676 seconds. Throughput is 349.02744 records/second. Loss is 0.36176816. Sequential2290a28's hyper parameters: Current learning rate is 0.01694628029147602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57792/60000][Iteration 903][Wall Clock 121.822024217s] Trained 64 records in 0.144632635 seconds. Throughput is 442.5004 records/second. Loss is 0.38866973. Sequential2290a28's hyper parameters: Current learning rate is 0.016943409013893594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 904][Wall Clock 121.908508829s] Trained 64 records in 0.086484612 seconds. Throughput is 740.01605 records/second. Loss is 0.36914495. Sequential2290a28's hyper parameters: Current learning rate is 0.01694053870913095. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:43 INFO  DistriOptimizer$:408 - [Epoch 1 57920/60000][Iteration 905][Wall Clock 122.000155182s] Trained 64 records in 0.091646353 seconds. Throughput is 698.3366 records/second. Loss is 0.3699342. Sequential2290a28's hyper parameters: Current learning rate is 0.016937669376693765. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 57984/60000][Iteration 906][Wall Clock 122.104271945s] Trained 64 records in 0.104116763 seconds. Throughput is 614.6945 records/second. Loss is 0.3567278. Sequential2290a28's hyper parameters: Current learning rate is 0.01693480101608806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58048/60000][Iteration 907][Wall Clock 122.251426046s] Trained 64 records in 0.147154101 seconds. Throughput is 434.9182 records/second. Loss is 0.24557468. Sequential2290a28's hyper parameters: Current learning rate is 0.016931933626820182. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 908][Wall Clock 122.385237001s] Trained 64 records in 0.133810955 seconds. Throughput is 478.2867 records/second. Loss is 0.23069552. Sequential2290a28's hyper parameters: Current learning rate is 0.016929067208396816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58176/60000][Iteration 909][Wall Clock 122.468725411s] Trained 64 records in 0.08348841 seconds. Throughput is 766.5734 records/second. Loss is 0.44059557. Sequential2290a28's hyper parameters: Current learning rate is 0.016926201760324985. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58240/60000][Iteration 910][Wall Clock 122.567718593s] Trained 64 records in 0.098993182 seconds. Throughput is 646.50916 records/second. Loss is 0.25738978. Sequential2290a28's hyper parameters: Current learning rate is 0.016923337282112032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58304/60000][Iteration 911][Wall Clock 122.703792194s] Trained 64 records in 0.136073601 seconds. Throughput is 470.33368 records/second. Loss is 0.3140685. Sequential2290a28's hyper parameters: Current learning rate is 0.01692047377326565. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 912][Wall Clock 122.792468693s] Trained 64 records in 0.088676499 seconds. Throughput is 721.7245 records/second. Loss is 0.34513295. Sequential2290a28's hyper parameters: Current learning rate is 0.01691761123329386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58432/60000][Iteration 913][Wall Clock 122.877687933s] Trained 64 records in 0.08521924 seconds. Throughput is 751.0041 records/second. Loss is 0.3244859. Sequential2290a28's hyper parameters: Current learning rate is 0.01691474966170501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:44 INFO  DistriOptimizer$:408 - [Epoch 1 58496/60000][Iteration 914][Wall Clock 122.958136201s] Trained 64 records in 0.080448268 seconds. Throughput is 795.5423 records/second. Loss is 0.3733451. Sequential2290a28's hyper parameters: Current learning rate is 0.01691188905800778. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58560/60000][Iteration 915][Wall Clock 123.063477148s] Trained 64 records in 0.105340947 seconds. Throughput is 607.551 records/second. Loss is 0.35079926. Sequential2290a28's hyper parameters: Current learning rate is 0.016909029421711193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 916][Wall Clock 123.166478491s] Trained 64 records in 0.103001343 seconds. Throughput is 621.35114 records/second. Loss is 0.38617897. Sequential2290a28's hyper parameters: Current learning rate is 0.016906170752324597. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58688/60000][Iteration 917][Wall Clock 123.261941171s] Trained 64 records in 0.09546268 seconds. Throughput is 670.41907 records/second. Loss is 0.22904456. Sequential2290a28's hyper parameters: Current learning rate is 0.016903313049357674. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58752/60000][Iteration 918][Wall Clock 123.357099672s] Trained 64 records in 0.095158501 seconds. Throughput is 672.5621 records/second. Loss is 0.252242. Sequential2290a28's hyper parameters: Current learning rate is 0.016900456312320435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58816/60000][Iteration 919][Wall Clock 123.435399389s] Trained 64 records in 0.078299717 seconds. Throughput is 817.3721 records/second. Loss is 0.34226638. Sequential2290a28's hyper parameters: Current learning rate is 0.01689760054072322. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 920][Wall Clock 123.52688786s] Trained 64 records in 0.091488471 seconds. Throughput is 699.5417 records/second. Loss is 0.1990778. Sequential2290a28's hyper parameters: Current learning rate is 0.0168947457340767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 58944/60000][Iteration 921][Wall Clock 123.630893947s] Trained 64 records in 0.104006087 seconds. Throughput is 615.3486 records/second. Loss is 0.24396366. Sequential2290a28's hyper parameters: Current learning rate is 0.016891891891891893. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 59008/60000][Iteration 922][Wall Clock 123.730559429s] Trained 64 records in 0.099665482 seconds. Throughput is 642.1481 records/second. Loss is 0.26203936. Sequential2290a28's hyper parameters: Current learning rate is 0.016889039013680125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 59072/60000][Iteration 923][Wall Clock 123.813680888s] Trained 64 records in 0.083121459 seconds. Throughput is 769.95764 records/second. Loss is 0.40450504. Sequential2290a28's hyper parameters: Current learning rate is 0.016886187098953055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:45 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 924][Wall Clock 123.886950318s] Trained 64 records in 0.07326943 seconds. Throughput is 873.48846 records/second. Loss is 0.23804516. Sequential2290a28's hyper parameters: Current learning rate is 0.01688333614722269. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59200/60000][Iteration 925][Wall Clock 123.994320031s] Trained 64 records in 0.107369713 seconds. Throughput is 596.0712 records/second. Loss is 0.43651637. Sequential2290a28's hyper parameters: Current learning rate is 0.016880486158001348. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59264/60000][Iteration 926][Wall Clock 124.091149116s] Trained 64 records in 0.096829085 seconds. Throughput is 660.95844 records/second. Loss is 0.35947508. Sequential2290a28's hyper parameters: Current learning rate is 0.016877637130801686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59328/60000][Iteration 927][Wall Clock 124.175806051s] Trained 64 records in 0.084656935 seconds. Throughput is 755.99243 records/second. Loss is 0.29119635. Sequential2290a28's hyper parameters: Current learning rate is 0.016874789065136685. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 928][Wall Clock 124.257968431s] Trained 64 records in 0.08216238 seconds. Throughput is 778.9453 records/second. Loss is 0.26105946. Sequential2290a28's hyper parameters: Current learning rate is 0.016871941960519655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59456/60000][Iteration 929][Wall Clock 124.345548747s] Trained 64 records in 0.087580316 seconds. Throughput is 730.7578 records/second. Loss is 0.2736894. Sequential2290a28's hyper parameters: Current learning rate is 0.016869095816464237. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59520/60000][Iteration 930][Wall Clock 124.482403032s] Trained 64 records in 0.136854285 seconds. Throughput is 467.65067 records/second. Loss is 0.57356566. Sequential2290a28's hyper parameters: Current learning rate is 0.0168662506324844. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59584/60000][Iteration 931][Wall Clock 124.59607252s] Trained 64 records in 0.113669488 seconds. Throughput is 563.0359 records/second. Loss is 0.17431906. Sequential2290a28's hyper parameters: Current learning rate is 0.016863406408094438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 932][Wall Clock 124.683182972s] Trained 64 records in 0.087110452 seconds. Throughput is 734.69946 records/second. Loss is 0.516328. Sequential2290a28's hyper parameters: Current learning rate is 0.01686056314280897. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59712/60000][Iteration 933][Wall Clock 124.776619793s] Trained 64 records in 0.093436821 seconds. Throughput is 684.9548 records/second. Loss is 0.41975728. Sequential2290a28's hyper parameters: Current learning rate is 0.016857720836142957. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59776/60000][Iteration 934][Wall Clock 124.851513677s] Trained 64 records in 0.074893884 seconds. Throughput is 854.5424 records/second. Loss is 0.43455416. Sequential2290a28's hyper parameters: Current learning rate is 0.016854879487611663. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:46 INFO  DistriOptimizer$:408 - [Epoch 1 59840/60000][Iteration 935][Wall Clock 124.956493809s] Trained 64 records in 0.104980132 seconds. Throughput is 609.63916 records/second. Loss is 0.5280701. Sequential2290a28's hyper parameters: Current learning rate is 0.016852039096730703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:47 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 936][Wall Clock 125.084935268s] Trained 64 records in 0.128441459 seconds. Throughput is 498.2815 records/second. Loss is 0.51971376. Sequential2290a28's hyper parameters: Current learning rate is 0.016849199663016005. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:47 INFO  DistriOptimizer$:408 - [Epoch 1 59968/60000][Iteration 937][Wall Clock 125.205351515s] Trained 64 records in 0.120416247 seconds. Throughput is 531.48975 records/second. Loss is 0.42343524. Sequential2290a28's hyper parameters: Current learning rate is 0.016846361185983826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:47 INFO  DistriOptimizer$:408 - [Epoch 1 60032/60000][Iteration 938][Wall Clock 125.317674459s] Trained 64 records in 0.112322944 seconds. Throughput is 569.78564 records/second. Loss is 0.43979353. Sequential2290a28's hyper parameters: Current learning rate is 0.01684352366515075. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:47 INFO  DistriOptimizer$:452 - [Epoch 1 60032/60000][Iteration 938][Wall Clock 125.317674459s] Epoch finished. Wall clock time is 126082.06356 ms
2019-10-24 03:15:47 INFO  DistriOptimizer$:111 - [Epoch 1 60032/60000][Iteration 938][Wall Clock 125.317674459s] Validate model...
2019-10-24 03:15:48 INFO  DistriOptimizer$:178 - [Epoch 1 60032/60000][Iteration 938][Wall Clock 125.317674459s] validate model throughput is 8791.496 records/second
2019-10-24 03:15:48 INFO  DistriOptimizer$:181 - [Epoch 1 60032/60000][Iteration 938][Wall Clock 125.317674459s] Top1Accuracy is Accuracy(correct: 9112, count: 10000, accuracy: 0.9112)
2019-10-24 03:15:48 INFO  DistriOptimizer$:221 - [Wall Clock 126.08206356s] Save model to /tmp/lenet5/20191024_031340
2019-10-24 03:15:48 INFO  DistriOptimizer$:226 - [Wall Clock 126.08206356s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@b5fef19 to /tmp/lenet5/20191024_031340
2019-10-24 03:15:48 INFO  DistriOptimizer$:408 - [Epoch 2 64/60000][Iteration 939][Wall Clock 126.225524817s] Trained 64 records in 0.143461257 seconds. Throughput is 446.11346 records/second. Loss is 0.17904311. Sequential2290a28's hyper parameters: Current learning rate is 0.016840687100033683. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:48 INFO  DistriOptimizer$:408 - [Epoch 2 128/60000][Iteration 940][Wall Clock 126.322765234s] Trained 64 records in 0.097240417 seconds. Throughput is 658.16254 records/second. Loss is 0.33849967. Sequential2290a28's hyper parameters: Current learning rate is 0.01683785149014986. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 192/60000][Iteration 941][Wall Clock 126.420196132s] Trained 64 records in 0.097430898 seconds. Throughput is 656.8758 records/second. Loss is 0.38472667. Sequential2290a28's hyper parameters: Current learning rate is 0.016835016835016835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 942][Wall Clock 126.515472542s] Trained 64 records in 0.09527641 seconds. Throughput is 671.7298 records/second. Loss is 0.3006986. Sequential2290a28's hyper parameters: Current learning rate is 0.016832183134152502. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 320/60000][Iteration 943][Wall Clock 126.592725475s] Trained 64 records in 0.077252933 seconds. Throughput is 828.4475 records/second. Loss is 0.40337935. Sequential2290a28's hyper parameters: Current learning rate is 0.016829350387075056. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 384/60000][Iteration 944][Wall Clock 126.701524449s] Trained 64 records in 0.108798974 seconds. Throughput is 588.24084 records/second. Loss is 0.28981084. Sequential2290a28's hyper parameters: Current learning rate is 0.016826518593303044. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 448/60000][Iteration 945][Wall Clock 126.803424417s] Trained 64 records in 0.101899968 seconds. Throughput is 628.06696 records/second. Loss is 0.3811844. Sequential2290a28's hyper parameters: Current learning rate is 0.016823687752355314. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 946][Wall Clock 126.900866439s] Trained 64 records in 0.097442022 seconds. Throughput is 656.8008 records/second. Loss is 0.36039788. Sequential2290a28's hyper parameters: Current learning rate is 0.01682085786375105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 576/60000][Iteration 947][Wall Clock 127.008002866s] Trained 64 records in 0.107136427 seconds. Throughput is 597.3692 records/second. Loss is 0.5190545. Sequential2290a28's hyper parameters: Current learning rate is 0.016818028927009756. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 640/60000][Iteration 948][Wall Clock 127.132551712s] Trained 64 records in 0.124548846 seconds. Throughput is 513.8546 records/second. Loss is 0.38461939. Sequential2290a28's hyper parameters: Current learning rate is 0.016815200941651252. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:49 INFO  DistriOptimizer$:408 - [Epoch 2 704/60000][Iteration 949][Wall Clock 127.239925103s] Trained 64 records in 0.107373391 seconds. Throughput is 596.05084 records/second. Loss is 0.23124671. Sequential2290a28's hyper parameters: Current learning rate is 0.016812373907195696. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 950][Wall Clock 127.360126777s] Trained 64 records in 0.120201674 seconds. Throughput is 532.4385 records/second. Loss is 0.26861197. Sequential2290a28's hyper parameters: Current learning rate is 0.01680954782316356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 832/60000][Iteration 951][Wall Clock 127.462382222s] Trained 64 records in 0.102255445 seconds. Throughput is 625.88354 records/second. Loss is 0.2862929. Sequential2290a28's hyper parameters: Current learning rate is 0.016806722689075633. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 896/60000][Iteration 952][Wall Clock 127.60818552s] Trained 64 records in 0.145803298 seconds. Throughput is 438.94754 records/second. Loss is 0.30250743. Sequential2290a28's hyper parameters: Current learning rate is 0.016803898504453036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 960/60000][Iteration 953][Wall Clock 127.717228594s] Trained 64 records in 0.109043074 seconds. Throughput is 586.924 records/second. Loss is 0.30542934. Sequential2290a28's hyper parameters: Current learning rate is 0.016801075268817207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 954][Wall Clock 127.822311671s] Trained 64 records in 0.105083077 seconds. Throughput is 609.04193 records/second. Loss is 0.36807215. Sequential2290a28's hyper parameters: Current learning rate is 0.016798252981689903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 1088/60000][Iteration 955][Wall Clock 127.927378627s] Trained 64 records in 0.105066956 seconds. Throughput is 609.1354 records/second. Loss is 0.35581738. Sequential2290a28's hyper parameters: Current learning rate is 0.016795431642593214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 1152/60000][Iteration 956][Wall Clock 128.042802712s] Trained 64 records in 0.115424085 seconds. Throughput is 554.477 records/second. Loss is 0.36585712. Sequential2290a28's hyper parameters: Current learning rate is 0.016792611251049538. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 1216/60000][Iteration 957][Wall Clock 128.121710775s] Trained 64 records in 0.078908063 seconds. Throughput is 811.0705 records/second. Loss is 0.44725335. Sequential2290a28's hyper parameters: Current learning rate is 0.0167897918065816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 958][Wall Clock 128.201150502s] Trained 64 records in 0.079439727 seconds. Throughput is 805.6422 records/second. Loss is 0.29108438. Sequential2290a28's hyper parameters: Current learning rate is 0.016786973308712438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:50 INFO  DistriOptimizer$:408 - [Epoch 2 1344/60000][Iteration 959][Wall Clock 128.279140215s] Trained 64 records in 0.077989713 seconds. Throughput is 820.62103 records/second. Loss is 0.39913666. Sequential2290a28's hyper parameters: Current learning rate is 0.016784155756965426. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1408/60000][Iteration 960][Wall Clock 128.382104436s] Trained 64 records in 0.102964221 seconds. Throughput is 621.57513 records/second. Loss is 0.2903608. Sequential2290a28's hyper parameters: Current learning rate is 0.01678133915086424. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1472/60000][Iteration 961][Wall Clock 128.490769198s] Trained 64 records in 0.108664762 seconds. Throughput is 588.9674 records/second. Loss is 0.2888004. Sequential2290a28's hyper parameters: Current learning rate is 0.016778523489932886. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 962][Wall Clock 128.628401705s] Trained 64 records in 0.137632507 seconds. Throughput is 465.00644 records/second. Loss is 0.3787784. Sequential2290a28's hyper parameters: Current learning rate is 0.01677570877369569. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1600/60000][Iteration 963][Wall Clock 128.710317498s] Trained 64 records in 0.081915793 seconds. Throughput is 781.2901 records/second. Loss is 0.35749933. Sequential2290a28's hyper parameters: Current learning rate is 0.01677289500167729. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1664/60000][Iteration 964][Wall Clock 128.793460674s] Trained 64 records in 0.083143176 seconds. Throughput is 769.75653 records/second. Loss is 0.33106172. Sequential2290a28's hyper parameters: Current learning rate is 0.01677008217340265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1728/60000][Iteration 965][Wall Clock 128.878110784s] Trained 64 records in 0.08465011 seconds. Throughput is 756.0534 records/second. Loss is 0.21124476. Sequential2290a28's hyper parameters: Current learning rate is 0.016767270288397047. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 966][Wall Clock 128.951976936s] Trained 64 records in 0.073866152 seconds. Throughput is 866.43207 records/second. Loss is 0.392582. Sequential2290a28's hyper parameters: Current learning rate is 0.016764459346186086. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1856/60000][Iteration 967][Wall Clock 129.032929988s] Trained 64 records in 0.080953052 seconds. Throughput is 790.58167 records/second. Loss is 0.28110844. Sequential2290a28's hyper parameters: Current learning rate is 0.016761649346295676. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1920/60000][Iteration 968][Wall Clock 129.104637628s] Trained 64 records in 0.07170764 seconds. Throughput is 892.51294 records/second. Loss is 0.31986964. Sequential2290a28's hyper parameters: Current learning rate is 0.016758840288252055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 1984/60000][Iteration 969][Wall Clock 129.192464268s] Trained 64 records in 0.08782664 seconds. Throughput is 728.7083 records/second. Loss is 0.47828603. Sequential2290a28's hyper parameters: Current learning rate is 0.01675603217158177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:51 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 970][Wall Clock 129.299099497s] Trained 64 records in 0.106635229 seconds. Throughput is 600.1769 records/second. Loss is 0.4239556. Sequential2290a28's hyper parameters: Current learning rate is 0.016753224995811694. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2112/60000][Iteration 971][Wall Clock 129.40727676s] Trained 64 records in 0.108177263 seconds. Throughput is 591.6216 records/second. Loss is 0.27083403. Sequential2290a28's hyper parameters: Current learning rate is 0.016750418760469014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2176/60000][Iteration 972][Wall Clock 129.482942808s] Trained 64 records in 0.075666048 seconds. Throughput is 845.8219 records/second. Loss is 0.29365578. Sequential2290a28's hyper parameters: Current learning rate is 0.01674761346508123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2240/60000][Iteration 973][Wall Clock 129.594817673s] Trained 64 records in 0.111874865 seconds. Throughput is 572.06775 records/second. Loss is 0.2939232. Sequential2290a28's hyper parameters: Current learning rate is 0.016744809109176157. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 974][Wall Clock 129.684150438s] Trained 64 records in 0.089332765 seconds. Throughput is 716.4224 records/second. Loss is 0.35200304. Sequential2290a28's hyper parameters: Current learning rate is 0.016742005692281934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2368/60000][Iteration 975][Wall Clock 129.757766855s] Trained 64 records in 0.073616417 seconds. Throughput is 869.37134 records/second. Loss is 0.3578443. Sequential2290a28's hyper parameters: Current learning rate is 0.016739203213927016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2432/60000][Iteration 976][Wall Clock 129.841747761s] Trained 64 records in 0.083980906 seconds. Throughput is 762.078 records/second. Loss is 0.25567707. Sequential2290a28's hyper parameters: Current learning rate is 0.016736401673640166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2496/60000][Iteration 977][Wall Clock 129.931759443s] Trained 64 records in 0.090011682 seconds. Throughput is 711.01886 records/second. Loss is 0.38729674. Sequential2290a28's hyper parameters: Current learning rate is 0.01673360107095047. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 978][Wall Clock 130.007122549s] Trained 64 records in 0.075363106 seconds. Throughput is 849.22186 records/second. Loss is 0.38276106. Sequential2290a28's hyper parameters: Current learning rate is 0.016730801405387317. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2624/60000][Iteration 979][Wall Clock 130.090340283s] Trained 64 records in 0.083217734 seconds. Throughput is 769.06683 records/second. Loss is 0.34020233. Sequential2290a28's hyper parameters: Current learning rate is 0.01672800267648043. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2688/60000][Iteration 980][Wall Clock 130.174145794s] Trained 64 records in 0.083805511 seconds. Throughput is 763.673 records/second. Loss is 0.36115152. Sequential2290a28's hyper parameters: Current learning rate is 0.016725204883759826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:52 INFO  DistriOptimizer$:408 - [Epoch 2 2752/60000][Iteration 981][Wall Clock 130.255706681s] Trained 64 records in 0.081560887 seconds. Throughput is 784.6898 records/second. Loss is 0.22034445. Sequential2290a28's hyper parameters: Current learning rate is 0.016722408026755856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 982][Wall Clock 130.355988053s] Trained 64 records in 0.100281372 seconds. Throughput is 638.2043 records/second. Loss is 0.37138084. Sequential2290a28's hyper parameters: Current learning rate is 0.016719612104999164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 2880/60000][Iteration 983][Wall Clock 130.439288905s] Trained 64 records in 0.083300852 seconds. Throughput is 768.2995 records/second. Loss is 0.4166811. Sequential2290a28's hyper parameters: Current learning rate is 0.016716817118020727. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 2944/60000][Iteration 984][Wall Clock 130.519023053s] Trained 64 records in 0.079734148 seconds. Throughput is 802.6674 records/second. Loss is 0.14524406. Sequential2290a28's hyper parameters: Current learning rate is 0.01671402306535183. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3008/60000][Iteration 985][Wall Clock 130.616965679s] Trained 64 records in 0.097942626 seconds. Throughput is 653.4438 records/second. Loss is 0.35811055. Sequential2290a28's hyper parameters: Current learning rate is 0.016711229946524065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 986][Wall Clock 130.697102344s] Trained 64 records in 0.080136665 seconds. Throughput is 798.6357 records/second. Loss is 0.32149297. Sequential2290a28's hyper parameters: Current learning rate is 0.01670843776106934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3136/60000][Iteration 987][Wall Clock 130.826003879s] Trained 64 records in 0.128901535 seconds. Throughput is 496.503 records/second. Loss is 0.29157922. Sequential2290a28's hyper parameters: Current learning rate is 0.01670564650851988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3200/60000][Iteration 988][Wall Clock 130.935872603s] Trained 64 records in 0.109868724 seconds. Throughput is 582.51337 records/second. Loss is 0.33504498. Sequential2290a28's hyper parameters: Current learning rate is 0.016702856188408218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3264/60000][Iteration 989][Wall Clock 131.056514795s] Trained 64 records in 0.120642192 seconds. Throughput is 530.4943 records/second. Loss is 0.27435532. Sequential2290a28's hyper parameters: Current learning rate is 0.016700066800267203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 990][Wall Clock 131.129752752s] Trained 64 records in 0.073237957 seconds. Throughput is 873.86383 records/second. Loss is 0.26140195. Sequential2290a28's hyper parameters: Current learning rate is 0.01669727834362999. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3392/60000][Iteration 991][Wall Clock 131.203318435s] Trained 64 records in 0.073565683 seconds. Throughput is 869.9708 records/second. Loss is 0.29911706. Sequential2290a28's hyper parameters: Current learning rate is 0.016694490818030053. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:53 INFO  DistriOptimizer$:408 - [Epoch 2 3456/60000][Iteration 992][Wall Clock 131.27855018s] Trained 64 records in 0.075231745 seconds. Throughput is 850.7047 records/second. Loss is 0.36790642. Sequential2290a28's hyper parameters: Current learning rate is 0.01669170422300117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3520/60000][Iteration 993][Wall Clock 131.35137274s] Trained 64 records in 0.07282256 seconds. Throughput is 878.8485 records/second. Loss is 0.23926976. Sequential2290a28's hyper parameters: Current learning rate is 0.01668891855807744. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 994][Wall Clock 131.425423562s] Trained 64 records in 0.074050822 seconds. Throughput is 864.2713 records/second. Loss is 0.3302105. Sequential2290a28's hyper parameters: Current learning rate is 0.01668613382279326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3648/60000][Iteration 995][Wall Clock 131.525829244s] Trained 64 records in 0.100405682 seconds. Throughput is 637.4141 records/second. Loss is 0.36126947. Sequential2290a28's hyper parameters: Current learning rate is 0.01668335001668335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3712/60000][Iteration 996][Wall Clock 131.631206221s] Trained 64 records in 0.105376977 seconds. Throughput is 607.3433 records/second. Loss is 0.38770992. Sequential2290a28's hyper parameters: Current learning rate is 0.016680567139282735. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3776/60000][Iteration 997][Wall Clock 131.725119101s] Trained 64 records in 0.09391288 seconds. Throughput is 681.48267 records/second. Loss is 0.39807615. Sequential2290a28's hyper parameters: Current learning rate is 0.01667778519012675. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 998][Wall Clock 131.820438882s] Trained 64 records in 0.095319781 seconds. Throughput is 671.42413 records/second. Loss is 0.2810154. Sequential2290a28's hyper parameters: Current learning rate is 0.01667500416875104. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3904/60000][Iteration 999][Wall Clock 131.902006335s] Trained 64 records in 0.081567453 seconds. Throughput is 784.6267 records/second. Loss is 0.28698915. Sequential2290a28's hyper parameters: Current learning rate is 0.016672224074691565. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 3968/60000][Iteration 1000][Wall Clock 131.971733811s] Trained 64 records in 0.069727476 seconds. Throughput is 917.8592 records/second. Loss is 0.3165593. Sequential2290a28's hyper parameters: Current learning rate is 0.016669444907484583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 4032/60000][Iteration 1001][Wall Clock 132.036828867s] Trained 64 records in 0.065095056 seconds. Throughput is 983.17755 records/second. Loss is 0.48597923. Sequential2290a28's hyper parameters: Current learning rate is 0.016666666666666666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 1002][Wall Clock 132.107373618s] Trained 64 records in 0.070544751 seconds. Throughput is 907.2256 records/second. Loss is 0.27524474. Sequential2290a28's hyper parameters: Current learning rate is 0.016663889351774704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 4160/60000][Iteration 1003][Wall Clock 132.176120605s] Trained 64 records in 0.068746987 seconds. Throughput is 930.94995 records/second. Loss is 0.28098005. Sequential2290a28's hyper parameters: Current learning rate is 0.016661112962345882. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:54 INFO  DistriOptimizer$:408 - [Epoch 2 4224/60000][Iteration 1004][Wall Clock 132.248143698s] Trained 64 records in 0.072023093 seconds. Throughput is 888.6039 records/second. Loss is 0.4112479. Sequential2290a28's hyper parameters: Current learning rate is 0.016658337497917706. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4288/60000][Iteration 1005][Wall Clock 132.324960557s] Trained 64 records in 0.076816859 seconds. Throughput is 833.15045 records/second. Loss is 0.43999445. Sequential2290a28's hyper parameters: Current learning rate is 0.016655562958027982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 1006][Wall Clock 132.407552734s] Trained 64 records in 0.082592177 seconds. Throughput is 774.89185 records/second. Loss is 0.36577225. Sequential2290a28's hyper parameters: Current learning rate is 0.01665278934221482. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4416/60000][Iteration 1007][Wall Clock 132.485361341s] Trained 64 records in 0.077808607 seconds. Throughput is 822.5311 records/second. Loss is 0.3788194. Sequential2290a28's hyper parameters: Current learning rate is 0.01665001665001665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4480/60000][Iteration 1008][Wall Clock 132.572007527s] Trained 64 records in 0.086646186 seconds. Throughput is 738.6361 records/second. Loss is 0.3001525. Sequential2290a28's hyper parameters: Current learning rate is 0.0166472448809722. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4544/60000][Iteration 1009][Wall Clock 132.652963548s] Trained 64 records in 0.080956021 seconds. Throughput is 790.5527 records/second. Loss is 0.3209139. Sequential2290a28's hyper parameters: Current learning rate is 0.016644474034620507. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 1010][Wall Clock 132.731494736s] Trained 64 records in 0.078531188 seconds. Throughput is 814.9628 records/second. Loss is 0.5618636. Sequential2290a28's hyper parameters: Current learning rate is 0.016641704110500914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4672/60000][Iteration 1011][Wall Clock 132.829927971s] Trained 64 records in 0.098433235 seconds. Throughput is 650.1869 records/second. Loss is 0.24700135. Sequential2290a28's hyper parameters: Current learning rate is 0.01663893510815308. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4736/60000][Iteration 1012][Wall Clock 132.917587931s] Trained 64 records in 0.08765996 seconds. Throughput is 730.0939 records/second. Loss is 0.4189191. Sequential2290a28's hyper parameters: Current learning rate is 0.016636167027116955. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4800/60000][Iteration 1013][Wall Clock 133.013026246s] Trained 64 records in 0.095438315 seconds. Throughput is 670.5902 records/second. Loss is 0.40431035. Sequential2290a28's hyper parameters: Current learning rate is 0.016633399866932803. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 1014][Wall Clock 133.119602809s] Trained 64 records in 0.106576563 seconds. Throughput is 600.50726 records/second. Loss is 0.29446584. Sequential2290a28's hyper parameters: Current learning rate is 0.016630633627141195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:55 INFO  DistriOptimizer$:408 - [Epoch 2 4928/60000][Iteration 1015][Wall Clock 133.235290656s] Trained 64 records in 0.115687847 seconds. Throughput is 553.2128 records/second. Loss is 0.36406523. Sequential2290a28's hyper parameters: Current learning rate is 0.016627868307283005. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 4992/60000][Iteration 1016][Wall Clock 133.328532346s] Trained 64 records in 0.09324169 seconds. Throughput is 686.38824 records/second. Loss is 0.3702296. Sequential2290a28's hyper parameters: Current learning rate is 0.01662510390689942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5056/60000][Iteration 1017][Wall Clock 133.456972214s] Trained 64 records in 0.128439868 seconds. Throughput is 498.28763 records/second. Loss is 0.2390472. Sequential2290a28's hyper parameters: Current learning rate is 0.016622340425531915. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 1018][Wall Clock 133.555492658s] Trained 64 records in 0.098520444 seconds. Throughput is 649.6114 records/second. Loss is 0.20351742. Sequential2290a28's hyper parameters: Current learning rate is 0.016619577862722286. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5184/60000][Iteration 1019][Wall Clock 133.635195415s] Trained 64 records in 0.079702757 seconds. Throughput is 802.9835 records/second. Loss is 0.27982754. Sequential2290a28's hyper parameters: Current learning rate is 0.01661681621801263. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5248/60000][Iteration 1020][Wall Clock 133.71040509s] Trained 64 records in 0.075209675 seconds. Throughput is 850.95435 records/second. Loss is 0.32188722. Sequential2290a28's hyper parameters: Current learning rate is 0.01661405549094534. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5312/60000][Iteration 1021][Wall Clock 133.79181678s] Trained 64 records in 0.08141169 seconds. Throughput is 786.12787 records/second. Loss is 0.36859873. Sequential2290a28's hyper parameters: Current learning rate is 0.016611295681063124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 1022][Wall Clock 133.87915374s] Trained 64 records in 0.08733696 seconds. Throughput is 732.794 records/second. Loss is 0.4968936. Sequential2290a28's hyper parameters: Current learning rate is 0.016608536787908985. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5440/60000][Iteration 1023][Wall Clock 133.973837185s] Trained 64 records in 0.094683445 seconds. Throughput is 675.9365 records/second. Loss is 0.42760515. Sequential2290a28's hyper parameters: Current learning rate is 0.016605778811026237. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5504/60000][Iteration 1024][Wall Clock 134.071311479s] Trained 64 records in 0.097474294 seconds. Throughput is 656.5834 records/second. Loss is 0.4701424. Sequential2290a28's hyper parameters: Current learning rate is 0.01660302174995849. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5568/60000][Iteration 1025][Wall Clock 134.188164682s] Trained 64 records in 0.116853203 seconds. Throughput is 547.69574 records/second. Loss is 0.33914605. Sequential2290a28's hyper parameters: Current learning rate is 0.016600265604249667. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:56 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 1026][Wall Clock 134.283226447s] Trained 64 records in 0.095061765 seconds. Throughput is 673.2465 records/second. Loss is 0.32694125. Sequential2290a28's hyper parameters: Current learning rate is 0.016597510373443983. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 5696/60000][Iteration 1027][Wall Clock 134.368910739s] Trained 64 records in 0.085684292 seconds. Throughput is 746.92804 records/second. Loss is 0.34343806. Sequential2290a28's hyper parameters: Current learning rate is 0.01659475605708596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 5760/60000][Iteration 1028][Wall Clock 134.457342322s] Trained 64 records in 0.088431583 seconds. Throughput is 723.7233 records/second. Loss is 0.20299895. Sequential2290a28's hyper parameters: Current learning rate is 0.016592002654720425. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 5824/60000][Iteration 1029][Wall Clock 134.538253487s] Trained 64 records in 0.080911165 seconds. Throughput is 790.99097 records/second. Loss is 0.4308788. Sequential2290a28's hyper parameters: Current learning rate is 0.0165892501658925. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 1030][Wall Clock 134.611530431s] Trained 64 records in 0.073276944 seconds. Throughput is 873.39886 records/second. Loss is 0.24029353. Sequential2290a28's hyper parameters: Current learning rate is 0.01658649859014762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 5952/60000][Iteration 1031][Wall Clock 134.689822306s] Trained 64 records in 0.078291875 seconds. Throughput is 817.45386 records/second. Loss is 0.39849868. Sequential2290a28's hyper parameters: Current learning rate is 0.01658374792703151. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 6016/60000][Iteration 1032][Wall Clock 134.778882169s] Trained 64 records in 0.089059863 seconds. Throughput is 718.6178 records/second. Loss is 0.43437663. Sequential2290a28's hyper parameters: Current learning rate is 0.0165809981760902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 6080/60000][Iteration 1033][Wall Clock 134.876567424s] Trained 64 records in 0.097685255 seconds. Throughput is 655.1654 records/second. Loss is 0.283359. Sequential2290a28's hyper parameters: Current learning rate is 0.016578249336870028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 1034][Wall Clock 134.949217592s] Trained 64 records in 0.072650168 seconds. Throughput is 880.934 records/second. Loss is 0.37988615. Sequential2290a28's hyper parameters: Current learning rate is 0.01657550140891762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 6208/60000][Iteration 1035][Wall Clock 135.024508565s] Trained 64 records in 0.075290973 seconds. Throughput is 850.0355 records/second. Loss is 0.34499007. Sequential2290a28's hyper parameters: Current learning rate is 0.016572754391779913. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 6272/60000][Iteration 1036][Wall Clock 135.131487808s] Trained 64 records in 0.106979243 seconds. Throughput is 598.2469 records/second. Loss is 0.3962445. Sequential2290a28's hyper parameters: Current learning rate is 0.016570008285004142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:57 INFO  DistriOptimizer$:408 - [Epoch 2 6336/60000][Iteration 1037][Wall Clock 135.210429732s] Trained 64 records in 0.078941924 seconds. Throughput is 810.72253 records/second. Loss is 0.364751. Sequential2290a28's hyper parameters: Current learning rate is 0.01656726308813784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 1038][Wall Clock 135.335499131s] Trained 64 records in 0.125069399 seconds. Throughput is 511.7159 records/second. Loss is 0.31213176. Sequential2290a28's hyper parameters: Current learning rate is 0.016564518800728838. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6464/60000][Iteration 1039][Wall Clock 135.467938015s] Trained 64 records in 0.132438884 seconds. Throughput is 483.24176 records/second. Loss is 0.25317305. Sequential2290a28's hyper parameters: Current learning rate is 0.016561775422325273. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6528/60000][Iteration 1040][Wall Clock 135.55518283s] Trained 64 records in 0.087244815 seconds. Throughput is 733.56793 records/second. Loss is 0.427784. Sequential2290a28's hyper parameters: Current learning rate is 0.016559032952475575. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6592/60000][Iteration 1041][Wall Clock 135.633896823s] Trained 64 records in 0.078713993 seconds. Throughput is 813.0702 records/second. Loss is 0.3872624. Sequential2290a28's hyper parameters: Current learning rate is 0.016556291390728478. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 1042][Wall Clock 135.762989142s] Trained 64 records in 0.129092319 seconds. Throughput is 495.76923 records/second. Loss is 0.49942672. Sequential2290a28's hyper parameters: Current learning rate is 0.01655355073663301. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6720/60000][Iteration 1043][Wall Clock 135.88117924s] Trained 64 records in 0.118190098 seconds. Throughput is 541.50055 records/second. Loss is 0.4672907. Sequential2290a28's hyper parameters: Current learning rate is 0.0165508109897385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6784/60000][Iteration 1044][Wall Clock 135.981363757s] Trained 64 records in 0.100184517 seconds. Throughput is 638.8213 records/second. Loss is 0.4495708. Sequential2290a28's hyper parameters: Current learning rate is 0.01654807214959457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6848/60000][Iteration 1045][Wall Clock 136.086024031s] Trained 64 records in 0.104660274 seconds. Throughput is 611.5023 records/second. Loss is 0.3413052. Sequential2290a28's hyper parameters: Current learning rate is 0.01654533421575116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 1046][Wall Clock 136.172168636s] Trained 64 records in 0.086144605 seconds. Throughput is 742.9368 records/second. Loss is 0.32756668. Sequential2290a28's hyper parameters: Current learning rate is 0.016542597187758478. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:58 INFO  DistriOptimizer$:408 - [Epoch 2 6976/60000][Iteration 1047][Wall Clock 136.251498188s] Trained 64 records in 0.079329552 seconds. Throughput is 806.76117 records/second. Loss is 0.27129197. Sequential2290a28's hyper parameters: Current learning rate is 0.016539861065167052. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7040/60000][Iteration 1048][Wall Clock 136.397288182s] Trained 64 records in 0.145789994 seconds. Throughput is 438.9876 records/second. Loss is 0.35227066. Sequential2290a28's hyper parameters: Current learning rate is 0.0165371258475277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7104/60000][Iteration 1049][Wall Clock 136.511420434s] Trained 64 records in 0.114132252 seconds. Throughput is 560.7529 records/second. Loss is 0.23691425. Sequential2290a28's hyper parameters: Current learning rate is 0.016534391534391533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 1050][Wall Clock 136.605725762s] Trained 64 records in 0.094305328 seconds. Throughput is 678.64667 records/second. Loss is 0.24833268. Sequential2290a28's hyper parameters: Current learning rate is 0.01653165812530997. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7232/60000][Iteration 1051][Wall Clock 136.716476635s] Trained 64 records in 0.110750873 seconds. Throughput is 577.87354 records/second. Loss is 0.27537572. Sequential2290a28's hyper parameters: Current learning rate is 0.01652892561983471. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7296/60000][Iteration 1052][Wall Clock 136.797383379s] Trained 64 records in 0.080906744 seconds. Throughput is 791.0342 records/second. Loss is 0.28150335. Sequential2290a28's hyper parameters: Current learning rate is 0.016526194017517766. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7360/60000][Iteration 1053][Wall Clock 136.89444972s] Trained 64 records in 0.097066341 seconds. Throughput is 659.34283 records/second. Loss is 0.29145354. Sequential2290a28's hyper parameters: Current learning rate is 0.016523463317911435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 1054][Wall Clock 137.004475582s] Trained 64 records in 0.110025862 seconds. Throughput is 581.68146 records/second. Loss is 0.32642606. Sequential2290a28's hyper parameters: Current learning rate is 0.016520733520568313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7488/60000][Iteration 1055][Wall Clock 137.110123882s] Trained 64 records in 0.1056483 seconds. Throughput is 605.7835 records/second. Loss is 0.33848113. Sequential2290a28's hyper parameters: Current learning rate is 0.016518004625041292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:15:59 INFO  DistriOptimizer$:408 - [Epoch 2 7552/60000][Iteration 1056][Wall Clock 137.204532606s] Trained 64 records in 0.094408724 seconds. Throughput is 677.9035 records/second. Loss is 0.3981074. Sequential2290a28's hyper parameters: Current learning rate is 0.016515276630883566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 7616/60000][Iteration 1057][Wall Clock 137.298218095s] Trained 64 records in 0.093685489 seconds. Throughput is 683.1368 records/second. Loss is 0.34773594. Sequential2290a28's hyper parameters: Current learning rate is 0.01651254953764861. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 1058][Wall Clock 137.384869146s] Trained 64 records in 0.086651051 seconds. Throughput is 738.5946 records/second. Loss is 0.3287416. Sequential2290a28's hyper parameters: Current learning rate is 0.01650982334489021. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 7744/60000][Iteration 1059][Wall Clock 137.501181117s] Trained 64 records in 0.116311971 seconds. Throughput is 550.2443 records/second. Loss is 0.17291495. Sequential2290a28's hyper parameters: Current learning rate is 0.01650709805216243. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 7808/60000][Iteration 1060][Wall Clock 137.587331111s] Trained 64 records in 0.086149994 seconds. Throughput is 742.8904 records/second. Loss is 0.31190783. Sequential2290a28's hyper parameters: Current learning rate is 0.01650437365901964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 7872/60000][Iteration 1061][Wall Clock 137.679946705s] Trained 64 records in 0.092615594 seconds. Throughput is 691.0283 records/second. Loss is 0.3662951. Sequential2290a28's hyper parameters: Current learning rate is 0.016501650165016504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 1062][Wall Clock 137.834524225s] Trained 64 records in 0.15457752 seconds. Throughput is 414.03174 records/second. Loss is 0.432002. Sequential2290a28's hyper parameters: Current learning rate is 0.016498927569707972. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 8000/60000][Iteration 1063][Wall Clock 137.911209472s] Trained 64 records in 0.076685247 seconds. Throughput is 834.5803 records/second. Loss is 0.28713006. Sequential2290a28's hyper parameters: Current learning rate is 0.016496205872649293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 8064/60000][Iteration 1064][Wall Clock 137.990728125s] Trained 64 records in 0.079518653 seconds. Throughput is 804.8426 records/second. Loss is 0.40847397. Sequential2290a28's hyper parameters: Current learning rate is 0.016493485073396007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 8128/60000][Iteration 1065][Wall Clock 138.130394844s] Trained 64 records in 0.139666719 seconds. Throughput is 458.2337 records/second. Loss is 0.4672644. Sequential2290a28's hyper parameters: Current learning rate is 0.016490765171503958. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:00 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 1066][Wall Clock 138.239142875s] Trained 64 records in 0.108748031 seconds. Throughput is 588.5164 records/second. Loss is 0.401716. Sequential2290a28's hyper parameters: Current learning rate is 0.016488046166529265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8256/60000][Iteration 1067][Wall Clock 138.320664265s] Trained 64 records in 0.08152139 seconds. Throughput is 785.07 records/second. Loss is 0.22366425. Sequential2290a28's hyper parameters: Current learning rate is 0.016485328058028353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8320/60000][Iteration 1068][Wall Clock 138.466843458s] Trained 64 records in 0.146179193 seconds. Throughput is 437.8188 records/second. Loss is 0.50238246. Sequential2290a28's hyper parameters: Current learning rate is 0.016482610845557938. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8384/60000][Iteration 1069][Wall Clock 138.554211228s] Trained 64 records in 0.08736777 seconds. Throughput is 732.5356 records/second. Loss is 0.3556906. Sequential2290a28's hyper parameters: Current learning rate is 0.016479894528675015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 1070][Wall Clock 138.656091667s] Trained 64 records in 0.101880439 seconds. Throughput is 628.1873 records/second. Loss is 0.3609976. Sequential2290a28's hyper parameters: Current learning rate is 0.01647717910693689. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8512/60000][Iteration 1071][Wall Clock 138.796123218s] Trained 64 records in 0.140031551 seconds. Throughput is 457.0399 records/second. Loss is 0.2700622. Sequential2290a28's hyper parameters: Current learning rate is 0.016474464579901153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8576/60000][Iteration 1072][Wall Clock 138.887105609s] Trained 64 records in 0.090982391 seconds. Throughput is 703.4328 records/second. Loss is 0.3555432. Sequential2290a28's hyper parameters: Current learning rate is 0.01647175094712568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8640/60000][Iteration 1073][Wall Clock 138.970759915s] Trained 64 records in 0.083654306 seconds. Throughput is 765.0533 records/second. Loss is 0.37347013. Sequential2290a28's hyper parameters: Current learning rate is 0.016469038208168644. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 1074][Wall Clock 139.098805853s] Trained 64 records in 0.128045938 seconds. Throughput is 499.82065 records/second. Loss is 0.38697562. Sequential2290a28's hyper parameters: Current learning rate is 0.016466326362588508. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:01 INFO  DistriOptimizer$:408 - [Epoch 2 8768/60000][Iteration 1075][Wall Clock 139.214764913s] Trained 64 records in 0.11595906 seconds. Throughput is 551.9189 records/second. Loss is 0.31507385. Sequential2290a28's hyper parameters: Current learning rate is 0.016463615409944024. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 8832/60000][Iteration 1076][Wall Clock 139.340949441s] Trained 64 records in 0.126184528 seconds. Throughput is 507.19373 records/second. Loss is 0.4678447. Sequential2290a28's hyper parameters: Current learning rate is 0.016460905349794237. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 8896/60000][Iteration 1077][Wall Clock 139.462673875s] Trained 64 records in 0.121724434 seconds. Throughput is 525.7778 records/second. Loss is 0.2163938. Sequential2290a28's hyper parameters: Current learning rate is 0.016458196181698484. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 1078][Wall Clock 139.560797256s] Trained 64 records in 0.098123381 seconds. Throughput is 652.24005 records/second. Loss is 0.37332195. Sequential2290a28's hyper parameters: Current learning rate is 0.01645548790521639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 9024/60000][Iteration 1079][Wall Clock 139.656406588s] Trained 64 records in 0.095609332 seconds. Throughput is 669.39075 records/second. Loss is 0.3583408. Sequential2290a28's hyper parameters: Current learning rate is 0.016452780519907863. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 9088/60000][Iteration 1080][Wall Clock 139.809519803s] Trained 64 records in 0.153113215 seconds. Throughput is 417.99136 records/second. Loss is 0.5891143. Sequential2290a28's hyper parameters: Current learning rate is 0.016450074025333116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 9152/60000][Iteration 1081][Wall Clock 139.929241262s] Trained 64 records in 0.119721459 seconds. Throughput is 534.57416 records/second. Loss is 0.21152753. Sequential2290a28's hyper parameters: Current learning rate is 0.01644736842105263. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 1082][Wall Clock 140.008809693s] Trained 64 records in 0.079568431 seconds. Throughput is 804.3391 records/second. Loss is 0.21782446. Sequential2290a28's hyper parameters: Current learning rate is 0.0164446637066272. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 9280/60000][Iteration 1083][Wall Clock 140.115347184s] Trained 64 records in 0.106537491 seconds. Throughput is 600.7275 records/second. Loss is 0.30310592. Sequential2290a28's hyper parameters: Current learning rate is 0.01644195988161789. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:02 INFO  DistriOptimizer$:408 - [Epoch 2 9344/60000][Iteration 1084][Wall Clock 140.243033287s] Trained 64 records in 0.127686103 seconds. Throughput is 501.2292 records/second. Loss is 0.31357613. Sequential2290a28's hyper parameters: Current learning rate is 0.016439256945586057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9408/60000][Iteration 1085][Wall Clock 140.334526701s] Trained 64 records in 0.091493414 seconds. Throughput is 699.5039 records/second. Loss is 0.2606786. Sequential2290a28's hyper parameters: Current learning rate is 0.01643655489809336. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 1086][Wall Clock 140.427981392s] Trained 64 records in 0.093454691 seconds. Throughput is 684.82385 records/second. Loss is 0.3593563. Sequential2290a28's hyper parameters: Current learning rate is 0.016433853738701727. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9536/60000][Iteration 1087][Wall Clock 140.513275564s] Trained 64 records in 0.085294172 seconds. Throughput is 750.34436 records/second. Loss is 0.40904713. Sequential2290a28's hyper parameters: Current learning rate is 0.01643115346697338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9600/60000][Iteration 1088][Wall Clock 140.604176847s] Trained 64 records in 0.090901283 seconds. Throughput is 704.0604 records/second. Loss is 0.32724565. Sequential2290a28's hyper parameters: Current learning rate is 0.016428454082470838. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9664/60000][Iteration 1089][Wall Clock 140.692054919s] Trained 64 records in 0.087878072 seconds. Throughput is 728.2818 records/second. Loss is 0.32199693. Sequential2290a28's hyper parameters: Current learning rate is 0.0164257555847569. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 1090][Wall Clock 140.811323256s] Trained 64 records in 0.119268337 seconds. Throughput is 536.6051 records/second. Loss is 0.3813403. Sequential2290a28's hyper parameters: Current learning rate is 0.016423057973394647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9792/60000][Iteration 1091][Wall Clock 140.90794786s] Trained 64 records in 0.096624604 seconds. Throughput is 662.3572 records/second. Loss is 0.5563165. Sequential2290a28's hyper parameters: Current learning rate is 0.016420361247947456. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9856/60000][Iteration 1092][Wall Clock 141.024640573s] Trained 64 records in 0.116692713 seconds. Throughput is 548.449 records/second. Loss is 0.31550264. Sequential2290a28's hyper parameters: Current learning rate is 0.016417665407978985. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9920/60000][Iteration 1093][Wall Clock 141.145822247s] Trained 64 records in 0.121181674 seconds. Throughput is 528.1327 records/second. Loss is 0.36384672. Sequential2290a28's hyper parameters: Current learning rate is 0.016414970453053186. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:03 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 1094][Wall Clock 141.275772703s] Trained 64 records in 0.129950456 seconds. Throughput is 492.49542 records/second. Loss is 0.3223253. Sequential2290a28's hyper parameters: Current learning rate is 0.016412276382734285. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10048/60000][Iteration 1095][Wall Clock 141.406046297s] Trained 64 records in 0.130273594 seconds. Throughput is 491.27377 records/second. Loss is 0.2896041. Sequential2290a28's hyper parameters: Current learning rate is 0.016409583196586804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10112/60000][Iteration 1096][Wall Clock 141.514651268s] Trained 64 records in 0.108604971 seconds. Throughput is 589.2916 records/second. Loss is 0.23320505. Sequential2290a28's hyper parameters: Current learning rate is 0.016406890894175553. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10176/60000][Iteration 1097][Wall Clock 141.609713293s] Trained 64 records in 0.095062025 seconds. Throughput is 673.2446 records/second. Loss is 0.41506794. Sequential2290a28's hyper parameters: Current learning rate is 0.016404199475065617. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 1098][Wall Clock 141.706667861s] Trained 64 records in 0.096954568 seconds. Throughput is 660.10297 records/second. Loss is 0.56009007. Sequential2290a28's hyper parameters: Current learning rate is 0.016401508938822373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10304/60000][Iteration 1099][Wall Clock 141.787811723s] Trained 64 records in 0.081143862 seconds. Throughput is 788.7226 records/second. Loss is 0.35205472. Sequential2290a28's hyper parameters: Current learning rate is 0.016398819285011478. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10368/60000][Iteration 1100][Wall Clock 141.886386527s] Trained 64 records in 0.098574804 seconds. Throughput is 649.2531 records/second. Loss is 0.23515342. Sequential2290a28's hyper parameters: Current learning rate is 0.016396130513198885. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10432/60000][Iteration 1101][Wall Clock 142.001613244s] Trained 64 records in 0.115226717 seconds. Throughput is 555.42676 records/second. Loss is 0.3621022. Sequential2290a28's hyper parameters: Current learning rate is 0.01639344262295082. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:04 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 1102][Wall Clock 142.183623816s] Trained 64 records in 0.182010572 seconds. Throughput is 351.62793 records/second. Loss is 0.23645684. Sequential2290a28's hyper parameters: Current learning rate is 0.0163907556138338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10560/60000][Iteration 1103][Wall Clock 142.323991903s] Trained 64 records in 0.140368087 seconds. Throughput is 455.9441 records/second. Loss is 0.2684753. Sequential2290a28's hyper parameters: Current learning rate is 0.01638806948541462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10624/60000][Iteration 1104][Wall Clock 142.464975409s] Trained 64 records in 0.140983506 seconds. Throughput is 453.9538 records/second. Loss is 0.2850024. Sequential2290a28's hyper parameters: Current learning rate is 0.016385384237260363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10688/60000][Iteration 1105][Wall Clock 142.542885632s] Trained 64 records in 0.077910223 seconds. Throughput is 821.4583 records/second. Loss is 0.40061113. Sequential2290a28's hyper parameters: Current learning rate is 0.0163826998689384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 1106][Wall Clock 142.655877119s] Trained 64 records in 0.112991487 seconds. Throughput is 566.41437 records/second. Loss is 0.19163153. Sequential2290a28's hyper parameters: Current learning rate is 0.01638001638001638. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10816/60000][Iteration 1107][Wall Clock 142.797205207s] Trained 64 records in 0.141328088 seconds. Throughput is 452.84702 records/second. Loss is 0.28961167. Sequential2290a28's hyper parameters: Current learning rate is 0.016377333770062234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10880/60000][Iteration 1108][Wall Clock 142.912225056s] Trained 64 records in 0.115019849 seconds. Throughput is 556.4257 records/second. Loss is 0.39343968. Sequential2290a28's hyper parameters: Current learning rate is 0.016374652038644178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 10944/60000][Iteration 1109][Wall Clock 143.048338339s] Trained 64 records in 0.136113283 seconds. Throughput is 470.19656 records/second. Loss is 0.19707897. Sequential2290a28's hyper parameters: Current learning rate is 0.016371971185330715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 1110][Wall Clock 143.162998962s] Trained 64 records in 0.114660623 seconds. Throughput is 558.16895 records/second. Loss is 0.18396464. Sequential2290a28's hyper parameters: Current learning rate is 0.01636929120969062. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:05 INFO  DistriOptimizer$:408 - [Epoch 2 11072/60000][Iteration 1111][Wall Clock 143.250953491s] Trained 64 records in 0.087954529 seconds. Throughput is 727.64874 records/second. Loss is 0.2894098. Sequential2290a28's hyper parameters: Current learning rate is 0.016366612111292964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11136/60000][Iteration 1112][Wall Clock 143.351443318s] Trained 64 records in 0.100489827 seconds. Throughput is 636.8804 records/second. Loss is 0.28920066. Sequential2290a28's hyper parameters: Current learning rate is 0.016363933889707086. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11200/60000][Iteration 1113][Wall Clock 143.426810041s] Trained 64 records in 0.075366723 seconds. Throughput is 849.18115 records/second. Loss is 0.24711783. Sequential2290a28's hyper parameters: Current learning rate is 0.016361256544502618. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 1114][Wall Clock 143.510134969s] Trained 64 records in 0.083324928 seconds. Throughput is 768.07745 records/second. Loss is 0.22688234. Sequential2290a28's hyper parameters: Current learning rate is 0.01635858007524947. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11328/60000][Iteration 1115][Wall Clock 143.596649904s] Trained 64 records in 0.086514935 seconds. Throughput is 739.75665 records/second. Loss is 0.25366738. Sequential2290a28's hyper parameters: Current learning rate is 0.01635590448151783. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11392/60000][Iteration 1116][Wall Clock 143.705635024s] Trained 64 records in 0.10898512 seconds. Throughput is 587.23615 records/second. Loss is 0.52030075. Sequential2290a28's hyper parameters: Current learning rate is 0.016353229762878167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11456/60000][Iteration 1117][Wall Clock 143.810720209s] Trained 64 records in 0.105085185 seconds. Throughput is 609.0297 records/second. Loss is 0.31085405. Sequential2290a28's hyper parameters: Current learning rate is 0.016350555918901243. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 1118][Wall Clock 143.890798546s] Trained 64 records in 0.080078337 seconds. Throughput is 799.2174 records/second. Loss is 0.34887612. Sequential2290a28's hyper parameters: Current learning rate is 0.016347882949158083. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11584/60000][Iteration 1119][Wall Clock 143.983255564s] Trained 64 records in 0.092457018 seconds. Throughput is 692.21356 records/second. Loss is 0.33766478. Sequential2290a28's hyper parameters: Current learning rate is 0.016345210853220007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11648/60000][Iteration 1120][Wall Clock 144.090610306s] Trained 64 records in 0.107354742 seconds. Throughput is 596.15436 records/second. Loss is 0.2056047. Sequential2290a28's hyper parameters: Current learning rate is 0.016342539630658605. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:06 INFO  DistriOptimizer$:408 - [Epoch 2 11712/60000][Iteration 1121][Wall Clock 144.201081223s] Trained 64 records in 0.110470917 seconds. Throughput is 579.338 records/second. Loss is 0.30416414. Sequential2290a28's hyper parameters: Current learning rate is 0.016339869281045753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 1122][Wall Clock 144.333898079s] Trained 64 records in 0.132816856 seconds. Throughput is 481.86658 records/second. Loss is 0.28480294. Sequential2290a28's hyper parameters: Current learning rate is 0.016337199803953602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 11840/60000][Iteration 1123][Wall Clock 144.407283034s] Trained 64 records in 0.073384955 seconds. Throughput is 872.11334 records/second. Loss is 0.4804121. Sequential2290a28's hyper parameters: Current learning rate is 0.016334531198954592. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 11904/60000][Iteration 1124][Wall Clock 144.491029364s] Trained 64 records in 0.08374633 seconds. Throughput is 764.2126 records/second. Loss is 0.3434054. Sequential2290a28's hyper parameters: Current learning rate is 0.016331863465621425. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 11968/60000][Iteration 1125][Wall Clock 144.634933832s] Trained 64 records in 0.143904468 seconds. Throughput is 444.7395 records/second. Loss is 0.15597759. Sequential2290a28's hyper parameters: Current learning rate is 0.016329196603527104. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 1126][Wall Clock 144.816053274s] Trained 64 records in 0.181119442 seconds. Throughput is 353.35797 records/second. Loss is 0.37337723. Sequential2290a28's hyper parameters: Current learning rate is 0.016326530612244896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 12096/60000][Iteration 1127][Wall Clock 144.90344333s] Trained 64 records in 0.087390056 seconds. Throughput is 732.34875 records/second. Loss is 0.30408493. Sequential2290a28's hyper parameters: Current learning rate is 0.01632386549134835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 12160/60000][Iteration 1128][Wall Clock 145.048016484s] Trained 64 records in 0.144573154 seconds. Throughput is 442.68246 records/second. Loss is 0.36666557. Sequential2290a28's hyper parameters: Current learning rate is 0.016321201240411295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 12224/60000][Iteration 1129][Wall Clock 145.145342322s] Trained 64 records in 0.097325838 seconds. Throughput is 657.5849 records/second. Loss is 0.17417532. Sequential2290a28's hyper parameters: Current learning rate is 0.016318537859007835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:07 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 1130][Wall Clock 145.233328933s] Trained 64 records in 0.087986611 seconds. Throughput is 727.3834 records/second. Loss is 0.22676155. Sequential2290a28's hyper parameters: Current learning rate is 0.01631587534671235. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12352/60000][Iteration 1131][Wall Clock 145.311957257s] Trained 64 records in 0.078628324 seconds. Throughput is 813.95605 records/second. Loss is 0.27094486. Sequential2290a28's hyper parameters: Current learning rate is 0.016313213703099513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12416/60000][Iteration 1132][Wall Clock 145.391293932s] Trained 64 records in 0.079336675 seconds. Throughput is 806.6887 records/second. Loss is 0.17051576. Sequential2290a28's hyper parameters: Current learning rate is 0.016310552927744252. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12480/60000][Iteration 1133][Wall Clock 145.469329492s] Trained 64 records in 0.07803556 seconds. Throughput is 820.1389 records/second. Loss is 0.2607249. Sequential2290a28's hyper parameters: Current learning rate is 0.01630789302022179. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 1134][Wall Clock 145.556990243s] Trained 64 records in 0.087660751 seconds. Throughput is 730.0873 records/second. Loss is 0.19238104. Sequential2290a28's hyper parameters: Current learning rate is 0.016305233980107615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12608/60000][Iteration 1135][Wall Clock 145.652407378s] Trained 64 records in 0.095417135 seconds. Throughput is 670.7391 records/second. Loss is 0.3462346. Sequential2290a28's hyper parameters: Current learning rate is 0.016302575806977505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12672/60000][Iteration 1136][Wall Clock 145.73338707s] Trained 64 records in 0.080979692 seconds. Throughput is 790.3216 records/second. Loss is 0.46017072. Sequential2290a28's hyper parameters: Current learning rate is 0.016299918500407497. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12736/60000][Iteration 1137][Wall Clock 145.808511923s] Trained 64 records in 0.075124853 seconds. Throughput is 851.91516 records/second. Loss is 0.3061002. Sequential2290a28's hyper parameters: Current learning rate is 0.016297262059973925. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 1138][Wall Clock 145.913400924s] Trained 64 records in 0.104889001 seconds. Throughput is 610.1689 records/second. Loss is 0.4095217. Sequential2290a28's hyper parameters: Current learning rate is 0.016294606485253382. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12864/60000][Iteration 1139][Wall Clock 146.005450591s] Trained 64 records in 0.092049667 seconds. Throughput is 695.27686 records/second. Loss is 0.3001068. Sequential2290a28's hyper parameters: Current learning rate is 0.016291951775822745. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12928/60000][Iteration 1140][Wall Clock 146.106365628s] Trained 64 records in 0.100915037 seconds. Throughput is 634.19684 records/second. Loss is 0.3383692. Sequential2290a28's hyper parameters: Current learning rate is 0.016289297931259165. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:08 INFO  DistriOptimizer$:408 - [Epoch 2 12992/60000][Iteration 1141][Wall Clock 146.207388688s] Trained 64 records in 0.10102306 seconds. Throughput is 633.5187 records/second. Loss is 0.33095387. Sequential2290a28's hyper parameters: Current learning rate is 0.016286644951140065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 1142][Wall Clock 146.384140056s] Trained 64 records in 0.176751368 seconds. Throughput is 362.09055 records/second. Loss is 0.2302816. Sequential2290a28's hyper parameters: Current learning rate is 0.016283992835043153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13120/60000][Iteration 1143][Wall Clock 146.497803977s] Trained 64 records in 0.113663921 seconds. Throughput is 563.0635 records/second. Loss is 0.30730033. Sequential2290a28's hyper parameters: Current learning rate is 0.016281341582546405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13184/60000][Iteration 1144][Wall Clock 146.605952037s] Trained 64 records in 0.10814806 seconds. Throughput is 591.7813 records/second. Loss is 0.3483198. Sequential2290a28's hyper parameters: Current learning rate is 0.016278691193228067. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13248/60000][Iteration 1145][Wall Clock 146.693157137s] Trained 64 records in 0.0872051 seconds. Throughput is 733.90204 records/second. Loss is 0.4066583. Sequential2290a28's hyper parameters: Current learning rate is 0.016276041666666664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 1146][Wall Clock 146.816808645s] Trained 64 records in 0.123651508 seconds. Throughput is 517.5837 records/second. Loss is 0.26937616. Sequential2290a28's hyper parameters: Current learning rate is 0.01627339300244101. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13376/60000][Iteration 1147][Wall Clock 146.961009276s] Trained 64 records in 0.144200631 seconds. Throughput is 443.82605 records/second. Loss is 0.32776552. Sequential2290a28's hyper parameters: Current learning rate is 0.016270745200130166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13440/60000][Iteration 1148][Wall Clock 147.082098629s] Trained 64 records in 0.121089353 seconds. Throughput is 528.53534 records/second. Loss is 0.24588081. Sequential2290a28's hyper parameters: Current learning rate is 0.016268098259313486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:09 INFO  DistriOptimizer$:408 - [Epoch 2 13504/60000][Iteration 1149][Wall Clock 147.166453134s] Trained 64 records in 0.084354505 seconds. Throughput is 758.7028 records/second. Loss is 0.24965304. Sequential2290a28's hyper parameters: Current learning rate is 0.01626545217957059. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 1150][Wall Clock 147.259271876s] Trained 64 records in 0.092818742 seconds. Throughput is 689.51587 records/second. Loss is 0.20928387. Sequential2290a28's hyper parameters: Current learning rate is 0.01626280696048138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13632/60000][Iteration 1151][Wall Clock 147.438235225s] Trained 64 records in 0.178963349 seconds. Throughput is 357.6151 records/second. Loss is 0.2333838. Sequential2290a28's hyper parameters: Current learning rate is 0.016260162601626018. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13696/60000][Iteration 1152][Wall Clock 147.571615223s] Trained 64 records in 0.133379998 seconds. Throughput is 479.83206 records/second. Loss is 0.43619546. Sequential2290a28's hyper parameters: Current learning rate is 0.016257519102584946. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13760/60000][Iteration 1153][Wall Clock 147.658101064s] Trained 64 records in 0.086485841 seconds. Throughput is 740.00555 records/second. Loss is 0.26855204. Sequential2290a28's hyper parameters: Current learning rate is 0.016254876462938883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 1154][Wall Clock 147.74034448s] Trained 64 records in 0.082243416 seconds. Throughput is 778.1778 records/second. Loss is 0.22034031. Sequential2290a28's hyper parameters: Current learning rate is 0.01625223468226881. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13888/60000][Iteration 1155][Wall Clock 147.809799688s] Trained 64 records in 0.069455208 seconds. Throughput is 921.4572 records/second. Loss is 0.33523026. Sequential2290a28's hyper parameters: Current learning rate is 0.016249593760155997. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 13952/60000][Iteration 1156][Wall Clock 147.896289712s] Trained 64 records in 0.086490024 seconds. Throughput is 739.9697 records/second. Loss is 0.2555953. Sequential2290a28's hyper parameters: Current learning rate is 0.016246953696181964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 14016/60000][Iteration 1157][Wall Clock 147.990376884s] Trained 64 records in 0.094087172 seconds. Throughput is 680.2203 records/second. Loss is 0.32645124. Sequential2290a28's hyper parameters: Current learning rate is 0.016244314489928524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 1158][Wall Clock 148.076551249s] Trained 64 records in 0.086174365 seconds. Throughput is 742.6803 records/second. Loss is 0.34441495. Sequential2290a28's hyper parameters: Current learning rate is 0.016241676140977747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 14144/60000][Iteration 1159][Wall Clock 148.152854296s] Trained 64 records in 0.076303047 seconds. Throughput is 838.7607 records/second. Loss is 0.18149415. Sequential2290a28's hyper parameters: Current learning rate is 0.016239038648911984. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:10 INFO  DistriOptimizer$:408 - [Epoch 2 14208/60000][Iteration 1160][Wall Clock 148.240973977s] Trained 64 records in 0.088119681 seconds. Throughput is 726.285 records/second. Loss is 0.33138147. Sequential2290a28's hyper parameters: Current learning rate is 0.01623640201331385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14272/60000][Iteration 1161][Wall Clock 148.348270885s] Trained 64 records in 0.107296908 seconds. Throughput is 596.4757 records/second. Loss is 0.32534137. Sequential2290a28's hyper parameters: Current learning rate is 0.016233766233766236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 1162][Wall Clock 148.496550884s] Trained 64 records in 0.148279999 seconds. Throughput is 431.61588 records/second. Loss is 0.18372346. Sequential2290a28's hyper parameters: Current learning rate is 0.016231131309852296. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14400/60000][Iteration 1163][Wall Clock 148.602753784s] Trained 64 records in 0.1062029 seconds. Throughput is 602.62006 records/second. Loss is 0.35714433. Sequential2290a28's hyper parameters: Current learning rate is 0.01622849724115547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14464/60000][Iteration 1164][Wall Clock 148.686444161s] Trained 64 records in 0.083690377 seconds. Throughput is 764.7235 records/second. Loss is 0.23697636. Sequential2290a28's hyper parameters: Current learning rate is 0.016225864027259455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14528/60000][Iteration 1165][Wall Clock 148.768300361s] Trained 64 records in 0.0818562 seconds. Throughput is 781.85895 records/second. Loss is 0.286401. Sequential2290a28's hyper parameters: Current learning rate is 0.016223231667748216. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 1166][Wall Clock 148.871953219s] Trained 64 records in 0.103652858 seconds. Throughput is 617.4456 records/second. Loss is 0.19735357. Sequential2290a28's hyper parameters: Current learning rate is 0.016220600162206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14656/60000][Iteration 1167][Wall Clock 148.977640456s] Trained 64 records in 0.105687237 seconds. Throughput is 605.56036 records/second. Loss is 0.16696523. Sequential2290a28's hyper parameters: Current learning rate is 0.01621796951021732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14720/60000][Iteration 1168][Wall Clock 149.087363922s] Trained 64 records in 0.109723466 seconds. Throughput is 583.28455 records/second. Loss is 0.22993259. Sequential2290a28's hyper parameters: Current learning rate is 0.016215339711366954. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:11 INFO  DistriOptimizer$:408 - [Epoch 2 14784/60000][Iteration 1169][Wall Clock 149.185962323s] Trained 64 records in 0.098598401 seconds. Throughput is 649.0978 records/second. Loss is 0.26611352. Sequential2290a28's hyper parameters: Current learning rate is 0.01621271076523995. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 1170][Wall Clock 149.293290736s] Trained 64 records in 0.107328413 seconds. Throughput is 596.3006 records/second. Loss is 0.27679163. Sequential2290a28's hyper parameters: Current learning rate is 0.016210082671421624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 14912/60000][Iteration 1171][Wall Clock 149.409491996s] Trained 64 records in 0.11620126 seconds. Throughput is 550.76855 records/second. Loss is 0.30044907. Sequential2290a28's hyper parameters: Current learning rate is 0.01620745542949757. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 14976/60000][Iteration 1172][Wall Clock 149.517634234s] Trained 64 records in 0.108142238 seconds. Throughput is 591.8132 records/second. Loss is 0.3484939. Sequential2290a28's hyper parameters: Current learning rate is 0.01620482903905364. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 15040/60000][Iteration 1173][Wall Clock 149.607770939s] Trained 64 records in 0.090136705 seconds. Throughput is 710.0326 records/second. Loss is 0.40282068. Sequential2290a28's hyper parameters: Current learning rate is 0.01620220349967596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 1174][Wall Clock 149.701801253s] Trained 64 records in 0.094030314 seconds. Throughput is 680.6316 records/second. Loss is 0.2662552. Sequential2290a28's hyper parameters: Current learning rate is 0.016199578810950917. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 15168/60000][Iteration 1175][Wall Clock 149.844590855s] Trained 64 records in 0.142789602 seconds. Throughput is 448.2119 records/second. Loss is 0.50190264. Sequential2290a28's hyper parameters: Current learning rate is 0.016196954972465177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 15232/60000][Iteration 1176][Wall Clock 149.972682246s] Trained 64 records in 0.128091391 seconds. Throughput is 499.64325 records/second. Loss is 0.284469. Sequential2290a28's hyper parameters: Current learning rate is 0.016194331983805668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 15296/60000][Iteration 1177][Wall Clock 150.07467289s] Trained 64 records in 0.101990644 seconds. Throughput is 627.50854 records/second. Loss is 0.30572578. Sequential2290a28's hyper parameters: Current learning rate is 0.016191709844559584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:12 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 1178][Wall Clock 150.166882379s] Trained 64 records in 0.092209489 seconds. Throughput is 694.0717 records/second. Loss is 0.51889676. Sequential2290a28's hyper parameters: Current learning rate is 0.01618908855431439. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15424/60000][Iteration 1179][Wall Clock 150.252841763s] Trained 64 records in 0.085959384 seconds. Throughput is 744.5377 records/second. Loss is 0.16811559. Sequential2290a28's hyper parameters: Current learning rate is 0.01618646811265782. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15488/60000][Iteration 1180][Wall Clock 150.376723795s] Trained 64 records in 0.123882032 seconds. Throughput is 516.62054 records/second. Loss is 0.3934679. Sequential2290a28's hyper parameters: Current learning rate is 0.01618384851917786. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15552/60000][Iteration 1181][Wall Clock 150.481577905s] Trained 64 records in 0.10485411 seconds. Throughput is 610.3719 records/second. Loss is 0.31192464. Sequential2290a28's hyper parameters: Current learning rate is 0.016181229773462785. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 1182][Wall Clock 150.592148452s] Trained 64 records in 0.110570547 seconds. Throughput is 578.816 records/second. Loss is 0.4447203. Sequential2290a28's hyper parameters: Current learning rate is 0.016178611875101116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15680/60000][Iteration 1183][Wall Clock 150.686757098s] Trained 64 records in 0.094608646 seconds. Throughput is 676.47095 records/second. Loss is 0.45015115. Sequential2290a28's hyper parameters: Current learning rate is 0.016175994823681657. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15744/60000][Iteration 1184][Wall Clock 150.806893388s] Trained 64 records in 0.12013629 seconds. Throughput is 532.7283 records/second. Loss is 0.39035067. Sequential2290a28's hyper parameters: Current learning rate is 0.016173378618793467. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15808/60000][Iteration 1185][Wall Clock 150.933349884s] Trained 64 records in 0.126456496 seconds. Throughput is 506.1029 records/second. Loss is 0.2477622. Sequential2290a28's hyper parameters: Current learning rate is 0.016170763260025874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 1186][Wall Clock 151.068379912s] Trained 64 records in 0.135030028 seconds. Throughput is 473.96863 records/second. Loss is 0.2999557. Sequential2290a28's hyper parameters: Current learning rate is 0.01616814874696847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:13 INFO  DistriOptimizer$:408 - [Epoch 2 15936/60000][Iteration 1187][Wall Clock 151.232488897s] Trained 64 records in 0.164108985 seconds. Throughput is 389.9847 records/second. Loss is 0.36597946. Sequential2290a28's hyper parameters: Current learning rate is 0.016165535079211122. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16000/60000][Iteration 1188][Wall Clock 151.355155439s] Trained 64 records in 0.122666542 seconds. Throughput is 521.7396 records/second. Loss is 0.2290777. Sequential2290a28's hyper parameters: Current learning rate is 0.016162922256343946. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16064/60000][Iteration 1189][Wall Clock 151.449326863s] Trained 64 records in 0.094171424 seconds. Throughput is 679.61163 records/second. Loss is 0.27699494. Sequential2290a28's hyper parameters: Current learning rate is 0.01616031027795734. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 1190][Wall Clock 151.579222662s] Trained 64 records in 0.129895799 seconds. Throughput is 492.70258 records/second. Loss is 0.31209263. Sequential2290a28's hyper parameters: Current learning rate is 0.016157699143641947. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16192/60000][Iteration 1191][Wall Clock 151.677046578s] Trained 64 records in 0.097823916 seconds. Throughput is 654.23676 records/second. Loss is 0.29003048. Sequential2290a28's hyper parameters: Current learning rate is 0.01615508885298869. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16256/60000][Iteration 1192][Wall Clock 151.797088198s] Trained 64 records in 0.12004162 seconds. Throughput is 533.1484 records/second. Loss is 0.29525253. Sequential2290a28's hyper parameters: Current learning rate is 0.016152479405588758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16320/60000][Iteration 1193][Wall Clock 151.959661458s] Trained 64 records in 0.16257326 seconds. Throughput is 393.66867 records/second. Loss is 0.2767225. Sequential2290a28's hyper parameters: Current learning rate is 0.016149870801033594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:14 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 1194][Wall Clock 152.070150856s] Trained 64 records in 0.110489398 seconds. Throughput is 579.2411 records/second. Loss is 0.24584728. Sequential2290a28's hyper parameters: Current learning rate is 0.016147263038914905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16448/60000][Iteration 1195][Wall Clock 152.252308574s] Trained 64 records in 0.182157718 seconds. Throughput is 351.34387 records/second. Loss is 0.404802. Sequential2290a28's hyper parameters: Current learning rate is 0.01614465611882467. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16512/60000][Iteration 1196][Wall Clock 152.391686948s] Trained 64 records in 0.139378374 seconds. Throughput is 459.18173 records/second. Loss is 0.35669863. Sequential2290a28's hyper parameters: Current learning rate is 0.016142050040355124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16576/60000][Iteration 1197][Wall Clock 152.504816622s] Trained 64 records in 0.113129674 seconds. Throughput is 565.7225 records/second. Loss is 0.33039564. Sequential2290a28's hyper parameters: Current learning rate is 0.016139444803098774. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 1198][Wall Clock 152.601475125s] Trained 64 records in 0.096658503 seconds. Throughput is 662.1249 records/second. Loss is 0.36961025. Sequential2290a28's hyper parameters: Current learning rate is 0.016136840406648378. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16704/60000][Iteration 1199][Wall Clock 152.684652436s] Trained 64 records in 0.083177311 seconds. Throughput is 769.44055 records/second. Loss is 0.19142246. Sequential2290a28's hyper parameters: Current learning rate is 0.016134236850596968. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16768/60000][Iteration 1200][Wall Clock 152.761517951s] Trained 64 records in 0.076865515 seconds. Throughput is 832.62305 records/second. Loss is 0.31607774. Sequential2290a28's hyper parameters: Current learning rate is 0.016131634134537828. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16832/60000][Iteration 1201][Wall Clock 152.833871904s] Trained 64 records in 0.072353953 seconds. Throughput is 884.54047 records/second. Loss is 0.4143004. Sequential2290a28's hyper parameters: Current learning rate is 0.016129032258064516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 1202][Wall Clock 152.914266427s] Trained 64 records in 0.080394523 seconds. Throughput is 796.07416 records/second. Loss is 0.19998321. Sequential2290a28's hyper parameters: Current learning rate is 0.016126431220770843. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 16960/60000][Iteration 1203][Wall Clock 153.067472419s] Trained 64 records in 0.153205992 seconds. Throughput is 417.73822 records/second. Loss is 0.322142. Sequential2290a28's hyper parameters: Current learning rate is 0.016123831022250887. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:15 INFO  DistriOptimizer$:408 - [Epoch 2 17024/60000][Iteration 1204][Wall Clock 153.193785114s] Trained 64 records in 0.126312695 seconds. Throughput is 506.6791 records/second. Loss is 0.2793394. Sequential2290a28's hyper parameters: Current learning rate is 0.016121231662098987. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17088/60000][Iteration 1205][Wall Clock 153.312901747s] Trained 64 records in 0.119116633 seconds. Throughput is 537.2885 records/second. Loss is 0.27060756. Sequential2290a28's hyper parameters: Current learning rate is 0.016118633139909733. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 1206][Wall Clock 153.426329117s] Trained 64 records in 0.11342737 seconds. Throughput is 564.23773 records/second. Loss is 0.44399416. Sequential2290a28's hyper parameters: Current learning rate is 0.016116035455278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17216/60000][Iteration 1207][Wall Clock 153.520537556s] Trained 64 records in 0.094208439 seconds. Throughput is 679.34467 records/second. Loss is 0.38937628. Sequential2290a28's hyper parameters: Current learning rate is 0.016113438607798902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17280/60000][Iteration 1208][Wall Clock 153.603059717s] Trained 64 records in 0.082522161 seconds. Throughput is 775.54926 records/second. Loss is 0.30180418. Sequential2290a28's hyper parameters: Current learning rate is 0.016110842597067826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17344/60000][Iteration 1209][Wall Clock 153.726364962s] Trained 64 records in 0.123305245 seconds. Throughput is 519.0371 records/second. Loss is 0.3010191. Sequential2290a28's hyper parameters: Current learning rate is 0.01610824742268041. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 1210][Wall Clock 153.803645976s] Trained 64 records in 0.077281014 seconds. Throughput is 828.1465 records/second. Loss is 0.47849378. Sequential2290a28's hyper parameters: Current learning rate is 0.016105653084232566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17472/60000][Iteration 1211][Wall Clock 153.876331184s] Trained 64 records in 0.072685208 seconds. Throughput is 880.50934 records/second. Loss is 0.40262032. Sequential2290a28's hyper parameters: Current learning rate is 0.016103059581320453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17536/60000][Iteration 1212][Wall Clock 153.945684582s] Trained 64 records in 0.069353398 seconds. Throughput is 922.8098 records/second. Loss is 0.45672742. Sequential2290a28's hyper parameters: Current learning rate is 0.016100466913540494. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17600/60000][Iteration 1213][Wall Clock 154.012949629s] Trained 64 records in 0.067265047 seconds. Throughput is 951.45996 records/second. Loss is 0.27358213. Sequential2290a28's hyper parameters: Current learning rate is 0.016097875080489377. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:16 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 1214][Wall Clock 154.126540515s] Trained 64 records in 0.113590886 seconds. Throughput is 563.4255 records/second. Loss is 0.28455603. Sequential2290a28's hyper parameters: Current learning rate is 0.016095284081764045. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 17728/60000][Iteration 1215][Wall Clock 154.251019946s] Trained 64 records in 0.124479431 seconds. Throughput is 514.1412 records/second. Loss is 0.28922063. Sequential2290a28's hyper parameters: Current learning rate is 0.016092693916961703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 17792/60000][Iteration 1216][Wall Clock 154.350692958s] Trained 64 records in 0.099673012 seconds. Throughput is 642.0996 records/second. Loss is 0.17876953. Sequential2290a28's hyper parameters: Current learning rate is 0.016090104585679804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 17856/60000][Iteration 1217][Wall Clock 154.465366343s] Trained 64 records in 0.114673385 seconds. Throughput is 558.1069 records/second. Loss is 0.35799342. Sequential2290a28's hyper parameters: Current learning rate is 0.016087516087516088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 1218][Wall Clock 154.539462841s] Trained 64 records in 0.074096498 seconds. Throughput is 863.73846 records/second. Loss is 0.2488643. Sequential2290a28's hyper parameters: Current learning rate is 0.01608492842206852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 17984/60000][Iteration 1219][Wall Clock 154.669901628s] Trained 64 records in 0.130438787 seconds. Throughput is 490.65158 records/second. Loss is 0.24271822. Sequential2290a28's hyper parameters: Current learning rate is 0.01608234158893535. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 18048/60000][Iteration 1220][Wall Clock 154.803483845s] Trained 64 records in 0.133582217 seconds. Throughput is 479.10568 records/second. Loss is 0.3710677. Sequential2290a28's hyper parameters: Current learning rate is 0.016079755587715065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 18112/60000][Iteration 1221][Wall Clock 154.919231082s] Trained 64 records in 0.115747237 seconds. Throughput is 552.92896 records/second. Loss is 0.39266905. Sequential2290a28's hyper parameters: Current learning rate is 0.01607717041800643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 1222][Wall Clock 155.038902605s] Trained 64 records in 0.119671523 seconds. Throughput is 534.79724 records/second. Loss is 0.20378041. Sequential2290a28's hyper parameters: Current learning rate is 0.016074586079408457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:17 INFO  DistriOptimizer$:408 - [Epoch 2 18240/60000][Iteration 1223][Wall Clock 155.149692642s] Trained 64 records in 0.110790037 seconds. Throughput is 577.66925 records/second. Loss is 0.34628958. Sequential2290a28's hyper parameters: Current learning rate is 0.016072002571520413. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18304/60000][Iteration 1224][Wall Clock 155.305118655s] Trained 64 records in 0.155426013 seconds. Throughput is 411.77148 records/second. Loss is 0.42160267. Sequential2290a28's hyper parameters: Current learning rate is 0.016069419893941828. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18368/60000][Iteration 1225][Wall Clock 155.409928729s] Trained 64 records in 0.104810074 seconds. Throughput is 610.6283 records/second. Loss is 0.22737077. Sequential2290a28's hyper parameters: Current learning rate is 0.016066838046272493. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 1226][Wall Clock 155.497839945s] Trained 64 records in 0.087911216 seconds. Throughput is 728.0072 records/second. Loss is 0.25488022. Sequential2290a28's hyper parameters: Current learning rate is 0.01606425702811245. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18496/60000][Iteration 1227][Wall Clock 155.572947342s] Trained 64 records in 0.075107397 seconds. Throughput is 852.11316 records/second. Loss is 0.3221932. Sequential2290a28's hyper parameters: Current learning rate is 0.016061676839061997. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18560/60000][Iteration 1228][Wall Clock 155.640289646s] Trained 64 records in 0.067342304 seconds. Throughput is 950.3684 records/second. Loss is 0.38627863. Sequential2290a28's hyper parameters: Current learning rate is 0.016059097478721696. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18624/60000][Iteration 1229][Wall Clock 155.71678964s] Trained 64 records in 0.076499994 seconds. Throughput is 836.6014 records/second. Loss is 0.25288856. Sequential2290a28's hyper parameters: Current learning rate is 0.016056518946692355. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 1230][Wall Clock 155.850873239s] Trained 64 records in 0.134083599 seconds. Throughput is 477.31415 records/second. Loss is 0.23337902. Sequential2290a28's hyper parameters: Current learning rate is 0.016053941242575052. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18752/60000][Iteration 1231][Wall Clock 155.956437001s] Trained 64 records in 0.105563762 seconds. Throughput is 606.2687 records/second. Loss is 0.2667333. Sequential2290a28's hyper parameters: Current learning rate is 0.01605136436597111. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18816/60000][Iteration 1232][Wall Clock 156.078749603s] Trained 64 records in 0.122312602 seconds. Throughput is 523.24945 records/second. Loss is 0.37921727. Sequential2290a28's hyper parameters: Current learning rate is 0.016048788316482106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:18 INFO  DistriOptimizer$:408 - [Epoch 2 18880/60000][Iteration 1233][Wall Clock 156.179392226s] Trained 64 records in 0.100642623 seconds. Throughput is 635.9135 records/second. Loss is 0.44670033. Sequential2290a28's hyper parameters: Current learning rate is 0.016046213093709884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 1234][Wall Clock 156.290971406s] Trained 64 records in 0.11157918 seconds. Throughput is 573.58374 records/second. Loss is 0.14204705. Sequential2290a28's hyper parameters: Current learning rate is 0.01604363869725654. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19008/60000][Iteration 1235][Wall Clock 156.390737291s] Trained 64 records in 0.099765885 seconds. Throughput is 641.5019 records/second. Loss is 0.3968613. Sequential2290a28's hyper parameters: Current learning rate is 0.016041065126724416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19072/60000][Iteration 1236][Wall Clock 156.483050932s] Trained 64 records in 0.092313641 seconds. Throughput is 693.28864 records/second. Loss is 0.3449649. Sequential2290a28's hyper parameters: Current learning rate is 0.01603849238171612. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19136/60000][Iteration 1237][Wall Clock 156.562741254s] Trained 64 records in 0.079690322 seconds. Throughput is 803.1088 records/second. Loss is 0.3021219. Sequential2290a28's hyper parameters: Current learning rate is 0.01603592046183451. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 1238][Wall Clock 156.64172866s] Trained 64 records in 0.078987406 seconds. Throughput is 810.25574 records/second. Loss is 0.28982216. Sequential2290a28's hyper parameters: Current learning rate is 0.0160333493666827. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19264/60000][Iteration 1239][Wall Clock 156.716398189s] Trained 64 records in 0.074669529 seconds. Throughput is 857.11 records/second. Loss is 0.25216725. Sequential2290a28's hyper parameters: Current learning rate is 0.016030779095864058. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19328/60000][Iteration 1240][Wall Clock 156.804116736s] Trained 64 records in 0.087718547 seconds. Throughput is 729.60626 records/second. Loss is 0.23796028. Sequential2290a28's hyper parameters: Current learning rate is 0.01602820964898221. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19392/60000][Iteration 1241][Wall Clock 156.899313615s] Trained 64 records in 0.095196879 seconds. Throughput is 672.29095 records/second. Loss is 0.30151403. Sequential2290a28's hyper parameters: Current learning rate is 0.016025641025641028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 1242][Wall Clock 156.985096078s] Trained 64 records in 0.085782463 seconds. Throughput is 746.07324 records/second. Loss is 0.2950846. Sequential2290a28's hyper parameters: Current learning rate is 0.01602307322544464. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19520/60000][Iteration 1243][Wall Clock 157.076105398s] Trained 64 records in 0.09100932 seconds. Throughput is 703.2247 records/second. Loss is 0.23328477. Sequential2290a28's hyper parameters: Current learning rate is 0.01602050624799744. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:19 INFO  DistriOptimizer$:408 - [Epoch 2 19584/60000][Iteration 1244][Wall Clock 157.203893272s] Trained 64 records in 0.127787874 seconds. Throughput is 500.83 records/second. Loss is 0.25239936. Sequential2290a28's hyper parameters: Current learning rate is 0.016017940092904054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 19648/60000][Iteration 1245][Wall Clock 157.294826824s] Trained 64 records in 0.090933552 seconds. Throughput is 703.8106 records/second. Loss is 0.22822419. Sequential2290a28's hyper parameters: Current learning rate is 0.016015374759769378. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 1246][Wall Clock 157.423893827s] Trained 64 records in 0.129067003 seconds. Throughput is 495.8665 records/second. Loss is 0.31295672. Sequential2290a28's hyper parameters: Current learning rate is 0.016012810248198558. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 19776/60000][Iteration 1247][Wall Clock 157.517370497s] Trained 64 records in 0.09347667 seconds. Throughput is 684.66284 records/second. Loss is 0.2600203. Sequential2290a28's hyper parameters: Current learning rate is 0.016010246557796988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 19840/60000][Iteration 1248][Wall Clock 157.614226133s] Trained 64 records in 0.096855636 seconds. Throughput is 660.7773 records/second. Loss is 0.35505894. Sequential2290a28's hyper parameters: Current learning rate is 0.01600768368817032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 19904/60000][Iteration 1249][Wall Clock 157.705780063s] Trained 64 records in 0.09155393 seconds. Throughput is 699.04156 records/second. Loss is 0.27065188. Sequential2290a28's hyper parameters: Current learning rate is 0.016005121638924456. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 1250][Wall Clock 157.82318091s] Trained 64 records in 0.117400847 seconds. Throughput is 545.14087 records/second. Loss is 0.15601353. Sequential2290a28's hyper parameters: Current learning rate is 0.016002560409665547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 20032/60000][Iteration 1251][Wall Clock 157.921495795s] Trained 64 records in 0.098314885 seconds. Throughput is 650.9696 records/second. Loss is 0.44948065. Sequential2290a28's hyper parameters: Current learning rate is 0.016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 20096/60000][Iteration 1252][Wall Clock 158.016587268s] Trained 64 records in 0.095091473 seconds. Throughput is 673.0362 records/second. Loss is 0.31616753. Sequential2290a28's hyper parameters: Current learning rate is 0.015997440409534474. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:20 INFO  DistriOptimizer$:408 - [Epoch 2 20160/60000][Iteration 1253][Wall Clock 158.107189932s] Trained 64 records in 0.090602664 seconds. Throughput is 706.381 records/second. Loss is 0.2695609. Sequential2290a28's hyper parameters: Current learning rate is 0.01599488163787588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 1254][Wall Clock 158.203683395s] Trained 64 records in 0.096493463 seconds. Throughput is 663.2574 records/second. Loss is 0.37020698. Sequential2290a28's hyper parameters: Current learning rate is 0.01599232368463138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20288/60000][Iteration 1255][Wall Clock 158.309909137s] Trained 64 records in 0.106225742 seconds. Throughput is 602.4905 records/second. Loss is 0.26959607. Sequential2290a28's hyper parameters: Current learning rate is 0.01598976654940838. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20352/60000][Iteration 1256][Wall Clock 158.47392224s] Trained 64 records in 0.164013103 seconds. Throughput is 390.21274 records/second. Loss is 0.25599337. Sequential2290a28's hyper parameters: Current learning rate is 0.01598721023181455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20416/60000][Iteration 1257][Wall Clock 158.594188378s] Trained 64 records in 0.120266138 seconds. Throughput is 532.15314 records/second. Loss is 0.35853243. Sequential2290a28's hyper parameters: Current learning rate is 0.015984654731457798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 1258][Wall Clock 158.710768428s] Trained 64 records in 0.11658005 seconds. Throughput is 548.979 records/second. Loss is 0.27450892. Sequential2290a28's hyper parameters: Current learning rate is 0.0159821000479463. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20544/60000][Iteration 1259][Wall Clock 158.79114672s] Trained 64 records in 0.080378292 seconds. Throughput is 796.23486 records/second. Loss is 0.30514082. Sequential2290a28's hyper parameters: Current learning rate is 0.01597954618088846. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20608/60000][Iteration 1260][Wall Clock 158.869498772s] Trained 64 records in 0.078352052 seconds. Throughput is 816.8261 records/second. Loss is 0.2989233. Sequential2290a28's hyper parameters: Current learning rate is 0.015976993129892956. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20672/60000][Iteration 1261][Wall Clock 158.995564533s] Trained 64 records in 0.126065761 seconds. Throughput is 507.67154 records/second. Loss is 0.334149. Sequential2290a28's hyper parameters: Current learning rate is 0.01597444089456869. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:21 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 1262][Wall Clock 159.136925231s] Trained 64 records in 0.141360698 seconds. Throughput is 452.74252 records/second. Loss is 0.19518803. Sequential2290a28's hyper parameters: Current learning rate is 0.015971889474524836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 20800/60000][Iteration 1263][Wall Clock 159.290847741s] Trained 64 records in 0.15392251 seconds. Throughput is 415.79364 records/second. Loss is 0.21983427. Sequential2290a28's hyper parameters: Current learning rate is 0.015969338869370808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 20864/60000][Iteration 1264][Wall Clock 159.413387297s] Trained 64 records in 0.122539556 seconds. Throughput is 522.28033 records/second. Loss is 0.29027015. Sequential2290a28's hyper parameters: Current learning rate is 0.01596678907871627. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 20928/60000][Iteration 1265][Wall Clock 159.508500061s] Trained 64 records in 0.095112764 seconds. Throughput is 672.8855 records/second. Loss is 0.24373376. Sequential2290a28's hyper parameters: Current learning rate is 0.015964240102171134. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 1266][Wall Clock 159.582299804s] Trained 64 records in 0.073799743 seconds. Throughput is 867.2117 records/second. Loss is 0.32572046. Sequential2290a28's hyper parameters: Current learning rate is 0.01596169193934557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 21056/60000][Iteration 1267][Wall Clock 159.669696071s] Trained 64 records in 0.087396267 seconds. Throughput is 732.29675 records/second. Loss is 0.22776102. Sequential2290a28's hyper parameters: Current learning rate is 0.015959144589849983. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 21120/60000][Iteration 1268][Wall Clock 159.770007195s] Trained 64 records in 0.100311124 seconds. Throughput is 638.015 records/second. Loss is 0.1981481. Sequential2290a28's hyper parameters: Current learning rate is 0.015956598053295037. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 21184/60000][Iteration 1269][Wall Clock 159.843726976s] Trained 64 records in 0.073719781 seconds. Throughput is 868.1523 records/second. Loss is 0.41559622. Sequential2290a28's hyper parameters: Current learning rate is 0.01595405232929164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 1270][Wall Clock 160.002414169s] Trained 64 records in 0.158687193 seconds. Throughput is 403.30917 records/second. Loss is 0.1998649. Sequential2290a28's hyper parameters: Current learning rate is 0.01595150741745095. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:22 INFO  DistriOptimizer$:408 - [Epoch 2 21312/60000][Iteration 1271][Wall Clock 160.097243644s] Trained 64 records in 0.094829475 seconds. Throughput is 674.8956 records/second. Loss is 0.20630988. Sequential2290a28's hyper parameters: Current learning rate is 0.01594896331738437. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21376/60000][Iteration 1272][Wall Clock 160.248777862s] Trained 64 records in 0.151534218 seconds. Throughput is 422.34686 records/second. Loss is 0.26991582. Sequential2290a28's hyper parameters: Current learning rate is 0.015946420028703556. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21440/60000][Iteration 1273][Wall Clock 160.36232033s] Trained 64 records in 0.113542468 seconds. Throughput is 563.6658 records/second. Loss is 0.36489105. Sequential2290a28's hyper parameters: Current learning rate is 0.01594387755102041. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 1274][Wall Clock 160.429832908s] Trained 64 records in 0.067512578 seconds. Throughput is 947.9715 records/second. Loss is 0.26499802. Sequential2290a28's hyper parameters: Current learning rate is 0.015941335883947076. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21568/60000][Iteration 1275][Wall Clock 160.505564679s] Trained 64 records in 0.075731771 seconds. Throughput is 845.0879 records/second. Loss is 0.2804658. Sequential2290a28's hyper parameters: Current learning rate is 0.015938795027095953. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21632/60000][Iteration 1276][Wall Clock 160.600108613s] Trained 64 records in 0.094543934 seconds. Throughput is 676.93396 records/second. Loss is 0.27838817. Sequential2290a28's hyper parameters: Current learning rate is 0.015936254980079684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21696/60000][Iteration 1277][Wall Clock 160.704650029s] Trained 64 records in 0.104541416 seconds. Throughput is 612.1976 records/second. Loss is 0.33160362. Sequential2290a28's hyper parameters: Current learning rate is 0.015933715742511154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 1278][Wall Clock 160.809693171s] Trained 64 records in 0.105043142 seconds. Throughput is 609.27344 records/second. Loss is 0.53998023. Sequential2290a28's hyper parameters: Current learning rate is 0.015931177314003505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21824/60000][Iteration 1279][Wall Clock 160.902327506s] Trained 64 records in 0.092634335 seconds. Throughput is 690.88855 records/second. Loss is 0.32295063. Sequential2290a28's hyper parameters: Current learning rate is 0.01592863969417012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21888/60000][Iteration 1280][Wall Clock 161.030478282s] Trained 64 records in 0.128150776 seconds. Throughput is 499.4117 records/second. Loss is 0.23477656. Sequential2290a28's hyper parameters: Current learning rate is 0.01592610288262462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:23 INFO  DistriOptimizer$:408 - [Epoch 2 21952/60000][Iteration 1281][Wall Clock 161.16257794s] Trained 64 records in 0.132099658 seconds. Throughput is 484.4827 records/second. Loss is 0.2830242. Sequential2290a28's hyper parameters: Current learning rate is 0.01592356687898089. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 1282][Wall Clock 161.264471798s] Trained 64 records in 0.101893858 seconds. Throughput is 628.1046 records/second. Loss is 0.2672451. Sequential2290a28's hyper parameters: Current learning rate is 0.01592103168285305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22080/60000][Iteration 1283][Wall Clock 161.409018982s] Trained 64 records in 0.144547184 seconds. Throughput is 442.76202 records/second. Loss is 0.47926006. Sequential2290a28's hyper parameters: Current learning rate is 0.01591849729385546. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22144/60000][Iteration 1284][Wall Clock 161.519770433s] Trained 64 records in 0.110751451 seconds. Throughput is 577.87054 records/second. Loss is 0.26572105. Sequential2290a28's hyper parameters: Current learning rate is 0.01591596371160274. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22208/60000][Iteration 1285][Wall Clock 161.615881874s] Trained 64 records in 0.096111441 seconds. Throughput is 665.8937 records/second. Loss is 0.27477002. Sequential2290a28's hyper parameters: Current learning rate is 0.015913430935709738. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 1286][Wall Clock 161.704376335s] Trained 64 records in 0.088494461 seconds. Throughput is 723.2091 records/second. Loss is 0.38976705. Sequential2290a28's hyper parameters: Current learning rate is 0.015910898965791564. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22336/60000][Iteration 1287][Wall Clock 161.809825828s] Trained 64 records in 0.105449493 seconds. Throughput is 606.92566 records/second. Loss is 0.32002693. Sequential2290a28's hyper parameters: Current learning rate is 0.01590836780146357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22400/60000][Iteration 1288][Wall Clock 161.888607376s] Trained 64 records in 0.078781548 seconds. Throughput is 812.373 records/second. Loss is 0.2540282. Sequential2290a28's hyper parameters: Current learning rate is 0.01590583744234134. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22464/60000][Iteration 1289][Wall Clock 161.972184105s] Trained 64 records in 0.083576729 seconds. Throughput is 765.76337 records/second. Loss is 0.21687622. Sequential2290a28's hyper parameters: Current learning rate is 0.015903307888040712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 1290][Wall Clock 162.057171783s] Trained 64 records in 0.084987678 seconds. Throughput is 753.05035 records/second. Loss is 0.28837398. Sequential2290a28's hyper parameters: Current learning rate is 0.01590077913817777. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:24 INFO  DistriOptimizer$:408 - [Epoch 2 22592/60000][Iteration 1291][Wall Clock 162.141181396s] Trained 64 records in 0.084009613 seconds. Throughput is 761.8176 records/second. Loss is 0.30265853. Sequential2290a28's hyper parameters: Current learning rate is 0.01589825119236884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 22656/60000][Iteration 1292][Wall Clock 162.246815149s] Trained 64 records in 0.105633753 seconds. Throughput is 605.86694 records/second. Loss is 0.26175648. Sequential2290a28's hyper parameters: Current learning rate is 0.01589572405023049. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 22720/60000][Iteration 1293][Wall Clock 162.327243312s] Trained 64 records in 0.080428163 seconds. Throughput is 795.7412 records/second. Loss is 0.29308665. Sequential2290a28's hyper parameters: Current learning rate is 0.01589319771137953. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 1294][Wall Clock 162.407513755s] Trained 64 records in 0.080270443 seconds. Throughput is 797.3047 records/second. Loss is 0.24539466. Sequential2290a28's hyper parameters: Current learning rate is 0.01589067217543302. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 22848/60000][Iteration 1295][Wall Clock 162.514090043s] Trained 64 records in 0.106576288 seconds. Throughput is 600.50885 records/second. Loss is 0.35322157. Sequential2290a28's hyper parameters: Current learning rate is 0.01588814744200826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 22912/60000][Iteration 1296][Wall Clock 162.647102556s] Trained 64 records in 0.133012513 seconds. Throughput is 481.1577 records/second. Loss is 0.19740412. Sequential2290a28's hyper parameters: Current learning rate is 0.0158856235107228. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 22976/60000][Iteration 1297][Wall Clock 162.739014682s] Trained 64 records in 0.091912126 seconds. Throughput is 696.31726 records/second. Loss is 0.4141401. Sequential2290a28's hyper parameters: Current learning rate is 0.01588310038119441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 1298][Wall Clock 162.813314147s] Trained 64 records in 0.074299465 seconds. Throughput is 861.379 records/second. Loss is 0.36677817. Sequential2290a28's hyper parameters: Current learning rate is 0.01588057805304113. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 23104/60000][Iteration 1299][Wall Clock 162.933029253s] Trained 64 records in 0.119715106 seconds. Throughput is 534.60254 records/second. Loss is 0.36634004. Sequential2290a28's hyper parameters: Current learning rate is 0.015878056525881232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 23168/60000][Iteration 1300][Wall Clock 163.054321378s] Trained 64 records in 0.121292125 seconds. Throughput is 527.65173 records/second. Loss is 0.325073. Sequential2290a28's hyper parameters: Current learning rate is 0.015875535799333228. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:25 INFO  DistriOptimizer$:408 - [Epoch 2 23232/60000][Iteration 1301][Wall Clock 163.175409364s] Trained 64 records in 0.121087986 seconds. Throughput is 528.5413 records/second. Loss is 0.21509874. Sequential2290a28's hyper parameters: Current learning rate is 0.015873015873015872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 1302][Wall Clock 163.286422398s] Trained 64 records in 0.111013034 seconds. Throughput is 576.5089 records/second. Loss is 0.26451388. Sequential2290a28's hyper parameters: Current learning rate is 0.01587049674654817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23360/60000][Iteration 1303][Wall Clock 163.390394219s] Trained 64 records in 0.103971821 seconds. Throughput is 615.5514 records/second. Loss is 0.19292563. Sequential2290a28's hyper parameters: Current learning rate is 0.01586797841954935. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23424/60000][Iteration 1304][Wall Clock 163.484350334s] Trained 64 records in 0.093956115 seconds. Throughput is 681.16907 records/second. Loss is 0.15713154. Sequential2290a28's hyper parameters: Current learning rate is 0.015865460891638903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23488/60000][Iteration 1305][Wall Clock 163.586250219s] Trained 64 records in 0.101899885 seconds. Throughput is 628.06744 records/second. Loss is 0.13585126. Sequential2290a28's hyper parameters: Current learning rate is 0.015862944162436547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 1306][Wall Clock 163.723753778s] Trained 64 records in 0.137503559 seconds. Throughput is 465.44247 records/second. Loss is 0.31936127. Sequential2290a28's hyper parameters: Current learning rate is 0.01586042823156225. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23616/60000][Iteration 1307][Wall Clock 163.810149162s] Trained 64 records in 0.086395384 seconds. Throughput is 740.78033 records/second. Loss is 0.24580818. Sequential2290a28's hyper parameters: Current learning rate is 0.01585791309863622. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23680/60000][Iteration 1308][Wall Clock 163.993285904s] Trained 64 records in 0.183136742 seconds. Throughput is 349.46564 records/second. Loss is 0.14488335. Sequential2290a28's hyper parameters: Current learning rate is 0.015855398763278895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:26 INFO  DistriOptimizer$:408 - [Epoch 2 23744/60000][Iteration 1309][Wall Clock 164.099657379s] Trained 64 records in 0.106371475 seconds. Throughput is 601.66504 records/second. Loss is 0.18072882. Sequential2290a28's hyper parameters: Current learning rate is 0.01585288522511097. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 1310][Wall Clock 164.189005703s] Trained 64 records in 0.089348324 seconds. Throughput is 716.2977 records/second. Loss is 0.29354087. Sequential2290a28's hyper parameters: Current learning rate is 0.01585037248375337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 23872/60000][Iteration 1311][Wall Clock 164.281289058s] Trained 64 records in 0.092283355 seconds. Throughput is 693.5162 records/second. Loss is 0.42080534. Sequential2290a28's hyper parameters: Current learning rate is 0.01584786053882726. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 23936/60000][Iteration 1312][Wall Clock 164.389471453s] Trained 64 records in 0.108182395 seconds. Throughput is 591.5935 records/second. Loss is 0.23321418. Sequential2290a28's hyper parameters: Current learning rate is 0.01584534938995405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24000/60000][Iteration 1313][Wall Clock 164.463830043s] Trained 64 records in 0.07435859 seconds. Throughput is 860.6941 records/second. Loss is 0.2649688. Sequential2290a28's hyper parameters: Current learning rate is 0.015842839036755388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 1314][Wall Clock 164.567292466s] Trained 64 records in 0.103462423 seconds. Throughput is 618.5821 records/second. Loss is 0.30738628. Sequential2290a28's hyper parameters: Current learning rate is 0.015840329478853162. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24128/60000][Iteration 1315][Wall Clock 164.687338911s] Trained 64 records in 0.120046445 seconds. Throughput is 533.127 records/second. Loss is 0.30081874. Sequential2290a28's hyper parameters: Current learning rate is 0.015837820715869498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24192/60000][Iteration 1316][Wall Clock 164.785475349s] Trained 64 records in 0.098136438 seconds. Throughput is 652.15326 records/second. Loss is 0.21151322. Sequential2290a28's hyper parameters: Current learning rate is 0.015835312747426764. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24256/60000][Iteration 1317][Wall Clock 164.89307259s] Trained 64 records in 0.107597241 seconds. Throughput is 594.8108 records/second. Loss is 0.4540648. Sequential2290a28's hyper parameters: Current learning rate is 0.015832805573147563. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 1318][Wall Clock 164.969585625s] Trained 64 records in 0.076513035 seconds. Throughput is 836.45874 records/second. Loss is 0.42592794. Sequential2290a28's hyper parameters: Current learning rate is 0.015830299192654742. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24384/60000][Iteration 1319][Wall Clock 165.042498514s] Trained 64 records in 0.072912889 seconds. Throughput is 877.75977 records/second. Loss is 0.3213945. Sequential2290a28's hyper parameters: Current learning rate is 0.015827793605571384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:27 INFO  DistriOptimizer$:408 - [Epoch 2 24448/60000][Iteration 1320][Wall Clock 165.121062999s] Trained 64 records in 0.078564485 seconds. Throughput is 814.61743 records/second. Loss is 0.31846166. Sequential2290a28's hyper parameters: Current learning rate is 0.01582528881152081. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24512/60000][Iteration 1321][Wall Clock 165.243260586s] Trained 64 records in 0.122197587 seconds. Throughput is 523.74194 records/second. Loss is 0.3113079. Sequential2290a28's hyper parameters: Current learning rate is 0.015822784810126583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 1322][Wall Clock 165.320485328s] Trained 64 records in 0.077224742 seconds. Throughput is 828.74994 records/second. Loss is 0.18838269. Sequential2290a28's hyper parameters: Current learning rate is 0.0158202816010125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24640/60000][Iteration 1323][Wall Clock 165.440482725s] Trained 64 records in 0.119997397 seconds. Throughput is 533.3449 records/second. Loss is 0.16286704. Sequential2290a28's hyper parameters: Current learning rate is 0.015817779183802595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24704/60000][Iteration 1324][Wall Clock 165.56976178s] Trained 64 records in 0.129279055 seconds. Throughput is 495.0531 records/second. Loss is 0.18059218. Sequential2290a28's hyper parameters: Current learning rate is 0.015815277558121146. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24768/60000][Iteration 1325][Wall Clock 165.645810139s] Trained 64 records in 0.076048359 seconds. Throughput is 841.56976 records/second. Loss is 0.25384152. Sequential2290a28's hyper parameters: Current learning rate is 0.015812776723592662. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 1326][Wall Clock 165.727529763s] Trained 64 records in 0.081719624 seconds. Throughput is 783.16565 records/second. Loss is 0.24652658. Sequential2290a28's hyper parameters: Current learning rate is 0.015810276679841896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24896/60000][Iteration 1327][Wall Clock 165.807476131s] Trained 64 records in 0.079946368 seconds. Throughput is 800.5367 records/second. Loss is 0.20465592. Sequential2290a28's hyper parameters: Current learning rate is 0.015807777426493835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 24960/60000][Iteration 1328][Wall Clock 165.88485759s] Trained 64 records in 0.077381459 seconds. Throughput is 827.0715 records/second. Loss is 0.43045515. Sequential2290a28's hyper parameters: Current learning rate is 0.0158052789631737. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 25024/60000][Iteration 1329][Wall Clock 165.961693646s] Trained 64 records in 0.076836056 seconds. Throughput is 832.94226 records/second. Loss is 0.36665916. Sequential2290a28's hyper parameters: Current learning rate is 0.01580278128950695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 1330][Wall Clock 166.04752404s] Trained 64 records in 0.085830394 seconds. Throughput is 745.6566 records/second. Loss is 0.28659776. Sequential2290a28's hyper parameters: Current learning rate is 0.015800284405119294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:28 INFO  DistriOptimizer$:408 - [Epoch 2 25152/60000][Iteration 1331][Wall Clock 166.140823409s] Trained 64 records in 0.093299369 seconds. Throughput is 685.9639 records/second. Loss is 0.30845076. Sequential2290a28's hyper parameters: Current learning rate is 0.01579778830963665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25216/60000][Iteration 1332][Wall Clock 166.260047989s] Trained 64 records in 0.11922458 seconds. Throughput is 536.80206 records/second. Loss is 0.3139987. Sequential2290a28's hyper parameters: Current learning rate is 0.0157952930026852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25280/60000][Iteration 1333][Wall Clock 166.379790883s] Trained 64 records in 0.119742894 seconds. Throughput is 534.4785 records/second. Loss is 0.28605995. Sequential2290a28's hyper parameters: Current learning rate is 0.015792798483891347. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 1334][Wall Clock 166.469839668s] Trained 64 records in 0.090048785 seconds. Throughput is 710.7259 records/second. Loss is 0.2937415. Sequential2290a28's hyper parameters: Current learning rate is 0.01579030475288173. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25408/60000][Iteration 1335][Wall Clock 166.598897686s] Trained 64 records in 0.129058018 seconds. Throughput is 495.901 records/second. Loss is 0.26948047. Sequential2290a28's hyper parameters: Current learning rate is 0.015787811809283233. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25472/60000][Iteration 1336][Wall Clock 166.720361502s] Trained 64 records in 0.121463816 seconds. Throughput is 526.9059 records/second. Loss is 0.17747551. Sequential2290a28's hyper parameters: Current learning rate is 0.01578531965272297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25536/60000][Iteration 1337][Wall Clock 166.836424758s] Trained 64 records in 0.116063256 seconds. Throughput is 551.4234 records/second. Loss is 0.2107585. Sequential2290a28's hyper parameters: Current learning rate is 0.015782828282828284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 1338][Wall Clock 166.942047959s] Trained 64 records in 0.105623201 seconds. Throughput is 605.9275 records/second. Loss is 0.29831597. Sequential2290a28's hyper parameters: Current learning rate is 0.015780337699226762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25664/60000][Iteration 1339][Wall Clock 167.010743706s] Trained 64 records in 0.068695747 seconds. Throughput is 931.6443 records/second. Loss is 0.291145. Sequential2290a28's hyper parameters: Current learning rate is 0.015777847901546228. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25728/60000][Iteration 1340][Wall Clock 167.087538208s] Trained 64 records in 0.076794502 seconds. Throughput is 833.39294 records/second. Loss is 0.21808775. Sequential2290a28's hyper parameters: Current learning rate is 0.015775358889414733. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:29 INFO  DistriOptimizer$:408 - [Epoch 2 25792/60000][Iteration 1341][Wall Clock 167.165441674s] Trained 64 records in 0.077903466 seconds. Throughput is 821.5296 records/second. Loss is 0.23014575. Sequential2290a28's hyper parameters: Current learning rate is 0.015772870662460567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 1342][Wall Clock 167.252319058s] Trained 64 records in 0.086877384 seconds. Throughput is 736.6704 records/second. Loss is 0.15042976. Sequential2290a28's hyper parameters: Current learning rate is 0.015770383220312253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 25920/60000][Iteration 1343][Wall Clock 167.322310832s] Trained 64 records in 0.069991774 seconds. Throughput is 914.3931 records/second. Loss is 0.269954. Sequential2290a28's hyper parameters: Current learning rate is 0.01576789656259855. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 25984/60000][Iteration 1344][Wall Clock 167.401072424s] Trained 64 records in 0.078761592 seconds. Throughput is 812.5788 records/second. Loss is 0.23475787. Sequential2290a28's hyper parameters: Current learning rate is 0.015765410688948447. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26048/60000][Iteration 1345][Wall Clock 167.477178202s] Trained 64 records in 0.076105778 seconds. Throughput is 840.9348 records/second. Loss is 0.22472712. Sequential2290a28's hyper parameters: Current learning rate is 0.01576292559899117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 1346][Wall Clock 167.562903403s] Trained 64 records in 0.085725201 seconds. Throughput is 746.5716 records/second. Loss is 0.17194256. Sequential2290a28's hyper parameters: Current learning rate is 0.015760441292356184. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26176/60000][Iteration 1347][Wall Clock 167.711714989s] Trained 64 records in 0.148811586 seconds. Throughput is 430.07407 records/second. Loss is 0.25450593. Sequential2290a28's hyper parameters: Current learning rate is 0.01575795776867318. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26240/60000][Iteration 1348][Wall Clock 167.841802514s] Trained 64 records in 0.130087525 seconds. Throughput is 491.97647 records/second. Loss is 0.17447102. Sequential2290a28's hyper parameters: Current learning rate is 0.01575547502757208. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26304/60000][Iteration 1349][Wall Clock 167.956744012s] Trained 64 records in 0.114941498 seconds. Throughput is 556.805 records/second. Loss is 0.18561663. Sequential2290a28's hyper parameters: Current learning rate is 0.01575299306868305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 1350][Wall Clock 168.054439037s] Trained 64 records in 0.097695025 seconds. Throughput is 655.0999 records/second. Loss is 0.22536902. Sequential2290a28's hyper parameters: Current learning rate is 0.015750511891636478. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:30 INFO  DistriOptimizer$:408 - [Epoch 2 26432/60000][Iteration 1351][Wall Clock 168.1402161s] Trained 64 records in 0.085777063 seconds. Throughput is 746.1202 records/second. Loss is 0.18070173. Sequential2290a28's hyper parameters: Current learning rate is 0.015748031496062992. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26496/60000][Iteration 1352][Wall Clock 168.222664315s] Trained 64 records in 0.082448215 seconds. Throughput is 776.2448 records/second. Loss is 0.27274466. Sequential2290a28's hyper parameters: Current learning rate is 0.01574555188159345. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26560/60000][Iteration 1353][Wall Clock 168.293259501s] Trained 64 records in 0.070595186 seconds. Throughput is 906.57745 records/second. Loss is 0.4877373. Sequential2290a28's hyper parameters: Current learning rate is 0.015743073047858942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 1354][Wall Clock 168.374326699s] Trained 64 records in 0.081067198 seconds. Throughput is 789.4685 records/second. Loss is 0.3686069. Sequential2290a28's hyper parameters: Current learning rate is 0.015740594994490792. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26688/60000][Iteration 1355][Wall Clock 168.465257234s] Trained 64 records in 0.090930535 seconds. Throughput is 703.834 records/second. Loss is 0.39149973. Sequential2290a28's hyper parameters: Current learning rate is 0.015738117721120555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26752/60000][Iteration 1356][Wall Clock 168.567880979s] Trained 64 records in 0.102623745 seconds. Throughput is 623.6373 records/second. Loss is 0.31914598. Sequential2290a28's hyper parameters: Current learning rate is 0.015735641227380016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26816/60000][Iteration 1357][Wall Clock 168.667983766s] Trained 64 records in 0.100102787 seconds. Throughput is 639.34283 records/second. Loss is 0.23726666. Sequential2290a28's hyper parameters: Current learning rate is 0.015733165512901198. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 1358][Wall Clock 168.823211447s] Trained 64 records in 0.155227681 seconds. Throughput is 412.2976 records/second. Loss is 0.18362162. Sequential2290a28's hyper parameters: Current learning rate is 0.015730690577316343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 26944/60000][Iteration 1359][Wall Clock 168.939310403s] Trained 64 records in 0.116098956 seconds. Throughput is 551.2539 records/second. Loss is 0.16592818. Sequential2290a28's hyper parameters: Current learning rate is 0.015728216420257943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 27008/60000][Iteration 1360][Wall Clock 169.046072863s] Trained 64 records in 0.10676246 seconds. Throughput is 599.4616 records/second. Loss is 0.29988623. Sequential2290a28's hyper parameters: Current learning rate is 0.015725743041358705. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:31 INFO  DistriOptimizer$:408 - [Epoch 2 27072/60000][Iteration 1361][Wall Clock 169.142091166s] Trained 64 records in 0.096018303 seconds. Throughput is 666.5396 records/second. Loss is 0.32650542. Sequential2290a28's hyper parameters: Current learning rate is 0.015723270440251572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 1362][Wall Clock 169.237702882s] Trained 64 records in 0.095611716 seconds. Throughput is 669.374 records/second. Loss is 0.2512471. Sequential2290a28's hyper parameters: Current learning rate is 0.015720798616569723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27200/60000][Iteration 1363][Wall Clock 169.309719463s] Trained 64 records in 0.072016581 seconds. Throughput is 888.6842 records/second. Loss is 0.29703355. Sequential2290a28's hyper parameters: Current learning rate is 0.01571832756994656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27264/60000][Iteration 1364][Wall Clock 169.425079598s] Trained 64 records in 0.115360135 seconds. Throughput is 554.78436 records/second. Loss is 0.25673106. Sequential2290a28's hyper parameters: Current learning rate is 0.015715857300015717. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27328/60000][Iteration 1365][Wall Clock 169.541836511s] Trained 64 records in 0.116756913 seconds. Throughput is 548.1474 records/second. Loss is 0.26768985. Sequential2290a28's hyper parameters: Current learning rate is 0.01571338780641106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 1366][Wall Clock 169.651420674s] Trained 64 records in 0.109584163 seconds. Throughput is 584.026 records/second. Loss is 0.26276857. Sequential2290a28's hyper parameters: Current learning rate is 0.015710919088766692. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27456/60000][Iteration 1367][Wall Clock 169.728885114s] Trained 64 records in 0.07746444 seconds. Throughput is 826.18555 records/second. Loss is 0.35555786. Sequential2290a28's hyper parameters: Current learning rate is 0.015708451146716932. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27520/60000][Iteration 1368][Wall Clock 169.815382867s] Trained 64 records in 0.086497753 seconds. Throughput is 739.9036 records/second. Loss is 0.2611227. Sequential2290a28's hyper parameters: Current learning rate is 0.01570598397989634. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27584/60000][Iteration 1369][Wall Clock 169.886841362s] Trained 64 records in 0.071458495 seconds. Throughput is 895.62476 records/second. Loss is 0.35082403. Sequential2290a28's hyper parameters: Current learning rate is 0.015703517587939697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 1370][Wall Clock 169.967651435s] Trained 64 records in 0.080810073 seconds. Throughput is 791.9805 records/second. Loss is 0.21064055. Sequential2290a28's hyper parameters: Current learning rate is 0.01570105197048202. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:32 INFO  DistriOptimizer$:408 - [Epoch 2 27712/60000][Iteration 1371][Wall Clock 170.042444517s] Trained 64 records in 0.074793082 seconds. Throughput is 855.6941 records/second. Loss is 0.335593. Sequential2290a28's hyper parameters: Current learning rate is 0.015698587127158554. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 27776/60000][Iteration 1372][Wall Clock 170.197817782s] Trained 64 records in 0.155373265 seconds. Throughput is 411.9113 records/second. Loss is 0.21277052. Sequential2290a28's hyper parameters: Current learning rate is 0.01569612305760477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 27840/60000][Iteration 1373][Wall Clock 170.272714965s] Trained 64 records in 0.074897183 seconds. Throughput is 854.50476 records/second. Loss is 0.38029706. Sequential2290a28's hyper parameters: Current learning rate is 0.015693659761456372. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 1374][Wall Clock 170.354529935s] Trained 64 records in 0.08181497 seconds. Throughput is 782.2529 records/second. Loss is 0.21702354. Sequential2290a28's hyper parameters: Current learning rate is 0.015691197238349285. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 27968/60000][Iteration 1375][Wall Clock 170.504186766s] Trained 64 records in 0.149656831 seconds. Throughput is 427.64502 records/second. Loss is 0.25697136. Sequential2290a28's hyper parameters: Current learning rate is 0.015688735487919676. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28032/60000][Iteration 1376][Wall Clock 170.593350831s] Trained 64 records in 0.089164065 seconds. Throughput is 717.77795 records/second. Loss is 0.32341123. Sequential2290a28's hyper parameters: Current learning rate is 0.01568627450980392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28096/60000][Iteration 1377][Wall Clock 170.679303168s] Trained 64 records in 0.085952337 seconds. Throughput is 744.59875 records/second. Loss is 0.27538717. Sequential2290a28's hyper parameters: Current learning rate is 0.015683814303638646. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 1378][Wall Clock 170.757211384s] Trained 64 records in 0.077908216 seconds. Throughput is 821.47943 records/second. Loss is 0.20756654. Sequential2290a28's hyper parameters: Current learning rate is 0.015681354869060686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28224/60000][Iteration 1379][Wall Clock 170.835471456s] Trained 64 records in 0.078260072 seconds. Throughput is 817.78613 records/second. Loss is 0.41327864. Sequential2290a28's hyper parameters: Current learning rate is 0.01567889620570712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28288/60000][Iteration 1380][Wall Clock 170.90828229s] Trained 64 records in 0.072810834 seconds. Throughput is 878.99005 records/second. Loss is 0.21737118. Sequential2290a28's hyper parameters: Current learning rate is 0.015676438313215236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28352/60000][Iteration 1381][Wall Clock 170.997784391s] Trained 64 records in 0.089502101 seconds. Throughput is 715.067 records/second. Loss is 0.24617891. Sequential2290a28's hyper parameters: Current learning rate is 0.01567398119122257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:33 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 1382][Wall Clock 171.087715798s] Trained 64 records in 0.089931407 seconds. Throughput is 711.6535 records/second. Loss is 0.25825018. Sequential2290a28's hyper parameters: Current learning rate is 0.01567152483936687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28480/60000][Iteration 1383][Wall Clock 171.175412701s] Trained 64 records in 0.087696903 seconds. Throughput is 729.7863 records/second. Loss is 0.31417552. Sequential2290a28's hyper parameters: Current learning rate is 0.015669069257286117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28544/60000][Iteration 1384][Wall Clock 171.318438402s] Trained 64 records in 0.143025701 seconds. Throughput is 447.47205 records/second. Loss is 0.21021466. Sequential2290a28's hyper parameters: Current learning rate is 0.015666614444618518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28608/60000][Iteration 1385][Wall Clock 171.403281533s] Trained 64 records in 0.084843131 seconds. Throughput is 754.3333 records/second. Loss is 0.34877163. Sequential2290a28's hyper parameters: Current learning rate is 0.01566416040100251. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 1386][Wall Clock 171.502751546s] Trained 64 records in 0.099470013 seconds. Throughput is 643.41 records/second. Loss is 0.19158337. Sequential2290a28's hyper parameters: Current learning rate is 0.01566170712607674. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28736/60000][Iteration 1387][Wall Clock 171.604691596s] Trained 64 records in 0.10194005 seconds. Throughput is 627.81995 records/second. Loss is 0.20749442. Sequential2290a28's hyper parameters: Current learning rate is 0.01565925461948011. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28800/60000][Iteration 1388][Wall Clock 171.677339685s] Trained 64 records in 0.072648089 seconds. Throughput is 880.9592 records/second. Loss is 0.30805448. Sequential2290a28's hyper parameters: Current learning rate is 0.01565680288085173. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28864/60000][Iteration 1389][Wall Clock 171.764648633s] Trained 64 records in 0.087308948 seconds. Throughput is 733.02905 records/second. Loss is 0.2047284. Sequential2290a28's hyper parameters: Current learning rate is 0.015654351909830933. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 1390][Wall Clock 171.850965314s] Trained 64 records in 0.086316681 seconds. Throughput is 741.45575 records/second. Loss is 0.29538393. Sequential2290a28's hyper parameters: Current learning rate is 0.015651901706057285. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 28992/60000][Iteration 1391][Wall Clock 171.923088502s] Trained 64 records in 0.072123188 seconds. Throughput is 887.37067 records/second. Loss is 0.36274624. Sequential2290a28's hyper parameters: Current learning rate is 0.01564945226917058. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 29056/60000][Iteration 1392][Wall Clock 171.996482789s] Trained 64 records in 0.073394287 seconds. Throughput is 872.0025 records/second. Loss is 0.36882523. Sequential2290a28's hyper parameters: Current learning rate is 0.015647003598810827. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:34 INFO  DistriOptimizer$:408 - [Epoch 2 29120/60000][Iteration 1393][Wall Clock 172.073268338s] Trained 64 records in 0.076785549 seconds. Throughput is 833.4902 records/second. Loss is 0.20365211. Sequential2290a28's hyper parameters: Current learning rate is 0.015644555694618274. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 1394][Wall Clock 172.14673428s] Trained 64 records in 0.073465942 seconds. Throughput is 871.152 records/second. Loss is 0.35887322. Sequential2290a28's hyper parameters: Current learning rate is 0.01564210855623338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29248/60000][Iteration 1395][Wall Clock 172.236532613s] Trained 64 records in 0.089798333 seconds. Throughput is 712.7081 records/second. Loss is 0.29927313. Sequential2290a28's hyper parameters: Current learning rate is 0.01563966218329684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29312/60000][Iteration 1396][Wall Clock 172.324837617s] Trained 64 records in 0.088305004 seconds. Throughput is 724.76074 records/second. Loss is 0.1942642. Sequential2290a28's hyper parameters: Current learning rate is 0.015637216575449572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29376/60000][Iteration 1397][Wall Clock 172.413712802s] Trained 64 records in 0.088875185 seconds. Throughput is 720.111 records/second. Loss is 0.26215166. Sequential2290a28's hyper parameters: Current learning rate is 0.01563477173233271. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 1398][Wall Clock 172.556630527s] Trained 64 records in 0.142917725 seconds. Throughput is 447.8101 records/second. Loss is 0.31218457. Sequential2290a28's hyper parameters: Current learning rate is 0.01563232765358762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29504/60000][Iteration 1399][Wall Clock 172.648863967s] Trained 64 records in 0.09223344 seconds. Throughput is 693.8915 records/second. Loss is 0.37586576. Sequential2290a28's hyper parameters: Current learning rate is 0.01562988433885589. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29568/60000][Iteration 1400][Wall Clock 172.776551291s] Trained 64 records in 0.127687324 seconds. Throughput is 501.2244 records/second. Loss is 0.12191571. Sequential2290a28's hyper parameters: Current learning rate is 0.01562744178777934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29632/60000][Iteration 1401][Wall Clock 172.88709226s] Trained 64 records in 0.110540969 seconds. Throughput is 578.9708 records/second. Loss is 0.34514856. Sequential2290a28's hyper parameters: Current learning rate is 0.015625. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:35 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 1402][Wall Clock 173.011165251s] Trained 64 records in 0.124072991 seconds. Throughput is 515.8254 records/second. Loss is 0.3354976. Sequential2290a28's hyper parameters: Current learning rate is 0.015622558975160131. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 29760/60000][Iteration 1403][Wall Clock 173.14428099s] Trained 64 records in 0.133115739 seconds. Throughput is 480.7846 records/second. Loss is 0.21368553. Sequential2290a28's hyper parameters: Current learning rate is 0.015620118712902219. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 29824/60000][Iteration 1404][Wall Clock 173.229767942s] Trained 64 records in 0.085486952 seconds. Throughput is 748.6523 records/second. Loss is 0.21106015. Sequential2290a28's hyper parameters: Current learning rate is 0.015617679212868968. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 29888/60000][Iteration 1405][Wall Clock 173.310359117s] Trained 64 records in 0.080591175 seconds. Throughput is 794.13165 records/second. Loss is 0.31809708. Sequential2290a28's hyper parameters: Current learning rate is 0.015615240474703312. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 1406][Wall Clock 173.386154319s] Trained 64 records in 0.075795202 seconds. Throughput is 844.3806 records/second. Loss is 0.26088944. Sequential2290a28's hyper parameters: Current learning rate is 0.015612802498048398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30016/60000][Iteration 1407][Wall Clock 173.458478196s] Trained 64 records in 0.072323877 seconds. Throughput is 884.9083 records/second. Loss is 0.246115. Sequential2290a28's hyper parameters: Current learning rate is 0.015610365282547611. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30080/60000][Iteration 1408][Wall Clock 173.540580247s] Trained 64 records in 0.082102051 seconds. Throughput is 779.51764 records/second. Loss is 0.27699608. Sequential2290a28's hyper parameters: Current learning rate is 0.015607928827844545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30144/60000][Iteration 1409][Wall Clock 173.656379111s] Trained 64 records in 0.115798864 seconds. Throughput is 552.6825 records/second. Loss is 0.32514673. Sequential2290a28's hyper parameters: Current learning rate is 0.015605493133583021. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 1410][Wall Clock 173.735519368s] Trained 64 records in 0.079140257 seconds. Throughput is 808.69086 records/second. Loss is 0.20585635. Sequential2290a28's hyper parameters: Current learning rate is 0.015603058199407084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30272/60000][Iteration 1411][Wall Clock 173.819912654s] Trained 64 records in 0.084393286 seconds. Throughput is 758.3542 records/second. Loss is 0.28946525. Sequential2290a28's hyper parameters: Current learning rate is 0.015600624024960999. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30336/60000][Iteration 1412][Wall Clock 173.903306157s] Trained 64 records in 0.083393503 seconds. Throughput is 767.44586 records/second. Loss is 0.28195205. Sequential2290a28's hyper parameters: Current learning rate is 0.015598190609889253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30400/60000][Iteration 1413][Wall Clock 173.977327412s] Trained 64 records in 0.074021255 seconds. Throughput is 864.6165 records/second. Loss is 0.37161863. Sequential2290a28's hyper parameters: Current learning rate is 0.015595757953836557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:36 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 1414][Wall Clock 174.053821683s] Trained 64 records in 0.076494271 seconds. Throughput is 836.664 records/second. Loss is 0.32370752. Sequential2290a28's hyper parameters: Current learning rate is 0.01559332605644784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30528/60000][Iteration 1415][Wall Clock 174.129620853s] Trained 64 records in 0.07579917 seconds. Throughput is 844.3364 records/second. Loss is 0.4061787. Sequential2290a28's hyper parameters: Current learning rate is 0.015590894917368259. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30592/60000][Iteration 1416][Wall Clock 174.213152815s] Trained 64 records in 0.083531962 seconds. Throughput is 766.1738 records/second. Loss is 0.28420487. Sequential2290a28's hyper parameters: Current learning rate is 0.015588464536243182. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30656/60000][Iteration 1417][Wall Clock 174.292325765s] Trained 64 records in 0.07917295 seconds. Throughput is 808.35693 records/second. Loss is 0.30775303. Sequential2290a28's hyper parameters: Current learning rate is 0.015586034912718207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 1418][Wall Clock 174.370819026s] Trained 64 records in 0.078493261 seconds. Throughput is 815.3566 records/second. Loss is 0.14328906. Sequential2290a28's hyper parameters: Current learning rate is 0.015583606046439146. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30784/60000][Iteration 1419][Wall Clock 174.475802059s] Trained 64 records in 0.104983033 seconds. Throughput is 609.6223 records/second. Loss is 0.3040055. Sequential2290a28's hyper parameters: Current learning rate is 0.01558117793705204. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30848/60000][Iteration 1420][Wall Clock 174.572628593s] Trained 64 records in 0.096826534 seconds. Throughput is 660.9759 records/second. Loss is 0.2891549. Sequential2290a28's hyper parameters: Current learning rate is 0.015578750584203147. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30912/60000][Iteration 1421][Wall Clock 174.657940153s] Trained 64 records in 0.08531156 seconds. Throughput is 750.1914 records/second. Loss is 0.1325735. Sequential2290a28's hyper parameters: Current learning rate is 0.01557632398753894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 1422][Wall Clock 174.738163567s] Trained 64 records in 0.080223414 seconds. Throughput is 797.7721 records/second. Loss is 0.1754441. Sequential2290a28's hyper parameters: Current learning rate is 0.01557389814670612. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 31040/60000][Iteration 1423][Wall Clock 174.848307762s] Trained 64 records in 0.110144195 seconds. Throughput is 581.05646 records/second. Loss is 0.17307541. Sequential2290a28's hyper parameters: Current learning rate is 0.015571473061351605. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 31104/60000][Iteration 1424][Wall Clock 174.978378116s] Trained 64 records in 0.130070354 seconds. Throughput is 492.04138 records/second. Loss is 0.34125385. Sequential2290a28's hyper parameters: Current learning rate is 0.015569048731122529. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:37 INFO  DistriOptimizer$:408 - [Epoch 2 31168/60000][Iteration 1425][Wall Clock 175.060585072s] Trained 64 records in 0.082206956 seconds. Throughput is 778.5229 records/second. Loss is 0.20841315. Sequential2290a28's hyper parameters: Current learning rate is 0.015566625155666253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 1426][Wall Clock 175.170367939s] Trained 64 records in 0.109782867 seconds. Throughput is 582.96893 records/second. Loss is 0.28227222. Sequential2290a28's hyper parameters: Current learning rate is 0.015564202334630349. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31296/60000][Iteration 1427][Wall Clock 175.249152797s] Trained 64 records in 0.078784858 seconds. Throughput is 812.3388 records/second. Loss is 0.19919543. Sequential2290a28's hyper parameters: Current learning rate is 0.01556178026766262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31360/60000][Iteration 1428][Wall Clock 175.337712273s] Trained 64 records in 0.088559476 seconds. Throughput is 722.67816 records/second. Loss is 0.23558632. Sequential2290a28's hyper parameters: Current learning rate is 0.015559358954411077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31424/60000][Iteration 1429][Wall Clock 175.433354318s] Trained 64 records in 0.095642045 seconds. Throughput is 669.16174 records/second. Loss is 0.2832698. Sequential2290a28's hyper parameters: Current learning rate is 0.015556938394523956. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 1430][Wall Clock 175.513130969s] Trained 64 records in 0.079776651 seconds. Throughput is 802.23975 records/second. Loss is 0.23172769. Sequential2290a28's hyper parameters: Current learning rate is 0.015554518587649712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31552/60000][Iteration 1431][Wall Clock 175.605520482s] Trained 64 records in 0.092389513 seconds. Throughput is 692.7193 records/second. Loss is 0.24525534. Sequential2290a28's hyper parameters: Current learning rate is 0.015552099533437013. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31616/60000][Iteration 1432][Wall Clock 175.694303007s] Trained 64 records in 0.088782525 seconds. Throughput is 720.86255 records/second. Loss is 0.26235217. Sequential2290a28's hyper parameters: Current learning rate is 0.015549681231534754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31680/60000][Iteration 1433][Wall Clock 175.892414672s] Trained 64 records in 0.198111665 seconds. Throughput is 323.05014 records/second. Loss is 0.42682037. Sequential2290a28's hyper parameters: Current learning rate is 0.01554726368159204. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 1434][Wall Clock 176.001436531s] Trained 64 records in 0.109021859 seconds. Throughput is 587.03827 records/second. Loss is 0.22503185. Sequential2290a28's hyper parameters: Current learning rate is 0.0155448468832582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:38 INFO  DistriOptimizer$:408 - [Epoch 2 31808/60000][Iteration 1435][Wall Clock 176.104927639s] Trained 64 records in 0.103491108 seconds. Throughput is 618.41064 records/second. Loss is 0.31005943. Sequential2290a28's hyper parameters: Current learning rate is 0.01554243083618278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 31872/60000][Iteration 1436][Wall Clock 176.183529901s] Trained 64 records in 0.078602262 seconds. Throughput is 814.22595 records/second. Loss is 0.17901358. Sequential2290a28's hyper parameters: Current learning rate is 0.015540015540015542. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 31936/60000][Iteration 1437][Wall Clock 176.263881767s] Trained 64 records in 0.080351866 seconds. Throughput is 796.49677 records/second. Loss is 0.26534525. Sequential2290a28's hyper parameters: Current learning rate is 0.015537600994406466. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 1438][Wall Clock 176.357590233s] Trained 64 records in 0.093708466 seconds. Throughput is 682.96924 records/second. Loss is 0.22596464. Sequential2290a28's hyper parameters: Current learning rate is 0.01553518719900575. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32064/60000][Iteration 1439][Wall Clock 176.435267041s] Trained 64 records in 0.077676808 seconds. Throughput is 823.9267 records/second. Loss is 0.15881115. Sequential2290a28's hyper parameters: Current learning rate is 0.015532774153463809. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32128/60000][Iteration 1440][Wall Clock 176.51485642s] Trained 64 records in 0.079589379 seconds. Throughput is 804.1274 records/second. Loss is 0.22316715. Sequential2290a28's hyper parameters: Current learning rate is 0.015530361857431278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32192/60000][Iteration 1441][Wall Clock 176.604153491s] Trained 64 records in 0.089297071 seconds. Throughput is 716.70886 records/second. Loss is 0.17338431. Sequential2290a28's hyper parameters: Current learning rate is 0.015527950310559006. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 1442][Wall Clock 176.682035878s] Trained 64 records in 0.077882387 seconds. Throughput is 821.7519 records/second. Loss is 0.27734822. Sequential2290a28's hyper parameters: Current learning rate is 0.01552553951249806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32320/60000][Iteration 1443][Wall Clock 176.758607628s] Trained 64 records in 0.07657175 seconds. Throughput is 835.8174 records/second. Loss is 0.21706736. Sequential2290a28's hyper parameters: Current learning rate is 0.01552312946289972. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32384/60000][Iteration 1444][Wall Clock 176.84113476s] Trained 64 records in 0.082527132 seconds. Throughput is 775.50256 records/second. Loss is 0.3988388. Sequential2290a28's hyper parameters: Current learning rate is 0.01552072016141549. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32448/60000][Iteration 1445][Wall Clock 176.961324165s] Trained 64 records in 0.120189405 seconds. Throughput is 532.49286 records/second. Loss is 0.29983974. Sequential2290a28's hyper parameters: Current learning rate is 0.015518311607697084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:39 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 1446][Wall Clock 177.070126464s] Trained 64 records in 0.108802299 seconds. Throughput is 588.2229 records/second. Loss is 0.26859003. Sequential2290a28's hyper parameters: Current learning rate is 0.01551590380139643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32576/60000][Iteration 1447][Wall Clock 177.149969356s] Trained 64 records in 0.079842892 seconds. Throughput is 801.57416 records/second. Loss is 0.3582129. Sequential2290a28's hyper parameters: Current learning rate is 0.015513496742165683. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32640/60000][Iteration 1448][Wall Clock 177.277377147s] Trained 64 records in 0.127407791 seconds. Throughput is 502.32407 records/second. Loss is 0.23021293. Sequential2290a28's hyper parameters: Current learning rate is 0.015511090429657204. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32704/60000][Iteration 1449][Wall Clock 177.481758134s] Trained 64 records in 0.204380987 seconds. Throughput is 313.14066 records/second. Loss is 0.35285985. Sequential2290a28's hyper parameters: Current learning rate is 0.015508684863523572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 1450][Wall Clock 177.592217868s] Trained 64 records in 0.110459734 seconds. Throughput is 579.3966 records/second. Loss is 0.24270551. Sequential2290a28's hyper parameters: Current learning rate is 0.015506280043417585. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32832/60000][Iteration 1451][Wall Clock 177.715326004s] Trained 64 records in 0.123108136 seconds. Throughput is 519.86816 records/second. Loss is 0.30262113. Sequential2290a28's hyper parameters: Current learning rate is 0.015503875968992248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32896/60000][Iteration 1452][Wall Clock 177.834772539s] Trained 64 records in 0.119446535 seconds. Throughput is 535.80457 records/second. Loss is 0.1294753. Sequential2290a28's hyper parameters: Current learning rate is 0.01550147263990079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 32960/60000][Iteration 1453][Wall Clock 177.908703545s] Trained 64 records in 0.073931006 seconds. Throughput is 865.67194 records/second. Loss is 0.20683822. Sequential2290a28's hyper parameters: Current learning rate is 0.015499070055796652. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 1454][Wall Clock 177.994447586s] Trained 64 records in 0.085744041 seconds. Throughput is 746.4076 records/second. Loss is 0.32372022. Sequential2290a28's hyper parameters: Current learning rate is 0.01549666821633349. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:40 INFO  DistriOptimizer$:408 - [Epoch 2 33088/60000][Iteration 1455][Wall Clock 178.067402848s] Trained 64 records in 0.072955262 seconds. Throughput is 877.2499 records/second. Loss is 0.21524891. Sequential2290a28's hyper parameters: Current learning rate is 0.015494267121165169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33152/60000][Iteration 1456][Wall Clock 178.145038537s] Trained 64 records in 0.077635689 seconds. Throughput is 824.3631 records/second. Loss is 0.29390705. Sequential2290a28's hyper parameters: Current learning rate is 0.015491866769945779. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33216/60000][Iteration 1457][Wall Clock 178.221979915s] Trained 64 records in 0.076941378 seconds. Throughput is 831.8021 records/second. Loss is 0.3706175. Sequential2290a28's hyper parameters: Current learning rate is 0.015489467162329617. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 1458][Wall Clock 178.357937024s] Trained 64 records in 0.135957109 seconds. Throughput is 470.7367 records/second. Loss is 0.19446999. Sequential2290a28's hyper parameters: Current learning rate is 0.015487068297971196. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33344/60000][Iteration 1459][Wall Clock 178.546995853s] Trained 64 records in 0.189058829 seconds. Throughput is 338.51898 records/second. Loss is 0.29642993. Sequential2290a28's hyper parameters: Current learning rate is 0.01548467017652524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33408/60000][Iteration 1460][Wall Clock 178.644820808s] Trained 64 records in 0.097824955 seconds. Throughput is 654.2298 records/second. Loss is 0.4029764. Sequential2290a28's hyper parameters: Current learning rate is 0.015482272797646694. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33472/60000][Iteration 1461][Wall Clock 178.724410856s] Trained 64 records in 0.079590048 seconds. Throughput is 804.12067 records/second. Loss is 0.25427687. Sequential2290a28's hyper parameters: Current learning rate is 0.015479876160990712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 1462][Wall Clock 178.806825735s] Trained 64 records in 0.082414879 seconds. Throughput is 776.5588 records/second. Loss is 0.22536188. Sequential2290a28's hyper parameters: Current learning rate is 0.015477480266212661. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33600/60000][Iteration 1463][Wall Clock 178.895397572s] Trained 64 records in 0.088571837 seconds. Throughput is 722.5773 records/second. Loss is 0.16133425. Sequential2290a28's hyper parameters: Current learning rate is 0.015475085112968122. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33664/60000][Iteration 1464][Wall Clock 178.980084806s] Trained 64 records in 0.084687234 seconds. Throughput is 755.7219 records/second. Loss is 0.18711142. Sequential2290a28's hyper parameters: Current learning rate is 0.01547269070091289. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:41 INFO  DistriOptimizer$:408 - [Epoch 2 33728/60000][Iteration 1465][Wall Clock 179.051745159s] Trained 64 records in 0.071660353 seconds. Throughput is 893.1019 records/second. Loss is 0.21037471. Sequential2290a28's hyper parameters: Current learning rate is 0.015470297029702972. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 1466][Wall Clock 179.17394763s] Trained 64 records in 0.122202471 seconds. Throughput is 523.721 records/second. Loss is 0.1471408. Sequential2290a28's hyper parameters: Current learning rate is 0.015467904098994584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 33856/60000][Iteration 1467][Wall Clock 179.257475763s] Trained 64 records in 0.083528133 seconds. Throughput is 766.2089 records/second. Loss is 0.3537416. Sequential2290a28's hyper parameters: Current learning rate is 0.015465511908444168. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 33920/60000][Iteration 1468][Wall Clock 179.346169354s] Trained 64 records in 0.088693591 seconds. Throughput is 721.5854 records/second. Loss is 0.342359. Sequential2290a28's hyper parameters: Current learning rate is 0.015463120457708365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 33984/60000][Iteration 1469][Wall Clock 179.461526603s] Trained 64 records in 0.115357249 seconds. Throughput is 554.7982 records/second. Loss is 0.26978278. Sequential2290a28's hyper parameters: Current learning rate is 0.015460729746444031. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 1470][Wall Clock 179.602584832s] Trained 64 records in 0.141058229 seconds. Throughput is 453.71332 records/second. Loss is 0.2789705. Sequential2290a28's hyper parameters: Current learning rate is 0.015458339774308239. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 34112/60000][Iteration 1471][Wall Clock 179.731279096s] Trained 64 records in 0.128694264 seconds. Throughput is 497.30264 records/second. Loss is 0.15745102. Sequential2290a28's hyper parameters: Current learning rate is 0.015455950540958269. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 34176/60000][Iteration 1472][Wall Clock 179.847904818s] Trained 64 records in 0.116625722 seconds. Throughput is 548.76404 records/second. Loss is 0.1780745. Sequential2290a28's hyper parameters: Current learning rate is 0.015453562046051614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 34240/60000][Iteration 1473][Wall Clock 179.945154934s] Trained 64 records in 0.097250116 seconds. Throughput is 658.09686 records/second. Loss is 0.31235182. Sequential2290a28's hyper parameters: Current learning rate is 0.015451174289245983. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:42 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 1474][Wall Clock 180.066768514s] Trained 64 records in 0.12161358 seconds. Throughput is 526.257 records/second. Loss is 0.2333269. Sequential2290a28's hyper parameters: Current learning rate is 0.01544878727019929. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34368/60000][Iteration 1475][Wall Clock 180.215129545s] Trained 64 records in 0.148361031 seconds. Throughput is 431.38013 records/second. Loss is 0.22289203. Sequential2290a28's hyper parameters: Current learning rate is 0.015446400988569664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34432/60000][Iteration 1476][Wall Clock 180.333384487s] Trained 64 records in 0.118254942 seconds. Throughput is 541.2036 records/second. Loss is 0.29552528. Sequential2290a28's hyper parameters: Current learning rate is 0.015444015444015444. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34496/60000][Iteration 1477][Wall Clock 180.429435087s] Trained 64 records in 0.0960506 seconds. Throughput is 666.3155 records/second. Loss is 0.32446685. Sequential2290a28's hyper parameters: Current learning rate is 0.015441630636195183. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 1478][Wall Clock 180.558198067s] Trained 64 records in 0.12876298 seconds. Throughput is 497.0373 records/second. Loss is 0.19231817. Sequential2290a28's hyper parameters: Current learning rate is 0.01543924656476764. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34624/60000][Iteration 1479][Wall Clock 180.660888071s] Trained 64 records in 0.102690004 seconds. Throughput is 623.235 records/second. Loss is 0.12863135. Sequential2290a28's hyper parameters: Current learning rate is 0.015436863229391787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34688/60000][Iteration 1480][Wall Clock 180.743180501s] Trained 64 records in 0.08229243 seconds. Throughput is 777.7143 records/second. Loss is 0.33784804. Sequential2290a28's hyper parameters: Current learning rate is 0.01543448062972681. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34752/60000][Iteration 1481][Wall Clock 180.836027603s] Trained 64 records in 0.092847102 seconds. Throughput is 689.3053 records/second. Loss is 0.26296034. Sequential2290a28's hyper parameters: Current learning rate is 0.015432098765432098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 1482][Wall Clock 180.936500706s] Trained 64 records in 0.100473103 seconds. Throughput is 636.9864 records/second. Loss is 0.3428744. Sequential2290a28's hyper parameters: Current learning rate is 0.015429717636167259. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:43 INFO  DistriOptimizer$:408 - [Epoch 2 34880/60000][Iteration 1483][Wall Clock 181.039153883s] Trained 64 records in 0.102653177 seconds. Throughput is 623.45856 records/second. Loss is 0.34191674. Sequential2290a28's hyper parameters: Current learning rate is 0.015427337241592102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 34944/60000][Iteration 1484][Wall Clock 181.146075263s] Trained 64 records in 0.10692138 seconds. Throughput is 598.5706 records/second. Loss is 0.34593904. Sequential2290a28's hyper parameters: Current learning rate is 0.015424957581366652. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35008/60000][Iteration 1485][Wall Clock 181.247401732s] Trained 64 records in 0.101326469 seconds. Throughput is 631.62177 records/second. Loss is 0.20931774. Sequential2290a28's hyper parameters: Current learning rate is 0.015422578655151143. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 1486][Wall Clock 181.393304261s] Trained 64 records in 0.145902529 seconds. Throughput is 438.64902 records/second. Loss is 0.09191321. Sequential2290a28's hyper parameters: Current learning rate is 0.015420200462606013. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35136/60000][Iteration 1487][Wall Clock 181.462484691s] Trained 64 records in 0.06918043 seconds. Throughput is 925.1171 records/second. Loss is 0.25898227. Sequential2290a28's hyper parameters: Current learning rate is 0.01541782300339192. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35200/60000][Iteration 1488][Wall Clock 181.544949872s] Trained 64 records in 0.082465181 seconds. Throughput is 776.08514 records/second. Loss is 0.2870394. Sequential2290a28's hyper parameters: Current learning rate is 0.015415446277169722. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35264/60000][Iteration 1489][Wall Clock 181.615661163s] Trained 64 records in 0.070711291 seconds. Throughput is 905.0888 records/second. Loss is 0.21803945. Sequential2290a28's hyper parameters: Current learning rate is 0.015413070283600493. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 1490][Wall Clock 181.690834841s] Trained 64 records in 0.075173678 seconds. Throughput is 851.3619 records/second. Loss is 0.21940763. Sequential2290a28's hyper parameters: Current learning rate is 0.015410695022345508. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35392/60000][Iteration 1491][Wall Clock 181.7853775s] Trained 64 records in 0.094542659 seconds. Throughput is 676.9431 records/second. Loss is 0.17350435. Sequential2290a28's hyper parameters: Current learning rate is 0.015408320493066256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35456/60000][Iteration 1492][Wall Clock 181.871461627s] Trained 64 records in 0.086084127 seconds. Throughput is 743.4588 records/second. Loss is 0.20969054. Sequential2290a28's hyper parameters: Current learning rate is 0.015405946695424434. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35520/60000][Iteration 1493][Wall Clock 181.944443068s] Trained 64 records in 0.072981441 seconds. Throughput is 876.9353 records/second. Loss is 0.3134457. Sequential2290a28's hyper parameters: Current learning rate is 0.015403573629081947. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:44 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 1494][Wall Clock 182.067191691s] Trained 64 records in 0.122748623 seconds. Throughput is 521.3908 records/second. Loss is 0.2795955. Sequential2290a28's hyper parameters: Current learning rate is 0.015401201293700909. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 35648/60000][Iteration 1495][Wall Clock 182.137913594s] Trained 64 records in 0.070721903 seconds. Throughput is 904.95306 records/second. Loss is 0.263619. Sequential2290a28's hyper parameters: Current learning rate is 0.015398829688943641. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 35712/60000][Iteration 1496][Wall Clock 182.239456737s] Trained 64 records in 0.101543143 seconds. Throughput is 630.274 records/second. Loss is 0.17550494. Sequential2290a28's hyper parameters: Current learning rate is 0.015396458814472672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 35776/60000][Iteration 1497][Wall Clock 182.331065464s] Trained 64 records in 0.091608727 seconds. Throughput is 698.6234 records/second. Loss is 0.2633189. Sequential2290a28's hyper parameters: Current learning rate is 0.015394088669950741. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 1498][Wall Clock 182.435137444s] Trained 64 records in 0.10407198 seconds. Throughput is 614.959 records/second. Loss is 0.3267579. Sequential2290a28's hyper parameters: Current learning rate is 0.01539171925504079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 35904/60000][Iteration 1499][Wall Clock 182.524045119s] Trained 64 records in 0.088907675 seconds. Throughput is 719.8479 records/second. Loss is 0.19080853. Sequential2290a28's hyper parameters: Current learning rate is 0.01538935056940597. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 35968/60000][Iteration 1500][Wall Clock 182.676416769s] Trained 64 records in 0.15237165 seconds. Throughput is 420.02567 records/second. Loss is 0.17984496. Sequential2290a28's hyper parameters: Current learning rate is 0.015386982612709647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 36032/60000][Iteration 1501][Wall Clock 182.78692747s] Trained 64 records in 0.110510701 seconds. Throughput is 579.12946 records/second. Loss is 0.31802055. Sequential2290a28's hyper parameters: Current learning rate is 0.015384615384615384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 1502][Wall Clock 182.894896757s] Trained 64 records in 0.107969287 seconds. Throughput is 592.76117 records/second. Loss is 0.31550485. Sequential2290a28's hyper parameters: Current learning rate is 0.015382248884786957. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:45 INFO  DistriOptimizer$:408 - [Epoch 2 36160/60000][Iteration 1503][Wall Clock 183.032922848s] Trained 64 records in 0.138026091 seconds. Throughput is 463.68045 records/second. Loss is 0.1404115. Sequential2290a28's hyper parameters: Current learning rate is 0.015379883112888343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36224/60000][Iteration 1504][Wall Clock 183.128380484s] Trained 64 records in 0.095457636 seconds. Throughput is 670.45447 records/second. Loss is 0.16805212. Sequential2290a28's hyper parameters: Current learning rate is 0.01537751806858373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36288/60000][Iteration 1505][Wall Clock 183.23588336s] Trained 64 records in 0.107502876 seconds. Throughput is 595.3329 records/second. Loss is 0.20685929. Sequential2290a28's hyper parameters: Current learning rate is 0.015375153751537517. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 1506][Wall Clock 183.322196207s] Trained 64 records in 0.086312847 seconds. Throughput is 741.4887 records/second. Loss is 0.24635476. Sequential2290a28's hyper parameters: Current learning rate is 0.015372790161414298. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36416/60000][Iteration 1507][Wall Clock 183.468131977s] Trained 64 records in 0.14593577 seconds. Throughput is 438.54907 records/second. Loss is 0.13955203. Sequential2290a28's hyper parameters: Current learning rate is 0.01537042729787888. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36480/60000][Iteration 1508][Wall Clock 183.579246942s] Trained 64 records in 0.111114965 seconds. Throughput is 575.98004 records/second. Loss is 0.22009893. Sequential2290a28's hyper parameters: Current learning rate is 0.01536806516059628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36544/60000][Iteration 1509][Wall Clock 183.712796466s] Trained 64 records in 0.133549524 seconds. Throughput is 479.22296 records/second. Loss is 0.2982385. Sequential2290a28's hyper parameters: Current learning rate is 0.015365703749231715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 1510][Wall Clock 183.812580628s] Trained 64 records in 0.099784162 seconds. Throughput is 641.38434 records/second. Loss is 0.25679517. Sequential2290a28's hyper parameters: Current learning rate is 0.015363343063450606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36672/60000][Iteration 1511][Wall Clock 183.955203732s] Trained 64 records in 0.142623104 seconds. Throughput is 448.73517 records/second. Loss is 0.31840092. Sequential2290a28's hyper parameters: Current learning rate is 0.015360983102918587. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:46 INFO  DistriOptimizer$:408 - [Epoch 2 36736/60000][Iteration 1512][Wall Clock 184.051126603s] Trained 64 records in 0.095922871 seconds. Throughput is 667.2027 records/second. Loss is 0.24978517. Sequential2290a28's hyper parameters: Current learning rate is 0.01535862386730149. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 36800/60000][Iteration 1513][Wall Clock 184.140869224s] Trained 64 records in 0.089742621 seconds. Throughput is 713.1505 records/second. Loss is 0.21887115. Sequential2290a28's hyper parameters: Current learning rate is 0.015356265356265357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 1514][Wall Clock 184.239858614s] Trained 64 records in 0.09898939 seconds. Throughput is 646.53394 records/second. Loss is 0.25031134. Sequential2290a28's hyper parameters: Current learning rate is 0.015353907569476433. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 36928/60000][Iteration 1515][Wall Clock 184.333412263s] Trained 64 records in 0.093553649 seconds. Throughput is 684.0995 records/second. Loss is 0.15589829. Sequential2290a28's hyper parameters: Current learning rate is 0.015351550506601168. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 36992/60000][Iteration 1516][Wall Clock 184.408953552s] Trained 64 records in 0.075541289 seconds. Throughput is 847.2188 records/second. Loss is 0.3656763. Sequential2290a28's hyper parameters: Current learning rate is 0.015349194167306218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 37056/60000][Iteration 1517][Wall Clock 184.493228274s] Trained 64 records in 0.084274722 seconds. Throughput is 759.4211 records/second. Loss is 0.29915625. Sequential2290a28's hyper parameters: Current learning rate is 0.015346838551258441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 1518][Wall Clock 184.581192514s] Trained 64 records in 0.08796424 seconds. Throughput is 727.5684 records/second. Loss is 0.50025535. Sequential2290a28's hyper parameters: Current learning rate is 0.015344483658124906. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 37184/60000][Iteration 1519][Wall Clock 184.709864293s] Trained 64 records in 0.128671779 seconds. Throughput is 497.38956 records/second. Loss is 0.23711057. Sequential2290a28's hyper parameters: Current learning rate is 0.015342129487572874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 37248/60000][Iteration 1520][Wall Clock 184.804419777s] Trained 64 records in 0.094555484 seconds. Throughput is 676.8513 records/second. Loss is 0.26704478. Sequential2290a28's hyper parameters: Current learning rate is 0.015339776039269826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 37312/60000][Iteration 1521][Wall Clock 184.886404997s] Trained 64 records in 0.08198522 seconds. Throughput is 780.6285 records/second. Loss is 0.31324288. Sequential2290a28's hyper parameters: Current learning rate is 0.015337423312883436. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:47 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 1522][Wall Clock 184.996656632s] Trained 64 records in 0.110251635 seconds. Throughput is 580.49023 records/second. Loss is 0.2307269. Sequential2290a28's hyper parameters: Current learning rate is 0.015335071308081583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37440/60000][Iteration 1523][Wall Clock 185.070936766s] Trained 64 records in 0.074280134 seconds. Throughput is 861.60315 records/second. Loss is 0.37912583. Sequential2290a28's hyper parameters: Current learning rate is 0.015332720024532353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37504/60000][Iteration 1524][Wall Clock 185.163866115s] Trained 64 records in 0.092929349 seconds. Throughput is 688.69525 records/second. Loss is 0.29024643. Sequential2290a28's hyper parameters: Current learning rate is 0.015330369461904032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37568/60000][Iteration 1525][Wall Clock 185.23838513s] Trained 64 records in 0.074519015 seconds. Throughput is 858.8412 records/second. Loss is 0.2745991. Sequential2290a28's hyper parameters: Current learning rate is 0.015328019619865114. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 1526][Wall Clock 185.370566358s] Trained 64 records in 0.132181228 seconds. Throughput is 484.18375 records/second. Loss is 0.26367265. Sequential2290a28's hyper parameters: Current learning rate is 0.015325670498084292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37696/60000][Iteration 1527][Wall Clock 185.464902835s] Trained 64 records in 0.094336477 seconds. Throughput is 678.4226 records/second. Loss is 0.15400071. Sequential2290a28's hyper parameters: Current learning rate is 0.015323322096230461. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37760/60000][Iteration 1528][Wall Clock 185.562347441s] Trained 64 records in 0.097444606 seconds. Throughput is 656.7834 records/second. Loss is 0.29708678. Sequential2290a28's hyper parameters: Current learning rate is 0.015320974413972727. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37824/60000][Iteration 1529][Wall Clock 185.700329314s] Trained 64 records in 0.137981873 seconds. Throughput is 463.82904 records/second. Loss is 0.15453196. Sequential2290a28's hyper parameters: Current learning rate is 0.015318627450980392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 1530][Wall Clock 185.842535212s] Trained 64 records in 0.142205898 seconds. Throughput is 450.05167 records/second. Loss is 0.28099105. Sequential2290a28's hyper parameters: Current learning rate is 0.015316281206922959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:48 INFO  DistriOptimizer$:408 - [Epoch 2 37952/60000][Iteration 1531][Wall Clock 185.998129769s] Trained 64 records in 0.155594557 seconds. Throughput is 411.32544 records/second. Loss is 0.21697308. Sequential2290a28's hyper parameters: Current learning rate is 0.015313935681470138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38016/60000][Iteration 1532][Wall Clock 186.106625424s] Trained 64 records in 0.108495655 seconds. Throughput is 589.8854 records/second. Loss is 0.24970701. Sequential2290a28's hyper parameters: Current learning rate is 0.015311590874291839. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38080/60000][Iteration 1533][Wall Clock 186.24853934s] Trained 64 records in 0.141913916 seconds. Throughput is 450.9776 records/second. Loss is 0.28426525. Sequential2290a28's hyper parameters: Current learning rate is 0.015309246785058175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 1534][Wall Clock 186.3890751s] Trained 64 records in 0.14053576 seconds. Throughput is 455.40012 records/second. Loss is 0.2662222. Sequential2290a28's hyper parameters: Current learning rate is 0.015306903413439462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38208/60000][Iteration 1535][Wall Clock 186.48753178s] Trained 64 records in 0.09845668 seconds. Throughput is 650.03204 records/second. Loss is 0.3173132. Sequential2290a28's hyper parameters: Current learning rate is 0.015304560759106214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38272/60000][Iteration 1536][Wall Clock 186.580251119s] Trained 64 records in 0.092719339 seconds. Throughput is 690.2551 records/second. Loss is 0.191203. Sequential2290a28's hyper parameters: Current learning rate is 0.015302218821729151. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38336/60000][Iteration 1537][Wall Clock 186.761686924s] Trained 64 records in 0.181435805 seconds. Throughput is 352.74182 records/second. Loss is 0.23119965. Sequential2290a28's hyper parameters: Current learning rate is 0.015299877600979193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 1538][Wall Clock 186.854511479s] Trained 64 records in 0.092824555 seconds. Throughput is 689.4727 records/second. Loss is 0.36785415. Sequential2290a28's hyper parameters: Current learning rate is 0.015297537096527461. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:49 INFO  DistriOptimizer$:408 - [Epoch 2 38464/60000][Iteration 1539][Wall Clock 186.958080113s] Trained 64 records in 0.103568634 seconds. Throughput is 617.9477 records/second. Loss is 0.24224721. Sequential2290a28's hyper parameters: Current learning rate is 0.015295197308045273. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38528/60000][Iteration 1540][Wall Clock 187.116307388s] Trained 64 records in 0.158227275 seconds. Throughput is 404.48145 records/second. Loss is 0.3237083. Sequential2290a28's hyper parameters: Current learning rate is 0.01529285823520416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38592/60000][Iteration 1541][Wall Clock 187.215374946s] Trained 64 records in 0.099067558 seconds. Throughput is 646.0238 records/second. Loss is 0.28875268. Sequential2290a28's hyper parameters: Current learning rate is 0.01529051987767584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 1542][Wall Clock 187.329058782s] Trained 64 records in 0.113683836 seconds. Throughput is 562.96484 records/second. Loss is 0.22750875. Sequential2290a28's hyper parameters: Current learning rate is 0.015288182235132243. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38720/60000][Iteration 1543][Wall Clock 187.4278268s] Trained 64 records in 0.098768018 seconds. Throughput is 647.98303 records/second. Loss is 0.27602223. Sequential2290a28's hyper parameters: Current learning rate is 0.01528584530724549. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38784/60000][Iteration 1544][Wall Clock 187.545453181s] Trained 64 records in 0.117626381 seconds. Throughput is 544.09564 records/second. Loss is 0.20279588. Sequential2290a28's hyper parameters: Current learning rate is 0.01528350909368791. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38848/60000][Iteration 1545][Wall Clock 187.637582861s] Trained 64 records in 0.09212968 seconds. Throughput is 694.67303 records/second. Loss is 0.18234882. Sequential2290a28's hyper parameters: Current learning rate is 0.01528117359413203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 1546][Wall Clock 187.735732684s] Trained 64 records in 0.098149823 seconds. Throughput is 652.06433 records/second. Loss is 0.27912575. Sequential2290a28's hyper parameters: Current learning rate is 0.015278838808250574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 38976/60000][Iteration 1547][Wall Clock 187.859631706s] Trained 64 records in 0.123899022 seconds. Throughput is 516.5497 records/second. Loss is 0.21247067. Sequential2290a28's hyper parameters: Current learning rate is 0.015276504735716467. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 39040/60000][Iteration 1548][Wall Clock 187.950406641s] Trained 64 records in 0.090774935 seconds. Throughput is 705.0404 records/second. Loss is 0.18785247. Sequential2290a28's hyper parameters: Current learning rate is 0.01527417137620284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:50 INFO  DistriOptimizer$:408 - [Epoch 2 39104/60000][Iteration 1549][Wall Clock 188.041807738s] Trained 64 records in 0.091401097 seconds. Throughput is 700.2104 records/second. Loss is 0.26120526. Sequential2290a28's hyper parameters: Current learning rate is 0.015271838729383017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 1550][Wall Clock 188.118944881s] Trained 64 records in 0.077137143 seconds. Throughput is 829.6911 records/second. Loss is 0.41602466. Sequential2290a28's hyper parameters: Current learning rate is 0.015269506794930523. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39232/60000][Iteration 1551][Wall Clock 188.307530479s] Trained 64 records in 0.188585598 seconds. Throughput is 339.36844 records/second. Loss is 0.18610641. Sequential2290a28's hyper parameters: Current learning rate is 0.015267175572519083. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39296/60000][Iteration 1552][Wall Clock 188.399057951s] Trained 64 records in 0.091527472 seconds. Throughput is 699.24365 records/second. Loss is 0.21770324. Sequential2290a28's hyper parameters: Current learning rate is 0.015264845061822623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39360/60000][Iteration 1553][Wall Clock 188.501806904s] Trained 64 records in 0.102748953 seconds. Throughput is 622.8774 records/second. Loss is 0.3379911. Sequential2290a28's hyper parameters: Current learning rate is 0.015262515262515262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 1554][Wall Clock 188.60459525s] Trained 64 records in 0.102788346 seconds. Throughput is 622.6387 records/second. Loss is 0.18501115. Sequential2290a28's hyper parameters: Current learning rate is 0.015260186174271327. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39488/60000][Iteration 1555][Wall Clock 188.726396275s] Trained 64 records in 0.121801025 seconds. Throughput is 525.44714 records/second. Loss is 0.16328359. Sequential2290a28's hyper parameters: Current learning rate is 0.015257857796765336. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39552/60000][Iteration 1556][Wall Clock 188.822076914s] Trained 64 records in 0.095680639 seconds. Throughput is 668.89185 records/second. Loss is 0.33867365. Sequential2290a28's hyper parameters: Current learning rate is 0.015255530129672007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39616/60000][Iteration 1557][Wall Clock 188.908434403s] Trained 64 records in 0.086357489 seconds. Throughput is 741.1054 records/second. Loss is 0.28387904. Sequential2290a28's hyper parameters: Current learning rate is 0.015253203172666261. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:51 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 1558][Wall Clock 188.98558838s] Trained 64 records in 0.077153977 seconds. Throughput is 829.5101 records/second. Loss is 0.24523237. Sequential2290a28's hyper parameters: Current learning rate is 0.015250876925423214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 39744/60000][Iteration 1559][Wall Clock 189.065503628s] Trained 64 records in 0.079915248 seconds. Throughput is 800.84845 records/second. Loss is 0.26609594. Sequential2290a28's hyper parameters: Current learning rate is 0.015248551387618178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 39808/60000][Iteration 1560][Wall Clock 189.173408017s] Trained 64 records in 0.107904389 seconds. Throughput is 593.1177 records/second. Loss is 0.38884515. Sequential2290a28's hyper parameters: Current learning rate is 0.015246226558926665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 39872/60000][Iteration 1561][Wall Clock 189.374171423s] Trained 64 records in 0.200763406 seconds. Throughput is 318.7832 records/second. Loss is 0.3632158. Sequential2290a28's hyper parameters: Current learning rate is 0.01524390243902439. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 1562][Wall Clock 189.448371571s] Trained 64 records in 0.074200148 seconds. Throughput is 862.532 records/second. Loss is 0.28877926. Sequential2290a28's hyper parameters: Current learning rate is 0.015241579027587259. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 40000/60000][Iteration 1563][Wall Clock 189.567067659s] Trained 64 records in 0.118696088 seconds. Throughput is 539.19214 records/second. Loss is 0.19348255. Sequential2290a28's hyper parameters: Current learning rate is 0.015239256324291375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 40064/60000][Iteration 1564][Wall Clock 189.688634079s] Trained 64 records in 0.12156642 seconds. Throughput is 526.4612 records/second. Loss is 0.32574564. Sequential2290a28's hyper parameters: Current learning rate is 0.015236934328813043. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 40128/60000][Iteration 1565][Wall Clock 189.811344227s] Trained 64 records in 0.122710148 seconds. Throughput is 521.55426 records/second. Loss is 0.26764083. Sequential2290a28's hyper parameters: Current learning rate is 0.015234613040828763. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 1566][Wall Clock 189.891909021s] Trained 64 records in 0.080564794 seconds. Throughput is 794.3916 records/second. Loss is 0.19777298. Sequential2290a28's hyper parameters: Current learning rate is 0.015232292460015234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:52 INFO  DistriOptimizer$:408 - [Epoch 2 40256/60000][Iteration 1567][Wall Clock 189.990985069s] Trained 64 records in 0.099076048 seconds. Throughput is 645.96844 records/second. Loss is 0.26560855. Sequential2290a28's hyper parameters: Current learning rate is 0.015229972586049344. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40320/60000][Iteration 1568][Wall Clock 190.101570776s] Trained 64 records in 0.110585707 seconds. Throughput is 578.73663 records/second. Loss is 0.17563362. Sequential2290a28's hyper parameters: Current learning rate is 0.015227653418608192. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40384/60000][Iteration 1569][Wall Clock 190.188889543s] Trained 64 records in 0.087318767 seconds. Throughput is 732.94666 records/second. Loss is 0.19194832. Sequential2290a28's hyper parameters: Current learning rate is 0.01522533495736906. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 1570][Wall Clock 190.276394886s] Trained 64 records in 0.087505343 seconds. Throughput is 731.3839 records/second. Loss is 0.33420604. Sequential2290a28's hyper parameters: Current learning rate is 0.015223017202009437. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40512/60000][Iteration 1571][Wall Clock 190.37943668s] Trained 64 records in 0.103041794 seconds. Throughput is 621.10724 records/second. Loss is 0.29025877. Sequential2290a28's hyper parameters: Current learning rate is 0.015220700152207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40576/60000][Iteration 1572][Wall Clock 190.471499237s] Trained 64 records in 0.092062557 seconds. Throughput is 695.1795 records/second. Loss is 0.38562948. Sequential2290a28's hyper parameters: Current learning rate is 0.015218383807639629. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40640/60000][Iteration 1573][Wall Clock 190.57119985s] Trained 64 records in 0.099700613 seconds. Throughput is 641.9218 records/second. Loss is 0.33671975. Sequential2290a28's hyper parameters: Current learning rate is 0.015216068167985392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 1574][Wall Clock 190.687348232s] Trained 64 records in 0.116148382 seconds. Throughput is 551.0193 records/second. Loss is 0.26773423. Sequential2290a28's hyper parameters: Current learning rate is 0.015213753232922563. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40768/60000][Iteration 1575][Wall Clock 190.853969913s] Trained 64 records in 0.166621681 seconds. Throughput is 384.10367 records/second. Loss is 0.3377545. Sequential2290a28's hyper parameters: Current learning rate is 0.015211439002129602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:53 INFO  DistriOptimizer$:408 - [Epoch 2 40832/60000][Iteration 1576][Wall Clock 190.952286659s] Trained 64 records in 0.098316746 seconds. Throughput is 650.9573 records/second. Loss is 0.32505032. Sequential2290a28's hyper parameters: Current learning rate is 0.015209125475285173. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 40896/60000][Iteration 1577][Wall Clock 191.101804753s] Trained 64 records in 0.149518094 seconds. Throughput is 428.04187 records/second. Loss is 0.092257746. Sequential2290a28's hyper parameters: Current learning rate is 0.015206812652068127. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 1578][Wall Clock 191.204428103s] Trained 64 records in 0.10262335 seconds. Throughput is 623.6398 records/second. Loss is 0.30758226. Sequential2290a28's hyper parameters: Current learning rate is 0.01520450053215752. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41024/60000][Iteration 1579][Wall Clock 191.296545086s] Trained 64 records in 0.092116983 seconds. Throughput is 694.76874 records/second. Loss is 0.47441643. Sequential2290a28's hyper parameters: Current learning rate is 0.015202189115232596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41088/60000][Iteration 1580][Wall Clock 191.370963534s] Trained 64 records in 0.074418448 seconds. Throughput is 860.00183 records/second. Loss is 0.47316772. Sequential2290a28's hyper parameters: Current learning rate is 0.015199878400972791. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41152/60000][Iteration 1581][Wall Clock 191.45091172s] Trained 64 records in 0.079948186 seconds. Throughput is 800.5185 records/second. Loss is 0.113549106. Sequential2290a28's hyper parameters: Current learning rate is 0.015197568389057751. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 1582][Wall Clock 191.555404479s] Trained 64 records in 0.104492759 seconds. Throughput is 612.4826 records/second. Loss is 0.27491564. Sequential2290a28's hyper parameters: Current learning rate is 0.0151952590791673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41280/60000][Iteration 1583][Wall Clock 191.646562319s] Trained 64 records in 0.09115784 seconds. Throughput is 702.079 records/second. Loss is 0.32298222. Sequential2290a28's hyper parameters: Current learning rate is 0.015192950470981464. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41344/60000][Iteration 1584][Wall Clock 191.771482575s] Trained 64 records in 0.124920256 seconds. Throughput is 512.32684 records/second. Loss is 0.14119413. Sequential2290a28's hyper parameters: Current learning rate is 0.015190642564180465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41408/60000][Iteration 1585][Wall Clock 191.85712959s] Trained 64 records in 0.085647015 seconds. Throughput is 747.2531 records/second. Loss is 0.2299901. Sequential2290a28's hyper parameters: Current learning rate is 0.015188335358444716. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:54 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 1586][Wall Clock 191.934521534s] Trained 64 records in 0.077391944 seconds. Throughput is 826.9595 records/second. Loss is 0.3234573. Sequential2290a28's hyper parameters: Current learning rate is 0.015186028853454823. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41536/60000][Iteration 1587][Wall Clock 192.044903023s] Trained 64 records in 0.110381489 seconds. Throughput is 579.8074 records/second. Loss is 0.30194768. Sequential2290a28's hyper parameters: Current learning rate is 0.015183723048891587. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41600/60000][Iteration 1588][Wall Clock 192.123287669s] Trained 64 records in 0.078384646 seconds. Throughput is 816.48645 records/second. Loss is 0.31513518. Sequential2290a28's hyper parameters: Current learning rate is 0.01518141794443601. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41664/60000][Iteration 1589][Wall Clock 192.319206778s] Trained 64 records in 0.195919109 seconds. Throughput is 326.66544 records/second. Loss is 0.21651572. Sequential2290a28's hyper parameters: Current learning rate is 0.015179113539769277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 1590][Wall Clock 192.431420299s] Trained 64 records in 0.112213521 seconds. Throughput is 570.34125 records/second. Loss is 0.29571748. Sequential2290a28's hyper parameters: Current learning rate is 0.015176809834572771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41792/60000][Iteration 1591][Wall Clock 192.549898511s] Trained 64 records in 0.118478212 seconds. Throughput is 540.1837 records/second. Loss is 0.17424253. Sequential2290a28's hyper parameters: Current learning rate is 0.015174506828528072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41856/60000][Iteration 1592][Wall Clock 192.657799415s] Trained 64 records in 0.107900904 seconds. Throughput is 593.13684 records/second. Loss is 0.39511037. Sequential2290a28's hyper parameters: Current learning rate is 0.015172204521316948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41920/60000][Iteration 1593][Wall Clock 192.759356473s] Trained 64 records in 0.101557058 seconds. Throughput is 630.1876 records/second. Loss is 0.2693522. Sequential2290a28's hyper parameters: Current learning rate is 0.01516990291262136. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 1594][Wall Clock 192.851121859s] Trained 64 records in 0.091765386 seconds. Throughput is 697.4307 records/second. Loss is 0.19275422. Sequential2290a28's hyper parameters: Current learning rate is 0.015167602002123465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 42048/60000][Iteration 1595][Wall Clock 192.928713438s] Trained 64 records in 0.077591579 seconds. Throughput is 824.8318 records/second. Loss is 0.19414844. Sequential2290a28's hyper parameters: Current learning rate is 0.015165301789505611. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:55 INFO  DistriOptimizer$:408 - [Epoch 2 42112/60000][Iteration 1596][Wall Clock 193.004070844s] Trained 64 records in 0.075357406 seconds. Throughput is 849.28613 records/second. Loss is 0.267369. Sequential2290a28's hyper parameters: Current learning rate is 0.015163002274450343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42176/60000][Iteration 1597][Wall Clock 193.074736834s] Trained 64 records in 0.07066599 seconds. Throughput is 905.669 records/second. Loss is 0.1806728. Sequential2290a28's hyper parameters: Current learning rate is 0.01516070345664039. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 1598][Wall Clock 193.153715445s] Trained 64 records in 0.078978611 seconds. Throughput is 810.34595 records/second. Loss is 0.23533528. Sequential2290a28's hyper parameters: Current learning rate is 0.01515840533575868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42304/60000][Iteration 1599][Wall Clock 193.231403194s] Trained 64 records in 0.077687749 seconds. Throughput is 823.8107 records/second. Loss is 0.1502079. Sequential2290a28's hyper parameters: Current learning rate is 0.015156107911488331. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42368/60000][Iteration 1600][Wall Clock 193.323568373s] Trained 64 records in 0.092165179 seconds. Throughput is 694.4054 records/second. Loss is 0.25587595. Sequential2290a28's hyper parameters: Current learning rate is 0.015153811183512653. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42432/60000][Iteration 1601][Wall Clock 193.410658629s] Trained 64 records in 0.087090256 seconds. Throughput is 734.8698 records/second. Loss is 0.2366249. Sequential2290a28's hyper parameters: Current learning rate is 0.015151515151515152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 1602][Wall Clock 193.550939236s] Trained 64 records in 0.140280607 seconds. Throughput is 456.22842 records/second. Loss is 0.23642904. Sequential2290a28's hyper parameters: Current learning rate is 0.015149219815179518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42560/60000][Iteration 1603][Wall Clock 193.63583143s] Trained 64 records in 0.084892194 seconds. Throughput is 753.8974 records/second. Loss is 0.2429822. Sequential2290a28's hyper parameters: Current learning rate is 0.01514692517418964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42624/60000][Iteration 1604][Wall Clock 193.794588109s] Trained 64 records in 0.158756679 seconds. Throughput is 403.13266 records/second. Loss is 0.18135525. Sequential2290a28's hyper parameters: Current learning rate is 0.015144631228229594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:56 INFO  DistriOptimizer$:408 - [Epoch 2 42688/60000][Iteration 1605][Wall Clock 193.93063142s] Trained 64 records in 0.136043311 seconds. Throughput is 470.43842 records/second. Loss is 0.18741621. Sequential2290a28's hyper parameters: Current learning rate is 0.015142337976983647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 1606][Wall Clock 194.061136385s] Trained 64 records in 0.130504965 seconds. Throughput is 490.4028 records/second. Loss is 0.20721173. Sequential2290a28's hyper parameters: Current learning rate is 0.015140045420136262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 42816/60000][Iteration 1607][Wall Clock 194.157472922s] Trained 64 records in 0.096336537 seconds. Throughput is 664.33777 records/second. Loss is 0.24272928. Sequential2290a28's hyper parameters: Current learning rate is 0.015137753557372085. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 42880/60000][Iteration 1608][Wall Clock 194.23927515s] Trained 64 records in 0.081802228 seconds. Throughput is 782.3748 records/second. Loss is 0.29642507. Sequential2290a28's hyper parameters: Current learning rate is 0.015135462388375964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 42944/60000][Iteration 1609][Wall Clock 194.318685392s] Trained 64 records in 0.079410242 seconds. Throughput is 805.9414 records/second. Loss is 0.2673241. Sequential2290a28's hyper parameters: Current learning rate is 0.015133171912832928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 1610][Wall Clock 194.390104429s] Trained 64 records in 0.071419037 seconds. Throughput is 896.1196 records/second. Loss is 0.21238685. Sequential2290a28's hyper parameters: Current learning rate is 0.015130882130428203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43072/60000][Iteration 1611][Wall Clock 194.467478531s] Trained 64 records in 0.077374102 seconds. Throughput is 827.15015 records/second. Loss is 0.28464139. Sequential2290a28's hyper parameters: Current learning rate is 0.015128593040847202. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43136/60000][Iteration 1612][Wall Clock 194.543992898s] Trained 64 records in 0.076514367 seconds. Throughput is 836.4443 records/second. Loss is 0.27645198. Sequential2290a28's hyper parameters: Current learning rate is 0.015126304643775526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43200/60000][Iteration 1613][Wall Clock 194.627308532s] Trained 64 records in 0.083315634 seconds. Throughput is 768.16315 records/second. Loss is 0.23802419. Sequential2290a28's hyper parameters: Current learning rate is 0.015124016938898971. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 1614][Wall Clock 194.69818585s] Trained 64 records in 0.070877318 seconds. Throughput is 902.9687 records/second. Loss is 0.24819079. Sequential2290a28's hyper parameters: Current learning rate is 0.015121729925903524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43328/60000][Iteration 1615][Wall Clock 194.828307733s] Trained 64 records in 0.130121883 seconds. Throughput is 491.84653 records/second. Loss is 0.24853328. Sequential2290a28's hyper parameters: Current learning rate is 0.015119443604475357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:57 INFO  DistriOptimizer$:408 - [Epoch 2 43392/60000][Iteration 1616][Wall Clock 194.946134615s] Trained 64 records in 0.117826882 seconds. Throughput is 543.1698 records/second. Loss is 0.23666787. Sequential2290a28's hyper parameters: Current learning rate is 0.015117157974300832. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43456/60000][Iteration 1617][Wall Clock 195.031557475s] Trained 64 records in 0.08542286 seconds. Throughput is 749.214 records/second. Loss is 0.18914518. Sequential2290a28's hyper parameters: Current learning rate is 0.015114873035066506. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 1618][Wall Clock 195.112773136s] Trained 64 records in 0.081215661 seconds. Throughput is 788.0254 records/second. Loss is 0.24993432. Sequential2290a28's hyper parameters: Current learning rate is 0.015112588786459122. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43584/60000][Iteration 1619][Wall Clock 195.189500785s] Trained 64 records in 0.076727649 seconds. Throughput is 834.1191 records/second. Loss is 0.3962581. Sequential2290a28's hyper parameters: Current learning rate is 0.01511030522816561. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43648/60000][Iteration 1620][Wall Clock 195.269775325s] Trained 64 records in 0.08027454 seconds. Throughput is 797.26404 records/second. Loss is 0.23385614. Sequential2290a28's hyper parameters: Current learning rate is 0.015108022359873092. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43712/60000][Iteration 1621][Wall Clock 195.353712566s] Trained 64 records in 0.083937241 seconds. Throughput is 762.4744 records/second. Loss is 0.40995887. Sequential2290a28's hyper parameters: Current learning rate is 0.015105740181268881. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 1622][Wall Clock 195.442374884s] Trained 64 records in 0.088662318 seconds. Throughput is 721.8399 records/second. Loss is 0.16543993. Sequential2290a28's hyper parameters: Current learning rate is 0.015103458692040477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43840/60000][Iteration 1623][Wall Clock 195.521081058s] Trained 64 records in 0.078706174 seconds. Throughput is 813.15094 records/second. Loss is 0.3709563. Sequential2290a28's hyper parameters: Current learning rate is 0.015101177891875567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43904/60000][Iteration 1624][Wall Clock 195.637749381s] Trained 64 records in 0.116668323 seconds. Throughput is 548.56366 records/second. Loss is 0.32436472. Sequential2290a28's hyper parameters: Current learning rate is 0.015098897780462027. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 43968/60000][Iteration 1625][Wall Clock 195.721570559s] Trained 64 records in 0.083821178 seconds. Throughput is 763.5302 records/second. Loss is 0.29195. Sequential2290a28's hyper parameters: Current learning rate is 0.015096618357487924. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 1626][Wall Clock 195.805575294s] Trained 64 records in 0.084004735 seconds. Throughput is 761.8618 records/second. Loss is 0.21741264. Sequential2290a28's hyper parameters: Current learning rate is 0.01509433962264151. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 44096/60000][Iteration 1627][Wall Clock 195.884018049s] Trained 64 records in 0.078442755 seconds. Throughput is 815.8816 records/second. Loss is 0.28739163. Sequential2290a28's hyper parameters: Current learning rate is 0.01509206157561123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:58 INFO  DistriOptimizer$:408 - [Epoch 2 44160/60000][Iteration 1628][Wall Clock 196.014421979s] Trained 64 records in 0.13040393 seconds. Throughput is 490.78275 records/second. Loss is 0.17673212. Sequential2290a28's hyper parameters: Current learning rate is 0.015089784216085709. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44224/60000][Iteration 1629][Wall Clock 196.095362482s] Trained 64 records in 0.080940503 seconds. Throughput is 790.7043 records/second. Loss is 0.2730189. Sequential2290a28's hyper parameters: Current learning rate is 0.015087507543753771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 1630][Wall Clock 196.201024459s] Trained 64 records in 0.105661977 seconds. Throughput is 605.70514 records/second. Loss is 0.26941636. Sequential2290a28's hyper parameters: Current learning rate is 0.01508523155830442. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44352/60000][Iteration 1631][Wall Clock 196.310876341s] Trained 64 records in 0.109851882 seconds. Throughput is 582.60266 records/second. Loss is 0.23244798. Sequential2290a28's hyper parameters: Current learning rate is 0.015082956259426848. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44416/60000][Iteration 1632][Wall Clock 196.383881158s] Trained 64 records in 0.073004817 seconds. Throughput is 876.6545 records/second. Loss is 0.21328512. Sequential2290a28's hyper parameters: Current learning rate is 0.015080681646810435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44480/60000][Iteration 1633][Wall Clock 196.458880424s] Trained 64 records in 0.074999266 seconds. Throughput is 853.3417 records/second. Loss is 0.18925636. Sequential2290a28's hyper parameters: Current learning rate is 0.015078407720144753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 1634][Wall Clock 196.531473465s] Trained 64 records in 0.072593041 seconds. Throughput is 881.6272 records/second. Loss is 0.16007763. Sequential2290a28's hyper parameters: Current learning rate is 0.015076134479119555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44608/60000][Iteration 1635][Wall Clock 196.623579824s] Trained 64 records in 0.092106359 seconds. Throughput is 694.8489 records/second. Loss is 0.13763668. Sequential2290a28's hyper parameters: Current learning rate is 0.015073861923424782. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44672/60000][Iteration 1636][Wall Clock 196.707284272s] Trained 64 records in 0.083704448 seconds. Throughput is 764.595 records/second. Loss is 0.24500377. Sequential2290a28's hyper parameters: Current learning rate is 0.015071590052750565. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44736/60000][Iteration 1637][Wall Clock 196.800673181s] Trained 64 records in 0.093388909 seconds. Throughput is 685.3062 records/second. Loss is 0.17620462. Sequential2290a28's hyper parameters: Current learning rate is 0.015069318866787222. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 1638][Wall Clock 196.898534387s] Trained 64 records in 0.097861206 seconds. Throughput is 653.9874 records/second. Loss is 0.16283365. Sequential2290a28's hyper parameters: Current learning rate is 0.015067048365225254. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:16:59 INFO  DistriOptimizer$:408 - [Epoch 2 44864/60000][Iteration 1639][Wall Clock 196.989360402s] Trained 64 records in 0.090826015 seconds. Throughput is 704.6439 records/second. Loss is 0.35153905. Sequential2290a28's hyper parameters: Current learning rate is 0.015064778547755349. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 44928/60000][Iteration 1640][Wall Clock 197.098965943s] Trained 64 records in 0.109605541 seconds. Throughput is 583.91205 records/second. Loss is 0.2887689. Sequential2290a28's hyper parameters: Current learning rate is 0.015062509414068384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 44992/60000][Iteration 1641][Wall Clock 197.189078611s] Trained 64 records in 0.090112668 seconds. Throughput is 710.222 records/second. Loss is 0.37167236. Sequential2290a28's hyper parameters: Current learning rate is 0.015060240963855422. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 1642][Wall Clock 197.288620846s] Trained 64 records in 0.099542235 seconds. Throughput is 642.9432 records/second. Loss is 0.22149402. Sequential2290a28's hyper parameters: Current learning rate is 0.01505797319680771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45120/60000][Iteration 1643][Wall Clock 197.370298291s] Trained 64 records in 0.081677445 seconds. Throughput is 783.57007 records/second. Loss is 0.1704733. Sequential2290a28's hyper parameters: Current learning rate is 0.015055706112616682. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45184/60000][Iteration 1644][Wall Clock 197.44608418s] Trained 64 records in 0.075785889 seconds. Throughput is 844.4844 records/second. Loss is 0.26017314. Sequential2290a28's hyper parameters: Current learning rate is 0.015053439710973959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45248/60000][Iteration 1645][Wall Clock 197.520987379s] Trained 64 records in 0.074903199 seconds. Throughput is 854.43616 records/second. Loss is 0.22423676. Sequential2290a28's hyper parameters: Current learning rate is 0.015051173991571343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 1646][Wall Clock 197.592652778s] Trained 64 records in 0.071665399 seconds. Throughput is 893.03906 records/second. Loss is 0.23833549. Sequential2290a28's hyper parameters: Current learning rate is 0.01504890895410083. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45376/60000][Iteration 1647][Wall Clock 197.661980874s] Trained 64 records in 0.069328096 seconds. Throughput is 923.1466 records/second. Loss is 0.21752736. Sequential2290a28's hyper parameters: Current learning rate is 0.01504664459825459. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45440/60000][Iteration 1648][Wall Clock 197.74152836s] Trained 64 records in 0.079547486 seconds. Throughput is 804.55084 records/second. Loss is 0.18867567. Sequential2290a28's hyper parameters: Current learning rate is 0.015044380923724987. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45504/60000][Iteration 1649][Wall Clock 197.83683043s] Trained 64 records in 0.09530207 seconds. Throughput is 671.5489 records/second. Loss is 0.1964379. Sequential2290a28's hyper parameters: Current learning rate is 0.015042117930204572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 1650][Wall Clock 197.926543733s] Trained 64 records in 0.089713303 seconds. Throughput is 713.3836 records/second. Loss is 0.22265266. Sequential2290a28's hyper parameters: Current learning rate is 0.015039855617386072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:00 INFO  DistriOptimizer$:408 - [Epoch 2 45632/60000][Iteration 1651][Wall Clock 198.002605004s] Trained 64 records in 0.076061271 seconds. Throughput is 841.4269 records/second. Loss is 0.26300198. Sequential2290a28's hyper parameters: Current learning rate is 0.015037593984962405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 45696/60000][Iteration 1652][Wall Clock 198.102012687s] Trained 64 records in 0.099407683 seconds. Throughput is 643.8134 records/second. Loss is 0.22779326. Sequential2290a28's hyper parameters: Current learning rate is 0.015035333032626672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 45760/60000][Iteration 1653][Wall Clock 198.182400292s] Trained 64 records in 0.080387605 seconds. Throughput is 796.14264 records/second. Loss is 0.21614611. Sequential2290a28's hyper parameters: Current learning rate is 0.01503307276007216. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 1654][Wall Clock 198.28772586s] Trained 64 records in 0.105325568 seconds. Throughput is 607.6398 records/second. Loss is 0.15512371. Sequential2290a28's hyper parameters: Current learning rate is 0.015030813166992335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 45888/60000][Iteration 1655][Wall Clock 198.376346003s] Trained 64 records in 0.088620143 seconds. Throughput is 722.1835 records/second. Loss is 0.24074742. Sequential2290a28's hyper parameters: Current learning rate is 0.015028554253080854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 45952/60000][Iteration 1656][Wall Clock 198.469275329s] Trained 64 records in 0.092929326 seconds. Throughput is 688.69543 records/second. Loss is 0.17153904. Sequential2290a28's hyper parameters: Current learning rate is 0.015026296018031555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 46016/60000][Iteration 1657][Wall Clock 198.543652101s] Trained 64 records in 0.074376772 seconds. Throughput is 860.4837 records/second. Loss is 0.15018344. Sequential2290a28's hyper parameters: Current learning rate is 0.015024038461538462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 1658][Wall Clock 198.687573381s] Trained 64 records in 0.14392128 seconds. Throughput is 444.68753 records/second. Loss is 0.19622603. Sequential2290a28's hyper parameters: Current learning rate is 0.01502178158329578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 46144/60000][Iteration 1659][Wall Clock 198.814440442s] Trained 64 records in 0.126867061 seconds. Throughput is 504.4651 records/second. Loss is 0.3385997. Sequential2290a28's hyper parameters: Current learning rate is 0.0150195253829979. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:01 INFO  DistriOptimizer$:408 - [Epoch 2 46208/60000][Iteration 1660][Wall Clock 198.915282572s] Trained 64 records in 0.10084213 seconds. Throughput is 634.65533 records/second. Loss is 0.18435034. Sequential2290a28's hyper parameters: Current learning rate is 0.01501726986033939. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46272/60000][Iteration 1661][Wall Clock 199.041034636s] Trained 64 records in 0.125752064 seconds. Throughput is 508.938 records/second. Loss is 0.26142567. Sequential2290a28's hyper parameters: Current learning rate is 0.015015015015015015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 1662][Wall Clock 199.161253401s] Trained 64 records in 0.120218765 seconds. Throughput is 532.3628 records/second. Loss is 0.19684152. Sequential2290a28's hyper parameters: Current learning rate is 0.015012760846719712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46400/60000][Iteration 1663][Wall Clock 199.263143869s] Trained 64 records in 0.101890468 seconds. Throughput is 628.1255 records/second. Loss is 0.25954574. Sequential2290a28's hyper parameters: Current learning rate is 0.015010507355148604. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46464/60000][Iteration 1664][Wall Clock 199.386413097s] Trained 64 records in 0.123269228 seconds. Throughput is 519.1888 records/second. Loss is 0.42993742. Sequential2290a28's hyper parameters: Current learning rate is 0.015008254539996999. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46528/60000][Iteration 1665][Wall Clock 199.50680266s] Trained 64 records in 0.120389563 seconds. Throughput is 531.60754 records/second. Loss is 0.5396767. Sequential2290a28's hyper parameters: Current learning rate is 0.015006002400960384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 1666][Wall Clock 199.656690593s] Trained 64 records in 0.149887933 seconds. Throughput is 426.98566 records/second. Loss is 0.1888142. Sequential2290a28's hyper parameters: Current learning rate is 0.015003750937734435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46656/60000][Iteration 1667][Wall Clock 199.772765908s] Trained 64 records in 0.116075315 seconds. Throughput is 551.36615 records/second. Loss is 0.259708. Sequential2290a28's hyper parameters: Current learning rate is 0.015001500150015003. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:02 INFO  DistriOptimizer$:408 - [Epoch 2 46720/60000][Iteration 1668][Wall Clock 199.945488685s] Trained 64 records in 0.172722777 seconds. Throughput is 370.53598 records/second. Loss is 0.3852226. Sequential2290a28's hyper parameters: Current learning rate is 0.014999250037498123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 46784/60000][Iteration 1669][Wall Clock 200.092257985s] Trained 64 records in 0.1467693 seconds. Throughput is 436.0585 records/second. Loss is 0.23018417. Sequential2290a28's hyper parameters: Current learning rate is 0.014997000599880022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 1670][Wall Clock 200.272694577s] Trained 64 records in 0.180436592 seconds. Throughput is 354.69522 records/second. Loss is 0.38197064. Sequential2290a28's hyper parameters: Current learning rate is 0.0149947518368571. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 46912/60000][Iteration 1671][Wall Clock 200.41363887s] Trained 64 records in 0.140944293 seconds. Throughput is 454.08014 records/second. Loss is 0.10344707. Sequential2290a28's hyper parameters: Current learning rate is 0.014992503748125937. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 46976/60000][Iteration 1672][Wall Clock 200.573990888s] Trained 64 records in 0.160352018 seconds. Throughput is 399.1219 records/second. Loss is 0.22496955. Sequential2290a28's hyper parameters: Current learning rate is 0.0149902563333833. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 47040/60000][Iteration 1673][Wall Clock 200.69952856s] Trained 64 records in 0.125537672 seconds. Throughput is 509.8071 records/second. Loss is 0.21328351. Sequential2290a28's hyper parameters: Current learning rate is 0.01498800959232614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 1674][Wall Clock 200.810826512s] Trained 64 records in 0.111297952 seconds. Throughput is 575.0331 records/second. Loss is 0.13551176. Sequential2290a28's hyper parameters: Current learning rate is 0.014985763524651582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:03 INFO  DistriOptimizer$:408 - [Epoch 2 47168/60000][Iteration 1675][Wall Clock 200.892498793s] Trained 64 records in 0.081672281 seconds. Throughput is 783.61957 records/second. Loss is 0.26863673. Sequential2290a28's hyper parameters: Current learning rate is 0.014983518130056939. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47232/60000][Iteration 1676][Wall Clock 200.998024212s] Trained 64 records in 0.105525419 seconds. Throughput is 606.48895 records/second. Loss is 0.24976474. Sequential2290a28's hyper parameters: Current learning rate is 0.0149812734082397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47296/60000][Iteration 1677][Wall Clock 201.089447286s] Trained 64 records in 0.091423074 seconds. Throughput is 700.0421 records/second. Loss is 0.29809767. Sequential2290a28's hyper parameters: Current learning rate is 0.014979029358897545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 1678][Wall Clock 201.259111765s] Trained 64 records in 0.169664479 seconds. Throughput is 377.2151 records/second. Loss is 0.22862422. Sequential2290a28's hyper parameters: Current learning rate is 0.014976785981728323. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47424/60000][Iteration 1679][Wall Clock 201.395184392s] Trained 64 records in 0.136072627 seconds. Throughput is 470.3371 records/second. Loss is 0.36806816. Sequential2290a28's hyper parameters: Current learning rate is 0.01497454327643007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47488/60000][Iteration 1680][Wall Clock 201.572976771s] Trained 64 records in 0.177792379 seconds. Throughput is 359.97043 records/second. Loss is 0.1587202. Sequential2290a28's hyper parameters: Current learning rate is 0.014972301242701002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47552/60000][Iteration 1681][Wall Clock 201.692586634s] Trained 64 records in 0.119609863 seconds. Throughput is 535.07294 records/second. Loss is 0.27259564. Sequential2290a28's hyper parameters: Current learning rate is 0.014970059880239521. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 1682][Wall Clock 201.811162068s] Trained 64 records in 0.118575434 seconds. Throughput is 539.74084 records/second. Loss is 0.315208. Sequential2290a28's hyper parameters: Current learning rate is 0.0149678191887442. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:04 INFO  DistriOptimizer$:408 - [Epoch 2 47680/60000][Iteration 1683][Wall Clock 201.93376791s] Trained 64 records in 0.122605842 seconds. Throughput is 521.9979 records/second. Loss is 0.17495827. Sequential2290a28's hyper parameters: Current learning rate is 0.014965579167913799. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 47744/60000][Iteration 1684][Wall Clock 202.052863292s] Trained 64 records in 0.119095382 seconds. Throughput is 537.3844 records/second. Loss is 0.23599091. Sequential2290a28's hyper parameters: Current learning rate is 0.014963339817447255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 47808/60000][Iteration 1685][Wall Clock 202.217739527s] Trained 64 records in 0.164876235 seconds. Throughput is 388.16995 records/second. Loss is 0.2122424. Sequential2290a28's hyper parameters: Current learning rate is 0.014961101137043686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 1686][Wall Clock 202.296586974s] Trained 64 records in 0.078847447 seconds. Throughput is 811.69403 records/second. Loss is 0.1807484. Sequential2290a28's hyper parameters: Current learning rate is 0.014958863126402395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 47936/60000][Iteration 1687][Wall Clock 202.412428182s] Trained 64 records in 0.115841208 seconds. Throughput is 552.4804 records/second. Loss is 0.14866053. Sequential2290a28's hyper parameters: Current learning rate is 0.014956625785222855. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 48000/60000][Iteration 1688][Wall Clock 202.487843925s] Trained 64 records in 0.075415743 seconds. Throughput is 848.62915 records/second. Loss is 0.2298285. Sequential2290a28's hyper parameters: Current learning rate is 0.014954389113204724. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 48064/60000][Iteration 1689][Wall Clock 202.563159191s] Trained 64 records in 0.075315266 seconds. Throughput is 849.7613 records/second. Loss is 0.35778993. Sequential2290a28's hyper parameters: Current learning rate is 0.014952153110047845. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 1690][Wall Clock 202.659164592s] Trained 64 records in 0.096005401 seconds. Throughput is 666.62915 records/second. Loss is 0.14937025. Sequential2290a28's hyper parameters: Current learning rate is 0.014949917775452234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 48192/60000][Iteration 1691][Wall Clock 202.770531692s] Trained 64 records in 0.1113671 seconds. Throughput is 574.676 records/second. Loss is 0.27788836. Sequential2290a28's hyper parameters: Current learning rate is 0.014947683109118086. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:05 INFO  DistriOptimizer$:408 - [Epoch 2 48256/60000][Iteration 1692][Wall Clock 202.895551706s] Trained 64 records in 0.125020014 seconds. Throughput is 511.91803 records/second. Loss is 0.24833363. Sequential2290a28's hyper parameters: Current learning rate is 0.014945449110745778. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48320/60000][Iteration 1693][Wall Clock 202.985765195s] Trained 64 records in 0.090213489 seconds. Throughput is 709.4282 records/second. Loss is 0.19049704. Sequential2290a28's hyper parameters: Current learning rate is 0.014943215780035863. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 1694][Wall Clock 203.076868352s] Trained 64 records in 0.091103157 seconds. Throughput is 702.50037 records/second. Loss is 0.17373015. Sequential2290a28's hyper parameters: Current learning rate is 0.014940983116689078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48448/60000][Iteration 1695][Wall Clock 203.161613621s] Trained 64 records in 0.084745269 seconds. Throughput is 755.2044 records/second. Loss is 0.3477564. Sequential2290a28's hyper parameters: Current learning rate is 0.014938751120406334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48512/60000][Iteration 1696][Wall Clock 203.237199528s] Trained 64 records in 0.075585907 seconds. Throughput is 846.7187 records/second. Loss is 0.24206372. Sequential2290a28's hyper parameters: Current learning rate is 0.014936519790888723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48576/60000][Iteration 1697][Wall Clock 203.313242287s] Trained 64 records in 0.076042759 seconds. Throughput is 841.6318 records/second. Loss is 0.102067575. Sequential2290a28's hyper parameters: Current learning rate is 0.014934289127837517. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 1698][Wall Clock 203.386403548s] Trained 64 records in 0.073161261 seconds. Throughput is 874.7799 records/second. Loss is 0.27028927. Sequential2290a28's hyper parameters: Current learning rate is 0.01493205913095416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48704/60000][Iteration 1699][Wall Clock 203.498439708s] Trained 64 records in 0.11203616 seconds. Throughput is 571.24414 records/second. Loss is 0.30062783. Sequential2290a28's hyper parameters: Current learning rate is 0.014929829799940283. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48768/60000][Iteration 1700][Wall Clock 203.569316366s] Trained 64 records in 0.070876658 seconds. Throughput is 902.9771 records/second. Loss is 0.26769435. Sequential2290a28's hyper parameters: Current learning rate is 0.014927601134497688. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48832/60000][Iteration 1701][Wall Clock 203.719028062s] Trained 64 records in 0.149711696 seconds. Throughput is 427.4883 records/second. Loss is 0.1463645. Sequential2290a28's hyper parameters: Current learning rate is 0.014925373134328358. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 1702][Wall Clock 203.836931898s] Trained 64 records in 0.117903836 seconds. Throughput is 542.81525 records/second. Loss is 0.21857733. Sequential2290a28's hyper parameters: Current learning rate is 0.014923145799134457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:06 INFO  DistriOptimizer$:408 - [Epoch 2 48960/60000][Iteration 1703][Wall Clock 203.939792308s] Trained 64 records in 0.10286041 seconds. Throughput is 622.20245 records/second. Loss is 0.24319372. Sequential2290a28's hyper parameters: Current learning rate is 0.014920919128618322. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49024/60000][Iteration 1704][Wall Clock 204.027436144s] Trained 64 records in 0.087643836 seconds. Throughput is 730.22815 records/second. Loss is 0.16828784. Sequential2290a28's hyper parameters: Current learning rate is 0.01491869312248247. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49088/60000][Iteration 1705][Wall Clock 204.113905263s] Trained 64 records in 0.086469119 seconds. Throughput is 740.1486 records/second. Loss is 0.2206407. Sequential2290a28's hyper parameters: Current learning rate is 0.014916467780429595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 1706][Wall Clock 204.196733845s] Trained 64 records in 0.082828582 seconds. Throughput is 772.6801 records/second. Loss is 0.3198384. Sequential2290a28's hyper parameters: Current learning rate is 0.014914243102162566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49216/60000][Iteration 1707][Wall Clock 204.267502614s] Trained 64 records in 0.070768769 seconds. Throughput is 904.35376 records/second. Loss is 0.34659874. Sequential2290a28's hyper parameters: Current learning rate is 0.014912019087384433. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49280/60000][Iteration 1708][Wall Clock 204.342877115s] Trained 64 records in 0.075374501 seconds. Throughput is 849.09357 records/second. Loss is 0.16237064. Sequential2290a28's hyper parameters: Current learning rate is 0.014909795735798419. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49344/60000][Iteration 1709][Wall Clock 204.428129704s] Trained 64 records in 0.085252589 seconds. Throughput is 750.7103 records/second. Loss is 0.21047416. Sequential2290a28's hyper parameters: Current learning rate is 0.014907573047107929. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 1710][Wall Clock 204.540417314s] Trained 64 records in 0.11228761 seconds. Throughput is 569.9649 records/second. Loss is 0.33914772. Sequential2290a28's hyper parameters: Current learning rate is 0.014905351021016543. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49472/60000][Iteration 1711][Wall Clock 204.652665488s] Trained 64 records in 0.112248174 seconds. Throughput is 570.16516 records/second. Loss is 0.2928385. Sequential2290a28's hyper parameters: Current learning rate is 0.014903129657228018. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49536/60000][Iteration 1712][Wall Clock 204.72427198s] Trained 64 records in 0.071606492 seconds. Throughput is 893.7737 records/second. Loss is 0.31737277. Sequential2290a28's hyper parameters: Current learning rate is 0.014900908955446282. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49600/60000][Iteration 1713][Wall Clock 204.800003253s] Trained 64 records in 0.075731273 seconds. Throughput is 845.09344 records/second. Loss is 0.14134935. Sequential2290a28's hyper parameters: Current learning rate is 0.014898688915375448. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:07 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 1714][Wall Clock 204.873862636s] Trained 64 records in 0.073859383 seconds. Throughput is 866.5114 records/second. Loss is 0.3311623. Sequential2290a28's hyper parameters: Current learning rate is 0.014896469536719798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 49728/60000][Iteration 1715][Wall Clock 204.996979601s] Trained 64 records in 0.123116965 seconds. Throughput is 519.8309 records/second. Loss is 0.28377014. Sequential2290a28's hyper parameters: Current learning rate is 0.014894250819183795. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 49792/60000][Iteration 1716][Wall Clock 205.087243179s] Trained 64 records in 0.090263578 seconds. Throughput is 709.0346 records/second. Loss is 0.27132037. Sequential2290a28's hyper parameters: Current learning rate is 0.014892032762472078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 49856/60000][Iteration 1717][Wall Clock 205.204623438s] Trained 64 records in 0.117380259 seconds. Throughput is 545.23645 records/second. Loss is 0.25542235. Sequential2290a28's hyper parameters: Current learning rate is 0.01488981536628946. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 1718][Wall Clock 205.342749856s] Trained 64 records in 0.138126418 seconds. Throughput is 463.34366 records/second. Loss is 0.26868707. Sequential2290a28's hyper parameters: Current learning rate is 0.014887598630340927. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 49984/60000][Iteration 1719][Wall Clock 205.45929776s] Trained 64 records in 0.116547904 seconds. Throughput is 549.13043 records/second. Loss is 0.24318007. Sequential2290a28's hyper parameters: Current learning rate is 0.014885382554331647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 50048/60000][Iteration 1720][Wall Clock 205.57571896s] Trained 64 records in 0.1164212 seconds. Throughput is 549.728 records/second. Loss is 0.27646828. Sequential2290a28's hyper parameters: Current learning rate is 0.014883167137966962. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 50112/60000][Iteration 1721][Wall Clock 205.650539567s] Trained 64 records in 0.074820607 seconds. Throughput is 855.37933 records/second. Loss is 0.20687342. Sequential2290a28's hyper parameters: Current learning rate is 0.01488095238095238. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 1722][Wall Clock 205.782819768s] Trained 64 records in 0.132280201 seconds. Throughput is 483.82147 records/second. Loss is 0.26581767. Sequential2290a28's hyper parameters: Current learning rate is 0.014878738282993602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:08 INFO  DistriOptimizer$:408 - [Epoch 2 50240/60000][Iteration 1723][Wall Clock 205.905753413s] Trained 64 records in 0.122933645 seconds. Throughput is 520.606 records/second. Loss is 0.14038417. Sequential2290a28's hyper parameters: Current learning rate is 0.01487652484379649. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50304/60000][Iteration 1724][Wall Clock 206.071693603s] Trained 64 records in 0.16594019 seconds. Throughput is 385.68112 records/second. Loss is 0.35789555. Sequential2290a28's hyper parameters: Current learning rate is 0.014874312063067083. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50368/60000][Iteration 1725][Wall Clock 206.156535452s] Trained 64 records in 0.084841849 seconds. Throughput is 754.3447 records/second. Loss is 0.21639569. Sequential2290a28's hyper parameters: Current learning rate is 0.0148720999405116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 1726][Wall Clock 206.269478033s] Trained 64 records in 0.112942581 seconds. Throughput is 566.6596 records/second. Loss is 0.24252433. Sequential2290a28's hyper parameters: Current learning rate is 0.014869888475836432. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50496/60000][Iteration 1727][Wall Clock 206.42527873s] Trained 64 records in 0.155800697 seconds. Throughput is 410.78122 records/second. Loss is 0.3953724. Sequential2290a28's hyper parameters: Current learning rate is 0.014867677668748143. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50560/60000][Iteration 1728][Wall Clock 206.566642086s] Trained 64 records in 0.141363356 seconds. Throughput is 452.73404 records/second. Loss is 0.232415. Sequential2290a28's hyper parameters: Current learning rate is 0.014865467518953469. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50624/60000][Iteration 1729][Wall Clock 206.668122076s] Trained 64 records in 0.10147999 seconds. Throughput is 630.6662 records/second. Loss is 0.2713039. Sequential2290a28's hyper parameters: Current learning rate is 0.014863258026159332. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 1730][Wall Clock 206.762696369s] Trained 64 records in 0.094574293 seconds. Throughput is 676.7167 records/second. Loss is 0.21683532. Sequential2290a28's hyper parameters: Current learning rate is 0.014861049190072818. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50752/60000][Iteration 1731][Wall Clock 206.84358294s] Trained 64 records in 0.080886571 seconds. Throughput is 791.23145 records/second. Loss is 0.12614746. Sequential2290a28's hyper parameters: Current learning rate is 0.014858841010401188. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:09 INFO  DistriOptimizer$:408 - [Epoch 2 50816/60000][Iteration 1732][Wall Clock 206.95289143s] Trained 64 records in 0.10930849 seconds. Throughput is 585.4989 records/second. Loss is 0.124010116. Sequential2290a28's hyper parameters: Current learning rate is 0.01485663348685188. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 50880/60000][Iteration 1733][Wall Clock 207.028413809s] Trained 64 records in 0.075522379 seconds. Throughput is 847.43097 records/second. Loss is 0.30629405. Sequential2290a28's hyper parameters: Current learning rate is 0.014854426619132501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 1734][Wall Clock 207.100079749s] Trained 64 records in 0.07166594 seconds. Throughput is 893.0323 records/second. Loss is 0.2846558. Sequential2290a28's hyper parameters: Current learning rate is 0.014852220406950839. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51008/60000][Iteration 1735][Wall Clock 207.179889697s] Trained 64 records in 0.079809948 seconds. Throughput is 801.905 records/second. Loss is 0.18977383. Sequential2290a28's hyper parameters: Current learning rate is 0.01485001485001485. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51072/60000][Iteration 1736][Wall Clock 207.2533399s] Trained 64 records in 0.073450203 seconds. Throughput is 871.3387 records/second. Loss is 0.19493961. Sequential2290a28's hyper parameters: Current learning rate is 0.014847809948032666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51136/60000][Iteration 1737][Wall Clock 207.335384492s] Trained 64 records in 0.082044592 seconds. Throughput is 780.0636 records/second. Loss is 0.3494691. Sequential2290a28's hyper parameters: Current learning rate is 0.01484560570071259. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 1738][Wall Clock 207.442393377s] Trained 64 records in 0.107008885 seconds. Throughput is 598.0812 records/second. Loss is 0.18209216. Sequential2290a28's hyper parameters: Current learning rate is 0.0148434021077631. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51264/60000][Iteration 1739][Wall Clock 207.531562895s] Trained 64 records in 0.089169518 seconds. Throughput is 717.7341 records/second. Loss is 0.18255243. Sequential2290a28's hyper parameters: Current learning rate is 0.014841199168892847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51328/60000][Iteration 1740][Wall Clock 207.605824996s] Trained 64 records in 0.074262101 seconds. Throughput is 861.81244 records/second. Loss is 0.15403943. Sequential2290a28's hyper parameters: Current learning rate is 0.014838996883810657. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51392/60000][Iteration 1741][Wall Clock 207.703281601s] Trained 64 records in 0.097456605 seconds. Throughput is 656.7025 records/second. Loss is 0.2657765. Sequential2290a28's hyper parameters: Current learning rate is 0.014836795252225518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 1742][Wall Clock 207.787260944s] Trained 64 records in 0.083979343 seconds. Throughput is 762.09216 records/second. Loss is 0.1005422. Sequential2290a28's hyper parameters: Current learning rate is 0.01483459427384661. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51520/60000][Iteration 1743][Wall Clock 207.872456309s] Trained 64 records in 0.085195365 seconds. Throughput is 751.2146 records/second. Loss is 0.2530883. Sequential2290a28's hyper parameters: Current learning rate is 0.014832393948383269. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:10 INFO  DistriOptimizer$:408 - [Epoch 2 51584/60000][Iteration 1744][Wall Clock 207.944936877s] Trained 64 records in 0.072480568 seconds. Throughput is 882.9953 records/second. Loss is 0.24914987. Sequential2290a28's hyper parameters: Current learning rate is 0.01483019427554501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 51648/60000][Iteration 1745][Wall Clock 208.086030117s] Trained 64 records in 0.14109324 seconds. Throughput is 453.60077 records/second. Loss is 0.16276382. Sequential2290a28's hyper parameters: Current learning rate is 0.01482799525504152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 1746][Wall Clock 208.196396467s] Trained 64 records in 0.11036635 seconds. Throughput is 579.8869 records/second. Loss is 0.26592618. Sequential2290a28's hyper parameters: Current learning rate is 0.014825796886582655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 51776/60000][Iteration 1747][Wall Clock 208.323730065s] Trained 64 records in 0.127333598 seconds. Throughput is 502.61676 records/second. Loss is 0.22880985. Sequential2290a28's hyper parameters: Current learning rate is 0.014823599169878448. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 51840/60000][Iteration 1748][Wall Clock 208.43443178s] Trained 64 records in 0.110701715 seconds. Throughput is 578.1301 records/second. Loss is 0.25981703. Sequential2290a28's hyper parameters: Current learning rate is 0.014821402104639097. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 51904/60000][Iteration 1749][Wall Clock 208.514597143s] Trained 64 records in 0.080165363 seconds. Throughput is 798.3498 records/second. Loss is 0.40228042. Sequential2290a28's hyper parameters: Current learning rate is 0.014819205690574985. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 1750][Wall Clock 208.624510082s] Trained 64 records in 0.109912939 seconds. Throughput is 582.27905 records/second. Loss is 0.2725455. Sequential2290a28's hyper parameters: Current learning rate is 0.01481700992739665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 52032/60000][Iteration 1751][Wall Clock 208.733827924s] Trained 64 records in 0.109317842 seconds. Throughput is 585.4488 records/second. Loss is 0.22248763. Sequential2290a28's hyper parameters: Current learning rate is 0.014814814814814814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:11 INFO  DistriOptimizer$:408 - [Epoch 2 52096/60000][Iteration 1752][Wall Clock 208.834338899s] Trained 64 records in 0.100510975 seconds. Throughput is 636.7464 records/second. Loss is 0.23038213. Sequential2290a28's hyper parameters: Current learning rate is 0.014812620352540364. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52160/60000][Iteration 1753][Wall Clock 208.957173021s] Trained 64 records in 0.122834122 seconds. Throughput is 521.02783 records/second. Loss is 0.20280328. Sequential2290a28's hyper parameters: Current learning rate is 0.01481042654028436. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 1754][Wall Clock 209.041749458s] Trained 64 records in 0.084576437 seconds. Throughput is 756.712 records/second. Loss is 0.18719766. Sequential2290a28's hyper parameters: Current learning rate is 0.014808233377758034. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52288/60000][Iteration 1755][Wall Clock 209.181001017s] Trained 64 records in 0.139251559 seconds. Throughput is 459.59988 records/second. Loss is 0.22327654. Sequential2290a28's hyper parameters: Current learning rate is 0.014806040864672786. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52352/60000][Iteration 1756][Wall Clock 209.323232547s] Trained 64 records in 0.14223153 seconds. Throughput is 449.97058 records/second. Loss is 0.2122633. Sequential2290a28's hyper parameters: Current learning rate is 0.014803849000740193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52416/60000][Iteration 1757][Wall Clock 209.464185089s] Trained 64 records in 0.140952542 seconds. Throughput is 454.05353 records/second. Loss is 0.10418204. Sequential2290a28's hyper parameters: Current learning rate is 0.014801657785671996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 1758][Wall Clock 209.60231589s] Trained 64 records in 0.138130801 seconds. Throughput is 463.32898 records/second. Loss is 0.22516893. Sequential2290a28's hyper parameters: Current learning rate is 0.01479946721918011. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52544/60000][Iteration 1759][Wall Clock 209.700209101s] Trained 64 records in 0.097893211 seconds. Throughput is 653.7736 records/second. Loss is 0.14947432. Sequential2290a28's hyper parameters: Current learning rate is 0.014797277300976621. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52608/60000][Iteration 1760][Wall Clock 209.793187061s] Trained 64 records in 0.09297796 seconds. Throughput is 688.33514 records/second. Loss is 0.16386804. Sequential2290a28's hyper parameters: Current learning rate is 0.014795088030773784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:12 INFO  DistriOptimizer$:408 - [Epoch 2 52672/60000][Iteration 1761][Wall Clock 209.882031619s] Trained 64 records in 0.088844558 seconds. Throughput is 720.35925 records/second. Loss is 0.2886354. Sequential2290a28's hyper parameters: Current learning rate is 0.014792899408284023. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 1762][Wall Clock 209.970234264s] Trained 64 records in 0.088202645 seconds. Throughput is 725.6018 records/second. Loss is 0.22486202. Sequential2290a28's hyper parameters: Current learning rate is 0.014790711433219937. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 52800/60000][Iteration 1763][Wall Clock 210.053180743s] Trained 64 records in 0.082946479 seconds. Throughput is 771.58185 records/second. Loss is 0.18785839. Sequential2290a28's hyper parameters: Current learning rate is 0.014788524105294291. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 52864/60000][Iteration 1764][Wall Clock 210.148675943s] Trained 64 records in 0.0954952 seconds. Throughput is 670.19073 records/second. Loss is 0.41635534. Sequential2290a28's hyper parameters: Current learning rate is 0.01478633742422002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 52928/60000][Iteration 1765][Wall Clock 210.240656526s] Trained 64 records in 0.091980583 seconds. Throughput is 695.799 records/second. Loss is 0.3087325. Sequential2290a28's hyper parameters: Current learning rate is 0.014784151389710232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 1766][Wall Clock 210.326794996s] Trained 64 records in 0.08613847 seconds. Throughput is 742.98975 records/second. Loss is 0.36211973. Sequential2290a28's hyper parameters: Current learning rate is 0.014781966001478197. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 53056/60000][Iteration 1767][Wall Clock 210.410550904s] Trained 64 records in 0.083755908 seconds. Throughput is 764.1252 records/second. Loss is 0.2750137. Sequential2290a28's hyper parameters: Current learning rate is 0.014779781259237365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 53120/60000][Iteration 1768][Wall Clock 210.510106031s] Trained 64 records in 0.099555127 seconds. Throughput is 642.8599 records/second. Loss is 0.3106105. Sequential2290a28's hyper parameters: Current learning rate is 0.014777597162701345. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 53184/60000][Iteration 1769][Wall Clock 210.625393766s] Trained 64 records in 0.115287735 seconds. Throughput is 555.13275 records/second. Loss is 0.2243993. Sequential2290a28's hyper parameters: Current learning rate is 0.014775413711583923. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 1770][Wall Clock 210.707931061s] Trained 64 records in 0.082537295 seconds. Throughput is 775.40704 records/second. Loss is 0.11338811. Sequential2290a28's hyper parameters: Current learning rate is 0.014773230905599054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:13 INFO  DistriOptimizer$:408 - [Epoch 2 53312/60000][Iteration 1771][Wall Clock 210.883740363s] Trained 64 records in 0.175809302 seconds. Throughput is 364.0308 records/second. Loss is 0.26188195. Sequential2290a28's hyper parameters: Current learning rate is 0.014771048744460856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53376/60000][Iteration 1772][Wall Clock 211.030026023s] Trained 64 records in 0.14628566 seconds. Throughput is 437.50018 records/second. Loss is 0.2668072. Sequential2290a28's hyper parameters: Current learning rate is 0.014768867227883621. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53440/60000][Iteration 1773][Wall Clock 211.226601471s] Trained 64 records in 0.196575448 seconds. Throughput is 325.57474 records/second. Loss is 0.22389743. Sequential2290a28's hyper parameters: Current learning rate is 0.014766686355581806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 1774][Wall Clock 211.338957884s] Trained 64 records in 0.112356413 seconds. Throughput is 569.6159 records/second. Loss is 0.08185367. Sequential2290a28's hyper parameters: Current learning rate is 0.014764506127270044. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53568/60000][Iteration 1775][Wall Clock 211.468521503s] Trained 64 records in 0.129563619 seconds. Throughput is 493.96585 records/second. Loss is 0.2217351. Sequential2290a28's hyper parameters: Current learning rate is 0.014762326542663124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53632/60000][Iteration 1776][Wall Clock 211.662189598s] Trained 64 records in 0.193668095 seconds. Throughput is 330.46228 records/second. Loss is 0.36222225. Sequential2290a28's hyper parameters: Current learning rate is 0.014760147601476016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53696/60000][Iteration 1777][Wall Clock 211.821321299s] Trained 64 records in 0.159131701 seconds. Throughput is 402.1826 records/second. Loss is 0.35694456. Sequential2290a28's hyper parameters: Current learning rate is 0.01475796930342385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:14 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 1778][Wall Clock 211.918215134s] Trained 64 records in 0.096893835 seconds. Throughput is 660.5168 records/second. Loss is 0.18825516. Sequential2290a28's hyper parameters: Current learning rate is 0.014755791648221928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 53824/60000][Iteration 1779][Wall Clock 212.005058513s] Trained 64 records in 0.086843379 seconds. Throughput is 736.95886 records/second. Loss is 0.21762991. Sequential2290a28's hyper parameters: Current learning rate is 0.01475361463558572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 53888/60000][Iteration 1780][Wall Clock 212.087621098s] Trained 64 records in 0.082562585 seconds. Throughput is 775.1695 records/second. Loss is 0.27593917. Sequential2290a28's hyper parameters: Current learning rate is 0.014751438265230862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 53952/60000][Iteration 1781][Wall Clock 212.236455179s] Trained 64 records in 0.148834081 seconds. Throughput is 430.00903 records/second. Loss is 0.16914085. Sequential2290a28's hyper parameters: Current learning rate is 0.014749262536873156. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 1782][Wall Clock 212.459080445s] Trained 64 records in 0.222625266 seconds. Throughput is 287.4786 records/second. Loss is 0.40619245. Sequential2290a28's hyper parameters: Current learning rate is 0.014747087450228579. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 54080/60000][Iteration 1783][Wall Clock 212.571810833s] Trained 64 records in 0.112730388 seconds. Throughput is 567.72626 records/second. Loss is 0.085734546. Sequential2290a28's hyper parameters: Current learning rate is 0.01474491300501327. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 54144/60000][Iteration 1784][Wall Clock 212.687633798s] Trained 64 records in 0.115822965 seconds. Throughput is 552.56744 records/second. Loss is 0.21837446. Sequential2290a28's hyper parameters: Current learning rate is 0.014742739200943536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 54208/60000][Iteration 1785][Wall Clock 212.773114332s] Trained 64 records in 0.085480534 seconds. Throughput is 748.7085 records/second. Loss is 0.22999191. Sequential2290a28's hyper parameters: Current learning rate is 0.01474056603773585. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:15 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 1786][Wall Clock 212.889162039s] Trained 64 records in 0.116047707 seconds. Throughput is 551.4973 records/second. Loss is 0.21435586. Sequential2290a28's hyper parameters: Current learning rate is 0.014738393515106854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54336/60000][Iteration 1787][Wall Clock 212.996522425s] Trained 64 records in 0.107360386 seconds. Throughput is 596.12305 records/second. Loss is 0.44696468. Sequential2290a28's hyper parameters: Current learning rate is 0.014736221632773357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54400/60000][Iteration 1788][Wall Clock 213.078411653s] Trained 64 records in 0.081889228 seconds. Throughput is 781.5436 records/second. Loss is 0.2920594. Sequential2290a28's hyper parameters: Current learning rate is 0.014734050390452336. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54464/60000][Iteration 1789][Wall Clock 213.15091416s] Trained 64 records in 0.072502507 seconds. Throughput is 882.7281 records/second. Loss is 0.26414075. Sequential2290a28's hyper parameters: Current learning rate is 0.014731879787860929. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 1790][Wall Clock 213.228829815s] Trained 64 records in 0.077915655 seconds. Throughput is 821.40106 records/second. Loss is 0.30562103. Sequential2290a28's hyper parameters: Current learning rate is 0.014729709824716452. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54592/60000][Iteration 1791][Wall Clock 213.300366021s] Trained 64 records in 0.071536206 seconds. Throughput is 894.65186 records/second. Loss is 0.23955455. Sequential2290a28's hyper parameters: Current learning rate is 0.014727540500736377. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54656/60000][Iteration 1792][Wall Clock 213.396328367s] Trained 64 records in 0.095962346 seconds. Throughput is 666.9283 records/second. Loss is 0.23848486. Sequential2290a28's hyper parameters: Current learning rate is 0.014725371815638344. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54720/60000][Iteration 1793][Wall Clock 213.472816186s] Trained 64 records in 0.076487819 seconds. Throughput is 836.73456 records/second. Loss is 0.12096971. Sequential2290a28's hyper parameters: Current learning rate is 0.014723203769140165. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 1794][Wall Clock 213.578055117s] Trained 64 records in 0.105238931 seconds. Throughput is 608.13995 records/second. Loss is 0.17541708. Sequential2290a28's hyper parameters: Current learning rate is 0.014721036360959812. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54848/60000][Iteration 1795][Wall Clock 213.656717976s] Trained 64 records in 0.078662859 seconds. Throughput is 813.5987 records/second. Loss is 0.29069585. Sequential2290a28's hyper parameters: Current learning rate is 0.014718869590815425. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:16 INFO  DistriOptimizer$:408 - [Epoch 2 54912/60000][Iteration 1796][Wall Clock 213.816828598s] Trained 64 records in 0.160110622 seconds. Throughput is 399.72363 records/second. Loss is 0.3787623. Sequential2290a28's hyper parameters: Current learning rate is 0.014716703458425313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 54976/60000][Iteration 1797][Wall Clock 214.055666758s] Trained 64 records in 0.23883816 seconds. Throughput is 267.96387 records/second. Loss is 0.17987737. Sequential2290a28's hyper parameters: Current learning rate is 0.014714537963507947. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 1798][Wall Clock 214.205046043s] Trained 64 records in 0.149379285 seconds. Throughput is 428.4396 records/second. Loss is 0.21347128. Sequential2290a28's hyper parameters: Current learning rate is 0.014712373105781964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55104/60000][Iteration 1799][Wall Clock 214.288371747s] Trained 64 records in 0.083325704 seconds. Throughput is 768.0703 records/second. Loss is 0.17793974. Sequential2290a28's hyper parameters: Current learning rate is 0.014710208884966167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55168/60000][Iteration 1800][Wall Clock 214.39458248s] Trained 64 records in 0.106210733 seconds. Throughput is 602.5756 records/second. Loss is 0.2299411. Sequential2290a28's hyper parameters: Current learning rate is 0.014708045300779527. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55232/60000][Iteration 1801][Wall Clock 214.470775707s] Trained 64 records in 0.076193227 seconds. Throughput is 839.96967 records/second. Loss is 0.28123942. Sequential2290a28's hyper parameters: Current learning rate is 0.014705882352941176. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 1802][Wall Clock 214.56144481s] Trained 64 records in 0.090669103 seconds. Throughput is 705.8634 records/second. Loss is 0.33102977. Sequential2290a28's hyper parameters: Current learning rate is 0.014703720041170416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55360/60000][Iteration 1803][Wall Clock 214.642918201s] Trained 64 records in 0.081473391 seconds. Throughput is 785.5326 records/second. Loss is 0.4790394. Sequential2290a28's hyper parameters: Current learning rate is 0.014701558365186709. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55424/60000][Iteration 1804][Wall Clock 214.725224694s] Trained 64 records in 0.082306493 seconds. Throughput is 777.5815 records/second. Loss is 0.12676433. Sequential2290a28's hyper parameters: Current learning rate is 0.014699397324709687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:17 INFO  DistriOptimizer$:408 - [Epoch 2 55488/60000][Iteration 1805][Wall Clock 214.874630398s] Trained 64 records in 0.149405704 seconds. Throughput is 428.36383 records/second. Loss is 0.21673416. Sequential2290a28's hyper parameters: Current learning rate is 0.014697236919459141. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 1806][Wall Clock 214.963633025s] Trained 64 records in 0.089002627 seconds. Throughput is 719.0799 records/second. Loss is 0.25020975. Sequential2290a28's hyper parameters: Current learning rate is 0.014695077149155033. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55616/60000][Iteration 1807][Wall Clock 215.039344837s] Trained 64 records in 0.075711812 seconds. Throughput is 845.31067 records/second. Loss is 0.226318. Sequential2290a28's hyper parameters: Current learning rate is 0.014692918013517485. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55680/60000][Iteration 1808][Wall Clock 215.130357985s] Trained 64 records in 0.091013148 seconds. Throughput is 703.1951 records/second. Loss is 0.3400889. Sequential2290a28's hyper parameters: Current learning rate is 0.014690759512266786. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55744/60000][Iteration 1809][Wall Clock 215.21740466s] Trained 64 records in 0.087046675 seconds. Throughput is 735.23773 records/second. Loss is 0.35155788. Sequential2290a28's hyper parameters: Current learning rate is 0.014688601645123383. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 1810][Wall Clock 215.292987258s] Trained 64 records in 0.075582598 seconds. Throughput is 846.75574 records/second. Loss is 0.22491899. Sequential2290a28's hyper parameters: Current learning rate is 0.0146864444118079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55872/60000][Iteration 1811][Wall Clock 215.361978488s] Trained 64 records in 0.06899123 seconds. Throughput is 927.6542 records/second. Loss is 0.22391608. Sequential2290a28's hyper parameters: Current learning rate is 0.014684287812041116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 55936/60000][Iteration 1812][Wall Clock 215.431894963s] Trained 64 records in 0.069916475 seconds. Throughput is 915.378 records/second. Loss is 0.2333706. Sequential2290a28's hyper parameters: Current learning rate is 0.014682131845543973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 56000/60000][Iteration 1813][Wall Clock 215.573674214s] Trained 64 records in 0.141779251 seconds. Throughput is 451.40598 records/second. Loss is 0.29842228. Sequential2290a28's hyper parameters: Current learning rate is 0.01467997651203758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 1814][Wall Clock 215.661647144s] Trained 64 records in 0.08797293 seconds. Throughput is 727.4965 records/second. Loss is 0.19837159. Sequential2290a28's hyper parameters: Current learning rate is 0.014677821811243212. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 56128/60000][Iteration 1815][Wall Clock 215.751303288s] Trained 64 records in 0.089656144 seconds. Throughput is 713.83844 records/second. Loss is 0.17745154. Sequential2290a28's hyper parameters: Current learning rate is 0.0146756677428823. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:18 INFO  DistriOptimizer$:408 - [Epoch 2 56192/60000][Iteration 1816][Wall Clock 215.872342777s] Trained 64 records in 0.121039489 seconds. Throughput is 528.75305 records/second. Loss is 0.13293576. Sequential2290a28's hyper parameters: Current learning rate is 0.01467351430667645. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56256/60000][Iteration 1817][Wall Clock 215.960517973s] Trained 64 records in 0.088175196 seconds. Throughput is 725.82776 records/second. Loss is 0.09096388. Sequential2290a28's hyper parameters: Current learning rate is 0.014671361502347418. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 1818][Wall Clock 216.086336637s] Trained 64 records in 0.125818664 seconds. Throughput is 508.66855 records/second. Loss is 0.29541272. Sequential2290a28's hyper parameters: Current learning rate is 0.014669209329617135. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56384/60000][Iteration 1819][Wall Clock 216.208586741s] Trained 64 records in 0.122250104 seconds. Throughput is 523.51697 records/second. Loss is 0.2623555. Sequential2290a28's hyper parameters: Current learning rate is 0.014667057788207687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56448/60000][Iteration 1820][Wall Clock 216.291786044s] Trained 64 records in 0.083199303 seconds. Throughput is 769.23724 records/second. Loss is 0.24134453. Sequential2290a28's hyper parameters: Current learning rate is 0.014664906877841328. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56512/60000][Iteration 1821][Wall Clock 216.419460457s] Trained 64 records in 0.127674413 seconds. Throughput is 501.27505 records/second. Loss is 0.15184362. Sequential2290a28's hyper parameters: Current learning rate is 0.01466275659824047. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 1822][Wall Clock 216.560354183s] Trained 64 records in 0.140893726 seconds. Throughput is 454.24307 records/second. Loss is 0.30874664. Sequential2290a28's hyper parameters: Current learning rate is 0.014660606949127693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56640/60000][Iteration 1823][Wall Clock 216.640024876s] Trained 64 records in 0.079670693 seconds. Throughput is 803.3067 records/second. Loss is 0.33372957. Sequential2290a28's hyper parameters: Current learning rate is 0.01465845793022574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56704/60000][Iteration 1824][Wall Clock 216.754049712s] Trained 64 records in 0.114024836 seconds. Throughput is 561.28125 records/second. Loss is 0.28190196. Sequential2290a28's hyper parameters: Current learning rate is 0.014656309541257512. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56768/60000][Iteration 1825][Wall Clock 216.835582276s] Trained 64 records in 0.081532564 seconds. Throughput is 784.96246 records/second. Loss is 0.2334047. Sequential2290a28's hyper parameters: Current learning rate is 0.014654161781946073. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:19 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 1826][Wall Clock 216.905760632s] Trained 64 records in 0.070178356 seconds. Throughput is 911.96216 records/second. Loss is 0.19449422. Sequential2290a28's hyper parameters: Current learning rate is 0.014652014652014652. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 56896/60000][Iteration 1827][Wall Clock 216.989223231s] Trained 64 records in 0.083462599 seconds. Throughput is 766.81055 records/second. Loss is 0.19801933. Sequential2290a28's hyper parameters: Current learning rate is 0.01464986815118664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 56960/60000][Iteration 1828][Wall Clock 217.068896103s] Trained 64 records in 0.079672872 seconds. Throughput is 803.2847 records/second. Loss is 0.27816248. Sequential2290a28's hyper parameters: Current learning rate is 0.014647722279185588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57024/60000][Iteration 1829][Wall Clock 217.15929408s] Trained 64 records in 0.090397977 seconds. Throughput is 707.98047 records/second. Loss is 0.24564278. Sequential2290a28's hyper parameters: Current learning rate is 0.014645577035735206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 1830][Wall Clock 217.285691413s] Trained 64 records in 0.126397333 seconds. Throughput is 506.3398 records/second. Loss is 0.2528442. Sequential2290a28's hyper parameters: Current learning rate is 0.014643432420559379. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57152/60000][Iteration 1831][Wall Clock 217.377427063s] Trained 64 records in 0.09173565 seconds. Throughput is 697.6568 records/second. Loss is 0.27781993. Sequential2290a28's hyper parameters: Current learning rate is 0.014641288433382136. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57216/60000][Iteration 1832][Wall Clock 217.503170235s] Trained 64 records in 0.125743172 seconds. Throughput is 508.974 records/second. Loss is 0.2643151. Sequential2290a28's hyper parameters: Current learning rate is 0.014639145073927683. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57280/60000][Iteration 1833][Wall Clock 217.607835992s] Trained 64 records in 0.104665757 seconds. Throughput is 611.4703 records/second. Loss is 0.27778363. Sequential2290a28's hyper parameters: Current learning rate is 0.014637002341920374. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 1834][Wall Clock 217.707477802s] Trained 64 records in 0.09964181 seconds. Throughput is 642.30066 records/second. Loss is 0.40245295. Sequential2290a28's hyper parameters: Current learning rate is 0.014634860237084735. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57408/60000][Iteration 1835][Wall Clock 217.791434379s] Trained 64 records in 0.083956577 seconds. Throughput is 762.2988 records/second. Loss is 0.09580257. Sequential2290a28's hyper parameters: Current learning rate is 0.014632718759145449. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:20 INFO  DistriOptimizer$:408 - [Epoch 2 57472/60000][Iteration 1836][Wall Clock 217.886653519s] Trained 64 records in 0.09521914 seconds. Throughput is 672.1337 records/second. Loss is 0.14252874. Sequential2290a28's hyper parameters: Current learning rate is 0.014630577907827359. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57536/60000][Iteration 1837][Wall Clock 217.992191114s] Trained 64 records in 0.105537595 seconds. Throughput is 606.419 records/second. Loss is 0.21812911. Sequential2290a28's hyper parameters: Current learning rate is 0.014628437682855471. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 1838][Wall Clock 218.090647954s] Trained 64 records in 0.09845684 seconds. Throughput is 650.03107 records/second. Loss is 0.33857602. Sequential2290a28's hyper parameters: Current learning rate is 0.014626298083954952. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57664/60000][Iteration 1839][Wall Clock 218.18465582s] Trained 64 records in 0.094007866 seconds. Throughput is 680.7941 records/second. Loss is 0.23953372. Sequential2290a28's hyper parameters: Current learning rate is 0.014624159110851126. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57728/60000][Iteration 1840][Wall Clock 218.276531049s] Trained 64 records in 0.091875229 seconds. Throughput is 696.5969 records/second. Loss is 0.18846336. Sequential2290a28's hyper parameters: Current learning rate is 0.014622020763269485. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57792/60000][Iteration 1841][Wall Clock 218.427327196s] Trained 64 records in 0.150796147 seconds. Throughput is 424.41403 records/second. Loss is 0.18916208. Sequential2290a28's hyper parameters: Current learning rate is 0.014619883040935673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 1842][Wall Clock 218.577764565s] Trained 64 records in 0.150437369 seconds. Throughput is 425.4262 records/second. Loss is 0.3293451. Sequential2290a28's hyper parameters: Current learning rate is 0.0146177459435755. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57920/60000][Iteration 1843][Wall Clock 218.746682097s] Trained 64 records in 0.168917532 seconds. Throughput is 378.8831 records/second. Loss is 0.27973258. Sequential2290a28's hyper parameters: Current learning rate is 0.014615609470914937. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:21 INFO  DistriOptimizer$:408 - [Epoch 2 57984/60000][Iteration 1844][Wall Clock 218.883098798s] Trained 64 records in 0.136416701 seconds. Throughput is 469.15076 records/second. Loss is 0.12276949. Sequential2290a28's hyper parameters: Current learning rate is 0.01461347362268011. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58048/60000][Iteration 1845][Wall Clock 219.033269687s] Trained 64 records in 0.150170889 seconds. Throughput is 426.18112 records/second. Loss is 0.16597065. Sequential2290a28's hyper parameters: Current learning rate is 0.014611338398597311. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 1846][Wall Clock 219.170814388s] Trained 64 records in 0.137544701 seconds. Throughput is 465.30325 records/second. Loss is 0.25015175. Sequential2290a28's hyper parameters: Current learning rate is 0.014609203798392988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58176/60000][Iteration 1847][Wall Clock 219.337353287s] Trained 64 records in 0.166538899 seconds. Throughput is 384.29462 records/second. Loss is 0.25622326. Sequential2290a28's hyper parameters: Current learning rate is 0.014607069821793748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58240/60000][Iteration 1848][Wall Clock 219.428397017s] Trained 64 records in 0.09104373 seconds. Throughput is 702.95886 records/second. Loss is 0.13959017. Sequential2290a28's hyper parameters: Current learning rate is 0.014604936468526362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58304/60000][Iteration 1849][Wall Clock 219.515381718s] Trained 64 records in 0.086984701 seconds. Throughput is 735.76154 records/second. Loss is 0.18174943. Sequential2290a28's hyper parameters: Current learning rate is 0.014602803738317755. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 1850][Wall Clock 219.627445498s] Trained 64 records in 0.11206378 seconds. Throughput is 571.10333 records/second. Loss is 0.28288716. Sequential2290a28's hyper parameters: Current learning rate is 0.01460067163089502. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58432/60000][Iteration 1851][Wall Clock 219.707730301s] Trained 64 records in 0.080284803 seconds. Throughput is 797.16205 records/second. Loss is 0.22621346. Sequential2290a28's hyper parameters: Current learning rate is 0.014598540145985401. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58496/60000][Iteration 1852][Wall Clock 219.793343322s] Trained 64 records in 0.085613021 seconds. Throughput is 747.54987 records/second. Loss is 0.36655664. Sequential2290a28's hyper parameters: Current learning rate is 0.014596409283316304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:22 INFO  DistriOptimizer$:408 - [Epoch 2 58560/60000][Iteration 1853][Wall Clock 219.860396729s] Trained 64 records in 0.067053407 seconds. Throughput is 954.4631 records/second. Loss is 0.18078154. Sequential2290a28's hyper parameters: Current learning rate is 0.014594279042615295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 1854][Wall Clock 219.956749792s] Trained 64 records in 0.096353063 seconds. Throughput is 664.2238 records/second. Loss is 0.114595436. Sequential2290a28's hyper parameters: Current learning rate is 0.014592149423610097. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 58688/60000][Iteration 1855][Wall Clock 220.066025283s] Trained 64 records in 0.109275491 seconds. Throughput is 585.6757 records/second. Loss is 0.13123685. Sequential2290a28's hyper parameters: Current learning rate is 0.014590020426028597. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 58752/60000][Iteration 1856][Wall Clock 220.163785603s] Trained 64 records in 0.09776032 seconds. Throughput is 654.66235 records/second. Loss is 0.29665005. Sequential2290a28's hyper parameters: Current learning rate is 0.014587892049598834. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 58816/60000][Iteration 1857][Wall Clock 220.2781613s] Trained 64 records in 0.114375697 seconds. Throughput is 559.55945 records/second. Loss is 0.15923774. Sequential2290a28's hyper parameters: Current learning rate is 0.014585764294049008. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 1858][Wall Clock 220.394653386s] Trained 64 records in 0.116492086 seconds. Throughput is 549.39355 records/second. Loss is 0.24515545. Sequential2290a28's hyper parameters: Current learning rate is 0.014583637159107482. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 58944/60000][Iteration 1859][Wall Clock 220.56246823s] Trained 64 records in 0.167814844 seconds. Throughput is 381.37268 records/second. Loss is 0.24349546. Sequential2290a28's hyper parameters: Current learning rate is 0.014581510644502771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 59008/60000][Iteration 1860][Wall Clock 220.682505633s] Trained 64 records in 0.120037403 seconds. Throughput is 533.1671 records/second. Loss is 0.1705074. Sequential2290a28's hyper parameters: Current learning rate is 0.014579384749963552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 59072/60000][Iteration 1861][Wall Clock 220.780902383s] Trained 64 records in 0.09839675 seconds. Throughput is 650.428 records/second. Loss is 0.1057394. Sequential2290a28's hyper parameters: Current learning rate is 0.01457725947521866. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:23 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 1862][Wall Clock 220.885137021s] Trained 64 records in 0.104234638 seconds. Throughput is 613.9994 records/second. Loss is 0.23825073. Sequential2290a28's hyper parameters: Current learning rate is 0.014575134819997084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59200/60000][Iteration 1863][Wall Clock 220.996671179s] Trained 64 records in 0.111534158 seconds. Throughput is 573.81525 records/second. Loss is 0.25101727. Sequential2290a28's hyper parameters: Current learning rate is 0.01457301078402798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59264/60000][Iteration 1864][Wall Clock 221.106035317s] Trained 64 records in 0.109364138 seconds. Throughput is 585.201 records/second. Loss is 0.14172524. Sequential2290a28's hyper parameters: Current learning rate is 0.014570887367040652. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59328/60000][Iteration 1865][Wall Clock 221.209996834s] Trained 64 records in 0.103961517 seconds. Throughput is 615.61237 records/second. Loss is 0.23593417. Sequential2290a28's hyper parameters: Current learning rate is 0.014568764568764568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 1866][Wall Clock 221.308505834s] Trained 64 records in 0.098509 seconds. Throughput is 649.6868 records/second. Loss is 0.400235. Sequential2290a28's hyper parameters: Current learning rate is 0.014566642388929352. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59456/60000][Iteration 1867][Wall Clock 221.412966229s] Trained 64 records in 0.104460395 seconds. Throughput is 612.67236 records/second. Loss is 0.21605793. Sequential2290a28's hyper parameters: Current learning rate is 0.014564520827264784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59520/60000][Iteration 1868][Wall Clock 221.530043154s] Trained 64 records in 0.117076925 seconds. Throughput is 546.6491 records/second. Loss is 0.24039966. Sequential2290a28's hyper parameters: Current learning rate is 0.014562399883500802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59584/60000][Iteration 1869][Wall Clock 221.658122288s] Trained 64 records in 0.128079134 seconds. Throughput is 499.69107 records/second. Loss is 0.27237067. Sequential2290a28's hyper parameters: Current learning rate is 0.0145602795573675. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 1870][Wall Clock 221.73909863s] Trained 64 records in 0.080976342 seconds. Throughput is 790.35425 records/second. Loss is 0.32764655. Sequential2290a28's hyper parameters: Current learning rate is 0.014558159848595136. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:24 INFO  DistriOptimizer$:408 - [Epoch 2 59712/60000][Iteration 1871][Wall Clock 221.842285491s] Trained 64 records in 0.103186861 seconds. Throughput is 620.234 records/second. Loss is 0.27090114. Sequential2290a28's hyper parameters: Current learning rate is 0.01455604075691412. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:25 INFO  DistriOptimizer$:408 - [Epoch 2 59776/60000][Iteration 1872][Wall Clock 221.95988888s] Trained 64 records in 0.117603389 seconds. Throughput is 544.20197 records/second. Loss is 0.5175327. Sequential2290a28's hyper parameters: Current learning rate is 0.014553922282055013. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:25 INFO  DistriOptimizer$:408 - [Epoch 2 59840/60000][Iteration 1873][Wall Clock 222.162238283s] Trained 64 records in 0.202349403 seconds. Throughput is 316.28458 records/second. Loss is 0.3213417. Sequential2290a28's hyper parameters: Current learning rate is 0.014551804423748545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:25 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 1874][Wall Clock 222.288454796s] Trained 64 records in 0.126216513 seconds. Throughput is 507.0652 records/second. Loss is 0.26994136. Sequential2290a28's hyper parameters: Current learning rate is 0.014549687181725593. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:25 INFO  DistriOptimizer$:408 - [Epoch 2 59968/60000][Iteration 1875][Wall Clock 222.433628852s] Trained 64 records in 0.145174056 seconds. Throughput is 440.85013 records/second. Loss is 0.27038127. Sequential2290a28's hyper parameters: Current learning rate is 0.014547570555717195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:25 INFO  DistriOptimizer$:408 - [Epoch 2 60032/60000][Iteration 1876][Wall Clock 222.511383184s] Trained 64 records in 0.077754332 seconds. Throughput is 823.1052 records/second. Loss is 0.20566745. Sequential2290a28's hyper parameters: Current learning rate is 0.014545454545454545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:25 INFO  DistriOptimizer$:452 - [Epoch 2 60032/60000][Iteration 1876][Wall Clock 222.511383184s] Epoch finished. Wall clock time is 224361.717811 ms
2019-10-24 03:17:25 INFO  DistriOptimizer$:111 - [Epoch 2 60032/60000][Iteration 1876][Wall Clock 222.511383184s] Validate model...
2019-10-24 03:17:26 INFO  DistriOptimizer$:178 - [Epoch 2 60032/60000][Iteration 1876][Wall Clock 222.511383184s] validate model throughput is 8660.676 records/second
2019-10-24 03:17:26 INFO  DistriOptimizer$:181 - [Epoch 2 60032/60000][Iteration 1876][Wall Clock 222.511383184s] Top1Accuracy is Accuracy(correct: 9408, count: 10000, accuracy: 0.9408)
2019-10-24 03:17:26 INFO  DistriOptimizer$:221 - [Wall Clock 224.361717811s] Save model to /tmp/lenet5/20191024_031340
2019-10-24 03:17:26 INFO  DistriOptimizer$:226 - [Wall Clock 224.361717811s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@b5fef19 to /tmp/lenet5/20191024_031340
2019-10-24 03:17:27 INFO  DistriOptimizer$:408 - [Epoch 3 64/60000][Iteration 1877][Wall Clock 224.493165223s] Trained 64 records in 0.131447412 seconds. Throughput is 486.88675 records/second. Loss is 0.16611737. Sequential2290a28's hyper parameters: Current learning rate is 0.014543339150668994. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:27 INFO  DistriOptimizer$:408 - [Epoch 3 128/60000][Iteration 1878][Wall Clock 224.640439814s] Trained 64 records in 0.147274591 seconds. Throughput is 434.56244 records/second. Loss is 0.19234243. Sequential2290a28's hyper parameters: Current learning rate is 0.014541224371092046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:27 INFO  DistriOptimizer$:408 - [Epoch 3 192/60000][Iteration 1879][Wall Clock 224.763394045s] Trained 64 records in 0.122954231 seconds. Throughput is 520.51886 records/second. Loss is 0.2009947. Sequential2290a28's hyper parameters: Current learning rate is 0.014539110206455366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:27 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 1880][Wall Clock 224.909476089s] Trained 64 records in 0.146082044 seconds. Throughput is 438.11 records/second. Loss is 0.06307875. Sequential2290a28's hyper parameters: Current learning rate is 0.01453699665649077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:27 INFO  DistriOptimizer$:408 - [Epoch 3 320/60000][Iteration 1881][Wall Clock 225.098098913s] Trained 64 records in 0.188622824 seconds. Throughput is 339.30148 records/second. Loss is 0.19407725. Sequential2290a28's hyper parameters: Current learning rate is 0.014534883720930234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:27 INFO  DistriOptimizer$:408 - [Epoch 3 384/60000][Iteration 1882][Wall Clock 225.306704054s] Trained 64 records in 0.208605141 seconds. Throughput is 306.7997 records/second. Loss is 0.2861042. Sequential2290a28's hyper parameters: Current learning rate is 0.014532771399505885. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 448/60000][Iteration 1883][Wall Clock 225.441907174s] Trained 64 records in 0.13520312 seconds. Throughput is 473.36185 records/second. Loss is 0.14262074. Sequential2290a28's hyper parameters: Current learning rate is 0.014530659691950014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 1884][Wall Clock 225.541037356s] Trained 64 records in 0.099130182 seconds. Throughput is 645.61566 records/second. Loss is 0.16659757. Sequential2290a28's hyper parameters: Current learning rate is 0.01452854859799506. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 576/60000][Iteration 1885][Wall Clock 225.638666968s] Trained 64 records in 0.097629612 seconds. Throughput is 655.5388 records/second. Loss is 0.21890837. Sequential2290a28's hyper parameters: Current learning rate is 0.01452643811737362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 640/60000][Iteration 1886][Wall Clock 225.744922407s] Trained 64 records in 0.106255439 seconds. Throughput is 602.3221 records/second. Loss is 0.18828699. Sequential2290a28's hyper parameters: Current learning rate is 0.014524328249818447. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 704/60000][Iteration 1887][Wall Clock 225.846686798s] Trained 64 records in 0.101764391 seconds. Throughput is 628.9037 records/second. Loss is 0.27576548. Sequential2290a28's hyper parameters: Current learning rate is 0.014522218995062446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 1888][Wall Clock 225.922869233s] Trained 64 records in 0.076182435 seconds. Throughput is 840.0887 records/second. Loss is 0.17408408. Sequential2290a28's hyper parameters: Current learning rate is 0.014520110352838683. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 832/60000][Iteration 1889][Wall Clock 226.061103719s] Trained 64 records in 0.138234486 seconds. Throughput is 462.98145 records/second. Loss is 0.14350721. Sequential2290a28's hyper parameters: Current learning rate is 0.014518002322880372. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:28 INFO  DistriOptimizer$:408 - [Epoch 3 896/60000][Iteration 1890][Wall Clock 226.238345402s] Trained 64 records in 0.177241683 seconds. Throughput is 361.08887 records/second. Loss is 0.22472626. Sequential2290a28's hyper parameters: Current learning rate is 0.014515894904920888. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 960/60000][Iteration 1891][Wall Clock 226.391468603s] Trained 64 records in 0.153123201 seconds. Throughput is 417.9641 records/second. Loss is 0.2066846. Sequential2290a28's hyper parameters: Current learning rate is 0.014513788098693758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 1892][Wall Clock 226.558638846s] Trained 64 records in 0.167170243 seconds. Throughput is 382.84326 records/second. Loss is 0.19005. Sequential2290a28's hyper parameters: Current learning rate is 0.014511681903932665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1088/60000][Iteration 1893][Wall Clock 226.683111904s] Trained 64 records in 0.124473058 seconds. Throughput is 514.1675 records/second. Loss is 0.20913577. Sequential2290a28's hyper parameters: Current learning rate is 0.014509576320371444. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1152/60000][Iteration 1894][Wall Clock 226.801254483s] Trained 64 records in 0.118142579 seconds. Throughput is 541.7183 records/second. Loss is 0.19558077. Sequential2290a28's hyper parameters: Current learning rate is 0.014507471347744088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1216/60000][Iteration 1895][Wall Clock 226.891851241s] Trained 64 records in 0.090596758 seconds. Throughput is 706.42706 records/second. Loss is 0.3905738. Sequential2290a28's hyper parameters: Current learning rate is 0.01450536698578474. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 1896][Wall Clock 226.986579413s] Trained 64 records in 0.094728172 seconds. Throughput is 675.6174 records/second. Loss is 0.19438523. Sequential2290a28's hyper parameters: Current learning rate is 0.014503263234227702. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1344/60000][Iteration 1897][Wall Clock 227.14794764s] Trained 64 records in 0.161368227 seconds. Throughput is 396.60846 records/second. Loss is 0.1316505. Sequential2290a28's hyper parameters: Current learning rate is 0.014501160092807426. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:29 INFO  DistriOptimizer$:408 - [Epoch 3 1408/60000][Iteration 1898][Wall Clock 227.267889103s] Trained 64 records in 0.119941463 seconds. Throughput is 533.5936 records/second. Loss is 0.3505246. Sequential2290a28's hyper parameters: Current learning rate is 0.01449905756125852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1472/60000][Iteration 1899][Wall Clock 227.38775434s] Trained 64 records in 0.119865237 seconds. Throughput is 533.9329 records/second. Loss is 0.3082357. Sequential2290a28's hyper parameters: Current learning rate is 0.014496955639315745. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 1900][Wall Clock 227.484143452s] Trained 64 records in 0.096389112 seconds. Throughput is 663.9754 records/second. Loss is 0.21233621. Sequential2290a28's hyper parameters: Current learning rate is 0.014494854326714018. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1600/60000][Iteration 1901][Wall Clock 227.589027898s] Trained 64 records in 0.104884446 seconds. Throughput is 610.1953 records/second. Loss is 0.2866584. Sequential2290a28's hyper parameters: Current learning rate is 0.014492753623188408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1664/60000][Iteration 1902][Wall Clock 227.679714352s] Trained 64 records in 0.090686454 seconds. Throughput is 705.72833 records/second. Loss is 0.15740056. Sequential2290a28's hyper parameters: Current learning rate is 0.014490653528474133. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1728/60000][Iteration 1903][Wall Clock 227.789625649s] Trained 64 records in 0.109911297 seconds. Throughput is 582.2877 records/second. Loss is 0.21640104. Sequential2290a28's hyper parameters: Current learning rate is 0.014488554042306577. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 1904][Wall Clock 227.899232771s] Trained 64 records in 0.109607122 seconds. Throughput is 583.9037 records/second. Loss is 0.18952088. Sequential2290a28's hyper parameters: Current learning rate is 0.014486455164421265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1856/60000][Iteration 1905][Wall Clock 228.010212966s] Trained 64 records in 0.110980195 seconds. Throughput is 576.67944 records/second. Loss is 0.23570766. Sequential2290a28's hyper parameters: Current learning rate is 0.014484356894553883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1920/60000][Iteration 1906][Wall Clock 228.148822724s] Trained 64 records in 0.138609758 seconds. Throughput is 461.72797 records/second. Loss is 0.26060963. Sequential2290a28's hyper parameters: Current learning rate is 0.01448225923244026. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:30 INFO  DistriOptimizer$:408 - [Epoch 3 1984/60000][Iteration 1907][Wall Clock 228.33869317s] Trained 64 records in 0.189870446 seconds. Throughput is 337.07193 records/second. Loss is 0.1342879. Sequential2290a28's hyper parameters: Current learning rate is 0.014480162177816391. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 1908][Wall Clock 228.548890876s] Trained 64 records in 0.210197706 seconds. Throughput is 304.47525 records/second. Loss is 0.28429326. Sequential2290a28's hyper parameters: Current learning rate is 0.014478065730418417. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2112/60000][Iteration 1909][Wall Clock 228.675186766s] Trained 64 records in 0.12629589 seconds. Throughput is 506.7465 records/second. Loss is 0.1842634. Sequential2290a28's hyper parameters: Current learning rate is 0.01447596988998263. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2176/60000][Iteration 1910][Wall Clock 228.830411838s] Trained 64 records in 0.155225072 seconds. Throughput is 412.30453 records/second. Loss is 0.18626535. Sequential2290a28's hyper parameters: Current learning rate is 0.014473874656245476. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2240/60000][Iteration 1911][Wall Clock 228.938502638s] Trained 64 records in 0.1080908 seconds. Throughput is 592.0948 records/second. Loss is 0.21472168. Sequential2290a28's hyper parameters: Current learning rate is 0.01447178002894356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 1912][Wall Clock 229.064193403s] Trained 64 records in 0.125690765 seconds. Throughput is 509.18622 records/second. Loss is 0.18445154. Sequential2290a28's hyper parameters: Current learning rate is 0.014469686007813629. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2368/60000][Iteration 1913][Wall Clock 229.171228708s] Trained 64 records in 0.107035305 seconds. Throughput is 597.9336 records/second. Loss is 0.17350419. Sequential2290a28's hyper parameters: Current learning rate is 0.014467592592592593. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:31 INFO  DistriOptimizer$:408 - [Epoch 3 2432/60000][Iteration 1914][Wall Clock 229.275482731s] Trained 64 records in 0.104254023 seconds. Throughput is 613.8852 records/second. Loss is 0.13750744. Sequential2290a28's hyper parameters: Current learning rate is 0.014465499783017503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2496/60000][Iteration 1915][Wall Clock 229.381669135s] Trained 64 records in 0.106186404 seconds. Throughput is 602.7137 records/second. Loss is 0.15242173. Sequential2290a28's hyper parameters: Current learning rate is 0.014463407578825572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 1916][Wall Clock 229.494276538s] Trained 64 records in 0.112607403 seconds. Throughput is 568.3463 records/second. Loss is 0.2070396. Sequential2290a28's hyper parameters: Current learning rate is 0.014461315979754159. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2624/60000][Iteration 1917][Wall Clock 229.586802197s] Trained 64 records in 0.092525659 seconds. Throughput is 691.7 records/second. Loss is 0.33396545. Sequential2290a28's hyper parameters: Current learning rate is 0.014459224985540775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2688/60000][Iteration 1918][Wall Clock 229.709750851s] Trained 64 records in 0.122948654 seconds. Throughput is 520.5425 records/second. Loss is 0.2911461. Sequential2290a28's hyper parameters: Current learning rate is 0.014457134595923089. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2752/60000][Iteration 1919][Wall Clock 229.823485505s] Trained 64 records in 0.113734654 seconds. Throughput is 562.71326 records/second. Loss is 0.22353011. Sequential2290a28's hyper parameters: Current learning rate is 0.014455044810638914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 1920][Wall Clock 229.922553054s] Trained 64 records in 0.099067549 seconds. Throughput is 646.02386 records/second. Loss is 0.16285834. Sequential2290a28's hyper parameters: Current learning rate is 0.01445295562942622. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2880/60000][Iteration 1921][Wall Clock 230.00258948s] Trained 64 records in 0.080036426 seconds. Throughput is 799.6359 records/second. Loss is 0.3053761. Sequential2290a28's hyper parameters: Current learning rate is 0.014450867052023123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 2944/60000][Iteration 1922][Wall Clock 230.181758016s] Trained 64 records in 0.179168536 seconds. Throughput is 357.20557 records/second. Loss is 0.19251591. Sequential2290a28's hyper parameters: Current learning rate is 0.014448779078167894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:32 INFO  DistriOptimizer$:408 - [Epoch 3 3008/60000][Iteration 1923][Wall Clock 230.29382311s] Trained 64 records in 0.112065094 seconds. Throughput is 571.0967 records/second. Loss is 0.18580179. Sequential2290a28's hyper parameters: Current learning rate is 0.01444669170759896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:33 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 1924][Wall Clock 230.51802267s] Trained 64 records in 0.22419956 seconds. Throughput is 285.45996 records/second. Loss is 0.38491344. Sequential2290a28's hyper parameters: Current learning rate is 0.01444460494005489. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:33 INFO  DistriOptimizer$:408 - [Epoch 3 3136/60000][Iteration 1925][Wall Clock 230.719772884s] Trained 64 records in 0.201750214 seconds. Throughput is 317.22394 records/second. Loss is 0.22202164. Sequential2290a28's hyper parameters: Current learning rate is 0.014442518775274409. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:33 INFO  DistriOptimizer$:408 - [Epoch 3 3200/60000][Iteration 1926][Wall Clock 230.817399703s] Trained 64 records in 0.097626819 seconds. Throughput is 655.55756 records/second. Loss is 0.26597384. Sequential2290a28's hyper parameters: Current learning rate is 0.01444043321299639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:33 INFO  DistriOptimizer$:408 - [Epoch 3 3264/60000][Iteration 1927][Wall Clock 230.959415793s] Trained 64 records in 0.14201609 seconds. Throughput is 450.6532 records/second. Loss is 0.19552448. Sequential2290a28's hyper parameters: Current learning rate is 0.014438348252959862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:33 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 1928][Wall Clock 231.064910884s] Trained 64 records in 0.105495091 seconds. Throughput is 606.6633 records/second. Loss is 0.16449401. Sequential2290a28's hyper parameters: Current learning rate is 0.014436263894904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:33 INFO  DistriOptimizer$:408 - [Epoch 3 3392/60000][Iteration 1929][Wall Clock 231.173988342s] Trained 64 records in 0.109077458 seconds. Throughput is 586.739 records/second. Loss is 0.08078624. Sequential2290a28's hyper parameters: Current learning rate is 0.01443418013856813. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3456/60000][Iteration 1930][Wall Clock 231.339789417s] Trained 64 records in 0.165801075 seconds. Throughput is 386.00473 records/second. Loss is 0.17277607. Sequential2290a28's hyper parameters: Current learning rate is 0.014432096983691729. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3520/60000][Iteration 1931][Wall Clock 231.464822773s] Trained 64 records in 0.125033356 seconds. Throughput is 511.86343 records/second. Loss is 0.16964763. Sequential2290a28's hyper parameters: Current learning rate is 0.014430014430014428. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 1932][Wall Clock 231.594485811s] Trained 64 records in 0.129663038 seconds. Throughput is 493.5871 records/second. Loss is 0.1866292. Sequential2290a28's hyper parameters: Current learning rate is 0.014427932477276006. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3648/60000][Iteration 1933][Wall Clock 231.744841029s] Trained 64 records in 0.150355218 seconds. Throughput is 425.65866 records/second. Loss is 0.3646049. Sequential2290a28's hyper parameters: Current learning rate is 0.014425851125216388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3712/60000][Iteration 1934][Wall Clock 231.818900795s] Trained 64 records in 0.074059766 seconds. Throughput is 864.1669 records/second. Loss is 0.22648416. Sequential2290a28's hyper parameters: Current learning rate is 0.014423770373575652. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3776/60000][Iteration 1935][Wall Clock 231.93353158s] Trained 64 records in 0.114630785 seconds. Throughput is 558.3142 records/second. Loss is 0.31705195. Sequential2290a28's hyper parameters: Current learning rate is 0.01442169022209403. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 1936][Wall Clock 232.026801837s] Trained 64 records in 0.093270257 seconds. Throughput is 686.17804 records/second. Loss is 0.25185755. Sequential2290a28's hyper parameters: Current learning rate is 0.014419610670511897. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3904/60000][Iteration 1937][Wall Clock 232.097991647s] Trained 64 records in 0.07118981 seconds. Throughput is 899.005 records/second. Loss is 0.1668369. Sequential2290a28's hyper parameters: Current learning rate is 0.01441753171856978. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 3968/60000][Iteration 1938][Wall Clock 232.179446833s] Trained 64 records in 0.081455186 seconds. Throughput is 785.7081 records/second. Loss is 0.19177437. Sequential2290a28's hyper parameters: Current learning rate is 0.014415453366008362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:34 INFO  DistriOptimizer$:408 - [Epoch 3 4032/60000][Iteration 1939][Wall Clock 232.295266499s] Trained 64 records in 0.115819666 seconds. Throughput is 552.5832 records/second. Loss is 0.17860311. Sequential2290a28's hyper parameters: Current learning rate is 0.014413375612568464. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:35 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 1940][Wall Clock 232.424970689s] Trained 64 records in 0.12970419 seconds. Throughput is 493.43045 records/second. Loss is 0.4280134. Sequential2290a28's hyper parameters: Current learning rate is 0.014411298457991066. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:35 INFO  DistriOptimizer$:408 - [Epoch 3 4160/60000][Iteration 1941][Wall Clock 232.581098812s] Trained 64 records in 0.156128123 seconds. Throughput is 409.91974 records/second. Loss is 0.2690846. Sequential2290a28's hyper parameters: Current learning rate is 0.014409221902017292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:35 INFO  DistriOptimizer$:408 - [Epoch 3 4224/60000][Iteration 1942][Wall Clock 232.730353852s] Trained 64 records in 0.14925504 seconds. Throughput is 428.79623 records/second. Loss is 0.25185937. Sequential2290a28's hyper parameters: Current learning rate is 0.014407145944388416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:35 INFO  DistriOptimizer$:408 - [Epoch 3 4288/60000][Iteration 1943][Wall Clock 232.87195804s] Trained 64 records in 0.141604188 seconds. Throughput is 451.96405 records/second. Loss is 0.20294538. Sequential2290a28's hyper parameters: Current learning rate is 0.014405070584845865. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:35 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 1944][Wall Clock 233.032928147s] Trained 64 records in 0.160970107 seconds. Throughput is 397.58936 records/second. Loss is 0.24361694. Sequential2290a28's hyper parameters: Current learning rate is 0.01440299582313121. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:35 INFO  DistriOptimizer$:408 - [Epoch 3 4416/60000][Iteration 1945][Wall Clock 233.260298725s] Trained 64 records in 0.227370578 seconds. Throughput is 281.47882 records/second. Loss is 0.26471722. Sequential2290a28's hyper parameters: Current learning rate is 0.014400921658986175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:36 INFO  DistriOptimizer$:408 - [Epoch 3 4480/60000][Iteration 1946][Wall Clock 233.40493809s] Trained 64 records in 0.144639365 seconds. Throughput is 442.47983 records/second. Loss is 0.15809032. Sequential2290a28's hyper parameters: Current learning rate is 0.014398848092152628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:36 INFO  DistriOptimizer$:408 - [Epoch 3 4544/60000][Iteration 1947][Wall Clock 233.507224405s] Trained 64 records in 0.102286315 seconds. Throughput is 625.69464 records/second. Loss is 0.2579545. Sequential2290a28's hyper parameters: Current learning rate is 0.014396775122372588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:36 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 1948][Wall Clock 233.702274137s] Trained 64 records in 0.195049732 seconds. Throughput is 328.12143 records/second. Loss is 0.15247692. Sequential2290a28's hyper parameters: Current learning rate is 0.014394702749388226. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:36 INFO  DistriOptimizer$:408 - [Epoch 3 4672/60000][Iteration 1949][Wall Clock 233.884271706s] Trained 64 records in 0.181997569 seconds. Throughput is 351.65305 records/second. Loss is 0.35228723. Sequential2290a28's hyper parameters: Current learning rate is 0.014392630972941854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:36 INFO  DistriOptimizer$:408 - [Epoch 3 4736/60000][Iteration 1950][Wall Clock 234.017122676s] Trained 64 records in 0.13285097 seconds. Throughput is 481.7428 records/second. Loss is 0.22736628. Sequential2290a28's hyper parameters: Current learning rate is 0.014390559792775938. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:36 INFO  DistriOptimizer$:408 - [Epoch 3 4800/60000][Iteration 1951][Wall Clock 234.160295712s] Trained 64 records in 0.143173036 seconds. Throughput is 447.01154 records/second. Loss is 0.16373695. Sequential2290a28's hyper parameters: Current learning rate is 0.014388489208633093. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 1952][Wall Clock 234.34003212s] Trained 64 records in 0.179736408 seconds. Throughput is 356.077 records/second. Loss is 0.24759892. Sequential2290a28's hyper parameters: Current learning rate is 0.014386419220256078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 4928/60000][Iteration 1953][Wall Clock 234.511871389s] Trained 64 records in 0.171839269 seconds. Throughput is 372.44107 records/second. Loss is 0.3263722. Sequential2290a28's hyper parameters: Current learning rate is 0.014384349827387802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 4992/60000][Iteration 1954][Wall Clock 234.654403422s] Trained 64 records in 0.142532033 seconds. Throughput is 449.02185 records/second. Loss is 0.27214456. Sequential2290a28's hyper parameters: Current learning rate is 0.014382281029771321. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 5056/60000][Iteration 1955][Wall Clock 234.794091247s] Trained 64 records in 0.139687825 seconds. Throughput is 458.1645 records/second. Loss is 0.327882. Sequential2290a28's hyper parameters: Current learning rate is 0.014380212827149842. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 1956][Wall Clock 234.875692095s] Trained 64 records in 0.081600848 seconds. Throughput is 784.3056 records/second. Loss is 0.15479124. Sequential2290a28's hyper parameters: Current learning rate is 0.014378145219266714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 5184/60000][Iteration 1957][Wall Clock 234.971910988s] Trained 64 records in 0.096218893 seconds. Throughput is 665.15 records/second. Loss is 0.20345476. Sequential2290a28's hyper parameters: Current learning rate is 0.01437607820586544. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 5248/60000][Iteration 1958][Wall Clock 235.142299417s] Trained 64 records in 0.170388429 seconds. Throughput is 375.61237 records/second. Loss is 0.15765455. Sequential2290a28's hyper parameters: Current learning rate is 0.014374011786689666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:37 INFO  DistriOptimizer$:408 - [Epoch 3 5312/60000][Iteration 1959][Wall Clock 235.311398298s] Trained 64 records in 0.169098881 seconds. Throughput is 378.47678 records/second. Loss is 0.19500777. Sequential2290a28's hyper parameters: Current learning rate is 0.014371945961483185. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 1960][Wall Clock 235.444435999s] Trained 64 records in 0.133037701 seconds. Throughput is 481.06665 records/second. Loss is 0.12049446. Sequential2290a28's hyper parameters: Current learning rate is 0.014369880729989942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5440/60000][Iteration 1961][Wall Clock 235.550434744s] Trained 64 records in 0.105998745 seconds. Throughput is 603.7807 records/second. Loss is 0.18532601. Sequential2290a28's hyper parameters: Current learning rate is 0.014367816091954025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5504/60000][Iteration 1962][Wall Clock 235.679742019s] Trained 64 records in 0.129307275 seconds. Throughput is 494.9451 records/second. Loss is 0.2387788. Sequential2290a28's hyper parameters: Current learning rate is 0.014365752047119668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5568/60000][Iteration 1963][Wall Clock 235.836986221s] Trained 64 records in 0.157244202 seconds. Throughput is 407.01022 records/second. Loss is 0.2727057. Sequential2290a28's hyper parameters: Current learning rate is 0.014363688595231254. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 1964][Wall Clock 235.954685794s] Trained 64 records in 0.117699573 seconds. Throughput is 543.75726 records/second. Loss is 0.16002713. Sequential2290a28's hyper parameters: Current learning rate is 0.014361625736033319. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5696/60000][Iteration 1965][Wall Clock 236.077623829s] Trained 64 records in 0.122938035 seconds. Throughput is 520.58746 records/second. Loss is 0.335273. Sequential2290a28's hyper parameters: Current learning rate is 0.014359563469270534. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:38 INFO  DistriOptimizer$:408 - [Epoch 3 5760/60000][Iteration 1966][Wall Clock 236.17554661s] Trained 64 records in 0.097922781 seconds. Throughput is 653.57623 records/second. Loss is 0.16293977. Sequential2290a28's hyper parameters: Current learning rate is 0.014357501794687725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 5824/60000][Iteration 1967][Wall Clock 236.323939117s] Trained 64 records in 0.148392507 seconds. Throughput is 431.2886 records/second. Loss is 0.17943597. Sequential2290a28's hyper parameters: Current learning rate is 0.01435544071202986. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 1968][Wall Clock 236.427389578s] Trained 64 records in 0.103450461 seconds. Throughput is 618.65356 records/second. Loss is 0.21943167. Sequential2290a28's hyper parameters: Current learning rate is 0.014353380221042057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 5952/60000][Iteration 1969][Wall Clock 236.534648931s] Trained 64 records in 0.107259353 seconds. Throughput is 596.6846 records/second. Loss is 0.1695503. Sequential2290a28's hyper parameters: Current learning rate is 0.014351320321469576. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 6016/60000][Iteration 1970][Wall Clock 236.738694843s] Trained 64 records in 0.204045912 seconds. Throughput is 313.6549 records/second. Loss is 0.19096771. Sequential2290a28's hyper parameters: Current learning rate is 0.014349261013057826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 6080/60000][Iteration 1971][Wall Clock 236.836139255s] Trained 64 records in 0.097444412 seconds. Throughput is 656.78467 records/second. Loss is 0.16749865. Sequential2290a28's hyper parameters: Current learning rate is 0.014347202295552365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 1972][Wall Clock 236.99525019s] Trained 64 records in 0.159110935 seconds. Throughput is 402.23508 records/second. Loss is 0.23175646. Sequential2290a28's hyper parameters: Current learning rate is 0.014345144168698894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:39 INFO  DistriOptimizer$:408 - [Epoch 3 6208/60000][Iteration 1973][Wall Clock 237.187087466s] Trained 64 records in 0.191837276 seconds. Throughput is 333.61606 records/second. Loss is 0.30508083. Sequential2290a28's hyper parameters: Current learning rate is 0.014343086632243257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6272/60000][Iteration 1974][Wall Clock 237.384891647s] Trained 64 records in 0.197804181 seconds. Throughput is 323.5523 records/second. Loss is 0.19079995. Sequential2290a28's hyper parameters: Current learning rate is 0.014341029685931449. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6336/60000][Iteration 1975][Wall Clock 237.58672206s] Trained 64 records in 0.201830413 seconds. Throughput is 317.0979 records/second. Loss is 0.22167931. Sequential2290a28's hyper parameters: Current learning rate is 0.014338973329509607. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 1976][Wall Clock 237.76867363s] Trained 64 records in 0.18195157 seconds. Throughput is 351.74194 records/second. Loss is 0.25335222. Sequential2290a28's hyper parameters: Current learning rate is 0.014336917562724014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6464/60000][Iteration 1977][Wall Clock 237.895119755s] Trained 64 records in 0.126446125 seconds. Throughput is 506.1444 records/second. Loss is 0.20545675. Sequential2290a28's hyper parameters: Current learning rate is 0.014334862385321102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6528/60000][Iteration 1978][Wall Clock 238.01215601s] Trained 64 records in 0.117036255 seconds. Throughput is 546.8391 records/second. Loss is 0.2824929. Sequential2290a28's hyper parameters: Current learning rate is 0.014332807797047441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6592/60000][Iteration 1979][Wall Clock 238.126928362s] Trained 64 records in 0.114772352 seconds. Throughput is 557.6256 records/second. Loss is 0.14032653. Sequential2290a28's hyper parameters: Current learning rate is 0.014330753797649757. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:40 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 1980][Wall Clock 238.220116086s] Trained 64 records in 0.093187724 seconds. Throughput is 686.7857 records/second. Loss is 0.122224115. Sequential2290a28's hyper parameters: Current learning rate is 0.014328700386874912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 6720/60000][Iteration 1981][Wall Clock 238.309016485s] Trained 64 records in 0.088900399 seconds. Throughput is 719.90674 records/second. Loss is 0.2892295. Sequential2290a28's hyper parameters: Current learning rate is 0.014326647564469915. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 6784/60000][Iteration 1982][Wall Clock 238.399956297s] Trained 64 records in 0.090939812 seconds. Throughput is 703.76215 records/second. Loss is 0.22812861. Sequential2290a28's hyper parameters: Current learning rate is 0.014324595330181924. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 6848/60000][Iteration 1983][Wall Clock 238.528691184s] Trained 64 records in 0.128734887 seconds. Throughput is 497.14572 records/second. Loss is 0.20014566. Sequential2290a28's hyper parameters: Current learning rate is 0.014322543683758234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 1984][Wall Clock 238.735693792s] Trained 64 records in 0.207002608 seconds. Throughput is 309.17484 records/second. Loss is 0.14016627. Sequential2290a28's hyper parameters: Current learning rate is 0.014320492624946298. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 6976/60000][Iteration 1985][Wall Clock 238.969561122s] Trained 64 records in 0.23386733 seconds. Throughput is 273.65942 records/second. Loss is 0.21049722. Sequential2290a28's hyper parameters: Current learning rate is 0.0143184421534937. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 7040/60000][Iteration 1986][Wall Clock 239.117952213s] Trained 64 records in 0.148391091 seconds. Throughput is 431.29272 records/second. Loss is 0.1903558. Sequential2290a28's hyper parameters: Current learning rate is 0.014316392269148175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:41 INFO  DistriOptimizer$:408 - [Epoch 3 7104/60000][Iteration 1987][Wall Clock 239.242740301s] Trained 64 records in 0.124788088 seconds. Throughput is 512.86945 records/second. Loss is 0.26874855. Sequential2290a28's hyper parameters: Current learning rate is 0.0143143429716576. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 1988][Wall Clock 239.33496757s] Trained 64 records in 0.092227269 seconds. Throughput is 693.9379 records/second. Loss is 0.19424456. Sequential2290a28's hyper parameters: Current learning rate is 0.014312294260770003. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7232/60000][Iteration 1989][Wall Clock 239.405128506s] Trained 64 records in 0.070160936 seconds. Throughput is 912.18854 records/second. Loss is 0.10253538. Sequential2290a28's hyper parameters: Current learning rate is 0.014310246136233544. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7296/60000][Iteration 1990][Wall Clock 239.486058905s] Trained 64 records in 0.080930399 seconds. Throughput is 790.803 records/second. Loss is 0.31166127. Sequential2290a28's hyper parameters: Current learning rate is 0.014308198597796536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7360/60000][Iteration 1991][Wall Clock 239.5626315s] Trained 64 records in 0.076572595 seconds. Throughput is 835.80817 records/second. Loss is 0.341322. Sequential2290a28's hyper parameters: Current learning rate is 0.014306151645207437. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 1992][Wall Clock 239.644839225s] Trained 64 records in 0.082207725 seconds. Throughput is 778.5156 records/second. Loss is 0.12632743. Sequential2290a28's hyper parameters: Current learning rate is 0.014304105278214846. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7488/60000][Iteration 1993][Wall Clock 239.760932194s] Trained 64 records in 0.116092969 seconds. Throughput is 551.2823 records/second. Loss is 0.15781999. Sequential2290a28's hyper parameters: Current learning rate is 0.014302059496567505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7552/60000][Iteration 1994][Wall Clock 239.858526704s] Trained 64 records in 0.09759451 seconds. Throughput is 655.7746 records/second. Loss is 0.30231377. Sequential2290a28's hyper parameters: Current learning rate is 0.0143000143000143. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7616/60000][Iteration 1995][Wall Clock 239.981666233s] Trained 64 records in 0.123139529 seconds. Throughput is 519.7356 records/second. Loss is 0.21238759. Sequential2290a28's hyper parameters: Current learning rate is 0.014297969688304261. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 1996][Wall Clock 240.119596416s] Trained 64 records in 0.137930183 seconds. Throughput is 464.00287 records/second. Loss is 0.16204414. Sequential2290a28's hyper parameters: Current learning rate is 0.014295925661186561. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:42 INFO  DistriOptimizer$:408 - [Epoch 3 7744/60000][Iteration 1997][Wall Clock 240.242359075s] Trained 64 records in 0.122762659 seconds. Throughput is 521.3312 records/second. Loss is 0.18428081. Sequential2290a28's hyper parameters: Current learning rate is 0.014293882218410521. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:43 INFO  DistriOptimizer$:408 - [Epoch 3 7808/60000][Iteration 1998][Wall Clock 240.365546276s] Trained 64 records in 0.123187201 seconds. Throughput is 519.5345 records/second. Loss is 0.1851068. Sequential2290a28's hyper parameters: Current learning rate is 0.014291839359725597. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:43 INFO  DistriOptimizer$:408 - [Epoch 3 7872/60000][Iteration 1999][Wall Clock 240.490141191s] Trained 64 records in 0.124594915 seconds. Throughput is 513.6646 records/second. Loss is 0.23764083. Sequential2290a28's hyper parameters: Current learning rate is 0.014289797084881395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:43 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 2000][Wall Clock 240.682810049s] Trained 64 records in 0.192668858 seconds. Throughput is 332.17615 records/second. Loss is 0.38995016. Sequential2290a28's hyper parameters: Current learning rate is 0.014287755393627663. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:43 INFO  DistriOptimizer$:408 - [Epoch 3 8000/60000][Iteration 2001][Wall Clock 240.84075079s] Trained 64 records in 0.157940741 seconds. Throughput is 405.21527 records/second. Loss is 0.17694819. Sequential2290a28's hyper parameters: Current learning rate is 0.014285714285714287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:43 INFO  DistriOptimizer$:408 - [Epoch 3 8064/60000][Iteration 2002][Wall Clock 241.003911626s] Trained 64 records in 0.163160836 seconds. Throughput is 392.251 records/second. Loss is 0.135959. Sequential2290a28's hyper parameters: Current learning rate is 0.014283673760891303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:43 INFO  DistriOptimizer$:408 - [Epoch 3 8128/60000][Iteration 2003][Wall Clock 241.158111127s] Trained 64 records in 0.154199501 seconds. Throughput is 415.04675 records/second. Loss is 0.2268722. Sequential2290a28's hyper parameters: Current learning rate is 0.014281633818908882. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 2004][Wall Clock 241.301300662s] Trained 64 records in 0.143189535 seconds. Throughput is 446.96005 records/second. Loss is 0.18247315. Sequential2290a28's hyper parameters: Current learning rate is 0.01427959445951735. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8256/60000][Iteration 2005][Wall Clock 241.429860804s] Trained 64 records in 0.128560142 seconds. Throughput is 497.82147 records/second. Loss is 0.25601768. Sequential2290a28's hyper parameters: Current learning rate is 0.014277555682467162. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8320/60000][Iteration 2006][Wall Clock 241.56803299s] Trained 64 records in 0.138172186 seconds. Throughput is 463.19022 records/second. Loss is 0.2747352. Sequential2290a28's hyper parameters: Current learning rate is 0.014275517487508922. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8384/60000][Iteration 2007][Wall Clock 241.693262324s] Trained 64 records in 0.125229334 seconds. Throughput is 511.06238 records/second. Loss is 0.15394127. Sequential2290a28's hyper parameters: Current learning rate is 0.014273479874393378. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 2008][Wall Clock 241.808936556s] Trained 64 records in 0.115674232 seconds. Throughput is 553.2779 records/second. Loss is 0.14117163. Sequential2290a28's hyper parameters: Current learning rate is 0.014271442842871416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8512/60000][Iteration 2009][Wall Clock 241.996539494s] Trained 64 records in 0.187602938 seconds. Throughput is 341.14606 records/second. Loss is 0.12156479. Sequential2290a28's hyper parameters: Current learning rate is 0.014269406392694065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:44 INFO  DistriOptimizer$:408 - [Epoch 3 8576/60000][Iteration 2010][Wall Clock 242.170290629s] Trained 64 records in 0.173751135 seconds. Throughput is 368.34293 records/second. Loss is 0.19450359. Sequential2290a28's hyper parameters: Current learning rate is 0.014267370523612497. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 8640/60000][Iteration 2011][Wall Clock 242.350229405s] Trained 64 records in 0.179938776 seconds. Throughput is 355.6765 records/second. Loss is 0.2718294. Sequential2290a28's hyper parameters: Current learning rate is 0.01426533523537803. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 2012][Wall Clock 242.54838632s] Trained 64 records in 0.198156915 seconds. Throughput is 322.97638 records/second. Loss is 0.1181602. Sequential2290a28's hyper parameters: Current learning rate is 0.014263300527742119. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 8768/60000][Iteration 2013][Wall Clock 242.673785708s] Trained 64 records in 0.125399388 seconds. Throughput is 510.36935 records/second. Loss is 0.107452154. Sequential2290a28's hyper parameters: Current learning rate is 0.01426126640045636. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 8832/60000][Iteration 2014][Wall Clock 242.813087945s] Trained 64 records in 0.139302237 seconds. Throughput is 459.43268 records/second. Loss is 0.18775806. Sequential2290a28's hyper parameters: Current learning rate is 0.014259232853272493. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 8896/60000][Iteration 2015][Wall Clock 242.914158319s] Trained 64 records in 0.101070374 seconds. Throughput is 633.22217 records/second. Loss is 0.30560872. Sequential2290a28's hyper parameters: Current learning rate is 0.014257199885942401. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 2016][Wall Clock 243.036577802s] Trained 64 records in 0.122419483 seconds. Throughput is 522.7926 records/second. Loss is 0.26127392. Sequential2290a28's hyper parameters: Current learning rate is 0.014255167498218105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 9024/60000][Iteration 2017][Wall Clock 243.145480495s] Trained 64 records in 0.108902693 seconds. Throughput is 587.6806 records/second. Loss is 0.20891581. Sequential2290a28's hyper parameters: Current learning rate is 0.014253135689851768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:45 INFO  DistriOptimizer$:408 - [Epoch 3 9088/60000][Iteration 2018][Wall Clock 243.246266432s] Trained 64 records in 0.100785937 seconds. Throughput is 635.0093 records/second. Loss is 0.37606722. Sequential2290a28's hyper parameters: Current learning rate is 0.014251104460595696. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9152/60000][Iteration 2019][Wall Clock 243.341723724s] Trained 64 records in 0.095457292 seconds. Throughput is 670.4569 records/second. Loss is 0.121900216. Sequential2290a28's hyper parameters: Current learning rate is 0.014249073810202337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 2020][Wall Clock 243.467562132s] Trained 64 records in 0.125838408 seconds. Throughput is 508.58875 records/second. Loss is 0.1693384. Sequential2290a28's hyper parameters: Current learning rate is 0.014247043738424277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9280/60000][Iteration 2021][Wall Clock 243.587216319s] Trained 64 records in 0.119654187 seconds. Throughput is 534.87476 records/second. Loss is 0.100925975. Sequential2290a28's hyper parameters: Current learning rate is 0.014245014245014247. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9344/60000][Iteration 2022][Wall Clock 243.734779937s] Trained 64 records in 0.147563618 seconds. Throughput is 433.71124 records/second. Loss is 0.19109645. Sequential2290a28's hyper parameters: Current learning rate is 0.014242985329725111. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9408/60000][Iteration 2023][Wall Clock 243.912047543s] Trained 64 records in 0.177267606 seconds. Throughput is 361.03607 records/second. Loss is 0.41929755. Sequential2290a28's hyper parameters: Current learning rate is 0.014240956992309883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 2024][Wall Clock 244.051429041s] Trained 64 records in 0.139381498 seconds. Throughput is 459.17142 records/second. Loss is 0.20983009. Sequential2290a28's hyper parameters: Current learning rate is 0.014238929232521715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:46 INFO  DistriOptimizer$:408 - [Epoch 3 9536/60000][Iteration 2025][Wall Clock 244.218495418s] Trained 64 records in 0.167066377 seconds. Throughput is 383.08127 records/second. Loss is 0.275097. Sequential2290a28's hyper parameters: Current learning rate is 0.014236902050113895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9600/60000][Iteration 2026][Wall Clock 244.342031201s] Trained 64 records in 0.123535783 seconds. Throughput is 518.06854 records/second. Loss is 0.20146015. Sequential2290a28's hyper parameters: Current learning rate is 0.014234875444839857. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9664/60000][Iteration 2027][Wall Clock 244.534503817s] Trained 64 records in 0.192472616 seconds. Throughput is 332.51483 records/second. Loss is 0.206458. Sequential2290a28's hyper parameters: Current learning rate is 0.014232849416453175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 2028][Wall Clock 244.670862178s] Trained 64 records in 0.136358361 seconds. Throughput is 469.35147 records/second. Loss is 0.32943514. Sequential2290a28's hyper parameters: Current learning rate is 0.014230823964707557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9792/60000][Iteration 2029][Wall Clock 244.818736932s] Trained 64 records in 0.147874754 seconds. Throughput is 432.79868 records/second. Loss is 0.22552028. Sequential2290a28's hyper parameters: Current learning rate is 0.014228799089356859. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9856/60000][Iteration 2030][Wall Clock 244.956323442s] Trained 64 records in 0.13758651 seconds. Throughput is 465.1619 records/second. Loss is 0.20536938. Sequential2290a28's hyper parameters: Current learning rate is 0.014226774790155073. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9920/60000][Iteration 2031][Wall Clock 245.11697053s] Trained 64 records in 0.160647088 seconds. Throughput is 398.3888 records/second. Loss is 0.17334355. Sequential2290a28's hyper parameters: Current learning rate is 0.014224751066856329. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:47 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 2032][Wall Clock 245.244658466s] Trained 64 records in 0.127687936 seconds. Throughput is 501.222 records/second. Loss is 0.14132464. Sequential2290a28's hyper parameters: Current learning rate is 0.014222727919214905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10048/60000][Iteration 2033][Wall Clock 245.361194863s] Trained 64 records in 0.116536397 seconds. Throughput is 549.18463 records/second. Loss is 0.27259547. Sequential2290a28's hyper parameters: Current learning rate is 0.01422070534698521. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10112/60000][Iteration 2034][Wall Clock 245.533816278s] Trained 64 records in 0.172621415 seconds. Throughput is 370.75354 records/second. Loss is 0.18564898. Sequential2290a28's hyper parameters: Current learning rate is 0.014218683349921797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10176/60000][Iteration 2035][Wall Clock 245.678114792s] Trained 64 records in 0.144298514 seconds. Throughput is 443.52502 records/second. Loss is 0.18998697. Sequential2290a28's hyper parameters: Current learning rate is 0.014216661927779357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 2036][Wall Clock 245.808126596s] Trained 64 records in 0.130011804 seconds. Throughput is 492.26303 records/second. Loss is 0.13832715. Sequential2290a28's hyper parameters: Current learning rate is 0.014214641080312722. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10304/60000][Iteration 2037][Wall Clock 245.876241314s] Trained 64 records in 0.068114718 seconds. Throughput is 939.5913 records/second. Loss is 0.25250268. Sequential2290a28's hyper parameters: Current learning rate is 0.014212620807276862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10368/60000][Iteration 2038][Wall Clock 245.983479521s] Trained 64 records in 0.107238207 seconds. Throughput is 596.80225 records/second. Loss is 0.17306322. Sequential2290a28's hyper parameters: Current learning rate is 0.014210601108426887. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10432/60000][Iteration 2039][Wall Clock 246.088430116s] Trained 64 records in 0.104950595 seconds. Throughput is 609.8107 records/second. Loss is 0.10031429. Sequential2290a28's hyper parameters: Current learning rate is 0.014208581983518046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:48 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 2040][Wall Clock 246.199552055s] Trained 64 records in 0.111121939 seconds. Throughput is 575.9439 records/second. Loss is 0.14798585. Sequential2290a28's hyper parameters: Current learning rate is 0.014206563432305726. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10560/60000][Iteration 2041][Wall Clock 246.304320118s] Trained 64 records in 0.104768063 seconds. Throughput is 610.87317 records/second. Loss is 0.11167394. Sequential2290a28's hyper parameters: Current learning rate is 0.014204545454545456. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10624/60000][Iteration 2042][Wall Clock 246.383051009s] Trained 64 records in 0.078730891 seconds. Throughput is 812.8957 records/second. Loss is 0.26130798. Sequential2290a28's hyper parameters: Current learning rate is 0.0142025280499929. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10688/60000][Iteration 2043][Wall Clock 246.462230083s] Trained 64 records in 0.079179074 seconds. Throughput is 808.29443 records/second. Loss is 0.395891. Sequential2290a28's hyper parameters: Current learning rate is 0.014200511218403862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 2044][Wall Clock 246.543260388s] Trained 64 records in 0.081030305 seconds. Throughput is 789.828 records/second. Loss is 0.22223449. Sequential2290a28's hyper parameters: Current learning rate is 0.01419849495953429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10816/60000][Iteration 2045][Wall Clock 246.618036991s] Trained 64 records in 0.074776603 seconds. Throughput is 855.8827 records/second. Loss is 0.21242237. Sequential2290a28's hyper parameters: Current learning rate is 0.014196479273140262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10880/60000][Iteration 2046][Wall Clock 246.69457224s] Trained 64 records in 0.076535249 seconds. Throughput is 836.216 records/second. Loss is 0.24069378. Sequential2290a28's hyper parameters: Current learning rate is 0.014194464158977998. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 10944/60000][Iteration 2047][Wall Clock 246.804566611s] Trained 64 records in 0.109994371 seconds. Throughput is 581.84796 records/second. Loss is 0.2030808. Sequential2290a28's hyper parameters: Current learning rate is 0.01419244961680386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 2048][Wall Clock 246.93042945s] Trained 64 records in 0.125862839 seconds. Throughput is 508.49005 records/second. Loss is 0.19399142. Sequential2290a28's hyper parameters: Current learning rate is 0.014190435646374344. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:49 INFO  DistriOptimizer$:408 - [Epoch 3 11072/60000][Iteration 2049][Wall Clock 247.098951225s] Trained 64 records in 0.168521775 seconds. Throughput is 379.7729 records/second. Loss is 0.18320692. Sequential2290a28's hyper parameters: Current learning rate is 0.014188422247446085. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:50 INFO  DistriOptimizer$:408 - [Epoch 3 11136/60000][Iteration 2050][Wall Clock 247.338444044s] Trained 64 records in 0.239492819 seconds. Throughput is 267.23138 records/second. Loss is 0.22975342. Sequential2290a28's hyper parameters: Current learning rate is 0.014186409419775855. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:50 INFO  DistriOptimizer$:408 - [Epoch 3 11200/60000][Iteration 2051][Wall Clock 247.570788385s] Trained 64 records in 0.232344341 seconds. Throughput is 275.45322 records/second. Loss is 0.2079965. Sequential2290a28's hyper parameters: Current learning rate is 0.014184397163120567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:50 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 2052][Wall Clock 247.764420994s] Trained 64 records in 0.193632609 seconds. Throughput is 330.52286 records/second. Loss is 0.22615623. Sequential2290a28's hyper parameters: Current learning rate is 0.014182385477237271. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:50 INFO  DistriOptimizer$:408 - [Epoch 3 11328/60000][Iteration 2053][Wall Clock 247.921841947s] Trained 64 records in 0.157420953 seconds. Throughput is 406.55325 records/second. Loss is 0.13203132. Sequential2290a28's hyper parameters: Current learning rate is 0.014180374361883153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:50 INFO  DistriOptimizer$:408 - [Epoch 3 11392/60000][Iteration 2054][Wall Clock 248.112053689s] Trained 64 records in 0.190211742 seconds. Throughput is 336.46713 records/second. Loss is 0.09869281. Sequential2290a28's hyper parameters: Current learning rate is 0.014178363816815538. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:50 INFO  DistriOptimizer$:408 - [Epoch 3 11456/60000][Iteration 2055][Wall Clock 248.248367266s] Trained 64 records in 0.136313577 seconds. Throughput is 469.5057 records/second. Loss is 0.43662164. Sequential2290a28's hyper parameters: Current learning rate is 0.01417635384179189. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:51 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 2056][Wall Clock 248.447656782s] Trained 64 records in 0.199289516 seconds. Throughput is 321.14084 records/second. Loss is 0.2019451. Sequential2290a28's hyper parameters: Current learning rate is 0.014174344436569808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:51 INFO  DistriOptimizer$:408 - [Epoch 3 11584/60000][Iteration 2057][Wall Clock 248.613010125s] Trained 64 records in 0.165353343 seconds. Throughput is 387.04993 records/second. Loss is 0.09918764. Sequential2290a28's hyper parameters: Current learning rate is 0.01417233560090703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:51 INFO  DistriOptimizer$:408 - [Epoch 3 11648/60000][Iteration 2058][Wall Clock 248.814213708s] Trained 64 records in 0.201203583 seconds. Throughput is 318.0858 records/second. Loss is 0.14078113. Sequential2290a28's hyper parameters: Current learning rate is 0.014170327334561429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:51 INFO  DistriOptimizer$:408 - [Epoch 3 11712/60000][Iteration 2059][Wall Clock 248.964366617s] Trained 64 records in 0.150152909 seconds. Throughput is 426.23218 records/second. Loss is 0.2622785. Sequential2290a28's hyper parameters: Current learning rate is 0.014168319637291017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:51 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 2060][Wall Clock 249.141550584s] Trained 64 records in 0.177183967 seconds. Throughput is 361.20648 records/second. Loss is 0.19279502. Sequential2290a28's hyper parameters: Current learning rate is 0.014166312508853945. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 11840/60000][Iteration 2061][Wall Clock 249.273045203s] Trained 64 records in 0.131494619 seconds. Throughput is 486.7119 records/second. Loss is 0.19744793. Sequential2290a28's hyper parameters: Current learning rate is 0.014164305949008499. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 11904/60000][Iteration 2062][Wall Clock 249.365178519s] Trained 64 records in 0.092133316 seconds. Throughput is 694.64557 records/second. Loss is 0.2325577. Sequential2290a28's hyper parameters: Current learning rate is 0.014162299957513102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 11968/60000][Iteration 2063][Wall Clock 249.565400329s] Trained 64 records in 0.20022181 seconds. Throughput is 319.6455 records/second. Loss is 0.20516181. Sequential2290a28's hyper parameters: Current learning rate is 0.01416029453412631. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 2064][Wall Clock 249.726399628s] Trained 64 records in 0.160999299 seconds. Throughput is 397.51727 records/second. Loss is 0.20644596. Sequential2290a28's hyper parameters: Current learning rate is 0.014158289678606824. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 12096/60000][Iteration 2065][Wall Clock 249.823697889s] Trained 64 records in 0.097298261 seconds. Throughput is 657.77124 records/second. Loss is 0.22709149. Sequential2290a28's hyper parameters: Current learning rate is 0.014156285390713477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 12160/60000][Iteration 2066][Wall Clock 249.965573074s] Trained 64 records in 0.141875185 seconds. Throughput is 451.10077 records/second. Loss is 0.13713676. Sequential2290a28's hyper parameters: Current learning rate is 0.014154281670205236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 12224/60000][Iteration 2067][Wall Clock 250.057803674s] Trained 64 records in 0.0922306 seconds. Throughput is 693.91284 records/second. Loss is 0.22624248. Sequential2290a28's hyper parameters: Current learning rate is 0.014152278516841211. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:52 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 2068][Wall Clock 250.17204759s] Trained 64 records in 0.114243916 seconds. Throughput is 560.2049 records/second. Loss is 0.16675547. Sequential2290a28's hyper parameters: Current learning rate is 0.014150275930380643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12352/60000][Iteration 2069][Wall Clock 250.291620606s] Trained 64 records in 0.119573016 seconds. Throughput is 535.2378 records/second. Loss is 0.21848026. Sequential2290a28's hyper parameters: Current learning rate is 0.014148273910582909. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12416/60000][Iteration 2070][Wall Clock 250.424318745s] Trained 64 records in 0.132698139 seconds. Throughput is 482.29767 records/second. Loss is 0.2946671. Sequential2290a28's hyper parameters: Current learning rate is 0.014146272457207527. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12480/60000][Iteration 2071][Wall Clock 250.576136543s] Trained 64 records in 0.151817798 seconds. Throughput is 421.55795 records/second. Loss is 0.22804955. Sequential2290a28's hyper parameters: Current learning rate is 0.014144271570014143. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 2072][Wall Clock 250.685807698s] Trained 64 records in 0.109671155 seconds. Throughput is 583.56274 records/second. Loss is 0.20546934. Sequential2290a28's hyper parameters: Current learning rate is 0.01414227124876255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12608/60000][Iteration 2073][Wall Clock 250.875239834s] Trained 64 records in 0.189432136 seconds. Throughput is 337.85187 records/second. Loss is 0.099002816. Sequential2290a28's hyper parameters: Current learning rate is 0.01414027149321267. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12672/60000][Iteration 2074][Wall Clock 250.979541917s] Trained 64 records in 0.104302083 seconds. Throughput is 613.6023 records/second. Loss is 0.19949466. Sequential2290a28's hyper parameters: Current learning rate is 0.014138272303124557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:53 INFO  DistriOptimizer$:408 - [Epoch 3 12736/60000][Iteration 2075][Wall Clock 251.167122795s] Trained 64 records in 0.187580878 seconds. Throughput is 341.18616 records/second. Loss is 0.1303434. Sequential2290a28's hyper parameters: Current learning rate is 0.01413627367825841. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 2076][Wall Clock 251.282310969s] Trained 64 records in 0.115188174 seconds. Throughput is 555.6126 records/second. Loss is 0.37198368. Sequential2290a28's hyper parameters: Current learning rate is 0.014134275618374558. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 12864/60000][Iteration 2077][Wall Clock 251.404541737s] Trained 64 records in 0.122230768 seconds. Throughput is 523.59973 records/second. Loss is 0.13713041. Sequential2290a28's hyper parameters: Current learning rate is 0.014132278123233465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 12928/60000][Iteration 2078][Wall Clock 251.519955202s] Trained 64 records in 0.115413465 seconds. Throughput is 554.528 records/second. Loss is 0.286695. Sequential2290a28's hyper parameters: Current learning rate is 0.014130281192595733. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 12992/60000][Iteration 2079][Wall Clock 251.667746512s] Trained 64 records in 0.14779131 seconds. Throughput is 433.04306 records/second. Loss is 0.28203052. Sequential2290a28's hyper parameters: Current learning rate is 0.014128284826222097. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 2080][Wall Clock 251.778319563s] Trained 64 records in 0.110573051 seconds. Throughput is 578.80286 records/second. Loss is 0.17335784. Sequential2290a28's hyper parameters: Current learning rate is 0.01412628902387343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 13120/60000][Iteration 2081][Wall Clock 251.882790524s] Trained 64 records in 0.104470961 seconds. Throughput is 612.6104 records/second. Loss is 0.17053056. Sequential2290a28's hyper parameters: Current learning rate is 0.014124293785310736. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 13184/60000][Iteration 2082][Wall Clock 252.003524782s] Trained 64 records in 0.120734258 seconds. Throughput is 530.0898 records/second. Loss is 0.23929657. Sequential2290a28's hyper parameters: Current learning rate is 0.014122299110295158. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:54 INFO  DistriOptimizer$:408 - [Epoch 3 13248/60000][Iteration 2083][Wall Clock 252.117624325s] Trained 64 records in 0.114099543 seconds. Throughput is 560.91376 records/second. Loss is 0.2512669. Sequential2290a28's hyper parameters: Current learning rate is 0.014120304998587971. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 2084][Wall Clock 252.238295352s] Trained 64 records in 0.120671027 seconds. Throughput is 530.36755 records/second. Loss is 0.14625388. Sequential2290a28's hyper parameters: Current learning rate is 0.014118311449950585. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13376/60000][Iteration 2085][Wall Clock 252.343511795s] Trained 64 records in 0.105216443 seconds. Throughput is 608.26996 records/second. Loss is 0.1966309. Sequential2290a28's hyper parameters: Current learning rate is 0.01411631846414455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13440/60000][Iteration 2086][Wall Clock 252.537738867s] Trained 64 records in 0.194227072 seconds. Throughput is 329.51123 records/second. Loss is 0.24745962. Sequential2290a28's hyper parameters: Current learning rate is 0.014114326040931546. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13504/60000][Iteration 2087][Wall Clock 252.738908237s] Trained 64 records in 0.20116937 seconds. Throughput is 318.1399 records/second. Loss is 0.20021401. Sequential2290a28's hyper parameters: Current learning rate is 0.014112334180073384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 2088][Wall Clock 252.926412189s] Trained 64 records in 0.187503952 seconds. Throughput is 341.32614 records/second. Loss is 0.18079974. Sequential2290a28's hyper parameters: Current learning rate is 0.014110342881332017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13632/60000][Iteration 2089][Wall Clock 253.061212628s] Trained 64 records in 0.134800439 seconds. Throughput is 474.7759 records/second. Loss is 0.099054694. Sequential2290a28's hyper parameters: Current learning rate is 0.014108352144469526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:55 INFO  DistriOptimizer$:408 - [Epoch 3 13696/60000][Iteration 2090][Wall Clock 253.182866019s] Trained 64 records in 0.121653391 seconds. Throughput is 526.0848 records/second. Loss is 0.20780775. Sequential2290a28's hyper parameters: Current learning rate is 0.014106361969248131. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 13760/60000][Iteration 2091][Wall Clock 253.275104911s] Trained 64 records in 0.092238892 seconds. Throughput is 693.85046 records/second. Loss is 0.30508232. Sequential2290a28's hyper parameters: Current learning rate is 0.014104372355430182. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 2092][Wall Clock 253.376578151s] Trained 64 records in 0.10147324 seconds. Throughput is 630.7081 records/second. Loss is 0.23865494. Sequential2290a28's hyper parameters: Current learning rate is 0.014102383302778168. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 13888/60000][Iteration 2093][Wall Clock 253.474968514s] Trained 64 records in 0.098390363 seconds. Throughput is 650.4702 records/second. Loss is 0.37931538. Sequential2290a28's hyper parameters: Current learning rate is 0.014100394811054708. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 13952/60000][Iteration 2094][Wall Clock 253.579431732s] Trained 64 records in 0.104463218 seconds. Throughput is 612.6558 records/second. Loss is 0.18164116. Sequential2290a28's hyper parameters: Current learning rate is 0.014098406880022557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 14016/60000][Iteration 2095][Wall Clock 253.691073413s] Trained 64 records in 0.111641681 seconds. Throughput is 573.2626 records/second. Loss is 0.27171957. Sequential2290a28's hyper parameters: Current learning rate is 0.0140964195094446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 2096][Wall Clock 253.854210051s] Trained 64 records in 0.163136638 seconds. Throughput is 392.3092 records/second. Loss is 0.37576306. Sequential2290a28's hyper parameters: Current learning rate is 0.014094432699083862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:56 INFO  DistriOptimizer$:408 - [Epoch 3 14144/60000][Iteration 2097][Wall Clock 254.004492484s] Trained 64 records in 0.150282433 seconds. Throughput is 425.86484 records/second. Loss is 0.21003035. Sequential2290a28's hyper parameters: Current learning rate is 0.014092446448703494. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14208/60000][Iteration 2098][Wall Clock 254.242311043s] Trained 64 records in 0.237818559 seconds. Throughput is 269.11273 records/second. Loss is 0.20809951. Sequential2290a28's hyper parameters: Current learning rate is 0.014090460758066789. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14272/60000][Iteration 2099][Wall Clock 254.370805725s] Trained 64 records in 0.128494682 seconds. Throughput is 498.0751 records/second. Loss is 0.26230437. Sequential2290a28's hyper parameters: Current learning rate is 0.014088475626937167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 2100][Wall Clock 254.518515986s] Trained 64 records in 0.147710261 seconds. Throughput is 433.28067 records/second. Loss is 0.29277176. Sequential2290a28's hyper parameters: Current learning rate is 0.014086491055078181. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14400/60000][Iteration 2101][Wall Clock 254.703420874s] Trained 64 records in 0.184904888 seconds. Throughput is 346.1239 records/second. Loss is 0.23374377. Sequential2290a28's hyper parameters: Current learning rate is 0.014084507042253521. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14464/60000][Iteration 2102][Wall Clock 254.85671988s] Trained 64 records in 0.153299006 seconds. Throughput is 417.48477 records/second. Loss is 0.19645883. Sequential2290a28's hyper parameters: Current learning rate is 0.014082523588227012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14528/60000][Iteration 2103][Wall Clock 254.952965201s] Trained 64 records in 0.096245321 seconds. Throughput is 664.9674 records/second. Loss is 0.2017546. Sequential2290a28's hyper parameters: Current learning rate is 0.014080540692762603. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:57 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 2104][Wall Clock 255.169812092s] Trained 64 records in 0.216846891 seconds. Throughput is 295.1391 records/second. Loss is 0.22933438. Sequential2290a28's hyper parameters: Current learning rate is 0.014078558355624384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:58 INFO  DistriOptimizer$:408 - [Epoch 3 14656/60000][Iteration 2105][Wall Clock 255.323256845s] Trained 64 records in 0.153444753 seconds. Throughput is 417.08823 records/second. Loss is 0.22764674. Sequential2290a28's hyper parameters: Current learning rate is 0.014076576576576577. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:58 INFO  DistriOptimizer$:408 - [Epoch 3 14720/60000][Iteration 2106][Wall Clock 255.466545223s] Trained 64 records in 0.143288378 seconds. Throughput is 446.65173 records/second. Loss is 0.124863476. Sequential2290a28's hyper parameters: Current learning rate is 0.014074595355383532. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:58 INFO  DistriOptimizer$:408 - [Epoch 3 14784/60000][Iteration 2107][Wall Clock 255.693915938s] Trained 64 records in 0.227370715 seconds. Throughput is 281.47864 records/second. Loss is 0.21596488. Sequential2290a28's hyper parameters: Current learning rate is 0.014072614691809739. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:58 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 2108][Wall Clock 255.929025024s] Trained 64 records in 0.235109086 seconds. Throughput is 272.21405 records/second. Loss is 0.19696853. Sequential2290a28's hyper parameters: Current learning rate is 0.014070634585619812. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:58 INFO  DistriOptimizer$:408 - [Epoch 3 14912/60000][Iteration 2109][Wall Clock 256.036998999s] Trained 64 records in 0.107973975 seconds. Throughput is 592.7354 records/second. Loss is 0.1314383. Sequential2290a28's hyper parameters: Current learning rate is 0.014068655036578503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:58 INFO  DistriOptimizer$:408 - [Epoch 3 14976/60000][Iteration 2110][Wall Clock 256.192248738s] Trained 64 records in 0.155249739 seconds. Throughput is 412.239 records/second. Loss is 0.25888693. Sequential2290a28's hyper parameters: Current learning rate is 0.014066676044450697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:59 INFO  DistriOptimizer$:408 - [Epoch 3 15040/60000][Iteration 2111][Wall Clock 256.367424363s] Trained 64 records in 0.175175625 seconds. Throughput is 365.34763 records/second. Loss is 0.30432624. Sequential2290a28's hyper parameters: Current learning rate is 0.014064697609001406. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:59 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 2112][Wall Clock 256.574097092s] Trained 64 records in 0.206672729 seconds. Throughput is 309.66833 records/second. Loss is 0.20458919. Sequential2290a28's hyper parameters: Current learning rate is 0.01406271972999578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:59 INFO  DistriOptimizer$:408 - [Epoch 3 15168/60000][Iteration 2113][Wall Clock 256.859218448s] Trained 64 records in 0.285121356 seconds. Throughput is 224.46582 records/second. Loss is 0.22709285. Sequential2290a28's hyper parameters: Current learning rate is 0.0140607424071991. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:59 INFO  DistriOptimizer$:408 - [Epoch 3 15232/60000][Iteration 2114][Wall Clock 256.981418987s] Trained 64 records in 0.122200539 seconds. Throughput is 523.72925 records/second. Loss is 0.14104867. Sequential2290a28's hyper parameters: Current learning rate is 0.014058765640376775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:17:59 INFO  DistriOptimizer$:408 - [Epoch 3 15296/60000][Iteration 2115][Wall Clock 257.154626455s] Trained 64 records in 0.173207468 seconds. Throughput is 369.49908 records/second. Loss is 0.3993526. Sequential2290a28's hyper parameters: Current learning rate is 0.014056789429294348. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 2116][Wall Clock 257.288308178s] Trained 64 records in 0.133681723 seconds. Throughput is 478.74905 records/second. Loss is 0.3171811. Sequential2290a28's hyper parameters: Current learning rate is 0.014054813773717497. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15424/60000][Iteration 2117][Wall Clock 257.457655303s] Trained 64 records in 0.169347125 seconds. Throughput is 377.92197 records/second. Loss is 0.30815762. Sequential2290a28's hyper parameters: Current learning rate is 0.014052838673412029. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15488/60000][Iteration 2118][Wall Clock 257.586507505s] Trained 64 records in 0.128852202 seconds. Throughput is 496.69308 records/second. Loss is 0.14117798. Sequential2290a28's hyper parameters: Current learning rate is 0.01405086412814388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15552/60000][Iteration 2119][Wall Clock 257.766129613s] Trained 64 records in 0.179622108 seconds. Throughput is 356.30356 records/second. Loss is 0.20811604. Sequential2290a28's hyper parameters: Current learning rate is 0.014048890137679125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 2120][Wall Clock 257.891128263s] Trained 64 records in 0.12499865 seconds. Throughput is 512.00555 records/second. Loss is 0.12941632. Sequential2290a28's hyper parameters: Current learning rate is 0.014046916701783959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15680/60000][Iteration 2121][Wall Clock 258.057956029s] Trained 64 records in 0.166827766 seconds. Throughput is 383.62918 records/second. Loss is 0.18795821. Sequential2290a28's hyper parameters: Current learning rate is 0.01404494382022472. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:00 INFO  DistriOptimizer$:408 - [Epoch 3 15744/60000][Iteration 2122][Wall Clock 258.172924464s] Trained 64 records in 0.114968435 seconds. Throughput is 556.67456 records/second. Loss is 0.07558997. Sequential2290a28's hyper parameters: Current learning rate is 0.014042971492767871. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:01 INFO  DistriOptimizer$:408 - [Epoch 3 15808/60000][Iteration 2123][Wall Clock 258.36291322s] Trained 64 records in 0.189988756 seconds. Throughput is 336.86203 records/second. Loss is 0.106489904. Sequential2290a28's hyper parameters: Current learning rate is 0.014040999719180007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:01 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 2124][Wall Clock 258.541510771s] Trained 64 records in 0.178597551 seconds. Throughput is 358.34756 records/second. Loss is 0.2152862. Sequential2290a28's hyper parameters: Current learning rate is 0.014039028499227852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:01 INFO  DistriOptimizer$:408 - [Epoch 3 15936/60000][Iteration 2125][Wall Clock 258.71443109s] Trained 64 records in 0.172920319 seconds. Throughput is 370.11267 records/second. Loss is 0.38592964. Sequential2290a28's hyper parameters: Current learning rate is 0.01403705783267827. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:01 INFO  DistriOptimizer$:408 - [Epoch 3 16000/60000][Iteration 2126][Wall Clock 258.816146165s] Trained 64 records in 0.101715075 seconds. Throughput is 629.2086 records/second. Loss is 0.14680034. Sequential2290a28's hyper parameters: Current learning rate is 0.014035087719298246. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:01 INFO  DistriOptimizer$:408 - [Epoch 3 16064/60000][Iteration 2127][Wall Clock 258.967247421s] Trained 64 records in 0.151101256 seconds. Throughput is 423.557 records/second. Loss is 0.120272115. Sequential2290a28's hyper parameters: Current learning rate is 0.014033118158854897. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:01 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 2128][Wall Clock 259.10190452s] Trained 64 records in 0.134657099 seconds. Throughput is 475.28128 records/second. Loss is 0.22411808. Sequential2290a28's hyper parameters: Current learning rate is 0.014031149151115477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16192/60000][Iteration 2129][Wall Clock 259.253917239s] Trained 64 records in 0.152012719 seconds. Throughput is 421.0174 records/second. Loss is 0.19874558. Sequential2290a28's hyper parameters: Current learning rate is 0.014029180695847363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16256/60000][Iteration 2130][Wall Clock 259.513440666s] Trained 64 records in 0.259523427 seconds. Throughput is 246.60588 records/second. Loss is 0.25070336. Sequential2290a28's hyper parameters: Current learning rate is 0.014027212792818067. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16320/60000][Iteration 2131][Wall Clock 259.688612445s] Trained 64 records in 0.175171779 seconds. Throughput is 365.35565 records/second. Loss is 0.33622545. Sequential2290a28's hyper parameters: Current learning rate is 0.014025245441795231. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 2132][Wall Clock 259.805642595s] Trained 64 records in 0.11703015 seconds. Throughput is 546.8676 records/second. Loss is 0.34600818. Sequential2290a28's hyper parameters: Current learning rate is 0.014023278642546627. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16448/60000][Iteration 2133][Wall Clock 259.911406296s] Trained 64 records in 0.105763701 seconds. Throughput is 605.12256 records/second. Loss is 0.1396605. Sequential2290a28's hyper parameters: Current learning rate is 0.014021312394840156. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16512/60000][Iteration 2134][Wall Clock 260.048065543s] Trained 64 records in 0.136659247 seconds. Throughput is 468.31808 records/second. Loss is 0.3687418. Sequential2290a28's hyper parameters: Current learning rate is 0.014019346698443852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:02 INFO  DistriOptimizer$:408 - [Epoch 3 16576/60000][Iteration 2135][Wall Clock 260.144905769s] Trained 64 records in 0.096840226 seconds. Throughput is 660.8824 records/second. Loss is 0.22016093. Sequential2290a28's hyper parameters: Current learning rate is 0.014017381553125876. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 2136][Wall Clock 260.253531219s] Trained 64 records in 0.10862545 seconds. Throughput is 589.18054 records/second. Loss is 0.1786953. Sequential2290a28's hyper parameters: Current learning rate is 0.01401541695865452. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 16704/60000][Iteration 2137][Wall Clock 260.3689209s] Trained 64 records in 0.115389681 seconds. Throughput is 554.64233 records/second. Loss is 0.17535734. Sequential2290a28's hyper parameters: Current learning rate is 0.014013452914798207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 16768/60000][Iteration 2138][Wall Clock 260.53033118s] Trained 64 records in 0.16141028 seconds. Throughput is 396.5051 records/second. Loss is 0.13914728. Sequential2290a28's hyper parameters: Current learning rate is 0.014011489421325487. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 16832/60000][Iteration 2139][Wall Clock 260.727775656s] Trained 64 records in 0.197444476 seconds. Throughput is 324.14178 records/second. Loss is 0.1741743. Sequential2290a28's hyper parameters: Current learning rate is 0.014009526478005043. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 2140][Wall Clock 260.862880918s] Trained 64 records in 0.135105262 seconds. Throughput is 473.7047 records/second. Loss is 0.26173526. Sequential2290a28's hyper parameters: Current learning rate is 0.014007564084605687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 16960/60000][Iteration 2141][Wall Clock 260.997735957s] Trained 64 records in 0.134855039 seconds. Throughput is 474.5837 records/second. Loss is 0.19704139. Sequential2290a28's hyper parameters: Current learning rate is 0.014005602240896359. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:03 INFO  DistriOptimizer$:408 - [Epoch 3 17024/60000][Iteration 2142][Wall Clock 261.104396053s] Trained 64 records in 0.106660096 seconds. Throughput is 600.0369 records/second. Loss is 0.3204431. Sequential2290a28's hyper parameters: Current learning rate is 0.014003640946646129. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17088/60000][Iteration 2143][Wall Clock 261.345986788s] Trained 64 records in 0.241590735 seconds. Throughput is 264.91083 records/second. Loss is 0.3110205. Sequential2290a28's hyper parameters: Current learning rate is 0.014001680201624195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 2144][Wall Clock 261.47654987s] Trained 64 records in 0.130563082 seconds. Throughput is 490.1845 records/second. Loss is 0.29925403. Sequential2290a28's hyper parameters: Current learning rate is 0.013999720005599887. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17216/60000][Iteration 2145][Wall Clock 261.649078396s] Trained 64 records in 0.172528526 seconds. Throughput is 370.95316 records/second. Loss is 0.22377494. Sequential2290a28's hyper parameters: Current learning rate is 0.013997760358342664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17280/60000][Iteration 2146][Wall Clock 261.783031309s] Trained 64 records in 0.133952913 seconds. Throughput is 477.77982 records/second. Loss is 0.17047524. Sequential2290a28's hyper parameters: Current learning rate is 0.013995801259622112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17344/60000][Iteration 2147][Wall Clock 261.876430632s] Trained 64 records in 0.093399323 seconds. Throughput is 685.2298 records/second. Loss is 0.121721625. Sequential2290a28's hyper parameters: Current learning rate is 0.013993842709207949. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 2148][Wall Clock 261.98629646s] Trained 64 records in 0.109865828 seconds. Throughput is 582.5287 records/second. Loss is 0.23773897. Sequential2290a28's hyper parameters: Current learning rate is 0.013991884706870015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:04 INFO  DistriOptimizer$:408 - [Epoch 3 17472/60000][Iteration 2149][Wall Clock 262.067542801s] Trained 64 records in 0.081246341 seconds. Throughput is 787.7278 records/second. Loss is 0.15367495. Sequential2290a28's hyper parameters: Current learning rate is 0.013989927252378288. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17536/60000][Iteration 2150][Wall Clock 262.209489426s] Trained 64 records in 0.141946625 seconds. Throughput is 450.8737 records/second. Loss is 0.12740648. Sequential2290a28's hyper parameters: Current learning rate is 0.013987970345502868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17600/60000][Iteration 2151][Wall Clock 262.365231027s] Trained 64 records in 0.155741601 seconds. Throughput is 410.93707 records/second. Loss is 0.18727897. Sequential2290a28's hyper parameters: Current learning rate is 0.013986013986013988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 2152][Wall Clock 262.544539868s] Trained 64 records in 0.179308841 seconds. Throughput is 356.92606 records/second. Loss is 0.31740373. Sequential2290a28's hyper parameters: Current learning rate is 0.013984058173682002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17728/60000][Iteration 2153][Wall Clock 262.68561572s] Trained 64 records in 0.141075852 seconds. Throughput is 453.65668 records/second. Loss is 0.28129184. Sequential2290a28's hyper parameters: Current learning rate is 0.013982102908277404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17792/60000][Iteration 2154][Wall Clock 262.806938751s] Trained 64 records in 0.121323031 seconds. Throughput is 527.51733 records/second. Loss is 0.15852626. Sequential2290a28's hyper parameters: Current learning rate is 0.013980148189570808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17856/60000][Iteration 2155][Wall Clock 262.902600325s] Trained 64 records in 0.095661574 seconds. Throughput is 669.02515 records/second. Loss is 0.25223663. Sequential2290a28's hyper parameters: Current learning rate is 0.01397819401733296. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 2156][Wall Clock 262.984150448s] Trained 64 records in 0.081550123 seconds. Throughput is 784.79346 records/second. Loss is 0.11078917. Sequential2290a28's hyper parameters: Current learning rate is 0.013976240391334731. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:05 INFO  DistriOptimizer$:408 - [Epoch 3 17984/60000][Iteration 2157][Wall Clock 263.100395221s] Trained 64 records in 0.116244773 seconds. Throughput is 550.5624 records/second. Loss is 0.15417568. Sequential2290a28's hyper parameters: Current learning rate is 0.013974287311347122. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18048/60000][Iteration 2158][Wall Clock 263.268332404s] Trained 64 records in 0.167937183 seconds. Throughput is 381.09485 records/second. Loss is 0.21534863. Sequential2290a28's hyper parameters: Current learning rate is 0.01397233477714126. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18112/60000][Iteration 2159][Wall Clock 263.389074005s] Trained 64 records in 0.120741601 seconds. Throughput is 530.05756 records/second. Loss is 0.13552019. Sequential2290a28's hyper parameters: Current learning rate is 0.013970382788488405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 2160][Wall Clock 263.517478394s] Trained 64 records in 0.128404389 seconds. Throughput is 498.42532 records/second. Loss is 0.20022407. Sequential2290a28's hyper parameters: Current learning rate is 0.013968431345159939. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18240/60000][Iteration 2161][Wall Clock 263.68953658s] Trained 64 records in 0.172058186 seconds. Throughput is 371.9672 records/second. Loss is 0.25080508. Sequential2290a28's hyper parameters: Current learning rate is 0.013966480446927375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18304/60000][Iteration 2162][Wall Clock 263.835861518s] Trained 64 records in 0.146324938 seconds. Throughput is 437.38275 records/second. Loss is 0.14921626. Sequential2290a28's hyper parameters: Current learning rate is 0.013964530093562353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18368/60000][Iteration 2163][Wall Clock 263.973174451s] Trained 64 records in 0.137312933 seconds. Throughput is 466.08865 records/second. Loss is 0.164956. Sequential2290a28's hyper parameters: Current learning rate is 0.013962580284836639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:06 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 2164][Wall Clock 264.142291395s] Trained 64 records in 0.169116944 seconds. Throughput is 378.43637 records/second. Loss is 0.23103136. Sequential2290a28's hyper parameters: Current learning rate is 0.013960631020522127. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18496/60000][Iteration 2165][Wall Clock 264.259820883s] Trained 64 records in 0.117529488 seconds. Throughput is 544.5442 records/second. Loss is 0.15142941. Sequential2290a28's hyper parameters: Current learning rate is 0.013958682300390842. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18560/60000][Iteration 2166][Wall Clock 264.372947017s] Trained 64 records in 0.113126134 seconds. Throughput is 565.7402 records/second. Loss is 0.365592. Sequential2290a28's hyper parameters: Current learning rate is 0.013956734124214934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18624/60000][Iteration 2167][Wall Clock 264.481319992s] Trained 64 records in 0.108372975 seconds. Throughput is 590.55316 records/second. Loss is 0.13756403. Sequential2290a28's hyper parameters: Current learning rate is 0.013954786491766676. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 2168][Wall Clock 264.586797258s] Trained 64 records in 0.105477266 seconds. Throughput is 606.7658 records/second. Loss is 0.20938079. Sequential2290a28's hyper parameters: Current learning rate is 0.013952839402818475. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18752/60000][Iteration 2169][Wall Clock 264.695866543s] Trained 64 records in 0.109069285 seconds. Throughput is 586.78296 records/second. Loss is 0.1345301. Sequential2290a28's hyper parameters: Current learning rate is 0.013950892857142858. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18816/60000][Iteration 2170][Wall Clock 264.826612012s] Trained 64 records in 0.130745469 seconds. Throughput is 489.5007 records/second. Loss is 0.26386407. Sequential2290a28's hyper parameters: Current learning rate is 0.013948946854512485. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18880/60000][Iteration 2171][Wall Clock 264.943844228s] Trained 64 records in 0.117232216 seconds. Throughput is 545.925 records/second. Loss is 0.14133394. Sequential2290a28's hyper parameters: Current learning rate is 0.013947001394700141. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:07 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 2172][Wall Clock 265.076210275s] Trained 64 records in 0.132366047 seconds. Throughput is 483.5077 records/second. Loss is 0.31496608. Sequential2290a28's hyper parameters: Current learning rate is 0.013945056477478733. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19008/60000][Iteration 2173][Wall Clock 265.304303651s] Trained 64 records in 0.228093376 seconds. Throughput is 280.58685 records/second. Loss is 0.17617615. Sequential2290a28's hyper parameters: Current learning rate is 0.013943112102621304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19072/60000][Iteration 2174][Wall Clock 265.460415417s] Trained 64 records in 0.156111766 seconds. Throughput is 409.9627 records/second. Loss is 0.109139435. Sequential2290a28's hyper parameters: Current learning rate is 0.013941168269901017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19136/60000][Iteration 2175][Wall Clock 265.630303188s] Trained 64 records in 0.169887771 seconds. Throughput is 376.7193 records/second. Loss is 0.36319578. Sequential2290a28's hyper parameters: Current learning rate is 0.013939224979091162. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 2176][Wall Clock 265.771752946s] Trained 64 records in 0.141449758 seconds. Throughput is 452.45746 records/second. Loss is 0.16689384. Sequential2290a28's hyper parameters: Current learning rate is 0.013937282229965157. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19264/60000][Iteration 2177][Wall Clock 265.933221281s] Trained 64 records in 0.161468335 seconds. Throughput is 396.36252 records/second. Loss is 0.18843257. Sequential2290a28's hyper parameters: Current learning rate is 0.013935340022296544. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19328/60000][Iteration 2178][Wall Clock 266.052354584s] Trained 64 records in 0.119133303 seconds. Throughput is 537.2134 records/second. Loss is 0.25403354. Sequential2290a28's hyper parameters: Current learning rate is 0.013933398355858995. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:08 INFO  DistriOptimizer$:408 - [Epoch 3 19392/60000][Iteration 2179][Wall Clock 266.162286703s] Trained 64 records in 0.109932119 seconds. Throughput is 582.1774 records/second. Loss is 0.18192762. Sequential2290a28's hyper parameters: Current learning rate is 0.013931457230426303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 2180][Wall Clock 266.300926539s] Trained 64 records in 0.138639836 seconds. Throughput is 461.62778 records/second. Loss is 0.17036358. Sequential2290a28's hyper parameters: Current learning rate is 0.013929516645772392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19520/60000][Iteration 2181][Wall Clock 266.428754228s] Trained 64 records in 0.127827689 seconds. Throughput is 500.674 records/second. Loss is 0.112198144. Sequential2290a28's hyper parameters: Current learning rate is 0.01392757660167131. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19584/60000][Iteration 2182][Wall Clock 266.515938743s] Trained 64 records in 0.087184515 seconds. Throughput is 734.07526 records/second. Loss is 0.20127256. Sequential2290a28's hyper parameters: Current learning rate is 0.01392563709789723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19648/60000][Iteration 2183][Wall Clock 266.647730779s] Trained 64 records in 0.131792036 seconds. Throughput is 485.61356 records/second. Loss is 0.16071007. Sequential2290a28's hyper parameters: Current learning rate is 0.013923698134224451. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 2184][Wall Clock 266.759578316s] Trained 64 records in 0.111847537 seconds. Throughput is 572.2075 records/second. Loss is 0.29837126. Sequential2290a28's hyper parameters: Current learning rate is 0.013921759710427398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19776/60000][Iteration 2185][Wall Clock 267.02466499s] Trained 64 records in 0.265086674 seconds. Throughput is 241.43047 records/second. Loss is 0.13953686. Sequential2290a28's hyper parameters: Current learning rate is 0.013919821826280623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:09 INFO  DistriOptimizer$:408 - [Epoch 3 19840/60000][Iteration 2186][Wall Clock 267.122834779s] Trained 64 records in 0.098169789 seconds. Throughput is 651.9317 records/second. Loss is 0.31438112. Sequential2290a28's hyper parameters: Current learning rate is 0.013917884481558803. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 19904/60000][Iteration 2187][Wall Clock 267.272609085s] Trained 64 records in 0.149774306 seconds. Throughput is 427.3096 records/second. Loss is 0.13820867. Sequential2290a28's hyper parameters: Current learning rate is 0.013915947676036738. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 2188][Wall Clock 267.382988872s] Trained 64 records in 0.110379787 seconds. Throughput is 579.8163 records/second. Loss is 0.1518226. Sequential2290a28's hyper parameters: Current learning rate is 0.013914011409489356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 20032/60000][Iteration 2189][Wall Clock 267.490386279s] Trained 64 records in 0.107397407 seconds. Throughput is 595.91754 records/second. Loss is 0.0656439. Sequential2290a28's hyper parameters: Current learning rate is 0.01391207568169171. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 20096/60000][Iteration 2190][Wall Clock 267.639237095s] Trained 64 records in 0.148850816 seconds. Throughput is 429.9607 records/second. Loss is 0.18029833. Sequential2290a28's hyper parameters: Current learning rate is 0.013910140492418973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 20160/60000][Iteration 2191][Wall Clock 267.82351767s] Trained 64 records in 0.184280575 seconds. Throughput is 347.2965 records/second. Loss is 0.17507952. Sequential2290a28's hyper parameters: Current learning rate is 0.013908205841446454. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 2192][Wall Clock 267.921124913s] Trained 64 records in 0.097607243 seconds. Throughput is 655.6891 records/second. Loss is 0.22747612. Sequential2290a28's hyper parameters: Current learning rate is 0.013906271728549574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:10 INFO  DistriOptimizer$:408 - [Epoch 3 20288/60000][Iteration 2193][Wall Clock 268.070729522s] Trained 64 records in 0.149604609 seconds. Throughput is 427.7943 records/second. Loss is 0.09197063. Sequential2290a28's hyper parameters: Current learning rate is 0.013904338153503892. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20352/60000][Iteration 2194][Wall Clock 268.217244802s] Trained 64 records in 0.14651528 seconds. Throughput is 436.8145 records/second. Loss is 0.29212838. Sequential2290a28's hyper parameters: Current learning rate is 0.013902405116085082. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20416/60000][Iteration 2195][Wall Clock 268.343583181s] Trained 64 records in 0.126338379 seconds. Throughput is 506.57608 records/second. Loss is 0.23866506. Sequential2290a28's hyper parameters: Current learning rate is 0.013900472616068946. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 2196][Wall Clock 268.484143688s] Trained 64 records in 0.140560507 seconds. Throughput is 455.31992 records/second. Loss is 0.15578064. Sequential2290a28's hyper parameters: Current learning rate is 0.01389854065323141. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20544/60000][Iteration 2197][Wall Clock 268.629430007s] Trained 64 records in 0.145286319 seconds. Throughput is 440.50946 records/second. Loss is 0.1501302. Sequential2290a28's hyper parameters: Current learning rate is 0.013896609227348526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20608/60000][Iteration 2198][Wall Clock 268.714457716s] Trained 64 records in 0.085027709 seconds. Throughput is 752.6958 records/second. Loss is 0.1950577. Sequential2290a28's hyper parameters: Current learning rate is 0.013894678338196471. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20672/60000][Iteration 2199][Wall Clock 268.835784852s] Trained 64 records in 0.121327136 seconds. Throughput is 527.49945 records/second. Loss is 0.34857264. Sequential2290a28's hyper parameters: Current learning rate is 0.013892747985551542. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 2200][Wall Clock 269.030816592s] Trained 64 records in 0.19503174 seconds. Throughput is 328.1517 records/second. Loss is 0.27641937. Sequential2290a28's hyper parameters: Current learning rate is 0.013890818169190166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:11 INFO  DistriOptimizer$:408 - [Epoch 3 20800/60000][Iteration 2201][Wall Clock 269.122312881s] Trained 64 records in 0.091496289 seconds. Throughput is 699.48193 records/second. Loss is 0.2006643. Sequential2290a28's hyper parameters: Current learning rate is 0.01388888888888889. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 20864/60000][Iteration 2202][Wall Clock 269.21452819s] Trained 64 records in 0.092215309 seconds. Throughput is 694.02795 records/second. Loss is 0.22291575. Sequential2290a28's hyper parameters: Current learning rate is 0.013886960144424386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 20928/60000][Iteration 2203][Wall Clock 269.306896468s] Trained 64 records in 0.092368278 seconds. Throughput is 692.8786 records/second. Loss is 0.3821448. Sequential2290a28's hyper parameters: Current learning rate is 0.013885031935573453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 2204][Wall Clock 269.3840216s] Trained 64 records in 0.077125132 seconds. Throughput is 829.8203 records/second. Loss is 0.179378. Sequential2290a28's hyper parameters: Current learning rate is 0.013883104262113007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 21056/60000][Iteration 2205][Wall Clock 269.486689703s] Trained 64 records in 0.102668103 seconds. Throughput is 623.36786 records/second. Loss is 0.22928293. Sequential2290a28's hyper parameters: Current learning rate is 0.0138811771238201. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 21120/60000][Iteration 2206][Wall Clock 269.605042315s] Trained 64 records in 0.118352612 seconds. Throughput is 540.75696 records/second. Loss is 0.081572935. Sequential2290a28's hyper parameters: Current learning rate is 0.013879250520471894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 21184/60000][Iteration 2207][Wall Clock 269.69758915s] Trained 64 records in 0.092546835 seconds. Throughput is 691.54175 records/second. Loss is 0.27526233. Sequential2290a28's hyper parameters: Current learning rate is 0.013877324451845684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 2208][Wall Clock 269.80564644s] Trained 64 records in 0.10805729 seconds. Throughput is 592.2784 records/second. Loss is 0.19903493. Sequential2290a28's hyper parameters: Current learning rate is 0.013875398917718884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 21312/60000][Iteration 2209][Wall Clock 269.94921836s] Trained 64 records in 0.14357192 seconds. Throughput is 445.76965 records/second. Loss is 0.20590205. Sequential2290a28's hyper parameters: Current learning rate is 0.013873473917869035. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:12 INFO  DistriOptimizer$:408 - [Epoch 3 21376/60000][Iteration 2210][Wall Clock 270.082981516s] Trained 64 records in 0.133763156 seconds. Throughput is 478.45764 records/second. Loss is 0.13874215. Sequential2290a28's hyper parameters: Current learning rate is 0.013871549452073797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21440/60000][Iteration 2211][Wall Clock 270.227681762s] Trained 64 records in 0.144700246 seconds. Throughput is 442.29367 records/second. Loss is 0.14572915. Sequential2290a28's hyper parameters: Current learning rate is 0.013869625520110958. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 2212][Wall Clock 270.388844645s] Trained 64 records in 0.161162883 seconds. Throughput is 397.11377 records/second. Loss is 0.31551006. Sequential2290a28's hyper parameters: Current learning rate is 0.013867702121758424. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21568/60000][Iteration 2213][Wall Clock 270.482365605s] Trained 64 records in 0.09352096 seconds. Throughput is 684.33856 records/second. Loss is 0.17057534. Sequential2290a28's hyper parameters: Current learning rate is 0.013865779256794232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21632/60000][Iteration 2214][Wall Clock 270.567624247s] Trained 64 records in 0.085258642 seconds. Throughput is 750.65704 records/second. Loss is 0.1517775. Sequential2290a28's hyper parameters: Current learning rate is 0.013863856924996533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21696/60000][Iteration 2215][Wall Clock 270.649638332s] Trained 64 records in 0.082014085 seconds. Throughput is 780.35376 records/second. Loss is 0.2590593. Sequential2290a28's hyper parameters: Current learning rate is 0.013861935126143608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 2216][Wall Clock 270.81525157s] Trained 64 records in 0.165613238 seconds. Throughput is 386.44254 records/second. Loss is 0.26931185. Sequential2290a28's hyper parameters: Current learning rate is 0.01386001386001386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:13 INFO  DistriOptimizer$:408 - [Epoch 3 21824/60000][Iteration 2217][Wall Clock 270.970040855s] Trained 64 records in 0.154789285 seconds. Throughput is 413.4653 records/second. Loss is 0.14183089. Sequential2290a28's hyper parameters: Current learning rate is 0.01385809312638581. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 21888/60000][Iteration 2218][Wall Clock 271.15822113s] Trained 64 records in 0.188180275 seconds. Throughput is 340.09943 records/second. Loss is 0.19615173. Sequential2290a28's hyper parameters: Current learning rate is 0.013856172925038105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 21952/60000][Iteration 2219][Wall Clock 271.270793756s] Trained 64 records in 0.112572626 seconds. Throughput is 568.52185 records/second. Loss is 0.118630655. Sequential2290a28's hyper parameters: Current learning rate is 0.013854253255749516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 2220][Wall Clock 271.386619519s] Trained 64 records in 0.115825763 seconds. Throughput is 552.5541 records/second. Loss is 0.15278816. Sequential2290a28's hyper parameters: Current learning rate is 0.013852334118298934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22080/60000][Iteration 2221][Wall Clock 271.49135149s] Trained 64 records in 0.104731971 seconds. Throughput is 611.0837 records/second. Loss is 0.10748859. Sequential2290a28's hyper parameters: Current learning rate is 0.013850415512465375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22144/60000][Iteration 2222][Wall Clock 271.605868867s] Trained 64 records in 0.114517377 seconds. Throughput is 558.8671 records/second. Loss is 0.16491428. Sequential2290a28's hyper parameters: Current learning rate is 0.013848497438027975. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22208/60000][Iteration 2223][Wall Clock 271.730889325s] Trained 64 records in 0.125020458 seconds. Throughput is 511.9162 records/second. Loss is 0.18806225. Sequential2290a28's hyper parameters: Current learning rate is 0.013846579894765993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 2224][Wall Clock 271.838119489s] Trained 64 records in 0.107230164 seconds. Throughput is 596.847 records/second. Loss is 0.21081665. Sequential2290a28's hyper parameters: Current learning rate is 0.013844662882458813. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22336/60000][Iteration 2225][Wall Clock 271.958762367s] Trained 64 records in 0.120642878 seconds. Throughput is 530.49133 records/second. Loss is 0.23409855. Sequential2290a28's hyper parameters: Current learning rate is 0.013842746400885935. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:14 INFO  DistriOptimizer$:408 - [Epoch 3 22400/60000][Iteration 2226][Wall Clock 272.109736073s] Trained 64 records in 0.150973706 seconds. Throughput is 423.9149 records/second. Loss is 0.17593. Sequential2290a28's hyper parameters: Current learning rate is 0.01384083044982699. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:15 INFO  DistriOptimizer$:408 - [Epoch 3 22464/60000][Iteration 2227][Wall Clock 272.315197661s] Trained 64 records in 0.205461588 seconds. Throughput is 311.49374 records/second. Loss is 0.21634051. Sequential2290a28's hyper parameters: Current learning rate is 0.013838915029061722. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:15 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 2228][Wall Clock 272.453832342s] Trained 64 records in 0.138634681 seconds. Throughput is 461.64496 records/second. Loss is 0.12658957. Sequential2290a28's hyper parameters: Current learning rate is 0.013837000138370002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:15 INFO  DistriOptimizer$:408 - [Epoch 3 22592/60000][Iteration 2229][Wall Clock 272.597454856s] Trained 64 records in 0.143622514 seconds. Throughput is 445.61258 records/second. Loss is 0.09939889. Sequential2290a28's hyper parameters: Current learning rate is 0.01383508577753182. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:15 INFO  DistriOptimizer$:408 - [Epoch 3 22656/60000][Iteration 2230][Wall Clock 272.731626127s] Trained 64 records in 0.134171271 seconds. Throughput is 477.00223 records/second. Loss is 0.3040267. Sequential2290a28's hyper parameters: Current learning rate is 0.013833171946327293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:15 INFO  DistriOptimizer$:408 - [Epoch 3 22720/60000][Iteration 2231][Wall Clock 272.930346483s] Trained 64 records in 0.198720356 seconds. Throughput is 322.0606 records/second. Loss is 0.1894367. Sequential2290a28's hyper parameters: Current learning rate is 0.013831258644536654. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:15 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 2232][Wall Clock 273.077826044s] Trained 64 records in 0.147479561 seconds. Throughput is 433.95844 records/second. Loss is 0.28734344. Sequential2290a28's hyper parameters: Current learning rate is 0.013829345871940256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 22848/60000][Iteration 2233][Wall Clock 273.280053109s] Trained 64 records in 0.202227065 seconds. Throughput is 316.47592 records/second. Loss is 0.29521686. Sequential2290a28's hyper parameters: Current learning rate is 0.013827433628318583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 22912/60000][Iteration 2234][Wall Clock 273.428395288s] Trained 64 records in 0.148342179 seconds. Throughput is 431.43494 records/second. Loss is 0.21820986. Sequential2290a28's hyper parameters: Current learning rate is 0.013825521913452233. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 22976/60000][Iteration 2235][Wall Clock 273.605092837s] Trained 64 records in 0.176697549 seconds. Throughput is 362.20084 records/second. Loss is 0.10169074. Sequential2290a28's hyper parameters: Current learning rate is 0.013823610727121923. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 2236][Wall Clock 273.730292191s] Trained 64 records in 0.125199354 seconds. Throughput is 511.18478 records/second. Loss is 0.26761204. Sequential2290a28's hyper parameters: Current learning rate is 0.0138217000691085. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 23104/60000][Iteration 2237][Wall Clock 273.848150338s] Trained 64 records in 0.117858147 seconds. Throughput is 543.0257 records/second. Loss is 0.24264696. Sequential2290a28's hyper parameters: Current learning rate is 0.013819789939192924. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 23168/60000][Iteration 2238][Wall Clock 273.934704725s] Trained 64 records in 0.086554387 seconds. Throughput is 739.4195 records/second. Loss is 0.31434023. Sequential2290a28's hyper parameters: Current learning rate is 0.01381788033715628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:16 INFO  DistriOptimizer$:408 - [Epoch 3 23232/60000][Iteration 2239][Wall Clock 274.039119267s] Trained 64 records in 0.104414542 seconds. Throughput is 612.9414 records/second. Loss is 0.1520586. Sequential2290a28's hyper parameters: Current learning rate is 0.013815971262779773. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 2240][Wall Clock 274.176167089s] Trained 64 records in 0.137047822 seconds. Throughput is 466.99026 records/second. Loss is 0.34651148. Sequential2290a28's hyper parameters: Current learning rate is 0.013814062715844731. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23360/60000][Iteration 2241][Wall Clock 274.314931932s] Trained 64 records in 0.138764843 seconds. Throughput is 461.2119 records/second. Loss is 0.19877982. Sequential2290a28's hyper parameters: Current learning rate is 0.013812154696132598. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23424/60000][Iteration 2242][Wall Clock 274.453211847s] Trained 64 records in 0.138279915 seconds. Throughput is 462.8293 records/second. Loss is 0.26184636. Sequential2290a28's hyper parameters: Current learning rate is 0.013810247203424943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23488/60000][Iteration 2243][Wall Clock 274.597587537s] Trained 64 records in 0.14437569 seconds. Throughput is 443.2879 records/second. Loss is 0.30091524. Sequential2290a28's hyper parameters: Current learning rate is 0.013808340237503453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 2244][Wall Clock 274.70151074s] Trained 64 records in 0.103923203 seconds. Throughput is 615.83936 records/second. Loss is 0.3953509. Sequential2290a28's hyper parameters: Current learning rate is 0.013806433798149938. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23616/60000][Iteration 2245][Wall Clock 274.819051269s] Trained 64 records in 0.117540529 seconds. Throughput is 544.49304 records/second. Loss is 0.13125952. Sequential2290a28's hyper parameters: Current learning rate is 0.013804527885146328. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23680/60000][Iteration 2246][Wall Clock 274.947489447s] Trained 64 records in 0.128438178 seconds. Throughput is 498.29422 records/second. Loss is 0.14117654. Sequential2290a28's hyper parameters: Current learning rate is 0.013802622498274672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:17 INFO  DistriOptimizer$:408 - [Epoch 3 23744/60000][Iteration 2247][Wall Clock 275.073886445s] Trained 64 records in 0.126396998 seconds. Throughput is 506.34113 records/second. Loss is 0.15071893. Sequential2290a28's hyper parameters: Current learning rate is 0.01380071763731714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:18 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 2248][Wall Clock 275.283402171s] Trained 64 records in 0.209515726 seconds. Throughput is 305.46634 records/second. Loss is 0.16145968. Sequential2290a28's hyper parameters: Current learning rate is 0.013798813302056023. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:18 INFO  DistriOptimizer$:408 - [Epoch 3 23872/60000][Iteration 2249][Wall Clock 275.496392154s] Trained 64 records in 0.212989983 seconds. Throughput is 300.4836 records/second. Loss is 0.22211578. Sequential2290a28's hyper parameters: Current learning rate is 0.013796909492273732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:18 INFO  DistriOptimizer$:408 - [Epoch 3 23936/60000][Iteration 2250][Wall Clock 275.614835524s] Trained 64 records in 0.11844337 seconds. Throughput is 540.3426 records/second. Loss is 0.13755964. Sequential2290a28's hyper parameters: Current learning rate is 0.013795006207752794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:18 INFO  DistriOptimizer$:408 - [Epoch 3 24000/60000][Iteration 2251][Wall Clock 275.759607166s] Trained 64 records in 0.144771642 seconds. Throughput is 442.07556 records/second. Loss is 0.16637576. Sequential2290a28's hyper parameters: Current learning rate is 0.013793103448275864. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:18 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 2252][Wall Clock 275.879337298s] Trained 64 records in 0.119730132 seconds. Throughput is 534.53546 records/second. Loss is 0.16445217. Sequential2290a28's hyper parameters: Current learning rate is 0.013791201213625705. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:18 INFO  DistriOptimizer$:408 - [Epoch 3 24128/60000][Iteration 2253][Wall Clock 276.070049295s] Trained 64 records in 0.190711997 seconds. Throughput is 335.58456 records/second. Loss is 0.35784054. Sequential2290a28's hyper parameters: Current learning rate is 0.013789299503585217. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24192/60000][Iteration 2254][Wall Clock 276.184468363s] Trained 64 records in 0.114419068 seconds. Throughput is 559.34735 records/second. Loss is 0.20219474. Sequential2290a28's hyper parameters: Current learning rate is 0.013787398317937405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24256/60000][Iteration 2255][Wall Clock 276.344263693s] Trained 64 records in 0.15979533 seconds. Throughput is 400.51233 records/second. Loss is 0.21535748. Sequential2290a28's hyper parameters: Current learning rate is 0.013785497656465398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 2256][Wall Clock 276.479675417s] Trained 64 records in 0.135411724 seconds. Throughput is 472.63263 records/second. Loss is 0.28724116. Sequential2290a28's hyper parameters: Current learning rate is 0.013783597518952447. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24384/60000][Iteration 2257][Wall Clock 276.586755488s] Trained 64 records in 0.107080071 seconds. Throughput is 597.6836 records/second. Loss is 0.39215463. Sequential2290a28's hyper parameters: Current learning rate is 0.013781697905181918. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24448/60000][Iteration 2258][Wall Clock 276.719585834s] Trained 64 records in 0.132830346 seconds. Throughput is 481.8176 records/second. Loss is 0.28780562. Sequential2290a28's hyper parameters: Current learning rate is 0.013779798814937303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24512/60000][Iteration 2259][Wall Clock 276.828987s] Trained 64 records in 0.109401166 seconds. Throughput is 585.0029 records/second. Loss is 0.2709504. Sequential2290a28's hyper parameters: Current learning rate is 0.013777900248002205. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 2260][Wall Clock 276.950655775s] Trained 64 records in 0.121668775 seconds. Throughput is 526.01825 records/second. Loss is 0.20477575. Sequential2290a28's hyper parameters: Current learning rate is 0.013776002204160353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:19 INFO  DistriOptimizer$:408 - [Epoch 3 24640/60000][Iteration 2261][Wall Clock 277.063599906s] Trained 64 records in 0.112944131 seconds. Throughput is 566.65186 records/second. Loss is 0.17840403. Sequential2290a28's hyper parameters: Current learning rate is 0.013774104683195593. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 24704/60000][Iteration 2262][Wall Clock 277.177429504s] Trained 64 records in 0.113829598 seconds. Throughput is 562.2439 records/second. Loss is 0.17547168. Sequential2290a28's hyper parameters: Current learning rate is 0.01377220768489189. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 24768/60000][Iteration 2263][Wall Clock 277.258163633s] Trained 64 records in 0.080734129 seconds. Throughput is 792.72546 records/second. Loss is 0.21158916. Sequential2290a28's hyper parameters: Current learning rate is 0.013770311209033326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 2264][Wall Clock 277.370589196s] Trained 64 records in 0.112425563 seconds. Throughput is 569.26556 records/second. Loss is 0.29326755. Sequential2290a28's hyper parameters: Current learning rate is 0.013768415255404105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 24896/60000][Iteration 2265][Wall Clock 277.460888807s] Trained 64 records in 0.090299611 seconds. Throughput is 708.75165 records/second. Loss is 0.19251612. Sequential2290a28's hyper parameters: Current learning rate is 0.013766519823788546. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 24960/60000][Iteration 2266][Wall Clock 277.591521206s] Trained 64 records in 0.130632399 seconds. Throughput is 489.9244 records/second. Loss is 0.21069685. Sequential2290a28's hyper parameters: Current learning rate is 0.013764624913971095. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 25024/60000][Iteration 2267][Wall Clock 277.712873554s] Trained 64 records in 0.121352348 seconds. Throughput is 527.3899 records/second. Loss is 0.25537. Sequential2290a28's hyper parameters: Current learning rate is 0.013762730525736306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 2268][Wall Clock 277.843061402s] Trained 64 records in 0.130187848 seconds. Throughput is 491.59732 records/second. Loss is 0.23446722. Sequential2290a28's hyper parameters: Current learning rate is 0.013760836658868859. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 25152/60000][Iteration 2269][Wall Clock 277.975066814s] Trained 64 records in 0.132005412 seconds. Throughput is 484.8286 records/second. Loss is 0.26409203. Sequential2290a28's hyper parameters: Current learning rate is 0.013758943313153551. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:20 INFO  DistriOptimizer$:408 - [Epoch 3 25216/60000][Iteration 2270][Wall Clock 278.107222779s] Trained 64 records in 0.132155965 seconds. Throughput is 484.27628 records/second. Loss is 0.17523482. Sequential2290a28's hyper parameters: Current learning rate is 0.013757050488375293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25280/60000][Iteration 2271][Wall Clock 278.325472938s] Trained 64 records in 0.218250159 seconds. Throughput is 293.2415 records/second. Loss is 0.21843578. Sequential2290a28's hyper parameters: Current learning rate is 0.01375515818431912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 2272][Wall Clock 278.441375714s] Trained 64 records in 0.115902776 seconds. Throughput is 552.18695 records/second. Loss is 0.28953817. Sequential2290a28's hyper parameters: Current learning rate is 0.013753266400770181. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25408/60000][Iteration 2273][Wall Clock 278.530544235s] Trained 64 records in 0.089168521 seconds. Throughput is 717.7421 records/second. Loss is 0.22381419. Sequential2290a28's hyper parameters: Current learning rate is 0.01375137513751375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25472/60000][Iteration 2274][Wall Clock 278.646687203s] Trained 64 records in 0.116142968 seconds. Throughput is 551.045 records/second. Loss is 0.07797994. Sequential2290a28's hyper parameters: Current learning rate is 0.013749484394335211. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25536/60000][Iteration 2275][Wall Clock 278.758717419s] Trained 64 records in 0.112030216 seconds. Throughput is 571.2745 records/second. Loss is 0.2374955. Sequential2290a28's hyper parameters: Current learning rate is 0.013747594171020072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 2276][Wall Clock 278.900675131s] Trained 64 records in 0.141957712 seconds. Throughput is 450.83847 records/second. Loss is 0.33349574. Sequential2290a28's hyper parameters: Current learning rate is 0.013745704467353952. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:21 INFO  DistriOptimizer$:408 - [Epoch 3 25664/60000][Iteration 2277][Wall Clock 279.04582134s] Trained 64 records in 0.145146209 seconds. Throughput is 440.93472 records/second. Loss is 0.37506884. Sequential2290a28's hyper parameters: Current learning rate is 0.013743815283122594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:22 INFO  DistriOptimizer$:408 - [Epoch 3 25728/60000][Iteration 2278][Wall Clock 279.226087293s] Trained 64 records in 0.180265953 seconds. Throughput is 355.031 records/second. Loss is 0.22348765. Sequential2290a28's hyper parameters: Current learning rate is 0.01374192661811186. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:22 INFO  DistriOptimizer$:408 - [Epoch 3 25792/60000][Iteration 2279][Wall Clock 279.388337839s] Trained 64 records in 0.162250546 seconds. Throughput is 394.45166 records/second. Loss is 0.17130497. Sequential2290a28's hyper parameters: Current learning rate is 0.013740038472107722. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:22 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 2280][Wall Clock 279.532436643s] Trained 64 records in 0.144098804 seconds. Throughput is 444.1397 records/second. Loss is 0.27075747. Sequential2290a28's hyper parameters: Current learning rate is 0.013738150844896277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:22 INFO  DistriOptimizer$:408 - [Epoch 3 25920/60000][Iteration 2281][Wall Clock 279.631999969s] Trained 64 records in 0.099563326 seconds. Throughput is 642.807 records/second. Loss is 0.10199615. Sequential2290a28's hyper parameters: Current learning rate is 0.013736263736263738. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:22 INFO  DistriOptimizer$:408 - [Epoch 3 25984/60000][Iteration 2282][Wall Clock 279.805215424s] Trained 64 records in 0.173215455 seconds. Throughput is 369.48206 records/second. Loss is 0.13421875. Sequential2290a28's hyper parameters: Current learning rate is 0.01373437714599643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:22 INFO  DistriOptimizer$:408 - [Epoch 3 26048/60000][Iteration 2283][Wall Clock 279.93723013s] Trained 64 records in 0.132014706 seconds. Throughput is 484.79446 records/second. Loss is 0.14804955. Sequential2290a28's hyper parameters: Current learning rate is 0.013732491073880804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 2284][Wall Clock 280.129703885s] Trained 64 records in 0.192473755 seconds. Throughput is 332.51288 records/second. Loss is 0.18763673. Sequential2290a28's hyper parameters: Current learning rate is 0.01373060551970342. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26176/60000][Iteration 2285][Wall Clock 280.318556166s] Trained 64 records in 0.188852281 seconds. Throughput is 338.88922 records/second. Loss is 0.1772567. Sequential2290a28's hyper parameters: Current learning rate is 0.01372872048325096. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26240/60000][Iteration 2286][Wall Clock 280.423200202s] Trained 64 records in 0.104644036 seconds. Throughput is 611.59717 records/second. Loss is 0.13364518. Sequential2290a28's hyper parameters: Current learning rate is 0.013726835964310227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26304/60000][Iteration 2287][Wall Clock 280.522396551s] Trained 64 records in 0.099196349 seconds. Throughput is 645.185 records/second. Loss is 0.113685526. Sequential2290a28's hyper parameters: Current learning rate is 0.01372495196266813. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 2288][Wall Clock 280.689237041s] Trained 64 records in 0.16684049 seconds. Throughput is 383.5999 records/second. Loss is 0.1890223. Sequential2290a28's hyper parameters: Current learning rate is 0.013723068478111706. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26432/60000][Iteration 2289][Wall Clock 280.815821788s] Trained 64 records in 0.126584747 seconds. Throughput is 505.59012 records/second. Loss is 0.13615012. Sequential2290a28's hyper parameters: Current learning rate is 0.013721185510428101. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26496/60000][Iteration 2290][Wall Clock 280.94279003s] Trained 64 records in 0.126968242 seconds. Throughput is 504.06308 records/second. Loss is 0.44959694. Sequential2290a28's hyper parameters: Current learning rate is 0.013719303059404582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:23 INFO  DistriOptimizer$:408 - [Epoch 3 26560/60000][Iteration 2291][Wall Clock 281.064205556s] Trained 64 records in 0.121415526 seconds. Throughput is 527.1155 records/second. Loss is 0.11250813. Sequential2290a28's hyper parameters: Current learning rate is 0.013717421124828533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 2292][Wall Clock 281.171427208s] Trained 64 records in 0.107221652 seconds. Throughput is 596.89435 records/second. Loss is 0.17064361. Sequential2290a28's hyper parameters: Current learning rate is 0.01371553970648745. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 26688/60000][Iteration 2293][Wall Clock 281.30462789s] Trained 64 records in 0.133200682 seconds. Throughput is 480.47806 records/second. Loss is 0.1353102. Sequential2290a28's hyper parameters: Current learning rate is 0.013713658804168952. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 26752/60000][Iteration 2294][Wall Clock 281.405797035s] Trained 64 records in 0.101169145 seconds. Throughput is 632.60394 records/second. Loss is 0.19849558. Sequential2290a28's hyper parameters: Current learning rate is 0.01371177841766077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 26816/60000][Iteration 2295][Wall Clock 281.509521958s] Trained 64 records in 0.103724923 seconds. Throughput is 617.0166 records/second. Loss is 0.08909166. Sequential2290a28's hyper parameters: Current learning rate is 0.013709898546750754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 2296][Wall Clock 281.696647633s] Trained 64 records in 0.187125675 seconds. Throughput is 342.01614 records/second. Loss is 0.1422457. Sequential2290a28's hyper parameters: Current learning rate is 0.013708019191226868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 26944/60000][Iteration 2297][Wall Clock 281.827670282s] Trained 64 records in 0.131022649 seconds. Throughput is 488.46518 records/second. Loss is 0.22712305. Sequential2290a28's hyper parameters: Current learning rate is 0.013706140350877192. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 27008/60000][Iteration 2298][Wall Clock 281.957969366s] Trained 64 records in 0.130299084 seconds. Throughput is 491.17764 records/second. Loss is 0.15363088. Sequential2290a28's hyper parameters: Current learning rate is 0.013704262025489928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:24 INFO  DistriOptimizer$:408 - [Epoch 3 27072/60000][Iteration 2299][Wall Clock 282.079798514s] Trained 64 records in 0.121829148 seconds. Throughput is 525.32587 records/second. Loss is 0.16060615. Sequential2290a28's hyper parameters: Current learning rate is 0.013702384214853385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:25 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 2300][Wall Clock 282.202998673s] Trained 64 records in 0.123200159 seconds. Throughput is 519.47986 records/second. Loss is 0.29251474. Sequential2290a28's hyper parameters: Current learning rate is 0.013700506918755994. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:25 INFO  DistriOptimizer$:408 - [Epoch 3 27200/60000][Iteration 2301][Wall Clock 282.355906011s] Trained 64 records in 0.152907338 seconds. Throughput is 418.55414 records/second. Loss is 0.30371243. Sequential2290a28's hyper parameters: Current learning rate is 0.013698630136986302. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:25 INFO  DistriOptimizer$:408 - [Epoch 3 27264/60000][Iteration 2302][Wall Clock 282.486506397s] Trained 64 records in 0.130600386 seconds. Throughput is 490.04446 records/second. Loss is 0.18457407. Sequential2290a28's hyper parameters: Current learning rate is 0.01369675386933297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:25 INFO  DistriOptimizer$:408 - [Epoch 3 27328/60000][Iteration 2303][Wall Clock 282.662261343s] Trained 64 records in 0.175754946 seconds. Throughput is 364.14337 records/second. Loss is 0.2877728. Sequential2290a28's hyper parameters: Current learning rate is 0.013694878115584772. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:25 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 2304][Wall Clock 282.85720421s] Trained 64 records in 0.194942867 seconds. Throughput is 328.30133 records/second. Loss is 0.18606094. Sequential2290a28's hyper parameters: Current learning rate is 0.013693002875530606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:25 INFO  DistriOptimizer$:408 - [Epoch 3 27456/60000][Iteration 2305][Wall Clock 282.983676491s] Trained 64 records in 0.126472281 seconds. Throughput is 506.03973 records/second. Loss is 0.15130681. Sequential2290a28's hyper parameters: Current learning rate is 0.013691128148959474. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27520/60000][Iteration 2306][Wall Clock 283.095758519s] Trained 64 records in 0.112082028 seconds. Throughput is 571.0104 records/second. Loss is 0.1890156. Sequential2290a28's hyper parameters: Current learning rate is 0.013689253935660506. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27584/60000][Iteration 2307][Wall Clock 283.198787851s] Trained 64 records in 0.103029332 seconds. Throughput is 621.1823 records/second. Loss is 0.21302962. Sequential2290a28's hyper parameters: Current learning rate is 0.01368738023542294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 2308][Wall Clock 283.299345525s] Trained 64 records in 0.100557674 seconds. Throughput is 636.4507 records/second. Loss is 0.21189323. Sequential2290a28's hyper parameters: Current learning rate is 0.01368550704803613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27712/60000][Iteration 2309][Wall Clock 283.38539118s] Trained 64 records in 0.086045655 seconds. Throughput is 743.7912 records/second. Loss is 0.17131862. Sequential2290a28's hyper parameters: Current learning rate is 0.013683634373289545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27776/60000][Iteration 2310][Wall Clock 283.484268963s] Trained 64 records in 0.098877783 seconds. Throughput is 647.26373 records/second. Loss is 0.18745735. Sequential2290a28's hyper parameters: Current learning rate is 0.013681762210972774. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27840/60000][Iteration 2311][Wall Clock 283.577040904s] Trained 64 records in 0.092771941 seconds. Throughput is 689.8638 records/second. Loss is 0.24795142. Sequential2290a28's hyper parameters: Current learning rate is 0.013679890560875513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 2312][Wall Clock 283.673377213s] Trained 64 records in 0.096336309 seconds. Throughput is 664.3393 records/second. Loss is 0.27451155. Sequential2290a28's hyper parameters: Current learning rate is 0.01367801942278758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 27968/60000][Iteration 2313][Wall Clock 283.765569041s] Trained 64 records in 0.092191828 seconds. Throughput is 694.20465 records/second. Loss is 0.19484484. Sequential2290a28's hyper parameters: Current learning rate is 0.013676148796498904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 28032/60000][Iteration 2314][Wall Clock 283.865945056s] Trained 64 records in 0.100376015 seconds. Throughput is 637.6025 records/second. Loss is 0.20028913. Sequential2290a28's hyper parameters: Current learning rate is 0.013674278681799535. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 28096/60000][Iteration 2315][Wall Clock 283.972270273s] Trained 64 records in 0.106325217 seconds. Throughput is 601.9268 records/second. Loss is 0.1864242. Sequential2290a28's hyper parameters: Current learning rate is 0.013672409078479627. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:26 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 2316][Wall Clock 284.052945492s] Trained 64 records in 0.080675219 seconds. Throughput is 793.3043 records/second. Loss is 0.21033105. Sequential2290a28's hyper parameters: Current learning rate is 0.01367053998632946. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28224/60000][Iteration 2317][Wall Clock 284.176091986s] Trained 64 records in 0.123146494 seconds. Throughput is 519.70624 records/second. Loss is 0.24659982. Sequential2290a28's hyper parameters: Current learning rate is 0.01366867140513942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28288/60000][Iteration 2318][Wall Clock 284.380338554s] Trained 64 records in 0.204246568 seconds. Throughput is 313.34677 records/second. Loss is 0.19481353. Sequential2290a28's hyper parameters: Current learning rate is 0.013666803334700014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28352/60000][Iteration 2319][Wall Clock 284.573559348s] Trained 64 records in 0.193220794 seconds. Throughput is 331.2273 records/second. Loss is 0.20742226. Sequential2290a28's hyper parameters: Current learning rate is 0.01366493577480186. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 2320][Wall Clock 284.708598086s] Trained 64 records in 0.135038738 seconds. Throughput is 473.93808 records/second. Loss is 0.2557218. Sequential2290a28's hyper parameters: Current learning rate is 0.013663068725235688. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28480/60000][Iteration 2321][Wall Clock 284.786306305s] Trained 64 records in 0.077708219 seconds. Throughput is 823.5937 records/second. Loss is 0.17211363. Sequential2290a28's hyper parameters: Current learning rate is 0.013661202185792351. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28544/60000][Iteration 2322][Wall Clock 284.879452669s] Trained 64 records in 0.093146364 seconds. Throughput is 687.0907 records/second. Loss is 0.14296564. Sequential2290a28's hyper parameters: Current learning rate is 0.013659336156262806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:27 INFO  DistriOptimizer$:408 - [Epoch 3 28608/60000][Iteration 2323][Wall Clock 284.996953875s] Trained 64 records in 0.117501206 seconds. Throughput is 544.67523 records/second. Loss is 0.31531018. Sequential2290a28's hyper parameters: Current learning rate is 0.013657470636438133. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 2324][Wall Clock 285.107493945s] Trained 64 records in 0.11054007 seconds. Throughput is 578.9756 records/second. Loss is 0.13128832. Sequential2290a28's hyper parameters: Current learning rate is 0.01365560562610952. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 28736/60000][Iteration 2325][Wall Clock 285.25735927s] Trained 64 records in 0.149865325 seconds. Throughput is 427.05008 records/second. Loss is 0.32868794. Sequential2290a28's hyper parameters: Current learning rate is 0.013653741125068269. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 28800/60000][Iteration 2326][Wall Clock 285.416455821s] Trained 64 records in 0.159096551 seconds. Throughput is 402.27145 records/second. Loss is 0.30939215. Sequential2290a28's hyper parameters: Current learning rate is 0.013651877133105802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 28864/60000][Iteration 2327][Wall Clock 285.529870661s] Trained 64 records in 0.11341484 seconds. Throughput is 564.30005 records/second. Loss is 0.35001066. Sequential2290a28's hyper parameters: Current learning rate is 0.01365001365001365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 2328][Wall Clock 285.66470197s] Trained 64 records in 0.134831309 seconds. Throughput is 474.6672 records/second. Loss is 0.16175233. Sequential2290a28's hyper parameters: Current learning rate is 0.013648150675583458. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 28992/60000][Iteration 2329][Wall Clock 285.792910253s] Trained 64 records in 0.128208283 seconds. Throughput is 499.18774 records/second. Loss is 0.2145938. Sequential2290a28's hyper parameters: Current learning rate is 0.013646288209606987. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 29056/60000][Iteration 2330][Wall Clock 285.877833325s] Trained 64 records in 0.084923072 seconds. Throughput is 753.6232 records/second. Loss is 0.41529915. Sequential2290a28's hyper parameters: Current learning rate is 0.01364442625187611. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:28 INFO  DistriOptimizer$:408 - [Epoch 3 29120/60000][Iteration 2331][Wall Clock 286.023409723s] Trained 64 records in 0.145576398 seconds. Throughput is 439.63168 records/second. Loss is 0.16085115. Sequential2290a28's hyper parameters: Current learning rate is 0.013642564802182811. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 2332][Wall Clock 286.18648072s] Trained 64 records in 0.163070997 seconds. Throughput is 392.4671 records/second. Loss is 0.36250818. Sequential2290a28's hyper parameters: Current learning rate is 0.013640703860319193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29248/60000][Iteration 2333][Wall Clock 286.302695898s] Trained 64 records in 0.116215178 seconds. Throughput is 550.7026 records/second. Loss is 0.19868691. Sequential2290a28's hyper parameters: Current learning rate is 0.013638843426077468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29312/60000][Iteration 2334][Wall Clock 286.426714956s] Trained 64 records in 0.124019058 seconds. Throughput is 516.04974 records/second. Loss is 0.16973537. Sequential2290a28's hyper parameters: Current learning rate is 0.013636983499249964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29376/60000][Iteration 2335][Wall Clock 286.565185797s] Trained 64 records in 0.138470841 seconds. Throughput is 462.19116 records/second. Loss is 0.2966906. Sequential2290a28's hyper parameters: Current learning rate is 0.013635124079629125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 2336][Wall Clock 286.707047971s] Trained 64 records in 0.141862174 seconds. Throughput is 451.14212 records/second. Loss is 0.21649328. Sequential2290a28's hyper parameters: Current learning rate is 0.013633265167007498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29504/60000][Iteration 2337][Wall Clock 286.818727361s] Trained 64 records in 0.11167939 seconds. Throughput is 573.06903 records/second. Loss is 0.21743713. Sequential2290a28's hyper parameters: Current learning rate is 0.013631406761177753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29568/60000][Iteration 2338][Wall Clock 286.902561889s] Trained 64 records in 0.083834528 seconds. Throughput is 763.40857 records/second. Loss is 0.25973415. Sequential2290a28's hyper parameters: Current learning rate is 0.01362954886193267. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:29 INFO  DistriOptimizer$:408 - [Epoch 3 29632/60000][Iteration 2339][Wall Clock 286.996124523s] Trained 64 records in 0.093562634 seconds. Throughput is 684.03375 records/second. Loss is 0.21215245. Sequential2290a28's hyper parameters: Current learning rate is 0.01362769146906514. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 2340][Wall Clock 287.166702487s] Trained 64 records in 0.170577964 seconds. Throughput is 375.195 records/second. Loss is 0.21307461. Sequential2290a28's hyper parameters: Current learning rate is 0.013625834582368171. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 29760/60000][Iteration 2341][Wall Clock 287.323009576s] Trained 64 records in 0.156307089 seconds. Throughput is 409.4504 records/second. Loss is 0.21466048. Sequential2290a28's hyper parameters: Current learning rate is 0.013623978201634877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 29824/60000][Iteration 2342][Wall Clock 287.52456632s] Trained 64 records in 0.201556744 seconds. Throughput is 317.52844 records/second. Loss is 0.2496918. Sequential2290a28's hyper parameters: Current learning rate is 0.013622122326658494. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 29888/60000][Iteration 2343][Wall Clock 287.62398327s] Trained 64 records in 0.09941695 seconds. Throughput is 643.7534 records/second. Loss is 0.20887029. Sequential2290a28's hyper parameters: Current learning rate is 0.013620266957232363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 2344][Wall Clock 287.724827547s] Trained 64 records in 0.100844277 seconds. Throughput is 634.64185 records/second. Loss is 0.24512908. Sequential2290a28's hyper parameters: Current learning rate is 0.013618412093149939. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 30016/60000][Iteration 2345][Wall Clock 287.848949995s] Trained 64 records in 0.124122448 seconds. Throughput is 515.6199 records/second. Loss is 0.14687811. Sequential2290a28's hyper parameters: Current learning rate is 0.013616557734204792. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 30080/60000][Iteration 2346][Wall Clock 287.918948442s] Trained 64 records in 0.069998447 seconds. Throughput is 914.30597 records/second. Loss is 0.19368206. Sequential2290a28's hyper parameters: Current learning rate is 0.013614703880190605. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:30 INFO  DistriOptimizer$:408 - [Epoch 3 30144/60000][Iteration 2347][Wall Clock 288.059220236s] Trained 64 records in 0.140271794 seconds. Throughput is 456.25708 records/second. Loss is 0.18693236. Sequential2290a28's hyper parameters: Current learning rate is 0.013612850530901171. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:31 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 2348][Wall Clock 288.234055965s] Trained 64 records in 0.174835729 seconds. Throughput is 366.0579 records/second. Loss is 0.31002825. Sequential2290a28's hyper parameters: Current learning rate is 0.013610997686130393. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:31 INFO  DistriOptimizer$:408 - [Epoch 3 30272/60000][Iteration 2349][Wall Clock 288.365452186s] Trained 64 records in 0.131396221 seconds. Throughput is 487.07642 records/second. Loss is 0.11326911. Sequential2290a28's hyper parameters: Current learning rate is 0.013609145345672292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:31 INFO  DistriOptimizer$:408 - [Epoch 3 30336/60000][Iteration 2350][Wall Clock 288.49680408s] Trained 64 records in 0.131351894 seconds. Throughput is 487.2408 records/second. Loss is 0.12133553. Sequential2290a28's hyper parameters: Current learning rate is 0.013607293509320996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:31 INFO  DistriOptimizer$:408 - [Epoch 3 30400/60000][Iteration 2351][Wall Clock 288.589285017s] Trained 64 records in 0.092480937 seconds. Throughput is 692.03455 records/second. Loss is 0.16282022. Sequential2290a28's hyper parameters: Current learning rate is 0.01360544217687075. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:31 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 2352][Wall Clock 288.77395785s] Trained 64 records in 0.184672833 seconds. Throughput is 346.55884 records/second. Loss is 0.2599257. Sequential2290a28's hyper parameters: Current learning rate is 0.013603591348115904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:31 INFO  DistriOptimizer$:408 - [Epoch 3 30528/60000][Iteration 2353][Wall Clock 288.959610002s] Trained 64 records in 0.185652152 seconds. Throughput is 344.7307 records/second. Loss is 0.10517693. Sequential2290a28's hyper parameters: Current learning rate is 0.013601741022850923. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30592/60000][Iteration 2354][Wall Clock 289.093502886s] Trained 64 records in 0.133892884 seconds. Throughput is 477.99405 records/second. Loss is 0.1675889. Sequential2290a28's hyper parameters: Current learning rate is 0.013599891200870393. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30656/60000][Iteration 2355][Wall Clock 289.244319332s] Trained 64 records in 0.150816446 seconds. Throughput is 424.35693 records/second. Loss is 0.19602937. Sequential2290a28's hyper parameters: Current learning rate is 0.013598041881968996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 2356][Wall Clock 289.335019213s] Trained 64 records in 0.090699881 seconds. Throughput is 705.62384 records/second. Loss is 0.24632066. Sequential2290a28's hyper parameters: Current learning rate is 0.013596193065941536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30784/60000][Iteration 2357][Wall Clock 289.443937284s] Trained 64 records in 0.108918071 seconds. Throughput is 587.59766 records/second. Loss is 0.20052442. Sequential2290a28's hyper parameters: Current learning rate is 0.013594344752582926. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30848/60000][Iteration 2358][Wall Clock 289.555374486s] Trained 64 records in 0.111437202 seconds. Throughput is 574.3145 records/second. Loss is 0.1998232. Sequential2290a28's hyper parameters: Current learning rate is 0.013592496941688188. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30912/60000][Iteration 2359][Wall Clock 289.6734535s] Trained 64 records in 0.118079014 seconds. Throughput is 542.00995 records/second. Loss is 0.14978349. Sequential2290a28's hyper parameters: Current learning rate is 0.01359064963305246. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 2360][Wall Clock 289.842496962s] Trained 64 records in 0.169043462 seconds. Throughput is 378.60086 records/second. Loss is 0.18233545. Sequential2290a28's hyper parameters: Current learning rate is 0.013588802826470988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:32 INFO  DistriOptimizer$:408 - [Epoch 3 31040/60000][Iteration 2361][Wall Clock 289.969225444s] Trained 64 records in 0.126728482 seconds. Throughput is 505.01672 records/second. Loss is 0.18307674. Sequential2290a28's hyper parameters: Current learning rate is 0.013586956521739132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31104/60000][Iteration 2362][Wall Clock 290.071290979s] Trained 64 records in 0.102065535 seconds. Throughput is 627.0481 records/second. Loss is 0.3074765. Sequential2290a28's hyper parameters: Current learning rate is 0.013585110718652357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31168/60000][Iteration 2363][Wall Clock 290.18622647s] Trained 64 records in 0.114935491 seconds. Throughput is 556.8341 records/second. Loss is 0.16945499. Sequential2290a28's hyper parameters: Current learning rate is 0.01358326541700625. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 2364][Wall Clock 290.287366188s] Trained 64 records in 0.101139718 seconds. Throughput is 632.788 records/second. Loss is 0.16662642. Sequential2290a28's hyper parameters: Current learning rate is 0.013581420616596496. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31296/60000][Iteration 2365][Wall Clock 290.387596695s] Trained 64 records in 0.100230507 seconds. Throughput is 638.52814 records/second. Loss is 0.17741445. Sequential2290a28's hyper parameters: Current learning rate is 0.013579576317218903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31360/60000][Iteration 2366][Wall Clock 290.497583624s] Trained 64 records in 0.109986929 seconds. Throughput is 581.8873 records/second. Loss is 0.14686401. Sequential2290a28's hyper parameters: Current learning rate is 0.013577732518669382. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31424/60000][Iteration 2367][Wall Clock 290.629975321s] Trained 64 records in 0.132391697 seconds. Throughput is 483.41403 records/second. Loss is 0.20302133. Sequential2290a28's hyper parameters: Current learning rate is 0.013575889220743959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 2368][Wall Clock 290.830855766s] Trained 64 records in 0.200880445 seconds. Throughput is 318.59747 records/second. Loss is 0.19578621. Sequential2290a28's hyper parameters: Current learning rate is 0.013574046423238768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:33 INFO  DistriOptimizer$:408 - [Epoch 3 31552/60000][Iteration 2369][Wall Clock 291.014994923s] Trained 64 records in 0.184139157 seconds. Throughput is 347.56323 records/second. Loss is 0.49892086. Sequential2290a28's hyper parameters: Current learning rate is 0.013572204125950055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 31616/60000][Iteration 2370][Wall Clock 291.184272927s] Trained 64 records in 0.169278004 seconds. Throughput is 378.07626 records/second. Loss is 0.2671169. Sequential2290a28's hyper parameters: Current learning rate is 0.013570362328674175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 31680/60000][Iteration 2371][Wall Clock 291.317188447s] Trained 64 records in 0.13291552 seconds. Throughput is 481.50882 records/second. Loss is 0.06763342. Sequential2290a28's hyper parameters: Current learning rate is 0.013568521031207599. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 2372][Wall Clock 291.441315227s] Trained 64 records in 0.12412678 seconds. Throughput is 515.60187 records/second. Loss is 0.27190155. Sequential2290a28's hyper parameters: Current learning rate is 0.0135666802333469. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 31808/60000][Iteration 2373][Wall Clock 291.555038645s] Trained 64 records in 0.113723418 seconds. Throughput is 562.76886 records/second. Loss is 0.2814213. Sequential2290a28's hyper parameters: Current learning rate is 0.013564839934888768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 31872/60000][Iteration 2374][Wall Clock 291.672245581s] Trained 64 records in 0.117206936 seconds. Throughput is 546.0428 records/second. Loss is 0.29242516. Sequential2290a28's hyper parameters: Current learning rate is 0.01356300013563. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 31936/60000][Iteration 2375][Wall Clock 291.761053912s] Trained 64 records in 0.088808331 seconds. Throughput is 720.65314 records/second. Loss is 0.25336683. Sequential2290a28's hyper parameters: Current learning rate is 0.013561160835367507. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 2376][Wall Clock 291.84766381s] Trained 64 records in 0.086609898 seconds. Throughput is 738.94556 records/second. Loss is 0.13884547. Sequential2290a28's hyper parameters: Current learning rate is 0.013559322033898305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 32064/60000][Iteration 2377][Wall Clock 291.930073157s] Trained 64 records in 0.082409347 seconds. Throughput is 776.61096 records/second. Loss is 0.096872546. Sequential2290a28's hyper parameters: Current learning rate is 0.013557483731019523. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:34 INFO  DistriOptimizer$:408 - [Epoch 3 32128/60000][Iteration 2378][Wall Clock 292.010164997s] Trained 64 records in 0.08009184 seconds. Throughput is 799.08264 records/second. Loss is 0.14630614. Sequential2290a28's hyper parameters: Current learning rate is 0.013555645926528399. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32192/60000][Iteration 2379][Wall Clock 292.09164459s] Trained 64 records in 0.081479593 seconds. Throughput is 785.4727 records/second. Loss is 0.15485713. Sequential2290a28's hyper parameters: Current learning rate is 0.013553808620222282. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 2380][Wall Clock 292.167363829s] Trained 64 records in 0.075719239 seconds. Throughput is 845.2277 records/second. Loss is 0.24104565. Sequential2290a28's hyper parameters: Current learning rate is 0.013551971811898631. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32320/60000][Iteration 2381][Wall Clock 292.291683836s] Trained 64 records in 0.124320007 seconds. Throughput is 514.8005 records/second. Loss is 0.20428255. Sequential2290a28's hyper parameters: Current learning rate is 0.013550135501355014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32384/60000][Iteration 2382][Wall Clock 292.397123571s] Trained 64 records in 0.105439735 seconds. Throughput is 606.9818 records/second. Loss is 0.17198747. Sequential2290a28's hyper parameters: Current learning rate is 0.013548299688389108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32448/60000][Iteration 2383][Wall Clock 292.529069978s] Trained 64 records in 0.131946407 seconds. Throughput is 485.04544 records/second. Loss is 0.0945186. Sequential2290a28's hyper parameters: Current learning rate is 0.013546464372798701. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 2384][Wall Clock 292.656495509s] Trained 64 records in 0.127425531 seconds. Throughput is 502.25412 records/second. Loss is 0.11934252. Sequential2290a28's hyper parameters: Current learning rate is 0.013544629554381689. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32576/60000][Iteration 2385][Wall Clock 292.76324428s] Trained 64 records in 0.106748771 seconds. Throughput is 599.5385 records/second. Loss is 0.21581343. Sequential2290a28's hyper parameters: Current learning rate is 0.01354279523293608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32640/60000][Iteration 2386][Wall Clock 292.858325082s] Trained 64 records in 0.095080802 seconds. Throughput is 673.1117 records/second. Loss is 0.2796685. Sequential2290a28's hyper parameters: Current learning rate is 0.013540961408259986. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32704/60000][Iteration 2387][Wall Clock 292.951387463s] Trained 64 records in 0.093062381 seconds. Throughput is 687.71075 records/second. Loss is 0.14747146. Sequential2290a28's hyper parameters: Current learning rate is 0.013539128080151638. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:35 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 2388][Wall Clock 293.038073918s] Trained 64 records in 0.086686455 seconds. Throughput is 738.29297 records/second. Loss is 0.1206983. Sequential2290a28's hyper parameters: Current learning rate is 0.013537295248409367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 32832/60000][Iteration 2389][Wall Clock 293.113760761s] Trained 64 records in 0.075686843 seconds. Throughput is 845.58954 records/second. Loss is 0.23763946. Sequential2290a28's hyper parameters: Current learning rate is 0.01353546291283162. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 32896/60000][Iteration 2390][Wall Clock 293.190126568s] Trained 64 records in 0.076365807 seconds. Throughput is 838.0714 records/second. Loss is 0.23875539. Sequential2290a28's hyper parameters: Current learning rate is 0.013533631073216944. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 32960/60000][Iteration 2391][Wall Clock 293.268483159s] Trained 64 records in 0.078356591 seconds. Throughput is 816.77875 records/second. Loss is 0.21620306. Sequential2290a28's hyper parameters: Current learning rate is 0.013531799729364006. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 2392][Wall Clock 293.366430973s] Trained 64 records in 0.097947814 seconds. Throughput is 653.4092 records/second. Loss is 0.17626221. Sequential2290a28's hyper parameters: Current learning rate is 0.013529968881071575. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 33088/60000][Iteration 2393][Wall Clock 293.521286754s] Trained 64 records in 0.154855781 seconds. Throughput is 413.28775 records/second. Loss is 0.21835536. Sequential2290a28's hyper parameters: Current learning rate is 0.013528138528138526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 33152/60000][Iteration 2394][Wall Clock 293.620743811s] Trained 64 records in 0.099457057 seconds. Throughput is 643.49384 records/second. Loss is 0.2681185. Sequential2290a28's hyper parameters: Current learning rate is 0.013526308670363857. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 33216/60000][Iteration 2395][Wall Clock 293.726527922s] Trained 64 records in 0.105784111 seconds. Throughput is 605.0058 records/second. Loss is 0.17947616. Sequential2290a28's hyper parameters: Current learning rate is 0.013524479307546659. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 2396][Wall Clock 293.833674985s] Trained 64 records in 0.107147063 seconds. Throughput is 597.3099 records/second. Loss is 0.24755324. Sequential2290a28's hyper parameters: Current learning rate is 0.013522650439486139. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:36 INFO  DistriOptimizer$:408 - [Epoch 3 33344/60000][Iteration 2397][Wall Clock 293.930250444s] Trained 64 records in 0.096575459 seconds. Throughput is 662.6942 records/second. Loss is 0.309016. Sequential2290a28's hyper parameters: Current learning rate is 0.01352082206598161. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33408/60000][Iteration 2398][Wall Clock 294.055982105s] Trained 64 records in 0.125731661 seconds. Throughput is 509.02054 records/second. Loss is 0.23895898. Sequential2290a28's hyper parameters: Current learning rate is 0.0135189941868325. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33472/60000][Iteration 2399][Wall Clock 294.148469604s] Trained 64 records in 0.092487499 seconds. Throughput is 691.9854 records/second. Loss is 0.2235097. Sequential2290a28's hyper parameters: Current learning rate is 0.013517166801838334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 2400][Wall Clock 294.239157279s] Trained 64 records in 0.090687675 seconds. Throughput is 705.7188 records/second. Loss is 0.120545454. Sequential2290a28's hyper parameters: Current learning rate is 0.013515339910798757. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33600/60000][Iteration 2401][Wall Clock 294.339396702s] Trained 64 records in 0.100239423 seconds. Throughput is 638.4713 records/second. Loss is 0.1338636. Sequential2290a28's hyper parameters: Current learning rate is 0.013513513513513514. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33664/60000][Iteration 2402][Wall Clock 294.434523607s] Trained 64 records in 0.095126905 seconds. Throughput is 672.78546 records/second. Loss is 0.16748849. Sequential2290a28's hyper parameters: Current learning rate is 0.013511687609782462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33728/60000][Iteration 2403][Wall Clock 294.540500212s] Trained 64 records in 0.105976605 seconds. Throughput is 603.90686 records/second. Loss is 0.18482848. Sequential2290a28's hyper parameters: Current learning rate is 0.013509862199405568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 2404][Wall Clock 294.647765859s] Trained 64 records in 0.107265647 seconds. Throughput is 596.6496 records/second. Loss is 0.20334959. Sequential2290a28's hyper parameters: Current learning rate is 0.013508037282182899. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33856/60000][Iteration 2405][Wall Clock 294.733628713s] Trained 64 records in 0.085862854 seconds. Throughput is 745.3747 records/second. Loss is 0.33024657. Sequential2290a28's hyper parameters: Current learning rate is 0.013506212857914642. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33920/60000][Iteration 2406][Wall Clock 294.811066259s] Trained 64 records in 0.077437546 seconds. Throughput is 826.47253 records/second. Loss is 0.069702156. Sequential2290a28's hyper parameters: Current learning rate is 0.01350438892640108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:37 INFO  DistriOptimizer$:408 - [Epoch 3 33984/60000][Iteration 2407][Wall Clock 294.962006853s] Trained 64 records in 0.150940594 seconds. Throughput is 424.00787 records/second. Loss is 0.18091896. Sequential2290a28's hyper parameters: Current learning rate is 0.013502565487442613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 2408][Wall Clock 295.057890874s] Trained 64 records in 0.095884021 seconds. Throughput is 667.4731 records/second. Loss is 0.14941943. Sequential2290a28's hyper parameters: Current learning rate is 0.013500742540839746. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34112/60000][Iteration 2409][Wall Clock 295.146798805s] Trained 64 records in 0.088907931 seconds. Throughput is 719.84576 records/second. Loss is 0.14675899. Sequential2290a28's hyper parameters: Current learning rate is 0.013498920086393088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34176/60000][Iteration 2410][Wall Clock 295.281792286s] Trained 64 records in 0.134993481 seconds. Throughput is 474.097 records/second. Loss is 0.1618799. Sequential2290a28's hyper parameters: Current learning rate is 0.01349709812390336. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34240/60000][Iteration 2411][Wall Clock 295.380914364s] Trained 64 records in 0.099122078 seconds. Throughput is 645.66846 records/second. Loss is 0.19159997. Sequential2290a28's hyper parameters: Current learning rate is 0.01349527665317139. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 2412][Wall Clock 295.51540084s] Trained 64 records in 0.134486476 seconds. Throughput is 475.88425 records/second. Loss is 0.29191807. Sequential2290a28's hyper parameters: Current learning rate is 0.013493455673998112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34368/60000][Iteration 2413][Wall Clock 295.613788239s] Trained 64 records in 0.098387399 seconds. Throughput is 650.4898 records/second. Loss is 0.27895907. Sequential2290a28's hyper parameters: Current learning rate is 0.013491635186184566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34432/60000][Iteration 2414][Wall Clock 295.685171408s] Trained 64 records in 0.071383169 seconds. Throughput is 896.5699 records/second. Loss is 0.14292857. Sequential2290a28's hyper parameters: Current learning rate is 0.013489815189531903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34496/60000][Iteration 2415][Wall Clock 295.785626518s] Trained 64 records in 0.10045511 seconds. Throughput is 637.10046 records/second. Loss is 0.2793371. Sequential2290a28's hyper parameters: Current learning rate is 0.01348799568384138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 2416][Wall Clock 295.919035087s] Trained 64 records in 0.133408569 seconds. Throughput is 479.72928 records/second. Loss is 0.3189272. Sequential2290a28's hyper parameters: Current learning rate is 0.013486176668914362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:38 INFO  DistriOptimizer$:408 - [Epoch 3 34624/60000][Iteration 2417][Wall Clock 296.02300978s] Trained 64 records in 0.103974693 seconds. Throughput is 615.5344 records/second. Loss is 0.21825145. Sequential2290a28's hyper parameters: Current learning rate is 0.013484358144552318. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 34688/60000][Iteration 2418][Wall Clock 296.142438107s] Trained 64 records in 0.119428327 seconds. Throughput is 535.8862 records/second. Loss is 0.14109004. Sequential2290a28's hyper parameters: Current learning rate is 0.013482540110556829. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 34752/60000][Iteration 2419][Wall Clock 296.230795165s] Trained 64 records in 0.088357058 seconds. Throughput is 724.33374 records/second. Loss is 0.15780747. Sequential2290a28's hyper parameters: Current learning rate is 0.013480722566729577. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 2420][Wall Clock 296.349876865s] Trained 64 records in 0.1190817 seconds. Throughput is 537.44617 records/second. Loss is 0.26276675. Sequential2290a28's hyper parameters: Current learning rate is 0.013478905512872355. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 34880/60000][Iteration 2421][Wall Clock 296.54270252s] Trained 64 records in 0.192825655 seconds. Throughput is 331.90604 records/second. Loss is 0.16183153. Sequential2290a28's hyper parameters: Current learning rate is 0.013477088948787063. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 34944/60000][Iteration 2422][Wall Clock 296.666338965s] Trained 64 records in 0.123636445 seconds. Throughput is 517.6467 records/second. Loss is 0.10820552. Sequential2290a28's hyper parameters: Current learning rate is 0.013475272874275704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 35008/60000][Iteration 2423][Wall Clock 296.789414486s] Trained 64 records in 0.123075521 seconds. Throughput is 520.0059 records/second. Loss is 0.2121595. Sequential2290a28's hyper parameters: Current learning rate is 0.013473457289140393. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 2424][Wall Clock 296.900135373s] Trained 64 records in 0.110720887 seconds. Throughput is 578.03 records/second. Loss is 0.14068069. Sequential2290a28's hyper parameters: Current learning rate is 0.01347164219318335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:39 INFO  DistriOptimizer$:408 - [Epoch 3 35136/60000][Iteration 2425][Wall Clock 296.98045036s] Trained 64 records in 0.080314987 seconds. Throughput is 796.8625 records/second. Loss is 0.11496698. Sequential2290a28's hyper parameters: Current learning rate is 0.013469827586206897. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35200/60000][Iteration 2426][Wall Clock 297.052489564s] Trained 64 records in 0.072039204 seconds. Throughput is 888.40515 records/second. Loss is 0.060995847. Sequential2290a28's hyper parameters: Current learning rate is 0.013468013468013467. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35264/60000][Iteration 2427][Wall Clock 297.123923827s] Trained 64 records in 0.071434263 seconds. Throughput is 895.92865 records/second. Loss is 0.12337165. Sequential2290a28's hyper parameters: Current learning rate is 0.013466199838405602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 2428][Wall Clock 297.203488035s] Trained 64 records in 0.079564208 seconds. Throughput is 804.38184 records/second. Loss is 0.24289812. Sequential2290a28's hyper parameters: Current learning rate is 0.013464386697185943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35392/60000][Iteration 2429][Wall Clock 297.284795243s] Trained 64 records in 0.081307208 seconds. Throughput is 787.13806 records/second. Loss is 0.15624315. Sequential2290a28's hyper parameters: Current learning rate is 0.013462574044157244. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35456/60000][Iteration 2430][Wall Clock 297.382060568s] Trained 64 records in 0.097265325 seconds. Throughput is 657.994 records/second. Loss is 0.10593724. Sequential2290a28's hyper parameters: Current learning rate is 0.013460761879122358. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35520/60000][Iteration 2431][Wall Clock 297.536442378s] Trained 64 records in 0.15438181 seconds. Throughput is 414.5566 records/second. Loss is 0.253735. Sequential2290a28's hyper parameters: Current learning rate is 0.013458950201884253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 2432][Wall Clock 297.63205785s] Trained 64 records in 0.095615472 seconds. Throughput is 669.3478 records/second. Loss is 0.08486503. Sequential2290a28's hyper parameters: Current learning rate is 0.013457139012245998. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35648/60000][Iteration 2433][Wall Clock 297.720030514s] Trained 64 records in 0.087972664 seconds. Throughput is 727.4987 records/second. Loss is 0.19502261. Sequential2290a28's hyper parameters: Current learning rate is 0.013455328310010764. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35712/60000][Iteration 2434][Wall Clock 297.817518346s] Trained 64 records in 0.097487832 seconds. Throughput is 656.4922 records/second. Loss is 0.1752953. Sequential2290a28's hyper parameters: Current learning rate is 0.013453518094981836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:40 INFO  DistriOptimizer$:408 - [Epoch 3 35776/60000][Iteration 2435][Wall Clock 297.934791687s] Trained 64 records in 0.117273341 seconds. Throughput is 545.7336 records/second. Loss is 0.226268. Sequential2290a28's hyper parameters: Current learning rate is 0.013451708366962604. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 2436][Wall Clock 298.025027746s] Trained 64 records in 0.090236059 seconds. Throughput is 709.2508 records/second. Loss is 0.18373203. Sequential2290a28's hyper parameters: Current learning rate is 0.013449899125756556. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 35904/60000][Iteration 2437][Wall Clock 298.164183233s] Trained 64 records in 0.139155487 seconds. Throughput is 459.91718 records/second. Loss is 0.12661429. Sequential2290a28's hyper parameters: Current learning rate is 0.013448090371167294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 35968/60000][Iteration 2438][Wall Clock 298.305224497s] Trained 64 records in 0.141041264 seconds. Throughput is 453.7679 records/second. Loss is 0.34866577. Sequential2290a28's hyper parameters: Current learning rate is 0.013446282102998522. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 36032/60000][Iteration 2439][Wall Clock 298.424456088s] Trained 64 records in 0.119231591 seconds. Throughput is 536.7705 records/second. Loss is 0.11972332. Sequential2290a28's hyper parameters: Current learning rate is 0.013444474321054048. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 2440][Wall Clock 298.635696932s] Trained 64 records in 0.211240844 seconds. Throughput is 302.9717 records/second. Loss is 0.14678767. Sequential2290a28's hyper parameters: Current learning rate is 0.013442667025137788. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 36160/60000][Iteration 2441][Wall Clock 298.818022581s] Trained 64 records in 0.182325649 seconds. Throughput is 351.0203 records/second. Loss is 0.23556507. Sequential2290a28's hyper parameters: Current learning rate is 0.013440860215053764. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:41 INFO  DistriOptimizer$:408 - [Epoch 3 36224/60000][Iteration 2442][Wall Clock 298.991810941s] Trained 64 records in 0.17378836 seconds. Throughput is 368.26404 records/second. Loss is 0.079311736. Sequential2290a28's hyper parameters: Current learning rate is 0.013439053890606102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36288/60000][Iteration 2443][Wall Clock 299.081451243s] Trained 64 records in 0.089640302 seconds. Throughput is 713.96454 records/second. Loss is 0.33800784. Sequential2290a28's hyper parameters: Current learning rate is 0.013437248051599033. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 2444][Wall Clock 299.175724789s] Trained 64 records in 0.094273546 seconds. Throughput is 678.8755 records/second. Loss is 0.26241875. Sequential2290a28's hyper parameters: Current learning rate is 0.013435442697836895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36416/60000][Iteration 2445][Wall Clock 299.38552595s] Trained 64 records in 0.209801161 seconds. Throughput is 305.05072 records/second. Loss is 0.37569892. Sequential2290a28's hyper parameters: Current learning rate is 0.013433637829124129. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36480/60000][Iteration 2446][Wall Clock 299.571715412s] Trained 64 records in 0.186189462 seconds. Throughput is 343.7359 records/second. Loss is 0.26736528. Sequential2290a28's hyper parameters: Current learning rate is 0.013431833445265278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36544/60000][Iteration 2447][Wall Clock 299.664578333s] Trained 64 records in 0.092862921 seconds. Throughput is 689.1879 records/second. Loss is 0.16826764. Sequential2290a28's hyper parameters: Current learning rate is 0.013430029546065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 2448][Wall Clock 299.737491818s] Trained 64 records in 0.072913485 seconds. Throughput is 877.7526 records/second. Loss is 0.17065986. Sequential2290a28's hyper parameters: Current learning rate is 0.01342822613132805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36672/60000][Iteration 2449][Wall Clock 299.824494929s] Trained 64 records in 0.087003111 seconds. Throughput is 735.6059 records/second. Loss is 0.13355632. Sequential2290a28's hyper parameters: Current learning rate is 0.01342642320085929. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:42 INFO  DistriOptimizer$:408 - [Epoch 3 36736/60000][Iteration 2450][Wall Clock 299.92456216s] Trained 64 records in 0.100067231 seconds. Throughput is 639.57 records/second. Loss is 0.25153154. Sequential2290a28's hyper parameters: Current learning rate is 0.013424620754463686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 36800/60000][Iteration 2451][Wall Clock 300.034755979s] Trained 64 records in 0.110193819 seconds. Throughput is 580.7948 records/second. Loss is 0.24086481. Sequential2290a28's hyper parameters: Current learning rate is 0.013422818791946308. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 2452][Wall Clock 300.123002716s] Trained 64 records in 0.088246737 seconds. Throughput is 725.23926 records/second. Loss is 0.1271854. Sequential2290a28's hyper parameters: Current learning rate is 0.013421017313112335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 36928/60000][Iteration 2453][Wall Clock 300.208945449s] Trained 64 records in 0.085942733 seconds. Throughput is 744.68195 records/second. Loss is 0.15239894. Sequential2290a28's hyper parameters: Current learning rate is 0.013419216317767043. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 36992/60000][Iteration 2454][Wall Clock 300.32982416s] Trained 64 records in 0.120878711 seconds. Throughput is 529.45636 records/second. Loss is 0.12927039. Sequential2290a28's hyper parameters: Current learning rate is 0.013417415805715817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 37056/60000][Iteration 2455][Wall Clock 300.433202344s] Trained 64 records in 0.103378184 seconds. Throughput is 619.0861 records/second. Loss is 0.100321665. Sequential2290a28's hyper parameters: Current learning rate is 0.013415615776764152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 2456][Wall Clock 300.533934599s] Trained 64 records in 0.100732255 seconds. Throughput is 635.34766 records/second. Loss is 0.14413029. Sequential2290a28's hyper parameters: Current learning rate is 0.013413816230717638. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 37184/60000][Iteration 2457][Wall Clock 300.652557234s] Trained 64 records in 0.118622635 seconds. Throughput is 539.526 records/second. Loss is 0.07207301. Sequential2290a28's hyper parameters: Current learning rate is 0.013412017167381975. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 37248/60000][Iteration 2458][Wall Clock 300.838855001s] Trained 64 records in 0.186297767 seconds. Throughput is 343.53604 records/second. Loss is 0.12415353. Sequential2290a28's hyper parameters: Current learning rate is 0.013410218586562961. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:43 INFO  DistriOptimizer$:408 - [Epoch 3 37312/60000][Iteration 2459][Wall Clock 300.977301395s] Trained 64 records in 0.138446394 seconds. Throughput is 462.2728 records/second. Loss is 0.1894192. Sequential2290a28's hyper parameters: Current learning rate is 0.013408420488066506. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 2460][Wall Clock 301.15181414s] Trained 64 records in 0.174512745 seconds. Throughput is 366.73538 records/second. Loss is 0.1877754. Sequential2290a28's hyper parameters: Current learning rate is 0.01340662287169862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37440/60000][Iteration 2461][Wall Clock 301.321408876s] Trained 64 records in 0.169594736 seconds. Throughput is 377.3702 records/second. Loss is 0.23712327. Sequential2290a28's hyper parameters: Current learning rate is 0.013404825737265416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37504/60000][Iteration 2462][Wall Clock 301.486269649s] Trained 64 records in 0.164860773 seconds. Throughput is 388.20636 records/second. Loss is 0.14833023. Sequential2290a28's hyper parameters: Current learning rate is 0.013403029084573114. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37568/60000][Iteration 2463][Wall Clock 301.592581354s] Trained 64 records in 0.106311705 seconds. Throughput is 602.0033 records/second. Loss is 0.1316177. Sequential2290a28's hyper parameters: Current learning rate is 0.013401232913428035. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 2464][Wall Clock 301.686754142s] Trained 64 records in 0.094172788 seconds. Throughput is 679.6018 records/second. Loss is 0.25566584. Sequential2290a28's hyper parameters: Current learning rate is 0.013399437223636608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37696/60000][Iteration 2465][Wall Clock 301.794235124s] Trained 64 records in 0.107480982 seconds. Throughput is 595.45416 records/second. Loss is 0.20110862. Sequential2290a28's hyper parameters: Current learning rate is 0.01339764201500536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:44 INFO  DistriOptimizer$:408 - [Epoch 3 37760/60000][Iteration 2466][Wall Clock 301.901686379s] Trained 64 records in 0.107451255 seconds. Throughput is 595.61896 records/second. Loss is 0.22105253. Sequential2290a28's hyper parameters: Current learning rate is 0.013395847287340924. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 37824/60000][Iteration 2467][Wall Clock 302.02277647s] Trained 64 records in 0.121090091 seconds. Throughput is 528.5321 records/second. Loss is 0.19804563. Sequential2290a28's hyper parameters: Current learning rate is 0.01339405304045004. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 2468][Wall Clock 302.14074104s] Trained 64 records in 0.11796457 seconds. Throughput is 542.53577 records/second. Loss is 0.15108363. Sequential2290a28's hyper parameters: Current learning rate is 0.013392259274139546. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 37952/60000][Iteration 2469][Wall Clock 302.259290596s] Trained 64 records in 0.118549556 seconds. Throughput is 539.85864 records/second. Loss is 0.12326219. Sequential2290a28's hyper parameters: Current learning rate is 0.01339046598821639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 38016/60000][Iteration 2470][Wall Clock 302.382269406s] Trained 64 records in 0.12297881 seconds. Throughput is 520.41486 records/second. Loss is 0.1813098. Sequential2290a28's hyper parameters: Current learning rate is 0.013388673182487616. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 38080/60000][Iteration 2471][Wall Clock 302.504096325s] Trained 64 records in 0.121826919 seconds. Throughput is 525.33545 records/second. Loss is 0.13752672. Sequential2290a28's hyper parameters: Current learning rate is 0.013386880856760375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 2472][Wall Clock 302.728717139s] Trained 64 records in 0.224620814 seconds. Throughput is 284.92462 records/second. Loss is 0.3913053. Sequential2290a28's hyper parameters: Current learning rate is 0.013385089010841922. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 38208/60000][Iteration 2473][Wall Clock 302.857482984s] Trained 64 records in 0.128765845 seconds. Throughput is 497.02618 records/second. Loss is 0.18391046. Sequential2290a28's hyper parameters: Current learning rate is 0.013383297644539615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:45 INFO  DistriOptimizer$:408 - [Epoch 3 38272/60000][Iteration 2474][Wall Clock 302.94414567s] Trained 64 records in 0.086662686 seconds. Throughput is 738.4954 records/second. Loss is 0.26513135. Sequential2290a28's hyper parameters: Current learning rate is 0.013381506757660911. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38336/60000][Iteration 2475][Wall Clock 303.085120091s] Trained 64 records in 0.140974421 seconds. Throughput is 453.9831 records/second. Loss is 0.16291432. Sequential2290a28's hyper parameters: Current learning rate is 0.01337971635001338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 2476][Wall Clock 303.225128256s] Trained 64 records in 0.140008165 seconds. Throughput is 457.11618 records/second. Loss is 0.17454591. Sequential2290a28's hyper parameters: Current learning rate is 0.013377926421404682. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38464/60000][Iteration 2477][Wall Clock 303.364172496s] Trained 64 records in 0.13904424 seconds. Throughput is 460.28516 records/second. Loss is 0.37018403. Sequential2290a28's hyper parameters: Current learning rate is 0.01337613697164259. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38528/60000][Iteration 2478][Wall Clock 303.493640185s] Trained 64 records in 0.129467689 seconds. Throughput is 494.33182 records/second. Loss is 0.08714436. Sequential2290a28's hyper parameters: Current learning rate is 0.013374348000534974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38592/60000][Iteration 2479][Wall Clock 303.612184781s] Trained 64 records in 0.118544596 seconds. Throughput is 539.8812 records/second. Loss is 0.13917717. Sequential2290a28's hyper parameters: Current learning rate is 0.01337255950788981. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 2480][Wall Clock 303.716308645s] Trained 64 records in 0.104123864 seconds. Throughput is 614.6526 records/second. Loss is 0.14125621. Sequential2290a28's hyper parameters: Current learning rate is 0.013370771493515177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38720/60000][Iteration 2481][Wall Clock 303.796691543s] Trained 64 records in 0.080382898 seconds. Throughput is 796.1893 records/second. Loss is 0.18389192. Sequential2290a28's hyper parameters: Current learning rate is 0.013368983957219251. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:46 INFO  DistriOptimizer$:408 - [Epoch 3 38784/60000][Iteration 2482][Wall Clock 303.941455716s] Trained 64 records in 0.144764173 seconds. Throughput is 442.09836 records/second. Loss is 0.28652644. Sequential2290a28's hyper parameters: Current learning rate is 0.01336719689881032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 38848/60000][Iteration 2483][Wall Clock 304.050549282s] Trained 64 records in 0.109093566 seconds. Throughput is 586.65234 records/second. Loss is 0.20626412. Sequential2290a28's hyper parameters: Current learning rate is 0.013365410318096767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 2484][Wall Clock 304.153273387s] Trained 64 records in 0.102724105 seconds. Throughput is 623.0281 records/second. Loss is 0.13319713. Sequential2290a28's hyper parameters: Current learning rate is 0.013363624214887078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 38976/60000][Iteration 2485][Wall Clock 304.241680676s] Trained 64 records in 0.088407289 seconds. Throughput is 723.92224 records/second. Loss is 0.13374795. Sequential2290a28's hyper parameters: Current learning rate is 0.013361838588989846. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39040/60000][Iteration 2486][Wall Clock 304.365017057s] Trained 64 records in 0.123336381 seconds. Throughput is 518.90607 records/second. Loss is 0.22531602. Sequential2290a28's hyper parameters: Current learning rate is 0.013360053440213761. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39104/60000][Iteration 2487][Wall Clock 304.45067041s] Trained 64 records in 0.085653353 seconds. Throughput is 747.1979 records/second. Loss is 0.1594106. Sequential2290a28's hyper parameters: Current learning rate is 0.013358268768367619. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 2488][Wall Clock 304.529964778s] Trained 64 records in 0.079294368 seconds. Throughput is 807.1191 records/second. Loss is 0.21918511. Sequential2290a28's hyper parameters: Current learning rate is 0.013356484573260318. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39232/60000][Iteration 2489][Wall Clock 304.612694557s] Trained 64 records in 0.082729779 seconds. Throughput is 773.6029 records/second. Loss is 0.36580357. Sequential2290a28's hyper parameters: Current learning rate is 0.013354700854700854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39296/60000][Iteration 2490][Wall Clock 304.727256434s] Trained 64 records in 0.114561877 seconds. Throughput is 558.6501 records/second. Loss is 0.1199752. Sequential2290a28's hyper parameters: Current learning rate is 0.01335291761249833. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39360/60000][Iteration 2491][Wall Clock 304.820709043s] Trained 64 records in 0.093452609 seconds. Throughput is 684.8391 records/second. Loss is 0.39785537. Sequential2290a28's hyper parameters: Current learning rate is 0.01335113484646195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:47 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 2492][Wall Clock 304.921135302s] Trained 64 records in 0.100426259 seconds. Throughput is 637.2835 records/second. Loss is 0.22776754. Sequential2290a28's hyper parameters: Current learning rate is 0.013349352556401016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39488/60000][Iteration 2493][Wall Clock 305.003663344s] Trained 64 records in 0.082528042 seconds. Throughput is 775.494 records/second. Loss is 0.22016388. Sequential2290a28's hyper parameters: Current learning rate is 0.013347570742124934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39552/60000][Iteration 2494][Wall Clock 305.127480043s] Trained 64 records in 0.123816699 seconds. Throughput is 516.8931 records/second. Loss is 0.16687185. Sequential2290a28's hyper parameters: Current learning rate is 0.013345789403443213. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39616/60000][Iteration 2495][Wall Clock 305.213317761s] Trained 64 records in 0.085837718 seconds. Throughput is 745.593 records/second. Loss is 0.12860104. Sequential2290a28's hyper parameters: Current learning rate is 0.013344008540165465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 2496][Wall Clock 305.284071517s] Trained 64 records in 0.070753756 seconds. Throughput is 904.54565 records/second. Loss is 0.11828842. Sequential2290a28's hyper parameters: Current learning rate is 0.0133422281521014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39744/60000][Iteration 2497][Wall Clock 305.383898724s] Trained 64 records in 0.099827207 seconds. Throughput is 641.1078 records/second. Loss is 0.40734607. Sequential2290a28's hyper parameters: Current learning rate is 0.013340448239060831. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39808/60000][Iteration 2498][Wall Clock 305.553918498s] Trained 64 records in 0.170019774 seconds. Throughput is 376.4268 records/second. Loss is 0.38943744. Sequential2290a28's hyper parameters: Current learning rate is 0.013338668800853675. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39872/60000][Iteration 2499][Wall Clock 305.648621998s] Trained 64 records in 0.0947035 seconds. Throughput is 675.7934 records/second. Loss is 0.1325364. Sequential2290a28's hyper parameters: Current learning rate is 0.013336889837289943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 2500][Wall Clock 305.887189645s] Trained 64 records in 0.238567647 seconds. Throughput is 268.26773 records/second. Loss is 0.10175906. Sequential2290a28's hyper parameters: Current learning rate is 0.013335111348179758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:48 INFO  DistriOptimizer$:408 - [Epoch 3 40000/60000][Iteration 2501][Wall Clock 305.976996587s] Trained 64 records in 0.089806942 seconds. Throughput is 712.6398 records/second. Loss is 0.20449372. Sequential2290a28's hyper parameters: Current learning rate is 0.013333333333333334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40064/60000][Iteration 2502][Wall Clock 306.162284414s] Trained 64 records in 0.185287827 seconds. Throughput is 345.40854 records/second. Loss is 0.23065668. Sequential2290a28's hyper parameters: Current learning rate is 0.013331555792560993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40128/60000][Iteration 2503][Wall Clock 306.246737903s] Trained 64 records in 0.084453489 seconds. Throughput is 757.8136 records/second. Loss is 0.21587715. Sequential2290a28's hyper parameters: Current learning rate is 0.013329778725673154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 2504][Wall Clock 306.333295128s] Trained 64 records in 0.086557225 seconds. Throughput is 739.39526 records/second. Loss is 0.26657173. Sequential2290a28's hyper parameters: Current learning rate is 0.013328002132480343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40256/60000][Iteration 2505][Wall Clock 306.413774649s] Trained 64 records in 0.080479521 seconds. Throughput is 795.2334 records/second. Loss is 0.09331701. Sequential2290a28's hyper parameters: Current learning rate is 0.013326226012793178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40320/60000][Iteration 2506][Wall Clock 306.530444106s] Trained 64 records in 0.116669457 seconds. Throughput is 548.55835 records/second. Loss is 0.13290535. Sequential2290a28's hyper parameters: Current learning rate is 0.013324450366422387. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40384/60000][Iteration 2507][Wall Clock 306.628296329s] Trained 64 records in 0.097852223 seconds. Throughput is 654.0475 records/second. Loss is 0.26922598. Sequential2290a28's hyper parameters: Current learning rate is 0.013322675193178792. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 2508][Wall Clock 306.756825968s] Trained 64 records in 0.128529639 seconds. Throughput is 497.93964 records/second. Loss is 0.16031766. Sequential2290a28's hyper parameters: Current learning rate is 0.013320900492873319. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:49 INFO  DistriOptimizer$:408 - [Epoch 3 40512/60000][Iteration 2509][Wall Clock 306.882007364s] Trained 64 records in 0.125181396 seconds. Throughput is 511.2581 records/second. Loss is 0.18510714. Sequential2290a28's hyper parameters: Current learning rate is 0.013319126265316995. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40576/60000][Iteration 2510][Wall Clock 306.985521708s] Trained 64 records in 0.103514344 seconds. Throughput is 618.2718 records/second. Loss is 0.22338131. Sequential2290a28's hyper parameters: Current learning rate is 0.013317352510320948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40640/60000][Iteration 2511][Wall Clock 307.147508928s] Trained 64 records in 0.16198722 seconds. Throughput is 395.0929 records/second. Loss is 0.14023802. Sequential2290a28's hyper parameters: Current learning rate is 0.013315579227696404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 2512][Wall Clock 307.248832077s] Trained 64 records in 0.101323149 seconds. Throughput is 631.6424 records/second. Loss is 0.20834179. Sequential2290a28's hyper parameters: Current learning rate is 0.013313806417254694. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40768/60000][Iteration 2513][Wall Clock 307.372457785s] Trained 64 records in 0.123625708 seconds. Throughput is 517.69165 records/second. Loss is 0.087250315. Sequential2290a28's hyper parameters: Current learning rate is 0.01331203407880724. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40832/60000][Iteration 2514][Wall Clock 307.496740012s] Trained 64 records in 0.124282227 seconds. Throughput is 514.957 records/second. Loss is 0.21355106. Sequential2290a28's hyper parameters: Current learning rate is 0.013310262212165578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40896/60000][Iteration 2515][Wall Clock 307.604094925s] Trained 64 records in 0.107354913 seconds. Throughput is 596.15344 records/second. Loss is 0.09067443. Sequential2290a28's hyper parameters: Current learning rate is 0.013308490817141335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 2516][Wall Clock 307.740673448s] Trained 64 records in 0.136578523 seconds. Throughput is 468.59488 records/second. Loss is 0.09490985. Sequential2290a28's hyper parameters: Current learning rate is 0.01330671989354624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:50 INFO  DistriOptimizer$:408 - [Epoch 3 41024/60000][Iteration 2517][Wall Clock 307.910886455s] Trained 64 records in 0.170213007 seconds. Throughput is 375.99945 records/second. Loss is 0.16782957. Sequential2290a28's hyper parameters: Current learning rate is 0.013304949441192123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41088/60000][Iteration 2518][Wall Clock 308.089464055s] Trained 64 records in 0.1785776 seconds. Throughput is 358.3876 records/second. Loss is 0.2603258. Sequential2290a28's hyper parameters: Current learning rate is 0.013303179459890914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41152/60000][Iteration 2519][Wall Clock 308.249443841s] Trained 64 records in 0.159979786 seconds. Throughput is 400.05054 records/second. Loss is 0.27860904. Sequential2290a28's hyper parameters: Current learning rate is 0.013301409949454642. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 2520][Wall Clock 308.373914141s] Trained 64 records in 0.1244703 seconds. Throughput is 514.1789 records/second. Loss is 0.29741597. Sequential2290a28's hyper parameters: Current learning rate is 0.013299640909695438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41280/60000][Iteration 2521][Wall Clock 308.479645846s] Trained 64 records in 0.105731705 seconds. Throughput is 605.30566 records/second. Loss is 0.277514. Sequential2290a28's hyper parameters: Current learning rate is 0.013297872340425532. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41344/60000][Iteration 2522][Wall Clock 308.590266882s] Trained 64 records in 0.110621036 seconds. Throughput is 578.5518 records/second. Loss is 0.21724282. Sequential2290a28's hyper parameters: Current learning rate is 0.013296104241457253. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41408/60000][Iteration 2523][Wall Clock 308.714183306s] Trained 64 records in 0.123916424 seconds. Throughput is 516.4771 records/second. Loss is 0.12834275. Sequential2290a28's hyper parameters: Current learning rate is 0.013294336612603031. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:51 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 2524][Wall Clock 308.853195009s] Trained 64 records in 0.139011703 seconds. Throughput is 460.3929 records/second. Loss is 0.1670011. Sequential2290a28's hyper parameters: Current learning rate is 0.013292569453675396. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41536/60000][Iteration 2525][Wall Clock 309.036977979s] Trained 64 records in 0.18378297 seconds. Throughput is 348.23685 records/second. Loss is 0.20633107. Sequential2290a28's hyper parameters: Current learning rate is 0.013290802764486976. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41600/60000][Iteration 2526][Wall Clock 309.147155385s] Trained 64 records in 0.110177406 seconds. Throughput is 580.88135 records/second. Loss is 0.08967264. Sequential2290a28's hyper parameters: Current learning rate is 0.0132890365448505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41664/60000][Iteration 2527][Wall Clock 309.341875695s] Trained 64 records in 0.19472031 seconds. Throughput is 328.67654 records/second. Loss is 0.11090223. Sequential2290a28's hyper parameters: Current learning rate is 0.013287270794578795. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 2528][Wall Clock 309.518904003s] Trained 64 records in 0.177028308 seconds. Throughput is 361.52408 records/second. Loss is 0.18308885. Sequential2290a28's hyper parameters: Current learning rate is 0.013285505513484787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41792/60000][Iteration 2529][Wall Clock 309.717385416s] Trained 64 records in 0.198481413 seconds. Throughput is 322.44833 records/second. Loss is 0.16273974. Sequential2290a28's hyper parameters: Current learning rate is 0.013283740701381509. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41856/60000][Iteration 2530][Wall Clock 309.840408887s] Trained 64 records in 0.123023471 seconds. Throughput is 520.22595 records/second. Loss is 0.1459372. Sequential2290a28's hyper parameters: Current learning rate is 0.013281976358082082. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:52 INFO  DistriOptimizer$:408 - [Epoch 3 41920/60000][Iteration 2531][Wall Clock 309.931665826s] Trained 64 records in 0.091256939 seconds. Throughput is 701.3165 records/second. Loss is 0.1225881. Sequential2290a28's hyper parameters: Current learning rate is 0.013280212483399735. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 2532][Wall Clock 310.029659026s] Trained 64 records in 0.0979932 seconds. Throughput is 653.1065 records/second. Loss is 0.20018128. Sequential2290a28's hyper parameters: Current learning rate is 0.01327844907714779. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42048/60000][Iteration 2533][Wall Clock 310.11807361s] Trained 64 records in 0.088414584 seconds. Throughput is 723.8624 records/second. Loss is 0.21623182. Sequential2290a28's hyper parameters: Current learning rate is 0.01327668613913967. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42112/60000][Iteration 2534][Wall Clock 310.234188306s] Trained 64 records in 0.116114696 seconds. Throughput is 551.17914 records/second. Loss is 0.35846922. Sequential2290a28's hyper parameters: Current learning rate is 0.013274923669188901. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42176/60000][Iteration 2535][Wall Clock 310.350943873s] Trained 64 records in 0.116755567 seconds. Throughput is 548.15375 records/second. Loss is 0.21754679. Sequential2290a28's hyper parameters: Current learning rate is 0.013273161667109104. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 2536][Wall Clock 310.441421734s] Trained 64 records in 0.090477861 seconds. Throughput is 707.35535 records/second. Loss is 0.23717897. Sequential2290a28's hyper parameters: Current learning rate is 0.013271400132714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42304/60000][Iteration 2537][Wall Clock 310.564596939s] Trained 64 records in 0.123175205 seconds. Throughput is 519.5851 records/second. Loss is 0.2536676. Sequential2290a28's hyper parameters: Current learning rate is 0.013269639065817409. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42368/60000][Iteration 2538][Wall Clock 310.676650797s] Trained 64 records in 0.112053858 seconds. Throughput is 571.15393 records/second. Loss is 0.41674614. Sequential2290a28's hyper parameters: Current learning rate is 0.013267878466233248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42432/60000][Iteration 2539][Wall Clock 310.802747871s] Trained 64 records in 0.126097074 seconds. Throughput is 507.5455 records/second. Loss is 0.19567646. Sequential2290a28's hyper parameters: Current learning rate is 0.013266118333775537. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:53 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 2540][Wall Clock 310.889407909s] Trained 64 records in 0.086660038 seconds. Throughput is 738.51807 records/second. Loss is 0.19272399. Sequential2290a28's hyper parameters: Current learning rate is 0.01326435866825839. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42560/60000][Iteration 2541][Wall Clock 311.022519902s] Trained 64 records in 0.133111993 seconds. Throughput is 480.79813 records/second. Loss is 0.078247994. Sequential2290a28's hyper parameters: Current learning rate is 0.013262599469496022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42624/60000][Iteration 2542][Wall Clock 311.112340736s] Trained 64 records in 0.089820834 seconds. Throughput is 712.5296 records/second. Loss is 0.21051362. Sequential2290a28's hyper parameters: Current learning rate is 0.013260840737302746. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42688/60000][Iteration 2543][Wall Clock 311.220734232s] Trained 64 records in 0.108393496 seconds. Throughput is 590.44135 records/second. Loss is 0.50510913. Sequential2290a28's hyper parameters: Current learning rate is 0.013259082471492973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 2544][Wall Clock 311.390535872s] Trained 64 records in 0.16980164 seconds. Throughput is 376.91037 records/second. Loss is 0.18551847. Sequential2290a28's hyper parameters: Current learning rate is 0.013257324671881215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42816/60000][Iteration 2545][Wall Clock 311.543841991s] Trained 64 records in 0.153306119 seconds. Throughput is 417.46542 records/second. Loss is 0.10153571. Sequential2290a28's hyper parameters: Current learning rate is 0.013255567338282079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42880/60000][Iteration 2546][Wall Clock 311.689572844s] Trained 64 records in 0.145730853 seconds. Throughput is 439.16574 records/second. Loss is 0.21038938. Sequential2290a28's hyper parameters: Current learning rate is 0.013253810470510273. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 42944/60000][Iteration 2547][Wall Clock 311.851278234s] Trained 64 records in 0.16170539 seconds. Throughput is 395.7815 records/second. Loss is 0.14643507. Sequential2290a28's hyper parameters: Current learning rate is 0.0132520540683806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:54 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 2548][Wall Clock 311.939868531s] Trained 64 records in 0.088590297 seconds. Throughput is 722.42676 records/second. Loss is 0.3412442. Sequential2290a28's hyper parameters: Current learning rate is 0.013250298131707963. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43072/60000][Iteration 2549][Wall Clock 312.038587708s] Trained 64 records in 0.098719177 seconds. Throughput is 648.3036 records/second. Loss is 0.24358775. Sequential2290a28's hyper parameters: Current learning rate is 0.013248542660307366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43136/60000][Iteration 2550][Wall Clock 312.119011239s] Trained 64 records in 0.080423531 seconds. Throughput is 795.787 records/second. Loss is 0.20701139. Sequential2290a28's hyper parameters: Current learning rate is 0.013246787653993907. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43200/60000][Iteration 2551][Wall Clock 312.222232296s] Trained 64 records in 0.103221057 seconds. Throughput is 620.0285 records/second. Loss is 0.17194694. Sequential2290a28's hyper parameters: Current learning rate is 0.013245033112582781. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 2552][Wall Clock 312.311934981s] Trained 64 records in 0.089702685 seconds. Throughput is 713.468 records/second. Loss is 0.25489104. Sequential2290a28's hyper parameters: Current learning rate is 0.013243279035889286. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43328/60000][Iteration 2553][Wall Clock 312.384071012s] Trained 64 records in 0.072136031 seconds. Throughput is 887.2127 records/second. Loss is 0.14147489. Sequential2290a28's hyper parameters: Current learning rate is 0.013241525423728813. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43392/60000][Iteration 2554][Wall Clock 312.466095539s] Trained 64 records in 0.082024527 seconds. Throughput is 780.2544 records/second. Loss is 0.28408352. Sequential2290a28's hyper parameters: Current learning rate is 0.013239772275916852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43456/60000][Iteration 2555][Wall Clock 312.591475145s] Trained 64 records in 0.125379606 seconds. Throughput is 510.44983 records/second. Loss is 0.28578863. Sequential2290a28's hyper parameters: Current learning rate is 0.013238019592268996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 2556][Wall Clock 312.666018501s] Trained 64 records in 0.074543356 seconds. Throughput is 858.5607 records/second. Loss is 0.14707303. Sequential2290a28's hyper parameters: Current learning rate is 0.013236267372600925. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43584/60000][Iteration 2557][Wall Clock 312.74159734s] Trained 64 records in 0.075578839 seconds. Throughput is 846.79785 records/second. Loss is 0.19804397. Sequential2290a28's hyper parameters: Current learning rate is 0.013234515616728428. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43648/60000][Iteration 2558][Wall Clock 312.808035787s] Trained 64 records in 0.066438447 seconds. Throughput is 963.29767 records/second. Loss is 0.19011422. Sequential2290a28's hyper parameters: Current learning rate is 0.013232764324467381. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:55 INFO  DistriOptimizer$:408 - [Epoch 3 43712/60000][Iteration 2559][Wall Clock 312.878650624s] Trained 64 records in 0.070614837 seconds. Throughput is 906.32513 records/second. Loss is 0.08786671. Sequential2290a28's hyper parameters: Current learning rate is 0.013231013495633765. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 2560][Wall Clock 312.995370418s] Trained 64 records in 0.116719794 seconds. Throughput is 548.3217 records/second. Loss is 0.14056641. Sequential2290a28's hyper parameters: Current learning rate is 0.013229263130043656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 43840/60000][Iteration 2561][Wall Clock 313.078492405s] Trained 64 records in 0.083121987 seconds. Throughput is 769.95276 records/second. Loss is 0.13282607. Sequential2290a28's hyper parameters: Current learning rate is 0.013227513227513229. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 43904/60000][Iteration 2562][Wall Clock 313.206025385s] Trained 64 records in 0.12753298 seconds. Throughput is 501.831 records/second. Loss is 0.17228127. Sequential2290a28's hyper parameters: Current learning rate is 0.013225763787858748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 43968/60000][Iteration 2563][Wall Clock 313.301465344s] Trained 64 records in 0.095439959 seconds. Throughput is 670.5787 records/second. Loss is 0.20819825. Sequential2290a28's hyper parameters: Current learning rate is 0.013224014810896589. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 2564][Wall Clock 313.422240526s] Trained 64 records in 0.120775182 seconds. Throughput is 529.91016 records/second. Loss is 0.22372818. Sequential2290a28's hyper parameters: Current learning rate is 0.013222266296443212. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 44096/60000][Iteration 2565][Wall Clock 313.594850861s] Trained 64 records in 0.172610335 seconds. Throughput is 370.77734 records/second. Loss is 0.16748582. Sequential2290a28's hyper parameters: Current learning rate is 0.013220518244315178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 44160/60000][Iteration 2566][Wall Clock 313.73141025s] Trained 64 records in 0.136559389 seconds. Throughput is 468.66058 records/second. Loss is 0.100807495. Sequential2290a28's hyper parameters: Current learning rate is 0.01321877065432915. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:56 INFO  DistriOptimizer$:408 - [Epoch 3 44224/60000][Iteration 2567][Wall Clock 313.883796996s] Trained 64 records in 0.152386746 seconds. Throughput is 419.98404 records/second. Loss is 0.15605056. Sequential2290a28's hyper parameters: Current learning rate is 0.013217023526301878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 2568][Wall Clock 313.986073729s] Trained 64 records in 0.102276733 seconds. Throughput is 625.75323 records/second. Loss is 0.15837294. Sequential2290a28's hyper parameters: Current learning rate is 0.013215276860050218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44352/60000][Iteration 2569][Wall Clock 314.098873585s] Trained 64 records in 0.112799856 seconds. Throughput is 567.37665 records/second. Loss is 0.09275993. Sequential2290a28's hyper parameters: Current learning rate is 0.013213530655391121. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44416/60000][Iteration 2570][Wall Clock 314.236127484s] Trained 64 records in 0.137253899 seconds. Throughput is 466.28912 records/second. Loss is 0.17243883. Sequential2290a28's hyper parameters: Current learning rate is 0.01321178491214163. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44480/60000][Iteration 2571][Wall Clock 314.398567174s] Trained 64 records in 0.16243969 seconds. Throughput is 393.99237 records/second. Loss is 0.16960159. Sequential2290a28's hyper parameters: Current learning rate is 0.013210039630118891. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 2572][Wall Clock 314.553646698s] Trained 64 records in 0.155079524 seconds. Throughput is 412.69147 records/second. Loss is 0.25593817. Sequential2290a28's hyper parameters: Current learning rate is 0.013208294809140141. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44608/60000][Iteration 2573][Wall Clock 314.801951833s] Trained 64 records in 0.248305135 seconds. Throughput is 257.74738 records/second. Loss is 0.16812018. Sequential2290a28's hyper parameters: Current learning rate is 0.013206550449022714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:57 INFO  DistriOptimizer$:408 - [Epoch 3 44672/60000][Iteration 2574][Wall Clock 314.898396763s] Trained 64 records in 0.09644493 seconds. Throughput is 663.5911 records/second. Loss is 0.21573567. Sequential2290a28's hyper parameters: Current learning rate is 0.013204806549584048. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 44736/60000][Iteration 2575][Wall Clock 315.071686796s] Trained 64 records in 0.173290033 seconds. Throughput is 369.32303 records/second. Loss is 0.18146314. Sequential2290a28's hyper parameters: Current learning rate is 0.013203063110641669. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 2576][Wall Clock 315.268004617s] Trained 64 records in 0.196317821 seconds. Throughput is 326.00198 records/second. Loss is 0.09975748. Sequential2290a28's hyper parameters: Current learning rate is 0.0132013201320132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 44864/60000][Iteration 2577][Wall Clock 315.366937849s] Trained 64 records in 0.098933232 seconds. Throughput is 646.90094 records/second. Loss is 0.11232996. Sequential2290a28's hyper parameters: Current learning rate is 0.013199577613516367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 44928/60000][Iteration 2578][Wall Clock 315.48371576s] Trained 64 records in 0.116777911 seconds. Throughput is 548.0488 records/second. Loss is 0.20417458. Sequential2290a28's hyper parameters: Current learning rate is 0.013197835554968985. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 44992/60000][Iteration 2579][Wall Clock 315.606569413s] Trained 64 records in 0.122853653 seconds. Throughput is 520.945 records/second. Loss is 0.2738157. Sequential2290a28's hyper parameters: Current learning rate is 0.013196093956188967. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 2580][Wall Clock 315.723951729s] Trained 64 records in 0.117382316 seconds. Throughput is 545.2269 records/second. Loss is 0.24648231. Sequential2290a28's hyper parameters: Current learning rate is 0.013194352816994326. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:58 INFO  DistriOptimizer$:408 - [Epoch 3 45120/60000][Iteration 2581][Wall Clock 315.81804365s] Trained 64 records in 0.094091921 seconds. Throughput is 680.1859 records/second. Loss is 0.37804455. Sequential2290a28's hyper parameters: Current learning rate is 0.013192612137203167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45184/60000][Iteration 2582][Wall Clock 315.93977892s] Trained 64 records in 0.12173527 seconds. Throughput is 525.73096 records/second. Loss is 0.14341596. Sequential2290a28's hyper parameters: Current learning rate is 0.01319087191663369. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45248/60000][Iteration 2583][Wall Clock 316.125639697s] Trained 64 records in 0.185860777 seconds. Throughput is 344.34375 records/second. Loss is 0.28683415. Sequential2290a28's hyper parameters: Current learning rate is 0.013189132155104194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 2584][Wall Clock 316.277123986s] Trained 64 records in 0.151484289 seconds. Throughput is 422.48605 records/second. Loss is 0.24278003. Sequential2290a28's hyper parameters: Current learning rate is 0.013187392852433075. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45376/60000][Iteration 2585][Wall Clock 316.421694111s] Trained 64 records in 0.144570125 seconds. Throughput is 442.69174 records/second. Loss is 0.0701033. Sequential2290a28's hyper parameters: Current learning rate is 0.013185654008438819. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45440/60000][Iteration 2586][Wall Clock 316.562557236s] Trained 64 records in 0.140863125 seconds. Throughput is 454.34177 records/second. Loss is 0.32199633. Sequential2290a28's hyper parameters: Current learning rate is 0.013183915622940015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45504/60000][Iteration 2587][Wall Clock 316.712970313s] Trained 64 records in 0.150413077 seconds. Throughput is 425.4949 records/second. Loss is 0.21859744. Sequential2290a28's hyper parameters: Current learning rate is 0.01318217769575534. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:18:59 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 2588][Wall Clock 316.786613008s] Trained 64 records in 0.073642695 seconds. Throughput is 869.0611 records/second. Loss is 0.16436324. Sequential2290a28's hyper parameters: Current learning rate is 0.013180440226703574. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 45632/60000][Iteration 2589][Wall Clock 316.937398827s] Trained 64 records in 0.150785819 seconds. Throughput is 424.44308 records/second. Loss is 0.2613928. Sequential2290a28's hyper parameters: Current learning rate is 0.013178703215603584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 45696/60000][Iteration 2590][Wall Clock 317.04874866s] Trained 64 records in 0.111349833 seconds. Throughput is 574.7651 records/second. Loss is 0.21685243. Sequential2290a28's hyper parameters: Current learning rate is 0.013176966662274345. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 45760/60000][Iteration 2591][Wall Clock 317.212006414s] Trained 64 records in 0.163257754 seconds. Throughput is 392.01816 records/second. Loss is 0.14563632. Sequential2290a28's hyper parameters: Current learning rate is 0.013175230566534914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 2592][Wall Clock 317.347953338s] Trained 64 records in 0.135946924 seconds. Throughput is 470.77194 records/second. Loss is 0.13618612. Sequential2290a28's hyper parameters: Current learning rate is 0.013173494928204453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 45888/60000][Iteration 2593][Wall Clock 317.51868586s] Trained 64 records in 0.170732522 seconds. Throughput is 374.85535 records/second. Loss is 0.23413298. Sequential2290a28's hyper parameters: Current learning rate is 0.013171759747102213. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 45952/60000][Iteration 2594][Wall Clock 317.631352449s] Trained 64 records in 0.112666589 seconds. Throughput is 568.0477 records/second. Loss is 0.21737744. Sequential2290a28's hyper parameters: Current learning rate is 0.013170025023047543. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:00 INFO  DistriOptimizer$:408 - [Epoch 3 46016/60000][Iteration 2595][Wall Clock 317.799500634s] Trained 64 records in 0.168148185 seconds. Throughput is 380.61664 records/second. Loss is 0.19205478. Sequential2290a28's hyper parameters: Current learning rate is 0.013168290755859888. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 2596][Wall Clock 318.002848224s] Trained 64 records in 0.20334759 seconds. Throughput is 314.73203 records/second. Loss is 0.31205705. Sequential2290a28's hyper parameters: Current learning rate is 0.013166556945358787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46144/60000][Iteration 2597][Wall Clock 318.097573703s] Trained 64 records in 0.094725479 seconds. Throughput is 675.6366 records/second. Loss is 0.10367081. Sequential2290a28's hyper parameters: Current learning rate is 0.013164823591363875. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46208/60000][Iteration 2598][Wall Clock 318.284660866s] Trained 64 records in 0.187087163 seconds. Throughput is 342.08655 records/second. Loss is 0.1738491. Sequential2290a28's hyper parameters: Current learning rate is 0.01316309069369488. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46272/60000][Iteration 2599][Wall Clock 318.398890962s] Trained 64 records in 0.114230096 seconds. Throughput is 560.27264 records/second. Loss is 0.2541358. Sequential2290a28's hyper parameters: Current learning rate is 0.013161358252171624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 2600][Wall Clock 318.528400479s] Trained 64 records in 0.129509517 seconds. Throughput is 494.17215 records/second. Loss is 0.16411658. Sequential2290a28's hyper parameters: Current learning rate is 0.013159626266614028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46400/60000][Iteration 2601][Wall Clock 318.659458125s] Trained 64 records in 0.131057646 seconds. Throughput is 488.33472 records/second. Loss is 0.16016665. Sequential2290a28's hyper parameters: Current learning rate is 0.013157894736842105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:01 INFO  DistriOptimizer$:408 - [Epoch 3 46464/60000][Iteration 2602][Wall Clock 318.784868692s] Trained 64 records in 0.125410567 seconds. Throughput is 510.3238 records/second. Loss is 0.16426805. Sequential2290a28's hyper parameters: Current learning rate is 0.013156163662675965. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46528/60000][Iteration 2603][Wall Clock 318.946883659s] Trained 64 records in 0.162014967 seconds. Throughput is 395.02524 records/second. Loss is 0.23310304. Sequential2290a28's hyper parameters: Current learning rate is 0.013154433043935806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 2604][Wall Clock 319.141302939s] Trained 64 records in 0.19441928 seconds. Throughput is 329.18546 records/second. Loss is 0.13277286. Sequential2290a28's hyper parameters: Current learning rate is 0.013152702880441932. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46656/60000][Iteration 2605][Wall Clock 319.251684734s] Trained 64 records in 0.110381795 seconds. Throughput is 579.8057 records/second. Loss is 0.1316324. Sequential2290a28's hyper parameters: Current learning rate is 0.01315097317201473. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46720/60000][Iteration 2606][Wall Clock 319.399171971s] Trained 64 records in 0.147487237 seconds. Throughput is 433.93585 records/second. Loss is 0.0930912. Sequential2290a28's hyper parameters: Current learning rate is 0.013149243918474688. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46784/60000][Iteration 2607][Wall Clock 319.510704666s] Trained 64 records in 0.111532695 seconds. Throughput is 573.82275 records/second. Loss is 0.20819113. Sequential2290a28's hyper parameters: Current learning rate is 0.013147515119642388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 2608][Wall Clock 319.599934104s] Trained 64 records in 0.089229438 seconds. Throughput is 717.25214 records/second. Loss is 0.16450846. Sequential2290a28's hyper parameters: Current learning rate is 0.013145786775338505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46912/60000][Iteration 2609][Wall Clock 319.719654407s] Trained 64 records in 0.119720303 seconds. Throughput is 534.57935 records/second. Loss is 0.15500158. Sequential2290a28's hyper parameters: Current learning rate is 0.013144058885383806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:02 INFO  DistriOptimizer$:408 - [Epoch 3 46976/60000][Iteration 2610][Wall Clock 319.832370814s] Trained 64 records in 0.112716407 seconds. Throughput is 567.7967 records/second. Loss is 0.15969431. Sequential2290a28's hyper parameters: Current learning rate is 0.013142331449599158. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47040/60000][Iteration 2611][Wall Clock 319.98855482s] Trained 64 records in 0.156184006 seconds. Throughput is 409.77307 records/second. Loss is 0.26843128. Sequential2290a28's hyper parameters: Current learning rate is 0.013140604467805518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 2612][Wall Clock 320.154885691s] Trained 64 records in 0.166330871 seconds. Throughput is 384.77524 records/second. Loss is 0.29676262. Sequential2290a28's hyper parameters: Current learning rate is 0.01313887793982394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47168/60000][Iteration 2613][Wall Clock 320.306239329s] Trained 64 records in 0.151353638 seconds. Throughput is 422.85074 records/second. Loss is 0.16541113. Sequential2290a28's hyper parameters: Current learning rate is 0.013137151865475566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47232/60000][Iteration 2614][Wall Clock 320.4579183s] Trained 64 records in 0.151678971 seconds. Throughput is 421.94382 records/second. Loss is 0.11856541. Sequential2290a28's hyper parameters: Current learning rate is 0.013135426244581635. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47296/60000][Iteration 2615][Wall Clock 320.647143491s] Trained 64 records in 0.189225191 seconds. Throughput is 338.22134 records/second. Loss is 0.24335459. Sequential2290a28's hyper parameters: Current learning rate is 0.013133701076963487. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 2616][Wall Clock 320.740295711s] Trained 64 records in 0.09315222 seconds. Throughput is 687.04755 records/second. Loss is 0.2042572. Sequential2290a28's hyper parameters: Current learning rate is 0.013131976362442547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:03 INFO  DistriOptimizer$:408 - [Epoch 3 47424/60000][Iteration 2617][Wall Clock 320.840739247s] Trained 64 records in 0.100443536 seconds. Throughput is 637.1739 records/second. Loss is 0.21349317. Sequential2290a28's hyper parameters: Current learning rate is 0.013130252100840336. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47488/60000][Iteration 2618][Wall Clock 320.944030979s] Trained 64 records in 0.103291732 seconds. Throughput is 619.60425 records/second. Loss is 0.08726637. Sequential2290a28's hyper parameters: Current learning rate is 0.01312852829197847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47552/60000][Iteration 2619][Wall Clock 321.121652241s] Trained 64 records in 0.177621262 seconds. Throughput is 360.31723 records/second. Loss is 0.245204. Sequential2290a28's hyper parameters: Current learning rate is 0.013126804935678655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 2620][Wall Clock 321.228143734s] Trained 64 records in 0.106491493 seconds. Throughput is 600.987 records/second. Loss is 0.13112973. Sequential2290a28's hyper parameters: Current learning rate is 0.013125082031762698. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47680/60000][Iteration 2621][Wall Clock 321.332280749s] Trained 64 records in 0.104137015 seconds. Throughput is 614.57495 records/second. Loss is 0.15663573. Sequential2290a28's hyper parameters: Current learning rate is 0.013123359580052493. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47744/60000][Iteration 2622][Wall Clock 321.434765236s] Trained 64 records in 0.102484487 seconds. Throughput is 624.48474 records/second. Loss is 0.2025563. Sequential2290a28's hyper parameters: Current learning rate is 0.01312163758037003. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47808/60000][Iteration 2623][Wall Clock 321.510478343s] Trained 64 records in 0.075713107 seconds. Throughput is 845.2962 records/second. Loss is 0.20593864. Sequential2290a28's hyper parameters: Current learning rate is 0.013119916032537392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 2624][Wall Clock 321.597642197s] Trained 64 records in 0.087163854 seconds. Throughput is 734.2493 records/second. Loss is 0.27683088. Sequential2290a28's hyper parameters: Current learning rate is 0.013118194936376755. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 47936/60000][Iteration 2625][Wall Clock 321.688866336s] Trained 64 records in 0.091224139 seconds. Throughput is 701.56866 records/second. Loss is 0.16815574. Sequential2290a28's hyper parameters: Current learning rate is 0.01311647429171039. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 48000/60000][Iteration 2626][Wall Clock 321.800315159s] Trained 64 records in 0.111448823 seconds. Throughput is 574.2546 records/second. Loss is 0.22687986. Sequential2290a28's hyper parameters: Current learning rate is 0.013114754098360657. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:04 INFO  DistriOptimizer$:408 - [Epoch 3 48064/60000][Iteration 2627][Wall Clock 321.908283506s] Trained 64 records in 0.107968347 seconds. Throughput is 592.76636 records/second. Loss is 0.17272027. Sequential2290a28's hyper parameters: Current learning rate is 0.013113034356150015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:05 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 2628][Wall Clock 322.069296611s] Trained 64 records in 0.161013105 seconds. Throughput is 397.48315 records/second. Loss is 0.1734806. Sequential2290a28's hyper parameters: Current learning rate is 0.013111315064901012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:05 INFO  DistriOptimizer$:408 - [Epoch 3 48192/60000][Iteration 2629][Wall Clock 322.244462555s] Trained 64 records in 0.175165944 seconds. Throughput is 365.3678 records/second. Loss is 0.14727694. Sequential2290a28's hyper parameters: Current learning rate is 0.013109596224436287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:05 INFO  DistriOptimizer$:408 - [Epoch 3 48256/60000][Iteration 2630][Wall Clock 322.399733625s] Trained 64 records in 0.15527107 seconds. Throughput is 412.1824 records/second. Loss is 0.22694999. Sequential2290a28's hyper parameters: Current learning rate is 0.013107877834578582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:05 INFO  DistriOptimizer$:408 - [Epoch 3 48320/60000][Iteration 2631][Wall Clock 322.565835759s] Trained 64 records in 0.166102134 seconds. Throughput is 385.30508 records/second. Loss is 0.17267203. Sequential2290a28's hyper parameters: Current learning rate is 0.01310615989515072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:05 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 2632][Wall Clock 322.756709504s] Trained 64 records in 0.190873745 seconds. Throughput is 335.30017 records/second. Loss is 0.23740056. Sequential2290a28's hyper parameters: Current learning rate is 0.013104442405975626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:05 INFO  DistriOptimizer$:408 - [Epoch 3 48448/60000][Iteration 2633][Wall Clock 322.893407197s] Trained 64 records in 0.136697693 seconds. Throughput is 468.1864 records/second. Loss is 0.22199754. Sequential2290a28's hyper parameters: Current learning rate is 0.013102725366876311. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48512/60000][Iteration 2634][Wall Clock 323.040315047s] Trained 64 records in 0.14690785 seconds. Throughput is 435.64725 records/second. Loss is 0.23755392. Sequential2290a28's hyper parameters: Current learning rate is 0.01310100877767588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48576/60000][Iteration 2635][Wall Clock 323.172307278s] Trained 64 records in 0.131992231 seconds. Throughput is 484.877 records/second. Loss is 0.24729767. Sequential2290a28's hyper parameters: Current learning rate is 0.013099292638197537. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 2636][Wall Clock 323.287664062s] Trained 64 records in 0.115356784 seconds. Throughput is 554.8005 records/second. Loss is 0.30585912. Sequential2290a28's hyper parameters: Current learning rate is 0.01309757694826457. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48704/60000][Iteration 2637][Wall Clock 323.445072168s] Trained 64 records in 0.157408106 seconds. Throughput is 406.58643 records/second. Loss is 0.16757098. Sequential2290a28's hyper parameters: Current learning rate is 0.013095861707700366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48768/60000][Iteration 2638][Wall Clock 323.554835573s] Trained 64 records in 0.109763405 seconds. Throughput is 583.07227 records/second. Loss is 0.13455048. Sequential2290a28's hyper parameters: Current learning rate is 0.013094146916328401. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48832/60000][Iteration 2639][Wall Clock 323.646536047s] Trained 64 records in 0.091700474 seconds. Throughput is 697.92444 records/second. Loss is 0.08127097. Sequential2290a28's hyper parameters: Current learning rate is 0.013092432573972244. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 2640][Wall Clock 323.736079793s] Trained 64 records in 0.089543746 seconds. Throughput is 714.73444 records/second. Loss is 0.1884866. Sequential2290a28's hyper parameters: Current learning rate is 0.013090718680455558. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:06 INFO  DistriOptimizer$:408 - [Epoch 3 48960/60000][Iteration 2641][Wall Clock 323.818929646s] Trained 64 records in 0.082849853 seconds. Throughput is 772.48175 records/second. Loss is 0.13988808. Sequential2290a28's hyper parameters: Current learning rate is 0.013089005235602094. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49024/60000][Iteration 2642][Wall Clock 323.904233857s] Trained 64 records in 0.085304211 seconds. Throughput is 750.25604 records/second. Loss is 0.23734704. Sequential2290a28's hyper parameters: Current learning rate is 0.013087292239235703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49088/60000][Iteration 2643][Wall Clock 324.00657687s] Trained 64 records in 0.102343013 seconds. Throughput is 625.348 records/second. Loss is 0.12553087. Sequential2290a28's hyper parameters: Current learning rate is 0.01308557969118032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 2644][Wall Clock 324.124237537s] Trained 64 records in 0.117660667 seconds. Throughput is 543.9371 records/second. Loss is 0.26039815. Sequential2290a28's hyper parameters: Current learning rate is 0.013083867591259978. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49216/60000][Iteration 2645][Wall Clock 324.261378284s] Trained 64 records in 0.137140747 seconds. Throughput is 466.67383 records/second. Loss is 0.12421523. Sequential2290a28's hyper parameters: Current learning rate is 0.013082155939298797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49280/60000][Iteration 2646][Wall Clock 324.398350657s] Trained 64 records in 0.136972373 seconds. Throughput is 467.24753 records/second. Loss is 0.16167004. Sequential2290a28's hyper parameters: Current learning rate is 0.013080444735120995. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49344/60000][Iteration 2647][Wall Clock 324.510961478s] Trained 64 records in 0.112610821 seconds. Throughput is 568.32904 records/second. Loss is 0.1173732. Sequential2290a28's hyper parameters: Current learning rate is 0.013078733978550878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 2648][Wall Clock 324.613193989s] Trained 64 records in 0.102232511 seconds. Throughput is 626.024 records/second. Loss is 0.21749017. Sequential2290a28's hyper parameters: Current learning rate is 0.013077023669412843. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49472/60000][Iteration 2649][Wall Clock 324.704775293s] Trained 64 records in 0.091581304 seconds. Throughput is 698.8326 records/second. Loss is 0.20953655. Sequential2290a28's hyper parameters: Current learning rate is 0.01307531380753138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:07 INFO  DistriOptimizer$:408 - [Epoch 3 49536/60000][Iteration 2650][Wall Clock 324.842971537s] Trained 64 records in 0.138196244 seconds. Throughput is 463.10956 records/second. Loss is 0.13384202. Sequential2290a28's hyper parameters: Current learning rate is 0.013073604392731076. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49600/60000][Iteration 2651][Wall Clock 324.922337766s] Trained 64 records in 0.079366229 seconds. Throughput is 806.3883 records/second. Loss is 0.3583122. Sequential2290a28's hyper parameters: Current learning rate is 0.013071895424836602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 2652][Wall Clock 325.071155953s] Trained 64 records in 0.148818187 seconds. Throughput is 430.055 records/second. Loss is 0.22846158. Sequential2290a28's hyper parameters: Current learning rate is 0.013070186903672723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49728/60000][Iteration 2653][Wall Clock 325.186636332s] Trained 64 records in 0.115480379 seconds. Throughput is 554.2067 records/second. Loss is 0.12985092. Sequential2290a28's hyper parameters: Current learning rate is 0.013068478829064298. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49792/60000][Iteration 2654][Wall Clock 325.347910435s] Trained 64 records in 0.161274103 seconds. Throughput is 396.8399 records/second. Loss is 0.08031255. Sequential2290a28's hyper parameters: Current learning rate is 0.013066771200836273. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49856/60000][Iteration 2655][Wall Clock 325.435962197s] Trained 64 records in 0.088051762 seconds. Throughput is 726.8452 records/second. Loss is 0.14136866. Sequential2290a28's hyper parameters: Current learning rate is 0.013065064018813691. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 2656][Wall Clock 325.507296622s] Trained 64 records in 0.071334425 seconds. Throughput is 897.18256 records/second. Loss is 0.24669412. Sequential2290a28's hyper parameters: Current learning rate is 0.013063357282821684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 49984/60000][Iteration 2657][Wall Clock 325.57343785s] Trained 64 records in 0.066141228 seconds. Throughput is 967.62646 records/second. Loss is 0.11844915. Sequential2290a28's hyper parameters: Current learning rate is 0.013061650992685475. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 50048/60000][Iteration 2658][Wall Clock 325.668609626s] Trained 64 records in 0.095171776 seconds. Throughput is 672.46826 records/second. Loss is 0.15063265. Sequential2290a28's hyper parameters: Current learning rate is 0.013059945148230378. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 50112/60000][Iteration 2659][Wall Clock 325.760602207s] Trained 64 records in 0.091992581 seconds. Throughput is 695.7083 records/second. Loss is 0.19459929. Sequential2290a28's hyper parameters: Current learning rate is 0.013058239749281797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:08 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 2660][Wall Clock 325.877220158s] Trained 64 records in 0.116617951 seconds. Throughput is 548.8006 records/second. Loss is 0.19398865. Sequential2290a28's hyper parameters: Current learning rate is 0.01305653479566523. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:09 INFO  DistriOptimizer$:408 - [Epoch 3 50240/60000][Iteration 2661][Wall Clock 326.084558204s] Trained 64 records in 0.207338046 seconds. Throughput is 308.67465 records/second. Loss is 0.0994666. Sequential2290a28's hyper parameters: Current learning rate is 0.013054830287206266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:09 INFO  DistriOptimizer$:408 - [Epoch 3 50304/60000][Iteration 2662][Wall Clock 326.237618672s] Trained 64 records in 0.153060468 seconds. Throughput is 418.1354 records/second. Loss is 0.24202563. Sequential2290a28's hyper parameters: Current learning rate is 0.013053126223730584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:09 INFO  DistriOptimizer$:408 - [Epoch 3 50368/60000][Iteration 2663][Wall Clock 326.49980043s] Trained 64 records in 0.262181758 seconds. Throughput is 244.10547 records/second. Loss is 0.15745895. Sequential2290a28's hyper parameters: Current learning rate is 0.013051422605063952. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:09 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 2664][Wall Clock 326.662513136s] Trained 64 records in 0.162712706 seconds. Throughput is 393.3313 records/second. Loss is 0.18843864. Sequential2290a28's hyper parameters: Current learning rate is 0.013049719431032234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:09 INFO  DistriOptimizer$:408 - [Epoch 3 50496/60000][Iteration 2665][Wall Clock 326.884533364s] Trained 64 records in 0.222020228 seconds. Throughput is 288.26202 records/second. Loss is 0.16810767. Sequential2290a28's hyper parameters: Current learning rate is 0.01304801670146138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50560/60000][Iteration 2666][Wall Clock 327.042414967s] Trained 64 records in 0.157881603 seconds. Throughput is 405.36707 records/second. Loss is 0.1894232. Sequential2290a28's hyper parameters: Current learning rate is 0.013046314416177431. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50624/60000][Iteration 2667][Wall Clock 327.152544163s] Trained 64 records in 0.110129196 seconds. Throughput is 581.1357 records/second. Loss is 0.10550329. Sequential2290a28's hyper parameters: Current learning rate is 0.013044612575006524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 2668][Wall Clock 327.31384773s] Trained 64 records in 0.161303567 seconds. Throughput is 396.76743 records/second. Loss is 0.17359449. Sequential2290a28's hyper parameters: Current learning rate is 0.01304291117777488. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50752/60000][Iteration 2669][Wall Clock 327.460820724s] Trained 64 records in 0.146972994 seconds. Throughput is 435.45413 records/second. Loss is 0.23584707. Sequential2290a28's hyper parameters: Current learning rate is 0.013041210224308816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50816/60000][Iteration 2670][Wall Clock 327.591555334s] Trained 64 records in 0.13073461 seconds. Throughput is 489.54138 records/second. Loss is 0.20326886. Sequential2290a28's hyper parameters: Current learning rate is 0.013039509714434737. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50880/60000][Iteration 2671][Wall Clock 327.696778044s] Trained 64 records in 0.10522271 seconds. Throughput is 608.2337 records/second. Loss is 0.2029786. Sequential2290a28's hyper parameters: Current learning rate is 0.01303780964797914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:10 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 2672][Wall Clock 327.803188224s] Trained 64 records in 0.10641018 seconds. Throughput is 601.4462 records/second. Loss is 0.095272645. Sequential2290a28's hyper parameters: Current learning rate is 0.013036110024768609. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:11 INFO  DistriOptimizer$:408 - [Epoch 3 51008/60000][Iteration 2673][Wall Clock 327.952063342s] Trained 64 records in 0.148875118 seconds. Throughput is 429.8905 records/second. Loss is 0.17754938. Sequential2290a28's hyper parameters: Current learning rate is 0.013034410844629822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:11 INFO  DistriOptimizer$:408 - [Epoch 3 51072/60000][Iteration 2674][Wall Clock 328.067160037s] Trained 64 records in 0.115096695 seconds. Throughput is 556.0542 records/second. Loss is 0.12554185. Sequential2290a28's hyper parameters: Current learning rate is 0.013032712107389547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:11 INFO  DistriOptimizer$:408 - [Epoch 3 51136/60000][Iteration 2675][Wall Clock 328.235418215s] Trained 64 records in 0.168258178 seconds. Throughput is 380.36786 records/second. Loss is 0.13961968. Sequential2290a28's hyper parameters: Current learning rate is 0.01303101381287464. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:11 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 2676][Wall Clock 328.436642697s] Trained 64 records in 0.201224482 seconds. Throughput is 318.05276 records/second. Loss is 0.21554844. Sequential2290a28's hyper parameters: Current learning rate is 0.013029315960912051. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:11 INFO  DistriOptimizer$:408 - [Epoch 3 51264/60000][Iteration 2677][Wall Clock 328.562942459s] Trained 64 records in 0.126299762 seconds. Throughput is 506.73093 records/second. Loss is 0.26474118. Sequential2290a28's hyper parameters: Current learning rate is 0.013027618551328817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:11 INFO  DistriOptimizer$:408 - [Epoch 3 51328/60000][Iteration 2678][Wall Clock 328.717514868s] Trained 64 records in 0.154572409 seconds. Throughput is 414.0454 records/second. Loss is 0.21308582. Sequential2290a28's hyper parameters: Current learning rate is 0.013025921583952065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51392/60000][Iteration 2679][Wall Clock 328.879299806s] Trained 64 records in 0.161784938 seconds. Throughput is 395.5869 records/second. Loss is 0.33389196. Sequential2290a28's hyper parameters: Current learning rate is 0.013024225058609012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 2680][Wall Clock 329.048887387s] Trained 64 records in 0.169587581 seconds. Throughput is 377.3861 records/second. Loss is 0.29214472. Sequential2290a28's hyper parameters: Current learning rate is 0.013022528975126969. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51520/60000][Iteration 2681][Wall Clock 329.254207927s] Trained 64 records in 0.20532054 seconds. Throughput is 311.70773 records/second. Loss is 0.2191502. Sequential2290a28's hyper parameters: Current learning rate is 0.013020833333333334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51584/60000][Iteration 2682][Wall Clock 329.399573432s] Trained 64 records in 0.145365505 seconds. Throughput is 440.2695 records/second. Loss is 0.19582267. Sequential2290a28's hyper parameters: Current learning rate is 0.013019138133055592. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51648/60000][Iteration 2683][Wall Clock 329.540735s] Trained 64 records in 0.141161568 seconds. Throughput is 453.38123 records/second. Loss is 0.11044473. Sequential2290a28's hyper parameters: Current learning rate is 0.013017443374121323. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 2684][Wall Clock 329.690908506s] Trained 64 records in 0.150173506 seconds. Throughput is 426.17374 records/second. Loss is 0.11861577. Sequential2290a28's hyper parameters: Current learning rate is 0.013015749056358194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:12 INFO  DistriOptimizer$:408 - [Epoch 3 51776/60000][Iteration 2685][Wall Clock 329.808580438s] Trained 64 records in 0.117671932 seconds. Throughput is 543.885 records/second. Loss is 0.21631609. Sequential2290a28's hyper parameters: Current learning rate is 0.013014055179593963. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 51840/60000][Iteration 2686][Wall Clock 329.908112327s] Trained 64 records in 0.099531889 seconds. Throughput is 643.01 records/second. Loss is 0.19270797. Sequential2290a28's hyper parameters: Current learning rate is 0.013012361743656475. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 51904/60000][Iteration 2687][Wall Clock 330.023306729s] Trained 64 records in 0.115194402 seconds. Throughput is 555.5826 records/second. Loss is 0.18502787. Sequential2290a28's hyper parameters: Current learning rate is 0.013010668748373668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 2688][Wall Clock 330.151499623s] Trained 64 records in 0.128192894 seconds. Throughput is 499.24768 records/second. Loss is 0.08141752. Sequential2290a28's hyper parameters: Current learning rate is 0.013008976193573567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 52032/60000][Iteration 2689][Wall Clock 330.383349882s] Trained 64 records in 0.231850259 seconds. Throughput is 276.04025 records/second. Loss is 0.22554554. Sequential2290a28's hyper parameters: Current learning rate is 0.013007284079084287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 52096/60000][Iteration 2690][Wall Clock 330.586020852s] Trained 64 records in 0.20267097 seconds. Throughput is 315.78275 records/second. Loss is 0.36454982. Sequential2290a28's hyper parameters: Current learning rate is 0.013005592404734036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 52160/60000][Iteration 2691][Wall Clock 330.693392077s] Trained 64 records in 0.107371225 seconds. Throughput is 596.06287 records/second. Loss is 0.3117263. Sequential2290a28's hyper parameters: Current learning rate is 0.013003901170351105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:13 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 2692][Wall Clock 330.800839678s] Trained 64 records in 0.107447601 seconds. Throughput is 595.63916 records/second. Loss is 0.29467645. Sequential2290a28's hyper parameters: Current learning rate is 0.01300221037576388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52288/60000][Iteration 2693][Wall Clock 330.928185791s] Trained 64 records in 0.127346113 seconds. Throughput is 502.56735 records/second. Loss is 0.20774207. Sequential2290a28's hyper parameters: Current learning rate is 0.013000520020800833. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52352/60000][Iteration 2694][Wall Clock 331.032712472s] Trained 64 records in 0.104526681 seconds. Throughput is 612.2839 records/second. Loss is 0.15326124. Sequential2290a28's hyper parameters: Current learning rate is 0.012998830105290522. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52416/60000][Iteration 2695][Wall Clock 331.12119525s] Trained 64 records in 0.088482778 seconds. Throughput is 723.3046 records/second. Loss is 0.21681769. Sequential2290a28's hyper parameters: Current learning rate is 0.012997140629061606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 2696][Wall Clock 331.216176774s] Trained 64 records in 0.094981524 seconds. Throughput is 673.81525 records/second. Loss is 0.19181131. Sequential2290a28's hyper parameters: Current learning rate is 0.01299545159194282. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52544/60000][Iteration 2697][Wall Clock 331.294128709s] Trained 64 records in 0.077951935 seconds. Throughput is 821.01874 records/second. Loss is 0.17625724. Sequential2290a28's hyper parameters: Current learning rate is 0.012993762993762993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52608/60000][Iteration 2698][Wall Clock 331.400000934s] Trained 64 records in 0.105872225 seconds. Throughput is 604.50226 records/second. Loss is 0.18350095. Sequential2290a28's hyper parameters: Current learning rate is 0.012992074834351046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52672/60000][Iteration 2699][Wall Clock 331.494560473s] Trained 64 records in 0.094559539 seconds. Throughput is 676.82227 records/second. Loss is 0.22067073. Sequential2290a28's hyper parameters: Current learning rate is 0.012990387113535984. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 2700][Wall Clock 331.610124868s] Trained 64 records in 0.115564395 seconds. Throughput is 553.8038 records/second. Loss is 0.13288173. Sequential2290a28's hyper parameters: Current learning rate is 0.012988699831146902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52800/60000][Iteration 2701][Wall Clock 331.691498839s] Trained 64 records in 0.081373971 seconds. Throughput is 786.49225 records/second. Loss is 0.2297265. Sequential2290a28's hyper parameters: Current learning rate is 0.012987012987012986. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:14 INFO  DistriOptimizer$:408 - [Epoch 3 52864/60000][Iteration 2702][Wall Clock 331.775114973s] Trained 64 records in 0.083616134 seconds. Throughput is 765.40247 records/second. Loss is 0.14970273. Sequential2290a28's hyper parameters: Current learning rate is 0.012985326580963512. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 52928/60000][Iteration 2703][Wall Clock 331.954624724s] Trained 64 records in 0.179509751 seconds. Throughput is 356.5266 records/second. Loss is 0.05438622. Sequential2290a28's hyper parameters: Current learning rate is 0.012983640612827837. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 2704][Wall Clock 332.075200861s] Trained 64 records in 0.120576137 seconds. Throughput is 530.785 records/second. Loss is 0.21992725. Sequential2290a28's hyper parameters: Current learning rate is 0.012981955082435416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 53056/60000][Iteration 2705][Wall Clock 332.18950168s] Trained 64 records in 0.114300819 seconds. Throughput is 559.926 records/second. Loss is 0.22667778. Sequential2290a28's hyper parameters: Current learning rate is 0.012980269989615784. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 53120/60000][Iteration 2706][Wall Clock 332.313855262s] Trained 64 records in 0.124353582 seconds. Throughput is 514.6615 records/second. Loss is 0.282243. Sequential2290a28's hyper parameters: Current learning rate is 0.012978585334198572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 53184/60000][Iteration 2707][Wall Clock 332.438398676s] Trained 64 records in 0.124543414 seconds. Throughput is 513.877 records/second. Loss is 0.19422911. Sequential2290a28's hyper parameters: Current learning rate is 0.012976901116013496. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 2708][Wall Clock 332.609245082s] Trained 64 records in 0.170846406 seconds. Throughput is 374.6055 records/second. Loss is 0.2218292. Sequential2290a28's hyper parameters: Current learning rate is 0.012975217334890361. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:15 INFO  DistriOptimizer$:408 - [Epoch 3 53312/60000][Iteration 2709][Wall Clock 332.735268769s] Trained 64 records in 0.126023687 seconds. Throughput is 507.84106 records/second. Loss is 0.094130985. Sequential2290a28's hyper parameters: Current learning rate is 0.012973533990659055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53376/60000][Iteration 2710][Wall Clock 332.878899713s] Trained 64 records in 0.143630944 seconds. Throughput is 445.58646 records/second. Loss is 0.31927517. Sequential2290a28's hyper parameters: Current learning rate is 0.012971851083149565. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53440/60000][Iteration 2711][Wall Clock 333.029553834s] Trained 64 records in 0.150654121 seconds. Throughput is 424.81412 records/second. Loss is 0.2957983. Sequential2290a28's hyper parameters: Current learning rate is 0.01297016861219196. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 2712][Wall Clock 333.212274912s] Trained 64 records in 0.182721078 seconds. Throughput is 350.26062 records/second. Loss is 0.14734954. Sequential2290a28's hyper parameters: Current learning rate is 0.012968486577616392. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53568/60000][Iteration 2713][Wall Clock 333.334367205s] Trained 64 records in 0.122092293 seconds. Throughput is 524.1936 records/second. Loss is 0.1723701. Sequential2290a28's hyper parameters: Current learning rate is 0.012966804979253113. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53632/60000][Iteration 2714][Wall Clock 333.421404316s] Trained 64 records in 0.087037111 seconds. Throughput is 735.31854 records/second. Loss is 0.16173531. Sequential2290a28's hyper parameters: Current learning rate is 0.012965123816932453. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53696/60000][Iteration 2715][Wall Clock 333.538018662s] Trained 64 records in 0.116614346 seconds. Throughput is 548.81757 records/second. Loss is 0.17896175. Sequential2290a28's hyper parameters: Current learning rate is 0.012963443090484831. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 2716][Wall Clock 333.62342845s] Trained 64 records in 0.085409788 seconds. Throughput is 749.3286 records/second. Loss is 0.4927952. Sequential2290a28's hyper parameters: Current learning rate is 0.012961762799740763. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:16 INFO  DistriOptimizer$:408 - [Epoch 3 53824/60000][Iteration 2717][Wall Clock 333.738792151s] Trained 64 records in 0.115363701 seconds. Throughput is 554.7672 records/second. Loss is 0.12833187. Sequential2290a28's hyper parameters: Current learning rate is 0.012960082944530844. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 53888/60000][Iteration 2718][Wall Clock 333.878158213s] Trained 64 records in 0.139366062 seconds. Throughput is 459.2223 records/second. Loss is 0.101221845. Sequential2290a28's hyper parameters: Current learning rate is 0.012958403524685759. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 53952/60000][Iteration 2719][Wall Clock 333.971682097s] Trained 64 records in 0.093523884 seconds. Throughput is 684.3172 records/second. Loss is 0.22101894. Sequential2290a28's hyper parameters: Current learning rate is 0.012956724540036279. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 2720][Wall Clock 334.079780176s] Trained 64 records in 0.108098079 seconds. Throughput is 592.05493 records/second. Loss is 0.19775873. Sequential2290a28's hyper parameters: Current learning rate is 0.012955045990413265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54080/60000][Iteration 2721][Wall Clock 334.167746566s] Trained 64 records in 0.08796639 seconds. Throughput is 727.5506 records/second. Loss is 0.15763567. Sequential2290a28's hyper parameters: Current learning rate is 0.012953367875647668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54144/60000][Iteration 2722][Wall Clock 334.24324101s] Trained 64 records in 0.075494444 seconds. Throughput is 847.7445 records/second. Loss is 0.107890986. Sequential2290a28's hyper parameters: Current learning rate is 0.012951690195570522. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54208/60000][Iteration 2723][Wall Clock 334.317469667s] Trained 64 records in 0.074228657 seconds. Throughput is 862.2007 records/second. Loss is 0.14827387. Sequential2290a28's hyper parameters: Current learning rate is 0.01295001295001295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 2724][Wall Clock 334.419076425s] Trained 64 records in 0.101606758 seconds. Throughput is 629.8794 records/second. Loss is 0.10540833. Sequential2290a28's hyper parameters: Current learning rate is 0.012948336138806164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54336/60000][Iteration 2725][Wall Clock 334.522827188s] Trained 64 records in 0.103750763 seconds. Throughput is 616.8629 records/second. Loss is 0.20686519. Sequential2290a28's hyper parameters: Current learning rate is 0.012946659761781462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54400/60000][Iteration 2726][Wall Clock 334.60047408s] Trained 64 records in 0.077646892 seconds. Throughput is 824.2442 records/second. Loss is 0.23413393. Sequential2290a28's hyper parameters: Current learning rate is 0.012944983818770227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54464/60000][Iteration 2727][Wall Clock 334.776544652s] Trained 64 records in 0.176070572 seconds. Throughput is 363.4906 records/second. Loss is 0.28714365. Sequential2290a28's hyper parameters: Current learning rate is 0.012943308309603935. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:17 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 2728][Wall Clock 334.85190068s] Trained 64 records in 0.075356028 seconds. Throughput is 849.30164 records/second. Loss is 0.1318371. Sequential2290a28's hyper parameters: Current learning rate is 0.012941633234114146. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54592/60000][Iteration 2729][Wall Clock 335.038612764s] Trained 64 records in 0.186712084 seconds. Throughput is 342.77374 records/second. Loss is 0.3077754. Sequential2290a28's hyper parameters: Current learning rate is 0.012939958592132506. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54656/60000][Iteration 2730][Wall Clock 335.16337725s] Trained 64 records in 0.124764486 seconds. Throughput is 512.9665 records/second. Loss is 0.09889976. Sequential2290a28's hyper parameters: Current learning rate is 0.012938284383490749. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54720/60000][Iteration 2731][Wall Clock 335.266570368s] Trained 64 records in 0.103193118 seconds. Throughput is 620.1964 records/second. Loss is 0.20835322. Sequential2290a28's hyper parameters: Current learning rate is 0.0129366106080207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 2732][Wall Clock 335.372068886s] Trained 64 records in 0.105498518 seconds. Throughput is 606.6436 records/second. Loss is 0.27509925. Sequential2290a28's hyper parameters: Current learning rate is 0.012934937265554261. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54848/60000][Iteration 2733][Wall Clock 335.467259939s] Trained 64 records in 0.095191053 seconds. Throughput is 672.3321 records/second. Loss is 0.32164872. Sequential2290a28's hyper parameters: Current learning rate is 0.012933264355923435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54912/60000][Iteration 2734][Wall Clock 335.570133731s] Trained 64 records in 0.102873792 seconds. Throughput is 622.1215 records/second. Loss is 0.18844193. Sequential2290a28's hyper parameters: Current learning rate is 0.012931591878960301. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 54976/60000][Iteration 2735][Wall Clock 335.67663196s] Trained 64 records in 0.106498229 seconds. Throughput is 600.949 records/second. Loss is 0.21934523. Sequential2290a28's hyper parameters: Current learning rate is 0.012929919834497025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:18 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 2736][Wall Clock 335.793075832s] Trained 64 records in 0.116443872 seconds. Throughput is 549.62103 records/second. Loss is 0.2291076. Sequential2290a28's hyper parameters: Current learning rate is 0.012928248222365869. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55104/60000][Iteration 2737][Wall Clock 335.911270328s] Trained 64 records in 0.118194496 seconds. Throughput is 541.48035 records/second. Loss is 0.18693787. Sequential2290a28's hyper parameters: Current learning rate is 0.012926577042399173. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55168/60000][Iteration 2738][Wall Clock 336.028539502s] Trained 64 records in 0.117269174 seconds. Throughput is 545.753 records/second. Loss is 0.23110703. Sequential2290a28's hyper parameters: Current learning rate is 0.012924906294429364. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55232/60000][Iteration 2739][Wall Clock 336.139407204s] Trained 64 records in 0.110867702 seconds. Throughput is 577.2646 records/second. Loss is 0.16468932. Sequential2290a28's hyper parameters: Current learning rate is 0.012923235978288964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 2740][Wall Clock 336.237127265s] Trained 64 records in 0.097720061 seconds. Throughput is 654.932 records/second. Loss is 0.23591751. Sequential2290a28's hyper parameters: Current learning rate is 0.01292156609381057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55360/60000][Iteration 2741][Wall Clock 336.37837964s] Trained 64 records in 0.141252375 seconds. Throughput is 453.08975 records/second. Loss is 0.1817761. Sequential2290a28's hyper parameters: Current learning rate is 0.012919896640826873. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55424/60000][Iteration 2742][Wall Clock 336.508642173s] Trained 64 records in 0.130262533 seconds. Throughput is 491.31546 records/second. Loss is 0.06975794. Sequential2290a28's hyper parameters: Current learning rate is 0.01291822761917065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55488/60000][Iteration 2743][Wall Clock 336.639849787s] Trained 64 records in 0.131207614 seconds. Throughput is 487.77658 records/second. Loss is 0.19815066. Sequential2290a28's hyper parameters: Current learning rate is 0.012916559028674762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:19 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 2744][Wall Clock 336.760705187s] Trained 64 records in 0.1208554 seconds. Throughput is 529.5585 records/second. Loss is 0.23795113. Sequential2290a28's hyper parameters: Current learning rate is 0.012914890869172156. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 55616/60000][Iteration 2745][Wall Clock 336.872613611s] Trained 64 records in 0.111908424 seconds. Throughput is 571.8962 records/second. Loss is 0.198502. Sequential2290a28's hyper parameters: Current learning rate is 0.012913223140495868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 55680/60000][Iteration 2746][Wall Clock 336.986822656s] Trained 64 records in 0.114209045 seconds. Throughput is 560.3759 records/second. Loss is 0.21893132. Sequential2290a28's hyper parameters: Current learning rate is 0.012911555842479019. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 55744/60000][Iteration 2747][Wall Clock 337.107853758s] Trained 64 records in 0.121031102 seconds. Throughput is 528.7897 records/second. Loss is 0.3206131. Sequential2290a28's hyper parameters: Current learning rate is 0.012909888974954816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 2748][Wall Clock 337.207205174s] Trained 64 records in 0.099351416 seconds. Throughput is 644.17804 records/second. Loss is 0.17540343. Sequential2290a28's hyper parameters: Current learning rate is 0.012908222537756552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 55872/60000][Iteration 2749][Wall Clock 337.308210822s] Trained 64 records in 0.101005648 seconds. Throughput is 633.6279 records/second. Loss is 0.17042606. Sequential2290a28's hyper parameters: Current learning rate is 0.012906556530717607. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 55936/60000][Iteration 2750][Wall Clock 337.426630162s] Trained 64 records in 0.11841934 seconds. Throughput is 540.4523 records/second. Loss is 0.24166447. Sequential2290a28's hyper parameters: Current learning rate is 0.012904890953671441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 56000/60000][Iteration 2751][Wall Clock 337.53868162s] Trained 64 records in 0.112051458 seconds. Throughput is 571.16614 records/second. Loss is 0.12193318. Sequential2290a28's hyper parameters: Current learning rate is 0.012903225806451613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:20 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 2752][Wall Clock 337.642768316s] Trained 64 records in 0.104086696 seconds. Throughput is 614.8721 records/second. Loss is 0.18449947. Sequential2290a28's hyper parameters: Current learning rate is 0.012901561088891756. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56128/60000][Iteration 2753][Wall Clock 337.832471267s] Trained 64 records in 0.189702951 seconds. Throughput is 337.36954 records/second. Loss is 0.1320155. Sequential2290a28's hyper parameters: Current learning rate is 0.012899896800825594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56192/60000][Iteration 2754][Wall Clock 338.024052343s] Trained 64 records in 0.191581076 seconds. Throughput is 334.06223 records/second. Loss is 0.12943964. Sequential2290a28's hyper parameters: Current learning rate is 0.012898232942086935. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56256/60000][Iteration 2755][Wall Clock 338.137104656s] Trained 64 records in 0.113052313 seconds. Throughput is 566.10956 records/second. Loss is 0.17409152. Sequential2290a28's hyper parameters: Current learning rate is 0.012896569512509672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 2756][Wall Clock 338.25356265s] Trained 64 records in 0.116457994 seconds. Throughput is 549.5544 records/second. Loss is 0.104850344. Sequential2290a28's hyper parameters: Current learning rate is 0.012894906511927788. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56384/60000][Iteration 2757][Wall Clock 338.35188337s] Trained 64 records in 0.09832072 seconds. Throughput is 650.9309 records/second. Loss is 0.23847635. Sequential2290a28's hyper parameters: Current learning rate is 0.012893243940175348. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56448/60000][Iteration 2758][Wall Clock 338.456598844s] Trained 64 records in 0.104715474 seconds. Throughput is 611.18 records/second. Loss is 0.23700821. Sequential2290a28's hyper parameters: Current learning rate is 0.012891581797086502. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56512/60000][Iteration 2759][Wall Clock 338.58303943s] Trained 64 records in 0.126440586 seconds. Throughput is 506.1666 records/second. Loss is 0.1881875. Sequential2290a28's hyper parameters: Current learning rate is 0.012889920082495489. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 2760][Wall Clock 338.71203317s] Trained 64 records in 0.12899374 seconds. Throughput is 496.14813 records/second. Loss is 0.28090227. Sequential2290a28's hyper parameters: Current learning rate is 0.012888258796236628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:21 INFO  DistriOptimizer$:408 - [Epoch 3 56640/60000][Iteration 2761][Wall Clock 338.816598368s] Trained 64 records in 0.104565198 seconds. Throughput is 612.05835 records/second. Loss is 0.13176644. Sequential2290a28's hyper parameters: Current learning rate is 0.01288659793814433. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 56704/60000][Iteration 2762][Wall Clock 338.901735871s] Trained 64 records in 0.085137503 seconds. Throughput is 751.72516 records/second. Loss is 0.23731765. Sequential2290a28's hyper parameters: Current learning rate is 0.012884937508053087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 56768/60000][Iteration 2763][Wall Clock 339.026506565s] Trained 64 records in 0.124770694 seconds. Throughput is 512.941 records/second. Loss is 0.12976971. Sequential2290a28's hyper parameters: Current learning rate is 0.012883277505797475. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 2764][Wall Clock 339.122850314s] Trained 64 records in 0.096343749 seconds. Throughput is 664.288 records/second. Loss is 0.073689245. Sequential2290a28's hyper parameters: Current learning rate is 0.012881617931212161. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 56896/60000][Iteration 2765][Wall Clock 339.23603513s] Trained 64 records in 0.113184816 seconds. Throughput is 565.44684 records/second. Loss is 0.1868469. Sequential2290a28's hyper parameters: Current learning rate is 0.012879958784131892. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 56960/60000][Iteration 2766][Wall Clock 339.330510341s] Trained 64 records in 0.094475211 seconds. Throughput is 677.4264 records/second. Loss is 0.2906301. Sequential2290a28's hyper parameters: Current learning rate is 0.012878300064391501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 57024/60000][Iteration 2767][Wall Clock 339.492327653s] Trained 64 records in 0.161817312 seconds. Throughput is 395.50775 records/second. Loss is 0.10320703. Sequential2290a28's hyper parameters: Current learning rate is 0.012876641771825908. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 2768][Wall Clock 339.587488789s] Trained 64 records in 0.095161136 seconds. Throughput is 672.5435 records/second. Loss is 0.091414414. Sequential2290a28's hyper parameters: Current learning rate is 0.012874983906270118. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 57152/60000][Iteration 2769][Wall Clock 339.693464555s] Trained 64 records in 0.105975766 seconds. Throughput is 603.9116 records/second. Loss is 0.11125923. Sequential2290a28's hyper parameters: Current learning rate is 0.012873326467559218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:22 INFO  DistriOptimizer$:408 - [Epoch 3 57216/60000][Iteration 2770][Wall Clock 339.786519045s] Trained 64 records in 0.09305449 seconds. Throughput is 687.7691 records/second. Loss is 0.13750508. Sequential2290a28's hyper parameters: Current learning rate is 0.012871669455528381. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57280/60000][Iteration 2771][Wall Clock 339.873122049s] Trained 64 records in 0.086603004 seconds. Throughput is 739.0044 records/second. Loss is 0.103313446. Sequential2290a28's hyper parameters: Current learning rate is 0.01287001287001287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 2772][Wall Clock 339.981982095s] Trained 64 records in 0.108860046 seconds. Throughput is 587.9108 records/second. Loss is 0.20731112. Sequential2290a28's hyper parameters: Current learning rate is 0.012868356710848025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57408/60000][Iteration 2773][Wall Clock 340.077601594s] Trained 64 records in 0.095619499 seconds. Throughput is 669.3195 records/second. Loss is 0.17196862. Sequential2290a28's hyper parameters: Current learning rate is 0.012866700977869275. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57472/60000][Iteration 2774][Wall Clock 340.170056591s] Trained 64 records in 0.092454997 seconds. Throughput is 692.22864 records/second. Loss is 0.15956977. Sequential2290a28's hyper parameters: Current learning rate is 0.012865045670912132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57536/60000][Iteration 2775][Wall Clock 340.254818428s] Trained 64 records in 0.084761837 seconds. Throughput is 755.0568 records/second. Loss is 0.107574485. Sequential2290a28's hyper parameters: Current learning rate is 0.012863390789812194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 2776][Wall Clock 340.3372533s] Trained 64 records in 0.082434872 seconds. Throughput is 776.3705 records/second. Loss is 0.113967575. Sequential2290a28's hyper parameters: Current learning rate is 0.012861736334405143. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57664/60000][Iteration 2777][Wall Clock 340.420727282s] Trained 64 records in 0.083473982 seconds. Throughput is 766.706 records/second. Loss is 0.25347418. Sequential2290a28's hyper parameters: Current learning rate is 0.012860082304526748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57728/60000][Iteration 2778][Wall Clock 340.525811479s] Trained 64 records in 0.105084197 seconds. Throughput is 609.03546 records/second. Loss is 0.09867203. Sequential2290a28's hyper parameters: Current learning rate is 0.012858428700012858. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57792/60000][Iteration 2779][Wall Clock 340.63421402s] Trained 64 records in 0.108402541 seconds. Throughput is 590.392 records/second. Loss is 0.08863326. Sequential2290a28's hyper parameters: Current learning rate is 0.012856775520699408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:23 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 2780][Wall Clock 340.73176967s] Trained 64 records in 0.09755565 seconds. Throughput is 656.03577 records/second. Loss is 0.14820704. Sequential2290a28's hyper parameters: Current learning rate is 0.012855122766422419. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 57920/60000][Iteration 2781][Wall Clock 340.828425718s] Trained 64 records in 0.096656048 seconds. Throughput is 662.1417 records/second. Loss is 0.18410766. Sequential2290a28's hyper parameters: Current learning rate is 0.012853470437017995. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 57984/60000][Iteration 2782][Wall Clock 340.908291915s] Trained 64 records in 0.079866197 seconds. Throughput is 801.3402 records/second. Loss is 0.2502849. Sequential2290a28's hyper parameters: Current learning rate is 0.012851818532322324. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58048/60000][Iteration 2783][Wall Clock 341.033200859s] Trained 64 records in 0.124908944 seconds. Throughput is 512.3732 records/second. Loss is 0.2760787. Sequential2290a28's hyper parameters: Current learning rate is 0.01285016705217168. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 2784][Wall Clock 341.141182518s] Trained 64 records in 0.107981659 seconds. Throughput is 592.69324 records/second. Loss is 0.16406696. Sequential2290a28's hyper parameters: Current learning rate is 0.012848515996402417. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58176/60000][Iteration 2785][Wall Clock 341.236981305s] Trained 64 records in 0.095798787 seconds. Throughput is 668.0669 records/second. Loss is 0.12820017. Sequential2290a28's hyper parameters: Current learning rate is 0.012846865364850977. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58240/60000][Iteration 2786][Wall Clock 341.369970931s] Trained 64 records in 0.132989626 seconds. Throughput is 481.24054 records/second. Loss is 0.09093788. Sequential2290a28's hyper parameters: Current learning rate is 0.012845215157353887. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58304/60000][Iteration 2787][Wall Clock 341.522553451s] Trained 64 records in 0.15258252 seconds. Throughput is 419.44516 records/second. Loss is 0.14140774. Sequential2290a28's hyper parameters: Current learning rate is 0.012843565373747753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 2788][Wall Clock 341.67114404s] Trained 64 records in 0.148590589 seconds. Throughput is 430.71365 records/second. Loss is 0.13807735. Sequential2290a28's hyper parameters: Current learning rate is 0.01284191601386927. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:24 INFO  DistriOptimizer$:408 - [Epoch 3 58432/60000][Iteration 2789][Wall Clock 341.74807763s] Trained 64 records in 0.07693359 seconds. Throughput is 831.8863 records/second. Loss is 0.34336305. Sequential2290a28's hyper parameters: Current learning rate is 0.012840267077555215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:25 INFO  DistriOptimizer$:408 - [Epoch 3 58496/60000][Iteration 2790][Wall Clock 341.884106883s] Trained 64 records in 0.136029253 seconds. Throughput is 470.48703 records/second. Loss is 0.13834795. Sequential2290a28's hyper parameters: Current learning rate is 0.012838618564642443. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:25 INFO  DistriOptimizer$:408 - [Epoch 3 58560/60000][Iteration 2791][Wall Clock 342.064888126s] Trained 64 records in 0.180781243 seconds. Throughput is 354.019 records/second. Loss is 0.09142855. Sequential2290a28's hyper parameters: Current learning rate is 0.012836970474967907. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:25 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 2792][Wall Clock 342.184425133s] Trained 64 records in 0.119537007 seconds. Throughput is 535.39905 records/second. Loss is 0.2125726. Sequential2290a28's hyper parameters: Current learning rate is 0.01283532280836863. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:25 INFO  DistriOptimizer$:408 - [Epoch 3 58688/60000][Iteration 2793][Wall Clock 342.2970789s] Trained 64 records in 0.112653767 seconds. Throughput is 568.11237 records/second. Loss is 0.21730554. Sequential2290a28's hyper parameters: Current learning rate is 0.012833675564681724. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:25 INFO  DistriOptimizer$:408 - [Epoch 3 58752/60000][Iteration 2794][Wall Clock 342.389244418s] Trained 64 records in 0.092165518 seconds. Throughput is 694.4029 records/second. Loss is 0.19788253. Sequential2290a28's hyper parameters: Current learning rate is 0.012832028743744386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:25 INFO  DistriOptimizer$:408 - [Epoch 3 58816/60000][Iteration 2795][Wall Clock 342.563378087s] Trained 64 records in 0.174133669 seconds. Throughput is 367.53375 records/second. Loss is 0.22641109. Sequential2290a28's hyper parameters: Current learning rate is 0.012830382345393892. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 2796][Wall Clock 342.819374353s] Trained 64 records in 0.255996266 seconds. Throughput is 250.00366 records/second. Loss is 0.19191918. Sequential2290a28's hyper parameters: Current learning rate is 0.012828736369467606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 58944/60000][Iteration 2797][Wall Clock 343.024527747s] Trained 64 records in 0.205153394 seconds. Throughput is 311.9617 records/second. Loss is 0.12449969. Sequential2290a28's hyper parameters: Current learning rate is 0.012827090815802975. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 59008/60000][Iteration 2798][Wall Clock 343.148910745s] Trained 64 records in 0.124382998 seconds. Throughput is 514.5398 records/second. Loss is 0.2585284. Sequential2290a28's hyper parameters: Current learning rate is 0.012825445684237527. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 59072/60000][Iteration 2799][Wall Clock 343.259260243s] Trained 64 records in 0.110349498 seconds. Throughput is 579.97546 records/second. Loss is 0.15437472. Sequential2290a28's hyper parameters: Current learning rate is 0.012823800974608874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 2800][Wall Clock 343.376752079s] Trained 64 records in 0.117491836 seconds. Throughput is 544.7187 records/second. Loss is 0.13680914. Sequential2290a28's hyper parameters: Current learning rate is 0.012822156686754712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 59200/60000][Iteration 2801][Wall Clock 343.481506701s] Trained 64 records in 0.104754622 seconds. Throughput is 610.9516 records/second. Loss is 0.2090795. Sequential2290a28's hyper parameters: Current learning rate is 0.01282051282051282. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 59264/60000][Iteration 2802][Wall Clock 343.590963805s] Trained 64 records in 0.109457104 seconds. Throughput is 584.7039 records/second. Loss is 0.10442788. Sequential2290a28's hyper parameters: Current learning rate is 0.012818869375721062. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:26 INFO  DistriOptimizer$:408 - [Epoch 3 59328/60000][Iteration 2803][Wall Clock 343.706647673s] Trained 64 records in 0.115683868 seconds. Throughput is 553.2319 records/second. Loss is 0.2575828. Sequential2290a28's hyper parameters: Current learning rate is 0.01281722635221738. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 2804][Wall Clock 343.812342027s] Trained 64 records in 0.105694354 seconds. Throughput is 605.5196 records/second. Loss is 0.19803144. Sequential2290a28's hyper parameters: Current learning rate is 0.012815583749839805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59456/60000][Iteration 2805][Wall Clock 343.922895967s] Trained 64 records in 0.11055394 seconds. Throughput is 578.9029 records/second. Loss is 0.12045854. Sequential2290a28's hyper parameters: Current learning rate is 0.012813941568426449. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59520/60000][Iteration 2806][Wall Clock 344.033695416s] Trained 64 records in 0.110799449 seconds. Throughput is 577.62024 records/second. Loss is 0.18099524. Sequential2290a28's hyper parameters: Current learning rate is 0.012812299807815503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59584/60000][Iteration 2807][Wall Clock 344.211470148s] Trained 64 records in 0.177774732 seconds. Throughput is 360.00616 records/second. Loss is 0.1591398. Sequential2290a28's hyper parameters: Current learning rate is 0.012810658467845248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 2808][Wall Clock 344.31575655s] Trained 64 records in 0.104286402 seconds. Throughput is 613.6946 records/second. Loss is 0.16898121. Sequential2290a28's hyper parameters: Current learning rate is 0.012809017548354042. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59712/60000][Iteration 2809][Wall Clock 344.439731375s] Trained 64 records in 0.123974825 seconds. Throughput is 516.2338 records/second. Loss is 0.2045516. Sequential2290a28's hyper parameters: Current learning rate is 0.01280737704918033. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59776/60000][Iteration 2810][Wall Clock 344.586892867s] Trained 64 records in 0.147161492 seconds. Throughput is 434.89636 records/second. Loss is 0.23820886. Sequential2290a28's hyper parameters: Current learning rate is 0.012805736970162632. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:27 INFO  DistriOptimizer$:408 - [Epoch 3 59840/60000][Iteration 2811][Wall Clock 344.676692656s] Trained 64 records in 0.089799789 seconds. Throughput is 712.69653 records/second. Loss is 0.20040585. Sequential2290a28's hyper parameters: Current learning rate is 0.012804097311139564. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:28 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 2812][Wall Clock 344.852880842s] Trained 64 records in 0.176188186 seconds. Throughput is 363.24796 records/second. Loss is 0.08299088. Sequential2290a28's hyper parameters: Current learning rate is 0.012802458071949815. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:28 INFO  DistriOptimizer$:408 - [Epoch 3 59968/60000][Iteration 2813][Wall Clock 344.955856336s] Trained 64 records in 0.102975494 seconds. Throughput is 621.5071 records/second. Loss is 0.1789002. Sequential2290a28's hyper parameters: Current learning rate is 0.012800819252432157. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:28 INFO  DistriOptimizer$:408 - [Epoch 3 60032/60000][Iteration 2814][Wall Clock 345.066600269s] Trained 64 records in 0.110743933 seconds. Throughput is 577.9098 records/second. Loss is 0.2990169. Sequential2290a28's hyper parameters: Current learning rate is 0.012799180852425445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:28 INFO  DistriOptimizer$:452 - [Epoch 3 60032/60000][Iteration 2814][Wall Clock 345.066600269s] Epoch finished. Wall clock time is 347044.242871 ms
2019-10-24 03:19:28 INFO  DistriOptimizer$:111 - [Epoch 3 60032/60000][Iteration 2814][Wall Clock 345.066600269s] Validate model...
2019-10-24 03:19:29 INFO  DistriOptimizer$:178 - [Epoch 3 60032/60000][Iteration 2814][Wall Clock 345.066600269s] validate model throughput is 8520.228 records/second
2019-10-24 03:19:29 INFO  DistriOptimizer$:181 - [Epoch 3 60032/60000][Iteration 2814][Wall Clock 345.066600269s] Top1Accuracy is Accuracy(correct: 9534, count: 10000, accuracy: 0.9534)
2019-10-24 03:19:29 INFO  DistriOptimizer$:221 - [Wall Clock 347.044242871s] Save model to /tmp/lenet5/20191024_031340
2019-10-24 03:19:29 INFO  DistriOptimizer$:226 - [Wall Clock 347.044242871s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@b5fef19 to /tmp/lenet5/20191024_031340
2019-10-24 03:19:29 INFO  DistriOptimizer$:408 - [Epoch 4 64/60000][Iteration 2815][Wall Clock 347.136158421s] Trained 64 records in 0.09191555 seconds. Throughput is 696.2913 records/second. Loss is 0.067085505. Sequential2290a28's hyper parameters: Current learning rate is 0.01279754287176862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 128/60000][Iteration 2816][Wall Clock 347.243639244s] Trained 64 records in 0.107480823 seconds. Throughput is 595.4551 records/second. Loss is 0.14093347. Sequential2290a28's hyper parameters: Current learning rate is 0.012795905310300703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 192/60000][Iteration 2817][Wall Clock 347.338489066s] Trained 64 records in 0.094849822 seconds. Throughput is 674.75085 records/second. Loss is 0.1487448. Sequential2290a28's hyper parameters: Current learning rate is 0.012794268167860797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 2818][Wall Clock 347.491566512s] Trained 64 records in 0.153077446 seconds. Throughput is 418.089 records/second. Loss is 0.19167641. Sequential2290a28's hyper parameters: Current learning rate is 0.01279263144428809. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 320/60000][Iteration 2819][Wall Clock 347.634865182s] Trained 64 records in 0.14329867 seconds. Throughput is 446.61963 records/second. Loss is 0.14544374. Sequential2290a28's hyper parameters: Current learning rate is 0.012790995139421847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 384/60000][Iteration 2820][Wall Clock 347.783582061s] Trained 64 records in 0.148716879 seconds. Throughput is 430.3479 records/second. Loss is 0.13894615. Sequential2290a28's hyper parameters: Current learning rate is 0.012789359253101418. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 448/60000][Iteration 2821][Wall Clock 347.951155664s] Trained 64 records in 0.167573603 seconds. Throughput is 381.92172 records/second. Loss is 0.1568754. Sequential2290a28's hyper parameters: Current learning rate is 0.01278772378516624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:30 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 2822][Wall Clock 348.158943991s] Trained 64 records in 0.207788327 seconds. Throughput is 308.00574 records/second. Loss is 0.19210242. Sequential2290a28's hyper parameters: Current learning rate is 0.012786088735455824. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:31 INFO  DistriOptimizer$:408 - [Epoch 4 576/60000][Iteration 2823][Wall Clock 348.278385986s] Trained 64 records in 0.119441995 seconds. Throughput is 535.82495 records/second. Loss is 0.17402667. Sequential2290a28's hyper parameters: Current learning rate is 0.012784454103809767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:31 INFO  DistriOptimizer$:408 - [Epoch 4 640/60000][Iteration 2824][Wall Clock 348.489786982s] Trained 64 records in 0.211400996 seconds. Throughput is 302.7422 records/second. Loss is 0.07826691. Sequential2290a28's hyper parameters: Current learning rate is 0.01278281989006775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:31 INFO  DistriOptimizer$:408 - [Epoch 4 704/60000][Iteration 2825][Wall Clock 348.723253634s] Trained 64 records in 0.233466652 seconds. Throughput is 274.1291 records/second. Loss is 0.12994576. Sequential2290a28's hyper parameters: Current learning rate is 0.01278118609406953. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:31 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 2826][Wall Clock 348.854079462s] Trained 64 records in 0.130825828 seconds. Throughput is 489.2 records/second. Loss is 0.17047489. Sequential2290a28's hyper parameters: Current learning rate is 0.012779552715654953. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:31 INFO  DistriOptimizer$:408 - [Epoch 4 832/60000][Iteration 2827][Wall Clock 348.980812473s] Trained 64 records in 0.126733011 seconds. Throughput is 504.9987 records/second. Loss is 0.13234547. Sequential2290a28's hyper parameters: Current learning rate is 0.012777919754663941. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:31 INFO  DistriOptimizer$:408 - [Epoch 4 896/60000][Iteration 2828][Wall Clock 349.19672884s] Trained 64 records in 0.215916367 seconds. Throughput is 296.41107 records/second. Loss is 0.15624416. Sequential2290a28's hyper parameters: Current learning rate is 0.012776287210936503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 960/60000][Iteration 2829][Wall Clock 349.305766201s] Trained 64 records in 0.109037361 seconds. Throughput is 586.9548 records/second. Loss is 0.29485047. Sequential2290a28's hyper parameters: Current learning rate is 0.012774655084312725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 2830][Wall Clock 349.457506763s] Trained 64 records in 0.151740562 seconds. Throughput is 421.77252 records/second. Loss is 0.1595329. Sequential2290a28's hyper parameters: Current learning rate is 0.012773023374632776. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1088/60000][Iteration 2831][Wall Clock 349.608717537s] Trained 64 records in 0.151210774 seconds. Throughput is 423.25027 records/second. Loss is 0.1054762. Sequential2290a28's hyper parameters: Current learning rate is 0.012771392081736908. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1152/60000][Iteration 2832][Wall Clock 349.723111622s] Trained 64 records in 0.114394085 seconds. Throughput is 559.4695 records/second. Loss is 0.13200276. Sequential2290a28's hyper parameters: Current learning rate is 0.012769761205465458. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1216/60000][Iteration 2833][Wall Clock 349.840847928s] Trained 64 records in 0.117736306 seconds. Throughput is 543.58765 records/second. Loss is 0.18838145. Sequential2290a28's hyper parameters: Current learning rate is 0.012768130745658836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 2834][Wall Clock 349.964020898s] Trained 64 records in 0.12317297 seconds. Throughput is 519.59454 records/second. Loss is 0.21667105. Sequential2290a28's hyper parameters: Current learning rate is 0.012766500702157539. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1344/60000][Iteration 2835][Wall Clock 350.046330513s] Trained 64 records in 0.082309615 seconds. Throughput is 777.5519 records/second. Loss is 0.10407897. Sequential2290a28's hyper parameters: Current learning rate is 0.012764871074802142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:32 INFO  DistriOptimizer$:408 - [Epoch 4 1408/60000][Iteration 2836][Wall Clock 350.180295694s] Trained 64 records in 0.133965181 seconds. Throughput is 477.73608 records/second. Loss is 0.20435676. Sequential2290a28's hyper parameters: Current learning rate is 0.01276324186343331. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:33 INFO  DistriOptimizer$:408 - [Epoch 4 1472/60000][Iteration 2837][Wall Clock 350.301415385s] Trained 64 records in 0.121119691 seconds. Throughput is 528.40295 records/second. Loss is 0.17786273. Sequential2290a28's hyper parameters: Current learning rate is 0.01276161306789178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:33 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 2838][Wall Clock 350.47380307s] Trained 64 records in 0.172387685 seconds. Throughput is 371.2562 records/second. Loss is 0.24272873. Sequential2290a28's hyper parameters: Current learning rate is 0.012759984688018373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:33 INFO  DistriOptimizer$:408 - [Epoch 4 1600/60000][Iteration 2839][Wall Clock 350.705045475s] Trained 64 records in 0.231242405 seconds. Throughput is 276.76584 records/second. Loss is 0.15670961. Sequential2290a28's hyper parameters: Current learning rate is 0.012758356723653993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:33 INFO  DistriOptimizer$:408 - [Epoch 4 1664/60000][Iteration 2840][Wall Clock 350.914855268s] Trained 64 records in 0.209809793 seconds. Throughput is 305.03818 records/second. Loss is 0.14719386. Sequential2290a28's hyper parameters: Current learning rate is 0.012756729174639622. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:33 INFO  DistriOptimizer$:408 - [Epoch 4 1728/60000][Iteration 2841][Wall Clock 351.125699085s] Trained 64 records in 0.210843817 seconds. Throughput is 303.5422 records/second. Loss is 0.17390758. Sequential2290a28's hyper parameters: Current learning rate is 0.012755102040816327. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 2842][Wall Clock 351.223560396s] Trained 64 records in 0.097861311 seconds. Throughput is 653.98676 records/second. Loss is 0.29702908. Sequential2290a28's hyper parameters: Current learning rate is 0.012753475322025252. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 1856/60000][Iteration 2843][Wall Clock 351.354715231s] Trained 64 records in 0.131154835 seconds. Throughput is 487.97287 records/second. Loss is 0.118454225. Sequential2290a28's hyper parameters: Current learning rate is 0.012751849018107626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 1920/60000][Iteration 2844][Wall Clock 351.525260822s] Trained 64 records in 0.170545591 seconds. Throughput is 375.2662 records/second. Loss is 0.11344145. Sequential2290a28's hyper parameters: Current learning rate is 0.012750223128904756. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 1984/60000][Iteration 2845][Wall Clock 351.674451841s] Trained 64 records in 0.149191019 seconds. Throughput is 428.98022 records/second. Loss is 0.16440898. Sequential2290a28's hyper parameters: Current learning rate is 0.012748597654258032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 2846][Wall Clock 351.783294742s] Trained 64 records in 0.108842901 seconds. Throughput is 588.0034 records/second. Loss is 0.21453792. Sequential2290a28's hyper parameters: Current learning rate is 0.012746972594008924. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 2112/60000][Iteration 2847][Wall Clock 351.953022698s] Trained 64 records in 0.169727956 seconds. Throughput is 377.074 records/second. Loss is 0.13126618. Sequential2290a28's hyper parameters: Current learning rate is 0.012745347947998982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:34 INFO  DistriOptimizer$:408 - [Epoch 4 2176/60000][Iteration 2848][Wall Clock 352.137624924s] Trained 64 records in 0.184602226 seconds. Throughput is 346.69138 records/second. Loss is 0.11884284. Sequential2290a28's hyper parameters: Current learning rate is 0.012743723716069837. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:35 INFO  DistriOptimizer$:408 - [Epoch 4 2240/60000][Iteration 2849][Wall Clock 352.308310599s] Trained 64 records in 0.170685675 seconds. Throughput is 374.95822 records/second. Loss is 0.19212931. Sequential2290a28's hyper parameters: Current learning rate is 0.012742099898063202. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:35 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 2850][Wall Clock 352.419670269s] Trained 64 records in 0.11135967 seconds. Throughput is 574.71436 records/second. Loss is 0.15998355. Sequential2290a28's hyper parameters: Current learning rate is 0.01274047649382087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:35 INFO  DistriOptimizer$:408 - [Epoch 4 2368/60000][Iteration 2851][Wall Clock 352.69884443s] Trained 64 records in 0.279174161 seconds. Throughput is 229.24759 records/second. Loss is 0.16981624. Sequential2290a28's hyper parameters: Current learning rate is 0.012738853503184712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:35 INFO  DistriOptimizer$:408 - [Epoch 4 2432/60000][Iteration 2852][Wall Clock 352.926373264s] Trained 64 records in 0.227528834 seconds. Throughput is 281.28302 records/second. Loss is 0.14896718. Sequential2290a28's hyper parameters: Current learning rate is 0.012737230925996688. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:35 INFO  DistriOptimizer$:408 - [Epoch 4 2496/60000][Iteration 2853][Wall Clock 353.147016798s] Trained 64 records in 0.220643534 seconds. Throughput is 290.0606 records/second. Loss is 0.14949232. Sequential2290a28's hyper parameters: Current learning rate is 0.01273560876209883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:36 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 2854][Wall Clock 353.262399592s] Trained 64 records in 0.115382794 seconds. Throughput is 554.6754 records/second. Loss is 0.17540488. Sequential2290a28's hyper parameters: Current learning rate is 0.012733987011333249. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:36 INFO  DistriOptimizer$:408 - [Epoch 4 2624/60000][Iteration 2855][Wall Clock 353.382401468s] Trained 64 records in 0.120001876 seconds. Throughput is 533.325 records/second. Loss is 0.39263257. Sequential2290a28's hyper parameters: Current learning rate is 0.012732365673542145. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:36 INFO  DistriOptimizer$:408 - [Epoch 4 2688/60000][Iteration 2856][Wall Clock 353.545460924s] Trained 64 records in 0.163059456 seconds. Throughput is 392.49487 records/second. Loss is 0.13145158. Sequential2290a28's hyper parameters: Current learning rate is 0.01273074474856779. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:36 INFO  DistriOptimizer$:408 - [Epoch 4 2752/60000][Iteration 2857][Wall Clock 353.822577027s] Trained 64 records in 0.277116103 seconds. Throughput is 230.95013 records/second. Loss is 0.16180924. Sequential2290a28's hyper parameters: Current learning rate is 0.012729124236252545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:36 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 2858][Wall Clock 353.941392729s] Trained 64 records in 0.118815702 seconds. Throughput is 538.64935 records/second. Loss is 0.06296338. Sequential2290a28's hyper parameters: Current learning rate is 0.012727504136438843. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:36 INFO  DistriOptimizer$:408 - [Epoch 4 2880/60000][Iteration 2859][Wall Clock 354.037497777s] Trained 64 records in 0.096105048 seconds. Throughput is 665.938 records/second. Loss is 0.25617668. Sequential2290a28's hyper parameters: Current learning rate is 0.012725884448969202. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 2944/60000][Iteration 2860][Wall Clock 354.214224491s] Trained 64 records in 0.176726714 seconds. Throughput is 362.14105 records/second. Loss is 0.18095042. Sequential2290a28's hyper parameters: Current learning rate is 0.012724265173686218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3008/60000][Iteration 2861][Wall Clock 354.345435804s] Trained 64 records in 0.131211313 seconds. Throughput is 487.76282 records/second. Loss is 0.35522938. Sequential2290a28's hyper parameters: Current learning rate is 0.01272264631043257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 2862][Wall Clock 354.457990397s] Trained 64 records in 0.112554593 seconds. Throughput is 568.613 records/second. Loss is 0.23341003. Sequential2290a28's hyper parameters: Current learning rate is 0.012721027859051012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3136/60000][Iteration 2863][Wall Clock 354.555188883s] Trained 64 records in 0.097198486 seconds. Throughput is 658.4465 records/second. Loss is 0.09744026. Sequential2290a28's hyper parameters: Current learning rate is 0.01271940981938438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3200/60000][Iteration 2864][Wall Clock 354.640606187s] Trained 64 records in 0.085417304 seconds. Throughput is 749.26276 records/second. Loss is 0.1600194. Sequential2290a28's hyper parameters: Current learning rate is 0.012717792191275595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3264/60000][Iteration 2865][Wall Clock 354.728645856s] Trained 64 records in 0.088039669 seconds. Throughput is 726.94507 records/second. Loss is 0.18509614. Sequential2290a28's hyper parameters: Current learning rate is 0.01271617497456765. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 2866][Wall Clock 354.833816618s] Trained 64 records in 0.105170762 seconds. Throughput is 608.5341 records/second. Loss is 0.34116948. Sequential2290a28's hyper parameters: Current learning rate is 0.012714558169103624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3392/60000][Iteration 2867][Wall Clock 354.91957378s] Trained 64 records in 0.085757162 seconds. Throughput is 746.2934 records/second. Loss is 0.15190196. Sequential2290a28's hyper parameters: Current learning rate is 0.012712941774726672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3456/60000][Iteration 2868][Wall Clock 355.00325606s] Trained 64 records in 0.08368228 seconds. Throughput is 764.79755 records/second. Loss is 0.18697749. Sequential2290a28's hyper parameters: Current learning rate is 0.012711325791280032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:37 INFO  DistriOptimizer$:408 - [Epoch 4 3520/60000][Iteration 2869][Wall Clock 355.178739617s] Trained 64 records in 0.175483557 seconds. Throughput is 364.70654 records/second. Loss is 0.12088164. Sequential2290a28's hyper parameters: Current learning rate is 0.012709710218607017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:38 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 2870][Wall Clock 355.282590179s] Trained 64 records in 0.103850562 seconds. Throughput is 616.27014 records/second. Loss is 0.15407217. Sequential2290a28's hyper parameters: Current learning rate is 0.012708095056551025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:38 INFO  DistriOptimizer$:408 - [Epoch 4 3648/60000][Iteration 2871][Wall Clock 355.447875997s] Trained 64 records in 0.165285818 seconds. Throughput is 387.20807 records/second. Loss is 0.11638256. Sequential2290a28's hyper parameters: Current learning rate is 0.012706480304955527. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:38 INFO  DistriOptimizer$:408 - [Epoch 4 3712/60000][Iteration 2872][Wall Clock 355.584222468s] Trained 64 records in 0.136346471 seconds. Throughput is 469.3924 records/second. Loss is 0.11418717. Sequential2290a28's hyper parameters: Current learning rate is 0.012704865963664084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:38 INFO  DistriOptimizer$:408 - [Epoch 4 3776/60000][Iteration 2873][Wall Clock 355.686332881s] Trained 64 records in 0.102110413 seconds. Throughput is 626.7725 records/second. Loss is 0.16099927. Sequential2290a28's hyper parameters: Current learning rate is 0.012703252032520325. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:38 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 2874][Wall Clock 355.800738413s] Trained 64 records in 0.114405532 seconds. Throughput is 559.4135 records/second. Loss is 0.08091363. Sequential2290a28's hyper parameters: Current learning rate is 0.012701638511367967. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:38 INFO  DistriOptimizer$:408 - [Epoch 4 3904/60000][Iteration 2875][Wall Clock 356.013015797s] Trained 64 records in 0.212277384 seconds. Throughput is 301.4923 records/second. Loss is 0.22736739. Sequential2290a28's hyper parameters: Current learning rate is 0.0127000254000508. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:39 INFO  DistriOptimizer$:408 - [Epoch 4 3968/60000][Iteration 2876][Wall Clock 356.234469682s] Trained 64 records in 0.221453885 seconds. Throughput is 288.9992 records/second. Loss is 0.08873229. Sequential2290a28's hyper parameters: Current learning rate is 0.012698412698412697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:39 INFO  DistriOptimizer$:408 - [Epoch 4 4032/60000][Iteration 2877][Wall Clock 356.420450167s] Trained 64 records in 0.185980485 seconds. Throughput is 344.12213 records/second. Loss is 0.13768867. Sequential2290a28's hyper parameters: Current learning rate is 0.012696800406297611. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:39 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 2878][Wall Clock 356.639348s] Trained 64 records in 0.218897833 seconds. Throughput is 292.37384 records/second. Loss is 0.11552963. Sequential2290a28's hyper parameters: Current learning rate is 0.012695188523549573. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:39 INFO  DistriOptimizer$:408 - [Epoch 4 4160/60000][Iteration 2879][Wall Clock 356.828690119s] Trained 64 records in 0.189342119 seconds. Throughput is 338.01248 records/second. Loss is 0.21494813. Sequential2290a28's hyper parameters: Current learning rate is 0.012693577050012693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:39 INFO  DistriOptimizer$:408 - [Epoch 4 4224/60000][Iteration 2880][Wall Clock 356.956253277s] Trained 64 records in 0.127563158 seconds. Throughput is 501.71225 records/second. Loss is 0.15987855. Sequential2290a28's hyper parameters: Current learning rate is 0.012691965985531158. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:39 INFO  DistriOptimizer$:408 - [Epoch 4 4288/60000][Iteration 2881][Wall Clock 357.094310762s] Trained 64 records in 0.138057485 seconds. Throughput is 463.575 records/second. Loss is 0.33733383. Sequential2290a28's hyper parameters: Current learning rate is 0.012690355329949238. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 2882][Wall Clock 357.199092934s] Trained 64 records in 0.104782172 seconds. Throughput is 610.79095 records/second. Loss is 0.12694015. Sequential2290a28's hyper parameters: Current learning rate is 0.01268874508311128. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4416/60000][Iteration 2883][Wall Clock 357.289285488s] Trained 64 records in 0.090192554 seconds. Throughput is 709.59296 records/second. Loss is 0.1641126. Sequential2290a28's hyper parameters: Current learning rate is 0.01268713524486171. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4480/60000][Iteration 2884][Wall Clock 357.387410138s] Trained 64 records in 0.09812465 seconds. Throughput is 652.2316 records/second. Loss is 0.21614128. Sequential2290a28's hyper parameters: Current learning rate is 0.012685525815045035. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4544/60000][Iteration 2885][Wall Clock 357.465035048s] Trained 64 records in 0.07762491 seconds. Throughput is 824.4776 records/second. Loss is 0.17811087. Sequential2290a28's hyper parameters: Current learning rate is 0.012683916793505836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 2886][Wall Clock 357.551598905s] Trained 64 records in 0.086563857 seconds. Throughput is 739.3386 records/second. Loss is 0.09840883. Sequential2290a28's hyper parameters: Current learning rate is 0.012682308180088777. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4672/60000][Iteration 2887][Wall Clock 357.634410964s] Trained 64 records in 0.082812059 seconds. Throughput is 772.83435 records/second. Loss is 0.22109517. Sequential2290a28's hyper parameters: Current learning rate is 0.0126806999746386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4736/60000][Iteration 2888][Wall Clock 357.720670791s] Trained 64 records in 0.086259827 seconds. Throughput is 741.94446 records/second. Loss is 0.14833787. Sequential2290a28's hyper parameters: Current learning rate is 0.012679092177000128. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4800/60000][Iteration 2889][Wall Clock 357.830248148s] Trained 64 records in 0.109577357 seconds. Throughput is 584.06226 records/second. Loss is 0.27552277. Sequential2290a28's hyper parameters: Current learning rate is 0.012677484787018257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 2890][Wall Clock 357.928719623s] Trained 64 records in 0.098471475 seconds. Throughput is 649.9344 records/second. Loss is 0.1634041. Sequential2290a28's hyper parameters: Current learning rate is 0.012675877804537966. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:40 INFO  DistriOptimizer$:408 - [Epoch 4 4928/60000][Iteration 2891][Wall Clock 358.100604636s] Trained 64 records in 0.171885013 seconds. Throughput is 372.34195 records/second. Loss is 0.17584139. Sequential2290a28's hyper parameters: Current learning rate is 0.012674271229404309. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 4992/60000][Iteration 2892][Wall Clock 358.302919299s] Trained 64 records in 0.202314663 seconds. Throughput is 316.33893 records/second. Loss is 0.20164469. Sequential2290a28's hyper parameters: Current learning rate is 0.012672665061462425. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 5056/60000][Iteration 2893][Wall Clock 358.420512709s] Trained 64 records in 0.11759341 seconds. Throughput is 544.24817 records/second. Loss is 0.17152718. Sequential2290a28's hyper parameters: Current learning rate is 0.012671059300557527. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 2894][Wall Clock 358.592928947s] Trained 64 records in 0.172416238 seconds. Throughput is 371.19473 records/second. Loss is 0.13124901. Sequential2290a28's hyper parameters: Current learning rate is 0.012669453946534905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 5184/60000][Iteration 2895][Wall Clock 358.717357004s] Trained 64 records in 0.124428057 seconds. Throughput is 514.35345 records/second. Loss is 0.14390332. Sequential2290a28's hyper parameters: Current learning rate is 0.01266784899923993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 5248/60000][Iteration 2896][Wall Clock 358.902517442s] Trained 64 records in 0.185160438 seconds. Throughput is 345.64618 records/second. Loss is 0.23979862. Sequential2290a28's hyper parameters: Current learning rate is 0.012666244458518048. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 5312/60000][Iteration 2897][Wall Clock 359.015793404s] Trained 64 records in 0.113275962 seconds. Throughput is 564.9919 records/second. Loss is 0.26123056. Sequential2290a28's hyper parameters: Current learning rate is 0.012664640324214792. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:41 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 2898][Wall Clock 359.125761008s] Trained 64 records in 0.109967604 seconds. Throughput is 581.98956 records/second. Loss is 0.19052434. Sequential2290a28's hyper parameters: Current learning rate is 0.012663036596175762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5440/60000][Iteration 2899][Wall Clock 359.273161983s] Trained 64 records in 0.147400975 seconds. Throughput is 434.1898 records/second. Loss is 0.09558979. Sequential2290a28's hyper parameters: Current learning rate is 0.012661433274246644. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5504/60000][Iteration 2900][Wall Clock 359.391223245s] Trained 64 records in 0.118061262 seconds. Throughput is 542.09143 records/second. Loss is 0.20787434. Sequential2290a28's hyper parameters: Current learning rate is 0.012659830358273198. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5568/60000][Iteration 2901][Wall Clock 359.506473592s] Trained 64 records in 0.115250347 seconds. Throughput is 555.31287 records/second. Loss is 0.23813413. Sequential2290a28's hyper parameters: Current learning rate is 0.012658227848101266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 2902][Wall Clock 359.588148478s] Trained 64 records in 0.081674886 seconds. Throughput is 783.5946 records/second. Loss is 0.13653126. Sequential2290a28's hyper parameters: Current learning rate is 0.012656625743576762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5696/60000][Iteration 2903][Wall Clock 359.67944955s] Trained 64 records in 0.091301072 seconds. Throughput is 700.97754 records/second. Loss is 0.16628224. Sequential2290a28's hyper parameters: Current learning rate is 0.012655024044545684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5760/60000][Iteration 2904][Wall Clock 359.790438069s] Trained 64 records in 0.110988519 seconds. Throughput is 576.6362 records/second. Loss is 0.14159825. Sequential2290a28's hyper parameters: Current learning rate is 0.012653422750854106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5824/60000][Iteration 2905][Wall Clock 359.895424077s] Trained 64 records in 0.104986008 seconds. Throughput is 609.60504 records/second. Loss is 0.16941692. Sequential2290a28's hyper parameters: Current learning rate is 0.012651821862348178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 2906][Wall Clock 360.03623814s] Trained 64 records in 0.140814063 seconds. Throughput is 454.50006 records/second. Loss is 0.29536462. Sequential2290a28's hyper parameters: Current learning rate is 0.012650221378874131. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:42 INFO  DistriOptimizer$:408 - [Epoch 4 5952/60000][Iteration 2907][Wall Clock 360.132392149s] Trained 64 records in 0.096154009 seconds. Throughput is 665.5989 records/second. Loss is 0.2884003. Sequential2290a28's hyper parameters: Current learning rate is 0.01264862130027827. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6016/60000][Iteration 2908][Wall Clock 360.247483234s] Trained 64 records in 0.115091085 seconds. Throughput is 556.0813 records/second. Loss is 0.16218787. Sequential2290a28's hyper parameters: Current learning rate is 0.012647021626406981. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6080/60000][Iteration 2909][Wall Clock 360.343387228s] Trained 64 records in 0.095903994 seconds. Throughput is 667.33405 records/second. Loss is 0.14975423. Sequential2290a28's hyper parameters: Current learning rate is 0.012645422357106728. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 2910][Wall Clock 360.449947176s] Trained 64 records in 0.106559948 seconds. Throughput is 600.6009 records/second. Loss is 0.18544258. Sequential2290a28's hyper parameters: Current learning rate is 0.01264382349222405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6208/60000][Iteration 2911][Wall Clock 360.519802838s] Trained 64 records in 0.069855662 seconds. Throughput is 916.17487 records/second. Loss is 0.11274633. Sequential2290a28's hyper parameters: Current learning rate is 0.012642225031605562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6272/60000][Iteration 2912][Wall Clock 360.593003754s] Trained 64 records in 0.073200916 seconds. Throughput is 874.30597 records/second. Loss is 0.16068342. Sequential2290a28's hyper parameters: Current learning rate is 0.012640626975097964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6336/60000][Iteration 2913][Wall Clock 360.665659266s] Trained 64 records in 0.072655512 seconds. Throughput is 880.86914 records/second. Loss is 0.26343718. Sequential2290a28's hyper parameters: Current learning rate is 0.012639029322548028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 2914][Wall Clock 360.738524836s] Trained 64 records in 0.07286557 seconds. Throughput is 878.3298 records/second. Loss is 0.2052604. Sequential2290a28's hyper parameters: Current learning rate is 0.012637432073802603. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6464/60000][Iteration 2915][Wall Clock 360.820594855s] Trained 64 records in 0.082070019 seconds. Throughput is 779.82196 records/second. Loss is 0.21618256. Sequential2290a28's hyper parameters: Current learning rate is 0.012635835228708618. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6528/60000][Iteration 2916][Wall Clock 360.895846608s] Trained 64 records in 0.075251753 seconds. Throughput is 850.4786 records/second. Loss is 0.17890492. Sequential2290a28's hyper parameters: Current learning rate is 0.012634238787113075. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6592/60000][Iteration 2917][Wall Clock 360.977704081s] Trained 64 records in 0.081857473 seconds. Throughput is 781.84674 records/second. Loss is 0.14381006. Sequential2290a28's hyper parameters: Current learning rate is 0.012632642748863061. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 2918][Wall Clock 361.055894963s] Trained 64 records in 0.078190882 seconds. Throughput is 818.5097 records/second. Loss is 0.09475026. Sequential2290a28's hyper parameters: Current learning rate is 0.012631047113805733. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:43 INFO  DistriOptimizer$:408 - [Epoch 4 6720/60000][Iteration 2919][Wall Clock 361.143366753s] Trained 64 records in 0.08747179 seconds. Throughput is 731.6644 records/second. Loss is 0.10104087. Sequential2290a28's hyper parameters: Current learning rate is 0.01262945188178833. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:44 INFO  DistriOptimizer$:408 - [Epoch 4 6784/60000][Iteration 2920][Wall Clock 361.312157675s] Trained 64 records in 0.168790922 seconds. Throughput is 379.1673 records/second. Loss is 0.14174402. Sequential2290a28's hyper parameters: Current learning rate is 0.012627857052658164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:44 INFO  DistriOptimizer$:408 - [Epoch 4 6848/60000][Iteration 2921][Wall Clock 361.454146357s] Trained 64 records in 0.141988682 seconds. Throughput is 450.74017 records/second. Loss is 0.14092907. Sequential2290a28's hyper parameters: Current learning rate is 0.012626262626262626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:44 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 2922][Wall Clock 361.665168904s] Trained 64 records in 0.211022547 seconds. Throughput is 303.28513 records/second. Loss is 0.1263368. Sequential2290a28's hyper parameters: Current learning rate is 0.012624668602449186. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:44 INFO  DistriOptimizer$:408 - [Epoch 4 6976/60000][Iteration 2923][Wall Clock 361.803643632s] Trained 64 records in 0.138474728 seconds. Throughput is 462.1782 records/second. Loss is 0.1632118. Sequential2290a28's hyper parameters: Current learning rate is 0.012623074981065388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:44 INFO  DistriOptimizer$:408 - [Epoch 4 7040/60000][Iteration 2924][Wall Clock 362.054701686s] Trained 64 records in 0.251058054 seconds. Throughput is 254.92113 records/second. Loss is 0.29846773. Sequential2290a28's hyper parameters: Current learning rate is 0.012621481761958854. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:44 INFO  DistriOptimizer$:408 - [Epoch 4 7104/60000][Iteration 2925][Wall Clock 362.154484026s] Trained 64 records in 0.09978234 seconds. Throughput is 641.39606 records/second. Loss is 0.18697807. Sequential2290a28's hyper parameters: Current learning rate is 0.012619888944977285. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:45 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 2926][Wall Clock 362.257397588s] Trained 64 records in 0.102913562 seconds. Throughput is 621.8811 records/second. Loss is 0.14190204. Sequential2290a28's hyper parameters: Current learning rate is 0.012618296529968456. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:45 INFO  DistriOptimizer$:408 - [Epoch 4 7232/60000][Iteration 2927][Wall Clock 362.399272438s] Trained 64 records in 0.14187485 seconds. Throughput is 451.1018 records/second. Loss is 0.0678046. Sequential2290a28's hyper parameters: Current learning rate is 0.012616704516780217. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:45 INFO  DistriOptimizer$:408 - [Epoch 4 7296/60000][Iteration 2928][Wall Clock 362.553755035s] Trained 64 records in 0.154482597 seconds. Throughput is 414.28613 records/second. Loss is 0.17420378. Sequential2290a28's hyper parameters: Current learning rate is 0.012615112905260503. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:45 INFO  DistriOptimizer$:408 - [Epoch 4 7360/60000][Iteration 2929][Wall Clock 362.741163372s] Trained 64 records in 0.187408337 seconds. Throughput is 341.50027 records/second. Loss is 0.2966588. Sequential2290a28's hyper parameters: Current learning rate is 0.012613521695257316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:45 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 2930][Wall Clock 362.901375761s] Trained 64 records in 0.160212389 seconds. Throughput is 399.46976 records/second. Loss is 0.15929478. Sequential2290a28's hyper parameters: Current learning rate is 0.012611930886618742. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:45 INFO  DistriOptimizer$:408 - [Epoch 4 7488/60000][Iteration 2931][Wall Clock 363.096475815s] Trained 64 records in 0.195100054 seconds. Throughput is 328.0368 records/second. Loss is 0.15404615. Sequential2290a28's hyper parameters: Current learning rate is 0.012610340479192938. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7552/60000][Iteration 2932][Wall Clock 363.278391021s] Trained 64 records in 0.181915206 seconds. Throughput is 351.81226 records/second. Loss is 0.27664587. Sequential2290a28's hyper parameters: Current learning rate is 0.012608750472828143. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7616/60000][Iteration 2933][Wall Clock 363.41077769s] Trained 64 records in 0.132386669 seconds. Throughput is 483.43237 records/second. Loss is 0.16350903. Sequential2290a28's hyper parameters: Current learning rate is 0.012607160867372668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 2934][Wall Clock 363.551933372s] Trained 64 records in 0.141155682 seconds. Throughput is 453.40012 records/second. Loss is 0.18963616. Sequential2290a28's hyper parameters: Current learning rate is 0.012605571662674902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7744/60000][Iteration 2935][Wall Clock 363.70051268s] Trained 64 records in 0.148579308 seconds. Throughput is 430.74637 records/second. Loss is 0.14694327. Sequential2290a28's hyper parameters: Current learning rate is 0.012603982858583314. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7808/60000][Iteration 2936][Wall Clock 363.797964202s] Trained 64 records in 0.097451522 seconds. Throughput is 656.7368 records/second. Loss is 0.1331375. Sequential2290a28's hyper parameters: Current learning rate is 0.01260239445494644. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7872/60000][Iteration 2937][Wall Clock 363.903610074s] Trained 64 records in 0.105645872 seconds. Throughput is 605.7974 records/second. Loss is 0.17265108. Sequential2290a28's hyper parameters: Current learning rate is 0.012600806451612902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 2938][Wall Clock 364.004303714s] Trained 64 records in 0.10069364 seconds. Throughput is 635.59125 records/second. Loss is 0.17634773. Sequential2290a28's hyper parameters: Current learning rate is 0.012599218848431397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:46 INFO  DistriOptimizer$:408 - [Epoch 4 8000/60000][Iteration 2939][Wall Clock 364.094369487s] Trained 64 records in 0.090065773 seconds. Throughput is 710.59186 records/second. Loss is 0.2004716. Sequential2290a28's hyper parameters: Current learning rate is 0.012597631645250693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8064/60000][Iteration 2940][Wall Clock 364.222003402s] Trained 64 records in 0.127633915 seconds. Throughput is 501.4341 records/second. Loss is 0.18481693. Sequential2290a28's hyper parameters: Current learning rate is 0.012596044841919637. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8128/60000][Iteration 2941][Wall Clock 364.392090012s] Trained 64 records in 0.17008661 seconds. Throughput is 376.2789 records/second. Loss is 0.13872084. Sequential2290a28's hyper parameters: Current learning rate is 0.012594458438287152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 2942][Wall Clock 364.513182872s] Trained 64 records in 0.12109286 seconds. Throughput is 528.52 records/second. Loss is 0.092773326. Sequential2290a28's hyper parameters: Current learning rate is 0.012592872434202242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8256/60000][Iteration 2943][Wall Clock 364.656586424s] Trained 64 records in 0.143403552 seconds. Throughput is 446.293 records/second. Loss is 0.09336069. Sequential2290a28's hyper parameters: Current learning rate is 0.012591286829513977. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8320/60000][Iteration 2944][Wall Clock 364.770216573s] Trained 64 records in 0.113630149 seconds. Throughput is 563.23083 records/second. Loss is 0.09592991. Sequential2290a28's hyper parameters: Current learning rate is 0.01258970162407151. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8384/60000][Iteration 2945][Wall Clock 364.876258392s] Trained 64 records in 0.106041819 seconds. Throughput is 603.53546 records/second. Loss is 0.31524706. Sequential2290a28's hyper parameters: Current learning rate is 0.012588116817724069. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 2946][Wall Clock 365.023409591s] Trained 64 records in 0.147151199 seconds. Throughput is 434.9268 records/second. Loss is 0.22449008. Sequential2290a28's hyper parameters: Current learning rate is 0.012586532410320957. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:47 INFO  DistriOptimizer$:408 - [Epoch 4 8512/60000][Iteration 2947][Wall Clock 365.113288319s] Trained 64 records in 0.089878728 seconds. Throughput is 712.07056 records/second. Loss is 0.18180549. Sequential2290a28's hyper parameters: Current learning rate is 0.012584948401711553. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8576/60000][Iteration 2948][Wall Clock 365.254721049s] Trained 64 records in 0.14143273 seconds. Throughput is 452.51193 records/second. Loss is 0.15589392. Sequential2290a28's hyper parameters: Current learning rate is 0.012583364791745313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8640/60000][Iteration 2949][Wall Clock 365.391941279s] Trained 64 records in 0.13722023 seconds. Throughput is 466.40353 records/second. Loss is 0.07328632. Sequential2290a28's hyper parameters: Current learning rate is 0.012581781580271768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 2950][Wall Clock 365.521790235s] Trained 64 records in 0.129848956 seconds. Throughput is 492.88034 records/second. Loss is 0.12714103. Sequential2290a28's hyper parameters: Current learning rate is 0.012580198767140522. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8768/60000][Iteration 2951][Wall Clock 365.636739108s] Trained 64 records in 0.114948873 seconds. Throughput is 556.7692 records/second. Loss is 0.10859983. Sequential2290a28's hyper parameters: Current learning rate is 0.012578616352201257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8832/60000][Iteration 2952][Wall Clock 365.719107971s] Trained 64 records in 0.082368863 seconds. Throughput is 776.9926 records/second. Loss is 0.182835. Sequential2290a28's hyper parameters: Current learning rate is 0.012577034335303735. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8896/60000][Iteration 2953][Wall Clock 365.810180856s] Trained 64 records in 0.091072885 seconds. Throughput is 702.7338 records/second. Loss is 0.13496622. Sequential2290a28's hyper parameters: Current learning rate is 0.012575452716297788. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 2954][Wall Clock 365.89464495s] Trained 64 records in 0.084464094 seconds. Throughput is 757.7184 records/second. Loss is 0.23527896. Sequential2290a28's hyper parameters: Current learning rate is 0.01257387149503332. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:48 INFO  DistriOptimizer$:408 - [Epoch 4 9024/60000][Iteration 2955][Wall Clock 366.01183776s] Trained 64 records in 0.11719281 seconds. Throughput is 546.1086 records/second. Loss is 0.2467621. Sequential2290a28's hyper parameters: Current learning rate is 0.012572290671360321. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9088/60000][Iteration 2956][Wall Clock 366.148385885s] Trained 64 records in 0.136548125 seconds. Throughput is 468.6992 records/second. Loss is 0.14685851. Sequential2290a28's hyper parameters: Current learning rate is 0.012570710245128848. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9152/60000][Iteration 2957][Wall Clock 366.235466642s] Trained 64 records in 0.087080757 seconds. Throughput is 734.95 records/second. Loss is 0.129406. Sequential2290a28's hyper parameters: Current learning rate is 0.012569130216189038. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 2958][Wall Clock 366.331051833s] Trained 64 records in 0.095585191 seconds. Throughput is 669.5598 records/second. Loss is 0.22492269. Sequential2290a28's hyper parameters: Current learning rate is 0.012567550584391102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9280/60000][Iteration 2959][Wall Clock 366.415049768s] Trained 64 records in 0.083997935 seconds. Throughput is 761.92346 records/second. Loss is 0.27129862. Sequential2290a28's hyper parameters: Current learning rate is 0.012565971349585323. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9344/60000][Iteration 2960][Wall Clock 366.508097645s] Trained 64 records in 0.093047877 seconds. Throughput is 687.81793 records/second. Loss is 0.20801306. Sequential2290a28's hyper parameters: Current learning rate is 0.012564392511622063. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9408/60000][Iteration 2961][Wall Clock 366.602753761s] Trained 64 records in 0.094656116 seconds. Throughput is 676.1317 records/second. Loss is 0.1777122. Sequential2290a28's hyper parameters: Current learning rate is 0.012562814070351758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 2962][Wall Clock 366.732738884s] Trained 64 records in 0.129985123 seconds. Throughput is 492.36404 records/second. Loss is 0.23047361. Sequential2290a28's hyper parameters: Current learning rate is 0.01256123602562492. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9536/60000][Iteration 2963][Wall Clock 366.87598832s] Trained 64 records in 0.143249436 seconds. Throughput is 446.77313 records/second. Loss is 0.26366466. Sequential2290a28's hyper parameters: Current learning rate is 0.012559658377292138. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9600/60000][Iteration 2964][Wall Clock 367.001691349s] Trained 64 records in 0.125703029 seconds. Throughput is 509.13654 records/second. Loss is 0.12665525. Sequential2290a28's hyper parameters: Current learning rate is 0.01255808112520407. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:49 INFO  DistriOptimizer$:408 - [Epoch 4 9664/60000][Iteration 2965][Wall Clock 367.125604139s] Trained 64 records in 0.12391279 seconds. Throughput is 516.4923 records/second. Loss is 0.16768628. Sequential2290a28's hyper parameters: Current learning rate is 0.012556504269211451. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 2966][Wall Clock 367.25606097s] Trained 64 records in 0.130456831 seconds. Throughput is 490.5837 records/second. Loss is 0.39971817. Sequential2290a28's hyper parameters: Current learning rate is 0.012554927809165098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 9792/60000][Iteration 2967][Wall Clock 367.38127413s] Trained 64 records in 0.12521316 seconds. Throughput is 511.1284 records/second. Loss is 0.08349798. Sequential2290a28's hyper parameters: Current learning rate is 0.012553351744915894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 9856/60000][Iteration 2968][Wall Clock 367.493985003s] Trained 64 records in 0.112710873 seconds. Throughput is 567.8246 records/second. Loss is 0.3640132. Sequential2290a28's hyper parameters: Current learning rate is 0.012551776076314799. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 9920/60000][Iteration 2969][Wall Clock 367.59707195s] Trained 64 records in 0.103086947 seconds. Throughput is 620.83514 records/second. Loss is 0.12952603. Sequential2290a28's hyper parameters: Current learning rate is 0.012550200803212853. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 2970][Wall Clock 367.715765403s] Trained 64 records in 0.118693453 seconds. Throughput is 539.2041 records/second. Loss is 0.13585605. Sequential2290a28's hyper parameters: Current learning rate is 0.012548625925461163. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 10048/60000][Iteration 2971][Wall Clock 367.869912871s] Trained 64 records in 0.154147468 seconds. Throughput is 415.18686 records/second. Loss is 0.12578803. Sequential2290a28's hyper parameters: Current learning rate is 0.012547051442910916. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:50 INFO  DistriOptimizer$:408 - [Epoch 4 10112/60000][Iteration 2972][Wall Clock 368.002982245s] Trained 64 records in 0.133069374 seconds. Throughput is 480.95212 records/second. Loss is 0.23227051. Sequential2290a28's hyper parameters: Current learning rate is 0.012545477355413373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10176/60000][Iteration 2973][Wall Clock 368.133902617s] Trained 64 records in 0.130920372 seconds. Throughput is 488.8468 records/second. Loss is 0.24165179. Sequential2290a28's hyper parameters: Current learning rate is 0.012543903662819869. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 2974][Wall Clock 368.260883451s] Trained 64 records in 0.126980834 seconds. Throughput is 504.01303 records/second. Loss is 0.16511607. Sequential2290a28's hyper parameters: Current learning rate is 0.012542330364981813. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10304/60000][Iteration 2975][Wall Clock 368.388032681s] Trained 64 records in 0.12714923 seconds. Throughput is 503.34558 records/second. Loss is 0.21518727. Sequential2290a28's hyper parameters: Current learning rate is 0.01254075746175069. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10368/60000][Iteration 2976][Wall Clock 368.477383979s] Trained 64 records in 0.089351298 seconds. Throughput is 716.27386 records/second. Loss is 0.14088789. Sequential2290a28's hyper parameters: Current learning rate is 0.012539184952978058. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10432/60000][Iteration 2977][Wall Clock 368.577915942s] Trained 64 records in 0.100531963 seconds. Throughput is 636.61346 records/second. Loss is 0.10167824. Sequential2290a28's hyper parameters: Current learning rate is 0.012537612838515545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 2978][Wall Clock 368.696583326s] Trained 64 records in 0.118667384 seconds. Throughput is 539.3226 records/second. Loss is 0.33886945. Sequential2290a28's hyper parameters: Current learning rate is 0.012536041118214866. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10560/60000][Iteration 2979][Wall Clock 368.876662674s] Trained 64 records in 0.180079348 seconds. Throughput is 355.3989 records/second. Loss is 0.3214251. Sequential2290a28's hyper parameters: Current learning rate is 0.0125344697919278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10624/60000][Iteration 2980][Wall Clock 368.962780441s] Trained 64 records in 0.086117767 seconds. Throughput is 743.1684 records/second. Loss is 0.11486979. Sequential2290a28's hyper parameters: Current learning rate is 0.012532898859506203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:51 INFO  DistriOptimizer$:408 - [Epoch 4 10688/60000][Iteration 2981][Wall Clock 369.111876718s] Trained 64 records in 0.149096277 seconds. Throughput is 429.25284 records/second. Loss is 0.1545338. Sequential2290a28's hyper parameters: Current learning rate is 0.012531328320802004. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 2982][Wall Clock 369.224793825s] Trained 64 records in 0.112917107 seconds. Throughput is 566.7874 records/second. Loss is 0.14873923. Sequential2290a28's hyper parameters: Current learning rate is 0.01252975817566721. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 10816/60000][Iteration 2983][Wall Clock 369.326899055s] Trained 64 records in 0.10210523 seconds. Throughput is 626.8043 records/second. Loss is 0.1635002. Sequential2290a28's hyper parameters: Current learning rate is 0.012528188423953895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 10880/60000][Iteration 2984][Wall Clock 369.452089949s] Trained 64 records in 0.125190894 seconds. Throughput is 511.21927 records/second. Loss is 0.10443428. Sequential2290a28's hyper parameters: Current learning rate is 0.012526619065514218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 10944/60000][Iteration 2985][Wall Clock 369.58099917s] Trained 64 records in 0.128909221 seconds. Throughput is 496.47342 records/second. Loss is 0.1405759. Sequential2290a28's hyper parameters: Current learning rate is 0.012525050100200401. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 2986][Wall Clock 369.682582133s] Trained 64 records in 0.101582963 seconds. Throughput is 630.0269 records/second. Loss is 0.2859255. Sequential2290a28's hyper parameters: Current learning rate is 0.012523481527864746. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 11072/60000][Iteration 2987][Wall Clock 369.780888079s] Trained 64 records in 0.098305946 seconds. Throughput is 651.02875 records/second. Loss is 0.19374475. Sequential2290a28's hyper parameters: Current learning rate is 0.01252191334835963. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 11136/60000][Iteration 2988][Wall Clock 369.887353092s] Trained 64 records in 0.106465013 seconds. Throughput is 601.1365 records/second. Loss is 0.15376085. Sequential2290a28's hyper parameters: Current learning rate is 0.0125203455615375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 11200/60000][Iteration 2989][Wall Clock 369.976827376s] Trained 64 records in 0.089474284 seconds. Throughput is 715.2893 records/second. Loss is 0.21473794. Sequential2290a28's hyper parameters: Current learning rate is 0.012518778167250878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:52 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 2990][Wall Clock 370.077173479s] Trained 64 records in 0.100346103 seconds. Throughput is 637.7926 records/second. Loss is 0.23726064. Sequential2290a28's hyper parameters: Current learning rate is 0.01251721116535236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11328/60000][Iteration 2991][Wall Clock 370.166094901s] Trained 64 records in 0.088921422 seconds. Throughput is 719.7366 records/second. Loss is 0.11620082. Sequential2290a28's hyper parameters: Current learning rate is 0.01251564455569462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11392/60000][Iteration 2992][Wall Clock 370.258403188s] Trained 64 records in 0.092308287 seconds. Throughput is 693.32886 records/second. Loss is 0.17788973. Sequential2290a28's hyper parameters: Current learning rate is 0.012514078338130397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11456/60000][Iteration 2993][Wall Clock 370.408639403s] Trained 64 records in 0.150236215 seconds. Throughput is 425.99582 records/second. Loss is 0.11698524. Sequential2290a28's hyper parameters: Current learning rate is 0.012512512512512513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 2994][Wall Clock 370.542531811s] Trained 64 records in 0.133892408 seconds. Throughput is 477.99576 records/second. Loss is 0.23891422. Sequential2290a28's hyper parameters: Current learning rate is 0.012510947078693857. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11584/60000][Iteration 2995][Wall Clock 370.718392308s] Trained 64 records in 0.175860497 seconds. Throughput is 363.92484 records/second. Loss is 0.06868216. Sequential2290a28's hyper parameters: Current learning rate is 0.012509382036527395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11648/60000][Iteration 2996][Wall Clock 370.817667041s] Trained 64 records in 0.099274733 seconds. Throughput is 644.6756 records/second. Loss is 0.15629755. Sequential2290a28's hyper parameters: Current learning rate is 0.012507817385866166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11712/60000][Iteration 2997][Wall Clock 370.91473439s] Trained 64 records in 0.097067349 seconds. Throughput is 659.336 records/second. Loss is 0.43347842. Sequential2290a28's hyper parameters: Current learning rate is 0.01250625312656328. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:53 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 2998][Wall Clock 371.036235136s] Trained 64 records in 0.121500746 seconds. Throughput is 526.7457 records/second. Loss is 0.15636373. Sequential2290a28's hyper parameters: Current learning rate is 0.012504689258471926. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 11840/60000][Iteration 2999][Wall Clock 371.161006513s] Trained 64 records in 0.124771377 seconds. Throughput is 512.9382 records/second. Loss is 0.12925965. Sequential2290a28's hyper parameters: Current learning rate is 0.01250312578144536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 11904/60000][Iteration 3000][Wall Clock 371.270643735s] Trained 64 records in 0.109637222 seconds. Throughput is 583.74335 records/second. Loss is 0.11023015. Sequential2290a28's hyper parameters: Current learning rate is 0.012501562695336917. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 11968/60000][Iteration 3001][Wall Clock 371.349986415s] Trained 64 records in 0.07934268 seconds. Throughput is 806.6277 records/second. Loss is 0.23307006. Sequential2290a28's hyper parameters: Current learning rate is 0.012499999999999999. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 3002][Wall Clock 371.469725185s] Trained 64 records in 0.11973877 seconds. Throughput is 534.4969 records/second. Loss is 0.18637913. Sequential2290a28's hyper parameters: Current learning rate is 0.012498437695288089. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12096/60000][Iteration 3003][Wall Clock 371.556946552s] Trained 64 records in 0.087221367 seconds. Throughput is 733.76514 records/second. Loss is 0.26857716. Sequential2290a28's hyper parameters: Current learning rate is 0.012496875781054736. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12160/60000][Iteration 3004][Wall Clock 371.633665706s] Trained 64 records in 0.076719154 seconds. Throughput is 834.2114 records/second. Loss is 0.11158693. Sequential2290a28's hyper parameters: Current learning rate is 0.012495314257153568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12224/60000][Iteration 3005][Wall Clock 371.717316983s] Trained 64 records in 0.083651277 seconds. Throughput is 765.081 records/second. Loss is 0.16938347. Sequential2290a28's hyper parameters: Current learning rate is 0.012493753123438282. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 3006][Wall Clock 371.799718903s] Trained 64 records in 0.08240192 seconds. Throughput is 776.68097 records/second. Loss is 0.16472192. Sequential2290a28's hyper parameters: Current learning rate is 0.01249219237976265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12352/60000][Iteration 3007][Wall Clock 371.914283626s] Trained 64 records in 0.114564723 seconds. Throughput is 558.63617 records/second. Loss is 0.25498608. Sequential2290a28's hyper parameters: Current learning rate is 0.012490632025980514. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12416/60000][Iteration 3008][Wall Clock 371.990733414s] Trained 64 records in 0.076449788 seconds. Throughput is 837.15076 records/second. Loss is 0.13135582. Sequential2290a28's hyper parameters: Current learning rate is 0.012489072061945798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:54 INFO  DistriOptimizer$:408 - [Epoch 4 12480/60000][Iteration 3009][Wall Clock 372.06344013s] Trained 64 records in 0.072706716 seconds. Throughput is 880.24884 records/second. Loss is 0.17172332. Sequential2290a28's hyper parameters: Current learning rate is 0.012487512487512488. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 3010][Wall Clock 372.215893322s] Trained 64 records in 0.152453192 seconds. Throughput is 419.80096 records/second. Loss is 0.20796579. Sequential2290a28's hyper parameters: Current learning rate is 0.01248595330253465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12608/60000][Iteration 3011][Wall Clock 372.305750477s] Trained 64 records in 0.089857155 seconds. Throughput is 712.2416 records/second. Loss is 0.14993209. Sequential2290a28's hyper parameters: Current learning rate is 0.012484394506866418. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12672/60000][Iteration 3012][Wall Clock 372.452093531s] Trained 64 records in 0.146343054 seconds. Throughput is 437.32858 records/second. Loss is 0.14812976. Sequential2290a28's hyper parameters: Current learning rate is 0.012482836100362002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12736/60000][Iteration 3013][Wall Clock 372.539933129s] Trained 64 records in 0.087839598 seconds. Throughput is 728.6008 records/second. Loss is 0.14075269. Sequential2290a28's hyper parameters: Current learning rate is 0.012481278082875686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 3014][Wall Clock 372.695312684s] Trained 64 records in 0.155379555 seconds. Throughput is 411.89462 records/second. Loss is 0.1668631. Sequential2290a28's hyper parameters: Current learning rate is 0.012479720454261824. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12864/60000][Iteration 3015][Wall Clock 372.919208759s] Trained 64 records in 0.223896075 seconds. Throughput is 285.84692 records/second. Loss is 0.10546879. Sequential2290a28's hyper parameters: Current learning rate is 0.012478163214374845. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:55 INFO  DistriOptimizer$:408 - [Epoch 4 12928/60000][Iteration 3016][Wall Clock 373.068695566s] Trained 64 records in 0.149486807 seconds. Throughput is 428.1314 records/second. Loss is 0.1960922. Sequential2290a28's hyper parameters: Current learning rate is 0.012476606363069246. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 12992/60000][Iteration 3017][Wall Clock 373.192731867s] Trained 64 records in 0.124036301 seconds. Throughput is 515.97797 records/second. Loss is 0.206458. Sequential2290a28's hyper parameters: Current learning rate is 0.012475049900199599. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 3018][Wall Clock 373.299591838s] Trained 64 records in 0.106859971 seconds. Throughput is 598.9146 records/second. Loss is 0.24122366. Sequential2290a28's hyper parameters: Current learning rate is 0.012473493825620555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13120/60000][Iteration 3019][Wall Clock 373.381846162s] Trained 64 records in 0.082254324 seconds. Throughput is 778.07465 records/second. Loss is 0.12139894. Sequential2290a28's hyper parameters: Current learning rate is 0.012471938139186829. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13184/60000][Iteration 3020][Wall Clock 373.448047588s] Trained 64 records in 0.066201426 seconds. Throughput is 966.7465 records/second. Loss is 0.17072469. Sequential2290a28's hyper parameters: Current learning rate is 0.01247038284075321. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13248/60000][Iteration 3021][Wall Clock 373.531357555s] Trained 64 records in 0.083309967 seconds. Throughput is 768.21545 records/second. Loss is 0.16291347. Sequential2290a28's hyper parameters: Current learning rate is 0.012468827930174562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 3022][Wall Clock 373.736962979s] Trained 64 records in 0.205605424 seconds. Throughput is 311.27585 records/second. Loss is 0.13844447. Sequential2290a28's hyper parameters: Current learning rate is 0.012467273407305822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13376/60000][Iteration 3023][Wall Clock 373.851499327s] Trained 64 records in 0.114536348 seconds. Throughput is 558.7746 records/second. Loss is 0.25590563. Sequential2290a28's hyper parameters: Current learning rate is 0.012465719272001994. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:56 INFO  DistriOptimizer$:408 - [Epoch 4 13440/60000][Iteration 3024][Wall Clock 374.053359937s] Trained 64 records in 0.20186061 seconds. Throughput is 317.05048 records/second. Loss is 0.16476348. Sequential2290a28's hyper parameters: Current learning rate is 0.01246416552411816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13504/60000][Iteration 3025][Wall Clock 374.216883166s] Trained 64 records in 0.163523229 seconds. Throughput is 391.3817 records/second. Loss is 0.16578776. Sequential2290a28's hyper parameters: Current learning rate is 0.012462612163509471. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 3026][Wall Clock 374.309851988s] Trained 64 records in 0.092968822 seconds. Throughput is 688.40283 records/second. Loss is 0.07840589. Sequential2290a28's hyper parameters: Current learning rate is 0.012461059190031152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13632/60000][Iteration 3027][Wall Clock 374.450020399s] Trained 64 records in 0.140168411 seconds. Throughput is 456.5936 records/second. Loss is 0.16801271. Sequential2290a28's hyper parameters: Current learning rate is 0.0124595066035385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13696/60000][Iteration 3028][Wall Clock 374.580386113s] Trained 64 records in 0.130365714 seconds. Throughput is 490.92664 records/second. Loss is 0.17621982. Sequential2290a28's hyper parameters: Current learning rate is 0.012457954403886883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13760/60000][Iteration 3029][Wall Clock 374.696263659s] Trained 64 records in 0.115877546 seconds. Throughput is 552.3072 records/second. Loss is 0.20745078. Sequential2290a28's hyper parameters: Current learning rate is 0.01245640259093174. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 3030][Wall Clock 374.85364718s] Trained 64 records in 0.157383521 seconds. Throughput is 406.64996 records/second. Loss is 0.12788905. Sequential2290a28's hyper parameters: Current learning rate is 0.012454851164528585. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13888/60000][Iteration 3031][Wall Clock 374.95649704s] Trained 64 records in 0.10284986 seconds. Throughput is 622.26624 records/second. Loss is 0.16396078. Sequential2290a28's hyper parameters: Current learning rate is 0.012453300124533002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:57 INFO  DistriOptimizer$:408 - [Epoch 4 13952/60000][Iteration 3032][Wall Clock 375.050573513s] Trained 64 records in 0.094076473 seconds. Throughput is 680.2976 records/second. Loss is 0.12721017. Sequential2290a28's hyper parameters: Current learning rate is 0.012451749470800647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14016/60000][Iteration 3033][Wall Clock 375.191890366s] Trained 64 records in 0.141316853 seconds. Throughput is 452.88303 records/second. Loss is 0.05172187. Sequential2290a28's hyper parameters: Current learning rate is 0.01245019920318725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 3034][Wall Clock 375.305543706s] Trained 64 records in 0.11365334 seconds. Throughput is 563.1159 records/second. Loss is 0.20099111. Sequential2290a28's hyper parameters: Current learning rate is 0.012448649321548612. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14144/60000][Iteration 3035][Wall Clock 375.410619452s] Trained 64 records in 0.105075746 seconds. Throughput is 609.0844 records/second. Loss is 0.21862337. Sequential2290a28's hyper parameters: Current learning rate is 0.012447099825740602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14208/60000][Iteration 3036][Wall Clock 375.513707891s] Trained 64 records in 0.103088439 seconds. Throughput is 620.8262 records/second. Loss is 0.21716285. Sequential2290a28's hyper parameters: Current learning rate is 0.012445550715619166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14272/60000][Iteration 3037][Wall Clock 375.701213822s] Trained 64 records in 0.187505931 seconds. Throughput is 341.32254 records/second. Loss is 0.15364128. Sequential2290a28's hyper parameters: Current learning rate is 0.012444001991040317. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 3038][Wall Clock 375.852103239s] Trained 64 records in 0.150889417 seconds. Throughput is 424.1517 records/second. Loss is 0.1788668. Sequential2290a28's hyper parameters: Current learning rate is 0.012442453651860147. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:58 INFO  DistriOptimizer$:408 - [Epoch 4 14400/60000][Iteration 3039][Wall Clock 376.001057893s] Trained 64 records in 0.148954654 seconds. Throughput is 429.66095 records/second. Loss is 0.33778882. Sequential2290a28's hyper parameters: Current learning rate is 0.01244090569793481. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14464/60000][Iteration 3040][Wall Clock 376.151603282s] Trained 64 records in 0.150545389 seconds. Throughput is 425.12097 records/second. Loss is 0.12062747. Sequential2290a28's hyper parameters: Current learning rate is 0.012439358129120536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14528/60000][Iteration 3041][Wall Clock 376.324541234s] Trained 64 records in 0.172937952 seconds. Throughput is 370.07492 records/second. Loss is 0.15358216. Sequential2290a28's hyper parameters: Current learning rate is 0.01243781094527363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 3042][Wall Clock 376.422269184s] Trained 64 records in 0.09772795 seconds. Throughput is 654.8792 records/second. Loss is 0.15239856. Sequential2290a28's hyper parameters: Current learning rate is 0.012436264146250466. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14656/60000][Iteration 3043][Wall Clock 376.514623718s] Trained 64 records in 0.092354534 seconds. Throughput is 692.9817 records/second. Loss is 0.27448496. Sequential2290a28's hyper parameters: Current learning rate is 0.012434717731907486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14720/60000][Iteration 3044][Wall Clock 376.65692913s] Trained 64 records in 0.142305412 seconds. Throughput is 449.7369 records/second. Loss is 0.14208296. Sequential2290a28's hyper parameters: Current learning rate is 0.012433171702101207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14784/60000][Iteration 3045][Wall Clock 376.764597141s] Trained 64 records in 0.107668011 seconds. Throughput is 594.4198 records/second. Loss is 0.1342142. Sequential2290a28's hyper parameters: Current learning rate is 0.012431626056688214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 3046][Wall Clock 376.857472156s] Trained 64 records in 0.092875015 seconds. Throughput is 689.0981 records/second. Loss is 0.17900886. Sequential2290a28's hyper parameters: Current learning rate is 0.012430080795525171. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:19:59 INFO  DistriOptimizer$:408 - [Epoch 4 14912/60000][Iteration 3047][Wall Clock 377.016235273s] Trained 64 records in 0.158763117 seconds. Throughput is 403.1163 records/second. Loss is 0.25369608. Sequential2290a28's hyper parameters: Current learning rate is 0.012428535918468805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 14976/60000][Iteration 3048][Wall Clock 377.113692048s] Trained 64 records in 0.097456775 seconds. Throughput is 656.7014 records/second. Loss is 0.10850747. Sequential2290a28's hyper parameters: Current learning rate is 0.012426991425375917. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15040/60000][Iteration 3049][Wall Clock 377.192880902s] Trained 64 records in 0.079188854 seconds. Throughput is 808.1946 records/second. Loss is 0.13583797. Sequential2290a28's hyper parameters: Current learning rate is 0.01242544731610338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 3050][Wall Clock 377.287220717s] Trained 64 records in 0.094339815 seconds. Throughput is 678.3986 records/second. Loss is 0.08700915. Sequential2290a28's hyper parameters: Current learning rate is 0.012423903590508139. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15168/60000][Iteration 3051][Wall Clock 377.374702408s] Trained 64 records in 0.087481691 seconds. Throughput is 731.58167 records/second. Loss is 0.19965632. Sequential2290a28's hyper parameters: Current learning rate is 0.012422360248447206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15232/60000][Iteration 3052][Wall Clock 377.458862577s] Trained 64 records in 0.084160169 seconds. Throughput is 760.4547 records/second. Loss is 0.11960696. Sequential2290a28's hyper parameters: Current learning rate is 0.012420817289777668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15296/60000][Iteration 3053][Wall Clock 377.578800644s] Trained 64 records in 0.119938067 seconds. Throughput is 533.6087 records/second. Loss is 0.074554846. Sequential2290a28's hyper parameters: Current learning rate is 0.01241927471435668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 3054][Wall Clock 377.710412174s] Trained 64 records in 0.13161153 seconds. Throughput is 486.2796 records/second. Loss is 0.13570505. Sequential2290a28's hyper parameters: Current learning rate is 0.012417732522041475. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15424/60000][Iteration 3055][Wall Clock 377.851806782s] Trained 64 records in 0.141394608 seconds. Throughput is 452.63394 records/second. Loss is 0.232397. Sequential2290a28's hyper parameters: Current learning rate is 0.012416190712689347. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15488/60000][Iteration 3056][Wall Clock 377.947289012s] Trained 64 records in 0.09548223 seconds. Throughput is 670.2818 records/second. Loss is 0.15148184. Sequential2290a28's hyper parameters: Current learning rate is 0.012414649286157667. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:00 INFO  DistriOptimizer$:408 - [Epoch 4 15552/60000][Iteration 3057][Wall Clock 378.036308286s] Trained 64 records in 0.089019274 seconds. Throughput is 718.94543 records/second. Loss is 0.12684512. Sequential2290a28's hyper parameters: Current learning rate is 0.012413108242303872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 3058][Wall Clock 378.128522543s] Trained 64 records in 0.092214257 seconds. Throughput is 694.0358 records/second. Loss is 0.1744705. Sequential2290a28's hyper parameters: Current learning rate is 0.012411567580985477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 15680/60000][Iteration 3059][Wall Clock 378.254708636s] Trained 64 records in 0.126186093 seconds. Throughput is 507.18744 records/second. Loss is 0.1447539. Sequential2290a28's hyper parameters: Current learning rate is 0.012410027302060063. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 15744/60000][Iteration 3060][Wall Clock 378.351427346s] Trained 64 records in 0.09671871 seconds. Throughput is 661.7127 records/second. Loss is 0.14875972. Sequential2290a28's hyper parameters: Current learning rate is 0.012408487405385284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 15808/60000][Iteration 3061][Wall Clock 378.431161048s] Trained 64 records in 0.079733702 seconds. Throughput is 802.6719 records/second. Loss is 0.12568845. Sequential2290a28's hyper parameters: Current learning rate is 0.012406947890818858. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 3062][Wall Clock 378.529475543s] Trained 64 records in 0.098314495 seconds. Throughput is 650.97217 records/second. Loss is 0.105718724. Sequential2290a28's hyper parameters: Current learning rate is 0.012405408758218583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 15936/60000][Iteration 3063][Wall Clock 378.637828161s] Trained 64 records in 0.108352618 seconds. Throughput is 590.6641 records/second. Loss is 0.20486155. Sequential2290a28's hyper parameters: Current learning rate is 0.012403870007442322. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 16000/60000][Iteration 3064][Wall Clock 378.786344105s] Trained 64 records in 0.148515944 seconds. Throughput is 430.93018 records/second. Loss is 0.09868565. Sequential2290a28's hyper parameters: Current learning rate is 0.012402331638348009. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 16064/60000][Iteration 3065][Wall Clock 378.896104346s] Trained 64 records in 0.109760241 seconds. Throughput is 583.0891 records/second. Loss is 0.115635894. Sequential2290a28's hyper parameters: Current learning rate is 0.01240079365079365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:01 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 3066][Wall Clock 379.014556721s] Trained 64 records in 0.118452375 seconds. Throughput is 540.3015 records/second. Loss is 0.16865486. Sequential2290a28's hyper parameters: Current learning rate is 0.012399256044637322. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16192/60000][Iteration 3067][Wall Clock 379.138704546s] Trained 64 records in 0.124147825 seconds. Throughput is 515.51447 records/second. Loss is 0.3163627. Sequential2290a28's hyper parameters: Current learning rate is 0.012397718819737169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16256/60000][Iteration 3068][Wall Clock 379.245060514s] Trained 64 records in 0.106355968 seconds. Throughput is 601.7528 records/second. Loss is 0.11404824. Sequential2290a28's hyper parameters: Current learning rate is 0.012396181975951407. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16320/60000][Iteration 3069][Wall Clock 379.343408269s] Trained 64 records in 0.098347755 seconds. Throughput is 650.752 records/second. Loss is 0.19110914. Sequential2290a28's hyper parameters: Current learning rate is 0.012394645513138325. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 3070][Wall Clock 379.434955722s] Trained 64 records in 0.091547453 seconds. Throughput is 699.091 records/second. Loss is 0.25046796. Sequential2290a28's hyper parameters: Current learning rate is 0.012393109431156278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16448/60000][Iteration 3071][Wall Clock 379.574066262s] Trained 64 records in 0.13911054 seconds. Throughput is 460.0658 records/second. Loss is 0.13182685. Sequential2290a28's hyper parameters: Current learning rate is 0.012391573729863693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16512/60000][Iteration 3072][Wall Clock 379.666048527s] Trained 64 records in 0.091982265 seconds. Throughput is 695.78625 records/second. Loss is 0.1562377. Sequential2290a28's hyper parameters: Current learning rate is 0.012390038409119068. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16576/60000][Iteration 3073][Wall Clock 379.772939071s] Trained 64 records in 0.106890544 seconds. Throughput is 598.74335 records/second. Loss is 0.1761587. Sequential2290a28's hyper parameters: Current learning rate is 0.012388503468780971. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 3074][Wall Clock 379.855917804s] Trained 64 records in 0.082978733 seconds. Throughput is 771.282 records/second. Loss is 0.15660134. Sequential2290a28's hyper parameters: Current learning rate is 0.01238696890870804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16704/60000][Iteration 3075][Wall Clock 379.941088821s] Trained 64 records in 0.085171017 seconds. Throughput is 751.4294 records/second. Loss is 0.2085234. Sequential2290a28's hyper parameters: Current learning rate is 0.01238543472875898. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:02 INFO  DistriOptimizer$:408 - [Epoch 4 16768/60000][Iteration 3076][Wall Clock 380.030232736s] Trained 64 records in 0.089143915 seconds. Throughput is 717.9402 records/second. Loss is 0.15439618. Sequential2290a28's hyper parameters: Current learning rate is 0.01238390092879257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 16832/60000][Iteration 3077][Wall Clock 380.109692166s] Trained 64 records in 0.07945943 seconds. Throughput is 805.4425 records/second. Loss is 0.1656225. Sequential2290a28's hyper parameters: Current learning rate is 0.012382367508667657. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 3078][Wall Clock 380.193256196s] Trained 64 records in 0.08356403 seconds. Throughput is 765.87976 records/second. Loss is 0.114927985. Sequential2290a28's hyper parameters: Current learning rate is 0.012380834468243158. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 16960/60000][Iteration 3079][Wall Clock 380.271621537s] Trained 64 records in 0.078365341 seconds. Throughput is 816.68756 records/second. Loss is 0.1329841. Sequential2290a28's hyper parameters: Current learning rate is 0.012379301807378063. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17024/60000][Iteration 3080][Wall Clock 380.36289701s] Trained 64 records in 0.091275473 seconds. Throughput is 701.17413 records/second. Loss is 0.23519391. Sequential2290a28's hyper parameters: Current learning rate is 0.012377769525931427. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17088/60000][Iteration 3081][Wall Clock 380.460256776s] Trained 64 records in 0.097359766 seconds. Throughput is 657.3557 records/second. Loss is 0.08504436. Sequential2290a28's hyper parameters: Current learning rate is 0.012376237623762375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 3082][Wall Clock 380.570925934s] Trained 64 records in 0.110669158 seconds. Throughput is 578.30023 records/second. Loss is 0.23059282. Sequential2290a28's hyper parameters: Current learning rate is 0.012374706100730107. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17216/60000][Iteration 3083][Wall Clock 380.649431077s] Trained 64 records in 0.078505143 seconds. Throughput is 815.2332 records/second. Loss is 0.08980377. Sequential2290a28's hyper parameters: Current learning rate is 0.012373174956693888. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17280/60000][Iteration 3084][Wall Clock 380.77517553s] Trained 64 records in 0.125744453 seconds. Throughput is 508.9688 records/second. Loss is 0.18104877. Sequential2290a28's hyper parameters: Current learning rate is 0.012371644191513051. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17344/60000][Iteration 3085][Wall Clock 380.881849494s] Trained 64 records in 0.106673964 seconds. Throughput is 599.959 records/second. Loss is 0.13032636. Sequential2290a28's hyper parameters: Current learning rate is 0.012370113805047007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:03 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 3086][Wall Clock 380.999984481s] Trained 64 records in 0.118134987 seconds. Throughput is 541.7531 records/second. Loss is 0.16120553. Sequential2290a28's hyper parameters: Current learning rate is 0.012368583797155226. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17472/60000][Iteration 3087][Wall Clock 381.114187613s] Trained 64 records in 0.114203132 seconds. Throughput is 560.40497 records/second. Loss is 0.21567827. Sequential2290a28's hyper parameters: Current learning rate is 0.012367054167697254. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17536/60000][Iteration 3088][Wall Clock 381.205368285s] Trained 64 records in 0.091180672 seconds. Throughput is 701.90314 records/second. Loss is 0.30360737. Sequential2290a28's hyper parameters: Current learning rate is 0.012365524916532707. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17600/60000][Iteration 3089][Wall Clock 381.298590205s] Trained 64 records in 0.09322192 seconds. Throughput is 686.5338 records/second. Loss is 0.17894003. Sequential2290a28's hyper parameters: Current learning rate is 0.012363996043521267. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 3090][Wall Clock 381.394579685s] Trained 64 records in 0.09598948 seconds. Throughput is 666.73975 records/second. Loss is 0.18323323. Sequential2290a28's hyper parameters: Current learning rate is 0.012362467548522686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17728/60000][Iteration 3091][Wall Clock 381.501061322s] Trained 64 records in 0.106481637 seconds. Throughput is 601.0426 records/second. Loss is 0.09466105. Sequential2290a28's hyper parameters: Current learning rate is 0.012360939431396788. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17792/60000][Iteration 3092][Wall Clock 381.610406944s] Trained 64 records in 0.109345622 seconds. Throughput is 585.30005 records/second. Loss is 0.28790277. Sequential2290a28's hyper parameters: Current learning rate is 0.01235941169200346. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17856/60000][Iteration 3093][Wall Clock 381.723531103s] Trained 64 records in 0.113124159 seconds. Throughput is 565.75006 records/second. Loss is 0.12835488. Sequential2290a28's hyper parameters: Current learning rate is 0.012357884330202669. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:04 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 3094][Wall Clock 381.957603809s] Trained 64 records in 0.234072706 seconds. Throughput is 273.4193 records/second. Loss is 0.09507965. Sequential2290a28's hyper parameters: Current learning rate is 0.012356357345854442. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 17984/60000][Iteration 3095][Wall Clock 382.082337852s] Trained 64 records in 0.124734043 seconds. Throughput is 513.0917 records/second. Loss is 0.10529414. Sequential2290a28's hyper parameters: Current learning rate is 0.012354830738818878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18048/60000][Iteration 3096][Wall Clock 382.233203974s] Trained 64 records in 0.150866122 seconds. Throughput is 424.21716 records/second. Loss is 0.13188791. Sequential2290a28's hyper parameters: Current learning rate is 0.012353304508956145. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18112/60000][Iteration 3097][Wall Clock 382.315933641s] Trained 64 records in 0.082729667 seconds. Throughput is 773.604 records/second. Loss is 0.35709676. Sequential2290a28's hyper parameters: Current learning rate is 0.01235177865612648. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 3098][Wall Clock 382.428747422s] Trained 64 records in 0.112813781 seconds. Throughput is 567.3066 records/second. Loss is 0.15045807. Sequential2290a28's hyper parameters: Current learning rate is 0.012350253180190193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18240/60000][Iteration 3099][Wall Clock 382.552970201s] Trained 64 records in 0.124222779 seconds. Throughput is 515.2034 records/second. Loss is 0.18553397. Sequential2290a28's hyper parameters: Current learning rate is 0.012348728081007655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18304/60000][Iteration 3100][Wall Clock 382.647604302s] Trained 64 records in 0.094634101 seconds. Throughput is 676.289 records/second. Loss is 0.20241904. Sequential2290a28's hyper parameters: Current learning rate is 0.012347203358439312. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18368/60000][Iteration 3101][Wall Clock 382.722310476s] Trained 64 records in 0.074706174 seconds. Throughput is 856.6896 records/second. Loss is 0.22419378. Sequential2290a28's hyper parameters: Current learning rate is 0.012345679012345678. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 3102][Wall Clock 382.796890089s] Trained 64 records in 0.074579613 seconds. Throughput is 858.1434 records/second. Loss is 0.082761794. Sequential2290a28's hyper parameters: Current learning rate is 0.012344155042587334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18496/60000][Iteration 3103][Wall Clock 382.893159874s] Trained 64 records in 0.096269785 seconds. Throughput is 664.7984 records/second. Loss is 0.16996898. Sequential2290a28's hyper parameters: Current learning rate is 0.012342631449024932. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:05 INFO  DistriOptimizer$:408 - [Epoch 4 18560/60000][Iteration 3104][Wall Clock 382.985902343s] Trained 64 records in 0.092742469 seconds. Throughput is 690.083 records/second. Loss is 0.10969348. Sequential2290a28's hyper parameters: Current learning rate is 0.012341108231519191. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 18624/60000][Iteration 3105][Wall Clock 383.067824902s] Trained 64 records in 0.081922559 seconds. Throughput is 781.2256 records/second. Loss is 0.16527033. Sequential2290a28's hyper parameters: Current learning rate is 0.012339585389930898. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 3106][Wall Clock 383.144482562s] Trained 64 records in 0.07665766 seconds. Throughput is 834.8807 records/second. Loss is 0.19482791. Sequential2290a28's hyper parameters: Current learning rate is 0.012338062924120914. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 18752/60000][Iteration 3107][Wall Clock 383.21810275s] Trained 64 records in 0.073620188 seconds. Throughput is 869.3268 records/second. Loss is 0.10551149. Sequential2290a28's hyper parameters: Current learning rate is 0.01233654083395016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 18816/60000][Iteration 3108][Wall Clock 383.298812849s] Trained 64 records in 0.080710099 seconds. Throughput is 792.9615 records/second. Loss is 0.22560425. Sequential2290a28's hyper parameters: Current learning rate is 0.012335019119279636. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 18880/60000][Iteration 3109][Wall Clock 383.398575211s] Trained 64 records in 0.099762362 seconds. Throughput is 641.5245 records/second. Loss is 0.11394584. Sequential2290a28's hyper parameters: Current learning rate is 0.0123334977799704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 3110][Wall Clock 383.516821984s] Trained 64 records in 0.118246773 seconds. Throughput is 541.24097 records/second. Loss is 0.18273549. Sequential2290a28's hyper parameters: Current learning rate is 0.012331976815883588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 19008/60000][Iteration 3111][Wall Clock 383.619184555s] Trained 64 records in 0.102362571 seconds. Throughput is 625.2285 records/second. Loss is 0.20216796. Sequential2290a28's hyper parameters: Current learning rate is 0.012330456226880396. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 19072/60000][Iteration 3112][Wall Clock 383.695962805s] Trained 64 records in 0.07677825 seconds. Throughput is 833.5694 records/second. Loss is 0.31500563. Sequential2290a28's hyper parameters: Current learning rate is 0.012328936012822094. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 19136/60000][Iteration 3113][Wall Clock 383.82787109s] Trained 64 records in 0.131908285 seconds. Throughput is 485.1856 records/second. Loss is 0.26158032. Sequential2290a28's hyper parameters: Current learning rate is 0.01232741617357002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 3114][Wall Clock 383.940313192s] Trained 64 records in 0.112442102 seconds. Throughput is 569.1818 records/second. Loss is 0.10440245. Sequential2290a28's hyper parameters: Current learning rate is 0.012325896708985578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:06 INFO  DistriOptimizer$:408 - [Epoch 4 19264/60000][Iteration 3115][Wall Clock 384.02076011s] Trained 64 records in 0.080446918 seconds. Throughput is 795.5556 records/second. Loss is 0.14403205. Sequential2290a28's hyper parameters: Current learning rate is 0.012324377618930245. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19328/60000][Iteration 3116][Wall Clock 384.138901786s] Trained 64 records in 0.118141676 seconds. Throughput is 541.7225 records/second. Loss is 0.15563428. Sequential2290a28's hyper parameters: Current learning rate is 0.012322858903265559. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19392/60000][Iteration 3117][Wall Clock 384.258752703s] Trained 64 records in 0.119850917 seconds. Throughput is 533.99677 records/second. Loss is 0.17915927. Sequential2290a28's hyper parameters: Current learning rate is 0.01232134056185313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 3118][Wall Clock 384.377023347s] Trained 64 records in 0.118270644 seconds. Throughput is 541.1318 records/second. Loss is 0.18883577. Sequential2290a28's hyper parameters: Current learning rate is 0.012319822594554638. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19520/60000][Iteration 3119][Wall Clock 384.477175259s] Trained 64 records in 0.100151912 seconds. Throughput is 639.02924 records/second. Loss is 0.22199607. Sequential2290a28's hyper parameters: Current learning rate is 0.012318305001231829. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19584/60000][Iteration 3120][Wall Clock 384.578537724s] Trained 64 records in 0.101362465 seconds. Throughput is 631.3974 records/second. Loss is 0.16794348. Sequential2290a28's hyper parameters: Current learning rate is 0.012316787781746519. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19648/60000][Iteration 3121][Wall Clock 384.701533765s] Trained 64 records in 0.122996041 seconds. Throughput is 520.342 records/second. Loss is 0.280887. Sequential2290a28's hyper parameters: Current learning rate is 0.01231527093596059. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 3122][Wall Clock 384.888122419s] Trained 64 records in 0.186588654 seconds. Throughput is 343.0005 records/second. Loss is 0.16909379. Sequential2290a28's hyper parameters: Current learning rate is 0.012313754463735992. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:07 INFO  DistriOptimizer$:408 - [Epoch 4 19776/60000][Iteration 3123][Wall Clock 384.982470733s] Trained 64 records in 0.094348314 seconds. Throughput is 678.3375 records/second. Loss is 0.160794. Sequential2290a28's hyper parameters: Current learning rate is 0.012312238364934745. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 19840/60000][Iteration 3124][Wall Clock 385.087996663s] Trained 64 records in 0.10552593 seconds. Throughput is 606.48596 records/second. Loss is 0.17813969. Sequential2290a28's hyper parameters: Current learning rate is 0.012310722639418934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 19904/60000][Iteration 3125][Wall Clock 385.228222744s] Trained 64 records in 0.140226081 seconds. Throughput is 456.40582 records/second. Loss is 0.19392876. Sequential2290a28's hyper parameters: Current learning rate is 0.012309207287050714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 3126][Wall Clock 385.324115777s] Trained 64 records in 0.095893033 seconds. Throughput is 667.41034 records/second. Loss is 0.18880875. Sequential2290a28's hyper parameters: Current learning rate is 0.012307692307692308. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20032/60000][Iteration 3127][Wall Clock 385.451327024s] Trained 64 records in 0.127211247 seconds. Throughput is 503.1002 records/second. Loss is 0.2284041. Sequential2290a28's hyper parameters: Current learning rate is 0.012306177701206006. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20096/60000][Iteration 3128][Wall Clock 385.543185766s] Trained 64 records in 0.091858742 seconds. Throughput is 696.7219 records/second. Loss is 0.23477402. Sequential2290a28's hyper parameters: Current learning rate is 0.012304663467454166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20160/60000][Iteration 3129][Wall Clock 385.62887155s] Trained 64 records in 0.085685784 seconds. Throughput is 746.91504 records/second. Loss is 0.12969235. Sequential2290a28's hyper parameters: Current learning rate is 0.012303149606299213. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 3130][Wall Clock 385.708722726s] Trained 64 records in 0.079851176 seconds. Throughput is 801.491 records/second. Loss is 0.09292928. Sequential2290a28's hyper parameters: Current learning rate is 0.012301636117603642. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20288/60000][Iteration 3131][Wall Clock 385.81103595s] Trained 64 records in 0.102313224 seconds. Throughput is 625.5301 records/second. Loss is 0.24058022. Sequential2290a28's hyper parameters: Current learning rate is 0.012300123001230014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20352/60000][Iteration 3132][Wall Clock 385.89618634s] Trained 64 records in 0.08515039 seconds. Throughput is 751.6113 records/second. Loss is 0.11335642. Sequential2290a28's hyper parameters: Current learning rate is 0.012298610257040956. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:08 INFO  DistriOptimizer$:408 - [Epoch 4 20416/60000][Iteration 3133][Wall Clock 385.978506158s] Trained 64 records in 0.082319818 seconds. Throughput is 777.45557 records/second. Loss is 0.24867664. Sequential2290a28's hyper parameters: Current learning rate is 0.012297097884899164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 3134][Wall Clock 386.066420142s] Trained 64 records in 0.087913984 seconds. Throughput is 727.9843 records/second. Loss is 0.09132449. Sequential2290a28's hyper parameters: Current learning rate is 0.012295585884667405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20544/60000][Iteration 3135][Wall Clock 386.181395042s] Trained 64 records in 0.1149749 seconds. Throughput is 556.64325 records/second. Loss is 0.24092245. Sequential2290a28's hyper parameters: Current learning rate is 0.012294074256208508. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20608/60000][Iteration 3136][Wall Clock 386.293878289s] Trained 64 records in 0.112483247 seconds. Throughput is 568.97363 records/second. Loss is 0.09760368. Sequential2290a28's hyper parameters: Current learning rate is 0.012292562999385371. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20672/60000][Iteration 3137][Wall Clock 386.379059199s] Trained 64 records in 0.08518091 seconds. Throughput is 751.34204 records/second. Loss is 0.25246096. Sequential2290a28's hyper parameters: Current learning rate is 0.012291052114060964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 3138][Wall Clock 386.467570965s] Trained 64 records in 0.088511766 seconds. Throughput is 723.06775 records/second. Loss is 0.13984653. Sequential2290a28's hyper parameters: Current learning rate is 0.012289541600098316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20800/60000][Iteration 3139][Wall Clock 386.56352073s] Trained 64 records in 0.095949765 seconds. Throughput is 667.01575 records/second. Loss is 0.32085484. Sequential2290a28's hyper parameters: Current learning rate is 0.01228803145736053. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20864/60000][Iteration 3140][Wall Clock 386.667952735s] Trained 64 records in 0.104432005 seconds. Throughput is 612.839 records/second. Loss is 0.18752946. Sequential2290a28's hyper parameters: Current learning rate is 0.012286521685710775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20928/60000][Iteration 3141][Wall Clock 386.764881227s] Trained 64 records in 0.096928492 seconds. Throughput is 660.2806 records/second. Loss is 0.1377637. Sequential2290a28's hyper parameters: Current learning rate is 0.012285012285012284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 3142][Wall Clock 386.844171112s] Trained 64 records in 0.079289885 seconds. Throughput is 807.16473 records/second. Loss is 0.2254948. Sequential2290a28's hyper parameters: Current learning rate is 0.012283503255128362. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:09 INFO  DistriOptimizer$:408 - [Epoch 4 21056/60000][Iteration 3143][Wall Clock 386.933173898s] Trained 64 records in 0.089002786 seconds. Throughput is 719.0786 records/second. Loss is 0.23039284. Sequential2290a28's hyper parameters: Current learning rate is 0.012281994595922378. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21120/60000][Iteration 3144][Wall Clock 387.011189566s] Trained 64 records in 0.078015668 seconds. Throughput is 820.348 records/second. Loss is 0.19427803. Sequential2290a28's hyper parameters: Current learning rate is 0.012280486307257768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21184/60000][Iteration 3145][Wall Clock 387.120543575s] Trained 64 records in 0.109354009 seconds. Throughput is 585.2552 records/second. Loss is 0.1812669. Sequential2290a28's hyper parameters: Current learning rate is 0.012278978388998035. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 3146][Wall Clock 387.244771717s] Trained 64 records in 0.124228142 seconds. Throughput is 515.18115 records/second. Loss is 0.21528785. Sequential2290a28's hyper parameters: Current learning rate is 0.012277470841006752. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21312/60000][Iteration 3147][Wall Clock 387.326213294s] Trained 64 records in 0.081441577 seconds. Throughput is 785.8394 records/second. Loss is 0.102864794. Sequential2290a28's hyper parameters: Current learning rate is 0.012275963663147557. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21376/60000][Iteration 3148][Wall Clock 387.418651525s] Trained 64 records in 0.092438231 seconds. Throughput is 692.35425 records/second. Loss is 0.14362931. Sequential2290a28's hyper parameters: Current learning rate is 0.012274456855284154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21440/60000][Iteration 3149][Wall Clock 387.497282517s] Trained 64 records in 0.078630992 seconds. Throughput is 813.92847 records/second. Loss is 0.11007945. Sequential2290a28's hyper parameters: Current learning rate is 0.012272950417280316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 3150][Wall Clock 387.568079197s] Trained 64 records in 0.07079668 seconds. Throughput is 903.99713 records/second. Loss is 0.079827294. Sequential2290a28's hyper parameters: Current learning rate is 0.012271444348999879. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21568/60000][Iteration 3151][Wall Clock 387.636380973s] Trained 64 records in 0.068301776 seconds. Throughput is 937.0181 records/second. Loss is 0.2518879. Sequential2290a28's hyper parameters: Current learning rate is 0.012269938650306749. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21632/60000][Iteration 3152][Wall Clock 387.702313345s] Trained 64 records in 0.065932372 seconds. Throughput is 970.69165 records/second. Loss is 0.09204418. Sequential2290a28's hyper parameters: Current learning rate is 0.0122684333210649. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21696/60000][Iteration 3153][Wall Clock 387.779755264s] Trained 64 records in 0.077441919 seconds. Throughput is 826.42584 records/second. Loss is 0.26276758. Sequential2290a28's hyper parameters: Current learning rate is 0.01226692836113837. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 3154][Wall Clock 387.855172947s] Trained 64 records in 0.075417683 seconds. Throughput is 848.60736 records/second. Loss is 0.20256536. Sequential2290a28's hyper parameters: Current learning rate is 0.012265423770391267. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21824/60000][Iteration 3155][Wall Clock 387.920662559s] Trained 64 records in 0.065489612 seconds. Throughput is 977.2542 records/second. Loss is 0.22343154. Sequential2290a28's hyper parameters: Current learning rate is 0.01226391954868776. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:10 INFO  DistriOptimizer$:408 - [Epoch 4 21888/60000][Iteration 3156][Wall Clock 387.992817919s] Trained 64 records in 0.07215536 seconds. Throughput is 886.97504 records/second. Loss is 0.28264716. Sequential2290a28's hyper parameters: Current learning rate is 0.012262415695892091. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 21952/60000][Iteration 3157][Wall Clock 388.063625317s] Trained 64 records in 0.070807398 seconds. Throughput is 903.86035 records/second. Loss is 0.13965282. Sequential2290a28's hyper parameters: Current learning rate is 0.012260912211868563. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 3158][Wall Clock 388.139098613s] Trained 64 records in 0.075473296 seconds. Throughput is 847.98206 records/second. Loss is 0.08389782. Sequential2290a28's hyper parameters: Current learning rate is 0.012259409096481549. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22080/60000][Iteration 3159][Wall Clock 388.213814516s] Trained 64 records in 0.074715903 seconds. Throughput is 856.578 records/second. Loss is 0.182053. Sequential2290a28's hyper parameters: Current learning rate is 0.012257906349595489. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22144/60000][Iteration 3160][Wall Clock 388.302039827s] Trained 64 records in 0.088225311 seconds. Throughput is 725.4154 records/second. Loss is 0.1634469. Sequential2290a28's hyper parameters: Current learning rate is 0.012256403971074886. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22208/60000][Iteration 3161][Wall Clock 388.395626921s] Trained 64 records in 0.093587094 seconds. Throughput is 683.855 records/second. Loss is 0.1502851. Sequential2290a28's hyper parameters: Current learning rate is 0.012254901960784314. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 3162][Wall Clock 388.524013055s] Trained 64 records in 0.128386134 seconds. Throughput is 498.4962 records/second. Loss is 0.11908123. Sequential2290a28's hyper parameters: Current learning rate is 0.012253400318588408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22336/60000][Iteration 3163][Wall Clock 388.614841327s] Trained 64 records in 0.090828272 seconds. Throughput is 704.62646 records/second. Loss is 0.10344952. Sequential2290a28's hyper parameters: Current learning rate is 0.012251899044351875. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22400/60000][Iteration 3164][Wall Clock 388.7129834s] Trained 64 records in 0.098142073 seconds. Throughput is 652.11584 records/second. Loss is 0.1400928. Sequential2290a28's hyper parameters: Current learning rate is 0.012250398137939484. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22464/60000][Iteration 3165][Wall Clock 388.798517712s] Trained 64 records in 0.085534312 seconds. Throughput is 748.23773 records/second. Loss is 0.13901284. Sequential2290a28's hyper parameters: Current learning rate is 0.01224889759921607. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 3166][Wall Clock 388.897640597s] Trained 64 records in 0.099122885 seconds. Throughput is 645.6632 records/second. Loss is 0.109936826. Sequential2290a28's hyper parameters: Current learning rate is 0.012247397428046541. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:11 INFO  DistriOptimizer$:408 - [Epoch 4 22592/60000][Iteration 3167][Wall Clock 388.974117974s] Trained 64 records in 0.076477377 seconds. Throughput is 836.84875 records/second. Loss is 0.14423671. Sequential2290a28's hyper parameters: Current learning rate is 0.012245897624295862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 22656/60000][Iteration 3168][Wall Clock 389.07608366s] Trained 64 records in 0.101965686 seconds. Throughput is 627.6621 records/second. Loss is 0.15616387. Sequential2290a28's hyper parameters: Current learning rate is 0.012244398187829068. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 22720/60000][Iteration 3169][Wall Clock 389.186385163s] Trained 64 records in 0.110301503 seconds. Throughput is 580.22784 records/second. Loss is 0.3102168. Sequential2290a28's hyper parameters: Current learning rate is 0.012242899118511265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 3170][Wall Clock 389.343350548s] Trained 64 records in 0.156965385 seconds. Throughput is 407.7332 records/second. Loss is 0.22314692. Sequential2290a28's hyper parameters: Current learning rate is 0.012241400416207615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 22848/60000][Iteration 3171][Wall Clock 389.467416828s] Trained 64 records in 0.12406628 seconds. Throughput is 515.85333 records/second. Loss is 0.21539113. Sequential2290a28's hyper parameters: Current learning rate is 0.012239902080783354. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 22912/60000][Iteration 3172][Wall Clock 389.546583472s] Trained 64 records in 0.079166644 seconds. Throughput is 808.42126 records/second. Loss is 0.28162813. Sequential2290a28's hyper parameters: Current learning rate is 0.012238404112103782. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 22976/60000][Iteration 3173][Wall Clock 389.711313287s] Trained 64 records in 0.164729815 seconds. Throughput is 388.51495 records/second. Loss is 0.13275683. Sequential2290a28's hyper parameters: Current learning rate is 0.012236906510034264. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 3174][Wall Clock 389.810471176s] Trained 64 records in 0.099157889 seconds. Throughput is 645.43524 records/second. Loss is 0.18074034. Sequential2290a28's hyper parameters: Current learning rate is 0.01223540927444023. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 23104/60000][Iteration 3175][Wall Clock 389.911761799s] Trained 64 records in 0.101290623 seconds. Throughput is 631.8453 records/second. Loss is 0.19567552. Sequential2290a28's hyper parameters: Current learning rate is 0.012233912405187179. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:12 INFO  DistriOptimizer$:408 - [Epoch 4 23168/60000][Iteration 3176][Wall Clock 389.995445384s] Trained 64 records in 0.083683585 seconds. Throughput is 764.7856 records/second. Loss is 0.18366027. Sequential2290a28's hyper parameters: Current learning rate is 0.012232415902140673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23232/60000][Iteration 3177][Wall Clock 390.091154924s] Trained 64 records in 0.09570954 seconds. Throughput is 668.6899 records/second. Loss is 0.2274132. Sequential2290a28's hyper parameters: Current learning rate is 0.012230919765166342. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 3178][Wall Clock 390.181294478s] Trained 64 records in 0.090139554 seconds. Throughput is 710.0102 records/second. Loss is 0.17176652. Sequential2290a28's hyper parameters: Current learning rate is 0.012229423994129875. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23360/60000][Iteration 3179][Wall Clock 390.273218368s] Trained 64 records in 0.09192389 seconds. Throughput is 696.22815 records/second. Loss is 0.07804064. Sequential2290a28's hyper parameters: Current learning rate is 0.01222792858889704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23424/60000][Iteration 3180][Wall Clock 390.358840724s] Trained 64 records in 0.085622356 seconds. Throughput is 747.4683 records/second. Loss is 0.13474596. Sequential2290a28's hyper parameters: Current learning rate is 0.012226433549333659. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23488/60000][Iteration 3181][Wall Clock 390.434553677s] Trained 64 records in 0.075712953 seconds. Throughput is 845.29785 records/second. Loss is 0.11982189. Sequential2290a28's hyper parameters: Current learning rate is 0.012224938875305623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 3182][Wall Clock 390.518942734s] Trained 64 records in 0.084389057 seconds. Throughput is 758.3922 records/second. Loss is 0.12796289. Sequential2290a28's hyper parameters: Current learning rate is 0.01222344456667889. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23616/60000][Iteration 3183][Wall Clock 390.607943791s] Trained 64 records in 0.089001057 seconds. Throughput is 719.0926 records/second. Loss is 0.0781168. Sequential2290a28's hyper parameters: Current learning rate is 0.012221950623319482. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23680/60000][Iteration 3184][Wall Clock 390.70775386s] Trained 64 records in 0.099810069 seconds. Throughput is 641.21783 records/second. Loss is 0.20174697. Sequential2290a28's hyper parameters: Current learning rate is 0.012220457045093487. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23744/60000][Iteration 3185][Wall Clock 390.805384775s] Trained 64 records in 0.097630915 seconds. Throughput is 655.53 records/second. Loss is 0.1266469. Sequential2290a28's hyper parameters: Current learning rate is 0.012218963831867057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:13 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 3186][Wall Clock 390.892064114s] Trained 64 records in 0.086679339 seconds. Throughput is 738.3536 records/second. Loss is 0.12442773. Sequential2290a28's hyper parameters: Current learning rate is 0.012217470983506415. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 23872/60000][Iteration 3187][Wall Clock 391.011065917s] Trained 64 records in 0.119001803 seconds. Throughput is 537.80695 records/second. Loss is 0.26014498. Sequential2290a28's hyper parameters: Current learning rate is 0.012215978499877841. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 23936/60000][Iteration 3188][Wall Clock 391.135971571s] Trained 64 records in 0.124905654 seconds. Throughput is 512.3867 records/second. Loss is 0.14270192. Sequential2290a28's hyper parameters: Current learning rate is 0.012214486380847685. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24000/60000][Iteration 3189][Wall Clock 391.257537787s] Trained 64 records in 0.121566216 seconds. Throughput is 526.46204 records/second. Loss is 0.07672313. Sequential2290a28's hyper parameters: Current learning rate is 0.012212994626282366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 3190][Wall Clock 391.37000237s] Trained 64 records in 0.112464583 seconds. Throughput is 569.06805 records/second. Loss is 0.1280307. Sequential2290a28's hyper parameters: Current learning rate is 0.012211503236048358. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24128/60000][Iteration 3191][Wall Clock 391.487219948s] Trained 64 records in 0.117217578 seconds. Throughput is 545.9932 records/second. Loss is 0.14797482. Sequential2290a28's hyper parameters: Current learning rate is 0.012210012210012212. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24192/60000][Iteration 3192][Wall Clock 391.587131746s] Trained 64 records in 0.099911798 seconds. Throughput is 640.56494 records/second. Loss is 0.099022664. Sequential2290a28's hyper parameters: Current learning rate is 0.012208521548040533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24256/60000][Iteration 3193][Wall Clock 391.693819811s] Trained 64 records in 0.106688065 seconds. Throughput is 599.87964 records/second. Loss is 0.1496207. Sequential2290a28's hyper parameters: Current learning rate is 0.01220703125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 3194][Wall Clock 391.851154963s] Trained 64 records in 0.157335152 seconds. Throughput is 406.77496 records/second. Loss is 0.15869059. Sequential2290a28's hyper parameters: Current learning rate is 0.012205541315757353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:14 INFO  DistriOptimizer$:408 - [Epoch 4 24384/60000][Iteration 3195][Wall Clock 391.948598573s] Trained 64 records in 0.09744361 seconds. Throughput is 656.7901 records/second. Loss is 0.20378073. Sequential2290a28's hyper parameters: Current learning rate is 0.0122040517451794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24448/60000][Iteration 3196][Wall Clock 392.037536177s] Trained 64 records in 0.088937604 seconds. Throughput is 719.60565 records/second. Loss is 0.05828675. Sequential2290a28's hyper parameters: Current learning rate is 0.012202562538133009. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24512/60000][Iteration 3197][Wall Clock 392.164097808s] Trained 64 records in 0.126561631 seconds. Throughput is 505.6825 records/second. Loss is 0.1572228. Sequential2290a28's hyper parameters: Current learning rate is 0.012201073694485115. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 3198][Wall Clock 392.298444975s] Trained 64 records in 0.134347167 seconds. Throughput is 476.37772 records/second. Loss is 0.10278113. Sequential2290a28's hyper parameters: Current learning rate is 0.012199585214102719. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24640/60000][Iteration 3199][Wall Clock 392.40505648s] Trained 64 records in 0.106611505 seconds. Throughput is 600.3104 records/second. Loss is 0.28317624. Sequential2290a28's hyper parameters: Current learning rate is 0.01219809709685289. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24704/60000][Iteration 3200][Wall Clock 392.548529817s] Trained 64 records in 0.143473337 seconds. Throughput is 446.0759 records/second. Loss is 0.09495231. Sequential2290a28's hyper parameters: Current learning rate is 0.012196609342602756. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24768/60000][Iteration 3201][Wall Clock 392.699373082s] Trained 64 records in 0.150843265 seconds. Throughput is 424.28146 records/second. Loss is 0.049971797. Sequential2290a28's hyper parameters: Current learning rate is 0.012195121951219511. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 3202][Wall Clock 392.852026003s] Trained 64 records in 0.152652921 seconds. Throughput is 419.25174 records/second. Loss is 0.17456786. Sequential2290a28's hyper parameters: Current learning rate is 0.012193634922570418. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:15 INFO  DistriOptimizer$:408 - [Epoch 4 24896/60000][Iteration 3203][Wall Clock 392.950442305s] Trained 64 records in 0.098416302 seconds. Throughput is 650.29877 records/second. Loss is 0.21579081. Sequential2290a28's hyper parameters: Current learning rate is 0.0121921482565228. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 24960/60000][Iteration 3204][Wall Clock 393.078620192s] Trained 64 records in 0.128177887 seconds. Throughput is 499.30612 records/second. Loss is 0.21849309. Sequential2290a28's hyper parameters: Current learning rate is 0.012190661952944045. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25024/60000][Iteration 3205][Wall Clock 393.208055508s] Trained 64 records in 0.129435316 seconds. Throughput is 494.45547 records/second. Loss is 0.1621648. Sequential2290a28's hyper parameters: Current learning rate is 0.01218917601170161. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 3206][Wall Clock 393.311890708s] Trained 64 records in 0.1038352 seconds. Throughput is 616.36127 records/second. Loss is 0.20849177. Sequential2290a28's hyper parameters: Current learning rate is 0.01218769043266301. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25152/60000][Iteration 3207][Wall Clock 393.40946771s] Trained 64 records in 0.097577002 seconds. Throughput is 655.8922 records/second. Loss is 0.1903423. Sequential2290a28's hyper parameters: Current learning rate is 0.012186205215695833. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25216/60000][Iteration 3208][Wall Clock 393.505860433s] Trained 64 records in 0.096392723 seconds. Throughput is 663.95056 records/second. Loss is 0.2214227. Sequential2290a28's hyper parameters: Current learning rate is 0.012184720360667723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25280/60000][Iteration 3209][Wall Clock 393.598414643s] Trained 64 records in 0.09255421 seconds. Throughput is 691.48663 records/second. Loss is 0.22596611. Sequential2290a28's hyper parameters: Current learning rate is 0.012183235867446395. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 3210][Wall Clock 393.714778951s] Trained 64 records in 0.116364308 seconds. Throughput is 549.9968 records/second. Loss is 0.09239544. Sequential2290a28's hyper parameters: Current learning rate is 0.012181751735899624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25408/60000][Iteration 3211][Wall Clock 393.833445009s] Trained 64 records in 0.118666058 seconds. Throughput is 539.3286 records/second. Loss is 0.11194997. Sequential2290a28's hyper parameters: Current learning rate is 0.01218026796589525. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:16 INFO  DistriOptimizer$:408 - [Epoch 4 25472/60000][Iteration 3212][Wall Clock 393.923267247s] Trained 64 records in 0.089822238 seconds. Throughput is 712.51843 records/second. Loss is 0.16918351. Sequential2290a28's hyper parameters: Current learning rate is 0.012178784557301182. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:17 INFO  DistriOptimizer$:408 - [Epoch 4 25536/60000][Iteration 3213][Wall Clock 394.030056633s] Trained 64 records in 0.106789386 seconds. Throughput is 599.3105 records/second. Loss is 0.25464237. Sequential2290a28's hyper parameters: Current learning rate is 0.012177301509985387. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:17 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 3214][Wall Clock 394.187344467s] Trained 64 records in 0.157287834 seconds. Throughput is 406.89734 records/second. Loss is 0.1157945. Sequential2290a28's hyper parameters: Current learning rate is 0.0121758188238159. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:17 INFO  DistriOptimizer$:408 - [Epoch 4 25664/60000][Iteration 3215][Wall Clock 394.431308316s] Trained 64 records in 0.243963849 seconds. Throughput is 262.33395 records/second. Loss is 0.2503714. Sequential2290a28's hyper parameters: Current learning rate is 0.012174336498660824. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:17 INFO  DistriOptimizer$:408 - [Epoch 4 25728/60000][Iteration 3216][Wall Clock 394.544682817s] Trained 64 records in 0.113374501 seconds. Throughput is 564.50085 records/second. Loss is 0.08522983. Sequential2290a28's hyper parameters: Current learning rate is 0.012172854534388313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:17 INFO  DistriOptimizer$:408 - [Epoch 4 25792/60000][Iteration 3217][Wall Clock 394.728835006s] Trained 64 records in 0.184152189 seconds. Throughput is 347.53864 records/second. Loss is 0.10098178. Sequential2290a28's hyper parameters: Current learning rate is 0.012171372930866602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:17 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 3218][Wall Clock 394.850642239s] Trained 64 records in 0.121807233 seconds. Throughput is 525.42035 records/second. Loss is 0.12325406. Sequential2290a28's hyper parameters: Current learning rate is 0.012169891687963976. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 25920/60000][Iteration 3219][Wall Clock 395.000860528s] Trained 64 records in 0.150218289 seconds. Throughput is 426.04666 records/second. Loss is 0.13040446. Sequential2290a28's hyper parameters: Current learning rate is 0.012168410805548794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 25984/60000][Iteration 3220][Wall Clock 395.0830334s] Trained 64 records in 0.082172872 seconds. Throughput is 778.8459 records/second. Loss is 0.4312266. Sequential2290a28's hyper parameters: Current learning rate is 0.012166930283489474. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 26048/60000][Iteration 3221][Wall Clock 395.234326748s] Trained 64 records in 0.151293348 seconds. Throughput is 423.01926 records/second. Loss is 0.066984005. Sequential2290a28's hyper parameters: Current learning rate is 0.0121654501216545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 3222][Wall Clock 395.347519762s] Trained 64 records in 0.113193014 seconds. Throughput is 565.40594 records/second. Loss is 0.2463777. Sequential2290a28's hyper parameters: Current learning rate is 0.012163970319912419. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 26176/60000][Iteration 3223][Wall Clock 395.515353085s] Trained 64 records in 0.167833323 seconds. Throughput is 381.3307 records/second. Loss is 0.17455499. Sequential2290a28's hyper parameters: Current learning rate is 0.012162490878131841. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 26240/60000][Iteration 3224][Wall Clock 395.634122293s] Trained 64 records in 0.118769208 seconds. Throughput is 538.8602 records/second. Loss is 0.100994766. Sequential2290a28's hyper parameters: Current learning rate is 0.012161011796181441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:18 INFO  DistriOptimizer$:408 - [Epoch 4 26304/60000][Iteration 3225][Wall Clock 395.892196485s] Trained 64 records in 0.258074192 seconds. Throughput is 247.99069 records/second. Loss is 0.11722537. Sequential2290a28's hyper parameters: Current learning rate is 0.012159533073929961. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 3226][Wall Clock 395.975277246s] Trained 64 records in 0.083080761 seconds. Throughput is 770.3348 records/second. Loss is 0.19611922. Sequential2290a28's hyper parameters: Current learning rate is 0.0121580547112462. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26432/60000][Iteration 3227][Wall Clock 396.121076054s] Trained 64 records in 0.145798808 seconds. Throughput is 438.9611 records/second. Loss is 0.21503069. Sequential2290a28's hyper parameters: Current learning rate is 0.012156576707999028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26496/60000][Iteration 3228][Wall Clock 396.25189416s] Trained 64 records in 0.130818106 seconds. Throughput is 489.22894 records/second. Loss is 0.20084262. Sequential2290a28's hyper parameters: Current learning rate is 0.012155099064057373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26560/60000][Iteration 3229][Wall Clock 396.333968995s] Trained 64 records in 0.082074835 seconds. Throughput is 779.7762 records/second. Loss is 0.08187322. Sequential2290a28's hyper parameters: Current learning rate is 0.01215362177929023. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 3230][Wall Clock 396.531929373s] Trained 64 records in 0.197960378 seconds. Throughput is 323.29703 records/second. Loss is 0.16659069. Sequential2290a28's hyper parameters: Current learning rate is 0.012152144853566655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26688/60000][Iteration 3231][Wall Clock 396.792122389s] Trained 64 records in 0.260193016 seconds. Throughput is 245.97124 records/second. Loss is 0.15374547. Sequential2290a28's hyper parameters: Current learning rate is 0.012150668286755772. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:19 INFO  DistriOptimizer$:408 - [Epoch 4 26752/60000][Iteration 3232][Wall Clock 396.961623963s] Trained 64 records in 0.169501574 seconds. Throughput is 377.5776 records/second. Loss is 0.19639085. Sequential2290a28's hyper parameters: Current learning rate is 0.012149192078726766. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 26816/60000][Iteration 3233][Wall Clock 397.144909467s] Trained 64 records in 0.183285504 seconds. Throughput is 349.182 records/second. Loss is 0.35235414. Sequential2290a28's hyper parameters: Current learning rate is 0.012147716229348881. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 3234][Wall Clock 397.260444759s] Trained 64 records in 0.115535292 seconds. Throughput is 553.9433 records/second. Loss is 0.17311198. Sequential2290a28's hyper parameters: Current learning rate is 0.012146240738491437. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 26944/60000][Iteration 3235][Wall Clock 397.35857094s] Trained 64 records in 0.098126181 seconds. Throughput is 652.22144 records/second. Loss is 0.1543119. Sequential2290a28's hyper parameters: Current learning rate is 0.012144765606023804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 27008/60000][Iteration 3236][Wall Clock 397.466638541s] Trained 64 records in 0.108067601 seconds. Throughput is 592.2219 records/second. Loss is 0.12489674. Sequential2290a28's hyper parameters: Current learning rate is 0.012143290831815421. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 27072/60000][Iteration 3237][Wall Clock 397.559527263s] Trained 64 records in 0.092888722 seconds. Throughput is 688.99646 records/second. Loss is 0.12824596. Sequential2290a28's hyper parameters: Current learning rate is 0.012141816415735794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 3238][Wall Clock 397.66114086s] Trained 64 records in 0.101613597 seconds. Throughput is 629.837 records/second. Loss is 0.21466158. Sequential2290a28's hyper parameters: Current learning rate is 0.012140342357654484. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 27200/60000][Iteration 3239][Wall Clock 397.751044074s] Trained 64 records in 0.089903214 seconds. Throughput is 711.87665 records/second. Loss is 0.2732977. Sequential2290a28's hyper parameters: Current learning rate is 0.012138868657441125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:20 INFO  DistriOptimizer$:408 - [Epoch 4 27264/60000][Iteration 3240][Wall Clock 397.945551443s] Trained 64 records in 0.194507369 seconds. Throughput is 329.03638 records/second. Loss is 0.11203333. Sequential2290a28's hyper parameters: Current learning rate is 0.012137395314965408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:21 INFO  DistriOptimizer$:408 - [Epoch 4 27328/60000][Iteration 3241][Wall Clock 398.087813811s] Trained 64 records in 0.142262368 seconds. Throughput is 449.87302 records/second. Loss is 0.12559856. Sequential2290a28's hyper parameters: Current learning rate is 0.012135922330097087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:21 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 3242][Wall Clock 398.29272631s] Trained 64 records in 0.204912499 seconds. Throughput is 312.32843 records/second. Loss is 0.083901554. Sequential2290a28's hyper parameters: Current learning rate is 0.012134449702705982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:21 INFO  DistriOptimizer$:408 - [Epoch 4 27456/60000][Iteration 3243][Wall Clock 398.469667386s] Trained 64 records in 0.176941076 seconds. Throughput is 361.70233 records/second. Loss is 0.12681903. Sequential2290a28's hyper parameters: Current learning rate is 0.012132977432661975. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:21 INFO  DistriOptimizer$:408 - [Epoch 4 27520/60000][Iteration 3244][Wall Clock 398.610595633s] Trained 64 records in 0.140928247 seconds. Throughput is 454.13177 records/second. Loss is 0.18217185. Sequential2290a28's hyper parameters: Current learning rate is 0.01213150551983501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:21 INFO  DistriOptimizer$:408 - [Epoch 4 27584/60000][Iteration 3245][Wall Clock 398.736571811s] Trained 64 records in 0.125976178 seconds. Throughput is 508.03256 records/second. Loss is 0.16618457. Sequential2290a28's hyper parameters: Current learning rate is 0.012130033964095099. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:21 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 3246][Wall Clock 398.866674602s] Trained 64 records in 0.130102791 seconds. Throughput is 491.9187 records/second. Loss is 0.16452402. Sequential2290a28's hyper parameters: Current learning rate is 0.01212856276531231. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:22 INFO  DistriOptimizer$:408 - [Epoch 4 27712/60000][Iteration 3247][Wall Clock 399.020401601s] Trained 64 records in 0.153726999 seconds. Throughput is 416.32245 records/second. Loss is 0.1631482. Sequential2290a28's hyper parameters: Current learning rate is 0.01212709192335678. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:22 INFO  DistriOptimizer$:408 - [Epoch 4 27776/60000][Iteration 3248][Wall Clock 399.192338901s] Trained 64 records in 0.1719373 seconds. Throughput is 372.2287 records/second. Loss is 0.14226341. Sequential2290a28's hyper parameters: Current learning rate is 0.012125621438098703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:22 INFO  DistriOptimizer$:408 - [Epoch 4 27840/60000][Iteration 3249][Wall Clock 399.30269815s] Trained 64 records in 0.110359249 seconds. Throughput is 579.9242 records/second. Loss is 0.064097926. Sequential2290a28's hyper parameters: Current learning rate is 0.012124151309408342. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:22 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 3250][Wall Clock 399.433277207s] Trained 64 records in 0.130579057 seconds. Throughput is 490.12454 records/second. Loss is 0.08330733. Sequential2290a28's hyper parameters: Current learning rate is 0.012122681537156019. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:22 INFO  DistriOptimizer$:408 - [Epoch 4 27968/60000][Iteration 3251][Wall Clock 399.538314696s] Trained 64 records in 0.105037489 seconds. Throughput is 609.3063 records/second. Loss is 0.052415475. Sequential2290a28's hyper parameters: Current learning rate is 0.012121212121212123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:22 INFO  DistriOptimizer$:408 - [Epoch 4 28032/60000][Iteration 3252][Wall Clock 399.732825223s] Trained 64 records in 0.194510527 seconds. Throughput is 329.03104 records/second. Loss is 0.17635459. Sequential2290a28's hyper parameters: Current learning rate is 0.012119743061447098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28096/60000][Iteration 3253][Wall Clock 399.96459152s] Trained 64 records in 0.231766297 seconds. Throughput is 276.14023 records/second. Loss is 0.15938008. Sequential2290a28's hyper parameters: Current learning rate is 0.01211827435773146. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 3254][Wall Clock 400.183321393s] Trained 64 records in 0.218729873 seconds. Throughput is 292.59836 records/second. Loss is 0.19653249. Sequential2290a28's hyper parameters: Current learning rate is 0.01211680600993578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28224/60000][Iteration 3255][Wall Clock 400.319216983s] Trained 64 records in 0.13589559 seconds. Throughput is 470.94977 records/second. Loss is 0.14451203. Sequential2290a28's hyper parameters: Current learning rate is 0.0121153380179307. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28288/60000][Iteration 3256][Wall Clock 400.465596375s] Trained 64 records in 0.146379392 seconds. Throughput is 437.22 records/second. Loss is 0.11580272. Sequential2290a28's hyper parameters: Current learning rate is 0.012113870381586917. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28352/60000][Iteration 3257][Wall Clock 400.571675696s] Trained 64 records in 0.106079321 seconds. Throughput is 603.32214 records/second. Loss is 0.23035276. Sequential2290a28's hyper parameters: Current learning rate is 0.012112403100775194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 3258][Wall Clock 400.670437623s] Trained 64 records in 0.098761927 seconds. Throughput is 648.023 records/second. Loss is 0.16025987. Sequential2290a28's hyper parameters: Current learning rate is 0.012110936175366356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28480/60000][Iteration 3259][Wall Clock 400.809224609s] Trained 64 records in 0.138786986 seconds. Throughput is 461.13834 records/second. Loss is 0.1178285. Sequential2290a28's hyper parameters: Current learning rate is 0.01210946960523129. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:23 INFO  DistriOptimizer$:408 - [Epoch 4 28544/60000][Iteration 3260][Wall Clock 400.919721662s] Trained 64 records in 0.110497053 seconds. Throughput is 579.201 records/second. Loss is 0.13900337. Sequential2290a28's hyper parameters: Current learning rate is 0.012108003390240948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28608/60000][Iteration 3261][Wall Clock 401.060655618s] Trained 64 records in 0.140933956 seconds. Throughput is 454.1134 records/second. Loss is 0.23393375. Sequential2290a28's hyper parameters: Current learning rate is 0.012106537530266344. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 3262][Wall Clock 401.165697096s] Trained 64 records in 0.105041478 seconds. Throughput is 609.2831 records/second. Loss is 0.15988395. Sequential2290a28's hyper parameters: Current learning rate is 0.01210507202517855. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28736/60000][Iteration 3263][Wall Clock 401.30343398s] Trained 64 records in 0.137736884 seconds. Throughput is 464.65402 records/second. Loss is 0.16651383. Sequential2290a28's hyper parameters: Current learning rate is 0.012103606874848705. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28800/60000][Iteration 3264][Wall Clock 401.428897459s] Trained 64 records in 0.125463479 seconds. Throughput is 510.10858 records/second. Loss is 0.057695244. Sequential2290a28's hyper parameters: Current learning rate is 0.012102142079148009. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28864/60000][Iteration 3265][Wall Clock 401.557326278s] Trained 64 records in 0.128428819 seconds. Throughput is 498.33054 records/second. Loss is 0.0648159. Sequential2290a28's hyper parameters: Current learning rate is 0.012100677637947725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 3266][Wall Clock 401.712000438s] Trained 64 records in 0.15467416 seconds. Throughput is 413.77307 records/second. Loss is 0.2253758. Sequential2290a28's hyper parameters: Current learning rate is 0.012099213551119177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:24 INFO  DistriOptimizer$:408 - [Epoch 4 28992/60000][Iteration 3267][Wall Clock 401.922625443s] Trained 64 records in 0.210625005 seconds. Throughput is 303.85754 records/second. Loss is 0.19245176. Sequential2290a28's hyper parameters: Current learning rate is 0.012097749818533753. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:25 INFO  DistriOptimizer$:408 - [Epoch 4 29056/60000][Iteration 3268][Wall Clock 402.12370911s] Trained 64 records in 0.201083667 seconds. Throughput is 318.27548 records/second. Loss is 0.09587165. Sequential2290a28's hyper parameters: Current learning rate is 0.0120962864400629. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:25 INFO  DistriOptimizer$:408 - [Epoch 4 29120/60000][Iteration 3269][Wall Clock 402.276166852s] Trained 64 records in 0.152457742 seconds. Throughput is 419.78845 records/second. Loss is 0.13777477. Sequential2290a28's hyper parameters: Current learning rate is 0.012094823415578134. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:25 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 3270][Wall Clock 402.411924672s] Trained 64 records in 0.13575782 seconds. Throughput is 471.42773 records/second. Loss is 0.25574434. Sequential2290a28's hyper parameters: Current learning rate is 0.012093360744951022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:25 INFO  DistriOptimizer$:408 - [Epoch 4 29248/60000][Iteration 3271][Wall Clock 402.531478497s] Trained 64 records in 0.119553825 seconds. Throughput is 535.3237 records/second. Loss is 0.09774663. Sequential2290a28's hyper parameters: Current learning rate is 0.012091898428053206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:25 INFO  DistriOptimizer$:408 - [Epoch 4 29312/60000][Iteration 3272][Wall Clock 402.746079477s] Trained 64 records in 0.21460098 seconds. Throughput is 298.2279 records/second. Loss is 0.06674346. Sequential2290a28's hyper parameters: Current learning rate is 0.012090436464756379. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:25 INFO  DistriOptimizer$:408 - [Epoch 4 29376/60000][Iteration 3273][Wall Clock 402.855188455s] Trained 64 records in 0.109108978 seconds. Throughput is 586.5695 records/second. Loss is 0.13288695. Sequential2290a28's hyper parameters: Current learning rate is 0.012088974854932303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 3274][Wall Clock 402.973727503s] Trained 64 records in 0.118539048 seconds. Throughput is 539.9065 records/second. Loss is 0.10456457. Sequential2290a28's hyper parameters: Current learning rate is 0.012087513598452799. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29504/60000][Iteration 3275][Wall Clock 403.100690791s] Trained 64 records in 0.126963288 seconds. Throughput is 504.08273 records/second. Loss is 0.11934696. Sequential2290a28's hyper parameters: Current learning rate is 0.012086052695189751. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29568/60000][Iteration 3276][Wall Clock 403.228498579s] Trained 64 records in 0.127807788 seconds. Throughput is 500.75198 records/second. Loss is 0.14546204. Sequential2290a28's hyper parameters: Current learning rate is 0.012084592145015106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29632/60000][Iteration 3277][Wall Clock 403.36028459s] Trained 64 records in 0.131786011 seconds. Throughput is 485.6358 records/second. Loss is 0.1525675. Sequential2290a28's hyper parameters: Current learning rate is 0.01208313194780087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 3278][Wall Clock 403.492125777s] Trained 64 records in 0.131841187 seconds. Throughput is 485.43253 records/second. Loss is 0.15899418. Sequential2290a28's hyper parameters: Current learning rate is 0.012081672103419113. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29760/60000][Iteration 3279][Wall Clock 403.595255774s] Trained 64 records in 0.103129997 seconds. Throughput is 620.576 records/second. Loss is 0.12485129. Sequential2290a28's hyper parameters: Current learning rate is 0.012080212611741966. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29824/60000][Iteration 3280][Wall Clock 403.703595657s] Trained 64 records in 0.108339883 seconds. Throughput is 590.7335 records/second. Loss is 0.19697335. Sequential2290a28's hyper parameters: Current learning rate is 0.012078753472641623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29888/60000][Iteration 3281][Wall Clock 403.807408336s] Trained 64 records in 0.103812679 seconds. Throughput is 616.495 records/second. Loss is 0.31154877. Sequential2290a28's hyper parameters: Current learning rate is 0.012077294685990338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:26 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 3282][Wall Clock 403.908618951s] Trained 64 records in 0.101210615 seconds. Throughput is 632.3447 records/second. Loss is 0.1895711. Sequential2290a28's hyper parameters: Current learning rate is 0.012075836251660426. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30016/60000][Iteration 3283][Wall Clock 404.028823303s] Trained 64 records in 0.120204352 seconds. Throughput is 532.42664 records/second. Loss is 0.18830949. Sequential2290a28's hyper parameters: Current learning rate is 0.01207437816952427. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30080/60000][Iteration 3284][Wall Clock 404.137395855s] Trained 64 records in 0.108572552 seconds. Throughput is 589.4676 records/second. Loss is 0.25135836. Sequential2290a28's hyper parameters: Current learning rate is 0.012072920439454304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30144/60000][Iteration 3285][Wall Clock 404.261051178s] Trained 64 records in 0.123655323 seconds. Throughput is 517.5677 records/second. Loss is 0.38845634. Sequential2290a28's hyper parameters: Current learning rate is 0.012071463061323033. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 3286][Wall Clock 404.349561163s] Trained 64 records in 0.088509985 seconds. Throughput is 723.0823 records/second. Loss is 0.16863734. Sequential2290a28's hyper parameters: Current learning rate is 0.012070006035003017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30272/60000][Iteration 3287][Wall Clock 404.487656526s] Trained 64 records in 0.138095363 seconds. Throughput is 463.44785 records/second. Loss is 0.15027493. Sequential2290a28's hyper parameters: Current learning rate is 0.012068549360366883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30336/60000][Iteration 3288][Wall Clock 404.599612609s] Trained 64 records in 0.111956083 seconds. Throughput is 571.6527 records/second. Loss is 0.10922089. Sequential2290a28's hyper parameters: Current learning rate is 0.012067093037287318. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30400/60000][Iteration 3289][Wall Clock 404.726557428s] Trained 64 records in 0.126944819 seconds. Throughput is 504.15604 records/second. Loss is 0.09509051. Sequential2290a28's hyper parameters: Current learning rate is 0.012065637065637066. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 3290][Wall Clock 404.802926893s] Trained 64 records in 0.076369465 seconds. Throughput is 838.03125 records/second. Loss is 0.24903989. Sequential2290a28's hyper parameters: Current learning rate is 0.012064181445288938. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:27 INFO  DistriOptimizer$:408 - [Epoch 4 30528/60000][Iteration 3291][Wall Clock 404.877064333s] Trained 64 records in 0.07413744 seconds. Throughput is 863.26154 records/second. Loss is 0.15099247. Sequential2290a28's hyper parameters: Current learning rate is 0.012062726176115804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30592/60000][Iteration 3292][Wall Clock 404.995601956s] Trained 64 records in 0.118537623 seconds. Throughput is 539.91296 records/second. Loss is 0.131926. Sequential2290a28's hyper parameters: Current learning rate is 0.012061271257990593. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30656/60000][Iteration 3293][Wall Clock 405.081103841s] Trained 64 records in 0.085501885 seconds. Throughput is 748.5215 records/second. Loss is 0.10605481. Sequential2290a28's hyper parameters: Current learning rate is 0.0120598166907863. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 3294][Wall Clock 405.181580068s] Trained 64 records in 0.100476227 seconds. Throughput is 636.9666 records/second. Loss is 0.12616983. Sequential2290a28's hyper parameters: Current learning rate is 0.012058362474375979. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30784/60000][Iteration 3295][Wall Clock 405.329911107s] Trained 64 records in 0.148331039 seconds. Throughput is 431.46732 records/second. Loss is 0.38247716. Sequential2290a28's hyper parameters: Current learning rate is 0.012056908608632746. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30848/60000][Iteration 3296][Wall Clock 405.455603246s] Trained 64 records in 0.125692139 seconds. Throughput is 509.1806 records/second. Loss is 0.15555519. Sequential2290a28's hyper parameters: Current learning rate is 0.012055455093429777. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30912/60000][Iteration 3297][Wall Clock 405.560728986s] Trained 64 records in 0.10512574 seconds. Throughput is 608.79474 records/second. Loss is 0.19709292. Sequential2290a28's hyper parameters: Current learning rate is 0.012054001928640309. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 3298][Wall Clock 405.643098927s] Trained 64 records in 0.082369941 seconds. Throughput is 776.9825 records/second. Loss is 0.13853303. Sequential2290a28's hyper parameters: Current learning rate is 0.012052549114137641. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 31040/60000][Iteration 3299][Wall Clock 405.747672061s] Trained 64 records in 0.104573134 seconds. Throughput is 612.0119 records/second. Loss is 0.07462669. Sequential2290a28's hyper parameters: Current learning rate is 0.01205109664979513. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 31104/60000][Iteration 3300][Wall Clock 405.823183879s] Trained 64 records in 0.075511818 seconds. Throughput is 847.54944 records/second. Loss is 0.07906222. Sequential2290a28's hyper parameters: Current learning rate is 0.012049644535486202. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:28 INFO  DistriOptimizer$:408 - [Epoch 4 31168/60000][Iteration 3301][Wall Clock 405.907686148s] Trained 64 records in 0.084502269 seconds. Throughput is 757.3761 records/second. Loss is 0.22688687. Sequential2290a28's hyper parameters: Current learning rate is 0.012048192771084336. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 3302][Wall Clock 406.013553984s] Trained 64 records in 0.105867836 seconds. Throughput is 604.52734 records/second. Loss is 0.08803678. Sequential2290a28's hyper parameters: Current learning rate is 0.012046741356463076. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31296/60000][Iteration 3303][Wall Clock 406.100008447s] Trained 64 records in 0.086454463 seconds. Throughput is 740.27405 records/second. Loss is 0.23738968. Sequential2290a28's hyper parameters: Current learning rate is 0.012045290291496025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31360/60000][Iteration 3304][Wall Clock 406.243492615s] Trained 64 records in 0.143484168 seconds. Throughput is 446.0422 records/second. Loss is 0.15072615. Sequential2290a28's hyper parameters: Current learning rate is 0.012043839576056847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31424/60000][Iteration 3305][Wall Clock 406.359207574s] Trained 64 records in 0.115714959 seconds. Throughput is 553.0832 records/second. Loss is 0.054186016. Sequential2290a28's hyper parameters: Current learning rate is 0.012042389210019268. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 3306][Wall Clock 406.475563259s] Trained 64 records in 0.116355685 seconds. Throughput is 550.0376 records/second. Loss is 0.28092885. Sequential2290a28's hyper parameters: Current learning rate is 0.012040939193257074. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31552/60000][Iteration 3307][Wall Clock 406.557295853s] Trained 64 records in 0.081732594 seconds. Throughput is 783.0413 records/second. Loss is 0.0651054. Sequential2290a28's hyper parameters: Current learning rate is 0.012039489525644112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31616/60000][Iteration 3308][Wall Clock 406.639274867s] Trained 64 records in 0.081979014 seconds. Throughput is 780.6876 records/second. Loss is 0.16526115. Sequential2290a28's hyper parameters: Current learning rate is 0.012038040207054292. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:29 INFO  DistriOptimizer$:408 - [Epoch 4 31680/60000][Iteration 3309][Wall Clock 406.790808038s] Trained 64 records in 0.151533171 seconds. Throughput is 422.34976 records/second. Loss is 0.21730131. Sequential2290a28's hyper parameters: Current learning rate is 0.01203659123736158. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 3310][Wall Clock 406.982542843s] Trained 64 records in 0.191734805 seconds. Throughput is 333.79437 records/second. Loss is 0.09925769. Sequential2290a28's hyper parameters: Current learning rate is 0.012035142616440005. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 31808/60000][Iteration 3311][Wall Clock 407.13862324s] Trained 64 records in 0.156080397 seconds. Throughput is 410.0451 records/second. Loss is 0.20842868. Sequential2290a28's hyper parameters: Current learning rate is 0.012033694344163659. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 31872/60000][Iteration 3312][Wall Clock 407.310576577s] Trained 64 records in 0.171953337 seconds. Throughput is 372.194 records/second. Loss is 0.22183877. Sequential2290a28's hyper parameters: Current learning rate is 0.01203224642040669. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 31936/60000][Iteration 3313][Wall Clock 407.438929543s] Trained 64 records in 0.128352966 seconds. Throughput is 498.625 records/second. Loss is 0.15371148. Sequential2290a28's hyper parameters: Current learning rate is 0.012030798845043312. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 3314][Wall Clock 407.520931918s] Trained 64 records in 0.082002375 seconds. Throughput is 780.4652 records/second. Loss is 0.1466113. Sequential2290a28's hyper parameters: Current learning rate is 0.012029351617947793. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 32064/60000][Iteration 3315][Wall Clock 407.626438724s] Trained 64 records in 0.105506806 seconds. Throughput is 606.59595 records/second. Loss is 0.14471892. Sequential2290a28's hyper parameters: Current learning rate is 0.012027904738994467. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 32128/60000][Iteration 3316][Wall Clock 407.75061467s] Trained 64 records in 0.124175946 seconds. Throughput is 515.3977 records/second. Loss is 0.20708618. Sequential2290a28's hyper parameters: Current learning rate is 0.012026458208057728. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:30 INFO  DistriOptimizer$:408 - [Epoch 4 32192/60000][Iteration 3317][Wall Clock 407.856828863s] Trained 64 records in 0.106214193 seconds. Throughput is 602.55597 records/second. Loss is 0.059034172. Sequential2290a28's hyper parameters: Current learning rate is 0.012025012025012025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 3318][Wall Clock 407.942110571s] Trained 64 records in 0.085281708 seconds. Throughput is 750.45404 records/second. Loss is 0.11367551. Sequential2290a28's hyper parameters: Current learning rate is 0.012023566189731875. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32320/60000][Iteration 3319][Wall Clock 408.101421022s] Trained 64 records in 0.159310451 seconds. Throughput is 401.73135 records/second. Loss is 0.12943153. Sequential2290a28's hyper parameters: Current learning rate is 0.012022120702091847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32384/60000][Iteration 3320][Wall Clock 408.187954411s] Trained 64 records in 0.086533389 seconds. Throughput is 739.5989 records/second. Loss is 0.21841095. Sequential2290a28's hyper parameters: Current learning rate is 0.012020675561966582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32448/60000][Iteration 3321][Wall Clock 408.275148334s] Trained 64 records in 0.087193923 seconds. Throughput is 733.9961 records/second. Loss is 0.122327834. Sequential2290a28's hyper parameters: Current learning rate is 0.012019230769230768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 3322][Wall Clock 408.405104802s] Trained 64 records in 0.129956468 seconds. Throughput is 492.4726 records/second. Loss is 0.21568435. Sequential2290a28's hyper parameters: Current learning rate is 0.012017786323759163. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32576/60000][Iteration 3323][Wall Clock 408.524501012s] Trained 64 records in 0.11939621 seconds. Throughput is 536.0304 records/second. Loss is 0.16871382. Sequential2290a28's hyper parameters: Current learning rate is 0.01201634222542658. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32640/60000][Iteration 3324][Wall Clock 408.64546681s] Trained 64 records in 0.120965798 seconds. Throughput is 529.07513 records/second. Loss is 0.1993505. Sequential2290a28's hyper parameters: Current learning rate is 0.012014898474107893. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32704/60000][Iteration 3325][Wall Clock 408.777972765s] Trained 64 records in 0.132505955 seconds. Throughput is 482.99716 records/second. Loss is 0.08576934. Sequential2290a28's hyper parameters: Current learning rate is 0.012013455069678039. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:31 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 3326][Wall Clock 408.891006194s] Trained 64 records in 0.113033429 seconds. Throughput is 566.20416 records/second. Loss is 0.14394787. Sequential2290a28's hyper parameters: Current learning rate is 0.012012012012012012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:32 INFO  DistriOptimizer$:408 - [Epoch 4 32832/60000][Iteration 3327][Wall Clock 409.001721289s] Trained 64 records in 0.110715095 seconds. Throughput is 578.06024 records/second. Loss is 0.20460397. Sequential2290a28's hyper parameters: Current learning rate is 0.012010569300984868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:32 INFO  DistriOptimizer$:408 - [Epoch 4 32896/60000][Iteration 3328][Wall Clock 409.176425883s] Trained 64 records in 0.174704594 seconds. Throughput is 366.33267 records/second. Loss is 0.1282529. Sequential2290a28's hyper parameters: Current learning rate is 0.012009126936471718. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:32 INFO  DistriOptimizer$:408 - [Epoch 4 32960/60000][Iteration 3329][Wall Clock 409.427314559s] Trained 64 records in 0.250888676 seconds. Throughput is 255.09322 records/second. Loss is 0.07345381. Sequential2290a28's hyper parameters: Current learning rate is 0.012007684918347743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:32 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 3330][Wall Clock 409.555794176s] Trained 64 records in 0.128479617 seconds. Throughput is 498.13348 records/second. Loss is 0.15440008. Sequential2290a28's hyper parameters: Current learning rate is 0.012006243246488175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:32 INFO  DistriOptimizer$:408 - [Epoch 4 33088/60000][Iteration 3331][Wall Clock 409.737332628s] Trained 64 records in 0.181538452 seconds. Throughput is 352.5424 records/second. Loss is 0.1288793. Sequential2290a28's hyper parameters: Current learning rate is 0.012004801920768308. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:33 INFO  DistriOptimizer$:408 - [Epoch 4 33152/60000][Iteration 3332][Wall Clock 409.953693376s] Trained 64 records in 0.216360748 seconds. Throughput is 295.80228 records/second. Loss is 0.15255764. Sequential2290a28's hyper parameters: Current learning rate is 0.012003360941063499. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:33 INFO  DistriOptimizer$:408 - [Epoch 4 33216/60000][Iteration 3333][Wall Clock 410.129773869s] Trained 64 records in 0.176080493 seconds. Throughput is 363.47012 records/second. Loss is 0.21417195. Sequential2290a28's hyper parameters: Current learning rate is 0.012001920307249161. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:33 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 3334][Wall Clock 410.280269404s] Trained 64 records in 0.150495535 seconds. Throughput is 425.2618 records/second. Loss is 0.1768621. Sequential2290a28's hyper parameters: Current learning rate is 0.012000480019200767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:33 INFO  DistriOptimizer$:408 - [Epoch 4 33344/60000][Iteration 3335][Wall Clock 410.428116068s] Trained 64 records in 0.147846664 seconds. Throughput is 432.88092 records/second. Loss is 0.23859741. Sequential2290a28's hyper parameters: Current learning rate is 0.011999040076793857. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:33 INFO  DistriOptimizer$:408 - [Epoch 4 33408/60000][Iteration 3336][Wall Clock 410.567627724s] Trained 64 records in 0.139511656 seconds. Throughput is 458.743 records/second. Loss is 0.27516213. Sequential2290a28's hyper parameters: Current learning rate is 0.01199760047990402. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:33 INFO  DistriOptimizer$:408 - [Epoch 4 33472/60000][Iteration 3337][Wall Clock 410.751737224s] Trained 64 records in 0.1841095 seconds. Throughput is 347.61923 records/second. Loss is 0.16203694. Sequential2290a28's hyper parameters: Current learning rate is 0.01199616122840691. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 3338][Wall Clock 410.922255368s] Trained 64 records in 0.170518144 seconds. Throughput is 375.32663 records/second. Loss is 0.12185138. Sequential2290a28's hyper parameters: Current learning rate is 0.011994722322178242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33600/60000][Iteration 3339][Wall Clock 411.038778805s] Trained 64 records in 0.116523437 seconds. Throughput is 549.2457 records/second. Loss is 0.2150191. Sequential2290a28's hyper parameters: Current learning rate is 0.011993283761093786. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33664/60000][Iteration 3340][Wall Clock 411.152451197s] Trained 64 records in 0.113672392 seconds. Throughput is 563.0215 records/second. Loss is 0.086346164. Sequential2290a28's hyper parameters: Current learning rate is 0.011991845545029379. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33728/60000][Iteration 3341][Wall Clock 411.333086215s] Trained 64 records in 0.180635018 seconds. Throughput is 354.3056 records/second. Loss is 0.10717217. Sequential2290a28's hyper parameters: Current learning rate is 0.01199040767386091. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 3342][Wall Clock 411.425630681s] Trained 64 records in 0.092544466 seconds. Throughput is 691.55945 records/second. Loss is 0.11249429. Sequential2290a28's hyper parameters: Current learning rate is 0.011988970147464332. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33856/60000][Iteration 3343][Wall Clock 411.587154783s] Trained 64 records in 0.161524102 seconds. Throughput is 396.2257 records/second. Loss is 0.15157518. Sequential2290a28's hyper parameters: Current learning rate is 0.011987532965715655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33920/60000][Iteration 3344][Wall Clock 411.715074573s] Trained 64 records in 0.12791979 seconds. Throughput is 500.3135 records/second. Loss is 0.19755046. Sequential2290a28's hyper parameters: Current learning rate is 0.01198609612849095. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:34 INFO  DistriOptimizer$:408 - [Epoch 4 33984/60000][Iteration 3345][Wall Clock 411.877538414s] Trained 64 records in 0.162463841 seconds. Throughput is 393.9338 records/second. Loss is 0.15303612. Sequential2290a28's hyper parameters: Current learning rate is 0.011984659635666348. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 3346][Wall Clock 411.999086119s] Trained 64 records in 0.121547705 seconds. Throughput is 526.54224 records/second. Loss is 0.22387776. Sequential2290a28's hyper parameters: Current learning rate is 0.011983223487118035. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34112/60000][Iteration 3347][Wall Clock 412.112543001s] Trained 64 records in 0.113456882 seconds. Throughput is 564.09094 records/second. Loss is 0.13417876. Sequential2290a28's hyper parameters: Current learning rate is 0.011981787682722263. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34176/60000][Iteration 3348][Wall Clock 412.232249846s] Trained 64 records in 0.119706845 seconds. Throughput is 534.6394 records/second. Loss is 0.2566242. Sequential2290a28's hyper parameters: Current learning rate is 0.011980352222355337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34240/60000][Iteration 3349][Wall Clock 412.360036937s] Trained 64 records in 0.127787091 seconds. Throughput is 500.83304 records/second. Loss is 0.17743587. Sequential2290a28's hyper parameters: Current learning rate is 0.011978917105893628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 3350][Wall Clock 412.463453436s] Trained 64 records in 0.103416499 seconds. Throughput is 618.85675 records/second. Loss is 0.16575336. Sequential2290a28's hyper parameters: Current learning rate is 0.011977482333213559. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34368/60000][Iteration 3351][Wall Clock 412.64539316s] Trained 64 records in 0.181939724 seconds. Throughput is 351.76486 records/second. Loss is 0.30633622. Sequential2290a28's hyper parameters: Current learning rate is 0.011976047904191617. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:35 INFO  DistriOptimizer$:408 - [Epoch 4 34432/60000][Iteration 3352][Wall Clock 412.838372801s] Trained 64 records in 0.192979641 seconds. Throughput is 331.6412 records/second. Loss is 0.23447132. Sequential2290a28's hyper parameters: Current learning rate is 0.011974613818704348. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:36 INFO  DistriOptimizer$:408 - [Epoch 4 34496/60000][Iteration 3353][Wall Clock 413.060029444s] Trained 64 records in 0.221656643 seconds. Throughput is 288.73486 records/second. Loss is 0.22007434. Sequential2290a28's hyper parameters: Current learning rate is 0.011973180076628353. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:36 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 3354][Wall Clock 413.182669624s] Trained 64 records in 0.12264018 seconds. Throughput is 521.8518 records/second. Loss is 0.30933848. Sequential2290a28's hyper parameters: Current learning rate is 0.011971746677840296. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:36 INFO  DistriOptimizer$:408 - [Epoch 4 34624/60000][Iteration 3355][Wall Clock 413.402907057s] Trained 64 records in 0.220237433 seconds. Throughput is 290.59546 records/second. Loss is 0.13427104. Sequential2290a28's hyper parameters: Current learning rate is 0.011970313622216901. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:36 INFO  DistriOptimizer$:408 - [Epoch 4 34688/60000][Iteration 3356][Wall Clock 413.630408206s] Trained 64 records in 0.227501149 seconds. Throughput is 281.31726 records/second. Loss is 0.15412048. Sequential2290a28's hyper parameters: Current learning rate is 0.011968880909634948. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:36 INFO  DistriOptimizer$:408 - [Epoch 4 34752/60000][Iteration 3357][Wall Clock 413.828106348s] Trained 64 records in 0.197698142 seconds. Throughput is 323.72586 records/second. Loss is 0.14014563. Sequential2290a28's hyper parameters: Current learning rate is 0.011967448539971278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:37 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 3358][Wall Clock 414.005056396s] Trained 64 records in 0.176950048 seconds. Throughput is 361.684 records/second. Loss is 0.20787024. Sequential2290a28's hyper parameters: Current learning rate is 0.011966016513102789. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:37 INFO  DistriOptimizer$:408 - [Epoch 4 34880/60000][Iteration 3359][Wall Clock 414.166839768s] Trained 64 records in 0.161783372 seconds. Throughput is 395.59073 records/second. Loss is 0.23956123. Sequential2290a28's hyper parameters: Current learning rate is 0.011964584828906435. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:37 INFO  DistriOptimizer$:408 - [Epoch 4 34944/60000][Iteration 3360][Wall Clock 414.362155312s] Trained 64 records in 0.195315544 seconds. Throughput is 327.6749 records/second. Loss is 0.10277156. Sequential2290a28's hyper parameters: Current learning rate is 0.01196315348725924. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:37 INFO  DistriOptimizer$:408 - [Epoch 4 35008/60000][Iteration 3361][Wall Clock 414.529684739s] Trained 64 records in 0.167529427 seconds. Throughput is 382.02243 records/second. Loss is 0.21710101. Sequential2290a28's hyper parameters: Current learning rate is 0.011961722488038277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:37 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 3362][Wall Clock 414.632752152s] Trained 64 records in 0.103067413 seconds. Throughput is 620.9528 records/second. Loss is 0.061021347. Sequential2290a28's hyper parameters: Current learning rate is 0.011960291831120679. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:37 INFO  DistriOptimizer$:408 - [Epoch 4 35136/60000][Iteration 3363][Wall Clock 414.759325153s] Trained 64 records in 0.126573001 seconds. Throughput is 505.6371 records/second. Loss is 0.1991646. Sequential2290a28's hyper parameters: Current learning rate is 0.01195886151638364. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35200/60000][Iteration 3364][Wall Clock 414.919527195s] Trained 64 records in 0.160202042 seconds. Throughput is 399.49554 records/second. Loss is 0.11800833. Sequential2290a28's hyper parameters: Current learning rate is 0.011957431543704412. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35264/60000][Iteration 3365][Wall Clock 415.02703042s] Trained 64 records in 0.107503225 seconds. Throughput is 595.33093 records/second. Loss is 0.14122498. Sequential2290a28's hyper parameters: Current learning rate is 0.011956001912960305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 3366][Wall Clock 415.133155877s] Trained 64 records in 0.106125457 seconds. Throughput is 603.0598 records/second. Loss is 0.24881482. Sequential2290a28's hyper parameters: Current learning rate is 0.011954572624028692. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35392/60000][Iteration 3367][Wall Clock 415.240146869s] Trained 64 records in 0.106990992 seconds. Throughput is 598.1812 records/second. Loss is 0.1592161. Sequential2290a28's hyper parameters: Current learning rate is 0.011953143676786996. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35456/60000][Iteration 3368][Wall Clock 415.374396501s] Trained 64 records in 0.134249632 seconds. Throughput is 476.72385 records/second. Loss is 0.09924184. Sequential2290a28's hyper parameters: Current learning rate is 0.011951715071112704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35520/60000][Iteration 3369][Wall Clock 415.530484591s] Trained 64 records in 0.15608809 seconds. Throughput is 410.0249 records/second. Loss is 0.068563625. Sequential2290a28's hyper parameters: Current learning rate is 0.011950286806883365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 3370][Wall Clock 415.642157748s] Trained 64 records in 0.111673157 seconds. Throughput is 573.101 records/second. Loss is 0.17763793. Sequential2290a28's hyper parameters: Current learning rate is 0.011948858883976581. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:38 INFO  DistriOptimizer$:408 - [Epoch 4 35648/60000][Iteration 3371][Wall Clock 415.818428724s] Trained 64 records in 0.176270976 seconds. Throughput is 363.07736 records/second. Loss is 0.29525983. Sequential2290a28's hyper parameters: Current learning rate is 0.011947431302270013. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:39 INFO  DistriOptimizer$:408 - [Epoch 4 35712/60000][Iteration 3372][Wall Clock 415.960729169s] Trained 64 records in 0.142300445 seconds. Throughput is 449.75266 records/second. Loss is 0.14247268. Sequential2290a28's hyper parameters: Current learning rate is 0.011946004061641383. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:39 INFO  DistriOptimizer$:408 - [Epoch 4 35776/60000][Iteration 3373][Wall Clock 416.123793826s] Trained 64 records in 0.163064657 seconds. Throughput is 392.48236 records/second. Loss is 0.097957276. Sequential2290a28's hyper parameters: Current learning rate is 0.011944577161968468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:39 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 3374][Wall Clock 416.322088201s] Trained 64 records in 0.198294375 seconds. Throughput is 322.75247 records/second. Loss is 0.064189255. Sequential2290a28's hyper parameters: Current learning rate is 0.011943150603129107. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:39 INFO  DistriOptimizer$:408 - [Epoch 4 35904/60000][Iteration 3375][Wall Clock 416.455375018s] Trained 64 records in 0.133286817 seconds. Throughput is 480.1675 records/second. Loss is 0.16148895. Sequential2290a28's hyper parameters: Current learning rate is 0.011941724385001193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:39 INFO  DistriOptimizer$:408 - [Epoch 4 35968/60000][Iteration 3376][Wall Clock 416.620087026s] Trained 64 records in 0.164712008 seconds. Throughput is 388.55698 records/second. Loss is 0.3013174. Sequential2290a28's hyper parameters: Current learning rate is 0.011940298507462687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:39 INFO  DistriOptimizer$:408 - [Epoch 4 36032/60000][Iteration 3377][Wall Clock 416.762556023s] Trained 64 records in 0.142468997 seconds. Throughput is 449.22052 records/second. Loss is 0.22182235. Sequential2290a28's hyper parameters: Current learning rate is 0.011938872970391595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 3378][Wall Clock 416.892349798s] Trained 64 records in 0.129793775 seconds. Throughput is 493.0899 records/second. Loss is 0.08580417. Sequential2290a28's hyper parameters: Current learning rate is 0.011937447773665991. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36160/60000][Iteration 3379][Wall Clock 417.067576522s] Trained 64 records in 0.175226724 seconds. Throughput is 365.2411 records/second. Loss is 0.252418. Sequential2290a28's hyper parameters: Current learning rate is 0.011936022917164002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36224/60000][Iteration 3380][Wall Clock 417.193916568s] Trained 64 records in 0.126340046 seconds. Throughput is 506.5694 records/second. Loss is 0.11752561. Sequential2290a28's hyper parameters: Current learning rate is 0.011934598400763814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36288/60000][Iteration 3381][Wall Clock 417.364991614s] Trained 64 records in 0.171075046 seconds. Throughput is 374.10483 records/second. Loss is 0.14195374. Sequential2290a28's hyper parameters: Current learning rate is 0.011933174224343675. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 3382][Wall Clock 417.545390368s] Trained 64 records in 0.180398754 seconds. Throughput is 354.76965 records/second. Loss is 0.15238613. Sequential2290a28's hyper parameters: Current learning rate is 0.011931750387781886. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36416/60000][Iteration 3383][Wall Clock 417.67333641s] Trained 64 records in 0.127946042 seconds. Throughput is 500.21085 records/second. Loss is 0.14324698. Sequential2290a28's hyper parameters: Current learning rate is 0.011930326890956812. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:40 INFO  DistriOptimizer$:408 - [Epoch 4 36480/60000][Iteration 3384][Wall Clock 417.78181182s] Trained 64 records in 0.10847541 seconds. Throughput is 589.9955 records/second. Loss is 0.13114068. Sequential2290a28's hyper parameters: Current learning rate is 0.011928903733746868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36544/60000][Iteration 3385][Wall Clock 417.898798389s] Trained 64 records in 0.116986569 seconds. Throughput is 547.07135 records/second. Loss is 0.1428034. Sequential2290a28's hyper parameters: Current learning rate is 0.011927480916030533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 3386][Wall Clock 418.05387313s] Trained 64 records in 0.155074741 seconds. Throughput is 412.7042 records/second. Loss is 0.23170811. Sequential2290a28's hyper parameters: Current learning rate is 0.011926058437686345. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36672/60000][Iteration 3387][Wall Clock 418.191965503s] Trained 64 records in 0.138092373 seconds. Throughput is 463.45792 records/second. Loss is 0.1298845. Sequential2290a28's hyper parameters: Current learning rate is 0.011924636298592892. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36736/60000][Iteration 3388][Wall Clock 418.323590102s] Trained 64 records in 0.131624599 seconds. Throughput is 486.23132 records/second. Loss is 0.17997512. Sequential2290a28's hyper parameters: Current learning rate is 0.01192321449862883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36800/60000][Iteration 3389][Wall Clock 418.446835803s] Trained 64 records in 0.123245701 seconds. Throughput is 519.2879 records/second. Loss is 0.14568996. Sequential2290a28's hyper parameters: Current learning rate is 0.011921793037672867. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 3390][Wall Clock 418.54560716s] Trained 64 records in 0.098771357 seconds. Throughput is 647.9611 records/second. Loss is 0.18526594. Sequential2290a28's hyper parameters: Current learning rate is 0.011920371915603767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36928/60000][Iteration 3391][Wall Clock 418.659986544s] Trained 64 records in 0.114379384 seconds. Throughput is 559.5414 records/second. Loss is 0.104325876. Sequential2290a28's hyper parameters: Current learning rate is 0.011918951132300359. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 36992/60000][Iteration 3392][Wall Clock 418.765462509s] Trained 64 records in 0.105475965 seconds. Throughput is 606.7733 records/second. Loss is 0.10144515. Sequential2290a28's hyper parameters: Current learning rate is 0.011917530687641521. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:41 INFO  DistriOptimizer$:408 - [Epoch 4 37056/60000][Iteration 3393][Wall Clock 418.847984971s] Trained 64 records in 0.082522462 seconds. Throughput is 775.54645 records/second. Loss is 0.06349235. Sequential2290a28's hyper parameters: Current learning rate is 0.011916110581506198. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 3394][Wall Clock 419.017710155s] Trained 64 records in 0.169725184 seconds. Throughput is 377.08017 records/second. Loss is 0.23252329. Sequential2290a28's hyper parameters: Current learning rate is 0.011914690813773384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 37184/60000][Iteration 3395][Wall Clock 419.138636029s] Trained 64 records in 0.120925874 seconds. Throughput is 529.2498 records/second. Loss is 0.11485619. Sequential2290a28's hyper parameters: Current learning rate is 0.011913271384322134. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 37248/60000][Iteration 3396][Wall Clock 419.267092089s] Trained 64 records in 0.12845606 seconds. Throughput is 498.22485 records/second. Loss is 0.14837502. Sequential2290a28's hyper parameters: Current learning rate is 0.011911852293031567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 37312/60000][Iteration 3397][Wall Clock 419.44432995s] Trained 64 records in 0.177237861 seconds. Throughput is 361.09665 records/second. Loss is 0.14566895. Sequential2290a28's hyper parameters: Current learning rate is 0.011910433539780848. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 3398][Wall Clock 419.584633939s] Trained 64 records in 0.140303989 seconds. Throughput is 456.1524 records/second. Loss is 0.2548316. Sequential2290a28's hyper parameters: Current learning rate is 0.011909015124449208. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 37440/60000][Iteration 3399][Wall Clock 419.802217662s] Trained 64 records in 0.217583723 seconds. Throughput is 294.13965 records/second. Loss is 0.09954281. Sequential2290a28's hyper parameters: Current learning rate is 0.011907597046915932. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 37504/60000][Iteration 3400][Wall Clock 419.976307446s] Trained 64 records in 0.174089784 seconds. Throughput is 367.62637 records/second. Loss is 0.10722466. Sequential2290a28's hyper parameters: Current learning rate is 0.011906179307060363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 37568/60000][Iteration 3401][Wall Clock 420.120696416s] Trained 64 records in 0.14438897 seconds. Throughput is 443.24713 records/second. Loss is 0.13843715. Sequential2290a28's hyper parameters: Current learning rate is 0.011904761904761904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 3402][Wall Clock 420.285897109s] Trained 64 records in 0.165200693 seconds. Throughput is 387.40756 records/second. Loss is 0.23096746. Sequential2290a28's hyper parameters: Current learning rate is 0.01190334483990001. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 37696/60000][Iteration 3403][Wall Clock 420.479371122s] Trained 64 records in 0.193474013 seconds. Throughput is 330.7938 records/second. Loss is 0.13689841. Sequential2290a28's hyper parameters: Current learning rate is 0.011901928112354201. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 37760/60000][Iteration 3404][Wall Clock 420.695040428s] Trained 64 records in 0.215669306 seconds. Throughput is 296.7506 records/second. Loss is 0.14148472. Sequential2290a28's hyper parameters: Current learning rate is 0.011900511722004046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 37824/60000][Iteration 3405][Wall Clock 420.828541837s] Trained 64 records in 0.133501409 seconds. Throughput is 479.3957 records/second. Loss is 0.17134261. Sequential2290a28's hyper parameters: Current learning rate is 0.011899095668729176. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 3406][Wall Clock 420.982589737s] Trained 64 records in 0.1540479 seconds. Throughput is 415.45517 records/second. Loss is 0.11278085. Sequential2290a28's hyper parameters: Current learning rate is 0.01189767995240928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 37952/60000][Iteration 3407][Wall Clock 421.1203008s] Trained 64 records in 0.137711063 seconds. Throughput is 464.74118 records/second. Loss is 0.05525575. Sequential2290a28's hyper parameters: Current learning rate is 0.011896264572924102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 38016/60000][Iteration 3408][Wall Clock 421.24335473s] Trained 64 records in 0.12305393 seconds. Throughput is 520.09717 records/second. Loss is 0.094707176. Sequential2290a28's hyper parameters: Current learning rate is 0.011894849530153444. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 38080/60000][Iteration 3409][Wall Clock 421.395850555s] Trained 64 records in 0.152495825 seconds. Throughput is 419.6836 records/second. Loss is 0.13051645. Sequential2290a28's hyper parameters: Current learning rate is 0.011893434823977166. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 3410][Wall Clock 421.507021695s] Trained 64 records in 0.11117114 seconds. Throughput is 575.68896 records/second. Loss is 0.08751501. Sequential2290a28's hyper parameters: Current learning rate is 0.011892020454275181. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 38208/60000][Iteration 3411][Wall Clock 421.651583255s] Trained 64 records in 0.14456156 seconds. Throughput is 442.71796 records/second. Loss is 0.06396197. Sequential2290a28's hyper parameters: Current learning rate is 0.011890606420927468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 38272/60000][Iteration 3412][Wall Clock 421.798283585s] Trained 64 records in 0.14670033 seconds. Throughput is 436.26352 records/second. Loss is 0.20473826. Sequential2290a28's hyper parameters: Current learning rate is 0.011889192723814054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38336/60000][Iteration 3413][Wall Clock 421.934865347s] Trained 64 records in 0.136581762 seconds. Throughput is 468.5838 records/second. Loss is 0.16686815. Sequential2290a28's hyper parameters: Current learning rate is 0.011887779362815027. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 3414][Wall Clock 422.051363497s] Trained 64 records in 0.11649815 seconds. Throughput is 549.3649 records/second. Loss is 0.07698291. Sequential2290a28's hyper parameters: Current learning rate is 0.011886366337810532. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38464/60000][Iteration 3415][Wall Clock 422.144006475s] Trained 64 records in 0.092642978 seconds. Throughput is 690.8241 records/second. Loss is 0.2860644. Sequential2290a28's hyper parameters: Current learning rate is 0.011884953648680769. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38528/60000][Iteration 3416][Wall Clock 422.28960739s] Trained 64 records in 0.145600915 seconds. Throughput is 439.55768 records/second. Loss is 0.2513517. Sequential2290a28's hyper parameters: Current learning rate is 0.011883541295306001. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38592/60000][Iteration 3417][Wall Clock 422.388464279s] Trained 64 records in 0.098856889 seconds. Throughput is 647.4005 records/second. Loss is 0.17866535. Sequential2290a28's hyper parameters: Current learning rate is 0.01188212927756654. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 3418][Wall Clock 422.5129113s] Trained 64 records in 0.124447021 seconds. Throughput is 514.2751 records/second. Loss is 0.1483329. Sequential2290a28's hyper parameters: Current learning rate is 0.011880717595342758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 38720/60000][Iteration 3419][Wall Clock 422.604237883s] Trained 64 records in 0.091326583 seconds. Throughput is 700.78174 records/second. Loss is 0.09653863. Sequential2290a28's hyper parameters: Current learning rate is 0.011879306248515088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 38784/60000][Iteration 3420][Wall Clock 422.86880015s] Trained 64 records in 0.264562267 seconds. Throughput is 241.90901 records/second. Loss is 0.15578577. Sequential2290a28's hyper parameters: Current learning rate is 0.011877895236964009. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 38848/60000][Iteration 3421][Wall Clock 423.017549551s] Trained 64 records in 0.148749401 seconds. Throughput is 430.25385 records/second. Loss is 0.11992996. Sequential2290a28's hyper parameters: Current learning rate is 0.011876484560570071. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 3422][Wall Clock 423.198298381s] Trained 64 records in 0.18074883 seconds. Throughput is 354.0825 records/second. Loss is 0.08849542. Sequential2290a28's hyper parameters: Current learning rate is 0.011875074219213869. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 38976/60000][Iteration 3423][Wall Clock 423.307082791s] Trained 64 records in 0.10878441 seconds. Throughput is 588.3196 records/second. Loss is 0.17261396. Sequential2290a28's hyper parameters: Current learning rate is 0.011873664212776061. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 39040/60000][Iteration 3424][Wall Clock 423.483795631s] Trained 64 records in 0.17671284 seconds. Throughput is 362.1695 records/second. Loss is 0.088855304. Sequential2290a28's hyper parameters: Current learning rate is 0.011872254541137361. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 39104/60000][Iteration 3425][Wall Clock 423.668253953s] Trained 64 records in 0.184458322 seconds. Throughput is 346.96185 records/second. Loss is 0.1994693. Sequential2290a28's hyper parameters: Current learning rate is 0.011870845204178537. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 3426][Wall Clock 423.783831704s] Trained 64 records in 0.115577751 seconds. Throughput is 553.7398 records/second. Loss is 0.15985459. Sequential2290a28's hyper parameters: Current learning rate is 0.011869436201780416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 39232/60000][Iteration 3427][Wall Clock 423.895428022s] Trained 64 records in 0.111596318 seconds. Throughput is 573.4956 records/second. Loss is 0.3626732. Sequential2290a28's hyper parameters: Current learning rate is 0.011868027533823879. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 39296/60000][Iteration 3428][Wall Clock 424.07222328s] Trained 64 records in 0.176795258 seconds. Throughput is 362.00067 records/second. Loss is 0.12466032. Sequential2290a28's hyper parameters: Current learning rate is 0.011866619200189867. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 39360/60000][Iteration 3429][Wall Clock 424.256457541s] Trained 64 records in 0.184234261 seconds. Throughput is 347.38382 records/second. Loss is 0.073265694. Sequential2290a28's hyper parameters: Current learning rate is 0.011865211200759373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 3430][Wall Clock 424.43445474s] Trained 64 records in 0.177997199 seconds. Throughput is 359.5562 records/second. Loss is 0.119221024. Sequential2290a28's hyper parameters: Current learning rate is 0.011863803535413454. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 39488/60000][Iteration 3431][Wall Clock 424.569627278s] Trained 64 records in 0.135172538 seconds. Throughput is 473.46896 records/second. Loss is 0.0952889. Sequential2290a28's hyper parameters: Current learning rate is 0.011862396204033215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 39552/60000][Iteration 3432][Wall Clock 424.671716556s] Trained 64 records in 0.102089278 seconds. Throughput is 626.9023 records/second. Loss is 0.15889302. Sequential2290a28's hyper parameters: Current learning rate is 0.011860989206499823. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 39616/60000][Iteration 3433][Wall Clock 424.833966562s] Trained 64 records in 0.162250006 seconds. Throughput is 394.45297 records/second. Loss is 0.12755467. Sequential2290a28's hyper parameters: Current learning rate is 0.011859582542694497. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 3434][Wall Clock 424.95836463s] Trained 64 records in 0.124398068 seconds. Throughput is 514.4774 records/second. Loss is 0.14470868. Sequential2290a28's hyper parameters: Current learning rate is 0.011858176212498519. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 39744/60000][Iteration 3435][Wall Clock 425.081145617s] Trained 64 records in 0.122780987 seconds. Throughput is 521.25336 records/second. Loss is 0.14820418. Sequential2290a28's hyper parameters: Current learning rate is 0.011856770215793217. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 39808/60000][Iteration 3436][Wall Clock 425.211834188s] Trained 64 records in 0.130688571 seconds. Throughput is 489.7138 records/second. Loss is 0.15840814. Sequential2290a28's hyper parameters: Current learning rate is 0.011855364552459988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 39872/60000][Iteration 3437][Wall Clock 425.309369697s] Trained 64 records in 0.097535509 seconds. Throughput is 656.1713 records/second. Loss is 0.1527564. Sequential2290a28's hyper parameters: Current learning rate is 0.011853959222380275. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 3438][Wall Clock 425.412571296s] Trained 64 records in 0.103201599 seconds. Throughput is 620.14545 records/second. Loss is 0.22438765. Sequential2290a28's hyper parameters: Current learning rate is 0.011852554225435581. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 40000/60000][Iteration 3439][Wall Clock 425.510009687s] Trained 64 records in 0.097438391 seconds. Throughput is 656.8253 records/second. Loss is 0.09111227. Sequential2290a28's hyper parameters: Current learning rate is 0.011851149561507467. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 40064/60000][Iteration 3440][Wall Clock 425.689866719s] Trained 64 records in 0.179857032 seconds. Throughput is 355.8382 records/second. Loss is 0.10547793. Sequential2290a28's hyper parameters: Current learning rate is 0.011849745230477543. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 40128/60000][Iteration 3441][Wall Clock 425.822542177s] Trained 64 records in 0.132675458 seconds. Throughput is 482.3801 records/second. Loss is 0.17936803. Sequential2290a28's hyper parameters: Current learning rate is 0.011848341232227487. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 3442][Wall Clock 425.958251878s] Trained 64 records in 0.135709701 seconds. Throughput is 471.59488 records/second. Loss is 0.154872. Sequential2290a28's hyper parameters: Current learning rate is 0.011846937566639022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40256/60000][Iteration 3443][Wall Clock 426.078071014s] Trained 64 records in 0.119819136 seconds. Throughput is 534.13837 records/second. Loss is 0.09045298. Sequential2290a28's hyper parameters: Current learning rate is 0.011845534233593934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40320/60000][Iteration 3444][Wall Clock 426.194384067s] Trained 64 records in 0.116313053 seconds. Throughput is 550.2392 records/second. Loss is 0.225752. Sequential2290a28's hyper parameters: Current learning rate is 0.011844131232974061. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40384/60000][Iteration 3445][Wall Clock 426.383465925s] Trained 64 records in 0.189081858 seconds. Throughput is 338.47772 records/second. Loss is 0.07951951. Sequential2290a28's hyper parameters: Current learning rate is 0.011842728564661297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 3446][Wall Clock 426.518807758s] Trained 64 records in 0.135341833 seconds. Throughput is 472.87668 records/second. Loss is 0.21214676. Sequential2290a28's hyper parameters: Current learning rate is 0.011841326228537596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40512/60000][Iteration 3447][Wall Clock 426.668910035s] Trained 64 records in 0.150102277 seconds. Throughput is 426.37595 records/second. Loss is 0.13035145. Sequential2290a28's hyper parameters: Current learning rate is 0.011839924224484964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 40576/60000][Iteration 3448][Wall Clock 426.809227007s] Trained 64 records in 0.140316972 seconds. Throughput is 456.11017 records/second. Loss is 0.1322419. Sequential2290a28's hyper parameters: Current learning rate is 0.011838522552385463. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 40640/60000][Iteration 3449][Wall Clock 426.940603238s] Trained 64 records in 0.131376231 seconds. Throughput is 487.1505 records/second. Loss is 0.10352753. Sequential2290a28's hyper parameters: Current learning rate is 0.011837121212121212. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 3450][Wall Clock 427.077589403s] Trained 64 records in 0.136986165 seconds. Throughput is 467.20047 records/second. Loss is 0.15646423. Sequential2290a28's hyper parameters: Current learning rate is 0.011835720203574387. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 40768/60000][Iteration 3451][Wall Clock 427.163570548s] Trained 64 records in 0.085981145 seconds. Throughput is 744.34924 records/second. Loss is 0.21513334. Sequential2290a28's hyper parameters: Current learning rate is 0.01183431952662722. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 40832/60000][Iteration 3452][Wall Clock 427.257957557s] Trained 64 records in 0.094387009 seconds. Throughput is 678.0594 records/second. Loss is 0.122182064. Sequential2290a28's hyper parameters: Current learning rate is 0.011832919181161994. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 40896/60000][Iteration 3453][Wall Clock 427.352540389s] Trained 64 records in 0.094582832 seconds. Throughput is 676.6556 records/second. Loss is 0.21543157. Sequential2290a28's hyper parameters: Current learning rate is 0.011831519167061051. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 3454][Wall Clock 427.456322117s] Trained 64 records in 0.103781728 seconds. Throughput is 616.6789 records/second. Loss is 0.07257033. Sequential2290a28's hyper parameters: Current learning rate is 0.011830119484206791. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 41024/60000][Iteration 3455][Wall Clock 427.566126659s] Trained 64 records in 0.109804542 seconds. Throughput is 582.8539 records/second. Loss is 0.13741612. Sequential2290a28's hyper parameters: Current learning rate is 0.011828720132481665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 41088/60000][Iteration 3456][Wall Clock 427.722807413s] Trained 64 records in 0.156680754 seconds. Throughput is 408.47394 records/second. Loss is 0.16211125. Sequential2290a28's hyper parameters: Current learning rate is 0.011827321111768185. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41152/60000][Iteration 3457][Wall Clock 427.893722456s] Trained 64 records in 0.170915043 seconds. Throughput is 374.45505 records/second. Loss is 0.21984965. Sequential2290a28's hyper parameters: Current learning rate is 0.011825922421948912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 3458][Wall Clock 428.06397624s] Trained 64 records in 0.170253784 seconds. Throughput is 375.90942 records/second. Loss is 0.121341884. Sequential2290a28's hyper parameters: Current learning rate is 0.011824524062906468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41280/60000][Iteration 3459][Wall Clock 428.2271909s] Trained 64 records in 0.16321466 seconds. Throughput is 392.12164 records/second. Loss is 0.13618119. Sequential2290a28's hyper parameters: Current learning rate is 0.011823126034523528. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41344/60000][Iteration 3460][Wall Clock 428.345119752s] Trained 64 records in 0.117928852 seconds. Throughput is 542.7001 records/second. Loss is 0.13066146. Sequential2290a28's hyper parameters: Current learning rate is 0.011821728336682822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41408/60000][Iteration 3461][Wall Clock 428.414202164s] Trained 64 records in 0.069082412 seconds. Throughput is 926.42975 records/second. Loss is 0.15021786. Sequential2290a28's hyper parameters: Current learning rate is 0.01182033096926714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 3462][Wall Clock 428.496516372s] Trained 64 records in 0.082314208 seconds. Throughput is 777.50854 records/second. Loss is 0.11461769. Sequential2290a28's hyper parameters: Current learning rate is 0.011818933932159319. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41536/60000][Iteration 3463][Wall Clock 428.576110191s] Trained 64 records in 0.079593819 seconds. Throughput is 804.0825 records/second. Loss is 0.074484974. Sequential2290a28's hyper parameters: Current learning rate is 0.011817537225242258. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41600/60000][Iteration 3464][Wall Clock 428.692423294s] Trained 64 records in 0.116313103 seconds. Throughput is 550.23895 records/second. Loss is 0.14887089. Sequential2290a28's hyper parameters: Current learning rate is 0.011816140848398913. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 41664/60000][Iteration 3465][Wall Clock 428.78654537s] Trained 64 records in 0.094122076 seconds. Throughput is 679.968 records/second. Loss is 0.1705112. Sequential2290a28's hyper parameters: Current learning rate is 0.011814744801512287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 3466][Wall Clock 428.878263023s] Trained 64 records in 0.091717653 seconds. Throughput is 697.7937 records/second. Loss is 0.29010934. Sequential2290a28's hyper parameters: Current learning rate is 0.011813349084465446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 41792/60000][Iteration 3467][Wall Clock 429.057920813s] Trained 64 records in 0.17965779 seconds. Throughput is 356.23282 records/second. Loss is 0.08138312. Sequential2290a28's hyper parameters: Current learning rate is 0.011811953697141508. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 41856/60000][Iteration 3468][Wall Clock 429.183376208s] Trained 64 records in 0.125455395 seconds. Throughput is 510.14148 records/second. Loss is 0.16334534. Sequential2290a28's hyper parameters: Current learning rate is 0.011810558639423645. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 41920/60000][Iteration 3469][Wall Clock 429.331784838s] Trained 64 records in 0.14840863 seconds. Throughput is 431.24176 records/second. Loss is 0.1944039. Sequential2290a28's hyper parameters: Current learning rate is 0.011809163911195087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 3470][Wall Clock 429.458245704s] Trained 64 records in 0.126460866 seconds. Throughput is 506.08542 records/second. Loss is 0.15371367. Sequential2290a28's hyper parameters: Current learning rate is 0.01180776951233912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 42048/60000][Iteration 3471][Wall Clock 429.662255634s] Trained 64 records in 0.20400993 seconds. Throughput is 313.7102 records/second. Loss is 0.1563226. Sequential2290a28's hyper parameters: Current learning rate is 0.011806375442739079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 42112/60000][Iteration 3472][Wall Clock 429.763958133s] Trained 64 records in 0.101702499 seconds. Throughput is 629.28644 records/second. Loss is 0.25535232. Sequential2290a28's hyper parameters: Current learning rate is 0.011804981702278363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42176/60000][Iteration 3473][Wall Clock 429.908259424s] Trained 64 records in 0.144301291 seconds. Throughput is 443.51645 records/second. Loss is 0.07001108. Sequential2290a28's hyper parameters: Current learning rate is 0.011803588290840416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 3474][Wall Clock 430.047500497s] Trained 64 records in 0.139241073 seconds. Throughput is 459.6345 records/second. Loss is 0.10236414. Sequential2290a28's hyper parameters: Current learning rate is 0.011802195208308747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42304/60000][Iteration 3475][Wall Clock 430.159297236s] Trained 64 records in 0.111796739 seconds. Throughput is 572.4675 records/second. Loss is 0.1703062. Sequential2290a28's hyper parameters: Current learning rate is 0.011800802454566911. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42368/60000][Iteration 3476][Wall Clock 430.324224536s] Trained 64 records in 0.1649273 seconds. Throughput is 388.04974 records/second. Loss is 0.12966768. Sequential2290a28's hyper parameters: Current learning rate is 0.011799410029498525. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42432/60000][Iteration 3477][Wall Clock 430.434251309s] Trained 64 records in 0.110026773 seconds. Throughput is 581.67664 records/second. Loss is 0.09859281. Sequential2290a28's hyper parameters: Current learning rate is 0.011798017932987258. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 3478][Wall Clock 430.54964513s] Trained 64 records in 0.115393821 seconds. Throughput is 554.62244 records/second. Loss is 0.08673336. Sequential2290a28's hyper parameters: Current learning rate is 0.011796626164916835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42560/60000][Iteration 3479][Wall Clock 430.659534519s] Trained 64 records in 0.109889389 seconds. Throughput is 582.4038 records/second. Loss is 0.21693844. Sequential2290a28's hyper parameters: Current learning rate is 0.01179523472517103. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 42624/60000][Iteration 3480][Wall Clock 430.770987691s] Trained 64 records in 0.111453172 seconds. Throughput is 574.2322 records/second. Loss is 0.11831258. Sequential2290a28's hyper parameters: Current learning rate is 0.011793843613633682. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 42688/60000][Iteration 3481][Wall Clock 430.880576452s] Trained 64 records in 0.109588761 seconds. Throughput is 584.00146 records/second. Loss is 0.30139232. Sequential2290a28's hyper parameters: Current learning rate is 0.011792452830188678. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 3482][Wall Clock 431.056816373s] Trained 64 records in 0.176239921 seconds. Throughput is 363.14133 records/second. Loss is 0.13807938. Sequential2290a28's hyper parameters: Current learning rate is 0.011791062374719961. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 42816/60000][Iteration 3483][Wall Clock 431.218284781s] Trained 64 records in 0.161468408 seconds. Throughput is 396.36237 records/second. Loss is 0.074339725. Sequential2290a28's hyper parameters: Current learning rate is 0.01178967224711153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 42880/60000][Iteration 3484][Wall Clock 431.308576001s] Trained 64 records in 0.09029122 seconds. Throughput is 708.81757 records/second. Loss is 0.11581312. Sequential2290a28's hyper parameters: Current learning rate is 0.011788282447247436. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 42944/60000][Iteration 3485][Wall Clock 431.382140038s] Trained 64 records in 0.073564037 seconds. Throughput is 869.9903 records/second. Loss is 0.1519337. Sequential2290a28's hyper parameters: Current learning rate is 0.011786892975011787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 3486][Wall Clock 431.462320999s] Trained 64 records in 0.080180961 seconds. Throughput is 798.1945 records/second. Loss is 0.07889488. Sequential2290a28's hyper parameters: Current learning rate is 0.011785503830288745. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 43072/60000][Iteration 3487][Wall Clock 431.608895565s] Trained 64 records in 0.146574566 seconds. Throughput is 436.63782 records/second. Loss is 0.11741853. Sequential2290a28's hyper parameters: Current learning rate is 0.011784115012962526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 43136/60000][Iteration 3488][Wall Clock 431.753000397s] Trained 64 records in 0.144104832 seconds. Throughput is 444.1211 records/second. Loss is 0.14740169. Sequential2290a28's hyper parameters: Current learning rate is 0.011782726522917402. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43200/60000][Iteration 3489][Wall Clock 431.873392713s] Trained 64 records in 0.120392316 seconds. Throughput is 531.5954 records/second. Loss is 0.24421686. Sequential2290a28's hyper parameters: Current learning rate is 0.0117813383600377. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 3490][Wall Clock 431.976001349s] Trained 64 records in 0.102608636 seconds. Throughput is 623.7292 records/second. Loss is 0.091092736. Sequential2290a28's hyper parameters: Current learning rate is 0.0117799505242078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43328/60000][Iteration 3491][Wall Clock 432.244934552s] Trained 64 records in 0.268933203 seconds. Throughput is 237.97731 records/second. Loss is 0.1353459. Sequential2290a28's hyper parameters: Current learning rate is 0.011778563015312132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43392/60000][Iteration 3492][Wall Clock 432.444848373s] Trained 64 records in 0.199913821 seconds. Throughput is 320.13797 records/second. Loss is 0.15506878. Sequential2290a28's hyper parameters: Current learning rate is 0.011777175833235192. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43456/60000][Iteration 3493][Wall Clock 432.552658693s] Trained 64 records in 0.10781032 seconds. Throughput is 593.6352 records/second. Loss is 0.17158996. Sequential2290a28's hyper parameters: Current learning rate is 0.011775788977861518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 3494][Wall Clock 432.637635186s] Trained 64 records in 0.084976493 seconds. Throughput is 753.1495 records/second. Loss is 0.08044149. Sequential2290a28's hyper parameters: Current learning rate is 0.01177440244907571. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 43584/60000][Iteration 3495][Wall Clock 432.781580145s] Trained 64 records in 0.143944959 seconds. Throughput is 444.61438 records/second. Loss is 0.10654553. Sequential2290a28's hyper parameters: Current learning rate is 0.01177301624676242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 43648/60000][Iteration 3496][Wall Clock 432.888036264s] Trained 64 records in 0.106456119 seconds. Throughput is 601.1867 records/second. Loss is 0.20731452. Sequential2290a28's hyper parameters: Current learning rate is 0.011771630370806356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 43712/60000][Iteration 3497][Wall Clock 433.009256364s] Trained 64 records in 0.1212201 seconds. Throughput is 527.9653 records/second. Loss is 0.09543911. Sequential2290a28's hyper parameters: Current learning rate is 0.011770244821092278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 3498][Wall Clock 433.167406491s] Trained 64 records in 0.158150127 seconds. Throughput is 404.6788 records/second. Loss is 0.08962841. Sequential2290a28's hyper parameters: Current learning rate is 0.011768859597505002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 43840/60000][Iteration 3499][Wall Clock 433.301539224s] Trained 64 records in 0.134132733 seconds. Throughput is 477.13934 records/second. Loss is 0.10547483. Sequential2290a28's hyper parameters: Current learning rate is 0.011767474699929396. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 43904/60000][Iteration 3500][Wall Clock 433.487343399s] Trained 64 records in 0.185804175 seconds. Throughput is 344.44867 records/second. Loss is 0.14019701. Sequential2290a28's hyper parameters: Current learning rate is 0.01176609012825038. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 43968/60000][Iteration 3501][Wall Clock 433.703352961s] Trained 64 records in 0.216009562 seconds. Throughput is 296.28317 records/second. Loss is 0.12482695. Sequential2290a28's hyper parameters: Current learning rate is 0.011764705882352941. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 3502][Wall Clock 433.847813373s] Trained 64 records in 0.144460412 seconds. Throughput is 443.02795 records/second. Loss is 0.17621496. Sequential2290a28's hyper parameters: Current learning rate is 0.011763321962122103. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44096/60000][Iteration 3503][Wall Clock 434.028385564s] Trained 64 records in 0.180572191 seconds. Throughput is 354.42886 records/second. Loss is 0.25206697. Sequential2290a28's hyper parameters: Current learning rate is 0.011761938367442954. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44160/60000][Iteration 3504][Wall Clock 434.196002719s] Trained 64 records in 0.167617155 seconds. Throughput is 381.82248 records/second. Loss is 0.11623261. Sequential2290a28's hyper parameters: Current learning rate is 0.011760555098200634. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44224/60000][Iteration 3505][Wall Clock 434.333731221s] Trained 64 records in 0.137728502 seconds. Throughput is 464.68234 records/second. Loss is 0.15460771. Sequential2290a28's hyper parameters: Current learning rate is 0.011759172154280339. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 3506][Wall Clock 434.419857918s] Trained 64 records in 0.086126697 seconds. Throughput is 743.0913 records/second. Loss is 0.05963929. Sequential2290a28's hyper parameters: Current learning rate is 0.011757789535567314. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44352/60000][Iteration 3507][Wall Clock 434.520202019s] Trained 64 records in 0.100344101 seconds. Throughput is 637.8053 records/second. Loss is 0.12662676. Sequential2290a28's hyper parameters: Current learning rate is 0.011756407241946862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 44416/60000][Iteration 3508][Wall Clock 434.68777787s] Trained 64 records in 0.167575851 seconds. Throughput is 381.9166 records/second. Loss is 0.11240914. Sequential2290a28's hyper parameters: Current learning rate is 0.011755025273304338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44480/60000][Iteration 3509][Wall Clock 434.868056974s] Trained 64 records in 0.180279104 seconds. Throughput is 355.0051 records/second. Loss is 0.18591876. Sequential2290a28's hyper parameters: Current learning rate is 0.011753643629525154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 3510][Wall Clock 435.020006794s] Trained 64 records in 0.15194982 seconds. Throughput is 421.19168 records/second. Loss is 0.17432126. Sequential2290a28's hyper parameters: Current learning rate is 0.01175226231049477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44608/60000][Iteration 3511][Wall Clock 435.12747664s] Trained 64 records in 0.107469846 seconds. Throughput is 595.51587 records/second. Loss is 0.09441511. Sequential2290a28's hyper parameters: Current learning rate is 0.011750881316098707. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44672/60000][Iteration 3512][Wall Clock 435.214700187s] Trained 64 records in 0.087223547 seconds. Throughput is 733.7468 records/second. Loss is 0.09309349. Sequential2290a28's hyper parameters: Current learning rate is 0.011749500646222537. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44736/60000][Iteration 3513][Wall Clock 435.330816926s] Trained 64 records in 0.116116739 seconds. Throughput is 551.16943 records/second. Loss is 0.25713688. Sequential2290a28's hyper parameters: Current learning rate is 0.01174812030075188. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 3514][Wall Clock 435.422148835s] Trained 64 records in 0.091331909 seconds. Throughput is 700.74084 records/second. Loss is 0.2387218. Sequential2290a28's hyper parameters: Current learning rate is 0.01174674027957242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44864/60000][Iteration 3515][Wall Clock 435.602680921s] Trained 64 records in 0.180532086 seconds. Throughput is 354.50763 records/second. Loss is 0.17690133. Sequential2290a28's hyper parameters: Current learning rate is 0.011745360582569886. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 44928/60000][Iteration 3516][Wall Clock 435.748690453s] Trained 64 records in 0.146009532 seconds. Throughput is 438.32755 records/second. Loss is 0.110217236. Sequential2290a28's hyper parameters: Current learning rate is 0.011743981209630064. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 44992/60000][Iteration 3517][Wall Clock 435.898993797s] Trained 64 records in 0.150303344 seconds. Throughput is 425.80554 records/second. Loss is 0.28913295. Sequential2290a28's hyper parameters: Current learning rate is 0.011742602160638797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 3518][Wall Clock 436.060715158s] Trained 64 records in 0.161721361 seconds. Throughput is 395.7424 records/second. Loss is 0.117085144. Sequential2290a28's hyper parameters: Current learning rate is 0.011741223435481977. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 45120/60000][Iteration 3519][Wall Clock 436.21019894s] Trained 64 records in 0.149483782 seconds. Throughput is 428.14008 records/second. Loss is 0.091027044. Sequential2290a28's hyper parameters: Current learning rate is 0.011739845034045552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 45184/60000][Iteration 3520][Wall Clock 436.348429913s] Trained 64 records in 0.138230973 seconds. Throughput is 462.99316 records/second. Loss is 0.110391736. Sequential2290a28's hyper parameters: Current learning rate is 0.01173846695621552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 45248/60000][Iteration 3521][Wall Clock 436.569788487s] Trained 64 records in 0.221358574 seconds. Throughput is 289.12366 records/second. Loss is 0.19437122. Sequential2290a28's hyper parameters: Current learning rate is 0.011737089201877934. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 3522][Wall Clock 436.804629626s] Trained 64 records in 0.234841139 seconds. Throughput is 272.52466 records/second. Loss is 0.16140257. Sequential2290a28's hyper parameters: Current learning rate is 0.011735711770918906. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 45376/60000][Iteration 3523][Wall Clock 437.064452057s] Trained 64 records in 0.259822431 seconds. Throughput is 246.32208 records/second. Loss is 0.15114346. Sequential2290a28's hyper parameters: Current learning rate is 0.011734334663224594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 45440/60000][Iteration 3524][Wall Clock 437.239805931s] Trained 64 records in 0.175353874 seconds. Throughput is 364.97626 records/second. Loss is 0.28470463. Sequential2290a28's hyper parameters: Current learning rate is 0.011732957878681215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 45504/60000][Iteration 3525][Wall Clock 437.375728687s] Trained 64 records in 0.135922756 seconds. Throughput is 470.85565 records/second. Loss is 0.08280666. Sequential2290a28's hyper parameters: Current learning rate is 0.011731581417175035. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 3526][Wall Clock 437.522843094s] Trained 64 records in 0.147114407 seconds. Throughput is 435.03555 records/second. Loss is 0.22407874. Sequential2290a28's hyper parameters: Current learning rate is 0.011730205278592375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 45632/60000][Iteration 3527][Wall Clock 437.655760035s] Trained 64 records in 0.132916941 seconds. Throughput is 481.5037 records/second. Loss is 0.07267677. Sequential2290a28's hyper parameters: Current learning rate is 0.01172882946281961. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 45696/60000][Iteration 3528][Wall Clock 437.901065326s] Trained 64 records in 0.245305291 seconds. Throughput is 260.89938 records/second. Loss is 0.13400468. Sequential2290a28's hyper parameters: Current learning rate is 0.011727453969743168. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 45760/60000][Iteration 3529][Wall Clock 438.066674754s] Trained 64 records in 0.165609428 seconds. Throughput is 386.45142 records/second. Loss is 0.0957912. Sequential2290a28's hyper parameters: Current learning rate is 0.011726078799249532. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 3530][Wall Clock 438.226271029s] Trained 64 records in 0.159596275 seconds. Throughput is 401.01184 records/second. Loss is 0.08695346. Sequential2290a28's hyper parameters: Current learning rate is 0.011724703951225232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 45888/60000][Iteration 3531][Wall Clock 438.415923726s] Trained 64 records in 0.189652697 seconds. Throughput is 337.45895 records/second. Loss is 0.13392836. Sequential2290a28's hyper parameters: Current learning rate is 0.011723329425556858. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 45952/60000][Iteration 3532][Wall Clock 438.57261912s] Trained 64 records in 0.156695394 seconds. Throughput is 408.43573 records/second. Loss is 0.13763502. Sequential2290a28's hyper parameters: Current learning rate is 0.011721955222131052. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 46016/60000][Iteration 3533][Wall Clock 438.72230369s] Trained 64 records in 0.14968457 seconds. Throughput is 427.5658 records/second. Loss is 0.12971184. Sequential2290a28's hyper parameters: Current learning rate is 0.011720581340834505. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 3534][Wall Clock 438.907612969s] Trained 64 records in 0.185309279 seconds. Throughput is 345.36856 records/second. Loss is 0.078892946. Sequential2290a28's hyper parameters: Current learning rate is 0.011719207781553968. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46144/60000][Iteration 3535][Wall Clock 439.045205248s] Trained 64 records in 0.137592279 seconds. Throughput is 465.14236 records/second. Loss is 0.17103715. Sequential2290a28's hyper parameters: Current learning rate is 0.011717834544176237. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46208/60000][Iteration 3536][Wall Clock 439.204828609s] Trained 64 records in 0.159623361 seconds. Throughput is 400.94385 records/second. Loss is 0.08883034. Sequential2290a28's hyper parameters: Current learning rate is 0.011716461628588167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46272/60000][Iteration 3537][Wall Clock 439.309464049s] Trained 64 records in 0.10463544 seconds. Throughput is 611.64746 records/second. Loss is 0.11665075. Sequential2290a28's hyper parameters: Current learning rate is 0.011715089034676664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 3538][Wall Clock 439.427761955s] Trained 64 records in 0.118297906 seconds. Throughput is 541.007 records/second. Loss is 0.3145567. Sequential2290a28's hyper parameters: Current learning rate is 0.011713716762328687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46400/60000][Iteration 3539][Wall Clock 439.549900589s] Trained 64 records in 0.122138634 seconds. Throughput is 523.99475 records/second. Loss is 0.18399267. Sequential2290a28's hyper parameters: Current learning rate is 0.011712344811431248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 46464/60000][Iteration 3540][Wall Clock 439.665699073s] Trained 64 records in 0.115798484 seconds. Throughput is 552.68427 records/second. Loss is 0.12475693. Sequential2290a28's hyper parameters: Current learning rate is 0.011710973181871413. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46528/60000][Iteration 3541][Wall Clock 439.806682537s] Trained 64 records in 0.140983464 seconds. Throughput is 453.95395 records/second. Loss is 0.13861802. Sequential2290a28's hyper parameters: Current learning rate is 0.011709601873536299. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 3542][Wall Clock 439.924952495s] Trained 64 records in 0.118269958 seconds. Throughput is 541.1349 records/second. Loss is 0.22940204. Sequential2290a28's hyper parameters: Current learning rate is 0.011708230886313077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46656/60000][Iteration 3543][Wall Clock 440.067812437s] Trained 64 records in 0.142859942 seconds. Throughput is 447.99124 records/second. Loss is 0.16075227. Sequential2290a28's hyper parameters: Current learning rate is 0.01170686022008897. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46720/60000][Iteration 3544][Wall Clock 440.191283805s] Trained 64 records in 0.123471368 seconds. Throughput is 518.3388 records/second. Loss is 0.1355249. Sequential2290a28's hyper parameters: Current learning rate is 0.011705489874751257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46784/60000][Iteration 3545][Wall Clock 440.314998306s] Trained 64 records in 0.123714501 seconds. Throughput is 517.3201 records/second. Loss is 0.3010353. Sequential2290a28's hyper parameters: Current learning rate is 0.011704119850187265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 3546][Wall Clock 440.433430894s] Trained 64 records in 0.118432588 seconds. Throughput is 540.3918 records/second. Loss is 0.11635583. Sequential2290a28's hyper parameters: Current learning rate is 0.011702750146284377. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 46912/60000][Iteration 3547][Wall Clock 440.654478315s] Trained 64 records in 0.221047421 seconds. Throughput is 289.53064 records/second. Loss is 0.07131187. Sequential2290a28's hyper parameters: Current learning rate is 0.011701380762930026. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 46976/60000][Iteration 3548][Wall Clock 440.755346108s] Trained 64 records in 0.100867793 seconds. Throughput is 634.4939 records/second. Loss is 0.28340852. Sequential2290a28's hyper parameters: Current learning rate is 0.0117000117000117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 47040/60000][Iteration 3549][Wall Clock 440.913651991s] Trained 64 records in 0.158305883 seconds. Throughput is 404.2806 records/second. Loss is 0.14376259. Sequential2290a28's hyper parameters: Current learning rate is 0.01169864295741694. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 3550][Wall Clock 441.147018372s] Trained 64 records in 0.233366381 seconds. Throughput is 274.24686 records/second. Loss is 0.09644873. Sequential2290a28's hyper parameters: Current learning rate is 0.011697274535033338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 47168/60000][Iteration 3551][Wall Clock 441.325969305s] Trained 64 records in 0.178950933 seconds. Throughput is 357.63992 records/second. Loss is 0.12645213. Sequential2290a28's hyper parameters: Current learning rate is 0.011695906432748539. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 47232/60000][Iteration 3552][Wall Clock 441.488830432s] Trained 64 records in 0.162861127 seconds. Throughput is 392.97284 records/second. Loss is 0.13047561. Sequential2290a28's hyper parameters: Current learning rate is 0.01169453865045024. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 47296/60000][Iteration 3553][Wall Clock 441.640769003s] Trained 64 records in 0.151938571 seconds. Throughput is 421.22287 records/second. Loss is 0.19813037. Sequential2290a28's hyper parameters: Current learning rate is 0.011693171188026194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 3554][Wall Clock 441.78515432s] Trained 64 records in 0.144385317 seconds. Throughput is 443.25836 records/second. Loss is 0.21108666. Sequential2290a28's hyper parameters: Current learning rate is 0.0116918040453642. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47424/60000][Iteration 3555][Wall Clock 441.887445583s] Trained 64 records in 0.102291263 seconds. Throughput is 625.66437 records/second. Loss is 0.21086612. Sequential2290a28's hyper parameters: Current learning rate is 0.011690437222352117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47488/60000][Iteration 3556][Wall Clock 442.030114835s] Trained 64 records in 0.142669252 seconds. Throughput is 448.59003 records/second. Loss is 0.07253988. Sequential2290a28's hyper parameters: Current learning rate is 0.011689070718877849. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47552/60000][Iteration 3557][Wall Clock 442.133312917s] Trained 64 records in 0.103198082 seconds. Throughput is 620.16656 records/second. Loss is 0.17608574. Sequential2290a28's hyper parameters: Current learning rate is 0.01168770453482936. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 3558][Wall Clock 442.223423583s] Trained 64 records in 0.090110666 seconds. Throughput is 710.2378 records/second. Loss is 0.10184027. Sequential2290a28's hyper parameters: Current learning rate is 0.01168633867009466. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47680/60000][Iteration 3559][Wall Clock 442.330711316s] Trained 64 records in 0.107287733 seconds. Throughput is 596.52673 records/second. Loss is 0.17802948. Sequential2290a28's hyper parameters: Current learning rate is 0.011684973124561814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 47744/60000][Iteration 3560][Wall Clock 442.512529872s] Trained 64 records in 0.181818556 seconds. Throughput is 351.99927 records/second. Loss is 0.16053274. Sequential2290a28's hyper parameters: Current learning rate is 0.011683607898118939. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 47808/60000][Iteration 3561][Wall Clock 442.718694301s] Trained 64 records in 0.206164429 seconds. Throughput is 310.43182 records/second. Loss is 0.093974784. Sequential2290a28's hyper parameters: Current learning rate is 0.011682242990654205. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 3562][Wall Clock 442.821885412s] Trained 64 records in 0.103191111 seconds. Throughput is 620.2085 records/second. Loss is 0.09619715. Sequential2290a28's hyper parameters: Current learning rate is 0.011680878402055834. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 47936/60000][Iteration 3563][Wall Clock 442.99364714s] Trained 64 records in 0.171761728 seconds. Throughput is 372.60922 records/second. Loss is 0.11957224. Sequential2290a28's hyper parameters: Current learning rate is 0.011679514132212099. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 48000/60000][Iteration 3564][Wall Clock 443.085366878s] Trained 64 records in 0.091719738 seconds. Throughput is 697.77783 records/second. Loss is 0.27745917. Sequential2290a28's hyper parameters: Current learning rate is 0.011678150181011327. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 48064/60000][Iteration 3565][Wall Clock 443.255661003s] Trained 64 records in 0.170294125 seconds. Throughput is 375.82037 records/second. Loss is 0.2755846. Sequential2290a28's hyper parameters: Current learning rate is 0.011676786548341896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 3566][Wall Clock 443.384977612s] Trained 64 records in 0.129316609 seconds. Throughput is 494.90933 records/second. Loss is 0.24086025. Sequential2290a28's hyper parameters: Current learning rate is 0.011675423234092236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 48192/60000][Iteration 3567][Wall Clock 443.528671186s] Trained 64 records in 0.143693574 seconds. Throughput is 445.3922 records/second. Loss is 0.07975945. Sequential2290a28's hyper parameters: Current learning rate is 0.011674060238150829. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 48256/60000][Iteration 3568][Wall Clock 443.683963562s] Trained 64 records in 0.155292376 seconds. Throughput is 412.12582 records/second. Loss is 0.24072427. Sequential2290a28's hyper parameters: Current learning rate is 0.01167269756040621. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48320/60000][Iteration 3569][Wall Clock 443.803583742s] Trained 64 records in 0.11962018 seconds. Throughput is 535.0268 records/second. Loss is 0.21018794. Sequential2290a28's hyper parameters: Current learning rate is 0.011671335200746966. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 3570][Wall Clock 443.884900286s] Trained 64 records in 0.081316544 seconds. Throughput is 787.04767 records/second. Loss is 0.2081418. Sequential2290a28's hyper parameters: Current learning rate is 0.011669973159061734. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48448/60000][Iteration 3571][Wall Clock 444.015353321s] Trained 64 records in 0.130453035 seconds. Throughput is 490.59802 records/second. Loss is 0.07267324. Sequential2290a28's hyper parameters: Current learning rate is 0.011668611435239206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48512/60000][Iteration 3572][Wall Clock 444.124608456s] Trained 64 records in 0.109255135 seconds. Throughput is 585.78485 records/second. Loss is 0.08801768. Sequential2290a28's hyper parameters: Current learning rate is 0.011667250029168125. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48576/60000][Iteration 3573][Wall Clock 444.293477834s] Trained 64 records in 0.168869378 seconds. Throughput is 378.99115 records/second. Loss is 0.1832797. Sequential2290a28's hyper parameters: Current learning rate is 0.011665888940737284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 3574][Wall Clock 444.476205462s] Trained 64 records in 0.182727628 seconds. Throughput is 350.24805 records/second. Loss is 0.25807. Sequential2290a28's hyper parameters: Current learning rate is 0.011664528169835531. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 48704/60000][Iteration 3575][Wall Clock 444.652608413s] Trained 64 records in 0.176402951 seconds. Throughput is 362.80573 records/second. Loss is 0.07547089. Sequential2290a28's hyper parameters: Current learning rate is 0.011663167716351763. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 48768/60000][Iteration 3576][Wall Clock 444.846602279s] Trained 64 records in 0.193993866 seconds. Throughput is 329.90735 records/second. Loss is 0.13431093. Sequential2290a28's hyper parameters: Current learning rate is 0.011661807580174927. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 48832/60000][Iteration 3577][Wall Clock 444.94165105s] Trained 64 records in 0.095048771 seconds. Throughput is 673.33856 records/second. Loss is 0.15347186. Sequential2290a28's hyper parameters: Current learning rate is 0.01166044776119403. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 3578][Wall Clock 445.044205115s] Trained 64 records in 0.102554065 seconds. Throughput is 624.06104 records/second. Loss is 0.22660393. Sequential2290a28's hyper parameters: Current learning rate is 0.011659088259298123. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 48960/60000][Iteration 3579][Wall Clock 445.190084574s] Trained 64 records in 0.145879459 seconds. Throughput is 438.71838 records/second. Loss is 0.08420306. Sequential2290a28's hyper parameters: Current learning rate is 0.011657729074376311. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 49024/60000][Iteration 3580][Wall Clock 445.327786293s] Trained 64 records in 0.137701719 seconds. Throughput is 464.7727 records/second. Loss is 0.24506316. Sequential2290a28's hyper parameters: Current learning rate is 0.011656370206317754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 49088/60000][Iteration 3581][Wall Clock 445.553443868s] Trained 64 records in 0.225657575 seconds. Throughput is 283.61554 records/second. Loss is 0.13618067. Sequential2290a28's hyper parameters: Current learning rate is 0.011655011655011654. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 3582][Wall Clock 445.756936737s] Trained 64 records in 0.203492869 seconds. Throughput is 314.50735 records/second. Loss is 0.10558316. Sequential2290a28's hyper parameters: Current learning rate is 0.011653653420347278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 49216/60000][Iteration 3583][Wall Clock 445.954519874s] Trained 64 records in 0.197583137 seconds. Throughput is 323.91428 records/second. Loss is 0.10295251. Sequential2290a28's hyper parameters: Current learning rate is 0.011652295502213935. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 49280/60000][Iteration 3584][Wall Clock 446.10602602s] Trained 64 records in 0.151506146 seconds. Throughput is 422.4251 records/second. Loss is 0.2761333. Sequential2290a28's hyper parameters: Current learning rate is 0.01165093790050099. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 49344/60000][Iteration 3585][Wall Clock 446.269381104s] Trained 64 records in 0.163355084 seconds. Throughput is 391.78458 records/second. Loss is 0.16376501. Sequential2290a28's hyper parameters: Current learning rate is 0.011649580615097856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 3586][Wall Clock 446.544709183s] Trained 64 records in 0.275328079 seconds. Throughput is 232.44997 records/second. Loss is 0.057877257. Sequential2290a28's hyper parameters: Current learning rate is 0.011648223645894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 49472/60000][Iteration 3587][Wall Clock 446.64861498s] Trained 64 records in 0.103905797 seconds. Throughput is 615.9425 records/second. Loss is 0.13252835. Sequential2290a28's hyper parameters: Current learning rate is 0.011646866992778943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 49536/60000][Iteration 3588][Wall Clock 446.849522918s] Trained 64 records in 0.200907938 seconds. Throughput is 318.55386 records/second. Loss is 0.15663154. Sequential2290a28's hyper parameters: Current learning rate is 0.01164551065564225. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 49600/60000][Iteration 3589][Wall Clock 446.997814197s] Trained 64 records in 0.148291279 seconds. Throughput is 431.58304 records/second. Loss is 0.07954592. Sequential2290a28's hyper parameters: Current learning rate is 0.011644154634373545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 3590][Wall Clock 447.188996618s] Trained 64 records in 0.191182421 seconds. Throughput is 334.75882 records/second. Loss is 0.14983413. Sequential2290a28's hyper parameters: Current learning rate is 0.011642798928862498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 49728/60000][Iteration 3591][Wall Clock 447.305416413s] Trained 64 records in 0.116419795 seconds. Throughput is 549.7347 records/second. Loss is 0.12907858. Sequential2290a28's hyper parameters: Current learning rate is 0.011641443538998836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 49792/60000][Iteration 3592][Wall Clock 447.44318265s] Trained 64 records in 0.137766237 seconds. Throughput is 464.55502 records/second. Loss is 0.09701096. Sequential2290a28's hyper parameters: Current learning rate is 0.011640088464672332. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 49856/60000][Iteration 3593][Wall Clock 447.553699268s] Trained 64 records in 0.110516618 seconds. Throughput is 579.09845 records/second. Loss is 0.15354513. Sequential2290a28's hyper parameters: Current learning rate is 0.011638733705772812. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 3594][Wall Clock 447.727108635s] Trained 64 records in 0.173409367 seconds. Throughput is 369.06888 records/second. Loss is 0.11530876. Sequential2290a28's hyper parameters: Current learning rate is 0.011637379262190157. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 49984/60000][Iteration 3595][Wall Clock 447.859864912s] Trained 64 records in 0.132756277 seconds. Throughput is 482.08643 records/second. Loss is 0.2010825. Sequential2290a28's hyper parameters: Current learning rate is 0.01163602513381429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 50048/60000][Iteration 3596][Wall Clock 447.936180196s] Trained 64 records in 0.076315284 seconds. Throughput is 838.6262 records/second. Loss is 0.1797488. Sequential2290a28's hyper parameters: Current learning rate is 0.011634671320535195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 50112/60000][Iteration 3597][Wall Clock 448.067821518s] Trained 64 records in 0.131641322 seconds. Throughput is 486.1695 records/second. Loss is 0.22114292. Sequential2290a28's hyper parameters: Current learning rate is 0.011633317822242903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 3598][Wall Clock 448.203124371s] Trained 64 records in 0.135302853 seconds. Throughput is 473.01294 records/second. Loss is 0.114585206. Sequential2290a28's hyper parameters: Current learning rate is 0.011631964638827498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 50240/60000][Iteration 3599][Wall Clock 448.330717077s] Trained 64 records in 0.127592706 seconds. Throughput is 501.59604 records/second. Loss is 0.28472984. Sequential2290a28's hyper parameters: Current learning rate is 0.011630611770179112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 50304/60000][Iteration 3600][Wall Clock 448.490004408s] Trained 64 records in 0.159287331 seconds. Throughput is 401.78964 records/second. Loss is 0.17312303. Sequential2290a28's hyper parameters: Current learning rate is 0.01162925921618793. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 50368/60000][Iteration 3601][Wall Clock 448.603513548s] Trained 64 records in 0.11350914 seconds. Throughput is 563.83124 records/second. Loss is 0.15015608. Sequential2290a28's hyper parameters: Current learning rate is 0.011627906976744184. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 3602][Wall Clock 448.715742456s] Trained 64 records in 0.112228908 seconds. Throughput is 570.26306 records/second. Loss is 0.14408448. Sequential2290a28's hyper parameters: Current learning rate is 0.01162655505173817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50496/60000][Iteration 3603][Wall Clock 448.796140405s] Trained 64 records in 0.080397949 seconds. Throughput is 796.0402 records/second. Loss is 0.090070434. Sequential2290a28's hyper parameters: Current learning rate is 0.011625203441060218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50560/60000][Iteration 3604][Wall Clock 448.890287255s] Trained 64 records in 0.09414685 seconds. Throughput is 679.78906 records/second. Loss is 0.095676444. Sequential2290a28's hyper parameters: Current learning rate is 0.01162385214460072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50624/60000][Iteration 3605][Wall Clock 449.050599612s] Trained 64 records in 0.160312357 seconds. Throughput is 399.22064 records/second. Loss is 0.081545584. Sequential2290a28's hyper parameters: Current learning rate is 0.011622501162250116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 3606][Wall Clock 449.169844719s] Trained 64 records in 0.119245107 seconds. Throughput is 536.70966 records/second. Loss is 0.097113036. Sequential2290a28's hyper parameters: Current learning rate is 0.011621150493898896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50752/60000][Iteration 3607][Wall Clock 449.38560949s] Trained 64 records in 0.215764771 seconds. Throughput is 296.61932 records/second. Loss is 0.14563161. Sequential2290a28's hyper parameters: Current learning rate is 0.011619800139437602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50816/60000][Iteration 3608][Wall Clock 449.465111641s] Trained 64 records in 0.079502151 seconds. Throughput is 805.00964 records/second. Loss is 0.060094155. Sequential2290a28's hyper parameters: Current learning rate is 0.011618450098756826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 50880/60000][Iteration 3609][Wall Clock 449.619985816s] Trained 64 records in 0.154874175 seconds. Throughput is 413.23868 records/second. Loss is 0.19925988. Sequential2290a28's hyper parameters: Current learning rate is 0.011617100371747213. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 3610][Wall Clock 449.73441135s] Trained 64 records in 0.114425534 seconds. Throughput is 559.31573 records/second. Loss is 0.15212257. Sequential2290a28's hyper parameters: Current learning rate is 0.011615750958299455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 51008/60000][Iteration 3611][Wall Clock 449.8515333s] Trained 64 records in 0.11712195 seconds. Throughput is 546.43896 records/second. Loss is 0.2222123. Sequential2290a28's hyper parameters: Current learning rate is 0.011614401858304297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 51072/60000][Iteration 3612][Wall Clock 450.007333728s] Trained 64 records in 0.155800428 seconds. Throughput is 410.78192 records/second. Loss is 0.117264286. Sequential2290a28's hyper parameters: Current learning rate is 0.011613053071652538. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 51136/60000][Iteration 3613][Wall Clock 450.14979077s] Trained 64 records in 0.142457042 seconds. Throughput is 449.25824 records/second. Loss is 0.14940333. Sequential2290a28's hyper parameters: Current learning rate is 0.011611704598235021. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 3614][Wall Clock 450.270837988s] Trained 64 records in 0.121047218 seconds. Throughput is 528.7193 records/second. Loss is 0.13613959. Sequential2290a28's hyper parameters: Current learning rate is 0.011610356437942646. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 51264/60000][Iteration 3615][Wall Clock 450.485286655s] Trained 64 records in 0.214448667 seconds. Throughput is 298.43973 records/second. Loss is 0.08706816. Sequential2290a28's hyper parameters: Current learning rate is 0.011609008590666358. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 51328/60000][Iteration 3616][Wall Clock 450.669292844s] Trained 64 records in 0.184006189 seconds. Throughput is 347.8144 records/second. Loss is 0.08369578. Sequential2290a28's hyper parameters: Current learning rate is 0.011607661056297156. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51392/60000][Iteration 3617][Wall Clock 450.765519918s] Trained 64 records in 0.096227074 seconds. Throughput is 665.0935 records/second. Loss is 0.15545858. Sequential2290a28's hyper parameters: Current learning rate is 0.01160631383472609. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 3618][Wall Clock 450.86954422s] Trained 64 records in 0.104024302 seconds. Throughput is 615.24084 records/second. Loss is 0.2420224. Sequential2290a28's hyper parameters: Current learning rate is 0.011604966925844262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51520/60000][Iteration 3619][Wall Clock 450.996313307s] Trained 64 records in 0.126769087 seconds. Throughput is 504.85498 records/second. Loss is 0.17838615. Sequential2290a28's hyper parameters: Current learning rate is 0.011603620329542817. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51584/60000][Iteration 3620][Wall Clock 451.114592882s] Trained 64 records in 0.118279575 seconds. Throughput is 541.0909 records/second. Loss is 0.23368587. Sequential2290a28's hyper parameters: Current learning rate is 0.01160227404571296. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51648/60000][Iteration 3621][Wall Clock 451.274428801s] Trained 64 records in 0.159835919 seconds. Throughput is 400.4106 records/second. Loss is 0.21975549. Sequential2290a28's hyper parameters: Current learning rate is 0.01160092807424594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 3622][Wall Clock 451.39940173s] Trained 64 records in 0.124972929 seconds. Throughput is 512.1109 records/second. Loss is 0.12955448. Sequential2290a28's hyper parameters: Current learning rate is 0.011599582415033057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51776/60000][Iteration 3623][Wall Clock 451.484520454s] Trained 64 records in 0.085118724 seconds. Throughput is 751.8909 records/second. Loss is 0.2374695. Sequential2290a28's hyper parameters: Current learning rate is 0.011598237067965669. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 51840/60000][Iteration 3624][Wall Clock 451.571752166s] Trained 64 records in 0.087231712 seconds. Throughput is 733.67816 records/second. Loss is 0.308419. Sequential2290a28's hyper parameters: Current learning rate is 0.011596892032935173. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 51904/60000][Iteration 3625][Wall Clock 451.693425008s] Trained 64 records in 0.121672842 seconds. Throughput is 526.00073 records/second. Loss is 0.057516523. Sequential2290a28's hyper parameters: Current learning rate is 0.011595547309833023. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 3626][Wall Clock 451.847399476s] Trained 64 records in 0.153974468 seconds. Throughput is 415.65332 records/second. Loss is 0.108309336. Sequential2290a28's hyper parameters: Current learning rate is 0.011594202898550725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 52032/60000][Iteration 3627][Wall Clock 451.943198432s] Trained 64 records in 0.095798956 seconds. Throughput is 668.06573 records/second. Loss is 0.08832436. Sequential2290a28's hyper parameters: Current learning rate is 0.011592858798979828. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 52096/60000][Iteration 3628][Wall Clock 452.056854598s] Trained 64 records in 0.113656166 seconds. Throughput is 563.10187 records/second. Loss is 0.21925712. Sequential2290a28's hyper parameters: Current learning rate is 0.01159151501101194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 52160/60000][Iteration 3629][Wall Clock 452.205037217s] Trained 64 records in 0.148182619 seconds. Throughput is 431.8995 records/second. Loss is 0.11701079. Sequential2290a28's hyper parameters: Current learning rate is 0.011590171534538712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 3630][Wall Clock 452.30703307s] Trained 64 records in 0.101995853 seconds. Throughput is 627.4765 records/second. Loss is 0.10546913. Sequential2290a28's hyper parameters: Current learning rate is 0.011588828369451848. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 52288/60000][Iteration 3631][Wall Clock 452.410241839s] Trained 64 records in 0.103208769 seconds. Throughput is 620.10236 records/second. Loss is 0.0696971. Sequential2290a28's hyper parameters: Current learning rate is 0.011587485515643106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 52352/60000][Iteration 3632][Wall Clock 452.545591613s] Trained 64 records in 0.135349774 seconds. Throughput is 472.84894 records/second. Loss is 0.1822337. Sequential2290a28's hyper parameters: Current learning rate is 0.011586142973004287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52416/60000][Iteration 3633][Wall Clock 452.666972101s] Trained 64 records in 0.121380488 seconds. Throughput is 527.26764 records/second. Loss is 0.12426353. Sequential2290a28's hyper parameters: Current learning rate is 0.011584800741427249. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 3634][Wall Clock 452.788579555s] Trained 64 records in 0.121607454 seconds. Throughput is 526.2835 records/second. Loss is 0.17028502. Sequential2290a28's hyper parameters: Current learning rate is 0.011583458820803893. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52544/60000][Iteration 3635][Wall Clock 452.985677467s] Trained 64 records in 0.197097912 seconds. Throughput is 324.7117 records/second. Loss is 0.15169176. Sequential2290a28's hyper parameters: Current learning rate is 0.011582117211026177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52608/60000][Iteration 3636][Wall Clock 453.077396246s] Trained 64 records in 0.091718779 seconds. Throughput is 697.78516 records/second. Loss is 0.08690435. Sequential2290a28's hyper parameters: Current learning rate is 0.011580775911986104. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52672/60000][Iteration 3637][Wall Clock 453.193714336s] Trained 64 records in 0.11631809 seconds. Throughput is 550.21533 records/second. Loss is 0.04450044. Sequential2290a28's hyper parameters: Current learning rate is 0.01157943492357573. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 3638][Wall Clock 453.384488284s] Trained 64 records in 0.190773948 seconds. Throughput is 335.4756 records/second. Loss is 0.2629942. Sequential2290a28's hyper parameters: Current learning rate is 0.01157809424568716. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52800/60000][Iteration 3639][Wall Clock 453.470913974s] Trained 64 records in 0.08642569 seconds. Throughput is 740.52057 records/second. Loss is 0.117223985. Sequential2290a28's hyper parameters: Current learning rate is 0.01157675387821255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 52864/60000][Iteration 3640][Wall Clock 453.618869912s] Trained 64 records in 0.147955938 seconds. Throughput is 432.56122 records/second. Loss is 0.14261544. Sequential2290a28's hyper parameters: Current learning rate is 0.011575413821044102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 52928/60000][Iteration 3641][Wall Clock 453.743543461s] Trained 64 records in 0.124673549 seconds. Throughput is 513.34064 records/second. Loss is 0.120590165. Sequential2290a28's hyper parameters: Current learning rate is 0.011574074074074075. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 3642][Wall Clock 453.840872231s] Trained 64 records in 0.09732877 seconds. Throughput is 657.5651 records/second. Loss is 0.13507202. Sequential2290a28's hyper parameters: Current learning rate is 0.011572734637194769. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 53056/60000][Iteration 3643][Wall Clock 453.945878172s] Trained 64 records in 0.105005941 seconds. Throughput is 609.4893 records/second. Loss is 0.11462316. Sequential2290a28's hyper parameters: Current learning rate is 0.011571395510298541. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 53120/60000][Iteration 3644][Wall Clock 454.090566213s] Trained 64 records in 0.144688041 seconds. Throughput is 442.33096 records/second. Loss is 0.09763524. Sequential2290a28's hyper parameters: Current learning rate is 0.011570056693277797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 53184/60000][Iteration 3645][Wall Clock 454.261533284s] Trained 64 records in 0.170967071 seconds. Throughput is 374.3411 records/second. Loss is 0.07545691. Sequential2290a28's hyper parameters: Current learning rate is 0.011568718186024987. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 3646][Wall Clock 454.407165588s] Trained 64 records in 0.145632304 seconds. Throughput is 439.46295 records/second. Loss is 0.12551892. Sequential2290a28's hyper parameters: Current learning rate is 0.01156737998843262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 53312/60000][Iteration 3647][Wall Clock 454.629204634s] Trained 64 records in 0.222039046 seconds. Throughput is 288.2376 records/second. Loss is 0.19880354. Sequential2290a28's hyper parameters: Current learning rate is 0.011566042100393244. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 53376/60000][Iteration 3648][Wall Clock 454.823934869s] Trained 64 records in 0.194730235 seconds. Throughput is 328.6598 records/second. Loss is 0.18165779. Sequential2290a28's hyper parameters: Current learning rate is 0.011564704521799469. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 53440/60000][Iteration 3649][Wall Clock 454.978651491s] Trained 64 records in 0.154716622 seconds. Throughput is 413.6595 records/second. Loss is 0.10392748. Sequential2290a28's hyper parameters: Current learning rate is 0.01156336725254394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 3650][Wall Clock 455.129320452s] Trained 64 records in 0.150668961 seconds. Throughput is 424.77228 records/second. Loss is 0.16554953. Sequential2290a28's hyper parameters: Current learning rate is 0.011562030292519367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 53568/60000][Iteration 3651][Wall Clock 455.244143126s] Trained 64 records in 0.114822674 seconds. Throughput is 557.3812 records/second. Loss is 0.14178832. Sequential2290a28's hyper parameters: Current learning rate is 0.011560693641618498. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 53632/60000][Iteration 3652][Wall Clock 455.427437757s] Trained 64 records in 0.183294631 seconds. Throughput is 349.16464 records/second. Loss is 0.29165775. Sequential2290a28's hyper parameters: Current learning rate is 0.011559357299734136. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 53696/60000][Iteration 3653][Wall Clock 455.701530391s] Trained 64 records in 0.274092634 seconds. Throughput is 233.4977 records/second. Loss is 0.253291. Sequential2290a28's hyper parameters: Current learning rate is 0.011558021266759132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 3654][Wall Clock 455.862256387s] Trained 64 records in 0.160725996 seconds. Throughput is 398.1932 records/second. Loss is 0.14500651. Sequential2290a28's hyper parameters: Current learning rate is 0.011556685542586388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 53824/60000][Iteration 3655][Wall Clock 455.968794281s] Trained 64 records in 0.106537894 seconds. Throughput is 600.7252 records/second. Loss is 0.15170121. Sequential2290a28's hyper parameters: Current learning rate is 0.011555350127108852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 53888/60000][Iteration 3656][Wall Clock 456.093821143s] Trained 64 records in 0.125026862 seconds. Throughput is 511.88998 records/second. Loss is 0.13225771. Sequential2290a28's hyper parameters: Current learning rate is 0.011554015020219527. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 53952/60000][Iteration 3657][Wall Clock 456.281002109s] Trained 64 records in 0.187180966 seconds. Throughput is 341.9151 records/second. Loss is 0.079566054. Sequential2290a28's hyper parameters: Current learning rate is 0.01155268022181146. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 3658][Wall Clock 456.38284751s] Trained 64 records in 0.101845401 seconds. Throughput is 628.40344 records/second. Loss is 0.22734341. Sequential2290a28's hyper parameters: Current learning rate is 0.011551345731777752. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 54080/60000][Iteration 3659][Wall Clock 456.539177447s] Trained 64 records in 0.156329937 seconds. Throughput is 409.39056 records/second. Loss is 0.22440067. Sequential2290a28's hyper parameters: Current learning rate is 0.01155001155001155. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54144/60000][Iteration 3660][Wall Clock 456.72928298s] Trained 64 records in 0.190105533 seconds. Throughput is 336.65512 records/second. Loss is 0.18324861. Sequential2290a28's hyper parameters: Current learning rate is 0.011548677676406051. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54208/60000][Iteration 3661][Wall Clock 456.845170862s] Trained 64 records in 0.115887882 seconds. Throughput is 552.25793 records/second. Loss is 0.15955108. Sequential2290a28's hyper parameters: Current learning rate is 0.011547344110854504. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 3662][Wall Clock 456.972642182s] Trained 64 records in 0.12747132 seconds. Throughput is 502.07376 records/second. Loss is 0.07769869. Sequential2290a28's hyper parameters: Current learning rate is 0.0115460108532502. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54336/60000][Iteration 3663][Wall Clock 457.066701743s] Trained 64 records in 0.094059561 seconds. Throughput is 680.4199 records/second. Loss is 0.07845532. Sequential2290a28's hyper parameters: Current learning rate is 0.011544677903486492. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54400/60000][Iteration 3664][Wall Clock 457.196449726s] Trained 64 records in 0.129747983 seconds. Throughput is 493.26392 records/second. Loss is 0.27256957. Sequential2290a28's hyper parameters: Current learning rate is 0.01154334526145677. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54464/60000][Iteration 3665][Wall Clock 457.396954115s] Trained 64 records in 0.200504389 seconds. Throughput is 319.195 records/second. Loss is 0.101305194. Sequential2290a28's hyper parameters: Current learning rate is 0.011542012927054477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 3666][Wall Clock 457.608406963s] Trained 64 records in 0.211452848 seconds. Throughput is 302.66797 records/second. Loss is 0.087768964. Sequential2290a28's hyper parameters: Current learning rate is 0.011540680900173109. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54592/60000][Iteration 3667][Wall Clock 457.719673752s] Trained 64 records in 0.111266789 seconds. Throughput is 575.1941 records/second. Loss is 0.09103052. Sequential2290a28's hyper parameters: Current learning rate is 0.011539349180706208. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54656/60000][Iteration 3668][Wall Clock 457.981766952s] Trained 64 records in 0.2620932 seconds. Throughput is 244.18796 records/second. Loss is 0.045829758. Sequential2290a28's hyper parameters: Current learning rate is 0.011538017768547364. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54720/60000][Iteration 3669][Wall Clock 458.153944416s] Trained 64 records in 0.172177464 seconds. Throughput is 371.7095 records/second. Loss is 0.18608364. Sequential2290a28's hyper parameters: Current learning rate is 0.011536686663590217. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 3670][Wall Clock 458.366546071s] Trained 64 records in 0.212601655 seconds. Throughput is 301.03244 records/second. Loss is 0.120648265. Sequential2290a28's hyper parameters: Current learning rate is 0.011535355865728458. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54848/60000][Iteration 3671][Wall Clock 458.528370456s] Trained 64 records in 0.161824385 seconds. Throughput is 395.49045 records/second. Loss is 0.044395898. Sequential2290a28's hyper parameters: Current learning rate is 0.011534025374855825. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 54912/60000][Iteration 3672][Wall Clock 458.67796864s] Trained 64 records in 0.149598184 seconds. Throughput is 427.81268 records/second. Loss is 0.15120223. Sequential2290a28's hyper parameters: Current learning rate is 0.011532695190866107. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 54976/60000][Iteration 3673][Wall Clock 458.826306594s] Trained 64 records in 0.148337954 seconds. Throughput is 431.4472 records/second. Loss is 0.19263071. Sequential2290a28's hyper parameters: Current learning rate is 0.011531365313653136. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 3674][Wall Clock 458.974132156s] Trained 64 records in 0.147825562 seconds. Throughput is 432.9427 records/second. Loss is 0.11241892. Sequential2290a28's hyper parameters: Current learning rate is 0.011530035743110805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55104/60000][Iteration 3675][Wall Clock 459.10503395s] Trained 64 records in 0.130901794 seconds. Throughput is 488.91614 records/second. Loss is 0.16259353. Sequential2290a28's hyper parameters: Current learning rate is 0.011528706479133042. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55168/60000][Iteration 3676][Wall Clock 459.174585666s] Trained 64 records in 0.069551716 seconds. Throughput is 920.17865 records/second. Loss is 0.13825679. Sequential2290a28's hyper parameters: Current learning rate is 0.011527377521613834. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55232/60000][Iteration 3677][Wall Clock 459.326550656s] Trained 64 records in 0.15196499 seconds. Throughput is 421.14963 records/second. Loss is 0.13133544. Sequential2290a28's hyper parameters: Current learning rate is 0.01152604887044721. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 3678][Wall Clock 459.439461745s] Trained 64 records in 0.112911089 seconds. Throughput is 566.8177 records/second. Loss is 0.12371284. Sequential2290a28's hyper parameters: Current learning rate is 0.011524720525527256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55360/60000][Iteration 3679][Wall Clock 459.553828262s] Trained 64 records in 0.114366517 seconds. Throughput is 559.6044 records/second. Loss is 0.100006536. Sequential2290a28's hyper parameters: Current learning rate is 0.011523392486748099. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55424/60000][Iteration 3680][Wall Clock 459.723899971s] Trained 64 records in 0.170071709 seconds. Throughput is 376.31186 records/second. Loss is 0.2019059. Sequential2290a28's hyper parameters: Current learning rate is 0.011522064754003917. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55488/60000][Iteration 3681][Wall Clock 459.836806625s] Trained 64 records in 0.112906654 seconds. Throughput is 566.8399 records/second. Loss is 0.0809567. Sequential2290a28's hyper parameters: Current learning rate is 0.01152073732718894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 3682][Wall Clock 459.999808108s] Trained 64 records in 0.163001483 seconds. Throughput is 392.6345 records/second. Loss is 0.3298517. Sequential2290a28's hyper parameters: Current learning rate is 0.011519410206197442. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55616/60000][Iteration 3683][Wall Clock 460.139715731s] Trained 64 records in 0.139907623 seconds. Throughput is 457.44467 records/second. Loss is 0.12417231. Sequential2290a28's hyper parameters: Current learning rate is 0.01151808339092375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55680/60000][Iteration 3684][Wall Clock 460.247265559s] Trained 64 records in 0.107549828 seconds. Throughput is 595.073 records/second. Loss is 0.32355148. Sequential2290a28's hyper parameters: Current learning rate is 0.011516756881262236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55744/60000][Iteration 3685][Wall Clock 460.363444113s] Trained 64 records in 0.116178554 seconds. Throughput is 550.87616 records/second. Loss is 0.18912563. Sequential2290a28's hyper parameters: Current learning rate is 0.011515430677107323. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 3686][Wall Clock 460.462207075s] Trained 64 records in 0.098762962 seconds. Throughput is 648.01624 records/second. Loss is 0.22702828. Sequential2290a28's hyper parameters: Current learning rate is 0.011514104778353483. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 55872/60000][Iteration 3687][Wall Clock 460.574338706s] Trained 64 records in 0.112131631 seconds. Throughput is 570.75775 records/second. Loss is 0.12714389. Sequential2290a28's hyper parameters: Current learning rate is 0.011512779184895234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 55936/60000][Iteration 3688][Wall Clock 460.6727259s] Trained 64 records in 0.098387194 seconds. Throughput is 650.49115 records/second. Loss is 0.35622063. Sequential2290a28's hyper parameters: Current learning rate is 0.011511453896627144. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 56000/60000][Iteration 3689][Wall Clock 460.763182818s] Trained 64 records in 0.090456918 seconds. Throughput is 707.5191 records/second. Loss is 0.2095092. Sequential2290a28's hyper parameters: Current learning rate is 0.01151012891344383. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 3690][Wall Clock 460.869752776s] Trained 64 records in 0.106569958 seconds. Throughput is 600.5445 records/second. Loss is 0.15940857. Sequential2290a28's hyper parameters: Current learning rate is 0.011508804235239959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 56128/60000][Iteration 3691][Wall Clock 461.007139982s] Trained 64 records in 0.137387206 seconds. Throughput is 465.8367 records/second. Loss is 0.22676623. Sequential2290a28's hyper parameters: Current learning rate is 0.011507479861910242. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 56192/60000][Iteration 3692][Wall Clock 461.166555262s] Trained 64 records in 0.15941528 seconds. Throughput is 401.46716 records/second. Loss is 0.12509267. Sequential2290a28's hyper parameters: Current learning rate is 0.011506155793349442. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 56256/60000][Iteration 3693][Wall Clock 461.353429551s] Trained 64 records in 0.186874289 seconds. Throughput is 342.47623 records/second. Loss is 0.22966932. Sequential2290a28's hyper parameters: Current learning rate is 0.01150483202945237. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 3694][Wall Clock 461.521985531s] Trained 64 records in 0.16855598 seconds. Throughput is 379.69583 records/second. Loss is 0.08069645. Sequential2290a28's hyper parameters: Current learning rate is 0.011503508570113886. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56384/60000][Iteration 3695][Wall Clock 461.683130627s] Trained 64 records in 0.161145096 seconds. Throughput is 397.15762 records/second. Loss is 0.20144744. Sequential2290a28's hyper parameters: Current learning rate is 0.011502185415228895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56448/60000][Iteration 3696][Wall Clock 461.852703815s] Trained 64 records in 0.169573188 seconds. Throughput is 377.41815 records/second. Loss is 0.090759575. Sequential2290a28's hyper parameters: Current learning rate is 0.011500862564692352. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56512/60000][Iteration 3697][Wall Clock 461.956003116s] Trained 64 records in 0.103299301 seconds. Throughput is 619.5589 records/second. Loss is 0.13920295. Sequential2290a28's hyper parameters: Current learning rate is 0.011499540018399264. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 3698][Wall Clock 462.104734804s] Trained 64 records in 0.148731688 seconds. Throughput is 430.30505 records/second. Loss is 0.057557564. Sequential2290a28's hyper parameters: Current learning rate is 0.011498217776244681. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56640/60000][Iteration 3699][Wall Clock 462.274086459s] Trained 64 records in 0.169351655 seconds. Throughput is 377.91187 records/second. Loss is 0.23047501. Sequential2290a28's hyper parameters: Current learning rate is 0.011496895838123706. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56704/60000][Iteration 3700][Wall Clock 462.424991009s] Trained 64 records in 0.15090455 seconds. Throughput is 424.10913 records/second. Loss is 0.06534108. Sequential2290a28's hyper parameters: Current learning rate is 0.011495574203931486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 56768/60000][Iteration 3701][Wall Clock 462.562714718s] Trained 64 records in 0.137723709 seconds. Throughput is 464.6985 records/second. Loss is 0.09360093. Sequential2290a28's hyper parameters: Current learning rate is 0.011494252873563218. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:26 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 3702][Wall Clock 462.764103642s] Trained 64 records in 0.201388924 seconds. Throughput is 317.79306 records/second. Loss is 0.22464158. Sequential2290a28's hyper parameters: Current learning rate is 0.011492931846914146. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:26 INFO  DistriOptimizer$:408 - [Epoch 4 56896/60000][Iteration 3703][Wall Clock 462.94363812s] Trained 64 records in 0.179534478 seconds. Throughput is 356.47748 records/second. Loss is 0.17029521. Sequential2290a28's hyper parameters: Current learning rate is 0.011491611123879567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:26 INFO  DistriOptimizer$:408 - [Epoch 4 56960/60000][Iteration 3704][Wall Clock 463.063379009s] Trained 64 records in 0.119740889 seconds. Throughput is 534.4874 records/second. Loss is 0.16984093. Sequential2290a28's hyper parameters: Current learning rate is 0.01149029070435482. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:26 INFO  DistriOptimizer$:408 - [Epoch 4 57024/60000][Iteration 3705][Wall Clock 463.177312843s] Trained 64 records in 0.113933834 seconds. Throughput is 561.72955 records/second. Loss is 0.19653918. Sequential2290a28's hyper parameters: Current learning rate is 0.011488970588235293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:26 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 3706][Wall Clock 463.344318575s] Trained 64 records in 0.167005732 seconds. Throughput is 383.22037 records/second. Loss is 0.10679535. Sequential2290a28's hyper parameters: Current learning rate is 0.011487650775416428. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:26 INFO  DistriOptimizer$:408 - [Epoch 4 57152/60000][Iteration 3707][Wall Clock 463.51313762s] Trained 64 records in 0.168819045 seconds. Throughput is 379.10416 records/second. Loss is 0.15738395. Sequential2290a28's hyper parameters: Current learning rate is 0.011486331265793705. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57216/60000][Iteration 3708][Wall Clock 463.677246799s] Trained 64 records in 0.164109179 seconds. Throughput is 389.98425 records/second. Loss is 0.10263648. Sequential2290a28's hyper parameters: Current learning rate is 0.011485012059262662. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57280/60000][Iteration 3709][Wall Clock 463.794031768s] Trained 64 records in 0.116784969 seconds. Throughput is 548.01575 records/second. Loss is 0.04789155. Sequential2290a28's hyper parameters: Current learning rate is 0.011483693155718878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 3710][Wall Clock 463.969657554s] Trained 64 records in 0.175625786 seconds. Throughput is 364.4112 records/second. Loss is 0.23535007. Sequential2290a28's hyper parameters: Current learning rate is 0.011482374555057986. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57408/60000][Iteration 3711][Wall Clock 464.090684989s] Trained 64 records in 0.121027435 seconds. Throughput is 528.8057 records/second. Loss is 0.22520088. Sequential2290a28's hyper parameters: Current learning rate is 0.011481056257175661. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57472/60000][Iteration 3712][Wall Clock 464.252540691s] Trained 64 records in 0.161855702 seconds. Throughput is 395.41394 records/second. Loss is 0.05968708. Sequential2290a28's hyper parameters: Current learning rate is 0.011479738261967628. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57536/60000][Iteration 3713][Wall Clock 464.382661952s] Trained 64 records in 0.130121261 seconds. Throughput is 491.8489 records/second. Loss is 0.18601775. Sequential2290a28's hyper parameters: Current learning rate is 0.011478420569329661. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:27 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 3714][Wall Clock 464.514220163s] Trained 64 records in 0.131558211 seconds. Throughput is 486.47668 records/second. Loss is 0.20175764. Sequential2290a28's hyper parameters: Current learning rate is 0.011477103179157582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 57664/60000][Iteration 3715][Wall Clock 464.619333307s] Trained 64 records in 0.105113144 seconds. Throughput is 608.86774 records/second. Loss is 0.14824346. Sequential2290a28's hyper parameters: Current learning rate is 0.011475786091347258. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 57728/60000][Iteration 3716][Wall Clock 464.743693019s] Trained 64 records in 0.124359712 seconds. Throughput is 514.6361 records/second. Loss is 0.193227. Sequential2290a28's hyper parameters: Current learning rate is 0.011474469305794608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 57792/60000][Iteration 3717][Wall Clock 464.90219756s] Trained 64 records in 0.158504541 seconds. Throughput is 403.7739 records/second. Loss is 0.16413824. Sequential2290a28's hyper parameters: Current learning rate is 0.011473152822395595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 3718][Wall Clock 465.008395288s] Trained 64 records in 0.106197728 seconds. Throughput is 602.6494 records/second. Loss is 0.10982023. Sequential2290a28's hyper parameters: Current learning rate is 0.011471836641046231. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 57920/60000][Iteration 3719][Wall Clock 465.181624627s] Trained 64 records in 0.173229339 seconds. Throughput is 369.45242 records/second. Loss is 0.11243956. Sequential2290a28's hyper parameters: Current learning rate is 0.011470520761642579. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 57984/60000][Iteration 3720][Wall Clock 465.275239279s] Trained 64 records in 0.093614652 seconds. Throughput is 683.6537 records/second. Loss is 0.12759504. Sequential2290a28's hyper parameters: Current learning rate is 0.011469205184080743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 58048/60000][Iteration 3721][Wall Clock 465.359190382s] Trained 64 records in 0.083951103 seconds. Throughput is 762.3486 records/second. Loss is 0.09077291. Sequential2290a28's hyper parameters: Current learning rate is 0.011467889908256881. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:28 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 3722][Wall Clock 465.559375281s] Trained 64 records in 0.200184899 seconds. Throughput is 319.70444 records/second. Loss is 0.12990925. Sequential2290a28's hyper parameters: Current learning rate is 0.011466574934067194. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58176/60000][Iteration 3723][Wall Clock 465.728295811s] Trained 64 records in 0.16892053 seconds. Throughput is 378.87637 records/second. Loss is 0.050947383. Sequential2290a28's hyper parameters: Current learning rate is 0.011465260261407933. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58240/60000][Iteration 3724][Wall Clock 465.820266715s] Trained 64 records in 0.091970904 seconds. Throughput is 695.87225 records/second. Loss is 0.2370716. Sequential2290a28's hyper parameters: Current learning rate is 0.011463945890175398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58304/60000][Iteration 3725][Wall Clock 465.921531862s] Trained 64 records in 0.101265147 seconds. Throughput is 632.0042 records/second. Loss is 0.07819818. Sequential2290a28's hyper parameters: Current learning rate is 0.011462631820265932. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 3726][Wall Clock 466.106773316s] Trained 64 records in 0.185241454 seconds. Throughput is 345.495 records/second. Loss is 0.044790022. Sequential2290a28's hyper parameters: Current learning rate is 0.011461318051575931. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58432/60000][Iteration 3727][Wall Clock 466.213767412s] Trained 64 records in 0.106994096 seconds. Throughput is 598.1639 records/second. Loss is 0.1426343. Sequential2290a28's hyper parameters: Current learning rate is 0.011460004584001834. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58496/60000][Iteration 3728][Wall Clock 466.330394482s] Trained 64 records in 0.11662707 seconds. Throughput is 548.7577 records/second. Loss is 0.244468. Sequential2290a28's hyper parameters: Current learning rate is 0.011458691417440128. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58560/60000][Iteration 3729][Wall Clock 466.461479682s] Trained 64 records in 0.1310852 seconds. Throughput is 488.2321 records/second. Loss is 0.09048352. Sequential2290a28's hyper parameters: Current learning rate is 0.011457378551787351. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:29 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 3730][Wall Clock 466.577403887s] Trained 64 records in 0.115924205 seconds. Throughput is 552.0849 records/second. Loss is 0.08196292. Sequential2290a28's hyper parameters: Current learning rate is 0.011456065986940085. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 58688/60000][Iteration 3731][Wall Clock 466.687784991s] Trained 64 records in 0.110381104 seconds. Throughput is 579.8094 records/second. Loss is 0.1641236. Sequential2290a28's hyper parameters: Current learning rate is 0.01145475372279496. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 58752/60000][Iteration 3732][Wall Clock 466.803826937s] Trained 64 records in 0.116041946 seconds. Throughput is 551.5247 records/second. Loss is 0.15019369. Sequential2290a28's hyper parameters: Current learning rate is 0.011453441759248655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 58816/60000][Iteration 3733][Wall Clock 466.954785987s] Trained 64 records in 0.15095905 seconds. Throughput is 423.95605 records/second. Loss is 0.19769478. Sequential2290a28's hyper parameters: Current learning rate is 0.011452130096197893. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 3734][Wall Clock 467.139366372s] Trained 64 records in 0.184580385 seconds. Throughput is 346.7324 records/second. Loss is 0.14688972. Sequential2290a28's hyper parameters: Current learning rate is 0.01145081873353945. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 58944/60000][Iteration 3735][Wall Clock 467.290205365s] Trained 64 records in 0.150838993 seconds. Throughput is 424.2935 records/second. Loss is 0.12167107. Sequential2290a28's hyper parameters: Current learning rate is 0.01144950767117014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 59008/60000][Iteration 3736][Wall Clock 467.395714938s] Trained 64 records in 0.105509573 seconds. Throughput is 606.58 records/second. Loss is 0.12968886. Sequential2290a28's hyper parameters: Current learning rate is 0.011448196908986836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:30 INFO  DistriOptimizer$:408 - [Epoch 4 59072/60000][Iteration 3737][Wall Clock 467.523033186s] Trained 64 records in 0.127318248 seconds. Throughput is 502.67737 records/second. Loss is 0.24101537. Sequential2290a28's hyper parameters: Current learning rate is 0.011446886446886446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:31 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 3738][Wall Clock 467.649972556s] Trained 64 records in 0.12693937 seconds. Throughput is 504.1777 records/second. Loss is 0.15013814. Sequential2290a28's hyper parameters: Current learning rate is 0.011445576284765937. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:31 INFO  DistriOptimizer$:408 - [Epoch 4 59200/60000][Iteration 3739][Wall Clock 467.822439466s] Trained 64 records in 0.17246691 seconds. Throughput is 371.0857 records/second. Loss is 0.07593763. Sequential2290a28's hyper parameters: Current learning rate is 0.011444266422522316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:31 INFO  DistriOptimizer$:408 - [Epoch 4 59264/60000][Iteration 3740][Wall Clock 467.940362578s] Trained 64 records in 0.117923112 seconds. Throughput is 542.7265 records/second. Loss is 0.12271121. Sequential2290a28's hyper parameters: Current learning rate is 0.011442956860052637. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:31 INFO  DistriOptimizer$:408 - [Epoch 4 59328/60000][Iteration 3741][Wall Clock 468.11182695s] Trained 64 records in 0.171464372 seconds. Throughput is 373.2554 records/second. Loss is 0.10809462. Sequential2290a28's hyper parameters: Current learning rate is 0.011441647597254004. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:31 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 3742][Wall Clock 468.320954586s] Trained 64 records in 0.209127636 seconds. Throughput is 306.0332 records/second. Loss is 0.110425286. Sequential2290a28's hyper parameters: Current learning rate is 0.011440338634023566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:31 INFO  DistriOptimizer$:408 - [Epoch 4 59456/60000][Iteration 3743][Wall Clock 468.43584043s] Trained 64 records in 0.114885844 seconds. Throughput is 557.0747 records/second. Loss is 0.2608726. Sequential2290a28's hyper parameters: Current learning rate is 0.011439029970258521. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59520/60000][Iteration 3744][Wall Clock 468.588106247s] Trained 64 records in 0.152265817 seconds. Throughput is 420.3176 records/second. Loss is 0.14594054. Sequential2290a28's hyper parameters: Current learning rate is 0.011437721605856113. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59584/60000][Iteration 3745][Wall Clock 468.7108588s] Trained 64 records in 0.122752553 seconds. Throughput is 521.3741 records/second. Loss is 0.09667633. Sequential2290a28's hyper parameters: Current learning rate is 0.011436413540713631. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 3746][Wall Clock 468.852341746s] Trained 64 records in 0.141482946 seconds. Throughput is 452.35132 records/second. Loss is 0.091852166. Sequential2290a28's hyper parameters: Current learning rate is 0.011435105774728416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59712/60000][Iteration 3747][Wall Clock 468.952381963s] Trained 64 records in 0.100040217 seconds. Throughput is 639.7427 records/second. Loss is 0.18999466. Sequential2290a28's hyper parameters: Current learning rate is 0.01143379830779785. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59776/60000][Iteration 3748][Wall Clock 469.061318265s] Trained 64 records in 0.108936302 seconds. Throughput is 587.49927 records/second. Loss is 0.16613373. Sequential2290a28's hyper parameters: Current learning rate is 0.011432491139819366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59840/60000][Iteration 3749][Wall Clock 469.170977166s] Trained 64 records in 0.109658901 seconds. Throughput is 583.6279 records/second. Loss is 0.09998581. Sequential2290a28's hyper parameters: Current learning rate is 0.011431184270690443. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 3750][Wall Clock 469.320721296s] Trained 64 records in 0.14974413 seconds. Throughput is 427.39575 records/second. Loss is 0.16828896. Sequential2290a28's hyper parameters: Current learning rate is 0.011429877700308606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:32 INFO  DistriOptimizer$:408 - [Epoch 4 59968/60000][Iteration 3751][Wall Clock 469.458420456s] Trained 64 records in 0.13769916 seconds. Throughput is 464.78134 records/second. Loss is 0.0966081. Sequential2290a28's hyper parameters: Current learning rate is 0.011428571428571429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:33 INFO  DistriOptimizer$:408 - [Epoch 4 60032/60000][Iteration 3752][Wall Clock 469.592928312s] Trained 64 records in 0.134507856 seconds. Throughput is 475.80865 records/second. Loss is 0.20149806. Sequential2290a28's hyper parameters: Current learning rate is 0.011427265455376529. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:33 INFO  DistriOptimizer$:452 - [Epoch 4 60032/60000][Iteration 3752][Wall Clock 469.592928312s] Epoch finished. Wall clock time is 471784.388392 ms
2019-10-24 03:21:33 INFO  DistriOptimizer$:111 - [Epoch 4 60032/60000][Iteration 3752][Wall Clock 469.592928312s] Validate model...
2019-10-24 03:21:33 INFO  DistriOptimizer$:178 - [Epoch 4 60032/60000][Iteration 3752][Wall Clock 469.592928312s] validate model throughput is 10993.167 records/second
2019-10-24 03:21:33 INFO  DistriOptimizer$:181 - [Epoch 4 60032/60000][Iteration 3752][Wall Clock 469.592928312s] Top1Accuracy is Accuracy(correct: 9606, count: 10000, accuracy: 0.9606)
2019-10-24 03:21:34 INFO  DistriOptimizer$:221 - [Wall Clock 471.784388392s] Save model to /tmp/lenet5/20191024_031340
2019-10-24 03:21:34 INFO  DistriOptimizer$:226 - [Wall Clock 471.784388392s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@b5fef19 to /tmp/lenet5/20191024_031340
2019-10-24 03:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 64/60000][Iteration 3753][Wall Clock 471.908072847s] Trained 64 records in 0.123684455 seconds. Throughput is 517.4458 records/second. Loss is 0.20553875. Sequential2290a28's hyper parameters: Current learning rate is 0.011425959780621572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 128/60000][Iteration 3754][Wall Clock 472.026831333s] Trained 64 records in 0.118758486 seconds. Throughput is 538.9089 records/second. Loss is 0.2940519. Sequential2290a28's hyper parameters: Current learning rate is 0.011424654404204274. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 192/60000][Iteration 3755][Wall Clock 472.164180237s] Trained 64 records in 0.137348904 seconds. Throughput is 465.96658 records/second. Loss is 0.1470721. Sequential2290a28's hyper parameters: Current learning rate is 0.01142334932602239. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 3756][Wall Clock 472.322458052s] Trained 64 records in 0.158277815 seconds. Throughput is 404.35233 records/second. Loss is 0.18071888. Sequential2290a28's hyper parameters: Current learning rate is 0.01142204454597373. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 320/60000][Iteration 3757][Wall Clock 472.438555052s] Trained 64 records in 0.116097 seconds. Throughput is 551.2631 records/second. Loss is 0.10426014. Sequential2290a28's hyper parameters: Current learning rate is 0.011420740063956145. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 384/60000][Iteration 3758][Wall Clock 472.569839392s] Trained 64 records in 0.13128434 seconds. Throughput is 487.4915 records/second. Loss is 0.057718523. Sequential2290a28's hyper parameters: Current learning rate is 0.011419435879867535. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 448/60000][Iteration 3759][Wall Clock 472.721117281s] Trained 64 records in 0.151277889 seconds. Throughput is 423.0625 records/second. Loss is 0.28774208. Sequential2290a28's hyper parameters: Current learning rate is 0.011418131993605847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 3760][Wall Clock 472.908466237s] Trained 64 records in 0.187348956 seconds. Throughput is 341.60852 records/second. Loss is 0.20845991. Sequential2290a28's hyper parameters: Current learning rate is 0.011416828405069072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 576/60000][Iteration 3761][Wall Clock 473.074810701s] Trained 64 records in 0.166344464 seconds. Throughput is 384.7438 records/second. Loss is 0.11840231. Sequential2290a28's hyper parameters: Current learning rate is 0.01141552511415525. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 640/60000][Iteration 3762][Wall Clock 473.239821149s] Trained 64 records in 0.165010448 seconds. Throughput is 387.85422 records/second. Loss is 0.1284952. Sequential2290a28's hyper parameters: Current learning rate is 0.01141422212076247. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 704/60000][Iteration 3763][Wall Clock 473.416402367s] Trained 64 records in 0.176581218 seconds. Throughput is 362.43945 records/second. Loss is 0.12460609. Sequential2290a28's hyper parameters: Current learning rate is 0.011412919424788861. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 3764][Wall Clock 473.557908898s] Trained 64 records in 0.141506531 seconds. Throughput is 452.2759 records/second. Loss is 0.1550043. Sequential2290a28's hyper parameters: Current learning rate is 0.011411617026132602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 832/60000][Iteration 3765][Wall Clock 473.707608031s] Trained 64 records in 0.149699133 seconds. Throughput is 427.52417 records/second. Loss is 0.16575053. Sequential2290a28's hyper parameters: Current learning rate is 0.011410314924691922. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 896/60000][Iteration 3766][Wall Clock 473.880277975s] Trained 64 records in 0.172669944 seconds. Throughput is 370.64932 records/second. Loss is 0.17157587. Sequential2290a28's hyper parameters: Current learning rate is 0.011409013120365089. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 960/60000][Iteration 3767][Wall Clock 474.026448383s] Trained 64 records in 0.146170408 seconds. Throughput is 437.84512 records/second. Loss is 0.1298483. Sequential2290a28's hyper parameters: Current learning rate is 0.011407711613050422. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 3768][Wall Clock 474.19628991s] Trained 64 records in 0.169841527 seconds. Throughput is 376.82187 records/second. Loss is 0.08981874. Sequential2290a28's hyper parameters: Current learning rate is 0.011406410402646287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 1088/60000][Iteration 3769][Wall Clock 474.294617309s] Trained 64 records in 0.098327399 seconds. Throughput is 650.8867 records/second. Loss is 0.3158013. Sequential2290a28's hyper parameters: Current learning rate is 0.011405109489051095. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 1152/60000][Iteration 3770][Wall Clock 474.458650794s] Trained 64 records in 0.164033485 seconds. Throughput is 390.16425 records/second. Loss is 0.2078411. Sequential2290a28's hyper parameters: Current learning rate is 0.011403808872163303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 1216/60000][Iteration 3771][Wall Clock 474.661537761s] Trained 64 records in 0.202886967 seconds. Throughput is 315.44656 records/second. Loss is 0.082804434. Sequential2290a28's hyper parameters: Current learning rate is 0.011402508551881414. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 3772][Wall Clock 474.789789721s] Trained 64 records in 0.12825196 seconds. Throughput is 499.01773 records/second. Loss is 0.3267687. Sequential2290a28's hyper parameters: Current learning rate is 0.01140120852810398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 1344/60000][Iteration 3773][Wall Clock 474.981425233s] Trained 64 records in 0.191635512 seconds. Throughput is 333.96732 records/second. Loss is 0.1400433. Sequential2290a28's hyper parameters: Current learning rate is 0.011399908800729594. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 1408/60000][Iteration 3774][Wall Clock 475.125856321s] Trained 64 records in 0.144431088 seconds. Throughput is 443.11792 records/second. Loss is 0.16338232. Sequential2290a28's hyper parameters: Current learning rate is 0.011398609369656903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 1472/60000][Iteration 3775][Wall Clock 475.306279894s] Trained 64 records in 0.180423573 seconds. Throughput is 354.72083 records/second. Loss is 0.05426776. Sequential2290a28's hyper parameters: Current learning rate is 0.011397310234784592. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 3776][Wall Clock 475.434133422s] Trained 64 records in 0.127853528 seconds. Throughput is 500.5728 records/second. Loss is 0.120899245. Sequential2290a28's hyper parameters: Current learning rate is 0.011396011396011397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 1600/60000][Iteration 3777][Wall Clock 475.541656076s] Trained 64 records in 0.107522654 seconds. Throughput is 595.2234 records/second. Loss is 0.105415985. Sequential2290a28's hyper parameters: Current learning rate is 0.0113947128532361. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 1664/60000][Iteration 3778][Wall Clock 475.755892463s] Trained 64 records in 0.214236387 seconds. Throughput is 298.7354 records/second. Loss is 0.15840766. Sequential2290a28's hyper parameters: Current learning rate is 0.011393414606357526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 1728/60000][Iteration 3779][Wall Clock 475.881314978s] Trained 64 records in 0.125422515 seconds. Throughput is 510.27518 records/second. Loss is 0.071482584. Sequential2290a28's hyper parameters: Current learning rate is 0.01139211665527455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 3780][Wall Clock 476.165241237s] Trained 64 records in 0.283926259 seconds. Throughput is 225.41064 records/second. Loss is 0.17156954. Sequential2290a28's hyper parameters: Current learning rate is 0.011390818999886091. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 1856/60000][Iteration 3781][Wall Clock 476.321562995s] Trained 64 records in 0.156321758 seconds. Throughput is 409.41196 records/second. Loss is 0.14185055. Sequential2290a28's hyper parameters: Current learning rate is 0.011389521640091117. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 1920/60000][Iteration 3782][Wall Clock 476.44534089s] Trained 64 records in 0.123777895 seconds. Throughput is 517.0552 records/second. Loss is 0.15272823. Sequential2290a28's hyper parameters: Current learning rate is 0.011388224575788634. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 1984/60000][Iteration 3783][Wall Clock 476.568717143s] Trained 64 records in 0.123376253 seconds. Throughput is 518.7384 records/second. Loss is 0.10326358. Sequential2290a28's hyper parameters: Current learning rate is 0.011386927806877703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 3784][Wall Clock 476.681915624s] Trained 64 records in 0.113198481 seconds. Throughput is 565.3786 records/second. Loss is 0.1570456. Sequential2290a28's hyper parameters: Current learning rate is 0.011385631333257429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 2112/60000][Iteration 3785][Wall Clock 476.795562273s] Trained 64 records in 0.113646649 seconds. Throughput is 563.14905 records/second. Loss is 0.10174503. Sequential2290a28's hyper parameters: Current learning rate is 0.011384335154826957. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 2176/60000][Iteration 3786][Wall Clock 476.911163372s] Trained 64 records in 0.115601099 seconds. Throughput is 553.6279 records/second. Loss is 0.0707609. Sequential2290a28's hyper parameters: Current learning rate is 0.011383039271485486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 2240/60000][Iteration 3787][Wall Clock 477.042496042s] Trained 64 records in 0.13133267 seconds. Throughput is 487.31213 records/second. Loss is 0.16113937. Sequential2290a28's hyper parameters: Current learning rate is 0.011381743683132255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 3788][Wall Clock 477.174640299s] Trained 64 records in 0.132144257 seconds. Throughput is 484.31918 records/second. Loss is 0.23728245. Sequential2290a28's hyper parameters: Current learning rate is 0.011380448389666552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 2368/60000][Iteration 3789][Wall Clock 477.353822413s] Trained 64 records in 0.179182114 seconds. Throughput is 357.1785 records/second. Loss is 0.10647546. Sequential2290a28's hyper parameters: Current learning rate is 0.01137915339098771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 2432/60000][Iteration 3790][Wall Clock 477.465644943s] Trained 64 records in 0.11182253 seconds. Throughput is 572.33545 records/second. Loss is 0.07085239. Sequential2290a28's hyper parameters: Current learning rate is 0.011377858686995108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 2496/60000][Iteration 3791][Wall Clock 477.58363535s] Trained 64 records in 0.117990407 seconds. Throughput is 542.417 records/second. Loss is 0.08709264. Sequential2290a28's hyper parameters: Current learning rate is 0.011376564277588168. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 3792][Wall Clock 477.775437652s] Trained 64 records in 0.191802302 seconds. Throughput is 333.6769 records/second. Loss is 0.1712212. Sequential2290a28's hyper parameters: Current learning rate is 0.011375270162666363. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 2624/60000][Iteration 3793][Wall Clock 477.953847745s] Trained 64 records in 0.178410093 seconds. Throughput is 358.7241 records/second. Loss is 0.092133224. Sequential2290a28's hyper parameters: Current learning rate is 0.01137397634212921. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 2688/60000][Iteration 3794][Wall Clock 478.155615007s] Trained 64 records in 0.201767262 seconds. Throughput is 317.19714 records/second. Loss is 0.06963436. Sequential2290a28's hyper parameters: Current learning rate is 0.011372682815876266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 2752/60000][Iteration 3795][Wall Clock 478.362419158s] Trained 64 records in 0.206804151 seconds. Throughput is 309.47153 records/second. Loss is 0.094004735. Sequential2290a28's hyper parameters: Current learning rate is 0.011371389583807142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 3796][Wall Clock 478.450113706s] Trained 64 records in 0.087694548 seconds. Throughput is 729.8059 records/second. Loss is 0.2234526. Sequential2290a28's hyper parameters: Current learning rate is 0.01137009664582149. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 2880/60000][Iteration 3797][Wall Clock 478.521873423s] Trained 64 records in 0.071759717 seconds. Throughput is 891.8653 records/second. Loss is 0.101450875. Sequential2290a28's hyper parameters: Current learning rate is 0.01136880400181901. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 2944/60000][Iteration 3798][Wall Clock 478.625166305s] Trained 64 records in 0.103292882 seconds. Throughput is 619.5974 records/second. Loss is 0.06690987. Sequential2290a28's hyper parameters: Current learning rate is 0.011367511651699443. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 3008/60000][Iteration 3799][Wall Clock 478.716042283s] Trained 64 records in 0.090875978 seconds. Throughput is 704.25653 records/second. Loss is 0.20837463. Sequential2290a28's hyper parameters: Current learning rate is 0.011366219595362582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 3800][Wall Clock 478.826039633s] Trained 64 records in 0.10999735 seconds. Throughput is 581.8322 records/second. Loss is 0.1228957. Sequential2290a28's hyper parameters: Current learning rate is 0.011364927832708262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 3136/60000][Iteration 3801][Wall Clock 478.95357466s] Trained 64 records in 0.127535027 seconds. Throughput is 501.8229 records/second. Loss is 0.07805016. Sequential2290a28's hyper parameters: Current learning rate is 0.011363636363636364. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 3200/60000][Iteration 3802][Wall Clock 479.079648232s] Trained 64 records in 0.126073572 seconds. Throughput is 507.6401 records/second. Loss is 0.15861945. Sequential2290a28's hyper parameters: Current learning rate is 0.011362345188046814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 3264/60000][Iteration 3803][Wall Clock 479.262933608s] Trained 64 records in 0.183285376 seconds. Throughput is 349.18225 records/second. Loss is 0.083520144. Sequential2290a28's hyper parameters: Current learning rate is 0.011361054305839582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 3804][Wall Clock 479.362610858s] Trained 64 records in 0.09967725 seconds. Throughput is 642.07227 records/second. Loss is 0.09876013. Sequential2290a28's hyper parameters: Current learning rate is 0.011359763716914687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3392/60000][Iteration 3805][Wall Clock 479.485739432s] Trained 64 records in 0.123128574 seconds. Throughput is 519.78186 records/second. Loss is 0.10102188. Sequential2290a28's hyper parameters: Current learning rate is 0.011358473421172193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3456/60000][Iteration 3806][Wall Clock 479.558932588s] Trained 64 records in 0.073193156 seconds. Throughput is 874.3987 records/second. Loss is 0.29537266. Sequential2290a28's hyper parameters: Current learning rate is 0.011357183418512209. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3520/60000][Iteration 3807][Wall Clock 479.6535239s] Trained 64 records in 0.094591312 seconds. Throughput is 676.5949 records/second. Loss is 0.0836228. Sequential2290a28's hyper parameters: Current learning rate is 0.011355893708834885. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 3808][Wall Clock 479.740752503s] Trained 64 records in 0.087228603 seconds. Throughput is 733.7043 records/second. Loss is 0.2212338. Sequential2290a28's hyper parameters: Current learning rate is 0.011354604292040422. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3648/60000][Iteration 3809][Wall Clock 479.82281501s] Trained 64 records in 0.082062507 seconds. Throughput is 779.8933 records/second. Loss is 0.12066939. Sequential2290a28's hyper parameters: Current learning rate is 0.011353315168029064. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3712/60000][Iteration 3810][Wall Clock 479.935708062s] Trained 64 records in 0.112893052 seconds. Throughput is 566.9082 records/second. Loss is 0.20780769. Sequential2290a28's hyper parameters: Current learning rate is 0.0113520263367011. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3776/60000][Iteration 3811][Wall Clock 480.059126324s] Trained 64 records in 0.123418262 seconds. Throughput is 518.5618 records/second. Loss is 0.31240565. Sequential2290a28's hyper parameters: Current learning rate is 0.011350737797956867. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 3812][Wall Clock 480.153351165s] Trained 64 records in 0.094224841 seconds. Throughput is 679.2264 records/second. Loss is 0.2150015. Sequential2290a28's hyper parameters: Current learning rate is 0.011349449551696743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3904/60000][Iteration 3813][Wall Clock 480.226944901s] Trained 64 records in 0.073593736 seconds. Throughput is 869.6392 records/second. Loss is 0.09751337. Sequential2290a28's hyper parameters: Current learning rate is 0.011348161597821153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 3968/60000][Iteration 3814][Wall Clock 480.325910277s] Trained 64 records in 0.098965376 seconds. Throughput is 646.6908 records/second. Loss is 0.22246525. Sequential2290a28's hyper parameters: Current learning rate is 0.01134687393623057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4032/60000][Iteration 3815][Wall Clock 480.425871671s] Trained 64 records in 0.099961394 seconds. Throughput is 640.2472 records/second. Loss is 0.07925816. Sequential2290a28's hyper parameters: Current learning rate is 0.011345586566825506. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 3816][Wall Clock 480.539124099s] Trained 64 records in 0.113252428 seconds. Throughput is 565.10925 records/second. Loss is 0.18523677. Sequential2290a28's hyper parameters: Current learning rate is 0.011344299489506524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4160/60000][Iteration 3817][Wall Clock 480.757007126s] Trained 64 records in 0.217883027 seconds. Throughput is 293.7356 records/second. Loss is 0.19020097. Sequential2290a28's hyper parameters: Current learning rate is 0.011343012704174229. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4224/60000][Iteration 3818][Wall Clock 480.84211991s] Trained 64 records in 0.085112784 seconds. Throughput is 751.9435 records/second. Loss is 0.12470008. Sequential2290a28's hyper parameters: Current learning rate is 0.011341726210729272. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4288/60000][Iteration 3819][Wall Clock 480.975401613s] Trained 64 records in 0.133281703 seconds. Throughput is 480.1859 records/second. Loss is 0.20580703. Sequential2290a28's hyper parameters: Current learning rate is 0.011340440009072352. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 3820][Wall Clock 481.130966203s] Trained 64 records in 0.15556459 seconds. Throughput is 411.40466 records/second. Loss is 0.13578242. Sequential2290a28's hyper parameters: Current learning rate is 0.011339154099104206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 4416/60000][Iteration 3821][Wall Clock 481.278795939s] Trained 64 records in 0.147829736 seconds. Throughput is 432.93048 records/second. Loss is 0.2501781. Sequential2290a28's hyper parameters: Current learning rate is 0.011337868480725623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4480/60000][Iteration 3822][Wall Clock 481.384110394s] Trained 64 records in 0.105314455 seconds. Throughput is 607.70386 records/second. Loss is 0.10041383. Sequential2290a28's hyper parameters: Current learning rate is 0.011336583153837433. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4544/60000][Iteration 3823][Wall Clock 481.457571713s] Trained 64 records in 0.073461319 seconds. Throughput is 871.20685 records/second. Loss is 0.13233133. Sequential2290a28's hyper parameters: Current learning rate is 0.011335298118340512. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 3824][Wall Clock 481.541451206s] Trained 64 records in 0.083879493 seconds. Throughput is 762.9994 records/second. Loss is 0.055943035. Sequential2290a28's hyper parameters: Current learning rate is 0.01133401337413578. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4672/60000][Iteration 3825][Wall Clock 481.625206543s] Trained 64 records in 0.083755337 seconds. Throughput is 764.13043 records/second. Loss is 0.04265455. Sequential2290a28's hyper parameters: Current learning rate is 0.011332728921124207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4736/60000][Iteration 3826][Wall Clock 481.718087511s] Trained 64 records in 0.092880968 seconds. Throughput is 689.054 records/second. Loss is 0.14402977. Sequential2290a28's hyper parameters: Current learning rate is 0.011331444759206798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4800/60000][Iteration 3827][Wall Clock 481.916991898s] Trained 64 records in 0.198904387 seconds. Throughput is 321.76263 records/second. Loss is 0.08796643. Sequential2290a28's hyper parameters: Current learning rate is 0.011330160888284613. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 3828][Wall Clock 482.054104709s] Trained 64 records in 0.137112811 seconds. Throughput is 466.76892 records/second. Loss is 0.124527656. Sequential2290a28's hyper parameters: Current learning rate is 0.011328877308258751. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 4928/60000][Iteration 3829][Wall Clock 482.189559685s] Trained 64 records in 0.135454976 seconds. Throughput is 472.4817 records/second. Loss is 0.12988755. Sequential2290a28's hyper parameters: Current learning rate is 0.011327594019030357. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 4992/60000][Iteration 3830][Wall Clock 482.368394483s] Trained 64 records in 0.178834798 seconds. Throughput is 357.8722 records/second. Loss is 0.19822767. Sequential2290a28's hyper parameters: Current learning rate is 0.011326311020500622. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 5056/60000][Iteration 3831][Wall Clock 482.493922203s] Trained 64 records in 0.12552772 seconds. Throughput is 509.84753 records/second. Loss is 0.14423206. Sequential2290a28's hyper parameters: Current learning rate is 0.011325028312570781. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 3832][Wall Clock 482.63278008s] Trained 64 records in 0.138857877 seconds. Throughput is 460.90292 records/second. Loss is 0.10368448. Sequential2290a28's hyper parameters: Current learning rate is 0.011323745895142113. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 5184/60000][Iteration 3833][Wall Clock 482.755411413s] Trained 64 records in 0.122631333 seconds. Throughput is 521.88947 records/second. Loss is 0.11318814. Sequential2290a28's hyper parameters: Current learning rate is 0.011322463768115942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 5248/60000][Iteration 3834][Wall Clock 482.881864636s] Trained 64 records in 0.126453223 seconds. Throughput is 506.11603 records/second. Loss is 0.036526315. Sequential2290a28's hyper parameters: Current learning rate is 0.011321181931393639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 5312/60000][Iteration 3835][Wall Clock 483.07541598s] Trained 64 records in 0.193551344 seconds. Throughput is 330.66162 records/second. Loss is 0.12614137. Sequential2290a28's hyper parameters: Current learning rate is 0.011319900384876614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 3836][Wall Clock 483.201039923s] Trained 64 records in 0.125623943 seconds. Throughput is 509.45703 records/second. Loss is 0.1056607. Sequential2290a28's hyper parameters: Current learning rate is 0.011318619128466328. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 5440/60000][Iteration 3837][Wall Clock 483.368800252s] Trained 64 records in 0.167760329 seconds. Throughput is 381.49664 records/second. Loss is 0.12244526. Sequential2290a28's hyper parameters: Current learning rate is 0.011317338162064284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 5504/60000][Iteration 3838][Wall Clock 483.550778019s] Trained 64 records in 0.181977767 seconds. Throughput is 351.6913 records/second. Loss is 0.12943062. Sequential2290a28's hyper parameters: Current learning rate is 0.011316057485572026. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 5568/60000][Iteration 3839][Wall Clock 483.703013471s] Trained 64 records in 0.152235452 seconds. Throughput is 420.40143 records/second. Loss is 0.093234174. Sequential2290a28's hyper parameters: Current learning rate is 0.011314777098891152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 3840][Wall Clock 483.885515079s] Trained 64 records in 0.182501608 seconds. Throughput is 350.68182 records/second. Loss is 0.16698706. Sequential2290a28's hyper parameters: Current learning rate is 0.011313497001923295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 5696/60000][Iteration 3841][Wall Clock 483.997646914s] Trained 64 records in 0.112131835 seconds. Throughput is 570.7567 records/second. Loss is 0.12302987. Sequential2290a28's hyper parameters: Current learning rate is 0.011312217194570135. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 5760/60000][Iteration 3842][Wall Clock 484.156252118s] Trained 64 records in 0.158605204 seconds. Throughput is 403.51767 records/second. Loss is 0.24585971. Sequential2290a28's hyper parameters: Current learning rate is 0.011310937676733402. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 5824/60000][Iteration 3843][Wall Clock 484.445248279s] Trained 64 records in 0.288996161 seconds. Throughput is 221.45622 records/second. Loss is 0.06416494. Sequential2290a28's hyper parameters: Current learning rate is 0.01130965844831486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 3844][Wall Clock 484.622216979s] Trained 64 records in 0.1769687 seconds. Throughput is 361.64587 records/second. Loss is 0.14394124. Sequential2290a28's hyper parameters: Current learning rate is 0.01130837950921633. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 5952/60000][Iteration 3845][Wall Clock 484.716792015s] Trained 64 records in 0.094575036 seconds. Throughput is 676.71136 records/second. Loss is 0.16208744. Sequential2290a28's hyper parameters: Current learning rate is 0.011307100859339664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 6016/60000][Iteration 3846][Wall Clock 484.801237236s] Trained 64 records in 0.084445221 seconds. Throughput is 757.88776 records/second. Loss is 0.18318701. Sequential2290a28's hyper parameters: Current learning rate is 0.011305822498586771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 6080/60000][Iteration 3847][Wall Clock 484.893222765s] Trained 64 records in 0.091985529 seconds. Throughput is 695.7616 records/second. Loss is 0.1954433. Sequential2290a28's hyper parameters: Current learning rate is 0.011304544426859598. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 3848][Wall Clock 484.973579141s] Trained 64 records in 0.080356376 seconds. Throughput is 796.4521 records/second. Loss is 0.09617858. Sequential2290a28's hyper parameters: Current learning rate is 0.011303266644060133. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 6208/60000][Iteration 3849][Wall Clock 485.092405867s] Trained 64 records in 0.118826726 seconds. Throughput is 538.59937 records/second. Loss is 0.12348732. Sequential2290a28's hyper parameters: Current learning rate is 0.011301989150090416. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 6272/60000][Iteration 3850][Wall Clock 485.193660191s] Trained 64 records in 0.101254324 seconds. Throughput is 632.0718 records/second. Loss is 0.2498505. Sequential2290a28's hyper parameters: Current learning rate is 0.011300711944852526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6336/60000][Iteration 3851][Wall Clock 485.337626526s] Trained 64 records in 0.143966335 seconds. Throughput is 444.54837 records/second. Loss is 0.10069451. Sequential2290a28's hyper parameters: Current learning rate is 0.011299435028248588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 3852][Wall Clock 485.510559443s] Trained 64 records in 0.172932917 seconds. Throughput is 370.0857 records/second. Loss is 0.23717989. Sequential2290a28's hyper parameters: Current learning rate is 0.011298158400180771. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6464/60000][Iteration 3853][Wall Clock 485.656490559s] Trained 64 records in 0.145931116 seconds. Throughput is 438.5631 records/second. Loss is 0.090152346. Sequential2290a28's hyper parameters: Current learning rate is 0.011296882060551289. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6528/60000][Iteration 3854][Wall Clock 485.732473134s] Trained 64 records in 0.075982575 seconds. Throughput is 842.29834 records/second. Loss is 0.08744448. Sequential2290a28's hyper parameters: Current learning rate is 0.011295606009262398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6592/60000][Iteration 3855][Wall Clock 485.865593211s] Trained 64 records in 0.133120077 seconds. Throughput is 480.76895 records/second. Loss is 0.08426626. Sequential2290a28's hyper parameters: Current learning rate is 0.0112943302462164. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 3856][Wall Clock 485.971742223s] Trained 64 records in 0.106149012 seconds. Throughput is 602.926 records/second. Loss is 0.14913414. Sequential2290a28's hyper parameters: Current learning rate is 0.011293054771315642. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6720/60000][Iteration 3857][Wall Clock 486.109658558s] Trained 64 records in 0.137916335 seconds. Throughput is 464.04944 records/second. Loss is 0.2445375. Sequential2290a28's hyper parameters: Current learning rate is 0.011291779584462511. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 6784/60000][Iteration 3858][Wall Clock 486.300360391s] Trained 64 records in 0.190701833 seconds. Throughput is 335.60245 records/second. Loss is 0.16290739. Sequential2290a28's hyper parameters: Current learning rate is 0.011290504685559444. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 6848/60000][Iteration 3859][Wall Clock 486.41539115s] Trained 64 records in 0.115030759 seconds. Throughput is 556.3729 records/second. Loss is 0.16541134. Sequential2290a28's hyper parameters: Current learning rate is 0.011289230074508919. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 3860][Wall Clock 486.550950731s] Trained 64 records in 0.135559581 seconds. Throughput is 472.11716 records/second. Loss is 0.14710149. Sequential2290a28's hyper parameters: Current learning rate is 0.011287955751213455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 6976/60000][Iteration 3861][Wall Clock 486.680617888s] Trained 64 records in 0.129667157 seconds. Throughput is 493.57138 records/second. Loss is 0.09742296. Sequential2290a28's hyper parameters: Current learning rate is 0.011286681715575621. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 7040/60000][Iteration 3862][Wall Clock 486.818242949s] Trained 64 records in 0.137625061 seconds. Throughput is 465.03156 records/second. Loss is 0.08545094. Sequential2290a28's hyper parameters: Current learning rate is 0.011285407967498025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 7104/60000][Iteration 3863][Wall Clock 486.930788671s] Trained 64 records in 0.112545722 seconds. Throughput is 568.6578 records/second. Loss is 0.08731923. Sequential2290a28's hyper parameters: Current learning rate is 0.011284134506883321. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 3864][Wall Clock 487.074578672s] Trained 64 records in 0.143790001 seconds. Throughput is 445.0935 records/second. Loss is 0.17154801. Sequential2290a28's hyper parameters: Current learning rate is 0.011282861333634209. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 7232/60000][Iteration 3865][Wall Clock 487.202754581s] Trained 64 records in 0.128175909 seconds. Throughput is 499.31378 records/second. Loss is 0.17258519. Sequential2290a28's hyper parameters: Current learning rate is 0.011281588447653429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 7296/60000][Iteration 3866][Wall Clock 487.31407549s] Trained 64 records in 0.111320909 seconds. Throughput is 574.9145 records/second. Loss is 0.14387675. Sequential2290a28's hyper parameters: Current learning rate is 0.011280315848843767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 7360/60000][Iteration 3867][Wall Clock 487.434926637s] Trained 64 records in 0.120851147 seconds. Throughput is 529.5771 records/second. Loss is 0.105454184. Sequential2290a28's hyper parameters: Current learning rate is 0.011279043537108053. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 3868][Wall Clock 487.626868394s] Trained 64 records in 0.191941757 seconds. Throughput is 333.43448 records/second. Loss is 0.27834255. Sequential2290a28's hyper parameters: Current learning rate is 0.01127777151234916. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 7488/60000][Iteration 3869][Wall Clock 487.888792869s] Trained 64 records in 0.261924475 seconds. Throughput is 244.34525 records/second. Loss is 0.13740212. Sequential2290a28's hyper parameters: Current learning rate is 0.011276499774470004. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 7552/60000][Iteration 3870][Wall Clock 488.074212877s] Trained 64 records in 0.185420008 seconds. Throughput is 345.16232 records/second. Loss is 0.19007933. Sequential2290a28's hyper parameters: Current learning rate is 0.011275228323373548. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 7616/60000][Iteration 3871][Wall Clock 488.259546457s] Trained 64 records in 0.18533358 seconds. Throughput is 345.32327 records/second. Loss is 0.14645655. Sequential2290a28's hyper parameters: Current learning rate is 0.011273957158962795. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 3872][Wall Clock 488.381752257s] Trained 64 records in 0.1222058 seconds. Throughput is 523.7067 records/second. Loss is 0.10631242. Sequential2290a28's hyper parameters: Current learning rate is 0.011272686281140797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 7744/60000][Iteration 3873][Wall Clock 488.515161565s] Trained 64 records in 0.133409308 seconds. Throughput is 479.72665 records/second. Loss is 0.092134304. Sequential2290a28's hyper parameters: Current learning rate is 0.01127141568981064. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 7808/60000][Iteration 3874][Wall Clock 488.624335308s] Trained 64 records in 0.109173743 seconds. Throughput is 586.22156 records/second. Loss is 0.3201438. Sequential2290a28's hyper parameters: Current learning rate is 0.011270145384875465. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 7872/60000][Iteration 3875][Wall Clock 488.760811305s] Trained 64 records in 0.136475997 seconds. Throughput is 468.94693 records/second. Loss is 0.122822896. Sequential2290a28's hyper parameters: Current learning rate is 0.01126887536623845. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 3876][Wall Clock 488.972794597s] Trained 64 records in 0.211983292 seconds. Throughput is 301.91058 records/second. Loss is 0.18347213. Sequential2290a28's hyper parameters: Current learning rate is 0.011267605633802818. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 8000/60000][Iteration 3877][Wall Clock 489.122641867s] Trained 64 records in 0.14984727 seconds. Throughput is 427.10153 records/second. Loss is 0.15782648. Sequential2290a28's hyper parameters: Current learning rate is 0.011266336187471835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8064/60000][Iteration 3878][Wall Clock 489.330399764s] Trained 64 records in 0.207757897 seconds. Throughput is 308.05087 records/second. Loss is 0.1813918. Sequential2290a28's hyper parameters: Current learning rate is 0.011265067027148811. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8128/60000][Iteration 3879][Wall Clock 489.461482513s] Trained 64 records in 0.131082749 seconds. Throughput is 488.24124 records/second. Loss is 0.10537069. Sequential2290a28's hyper parameters: Current learning rate is 0.011263798152737103. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 3880][Wall Clock 489.643610919s] Trained 64 records in 0.182128406 seconds. Throughput is 351.40045 records/second. Loss is 0.069123626. Sequential2290a28's hyper parameters: Current learning rate is 0.011262529564140106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8256/60000][Iteration 3881][Wall Clock 489.806675458s] Trained 64 records in 0.163064539 seconds. Throughput is 392.48264 records/second. Loss is 0.078329414. Sequential2290a28's hyper parameters: Current learning rate is 0.01126126126126126. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8320/60000][Iteration 3882][Wall Clock 489.972141624s] Trained 64 records in 0.165466166 seconds. Throughput is 386.78604 records/second. Loss is 0.07818647. Sequential2290a28's hyper parameters: Current learning rate is 0.011259993244004054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8384/60000][Iteration 3883][Wall Clock 490.074345197s] Trained 64 records in 0.102203573 seconds. Throughput is 626.20123 records/second. Loss is 0.13519122. Sequential2290a28's hyper parameters: Current learning rate is 0.01125872551227201. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 3884][Wall Clock 490.178677804s] Trained 64 records in 0.104332607 seconds. Throughput is 613.42285 records/second. Loss is 0.07976312. Sequential2290a28's hyper parameters: Current learning rate is 0.011257458065968704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 8512/60000][Iteration 3885][Wall Clock 490.256356724s] Trained 64 records in 0.07767892 seconds. Throughput is 823.90436 records/second. Loss is 0.3139422. Sequential2290a28's hyper parameters: Current learning rate is 0.011256190904997748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8576/60000][Iteration 3886][Wall Clock 490.33209798s] Trained 64 records in 0.075741256 seconds. Throughput is 844.98206 records/second. Loss is 0.20382985. Sequential2290a28's hyper parameters: Current learning rate is 0.011254924029262802. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8640/60000][Iteration 3887][Wall Clock 490.43778492s] Trained 64 records in 0.10568694 seconds. Throughput is 605.5621 records/second. Loss is 0.115116745. Sequential2290a28's hyper parameters: Current learning rate is 0.011253657438667566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 3888][Wall Clock 490.550512491s] Trained 64 records in 0.112727571 seconds. Throughput is 567.7405 records/second. Loss is 0.1880319. Sequential2290a28's hyper parameters: Current learning rate is 0.011252391133115786. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8768/60000][Iteration 3889][Wall Clock 490.651373801s] Trained 64 records in 0.10086131 seconds. Throughput is 634.53467 records/second. Loss is 0.112046294. Sequential2290a28's hyper parameters: Current learning rate is 0.011251125112511251. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8832/60000][Iteration 3890][Wall Clock 490.722446802s] Trained 64 records in 0.071073001 seconds. Throughput is 900.48254 records/second. Loss is 0.12711394. Sequential2290a28's hyper parameters: Current learning rate is 0.01124985937675779. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8896/60000][Iteration 3891][Wall Clock 490.94137266s] Trained 64 records in 0.218925858 seconds. Throughput is 292.3364 records/second. Loss is 0.21032421. Sequential2290a28's hyper parameters: Current learning rate is 0.01124859392575928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 3892][Wall Clock 491.109594294s] Trained 64 records in 0.168221634 seconds. Throughput is 380.45047 records/second. Loss is 0.2283044. Sequential2290a28's hyper parameters: Current learning rate is 0.011247328759419637. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 9024/60000][Iteration 3893][Wall Clock 491.317184525s] Trained 64 records in 0.207590231 seconds. Throughput is 308.29965 records/second. Loss is 0.08587083. Sequential2290a28's hyper parameters: Current learning rate is 0.011246063877642825. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 9088/60000][Iteration 3894][Wall Clock 491.52123956s] Trained 64 records in 0.204055035 seconds. Throughput is 313.64087 records/second. Loss is 0.09966187. Sequential2290a28's hyper parameters: Current learning rate is 0.011244799280332847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 9152/60000][Iteration 3895][Wall Clock 491.674450839s] Trained 64 records in 0.153211279 seconds. Throughput is 417.72382 records/second. Loss is 0.2433712. Sequential2290a28's hyper parameters: Current learning rate is 0.01124353496739375. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 3896][Wall Clock 491.878171674s] Trained 64 records in 0.203720835 seconds. Throughput is 314.1554 records/second. Loss is 0.11786102. Sequential2290a28's hyper parameters: Current learning rate is 0.011242270938729624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 9280/60000][Iteration 3897][Wall Clock 492.097187539s] Trained 64 records in 0.219015865 seconds. Throughput is 292.21628 records/second. Loss is 0.091068506. Sequential2290a28's hyper parameters: Current learning rate is 0.011241007194244606. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 9344/60000][Iteration 3898][Wall Clock 492.229129113s] Trained 64 records in 0.131941574 seconds. Throughput is 485.0632 records/second. Loss is 0.2396178. Sequential2290a28's hyper parameters: Current learning rate is 0.011239743733842868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 9408/60000][Iteration 3899][Wall Clock 492.365104341s] Trained 64 records in 0.135975228 seconds. Throughput is 470.67398 records/second. Loss is 0.09754498. Sequential2290a28's hyper parameters: Current learning rate is 0.011238480557428635. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 3900][Wall Clock 492.510720784s] Trained 64 records in 0.145616443 seconds. Throughput is 439.5108 records/second. Loss is 0.12960255. Sequential2290a28's hyper parameters: Current learning rate is 0.011237217664906169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 9536/60000][Iteration 3901][Wall Clock 492.646892626s] Trained 64 records in 0.136171842 seconds. Throughput is 469.99435 records/second. Loss is 0.120951675. Sequential2290a28's hyper parameters: Current learning rate is 0.011235955056179775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 9600/60000][Iteration 3902][Wall Clock 492.810034572s] Trained 64 records in 0.163141946 seconds. Throughput is 392.2964 records/second. Loss is 0.058002442. Sequential2290a28's hyper parameters: Current learning rate is 0.011234692731153803. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 9664/60000][Iteration 3903][Wall Clock 492.949706941s] Trained 64 records in 0.139672369 seconds. Throughput is 458.21518 records/second. Loss is 0.17751546. Sequential2290a28's hyper parameters: Current learning rate is 0.011233430689732645. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 3904][Wall Clock 493.125564133s] Trained 64 records in 0.175857192 seconds. Throughput is 363.93167 records/second. Loss is 0.109042436. Sequential2290a28's hyper parameters: Current learning rate is 0.011232168931820734. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 9792/60000][Iteration 3905][Wall Clock 493.281038677s] Trained 64 records in 0.155474544 seconds. Throughput is 411.64294 records/second. Loss is 0.07048017. Sequential2290a28's hyper parameters: Current learning rate is 0.011230907457322551. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 9856/60000][Iteration 3906][Wall Clock 493.462914798s] Trained 64 records in 0.181876121 seconds. Throughput is 351.88785 records/second. Loss is 0.13701048. Sequential2290a28's hyper parameters: Current learning rate is 0.011229646266142616. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 9920/60000][Iteration 3907][Wall Clock 493.589053496s] Trained 64 records in 0.126138698 seconds. Throughput is 507.378 records/second. Loss is 0.06525259. Sequential2290a28's hyper parameters: Current learning rate is 0.011228385358185492. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 3908][Wall Clock 493.781193437s] Trained 64 records in 0.192139941 seconds. Throughput is 333.09058 records/second. Loss is 0.10834122. Sequential2290a28's hyper parameters: Current learning rate is 0.011227124733355787. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 10048/60000][Iteration 3909][Wall Clock 493.922908036s] Trained 64 records in 0.141714599 seconds. Throughput is 451.6119 records/second. Loss is 0.10473531. Sequential2290a28's hyper parameters: Current learning rate is 0.011225864391558149. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 10112/60000][Iteration 3910][Wall Clock 494.015867106s] Trained 64 records in 0.09295907 seconds. Throughput is 688.47504 records/second. Loss is 0.06817208. Sequential2290a28's hyper parameters: Current learning rate is 0.011224604332697272. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 10176/60000][Iteration 3911][Wall Clock 494.115427343s] Trained 64 records in 0.099560237 seconds. Throughput is 642.8269 records/second. Loss is 0.18375841. Sequential2290a28's hyper parameters: Current learning rate is 0.01122334455667789. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 3912][Wall Clock 494.22871919s] Trained 64 records in 0.113291847 seconds. Throughput is 564.91266 records/second. Loss is 0.26944157. Sequential2290a28's hyper parameters: Current learning rate is 0.011222085063404781. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10304/60000][Iteration 3913][Wall Clock 494.321261029s] Trained 64 records in 0.092541839 seconds. Throughput is 691.5791 records/second. Loss is 0.042093784. Sequential2290a28's hyper parameters: Current learning rate is 0.011220825852782765. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10368/60000][Iteration 3914][Wall Clock 494.413237807s] Trained 64 records in 0.091976778 seconds. Throughput is 695.8278 records/second. Loss is 0.25557762. Sequential2290a28's hyper parameters: Current learning rate is 0.011219566924716706. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10432/60000][Iteration 3915][Wall Clock 494.525598139s] Trained 64 records in 0.112360332 seconds. Throughput is 569.59607 records/second. Loss is 0.1919513. Sequential2290a28's hyper parameters: Current learning rate is 0.011218308279111511. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 3916][Wall Clock 494.615775116s] Trained 64 records in 0.090176977 seconds. Throughput is 709.7155 records/second. Loss is 0.17614296. Sequential2290a28's hyper parameters: Current learning rate is 0.011217049915872126. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10560/60000][Iteration 3917][Wall Clock 494.799281533s] Trained 64 records in 0.183506417 seconds. Throughput is 348.76166 records/second. Loss is 0.12091906. Sequential2290a28's hyper parameters: Current learning rate is 0.011215791834903545. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10624/60000][Iteration 3918][Wall Clock 495.004330943s] Trained 64 records in 0.20504941 seconds. Throughput is 312.1199 records/second. Loss is 0.14577875. Sequential2290a28's hyper parameters: Current learning rate is 0.0112145340361108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 10688/60000][Iteration 3919][Wall Clock 495.135173064s] Trained 64 records in 0.130842121 seconds. Throughput is 489.13913 records/second. Loss is 0.09675383. Sequential2290a28's hyper parameters: Current learning rate is 0.011213276519398968. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 3920][Wall Clock 495.346928854s] Trained 64 records in 0.21175579 seconds. Throughput is 302.23492 records/second. Loss is 0.21577823. Sequential2290a28's hyper parameters: Current learning rate is 0.011212019284673169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 10816/60000][Iteration 3921][Wall Clock 495.479874866s] Trained 64 records in 0.132946012 seconds. Throughput is 481.3984 records/second. Loss is 0.10084818. Sequential2290a28's hyper parameters: Current learning rate is 0.011210762331838564. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 10880/60000][Iteration 3922][Wall Clock 495.673111429s] Trained 64 records in 0.193236563 seconds. Throughput is 331.20026 records/second. Loss is 0.09843104. Sequential2290a28's hyper parameters: Current learning rate is 0.011209505660800359. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 10944/60000][Iteration 3923][Wall Clock 495.800219745s] Trained 64 records in 0.127108316 seconds. Throughput is 503.50757 records/second. Loss is 0.10195838. Sequential2290a28's hyper parameters: Current learning rate is 0.011208249271463798. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 3924][Wall Clock 495.902982642s] Trained 64 records in 0.102762897 seconds. Throughput is 622.79285 records/second. Loss is 0.082705386. Sequential2290a28's hyper parameters: Current learning rate is 0.011206993163734169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 11072/60000][Iteration 3925][Wall Clock 496.04447509s] Trained 64 records in 0.141492448 seconds. Throughput is 452.32098 records/second. Loss is 0.08906333. Sequential2290a28's hyper parameters: Current learning rate is 0.011205737337516808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 11136/60000][Iteration 3926][Wall Clock 496.169252034s] Trained 64 records in 0.124776944 seconds. Throughput is 512.9153 records/second. Loss is 0.08427119. Sequential2290a28's hyper parameters: Current learning rate is 0.011204481792717087. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 11200/60000][Iteration 3927][Wall Clock 496.324823201s] Trained 64 records in 0.155571167 seconds. Throughput is 411.3873 records/second. Loss is 0.097853534. Sequential2290a28's hyper parameters: Current learning rate is 0.01120322652924042. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 3928][Wall Clock 496.50204275s] Trained 64 records in 0.177219549 seconds. Throughput is 361.13397 records/second. Loss is 0.13062298. Sequential2290a28's hyper parameters: Current learning rate is 0.01120197154699227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 11328/60000][Iteration 3929][Wall Clock 496.737130953s] Trained 64 records in 0.235088203 seconds. Throughput is 272.23825 records/second. Loss is 0.16978759. Sequential2290a28's hyper parameters: Current learning rate is 0.011200716845878136. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 11392/60000][Iteration 3930][Wall Clock 497.000580852s] Trained 64 records in 0.263449899 seconds. Throughput is 242.93044 records/second. Loss is 0.123755306. Sequential2290a28's hyper parameters: Current learning rate is 0.011199462425803561. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 11456/60000][Iteration 3931][Wall Clock 497.146648802s] Trained 64 records in 0.14606795 seconds. Throughput is 438.15225 records/second. Loss is 0.09084663. Sequential2290a28's hyper parameters: Current learning rate is 0.011198208286674132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 3932][Wall Clock 497.248463558s] Trained 64 records in 0.101814756 seconds. Throughput is 628.5926 records/second. Loss is 0.30621618. Sequential2290a28's hyper parameters: Current learning rate is 0.011196954428395477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11584/60000][Iteration 3933][Wall Clock 497.320250195s] Trained 64 records in 0.071786637 seconds. Throughput is 891.5309 records/second. Loss is 0.14333034. Sequential2290a28's hyper parameters: Current learning rate is 0.011195700850873265. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11648/60000][Iteration 3934][Wall Clock 497.407325815s] Trained 64 records in 0.08707562 seconds. Throughput is 734.99335 records/second. Loss is 0.09533707. Sequential2290a28's hyper parameters: Current learning rate is 0.01119444755401321. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11712/60000][Iteration 3935][Wall Clock 497.482625107s] Trained 64 records in 0.075299292 seconds. Throughput is 849.9416 records/second. Loss is 0.1072154. Sequential2290a28's hyper parameters: Current learning rate is 0.011193194537721066. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 3936][Wall Clock 497.583227577s] Trained 64 records in 0.10060247 seconds. Throughput is 636.1673 records/second. Loss is 0.15453848. Sequential2290a28's hyper parameters: Current learning rate is 0.011191941801902631. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11840/60000][Iteration 3937][Wall Clock 497.651886917s] Trained 64 records in 0.06865934 seconds. Throughput is 932.13824 records/second. Loss is 0.22744042. Sequential2290a28's hyper parameters: Current learning rate is 0.011190689346463743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11904/60000][Iteration 3938][Wall Clock 497.78159773s] Trained 64 records in 0.129710813 seconds. Throughput is 493.4053 records/second. Loss is 0.1977965. Sequential2290a28's hyper parameters: Current learning rate is 0.011189437171310284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 11968/60000][Iteration 3939][Wall Clock 497.897979599s] Trained 64 records in 0.116381869 seconds. Throughput is 549.9138 records/second. Loss is 0.25379595. Sequential2290a28's hyper parameters: Current learning rate is 0.011188185276348177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 3940][Wall Clock 498.054081088s] Trained 64 records in 0.156101489 seconds. Throughput is 409.98965 records/second. Loss is 0.20525682. Sequential2290a28's hyper parameters: Current learning rate is 0.011186933661483387. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 12096/60000][Iteration 3941][Wall Clock 498.244119689s] Trained 64 records in 0.190038601 seconds. Throughput is 336.77368 records/second. Loss is 0.33543423. Sequential2290a28's hyper parameters: Current learning rate is 0.011185682326621925. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12160/60000][Iteration 3942][Wall Clock 498.343468693s] Trained 64 records in 0.099349004 seconds. Throughput is 644.19366 records/second. Loss is 0.100534275. Sequential2290a28's hyper parameters: Current learning rate is 0.011184431271669836. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12224/60000][Iteration 3943][Wall Clock 498.43383993s] Trained 64 records in 0.090371237 seconds. Throughput is 708.18994 records/second. Loss is 0.09955494. Sequential2290a28's hyper parameters: Current learning rate is 0.011183180496533215. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 3944][Wall Clock 498.51244953s] Trained 64 records in 0.0786096 seconds. Throughput is 814.1499 records/second. Loss is 0.07700722. Sequential2290a28's hyper parameters: Current learning rate is 0.011181930001118192. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12352/60000][Iteration 3945][Wall Clock 498.720591782s] Trained 64 records in 0.208142252 seconds. Throughput is 307.48203 records/second. Loss is 0.17321458. Sequential2290a28's hyper parameters: Current learning rate is 0.011180679785330947. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12416/60000][Iteration 3946][Wall Clock 498.824476269s] Trained 64 records in 0.103884487 seconds. Throughput is 616.06885 records/second. Loss is 0.10425738. Sequential2290a28's hyper parameters: Current learning rate is 0.011179429849077696. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12480/60000][Iteration 3947][Wall Clock 498.985883493s] Trained 64 records in 0.161407224 seconds. Throughput is 396.51263 records/second. Loss is 0.07420437. Sequential2290a28's hyper parameters: Current learning rate is 0.011178180192264698. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 3948][Wall Clock 499.13491251s] Trained 64 records in 0.149029017 seconds. Throughput is 429.44656 records/second. Loss is 0.22160277. Sequential2290a28's hyper parameters: Current learning rate is 0.011176930814798256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 12608/60000][Iteration 3949][Wall Clock 499.254070242s] Trained 64 records in 0.119157732 seconds. Throughput is 537.1032 records/second. Loss is 0.1124398. Sequential2290a28's hyper parameters: Current learning rate is 0.011175681716584712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 12672/60000][Iteration 3950][Wall Clock 499.382704366s] Trained 64 records in 0.128634124 seconds. Throughput is 497.53516 records/second. Loss is 0.13771209. Sequential2290a28's hyper parameters: Current learning rate is 0.01117443289753045. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 12736/60000][Iteration 3951][Wall Clock 499.535050242s] Trained 64 records in 0.152345876 seconds. Throughput is 420.09668 records/second. Loss is 0.13122708. Sequential2290a28's hyper parameters: Current learning rate is 0.0111731843575419. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 3952][Wall Clock 499.626142433s] Trained 64 records in 0.091092191 seconds. Throughput is 702.5849 records/second. Loss is 0.101060174. Sequential2290a28's hyper parameters: Current learning rate is 0.011171936096525528. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 12864/60000][Iteration 3953][Wall Clock 499.760445758s] Trained 64 records in 0.134303325 seconds. Throughput is 476.53323 records/second. Loss is 0.12964806. Sequential2290a28's hyper parameters: Current learning rate is 0.011170688114387846. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 12928/60000][Iteration 3954][Wall Clock 499.893427343s] Trained 64 records in 0.132981585 seconds. Throughput is 481.26965 records/second. Loss is 0.17102124. Sequential2290a28's hyper parameters: Current learning rate is 0.011169440411035408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 12992/60000][Iteration 3955][Wall Clock 499.995229718s] Trained 64 records in 0.101802375 seconds. Throughput is 628.66907 records/second. Loss is 0.21198452. Sequential2290a28's hyper parameters: Current learning rate is 0.011168192986374805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 3956][Wall Clock 500.117535153s] Trained 64 records in 0.122305435 seconds. Throughput is 523.2801 records/second. Loss is 0.11740894. Sequential2290a28's hyper parameters: Current learning rate is 0.011166945840312675. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 13120/60000][Iteration 3957][Wall Clock 500.221592721s] Trained 64 records in 0.104057568 seconds. Throughput is 615.0442 records/second. Loss is 0.1543925. Sequential2290a28's hyper parameters: Current learning rate is 0.011165698972755695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 13184/60000][Iteration 3958][Wall Clock 500.456651026s] Trained 64 records in 0.235058305 seconds. Throughput is 272.27286 records/second. Loss is 0.06387532. Sequential2290a28's hyper parameters: Current learning rate is 0.011164452383610584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 13248/60000][Iteration 3959][Wall Clock 500.610827444s] Trained 64 records in 0.154176418 seconds. Throughput is 415.1089 records/second. Loss is 0.3003478. Sequential2290a28's hyper parameters: Current learning rate is 0.011163206072784104. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 3960][Wall Clock 500.748550194s] Trained 64 records in 0.13772275 seconds. Throughput is 464.70175 records/second. Loss is 0.1534022. Sequential2290a28's hyper parameters: Current learning rate is 0.011161960040183057. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 13376/60000][Iteration 3961][Wall Clock 500.905807915s] Trained 64 records in 0.157257721 seconds. Throughput is 406.97525 records/second. Loss is 0.16123295. Sequential2290a28's hyper parameters: Current learning rate is 0.011160714285714286. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 13440/60000][Iteration 3962][Wall Clock 501.027661178s] Trained 64 records in 0.121853263 seconds. Throughput is 525.22186 records/second. Loss is 0.075592026. Sequential2290a28's hyper parameters: Current learning rate is 0.011159468809284678. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 13504/60000][Iteration 3963][Wall Clock 501.184307562s] Trained 64 records in 0.156646384 seconds. Throughput is 408.56354 records/second. Loss is 0.19185585. Sequential2290a28's hyper parameters: Current learning rate is 0.011158223610801161. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 3964][Wall Clock 501.346002571s] Trained 64 records in 0.161695009 seconds. Throughput is 395.80692 records/second. Loss is 0.41229498. Sequential2290a28's hyper parameters: Current learning rate is 0.011156978690170702. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 13632/60000][Iteration 3965][Wall Clock 501.485088017s] Trained 64 records in 0.139085446 seconds. Throughput is 460.1488 records/second. Loss is 0.113920465. Sequential2290a28's hyper parameters: Current learning rate is 0.011155734047300312. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 13696/60000][Iteration 3966][Wall Clock 501.61196427s] Trained 64 records in 0.126876253 seconds. Throughput is 504.42853 records/second. Loss is 0.05230645. Sequential2290a28's hyper parameters: Current learning rate is 0.011154489682097044. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 13760/60000][Iteration 3967][Wall Clock 501.721044116s] Trained 64 records in 0.109079846 seconds. Throughput is 586.7262 records/second. Loss is 0.1141344. Sequential2290a28's hyper parameters: Current learning rate is 0.01115324559446799. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 3968][Wall Clock 501.887359115s] Trained 64 records in 0.166314999 seconds. Throughput is 384.81195 records/second. Loss is 0.21646154. Sequential2290a28's hyper parameters: Current learning rate is 0.011152001784320286. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 13888/60000][Iteration 3969][Wall Clock 502.055183277s] Trained 64 records in 0.167824162 seconds. Throughput is 381.35153 records/second. Loss is 0.1576618. Sequential2290a28's hyper parameters: Current learning rate is 0.011150758251561105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 13952/60000][Iteration 3970][Wall Clock 502.26566871s] Trained 64 records in 0.210485433 seconds. Throughput is 304.05905 records/second. Loss is 0.058365263. Sequential2290a28's hyper parameters: Current learning rate is 0.011149514996097669. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 14016/60000][Iteration 3971][Wall Clock 502.335850866s] Trained 64 records in 0.070182156 seconds. Throughput is 911.91266 records/second. Loss is 0.17963251. Sequential2290a28's hyper parameters: Current learning rate is 0.011148272017837236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 3972][Wall Clock 502.472814305s] Trained 64 records in 0.136963439 seconds. Throughput is 467.27798 records/second. Loss is 0.22245023. Sequential2290a28's hyper parameters: Current learning rate is 0.011147029316687103. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 14144/60000][Iteration 3973][Wall Clock 502.616524755s] Trained 64 records in 0.14371045 seconds. Throughput is 445.3399 records/second. Loss is 0.104872406. Sequential2290a28's hyper parameters: Current learning rate is 0.011145786892554615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 14208/60000][Iteration 3974][Wall Clock 502.730063678s] Trained 64 records in 0.113538923 seconds. Throughput is 563.68335 records/second. Loss is 0.11058037. Sequential2290a28's hyper parameters: Current learning rate is 0.011144544745347153. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 14272/60000][Iteration 3975][Wall Clock 502.860256515s] Trained 64 records in 0.130192837 seconds. Throughput is 491.57852 records/second. Loss is 0.114602946. Sequential2290a28's hyper parameters: Current learning rate is 0.011143302874972142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 3976][Wall Clock 503.085683437s] Trained 64 records in 0.225426922 seconds. Throughput is 283.90573 records/second. Loss is 0.16741547. Sequential2290a28's hyper parameters: Current learning rate is 0.011142061281337047. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14400/60000][Iteration 3977][Wall Clock 503.278424582s] Trained 64 records in 0.192741145 seconds. Throughput is 332.05157 records/second. Loss is 0.14597109. Sequential2290a28's hyper parameters: Current learning rate is 0.011140819964349376. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14464/60000][Iteration 3978][Wall Clock 503.365325273s] Trained 64 records in 0.086900691 seconds. Throughput is 736.4729 records/second. Loss is 0.1993383. Sequential2290a28's hyper parameters: Current learning rate is 0.011139578923916676. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14528/60000][Iteration 3979][Wall Clock 503.494144547s] Trained 64 records in 0.128819274 seconds. Throughput is 496.82007 records/second. Loss is 0.10991964. Sequential2290a28's hyper parameters: Current learning rate is 0.011138338159946536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 3980][Wall Clock 503.573222577s] Trained 64 records in 0.07907803 seconds. Throughput is 809.32715 records/second. Loss is 0.09215587. Sequential2290a28's hyper parameters: Current learning rate is 0.011137097672346587. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14656/60000][Iteration 3981][Wall Clock 503.670347624s] Trained 64 records in 0.097125047 seconds. Throughput is 658.94434 records/second. Loss is 0.057025097. Sequential2290a28's hyper parameters: Current learning rate is 0.011135857461024499. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14720/60000][Iteration 3982][Wall Clock 503.873203049s] Trained 64 records in 0.202855425 seconds. Throughput is 315.49564 records/second. Loss is 0.27350116. Sequential2290a28's hyper parameters: Current learning rate is 0.011134617525887985. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14784/60000][Iteration 3983][Wall Clock 503.970657984s] Trained 64 records in 0.097454935 seconds. Throughput is 656.7138 records/second. Loss is 0.1502566. Sequential2290a28's hyper parameters: Current learning rate is 0.0111333778668448. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 3984][Wall Clock 504.077919871s] Trained 64 records in 0.107261887 seconds. Throughput is 596.6705 records/second. Loss is 0.24441528. Sequential2290a28's hyper parameters: Current learning rate is 0.011132138483802737. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 14912/60000][Iteration 3985][Wall Clock 504.249790536s] Trained 64 records in 0.171870665 seconds. Throughput is 372.37302 records/second. Loss is 0.2563653. Sequential2290a28's hyper parameters: Current learning rate is 0.011130899376669634. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 14976/60000][Iteration 3986][Wall Clock 504.351998031s] Trained 64 records in 0.102207495 seconds. Throughput is 626.1772 records/second. Loss is 0.22448966. Sequential2290a28's hyper parameters: Current learning rate is 0.011129660545353366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15040/60000][Iteration 3987][Wall Clock 504.43107955s] Trained 64 records in 0.079081519 seconds. Throughput is 809.29144 records/second. Loss is 0.10249693. Sequential2290a28's hyper parameters: Current learning rate is 0.011128421989761852. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 3988][Wall Clock 504.511114985s] Trained 64 records in 0.080035435 seconds. Throughput is 799.6458 records/second. Loss is 0.18140003. Sequential2290a28's hyper parameters: Current learning rate is 0.011127183709803048. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15168/60000][Iteration 3989][Wall Clock 504.616337277s] Trained 64 records in 0.105222292 seconds. Throughput is 608.23615 records/second. Loss is 0.15499546. Sequential2290a28's hyper parameters: Current learning rate is 0.011125945705384957. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15232/60000][Iteration 3990][Wall Clock 504.726246761s] Trained 64 records in 0.109909484 seconds. Throughput is 582.29736 records/second. Loss is 0.18104118. Sequential2290a28's hyper parameters: Current learning rate is 0.01112470797641562. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15296/60000][Iteration 3991][Wall Clock 504.815557302s] Trained 64 records in 0.089310541 seconds. Throughput is 716.6007 records/second. Loss is 0.18355186. Sequential2290a28's hyper parameters: Current learning rate is 0.011123470522803115. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 3992][Wall Clock 504.950801374s] Trained 64 records in 0.135244072 seconds. Throughput is 473.21854 records/second. Loss is 0.13904232. Sequential2290a28's hyper parameters: Current learning rate is 0.011122233344455567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 15424/60000][Iteration 3993][Wall Clock 505.130539591s] Trained 64 records in 0.179738217 seconds. Throughput is 356.0734 records/second. Loss is 0.112636074. Sequential2290a28's hyper parameters: Current learning rate is 0.01112099644128114. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15488/60000][Iteration 3994][Wall Clock 505.307292927s] Trained 64 records in 0.176753336 seconds. Throughput is 362.08652 records/second. Loss is 0.15473628. Sequential2290a28's hyper parameters: Current learning rate is 0.011119759813188036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15552/60000][Iteration 3995][Wall Clock 505.456852521s] Trained 64 records in 0.149559594 seconds. Throughput is 427.9231 records/second. Loss is 0.06288419. Sequential2290a28's hyper parameters: Current learning rate is 0.011118523460084502. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 3996][Wall Clock 505.58587797s] Trained 64 records in 0.129025449 seconds. Throughput is 496.02618 records/second. Loss is 0.20031416. Sequential2290a28's hyper parameters: Current learning rate is 0.011117287381878822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15680/60000][Iteration 3997][Wall Clock 505.670938785s] Trained 64 records in 0.085060815 seconds. Throughput is 752.4029 records/second. Loss is 0.1155853. Sequential2290a28's hyper parameters: Current learning rate is 0.011116051578479325. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15744/60000][Iteration 3998][Wall Clock 505.756018561s] Trained 64 records in 0.085079776 seconds. Throughput is 752.23517 records/second. Loss is 0.20697613. Sequential2290a28's hyper parameters: Current learning rate is 0.011114816049794377. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15808/60000][Iteration 3999][Wall Clock 505.875718187s] Trained 64 records in 0.119699626 seconds. Throughput is 534.6717 records/second. Loss is 0.12307306. Sequential2290a28's hyper parameters: Current learning rate is 0.011113580795732384. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 4000][Wall Clock 505.959568153s] Trained 64 records in 0.083849966 seconds. Throughput is 763.26807 records/second. Loss is 0.10700246. Sequential2290a28's hyper parameters: Current learning rate is 0.0111123458162018. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 15936/60000][Iteration 4001][Wall Clock 506.045433792s] Trained 64 records in 0.085865639 seconds. Throughput is 745.3505 records/second. Loss is 0.08641545. Sequential2290a28's hyper parameters: Current learning rate is 0.011111111111111112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 16000/60000][Iteration 4002][Wall Clock 506.148909277s] Trained 64 records in 0.103475485 seconds. Throughput is 618.50397 records/second. Loss is 0.21572743. Sequential2290a28's hyper parameters: Current learning rate is 0.011109876680368847. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16064/60000][Iteration 4003][Wall Clock 506.24330177s] Trained 64 records in 0.094392493 seconds. Throughput is 678.02 records/second. Loss is 0.18890552. Sequential2290a28's hyper parameters: Current learning rate is 0.011108642523883583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 4004][Wall Clock 506.339708611s] Trained 64 records in 0.096406841 seconds. Throughput is 663.85333 records/second. Loss is 0.23058833. Sequential2290a28's hyper parameters: Current learning rate is 0.011107408641563923. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16192/60000][Iteration 4005][Wall Clock 506.457816456s] Trained 64 records in 0.118107845 seconds. Throughput is 541.8776 records/second. Loss is 0.13587983. Sequential2290a28's hyper parameters: Current learning rate is 0.011106175033318524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16256/60000][Iteration 4006][Wall Clock 506.574533729s] Trained 64 records in 0.116717273 seconds. Throughput is 548.33356 records/second. Loss is 0.060276166. Sequential2290a28's hyper parameters: Current learning rate is 0.011104941699056079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16320/60000][Iteration 4007][Wall Clock 506.731773529s] Trained 64 records in 0.1572398 seconds. Throughput is 407.02164 records/second. Loss is 0.11876163. Sequential2290a28's hyper parameters: Current learning rate is 0.01110370863868532. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 4008][Wall Clock 506.942445988s] Trained 64 records in 0.210672459 seconds. Throughput is 303.78912 records/second. Loss is 0.09009383. Sequential2290a28's hyper parameters: Current learning rate is 0.011102475852115021. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:09 INFO  DistriOptimizer$:408 - [Epoch 5 16448/60000][Iteration 4009][Wall Clock 507.064774805s] Trained 64 records in 0.122328817 seconds. Throughput is 523.18005 records/second. Loss is 0.10538362. Sequential2290a28's hyper parameters: Current learning rate is 0.011101243339253997. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16512/60000][Iteration 4010][Wall Clock 507.306757453s] Trained 64 records in 0.241982648 seconds. Throughput is 264.48178 records/second. Loss is 0.16324055. Sequential2290a28's hyper parameters: Current learning rate is 0.0111000111000111. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16576/60000][Iteration 4011][Wall Clock 507.427002683s] Trained 64 records in 0.12024523 seconds. Throughput is 532.2456 records/second. Loss is 0.07766065. Sequential2290a28's hyper parameters: Current learning rate is 0.011098779134295227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 4012][Wall Clock 507.562414855s] Trained 64 records in 0.135412172 seconds. Throughput is 472.63107 records/second. Loss is 0.2921586. Sequential2290a28's hyper parameters: Current learning rate is 0.011097547442015314. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16704/60000][Iteration 4013][Wall Clock 507.678198916s] Trained 64 records in 0.115784061 seconds. Throughput is 552.7531 records/second. Loss is 0.15242802. Sequential2290a28's hyper parameters: Current learning rate is 0.011096316023080338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16768/60000][Iteration 4014][Wall Clock 507.835197828s] Trained 64 records in 0.156998912 seconds. Throughput is 407.64612 records/second. Loss is 0.15300909. Sequential2290a28's hyper parameters: Current learning rate is 0.011095084877399313. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16832/60000][Iteration 4015][Wall Clock 507.973650204s] Trained 64 records in 0.138452376 seconds. Throughput is 462.2528 records/second. Loss is 0.07700703. Sequential2290a28's hyper parameters: Current learning rate is 0.011093854004881297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 4016][Wall Clock 508.091250883s] Trained 64 records in 0.117600679 seconds. Throughput is 544.21454 records/second. Loss is 0.12566142. Sequential2290a28's hyper parameters: Current learning rate is 0.011092623405435386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:10 INFO  DistriOptimizer$:408 - [Epoch 5 16960/60000][Iteration 4017][Wall Clock 508.218696041s] Trained 64 records in 0.127445158 seconds. Throughput is 502.1768 records/second. Loss is 0.215855. Sequential2290a28's hyper parameters: Current learning rate is 0.01109139307897072. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:11 INFO  DistriOptimizer$:408 - [Epoch 5 17024/60000][Iteration 4018][Wall Clock 508.354033823s] Trained 64 records in 0.135337782 seconds. Throughput is 472.89084 records/second. Loss is 0.104435645. Sequential2290a28's hyper parameters: Current learning rate is 0.011090163025396475. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:11 INFO  DistriOptimizer$:408 - [Epoch 5 17088/60000][Iteration 4019][Wall Clock 508.535682627s] Trained 64 records in 0.181648804 seconds. Throughput is 352.32822 records/second. Loss is 0.091157906. Sequential2290a28's hyper parameters: Current learning rate is 0.011088933244621867. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:11 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 4020][Wall Clock 508.697249152s] Trained 64 records in 0.161566525 seconds. Throughput is 396.12164 records/second. Loss is 0.15796193. Sequential2290a28's hyper parameters: Current learning rate is 0.011087703736556159. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:11 INFO  DistriOptimizer$:408 - [Epoch 5 17216/60000][Iteration 4021][Wall Clock 508.847326193s] Trained 64 records in 0.150077041 seconds. Throughput is 426.44763 records/second. Loss is 0.08358149. Sequential2290a28's hyper parameters: Current learning rate is 0.011086474501108647. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:11 INFO  DistriOptimizer$:408 - [Epoch 5 17280/60000][Iteration 4022][Wall Clock 508.997412724s] Trained 64 records in 0.150086531 seconds. Throughput is 426.42065 records/second. Loss is 0.04716303. Sequential2290a28's hyper parameters: Current learning rate is 0.011085245538188671. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:11 INFO  DistriOptimizer$:408 - [Epoch 5 17344/60000][Iteration 4023][Wall Clock 509.164560499s] Trained 64 records in 0.167147775 seconds. Throughput is 382.8947 records/second. Loss is 0.11723378. Sequential2290a28's hyper parameters: Current learning rate is 0.01108401684770561. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 4024][Wall Clock 509.299350091s] Trained 64 records in 0.134789592 seconds. Throughput is 474.81412 records/second. Loss is 0.13751644. Sequential2290a28's hyper parameters: Current learning rate is 0.011082788429568878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17472/60000][Iteration 4025][Wall Clock 509.3895579s] Trained 64 records in 0.090207809 seconds. Throughput is 709.47296 records/second. Loss is 0.064723365. Sequential2290a28's hyper parameters: Current learning rate is 0.011081560283687942. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17536/60000][Iteration 4026][Wall Clock 509.504849548s] Trained 64 records in 0.115291648 seconds. Throughput is 555.11395 records/second. Loss is 0.17383908. Sequential2290a28's hyper parameters: Current learning rate is 0.0110803324099723. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17600/60000][Iteration 4027][Wall Clock 509.633204893s] Trained 64 records in 0.128355345 seconds. Throughput is 498.6158 records/second. Loss is 0.095686994. Sequential2290a28's hyper parameters: Current learning rate is 0.011079104808331486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 4028][Wall Clock 509.769771091s] Trained 64 records in 0.136566198 seconds. Throughput is 468.6372 records/second. Loss is 0.14862278. Sequential2290a28's hyper parameters: Current learning rate is 0.011077877478675086. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17728/60000][Iteration 4029][Wall Clock 509.850311765s] Trained 64 records in 0.080540674 seconds. Throughput is 794.6296 records/second. Loss is 0.1873011. Sequential2290a28's hyper parameters: Current learning rate is 0.011076650420912715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17792/60000][Iteration 4030][Wall Clock 509.932107437s] Trained 64 records in 0.081795672 seconds. Throughput is 782.4375 records/second. Loss is 0.12388782. Sequential2290a28's hyper parameters: Current learning rate is 0.011075423634954036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17856/60000][Iteration 4031][Wall Clock 510.042562844s] Trained 64 records in 0.110455407 seconds. Throughput is 579.4193 records/second. Loss is 0.111122794. Sequential2290a28's hyper parameters: Current learning rate is 0.011074197120708748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:12 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 4032][Wall Clock 510.161497757s] Trained 64 records in 0.118934913 seconds. Throughput is 538.10944 records/second. Loss is 0.118764676. Sequential2290a28's hyper parameters: Current learning rate is 0.011072970878086591. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 17984/60000][Iteration 4033][Wall Clock 510.300310326s] Trained 64 records in 0.138812569 seconds. Throughput is 461.05334 records/second. Loss is 0.097921975. Sequential2290a28's hyper parameters: Current learning rate is 0.011071744906997343. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18048/60000][Iteration 4034][Wall Clock 510.429881764s] Trained 64 records in 0.129571438 seconds. Throughput is 493.936 records/second. Loss is 0.12417469. Sequential2290a28's hyper parameters: Current learning rate is 0.011070519207350825. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18112/60000][Iteration 4035][Wall Clock 510.53673909s] Trained 64 records in 0.106857326 seconds. Throughput is 598.92944 records/second. Loss is 0.07102936. Sequential2290a28's hyper parameters: Current learning rate is 0.011069293779056896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 4036][Wall Clock 510.713349496s] Trained 64 records in 0.176610406 seconds. Throughput is 362.37955 records/second. Loss is 0.1179745. Sequential2290a28's hyper parameters: Current learning rate is 0.011068068622025458. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18240/60000][Iteration 4037][Wall Clock 510.905103556s] Trained 64 records in 0.19175406 seconds. Throughput is 333.76086 records/second. Loss is 0.25382942. Sequential2290a28's hyper parameters: Current learning rate is 0.011066843736166445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18304/60000][Iteration 4038][Wall Clock 511.007581254s] Trained 64 records in 0.102477698 seconds. Throughput is 624.5261 records/second. Loss is 0.08951578. Sequential2290a28's hyper parameters: Current learning rate is 0.011065619121389843. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18368/60000][Iteration 4039][Wall Clock 511.098229709s] Trained 64 records in 0.090648455 seconds. Throughput is 706.0242 records/second. Loss is 0.10793078. Sequential2290a28's hyper parameters: Current learning rate is 0.011064394777605666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:13 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 4040][Wall Clock 511.174351118s] Trained 64 records in 0.076121409 seconds. Throughput is 840.76215 records/second. Loss is 0.114507034. Sequential2290a28's hyper parameters: Current learning rate is 0.011063170704723974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18496/60000][Iteration 4041][Wall Clock 511.250983233s] Trained 64 records in 0.076632115 seconds. Throughput is 835.159 records/second. Loss is 0.11555806. Sequential2290a28's hyper parameters: Current learning rate is 0.011061946902654867. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18560/60000][Iteration 4042][Wall Clock 511.344564915s] Trained 64 records in 0.093581682 seconds. Throughput is 683.89453 records/second. Loss is 0.16873594. Sequential2290a28's hyper parameters: Current learning rate is 0.011060723371308484. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18624/60000][Iteration 4043][Wall Clock 511.47029383s] Trained 64 records in 0.125728915 seconds. Throughput is 509.03165 records/second. Loss is 0.09440527. Sequential2290a28's hyper parameters: Current learning rate is 0.011059500110595002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 4044][Wall Clock 511.577671299s] Trained 64 records in 0.107377469 seconds. Throughput is 596.0282 records/second. Loss is 0.103217095. Sequential2290a28's hyper parameters: Current learning rate is 0.011058277120424637. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18752/60000][Iteration 4045][Wall Clock 511.721699442s] Trained 64 records in 0.144028143 seconds. Throughput is 444.3576 records/second. Loss is 0.080598846. Sequential2290a28's hyper parameters: Current learning rate is 0.011057054400707651. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18816/60000][Iteration 4046][Wall Clock 511.816910999s] Trained 64 records in 0.095211557 seconds. Throughput is 672.1873 records/second. Loss is 0.111896314. Sequential2290a28's hyper parameters: Current learning rate is 0.01105583195135434. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18880/60000][Iteration 4047][Wall Clock 511.947458057s] Trained 64 records in 0.130547058 seconds. Throughput is 490.24466 records/second. Loss is 0.10425018. Sequential2290a28's hyper parameters: Current learning rate is 0.011054609772275037. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:14 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 4048][Wall Clock 512.076750405s] Trained 64 records in 0.129292348 seconds. Throughput is 495.0022 records/second. Loss is 0.1472042. Sequential2290a28's hyper parameters: Current learning rate is 0.011053387863380126. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19008/60000][Iteration 4049][Wall Clock 512.217978419s] Trained 64 records in 0.141228014 seconds. Throughput is 453.16788 records/second. Loss is 0.20264605. Sequential2290a28's hyper parameters: Current learning rate is 0.011052166224580016. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19072/60000][Iteration 4050][Wall Clock 512.353636808s] Trained 64 records in 0.135658389 seconds. Throughput is 471.7733 records/second. Loss is 0.067677565. Sequential2290a28's hyper parameters: Current learning rate is 0.01105094485578517. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19136/60000][Iteration 4051][Wall Clock 512.442962617s] Trained 64 records in 0.089325809 seconds. Throughput is 716.4783 records/second. Loss is 0.19337478. Sequential2290a28's hyper parameters: Current learning rate is 0.011049723756906077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 4052][Wall Clock 512.536608844s] Trained 64 records in 0.093646227 seconds. Throughput is 683.42316 records/second. Loss is 0.1667234. Sequential2290a28's hyper parameters: Current learning rate is 0.011048502927853275. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19264/60000][Iteration 4053][Wall Clock 512.642688192s] Trained 64 records in 0.106079348 seconds. Throughput is 603.32196 records/second. Loss is 0.14340517. Sequential2290a28's hyper parameters: Current learning rate is 0.01104728236853734. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19328/60000][Iteration 4054][Wall Clock 512.785606835s] Trained 64 records in 0.142918643 seconds. Throughput is 447.80722 records/second. Loss is 0.14408395. Sequential2290a28's hyper parameters: Current learning rate is 0.011046062078868884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19392/60000][Iteration 4055][Wall Clock 512.956802666s] Trained 64 records in 0.171195831 seconds. Throughput is 373.84088 records/second. Loss is 0.2019289. Sequential2290a28's hyper parameters: Current learning rate is 0.01104484205875856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:15 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 4056][Wall Clock 513.094313571s] Trained 64 records in 0.137510905 seconds. Throughput is 465.4176 records/second. Loss is 0.17979331. Sequential2290a28's hyper parameters: Current learning rate is 0.011043622308117063. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:16 INFO  DistriOptimizer$:408 - [Epoch 5 19520/60000][Iteration 4057][Wall Clock 513.236283596s] Trained 64 records in 0.141970025 seconds. Throughput is 450.79938 records/second. Loss is 0.3009397. Sequential2290a28's hyper parameters: Current learning rate is 0.011042402826855124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:16 INFO  DistriOptimizer$:408 - [Epoch 5 19584/60000][Iteration 4058][Wall Clock 513.41801795s] Trained 64 records in 0.181734354 seconds. Throughput is 352.16235 records/second. Loss is 0.16984735. Sequential2290a28's hyper parameters: Current learning rate is 0.011041183614883517. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:16 INFO  DistriOptimizer$:408 - [Epoch 5 19648/60000][Iteration 4059][Wall Clock 513.594544955s] Trained 64 records in 0.176527005 seconds. Throughput is 362.55075 records/second. Loss is 0.2207812. Sequential2290a28's hyper parameters: Current learning rate is 0.01103996467211305. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:16 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 4060][Wall Clock 513.754534361s] Trained 64 records in 0.159989406 seconds. Throughput is 400.0265 records/second. Loss is 0.14535709. Sequential2290a28's hyper parameters: Current learning rate is 0.011038745998454575. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:16 INFO  DistriOptimizer$:408 - [Epoch 5 19776/60000][Iteration 4061][Wall Clock 513.923257422s] Trained 64 records in 0.168723061 seconds. Throughput is 379.31982 records/second. Loss is 0.13765027. Sequential2290a28's hyper parameters: Current learning rate is 0.011037527593818984. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:16 INFO  DistriOptimizer$:408 - [Epoch 5 19840/60000][Iteration 4062][Wall Clock 514.062268429s] Trained 64 records in 0.139011007 seconds. Throughput is 460.39517 records/second. Loss is 0.29124078. Sequential2290a28's hyper parameters: Current learning rate is 0.011036309458117205. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 19904/60000][Iteration 4063][Wall Clock 514.209945215s] Trained 64 records in 0.147676786 seconds. Throughput is 433.3789 records/second. Loss is 0.1444323. Sequential2290a28's hyper parameters: Current learning rate is 0.011035091591260208. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 4064][Wall Clock 514.323596131s] Trained 64 records in 0.113650916 seconds. Throughput is 563.12787 records/second. Loss is 0.14357714. Sequential2290a28's hyper parameters: Current learning rate is 0.011033873993158999. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20032/60000][Iteration 4065][Wall Clock 514.438906387s] Trained 64 records in 0.115310256 seconds. Throughput is 555.02435 records/second. Loss is 0.23689486. Sequential2290a28's hyper parameters: Current learning rate is 0.011032656663724624. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20096/60000][Iteration 4066][Wall Clock 514.575925385s] Trained 64 records in 0.137018998 seconds. Throughput is 467.08853 records/second. Loss is 0.21853873. Sequential2290a28's hyper parameters: Current learning rate is 0.011031439602868174. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20160/60000][Iteration 4067][Wall Clock 514.739945926s] Trained 64 records in 0.164020541 seconds. Throughput is 390.19504 records/second. Loss is 0.084005795. Sequential2290a28's hyper parameters: Current learning rate is 0.011030222810500772. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 4068][Wall Clock 514.915129045s] Trained 64 records in 0.175183119 seconds. Throughput is 365.332 records/second. Loss is 0.058861718. Sequential2290a28's hyper parameters: Current learning rate is 0.011029006286533583. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20288/60000][Iteration 4069][Wall Clock 514.990829047s] Trained 64 records in 0.075700002 seconds. Throughput is 845.44257 records/second. Loss is 0.090191305. Sequential2290a28's hyper parameters: Current learning rate is 0.011027790030877812. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20352/60000][Iteration 4070][Wall Clock 515.076544218s] Trained 64 records in 0.085715171 seconds. Throughput is 746.65894 records/second. Loss is 0.1701408. Sequential2290a28's hyper parameters: Current learning rate is 0.011026574043444702. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:17 INFO  DistriOptimizer$:408 - [Epoch 5 20416/60000][Iteration 4071][Wall Clock 515.157931424s] Trained 64 records in 0.081387206 seconds. Throughput is 786.3644 records/second. Loss is 0.11528226. Sequential2290a28's hyper parameters: Current learning rate is 0.011025358324145534. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 4072][Wall Clock 515.314266636s] Trained 64 records in 0.156335212 seconds. Throughput is 409.37677 records/second. Loss is 0.13362944. Sequential2290a28's hyper parameters: Current learning rate is 0.011024142872891633. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20544/60000][Iteration 4073][Wall Clock 515.395261407s] Trained 64 records in 0.080994771 seconds. Throughput is 790.1745 records/second. Loss is 0.15782158. Sequential2290a28's hyper parameters: Current learning rate is 0.011022927689594356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20608/60000][Iteration 4074][Wall Clock 515.475471257s] Trained 64 records in 0.08020985 seconds. Throughput is 797.907 records/second. Loss is 0.17081158. Sequential2290a28's hyper parameters: Current learning rate is 0.011021712774165105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20672/60000][Iteration 4075][Wall Clock 515.560304053s] Trained 64 records in 0.084832796 seconds. Throughput is 754.42523 records/second. Loss is 0.097613655. Sequential2290a28's hyper parameters: Current learning rate is 0.01102049812651532. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 4076][Wall Clock 515.641479713s] Trained 64 records in 0.08117566 seconds. Throughput is 788.41364 records/second. Loss is 0.057984553. Sequential2290a28's hyper parameters: Current learning rate is 0.011019283746556474. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20800/60000][Iteration 4077][Wall Clock 515.717368083s] Trained 64 records in 0.07588837 seconds. Throughput is 843.34393 records/second. Loss is 0.13886833. Sequential2290a28's hyper parameters: Current learning rate is 0.011018069634200088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20864/60000][Iteration 4078][Wall Clock 515.852148061s] Trained 64 records in 0.134779978 seconds. Throughput is 474.848 records/second. Loss is 0.40371627. Sequential2290a28's hyper parameters: Current learning rate is 0.011016855789357719. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20928/60000][Iteration 4079][Wall Clock 515.961810133s] Trained 64 records in 0.109662072 seconds. Throughput is 583.6111 records/second. Loss is 0.09117879. Sequential2290a28's hyper parameters: Current learning rate is 0.011015642211940957. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:18 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 4080][Wall Clock 516.105947146s] Trained 64 records in 0.144137013 seconds. Throughput is 444.02197 records/second. Loss is 0.20167224. Sequential2290a28's hyper parameters: Current learning rate is 0.011014428901861438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:19 INFO  DistriOptimizer$:408 - [Epoch 5 21056/60000][Iteration 4081][Wall Clock 516.22270885s] Trained 64 records in 0.116761704 seconds. Throughput is 548.12494 records/second. Loss is 0.30939233. Sequential2290a28's hyper parameters: Current learning rate is 0.011013215859030838. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:19 INFO  DistriOptimizer$:408 - [Epoch 5 21120/60000][Iteration 4082][Wall Clock 516.369710952s] Trained 64 records in 0.147002102 seconds. Throughput is 435.36792 records/second. Loss is 0.059827432. Sequential2290a28's hyper parameters: Current learning rate is 0.011012003083360863. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:19 INFO  DistriOptimizer$:408 - [Epoch 5 21184/60000][Iteration 4083][Wall Clock 516.513182591s] Trained 64 records in 0.143471639 seconds. Throughput is 446.08118 records/second. Loss is 0.15099864. Sequential2290a28's hyper parameters: Current learning rate is 0.011010790574763268. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:19 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 4084][Wall Clock 516.640452813s] Trained 64 records in 0.127270222 seconds. Throughput is 502.86703 records/second. Loss is 0.12321091. Sequential2290a28's hyper parameters: Current learning rate is 0.01100957833314984. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:19 INFO  DistriOptimizer$:408 - [Epoch 5 21312/60000][Iteration 4085][Wall Clock 516.802216811s] Trained 64 records in 0.161763998 seconds. Throughput is 395.6381 records/second. Loss is 0.043878004. Sequential2290a28's hyper parameters: Current learning rate is 0.011008366358432407. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:19 INFO  DistriOptimizer$:408 - [Epoch 5 21376/60000][Iteration 4086][Wall Clock 517.050549233s] Trained 64 records in 0.248332422 seconds. Throughput is 257.71906 records/second. Loss is 0.1802527. Sequential2290a28's hyper parameters: Current learning rate is 0.011007154650522839. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:20 INFO  DistriOptimizer$:408 - [Epoch 5 21440/60000][Iteration 4087][Wall Clock 517.371156754s] Trained 64 records in 0.320607521 seconds. Throughput is 199.62102 records/second. Loss is 0.15993363. Sequential2290a28's hyper parameters: Current learning rate is 0.01100594320933304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:20 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 4088][Wall Clock 517.523927935s] Trained 64 records in 0.152771181 seconds. Throughput is 418.9272 records/second. Loss is 0.100618824. Sequential2290a28's hyper parameters: Current learning rate is 0.011004732034774953. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:20 INFO  DistriOptimizer$:408 - [Epoch 5 21568/60000][Iteration 4089][Wall Clock 517.666079876s] Trained 64 records in 0.142151941 seconds. Throughput is 450.2225 records/second. Loss is 0.12639502. Sequential2290a28's hyper parameters: Current learning rate is 0.011003521126760563. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:20 INFO  DistriOptimizer$:408 - [Epoch 5 21632/60000][Iteration 4090][Wall Clock 517.773526549s] Trained 64 records in 0.107446673 seconds. Throughput is 595.64435 records/second. Loss is 0.12602729. Sequential2290a28's hyper parameters: Current learning rate is 0.011002310485201892. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:20 INFO  DistriOptimizer$:408 - [Epoch 5 21696/60000][Iteration 4091][Wall Clock 517.998618027s] Trained 64 records in 0.225091478 seconds. Throughput is 284.32886 records/second. Loss is 0.10428507. Sequential2290a28's hyper parameters: Current learning rate is 0.011001100110011002. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:20 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 4092][Wall Clock 518.128342515s] Trained 64 records in 0.129724488 seconds. Throughput is 493.35327 records/second. Loss is 0.087360695. Sequential2290a28's hyper parameters: Current learning rate is 0.010999890001099988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 21824/60000][Iteration 4093][Wall Clock 518.211116642s] Trained 64 records in 0.082774127 seconds. Throughput is 773.1885 records/second. Loss is 0.13932484. Sequential2290a28's hyper parameters: Current learning rate is 0.010998680158380994. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 21888/60000][Iteration 4094][Wall Clock 518.322274671s] Trained 64 records in 0.111158029 seconds. Throughput is 575.7569 records/second. Loss is 0.19274732. Sequential2290a28's hyper parameters: Current learning rate is 0.010997470581766195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 21952/60000][Iteration 4095][Wall Clock 518.426353485s] Trained 64 records in 0.104078814 seconds. Throughput is 614.91864 records/second. Loss is 0.24742651. Sequential2290a28's hyper parameters: Current learning rate is 0.010996261271167804. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 4096][Wall Clock 518.50480886s] Trained 64 records in 0.078455375 seconds. Throughput is 815.75037 records/second. Loss is 0.2103499. Sequential2290a28's hyper parameters: Current learning rate is 0.010995052226498077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22080/60000][Iteration 4097][Wall Clock 518.650313625s] Trained 64 records in 0.145504765 seconds. Throughput is 439.84818 records/second. Loss is 0.15631564. Sequential2290a28's hyper parameters: Current learning rate is 0.010993843447669306. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22144/60000][Iteration 4098][Wall Clock 518.727601281s] Trained 64 records in 0.077287656 seconds. Throughput is 828.07526 records/second. Loss is 0.17265424. Sequential2290a28's hyper parameters: Current learning rate is 0.010992634934593824. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22208/60000][Iteration 4099][Wall Clock 518.795972984s] Trained 64 records in 0.068371703 seconds. Throughput is 936.05975 records/second. Loss is 0.10693331. Sequential2290a28's hyper parameters: Current learning rate is 0.010991426687183998. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 4100][Wall Clock 518.888613039s] Trained 64 records in 0.092640055 seconds. Throughput is 690.8459 records/second. Loss is 0.14679909. Sequential2290a28's hyper parameters: Current learning rate is 0.010990218705352236. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22336/60000][Iteration 4101][Wall Clock 518.972969906s] Trained 64 records in 0.084356867 seconds. Throughput is 758.6816 records/second. Loss is 0.045729063. Sequential2290a28's hyper parameters: Current learning rate is 0.010989010989010988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:21 INFO  DistriOptimizer$:408 - [Epoch 5 22400/60000][Iteration 4102][Wall Clock 519.052467276s] Trained 64 records in 0.07949737 seconds. Throughput is 805.0581 records/second. Loss is 0.117477275. Sequential2290a28's hyper parameters: Current learning rate is 0.01098780353807274. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22464/60000][Iteration 4103][Wall Clock 519.202076832s] Trained 64 records in 0.149609556 seconds. Throughput is 427.78018 records/second. Loss is 0.31291917. Sequential2290a28's hyper parameters: Current learning rate is 0.010986596352450011. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 4104][Wall Clock 519.348086437s] Trained 64 records in 0.146009605 seconds. Throughput is 438.3273 records/second. Loss is 0.13747412. Sequential2290a28's hyper parameters: Current learning rate is 0.010985389432055367. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22592/60000][Iteration 4105][Wall Clock 519.473161727s] Trained 64 records in 0.12507529 seconds. Throughput is 511.69177 records/second. Loss is 0.1686319. Sequential2290a28's hyper parameters: Current learning rate is 0.010984182776801405. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22656/60000][Iteration 4106][Wall Clock 519.584791328s] Trained 64 records in 0.111629601 seconds. Throughput is 573.32465 records/second. Loss is 0.078777134. Sequential2290a28's hyper parameters: Current learning rate is 0.010982976386600767. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22720/60000][Iteration 4107][Wall Clock 519.702643789s] Trained 64 records in 0.117852461 seconds. Throughput is 543.0519 records/second. Loss is 0.15825945. Sequential2290a28's hyper parameters: Current learning rate is 0.010981770261366132. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 4108][Wall Clock 519.870069475s] Trained 64 records in 0.167425686 seconds. Throughput is 382.25912 records/second. Loss is 0.07910241. Sequential2290a28's hyper parameters: Current learning rate is 0.010980564401010211. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22848/60000][Iteration 4109][Wall Clock 519.961383847s] Trained 64 records in 0.091314372 seconds. Throughput is 700.8754 records/second. Loss is 0.1698403. Sequential2290a28's hyper parameters: Current learning rate is 0.010979358805445762. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:22 INFO  DistriOptimizer$:408 - [Epoch 5 22912/60000][Iteration 4110][Wall Clock 520.074487274s] Trained 64 records in 0.113103427 seconds. Throughput is 565.85376 records/second. Loss is 0.08234369. Sequential2290a28's hyper parameters: Current learning rate is 0.010978153474585575. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 22976/60000][Iteration 4111][Wall Clock 520.208489577s] Trained 64 records in 0.134002303 seconds. Throughput is 477.60376 records/second. Loss is 0.10009498. Sequential2290a28's hyper parameters: Current learning rate is 0.01097694840834248. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 4112][Wall Clock 520.338988304s] Trained 64 records in 0.130498727 seconds. Throughput is 490.42627 records/second. Loss is 0.13300483. Sequential2290a28's hyper parameters: Current learning rate is 0.010975743606629349. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 23104/60000][Iteration 4113][Wall Clock 520.504170065s] Trained 64 records in 0.165181761 seconds. Throughput is 387.452 records/second. Loss is 0.30461437. Sequential2290a28's hyper parameters: Current learning rate is 0.010974539069359086. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 23168/60000][Iteration 4114][Wall Clock 520.648131686s] Trained 64 records in 0.143961621 seconds. Throughput is 444.56293 records/second. Loss is 0.11690004. Sequential2290a28's hyper parameters: Current learning rate is 0.010973334796444639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 23232/60000][Iteration 4115][Wall Clock 520.771010817s] Trained 64 records in 0.122879131 seconds. Throughput is 520.83704 records/second. Loss is 0.11530605. Sequential2290a28's hyper parameters: Current learning rate is 0.010972130787798991. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 4116][Wall Clock 520.90805229s] Trained 64 records in 0.137041473 seconds. Throughput is 467.0119 records/second. Loss is 0.10351152. Sequential2290a28's hyper parameters: Current learning rate is 0.010970927043335162. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:23 INFO  DistriOptimizer$:408 - [Epoch 5 23360/60000][Iteration 4117][Wall Clock 521.052184753s] Trained 64 records in 0.144132463 seconds. Throughput is 444.03598 records/second. Loss is 0.11262953. Sequential2290a28's hyper parameters: Current learning rate is 0.010969723562966214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23424/60000][Iteration 4118][Wall Clock 521.22645528s] Trained 64 records in 0.174270527 seconds. Throughput is 367.24512 records/second. Loss is 0.2391333. Sequential2290a28's hyper parameters: Current learning rate is 0.010968520346605243. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23488/60000][Iteration 4119][Wall Clock 521.361190659s] Trained 64 records in 0.134735379 seconds. Throughput is 475.00516 records/second. Loss is 0.048260517. Sequential2290a28's hyper parameters: Current learning rate is 0.010967317394165389. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 4120][Wall Clock 521.50127643s] Trained 64 records in 0.140085771 seconds. Throughput is 456.86295 records/second. Loss is 0.13620317. Sequential2290a28's hyper parameters: Current learning rate is 0.01096611470555982. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23616/60000][Iteration 4121][Wall Clock 521.602958246s] Trained 64 records in 0.101681816 seconds. Throughput is 629.4144 records/second. Loss is 0.1832858. Sequential2290a28's hyper parameters: Current learning rate is 0.010964912280701754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23680/60000][Iteration 4122][Wall Clock 521.73893258s] Trained 64 records in 0.135974334 seconds. Throughput is 470.67706 records/second. Loss is 0.18262741. Sequential2290a28's hyper parameters: Current learning rate is 0.01096371011950444. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23744/60000][Iteration 4123][Wall Clock 521.936799099s] Trained 64 records in 0.197866519 seconds. Throughput is 323.45038 records/second. Loss is 0.1232578. Sequential2290a28's hyper parameters: Current learning rate is 0.010962508221881167. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:24 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 4124][Wall Clock 522.05454352s] Trained 64 records in 0.117744421 seconds. Throughput is 543.5502 records/second. Loss is 0.29056388. Sequential2290a28's hyper parameters: Current learning rate is 0.01096130658774526. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 23872/60000][Iteration 4125][Wall Clock 522.188199658s] Trained 64 records in 0.133656138 seconds. Throughput is 478.8407 records/second. Loss is 0.04048969. Sequential2290a28's hyper parameters: Current learning rate is 0.010960105217010083. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 23936/60000][Iteration 4126][Wall Clock 522.301820131s] Trained 64 records in 0.113620473 seconds. Throughput is 563.27875 records/second. Loss is 0.069312744. Sequential2290a28's hyper parameters: Current learning rate is 0.01095890410958904. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24000/60000][Iteration 4127][Wall Clock 522.414741064s] Trained 64 records in 0.112920933 seconds. Throughput is 566.76825 records/second. Loss is 0.12700072. Sequential2290a28's hyper parameters: Current learning rate is 0.010957703265395573. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 4128][Wall Clock 522.50567575s] Trained 64 records in 0.090934686 seconds. Throughput is 703.8018 records/second. Loss is 0.16276227. Sequential2290a28's hyper parameters: Current learning rate is 0.010956502684343157. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24128/60000][Iteration 4129][Wall Clock 522.60141492s] Trained 64 records in 0.09573917 seconds. Throughput is 668.4829 records/second. Loss is 0.12456927. Sequential2290a28's hyper parameters: Current learning rate is 0.01095530236634531. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24192/60000][Iteration 4130][Wall Clock 522.726123921s] Trained 64 records in 0.124709001 seconds. Throughput is 513.1947 records/second. Loss is 0.06576727. Sequential2290a28's hyper parameters: Current learning rate is 0.010954102311315588. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24256/60000][Iteration 4131][Wall Clock 522.834662435s] Trained 64 records in 0.108538514 seconds. Throughput is 589.6524 records/second. Loss is 0.14976493. Sequential2290a28's hyper parameters: Current learning rate is 0.01095290251916758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 4132][Wall Clock 522.929600359s] Trained 64 records in 0.094937924 seconds. Throughput is 674.12476 records/second. Loss is 0.15251625. Sequential2290a28's hyper parameters: Current learning rate is 0.010951702989814916. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24384/60000][Iteration 4133][Wall Clock 523.054224642s] Trained 64 records in 0.124624283 seconds. Throughput is 513.5436 records/second. Loss is 0.15756872. Sequential2290a28's hyper parameters: Current learning rate is 0.010950503723171266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:25 INFO  DistriOptimizer$:408 - [Epoch 5 24448/60000][Iteration 4134][Wall Clock 523.149897923s] Trained 64 records in 0.095673281 seconds. Throughput is 668.9433 records/second. Loss is 0.142939. Sequential2290a28's hyper parameters: Current learning rate is 0.010949304719150335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24512/60000][Iteration 4135][Wall Clock 523.266804174s] Trained 64 records in 0.116906251 seconds. Throughput is 547.4472 records/second. Loss is 0.23083596. Sequential2290a28's hyper parameters: Current learning rate is 0.010948105977665865. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 4136][Wall Clock 523.386514151s] Trained 64 records in 0.119709977 seconds. Throughput is 534.6254 records/second. Loss is 0.060546033. Sequential2290a28's hyper parameters: Current learning rate is 0.010946907498631636. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24640/60000][Iteration 4137][Wall Clock 523.519655109s] Trained 64 records in 0.133140958 seconds. Throughput is 480.69357 records/second. Loss is 0.1214804. Sequential2290a28's hyper parameters: Current learning rate is 0.010945709281961471. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24704/60000][Iteration 4138][Wall Clock 523.696067463s] Trained 64 records in 0.176412354 seconds. Throughput is 362.78638 records/second. Loss is 0.18322578. Sequential2290a28's hyper parameters: Current learning rate is 0.010944511327569224. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24768/60000][Iteration 4139][Wall Clock 523.776697634s] Trained 64 records in 0.080630171 seconds. Throughput is 793.74756 records/second. Loss is 0.09626641. Sequential2290a28's hyper parameters: Current learning rate is 0.01094331363536879. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 4140][Wall Clock 523.86347854s] Trained 64 records in 0.086780906 seconds. Throughput is 737.48944 records/second. Loss is 0.32164514. Sequential2290a28's hyper parameters: Current learning rate is 0.0109421162052741. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24896/60000][Iteration 4141][Wall Clock 523.995134846s] Trained 64 records in 0.131656306 seconds. Throughput is 486.1142 records/second. Loss is 0.22719392. Sequential2290a28's hyper parameters: Current learning rate is 0.010940919037199124. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:26 INFO  DistriOptimizer$:408 - [Epoch 5 24960/60000][Iteration 4142][Wall Clock 524.08598797s] Trained 64 records in 0.090853124 seconds. Throughput is 704.43365 records/second. Loss is 0.0924648. Sequential2290a28's hyper parameters: Current learning rate is 0.010939722131057872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25024/60000][Iteration 4143][Wall Clock 524.185512698s] Trained 64 records in 0.099524728 seconds. Throughput is 643.0563 records/second. Loss is 0.21033871. Sequential2290a28's hyper parameters: Current learning rate is 0.010938525486764385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 4144][Wall Clock 524.270407291s] Trained 64 records in 0.084894593 seconds. Throughput is 753.8761 records/second. Loss is 0.08245227. Sequential2290a28's hyper parameters: Current learning rate is 0.010937329104232747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25152/60000][Iteration 4145][Wall Clock 524.385115973s] Trained 64 records in 0.114708682 seconds. Throughput is 557.93506 records/second. Loss is 0.063169576. Sequential2290a28's hyper parameters: Current learning rate is 0.010936132983377077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25216/60000][Iteration 4146][Wall Clock 524.54629527s] Trained 64 records in 0.161179297 seconds. Throughput is 397.0733 records/second. Loss is 0.14448358. Sequential2290a28's hyper parameters: Current learning rate is 0.010934937124111536. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25280/60000][Iteration 4147][Wall Clock 524.663570559s] Trained 64 records in 0.117275289 seconds. Throughput is 545.7245 records/second. Loss is 0.10703009. Sequential2290a28's hyper parameters: Current learning rate is 0.010933741526350316. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 4148][Wall Clock 524.806135202s] Trained 64 records in 0.142564643 seconds. Throughput is 448.91916 records/second. Loss is 0.10134438. Sequential2290a28's hyper parameters: Current learning rate is 0.010932546190007652. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25408/60000][Iteration 4149][Wall Clock 524.969820894s] Trained 64 records in 0.163685692 seconds. Throughput is 390.99323 records/second. Loss is 0.052484076. Sequential2290a28's hyper parameters: Current learning rate is 0.010931351114997814. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:27 INFO  DistriOptimizer$:408 - [Epoch 5 25472/60000][Iteration 4150][Wall Clock 525.082724306s] Trained 64 records in 0.112903412 seconds. Throughput is 566.8562 records/second. Loss is 0.16047266. Sequential2290a28's hyper parameters: Current learning rate is 0.010930156301235108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25536/60000][Iteration 4151][Wall Clock 525.184286296s] Trained 64 records in 0.10156199 seconds. Throughput is 630.157 records/second. Loss is 0.29956156. Sequential2290a28's hyper parameters: Current learning rate is 0.01092896174863388. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 4152][Wall Clock 525.300146414s] Trained 64 records in 0.115860118 seconds. Throughput is 552.39026 records/second. Loss is 0.26201752. Sequential2290a28's hyper parameters: Current learning rate is 0.010927767457108512. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25664/60000][Iteration 4153][Wall Clock 525.379241183s] Trained 64 records in 0.079094769 seconds. Throughput is 809.15594 records/second. Loss is 0.13465995. Sequential2290a28's hyper parameters: Current learning rate is 0.010926573426573426. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25728/60000][Iteration 4154][Wall Clock 525.478473618s] Trained 64 records in 0.099232435 seconds. Throughput is 644.95044 records/second. Loss is 0.044733472. Sequential2290a28's hyper parameters: Current learning rate is 0.010925379656943079. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25792/60000][Iteration 4155][Wall Clock 525.589566911s] Trained 64 records in 0.111093293 seconds. Throughput is 576.0924 records/second. Loss is 0.11051951. Sequential2290a28's hyper parameters: Current learning rate is 0.010924186148131964. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 4156][Wall Clock 525.722775518s] Trained 64 records in 0.133208607 seconds. Throughput is 480.44946 records/second. Loss is 0.08900435. Sequential2290a28's hyper parameters: Current learning rate is 0.010922992900054615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25920/60000][Iteration 4157][Wall Clock 525.835493933s] Trained 64 records in 0.112718415 seconds. Throughput is 567.78656 records/second. Loss is 0.102975234. Sequential2290a28's hyper parameters: Current learning rate is 0.010921799912625601. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 25984/60000][Iteration 4158][Wall Clock 525.924072246s] Trained 64 records in 0.088578313 seconds. Throughput is 722.5245 records/second. Loss is 0.15415633. Sequential2290a28's hyper parameters: Current learning rate is 0.010920607185759528. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:28 INFO  DistriOptimizer$:408 - [Epoch 5 26048/60000][Iteration 4159][Wall Clock 526.067994618s] Trained 64 records in 0.143922372 seconds. Throughput is 444.68417 records/second. Loss is 0.17830446. Sequential2290a28's hyper parameters: Current learning rate is 0.010919414719371042. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 4160][Wall Clock 526.232833946s] Trained 64 records in 0.164839328 seconds. Throughput is 388.25687 records/second. Loss is 0.19728655. Sequential2290a28's hyper parameters: Current learning rate is 0.010918222513374822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26176/60000][Iteration 4161][Wall Clock 526.398583558s] Trained 64 records in 0.165749612 seconds. Throughput is 386.1246 records/second. Loss is 0.08359608. Sequential2290a28's hyper parameters: Current learning rate is 0.010917030567685589. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26240/60000][Iteration 4162][Wall Clock 526.51997242s] Trained 64 records in 0.121388862 seconds. Throughput is 527.23126 records/second. Loss is 0.19405605. Sequential2290a28's hyper parameters: Current learning rate is 0.010915838882218098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26304/60000][Iteration 4163][Wall Clock 526.666379002s] Trained 64 records in 0.146406582 seconds. Throughput is 437.13882 records/second. Loss is 0.105304696. Sequential2290a28's hyper parameters: Current learning rate is 0.010914647456887142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 4164][Wall Clock 526.813576323s] Trained 64 records in 0.147197321 seconds. Throughput is 434.79053 records/second. Loss is 0.13182351. Sequential2290a28's hyper parameters: Current learning rate is 0.010913456291607553. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26432/60000][Iteration 4165][Wall Clock 526.932655857s] Trained 64 records in 0.119079534 seconds. Throughput is 537.4559 records/second. Loss is 0.24357173. Sequential2290a28's hyper parameters: Current learning rate is 0.010912265386294195. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:29 INFO  DistriOptimizer$:408 - [Epoch 5 26496/60000][Iteration 4166][Wall Clock 527.022929457s] Trained 64 records in 0.0902736 seconds. Throughput is 708.95593 records/second. Loss is 0.18423085. Sequential2290a28's hyper parameters: Current learning rate is 0.010911074740861974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26560/60000][Iteration 4167][Wall Clock 527.152164045s] Trained 64 records in 0.129234588 seconds. Throughput is 495.22348 records/second. Loss is 0.09897418. Sequential2290a28's hyper parameters: Current learning rate is 0.010909884355225833. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 4168][Wall Clock 527.251203263s] Trained 64 records in 0.099039218 seconds. Throughput is 646.2086 records/second. Loss is 0.14920601. Sequential2290a28's hyper parameters: Current learning rate is 0.010908694229300752. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26688/60000][Iteration 4169][Wall Clock 527.326647302s] Trained 64 records in 0.075444039 seconds. Throughput is 848.31085 records/second. Loss is 0.15467897. Sequential2290a28's hyper parameters: Current learning rate is 0.010907504363001745. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26752/60000][Iteration 4170][Wall Clock 527.409096876s] Trained 64 records in 0.082449574 seconds. Throughput is 776.23206 records/second. Loss is 0.14457823. Sequential2290a28's hyper parameters: Current learning rate is 0.010906314756243865. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26816/60000][Iteration 4171][Wall Clock 527.49346815s] Trained 64 records in 0.084371274 seconds. Throughput is 758.552 records/second. Loss is 0.12678796. Sequential2290a28's hyper parameters: Current learning rate is 0.010905125408942203. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 4172][Wall Clock 527.586502549s] Trained 64 records in 0.093034399 seconds. Throughput is 687.9176 records/second. Loss is 0.116003215. Sequential2290a28's hyper parameters: Current learning rate is 0.010903936321011885. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 26944/60000][Iteration 4173][Wall Clock 527.790250389s] Trained 64 records in 0.20374784 seconds. Throughput is 314.11377 records/second. Loss is 0.1608059. Sequential2290a28's hyper parameters: Current learning rate is 0.010902747492368076. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 27008/60000][Iteration 4174][Wall Clock 527.912318377s] Trained 64 records in 0.122067988 seconds. Throughput is 524.298 records/second. Loss is 0.110103786. Sequential2290a28's hyper parameters: Current learning rate is 0.010901558922925979. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:30 INFO  DistriOptimizer$:408 - [Epoch 5 27072/60000][Iteration 4175][Wall Clock 528.02185369s] Trained 64 records in 0.109535313 seconds. Throughput is 584.28644 records/second. Loss is 0.10766956. Sequential2290a28's hyper parameters: Current learning rate is 0.010900370612600829. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 4176][Wall Clock 528.152448886s] Trained 64 records in 0.130595196 seconds. Throughput is 490.064 records/second. Loss is 0.12744108. Sequential2290a28's hyper parameters: Current learning rate is 0.010899182561307902. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27200/60000][Iteration 4177][Wall Clock 528.323244197s] Trained 64 records in 0.170795311 seconds. Throughput is 374.71756 records/second. Loss is 0.2602709. Sequential2290a28's hyper parameters: Current learning rate is 0.010897994768962511. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27264/60000][Iteration 4178][Wall Clock 528.457468002s] Trained 64 records in 0.134223805 seconds. Throughput is 476.81558 records/second. Loss is 0.20215806. Sequential2290a28's hyper parameters: Current learning rate is 0.010896807235480005. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27328/60000][Iteration 4179][Wall Clock 528.605358879s] Trained 64 records in 0.147890877 seconds. Throughput is 432.7515 records/second. Loss is 0.09186697. Sequential2290a28's hyper parameters: Current learning rate is 0.010895619960775768. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 4180][Wall Clock 528.695165082s] Trained 64 records in 0.089806203 seconds. Throughput is 712.6456 records/second. Loss is 0.16216211. Sequential2290a28's hyper parameters: Current learning rate is 0.010894432944765225. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27456/60000][Iteration 4181][Wall Clock 528.78721104s] Trained 64 records in 0.092045958 seconds. Throughput is 695.3049 records/second. Loss is 0.20694914. Sequential2290a28's hyper parameters: Current learning rate is 0.010893246187363835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27520/60000][Iteration 4182][Wall Clock 528.880492885s] Trained 64 records in 0.093281845 seconds. Throughput is 686.0928 records/second. Loss is 0.030822352. Sequential2290a28's hyper parameters: Current learning rate is 0.010892059688487093. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27584/60000][Iteration 4183][Wall Clock 528.96707862s] Trained 64 records in 0.086585735 seconds. Throughput is 739.15173 records/second. Loss is 0.16284575. Sequential2290a28's hyper parameters: Current learning rate is 0.010890873448050533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:31 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 4184][Wall Clock 529.073492714s] Trained 64 records in 0.106414094 seconds. Throughput is 601.4241 records/second. Loss is 0.33495006. Sequential2290a28's hyper parameters: Current learning rate is 0.010889687465969727. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 27712/60000][Iteration 4185][Wall Clock 529.221420651s] Trained 64 records in 0.147927937 seconds. Throughput is 432.6431 records/second. Loss is 0.06639077. Sequential2290a28's hyper parameters: Current learning rate is 0.01088850174216028. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 27776/60000][Iteration 4186][Wall Clock 529.367695602s] Trained 64 records in 0.146274951 seconds. Throughput is 437.5322 records/second. Loss is 0.22818737. Sequential2290a28's hyper parameters: Current learning rate is 0.010887316276537832. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 27840/60000][Iteration 4187][Wall Clock 529.545445405s] Trained 64 records in 0.177749803 seconds. Throughput is 360.05667 records/second. Loss is 0.17522451. Sequential2290a28's hyper parameters: Current learning rate is 0.010886131069018071. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 4188][Wall Clock 529.685664518s] Trained 64 records in 0.140219113 seconds. Throughput is 456.42853 records/second. Loss is 0.09074928. Sequential2290a28's hyper parameters: Current learning rate is 0.010884946119516709. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 27968/60000][Iteration 4189][Wall Clock 529.791761188s] Trained 64 records in 0.10609667 seconds. Throughput is 603.22345 records/second. Loss is 0.08084176. Sequential2290a28's hyper parameters: Current learning rate is 0.0108837614279495. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 28032/60000][Iteration 4190][Wall Clock 529.907789061s] Trained 64 records in 0.116027873 seconds. Throughput is 551.5916 records/second. Loss is 0.16648096. Sequential2290a28's hyper parameters: Current learning rate is 0.010882576994232234. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:32 INFO  DistriOptimizer$:408 - [Epoch 5 28096/60000][Iteration 4191][Wall Clock 530.09342401s] Trained 64 records in 0.185634949 seconds. Throughput is 344.76266 records/second. Loss is 0.13605312. Sequential2290a28's hyper parameters: Current learning rate is 0.01088139281828074. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 4192][Wall Clock 530.217695121s] Trained 64 records in 0.124271111 seconds. Throughput is 515.00305 records/second. Loss is 0.26447797. Sequential2290a28's hyper parameters: Current learning rate is 0.01088020890001088. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28224/60000][Iteration 4193][Wall Clock 530.347809804s] Trained 64 records in 0.130114683 seconds. Throughput is 491.87375 records/second. Loss is 0.109957784. Sequential2290a28's hyper parameters: Current learning rate is 0.010879025239338555. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28288/60000][Iteration 4194][Wall Clock 530.468366535s] Trained 64 records in 0.120556731 seconds. Throughput is 530.87036 records/second. Loss is 0.16817081. Sequential2290a28's hyper parameters: Current learning rate is 0.010877841836179703. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28352/60000][Iteration 4195][Wall Clock 530.572520114s] Trained 64 records in 0.104153579 seconds. Throughput is 614.4772 records/second. Loss is 0.0694742. Sequential2290a28's hyper parameters: Current learning rate is 0.010876658690450293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 4196][Wall Clock 530.65305525s] Trained 64 records in 0.080535136 seconds. Throughput is 794.6842 records/second. Loss is 0.08260436. Sequential2290a28's hyper parameters: Current learning rate is 0.010875475802066341. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28480/60000][Iteration 4197][Wall Clock 530.728259058s] Trained 64 records in 0.075203808 seconds. Throughput is 851.02075 records/second. Loss is 0.069457784. Sequential2290a28's hyper parameters: Current learning rate is 0.01087429317094389. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28544/60000][Iteration 4198][Wall Clock 530.829187327s] Trained 64 records in 0.100928269 seconds. Throughput is 634.1137 records/second. Loss is 0.06575019. Sequential2290a28's hyper parameters: Current learning rate is 0.010873110796999022. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28608/60000][Iteration 4199][Wall Clock 530.940941441s] Trained 64 records in 0.111754114 seconds. Throughput is 572.68585 records/second. Loss is 0.08536402. Sequential2290a28's hyper parameters: Current learning rate is 0.01087192868014786. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:33 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 4200][Wall Clock 531.038595464s] Trained 64 records in 0.097654023 seconds. Throughput is 655.37494 records/second. Loss is 0.1111184. Sequential2290a28's hyper parameters: Current learning rate is 0.010870746820306556. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 28736/60000][Iteration 4201][Wall Clock 531.141519211s] Trained 64 records in 0.102923747 seconds. Throughput is 621.8196 records/second. Loss is 0.10549174. Sequential2290a28's hyper parameters: Current learning rate is 0.010869565217391304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 28800/60000][Iteration 4202][Wall Clock 531.282547721s] Trained 64 records in 0.14102851 seconds. Throughput is 453.80896 records/second. Loss is 0.1577831. Sequential2290a28's hyper parameters: Current learning rate is 0.010868383871318334. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 28864/60000][Iteration 4203][Wall Clock 531.378206905s] Trained 64 records in 0.095659184 seconds. Throughput is 669.0419 records/second. Loss is 0.095779605. Sequential2290a28's hyper parameters: Current learning rate is 0.010867202782003912. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 4204][Wall Clock 531.497360397s] Trained 64 records in 0.119153492 seconds. Throughput is 537.1223 records/second. Loss is 0.15837517. Sequential2290a28's hyper parameters: Current learning rate is 0.010866021949364337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 28992/60000][Iteration 4205][Wall Clock 531.608639712s] Trained 64 records in 0.111279315 seconds. Throughput is 575.12933 records/second. Loss is 0.1941702. Sequential2290a28's hyper parameters: Current learning rate is 0.01086484137331595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 29056/60000][Iteration 4206][Wall Clock 531.723527764s] Trained 64 records in 0.114888052 seconds. Throughput is 557.064 records/second. Loss is 0.2066692. Sequential2290a28's hyper parameters: Current learning rate is 0.010863661053775122. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 29120/60000][Iteration 4207][Wall Clock 531.83496191s] Trained 64 records in 0.111434146 seconds. Throughput is 574.33026 records/second. Loss is 0.110296376. Sequential2290a28's hyper parameters: Current learning rate is 0.010862480990658266. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 4208][Wall Clock 531.937430622s] Trained 64 records in 0.102468712 seconds. Throughput is 624.5809 records/second. Loss is 0.05444528. Sequential2290a28's hyper parameters: Current learning rate is 0.010861301183881828. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:34 INFO  DistriOptimizer$:408 - [Epoch 5 29248/60000][Iteration 4209][Wall Clock 532.037989397s] Trained 64 records in 0.100558775 seconds. Throughput is 636.4437 records/second. Loss is 0.0795172. Sequential2290a28's hyper parameters: Current learning rate is 0.010860121633362294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29312/60000][Iteration 4210][Wall Clock 532.151466982s] Trained 64 records in 0.113477585 seconds. Throughput is 563.98804 records/second. Loss is 0.38331202. Sequential2290a28's hyper parameters: Current learning rate is 0.01085894233901618. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29376/60000][Iteration 4211][Wall Clock 532.263640067s] Trained 64 records in 0.112173085 seconds. Throughput is 570.5468 records/second. Loss is 0.15744597. Sequential2290a28's hyper parameters: Current learning rate is 0.010857763300760043. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 4212][Wall Clock 532.386924268s] Trained 64 records in 0.123284201 seconds. Throughput is 519.12573 records/second. Loss is 0.060639516. Sequential2290a28's hyper parameters: Current learning rate is 0.010856584518510477. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29504/60000][Iteration 4213][Wall Clock 532.487051118s] Trained 64 records in 0.10012685 seconds. Throughput is 639.1892 records/second. Loss is 0.15951973. Sequential2290a28's hyper parameters: Current learning rate is 0.010855405992184108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29568/60000][Iteration 4214][Wall Clock 532.617203997s] Trained 64 records in 0.130152879 seconds. Throughput is 491.7294 records/second. Loss is 0.14168917. Sequential2290a28's hyper parameters: Current learning rate is 0.010854227721697602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29632/60000][Iteration 4215][Wall Clock 532.765005855s] Trained 64 records in 0.147801858 seconds. Throughput is 433.01215 records/second. Loss is 0.08261987. Sequential2290a28's hyper parameters: Current learning rate is 0.010853049706967658. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:35 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 4216][Wall Clock 532.962310496s] Trained 64 records in 0.197304641 seconds. Throughput is 324.3715 records/second. Loss is 0.17352882. Sequential2290a28's hyper parameters: Current learning rate is 0.010851871947911014. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 29760/60000][Iteration 4217][Wall Clock 533.105239691s] Trained 64 records in 0.142929195 seconds. Throughput is 447.77414 records/second. Loss is 0.2837572. Sequential2290a28's hyper parameters: Current learning rate is 0.010850694444444446. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 29824/60000][Iteration 4218][Wall Clock 533.25425629s] Trained 64 records in 0.149016599 seconds. Throughput is 429.48233 records/second. Loss is 0.16597559. Sequential2290a28's hyper parameters: Current learning rate is 0.010849517196484757. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 29888/60000][Iteration 4219][Wall Clock 533.382687773s] Trained 64 records in 0.128431483 seconds. Throughput is 498.3202 records/second. Loss is 0.13970667. Sequential2290a28's hyper parameters: Current learning rate is 0.010848340203948797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 4220][Wall Clock 533.525101555s] Trained 64 records in 0.142413782 seconds. Throughput is 449.3947 records/second. Loss is 0.09979665. Sequential2290a28's hyper parameters: Current learning rate is 0.010847163466753445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 30016/60000][Iteration 4221][Wall Clock 533.62847932s] Trained 64 records in 0.103377765 seconds. Throughput is 619.0886 records/second. Loss is 0.09317899. Sequential2290a28's hyper parameters: Current learning rate is 0.010845986984815618. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 30080/60000][Iteration 4222][Wall Clock 533.760770712s] Trained 64 records in 0.132291392 seconds. Throughput is 483.78055 records/second. Loss is 0.105201155. Sequential2290a28's hyper parameters: Current learning rate is 0.010844810758052272. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 30144/60000][Iteration 4223][Wall Clock 533.856595208s] Trained 64 records in 0.095824496 seconds. Throughput is 667.8877 records/second. Loss is 0.12560073. Sequential2290a28's hyper parameters: Current learning rate is 0.010843634786380394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:36 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 4224][Wall Clock 534.000407505s] Trained 64 records in 0.143812297 seconds. Throughput is 445.02454 records/second. Loss is 0.1804263. Sequential2290a28's hyper parameters: Current learning rate is 0.010842459069717012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30272/60000][Iteration 4225][Wall Clock 534.090898536s] Trained 64 records in 0.090491031 seconds. Throughput is 707.2524 records/second. Loss is 0.14384979. Sequential2290a28's hyper parameters: Current learning rate is 0.010841283607979185. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30336/60000][Iteration 4226][Wall Clock 534.215877774s] Trained 64 records in 0.124979238 seconds. Throughput is 512.0851 records/second. Loss is 0.22897485. Sequential2290a28's hyper parameters: Current learning rate is 0.010840108401084009. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30400/60000][Iteration 4227][Wall Clock 534.331893669s] Trained 64 records in 0.116015895 seconds. Throughput is 551.64856 records/second. Loss is 0.26120812. Sequential2290a28's hyper parameters: Current learning rate is 0.010838933448948623. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 4228][Wall Clock 534.439265037s] Trained 64 records in 0.107371368 seconds. Throughput is 596.0621 records/second. Loss is 0.059371784. Sequential2290a28's hyper parameters: Current learning rate is 0.01083775875149019. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30528/60000][Iteration 4229][Wall Clock 534.544525507s] Trained 64 records in 0.10526047 seconds. Throughput is 608.0155 records/second. Loss is 0.18259346. Sequential2290a28's hyper parameters: Current learning rate is 0.01083658430862592. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30592/60000][Iteration 4230][Wall Clock 534.638133588s] Trained 64 records in 0.093608081 seconds. Throughput is 683.70166 records/second. Loss is 0.12517366. Sequential2290a28's hyper parameters: Current learning rate is 0.010835410120273052. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30656/60000][Iteration 4231][Wall Clock 534.720231145s] Trained 64 records in 0.082097557 seconds. Throughput is 779.5603 records/second. Loss is 0.18898752. Sequential2290a28's hyper parameters: Current learning rate is 0.010834236186348862. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 4232][Wall Clock 534.808588121s] Trained 64 records in 0.088356976 seconds. Throughput is 724.3344 records/second. Loss is 0.11542208. Sequential2290a28's hyper parameters: Current learning rate is 0.010833062506770665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30784/60000][Iteration 4233][Wall Clock 534.890599271s] Trained 64 records in 0.08201115 seconds. Throughput is 780.3817 records/second. Loss is 0.07926817. Sequential2290a28's hyper parameters: Current learning rate is 0.010831889081455806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30848/60000][Iteration 4234][Wall Clock 534.980059692s] Trained 64 records in 0.089460421 seconds. Throughput is 715.4002 records/second. Loss is 0.1340377. Sequential2290a28's hyper parameters: Current learning rate is 0.010830715910321672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:37 INFO  DistriOptimizer$:408 - [Epoch 5 30912/60000][Iteration 4235][Wall Clock 535.065192105s] Trained 64 records in 0.085132413 seconds. Throughput is 751.7701 records/second. Loss is 0.12637228. Sequential2290a28's hyper parameters: Current learning rate is 0.010829542993285684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 4236][Wall Clock 535.148673405s] Trained 64 records in 0.0834813 seconds. Throughput is 766.6388 records/second. Loss is 0.11606083. Sequential2290a28's hyper parameters: Current learning rate is 0.010828370330265295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31040/60000][Iteration 4237][Wall Clock 535.273654999s] Trained 64 records in 0.124981594 seconds. Throughput is 512.0754 records/second. Loss is 0.19258401. Sequential2290a28's hyper parameters: Current learning rate is 0.010827197921178. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31104/60000][Iteration 4238][Wall Clock 535.370246324s] Trained 64 records in 0.096591325 seconds. Throughput is 662.5854 records/second. Loss is 0.3122832. Sequential2290a28's hyper parameters: Current learning rate is 0.010826025765941324. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31168/60000][Iteration 4239][Wall Clock 535.480895674s] Trained 64 records in 0.11064935 seconds. Throughput is 578.40375 records/second. Loss is 0.087148234. Sequential2290a28's hyper parameters: Current learning rate is 0.01082485386447283. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 4240][Wall Clock 535.572310907s] Trained 64 records in 0.091415233 seconds. Throughput is 700.1021 records/second. Loss is 0.26016542. Sequential2290a28's hyper parameters: Current learning rate is 0.010823682216690118. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31296/60000][Iteration 4241][Wall Clock 535.705085435s] Trained 64 records in 0.132774528 seconds. Throughput is 482.02014 records/second. Loss is 0.13970393. Sequential2290a28's hyper parameters: Current learning rate is 0.010822510822510822. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31360/60000][Iteration 4242][Wall Clock 535.787001214s] Trained 64 records in 0.081915779 seconds. Throughput is 781.2902 records/second. Loss is 0.121991076. Sequential2290a28's hyper parameters: Current learning rate is 0.010821339681852614. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31424/60000][Iteration 4243][Wall Clock 535.925127386s] Trained 64 records in 0.138126172 seconds. Throughput is 463.3445 records/second. Loss is 0.1220271. Sequential2290a28's hyper parameters: Current learning rate is 0.010820168794633196. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:38 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 4244][Wall Clock 536.054646072s] Trained 64 records in 0.129518686 seconds. Throughput is 494.13718 records/second. Loss is 0.08249618. Sequential2290a28's hyper parameters: Current learning rate is 0.010818998160770314. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31552/60000][Iteration 4245][Wall Clock 536.21742086s] Trained 64 records in 0.162774788 seconds. Throughput is 393.18127 records/second. Loss is 0.16429077. Sequential2290a28's hyper parameters: Current learning rate is 0.010817827780181739. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31616/60000][Iteration 4246][Wall Clock 536.309122402s] Trained 64 records in 0.091701542 seconds. Throughput is 697.91626 records/second. Loss is 0.36679545. Sequential2290a28's hyper parameters: Current learning rate is 0.010816657652785288. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31680/60000][Iteration 4247][Wall Clock 536.408835069s] Trained 64 records in 0.099712667 seconds. Throughput is 641.84424 records/second. Loss is 0.20705554. Sequential2290a28's hyper parameters: Current learning rate is 0.01081548777849881. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 4248][Wall Clock 536.486384209s] Trained 64 records in 0.07754914 seconds. Throughput is 825.2832 records/second. Loss is 0.054952294. Sequential2290a28's hyper parameters: Current learning rate is 0.010814318157240186. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31808/60000][Iteration 4249][Wall Clock 536.580038315s] Trained 64 records in 0.093654106 seconds. Throughput is 683.36566 records/second. Loss is 0.08021383. Sequential2290a28's hyper parameters: Current learning rate is 0.010813148788927335. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31872/60000][Iteration 4250][Wall Clock 536.694718494s] Trained 64 records in 0.114680179 seconds. Throughput is 558.0738 records/second. Loss is 0.07368501. Sequential2290a28's hyper parameters: Current learning rate is 0.010811979673478214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 31936/60000][Iteration 4251][Wall Clock 536.802632822s] Trained 64 records in 0.107914328 seconds. Throughput is 593.06305 records/second. Loss is 0.048588425. Sequential2290a28's hyper parameters: Current learning rate is 0.01081081081081081. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 4252][Wall Clock 536.944324388s] Trained 64 records in 0.141691566 seconds. Throughput is 451.68533 records/second. Loss is 0.144016. Sequential2290a28's hyper parameters: Current learning rate is 0.010809642200843152. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:39 INFO  DistriOptimizer$:408 - [Epoch 5 32064/60000][Iteration 4253][Wall Clock 537.040703164s] Trained 64 records in 0.096378776 seconds. Throughput is 664.04663 records/second. Loss is 0.07632812. Sequential2290a28's hyper parameters: Current learning rate is 0.010808473843493299. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32128/60000][Iteration 4254][Wall Clock 537.112551735s] Trained 64 records in 0.071848571 seconds. Throughput is 890.7623 records/second. Loss is 0.12603685. Sequential2290a28's hyper parameters: Current learning rate is 0.010807305738679347. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32192/60000][Iteration 4255][Wall Clock 537.182813671s] Trained 64 records in 0.070261936 seconds. Throughput is 910.8773 records/second. Loss is 0.106965475. Sequential2290a28's hyper parameters: Current learning rate is 0.01080613788631943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 4256][Wall Clock 537.287824242s] Trained 64 records in 0.105010571 seconds. Throughput is 609.46246 records/second. Loss is 0.07723832. Sequential2290a28's hyper parameters: Current learning rate is 0.010804970286331712. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32320/60000][Iteration 4257][Wall Clock 537.440078263s] Trained 64 records in 0.152254021 seconds. Throughput is 420.35016 records/second. Loss is 0.14746343. Sequential2290a28's hyper parameters: Current learning rate is 0.0108038029386344. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32384/60000][Iteration 4258][Wall Clock 537.589422335s] Trained 64 records in 0.149344072 seconds. Throughput is 428.54062 records/second. Loss is 0.20114082. Sequential2290a28's hyper parameters: Current learning rate is 0.010802635843145728. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32448/60000][Iteration 4259][Wall Clock 537.670950006s] Trained 64 records in 0.081527671 seconds. Throughput is 785.0095 records/second. Loss is 0.1727299. Sequential2290a28's hyper parameters: Current learning rate is 0.01080146899978397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 4260][Wall Clock 537.738859623s] Trained 64 records in 0.067909617 seconds. Throughput is 942.4291 records/second. Loss is 0.04259392. Sequential2290a28's hyper parameters: Current learning rate is 0.010800302408467438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32576/60000][Iteration 4261][Wall Clock 537.839177417s] Trained 64 records in 0.100317794 seconds. Throughput is 637.9726 records/second. Loss is 0.19530952. Sequential2290a28's hyper parameters: Current learning rate is 0.01079913606911447. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32640/60000][Iteration 4262][Wall Clock 537.923406941s] Trained 64 records in 0.084229524 seconds. Throughput is 759.8286 records/second. Loss is 0.06675261. Sequential2290a28's hyper parameters: Current learning rate is 0.010797969981643452. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:40 INFO  DistriOptimizer$:408 - [Epoch 5 32704/60000][Iteration 4263][Wall Clock 538.022658429s] Trained 64 records in 0.099251488 seconds. Throughput is 644.8266 records/second. Loss is 0.14173223. Sequential2290a28's hyper parameters: Current learning rate is 0.010796804145972791. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 4264][Wall Clock 538.096419211s] Trained 64 records in 0.073760782 seconds. Throughput is 867.66974 records/second. Loss is 0.17329645. Sequential2290a28's hyper parameters: Current learning rate is 0.010795638562020943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 32832/60000][Iteration 4265][Wall Clock 538.185844796s] Trained 64 records in 0.089425585 seconds. Throughput is 715.67883 records/second. Loss is 0.06478712. Sequential2290a28's hyper parameters: Current learning rate is 0.01079447322970639. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 32896/60000][Iteration 4266][Wall Clock 538.341629244s] Trained 64 records in 0.155784448 seconds. Throughput is 410.82407 records/second. Loss is 0.07596577. Sequential2290a28's hyper parameters: Current learning rate is 0.01079330814894765. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 32960/60000][Iteration 4267][Wall Clock 538.440614639s] Trained 64 records in 0.098985395 seconds. Throughput is 646.56 records/second. Loss is 0.07860194. Sequential2290a28's hyper parameters: Current learning rate is 0.010792143319663284. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 4268][Wall Clock 538.539487035s] Trained 64 records in 0.098872396 seconds. Throughput is 647.299 records/second. Loss is 0.09887454. Sequential2290a28's hyper parameters: Current learning rate is 0.010790978741771878. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 33088/60000][Iteration 4269][Wall Clock 538.648733327s] Trained 64 records in 0.109246292 seconds. Throughput is 585.8322 records/second. Loss is 0.13541995. Sequential2290a28's hyper parameters: Current learning rate is 0.010789814415192058. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 33152/60000][Iteration 4270][Wall Clock 538.738562976s] Trained 64 records in 0.089829649 seconds. Throughput is 712.45966 records/second. Loss is 0.08301232. Sequential2290a28's hyper parameters: Current learning rate is 0.010788650339842486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 33216/60000][Iteration 4271][Wall Clock 538.863432314s] Trained 64 records in 0.124869338 seconds. Throughput is 512.53577 records/second. Loss is 0.2292673. Sequential2290a28's hyper parameters: Current learning rate is 0.010787486515641855. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 4272][Wall Clock 538.936917989s] Trained 64 records in 0.073485675 seconds. Throughput is 870.9181 records/second. Loss is 0.12266285. Sequential2290a28's hyper parameters: Current learning rate is 0.010786322942508898. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:41 INFO  DistriOptimizer$:408 - [Epoch 5 33344/60000][Iteration 4273][Wall Clock 539.007740863s] Trained 64 records in 0.070822874 seconds. Throughput is 903.66284 records/second. Loss is 0.23231356. Sequential2290a28's hyper parameters: Current learning rate is 0.010785159620362382. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33408/60000][Iteration 4274][Wall Clock 539.093770274s] Trained 64 records in 0.086029411 seconds. Throughput is 743.93164 records/second. Loss is 0.2559162. Sequential2290a28's hyper parameters: Current learning rate is 0.010783996549121105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33472/60000][Iteration 4275][Wall Clock 539.224327539s] Trained 64 records in 0.130557265 seconds. Throughput is 490.20633 records/second. Loss is 0.111202605. Sequential2290a28's hyper parameters: Current learning rate is 0.010782833728703903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 4276][Wall Clock 539.328439158s] Trained 64 records in 0.104111619 seconds. Throughput is 614.72485 records/second. Loss is 0.07566734. Sequential2290a28's hyper parameters: Current learning rate is 0.01078167115902965. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33600/60000][Iteration 4277][Wall Clock 539.449385806s] Trained 64 records in 0.120946648 seconds. Throughput is 529.15894 records/second. Loss is 0.25888205. Sequential2290a28's hyper parameters: Current learning rate is 0.01078050884001725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33664/60000][Iteration 4278][Wall Clock 539.550931855s] Trained 64 records in 0.101546049 seconds. Throughput is 630.2559 records/second. Loss is 0.10115258. Sequential2290a28's hyper parameters: Current learning rate is 0.010779346771585643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33728/60000][Iteration 4279][Wall Clock 539.640977391s] Trained 64 records in 0.090045536 seconds. Throughput is 710.7515 records/second. Loss is 0.16648255. Sequential2290a28's hyper parameters: Current learning rate is 0.010778184953653805. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 4280][Wall Clock 539.766493841s] Trained 64 records in 0.12551645 seconds. Throughput is 509.89334 records/second. Loss is 0.16686347. Sequential2290a28's hyper parameters: Current learning rate is 0.010777023386140748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:42 INFO  DistriOptimizer$:408 - [Epoch 5 33856/60000][Iteration 4281][Wall Clock 539.974587544s] Trained 64 records in 0.208093703 seconds. Throughput is 307.55374 records/second. Loss is 0.1318575. Sequential2290a28's hyper parameters: Current learning rate is 0.010775862068965516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 33920/60000][Iteration 4282][Wall Clock 540.0609179s] Trained 64 records in 0.086330356 seconds. Throughput is 741.3383 records/second. Loss is 0.2008367. Sequential2290a28's hyper parameters: Current learning rate is 0.010774701002047193. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 33984/60000][Iteration 4283][Wall Clock 540.142148829s] Trained 64 records in 0.081230929 seconds. Throughput is 787.8772 records/second. Loss is 0.187422. Sequential2290a28's hyper parameters: Current learning rate is 0.010773540185304891. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 4284][Wall Clock 540.235355449s] Trained 64 records in 0.09320662 seconds. Throughput is 686.6465 records/second. Loss is 0.12115182. Sequential2290a28's hyper parameters: Current learning rate is 0.01077237961865776. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34112/60000][Iteration 4285][Wall Clock 540.369477874s] Trained 64 records in 0.134122425 seconds. Throughput is 477.17596 records/second. Loss is 0.24191782. Sequential2290a28's hyper parameters: Current learning rate is 0.010771219302024989. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34176/60000][Iteration 4286][Wall Clock 540.461806956s] Trained 64 records in 0.092329082 seconds. Throughput is 693.17267 records/second. Loss is 0.050262596. Sequential2290a28's hyper parameters: Current learning rate is 0.010770059235325794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34240/60000][Iteration 4287][Wall Clock 540.616146994s] Trained 64 records in 0.154340038 seconds. Throughput is 414.6688 records/second. Loss is 0.11382958. Sequential2290a28's hyper parameters: Current learning rate is 0.01076889941847943. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 4288][Wall Clock 540.749578551s] Trained 64 records in 0.133431557 seconds. Throughput is 479.64667 records/second. Loss is 0.2671752. Sequential2290a28's hyper parameters: Current learning rate is 0.01076773985140519. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34368/60000][Iteration 4289][Wall Clock 540.850593654s] Trained 64 records in 0.101015103 seconds. Throughput is 633.5686 records/second. Loss is 0.16698702. Sequential2290a28's hyper parameters: Current learning rate is 0.010766580534022394. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:43 INFO  DistriOptimizer$:408 - [Epoch 5 34432/60000][Iteration 4290][Wall Clock 540.964572756s] Trained 64 records in 0.113979102 seconds. Throughput is 561.5065 records/second. Loss is 0.03719099. Sequential2290a28's hyper parameters: Current learning rate is 0.010765421466250404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34496/60000][Iteration 4291][Wall Clock 541.074140412s] Trained 64 records in 0.109567656 seconds. Throughput is 584.11395 records/second. Loss is 0.3075566. Sequential2290a28's hyper parameters: Current learning rate is 0.01076426264800861. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 4292][Wall Clock 541.190747198s] Trained 64 records in 0.116606786 seconds. Throughput is 548.85315 records/second. Loss is 0.2889299. Sequential2290a28's hyper parameters: Current learning rate is 0.010763104079216447. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34624/60000][Iteration 4293][Wall Clock 541.28561346s] Trained 64 records in 0.094866262 seconds. Throughput is 674.634 records/second. Loss is 0.17443214. Sequential2290a28's hyper parameters: Current learning rate is 0.01076194575979337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34688/60000][Iteration 4294][Wall Clock 541.391513682s] Trained 64 records in 0.105900222 seconds. Throughput is 604.34247 records/second. Loss is 0.09046059. Sequential2290a28's hyper parameters: Current learning rate is 0.010760787689658883. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34752/60000][Iteration 4295][Wall Clock 541.481163476s] Trained 64 records in 0.089649794 seconds. Throughput is 713.889 records/second. Loss is 0.11281477. Sequential2290a28's hyper parameters: Current learning rate is 0.010759629868732516. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 4296][Wall Clock 541.611263838s] Trained 64 records in 0.130100362 seconds. Throughput is 491.92795 records/second. Loss is 0.20630851. Sequential2290a28's hyper parameters: Current learning rate is 0.010758472296933835. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34880/60000][Iteration 4297][Wall Clock 541.717576335s] Trained 64 records in 0.106312497 seconds. Throughput is 601.99884 records/second. Loss is 0.13820751. Sequential2290a28's hyper parameters: Current learning rate is 0.010757314974182445. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 34944/60000][Iteration 4298][Wall Clock 541.852343063s] Trained 64 records in 0.134766728 seconds. Throughput is 474.89465 records/second. Loss is 0.13944341. Sequential2290a28's hyper parameters: Current learning rate is 0.010756157900397979. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:44 INFO  DistriOptimizer$:408 - [Epoch 5 35008/60000][Iteration 4299][Wall Clock 541.990351302s] Trained 64 records in 0.138008239 seconds. Throughput is 463.74045 records/second. Loss is 0.07628127. Sequential2290a28's hyper parameters: Current learning rate is 0.010755001075500108. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 4300][Wall Clock 542.076252842s] Trained 64 records in 0.08590154 seconds. Throughput is 745.039 records/second. Loss is 0.47232765. Sequential2290a28's hyper parameters: Current learning rate is 0.010753844499408539. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35136/60000][Iteration 4301][Wall Clock 542.20944463s] Trained 64 records in 0.133191788 seconds. Throughput is 480.51007 records/second. Loss is 0.12713683. Sequential2290a28's hyper parameters: Current learning rate is 0.010752688172043012. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35200/60000][Iteration 4302][Wall Clock 542.290995175s] Trained 64 records in 0.081550545 seconds. Throughput is 784.78937 records/second. Loss is 0.15398733. Sequential2290a28's hyper parameters: Current learning rate is 0.010751532093323298. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35264/60000][Iteration 4303][Wall Clock 542.39234194s] Trained 64 records in 0.101346765 seconds. Throughput is 631.49524 records/second. Loss is 0.10910069. Sequential2290a28's hyper parameters: Current learning rate is 0.010750376263169211. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 4304][Wall Clock 542.488171137s] Trained 64 records in 0.095829197 seconds. Throughput is 667.8549 records/second. Loss is 0.13393253. Sequential2290a28's hyper parameters: Current learning rate is 0.01074922068150059. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35392/60000][Iteration 4305][Wall Clock 542.592751587s] Trained 64 records in 0.10458045 seconds. Throughput is 611.96906 records/second. Loss is 0.10367687. Sequential2290a28's hyper parameters: Current learning rate is 0.010748065348237317. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35456/60000][Iteration 4306][Wall Clock 542.693731014s] Trained 64 records in 0.100979427 seconds. Throughput is 633.7925 records/second. Loss is 0.07594741. Sequential2290a28's hyper parameters: Current learning rate is 0.010746910263299301. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35520/60000][Iteration 4307][Wall Clock 542.812056637s] Trained 64 records in 0.118325623 seconds. Throughput is 540.8803 records/second. Loss is 0.13130307. Sequential2290a28's hyper parameters: Current learning rate is 0.010745755426606489. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 4308][Wall Clock 542.929271504s] Trained 64 records in 0.117214867 seconds. Throughput is 546.0058 records/second. Loss is 0.08625753. Sequential2290a28's hyper parameters: Current learning rate is 0.010744600838078865. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:45 INFO  DistriOptimizer$:408 - [Epoch 5 35648/60000][Iteration 4309][Wall Clock 543.017866824s] Trained 64 records in 0.08859532 seconds. Throughput is 722.38574 records/second. Loss is 0.06710367. Sequential2290a28's hyper parameters: Current learning rate is 0.010743446497636441. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 35712/60000][Iteration 4310][Wall Clock 543.120143275s] Trained 64 records in 0.102276451 seconds. Throughput is 625.755 records/second. Loss is 0.09293769. Sequential2290a28's hyper parameters: Current learning rate is 0.010742292405199269. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 35776/60000][Iteration 4311][Wall Clock 543.202389749s] Trained 64 records in 0.082246474 seconds. Throughput is 778.14886 records/second. Loss is 0.07916315. Sequential2290a28's hyper parameters: Current learning rate is 0.010741138560687433. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 4312][Wall Clock 543.287239242s] Trained 64 records in 0.084849493 seconds. Throughput is 754.27673 records/second. Loss is 0.070777915. Sequential2290a28's hyper parameters: Current learning rate is 0.01073998496402105. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 35904/60000][Iteration 4313][Wall Clock 543.379390681s] Trained 64 records in 0.092151439 seconds. Throughput is 694.509 records/second. Loss is 0.14063305. Sequential2290a28's hyper parameters: Current learning rate is 0.010738831615120275. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 35968/60000][Iteration 4314][Wall Clock 543.456304304s] Trained 64 records in 0.076913623 seconds. Throughput is 832.10223 records/second. Loss is 0.13776565. Sequential2290a28's hyper parameters: Current learning rate is 0.010737678513905294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 36032/60000][Iteration 4315][Wall Clock 543.53511625s] Trained 64 records in 0.078811946 seconds. Throughput is 812.05963 records/second. Loss is 0.10677617. Sequential2290a28's hyper parameters: Current learning rate is 0.010736525660296328. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 4316][Wall Clock 543.618801136s] Trained 64 records in 0.083684886 seconds. Throughput is 764.77374 records/second. Loss is 0.07474419. Sequential2290a28's hyper parameters: Current learning rate is 0.010735373054213635. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 36160/60000][Iteration 4317][Wall Clock 543.764931279s] Trained 64 records in 0.146130143 seconds. Throughput is 437.96576 records/second. Loss is 0.17871994. Sequential2290a28's hyper parameters: Current learning rate is 0.010734220695577501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:46 INFO  DistriOptimizer$:408 - [Epoch 5 36224/60000][Iteration 4318][Wall Clock 543.857519058s] Trained 64 records in 0.092587779 seconds. Throughput is 691.23596 records/second. Loss is 0.1078868. Sequential2290a28's hyper parameters: Current learning rate is 0.010733068584308255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36288/60000][Iteration 4319][Wall Clock 544.025977218s] Trained 64 records in 0.16845816 seconds. Throughput is 379.9163 records/second. Loss is 0.070568696. Sequential2290a28's hyper parameters: Current learning rate is 0.010731916720326251. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 4320][Wall Clock 544.191035807s] Trained 64 records in 0.165058589 seconds. Throughput is 387.74112 records/second. Loss is 0.24844292. Sequential2290a28's hyper parameters: Current learning rate is 0.010730765103551884. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36416/60000][Iteration 4321][Wall Clock 544.38806835s] Trained 64 records in 0.197032543 seconds. Throughput is 324.81943 records/second. Loss is 0.16227442. Sequential2290a28's hyper parameters: Current learning rate is 0.010729613733905581. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36480/60000][Iteration 4322][Wall Clock 544.571844391s] Trained 64 records in 0.183776041 seconds. Throughput is 348.24997 records/second. Loss is 0.14093125. Sequential2290a28's hyper parameters: Current learning rate is 0.010728462611307799. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36544/60000][Iteration 4323][Wall Clock 544.695448384s] Trained 64 records in 0.123603993 seconds. Throughput is 517.78265 records/second. Loss is 0.2016376. Sequential2290a28's hyper parameters: Current learning rate is 0.010727311735679038. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 4324][Wall Clock 544.808863748s] Trained 64 records in 0.113415364 seconds. Throughput is 564.2975 records/second. Loss is 0.24276125. Sequential2290a28's hyper parameters: Current learning rate is 0.010726161106939826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:47 INFO  DistriOptimizer$:408 - [Epoch 5 36672/60000][Iteration 4325][Wall Clock 544.918733898s] Trained 64 records in 0.10987015 seconds. Throughput is 582.5058 records/second. Loss is 0.17306644. Sequential2290a28's hyper parameters: Current learning rate is 0.010725010725010725. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 36736/60000][Iteration 4326][Wall Clock 545.097137331s] Trained 64 records in 0.178403433 seconds. Throughput is 358.7375 records/second. Loss is 0.052989863. Sequential2290a28's hyper parameters: Current learning rate is 0.010723860589812333. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 36800/60000][Iteration 4327][Wall Clock 545.191978455s] Trained 64 records in 0.094841124 seconds. Throughput is 674.81274 records/second. Loss is 0.15485266. Sequential2290a28's hyper parameters: Current learning rate is 0.010722710701265278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 4328][Wall Clock 545.381481215s] Trained 64 records in 0.18950276 seconds. Throughput is 337.72595 records/second. Loss is 0.1033211. Sequential2290a28's hyper parameters: Current learning rate is 0.010721561059290232. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 36928/60000][Iteration 4329][Wall Clock 545.464942152s] Trained 64 records in 0.083460937 seconds. Throughput is 766.8258 records/second. Loss is 0.15263113. Sequential2290a28's hyper parameters: Current learning rate is 0.01072041166380789. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 36992/60000][Iteration 4330][Wall Clock 545.566540359s] Trained 64 records in 0.101598207 seconds. Throughput is 629.9324 records/second. Loss is 0.10428359. Sequential2290a28's hyper parameters: Current learning rate is 0.010719262514738986. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 37056/60000][Iteration 4331][Wall Clock 545.677836236s] Trained 64 records in 0.111295877 seconds. Throughput is 575.04376 records/second. Loss is 0.14808033. Sequential2290a28's hyper parameters: Current learning rate is 0.010718113612004287. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 4332][Wall Clock 545.807210557s] Trained 64 records in 0.129374321 seconds. Throughput is 494.68857 records/second. Loss is 0.046883836. Sequential2290a28's hyper parameters: Current learning rate is 0.010716964955524596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:48 INFO  DistriOptimizer$:408 - [Epoch 5 37184/60000][Iteration 4333][Wall Clock 545.940718973s] Trained 64 records in 0.133508416 seconds. Throughput is 479.37054 records/second. Loss is 0.16423015. Sequential2290a28's hyper parameters: Current learning rate is 0.010715816545220747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37248/60000][Iteration 4334][Wall Clock 546.097744349s] Trained 64 records in 0.157025376 seconds. Throughput is 407.57742 records/second. Loss is 0.04843723. Sequential2290a28's hyper parameters: Current learning rate is 0.010714668381013608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37312/60000][Iteration 4335][Wall Clock 546.177036191s] Trained 64 records in 0.079291842 seconds. Throughput is 807.14484 records/second. Loss is 0.12286273. Sequential2290a28's hyper parameters: Current learning rate is 0.010713520462824084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 4336][Wall Clock 546.255740516s] Trained 64 records in 0.078704325 seconds. Throughput is 813.17004 records/second. Loss is 0.06953619. Sequential2290a28's hyper parameters: Current learning rate is 0.010712372790573112. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37440/60000][Iteration 4337][Wall Clock 546.376426278s] Trained 64 records in 0.120685762 seconds. Throughput is 530.3028 records/second. Loss is 0.11918357. Sequential2290a28's hyper parameters: Current learning rate is 0.010711225364181664. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37504/60000][Iteration 4338][Wall Clock 546.4977881s] Trained 64 records in 0.121361822 seconds. Throughput is 527.3487 records/second. Loss is 0.11741688. Sequential2290a28's hyper parameters: Current learning rate is 0.01071007818357074. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37568/60000][Iteration 4339][Wall Clock 546.650192069s] Trained 64 records in 0.152403969 seconds. Throughput is 419.93658 records/second. Loss is 0.12070425. Sequential2290a28's hyper parameters: Current learning rate is 0.010708931248661385. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 4340][Wall Clock 546.792511286s] Trained 64 records in 0.142319217 seconds. Throughput is 449.6933 records/second. Loss is 0.11110064. Sequential2290a28's hyper parameters: Current learning rate is 0.010707784559374666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:49 INFO  DistriOptimizer$:408 - [Epoch 5 37696/60000][Iteration 4341][Wall Clock 546.902292462s] Trained 64 records in 0.109781176 seconds. Throughput is 582.9779 records/second. Loss is 0.18225317. Sequential2290a28's hyper parameters: Current learning rate is 0.010706638115631693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 37760/60000][Iteration 4342][Wall Clock 547.094427021s] Trained 64 records in 0.192134559 seconds. Throughput is 333.09988 records/second. Loss is 0.1752441. Sequential2290a28's hyper parameters: Current learning rate is 0.010705491917353602. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 37824/60000][Iteration 4343][Wall Clock 547.231956416s] Trained 64 records in 0.137529395 seconds. Throughput is 465.35507 records/second. Loss is 0.15233088. Sequential2290a28's hyper parameters: Current learning rate is 0.010704345964461572. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 4344][Wall Clock 547.370357784s] Trained 64 records in 0.138401368 seconds. Throughput is 462.42316 records/second. Loss is 0.12042349. Sequential2290a28's hyper parameters: Current learning rate is 0.010703200256876806. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 37952/60000][Iteration 4345][Wall Clock 547.53077168s] Trained 64 records in 0.160413896 seconds. Throughput is 398.96796 records/second. Loss is 0.12760365. Sequential2290a28's hyper parameters: Current learning rate is 0.010702054794520547. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 38016/60000][Iteration 4346][Wall Clock 547.687241647s] Trained 64 records in 0.156469967 seconds. Throughput is 409.02417 records/second. Loss is 0.18512942. Sequential2290a28's hyper parameters: Current learning rate is 0.010700909577314071. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 38080/60000][Iteration 4347][Wall Clock 547.769287639s] Trained 64 records in 0.082045992 seconds. Throughput is 780.0503 records/second. Loss is 0.18398783. Sequential2290a28's hyper parameters: Current learning rate is 0.010699764605178685. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:50 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 4348][Wall Clock 547.890838546s] Trained 64 records in 0.121550907 seconds. Throughput is 526.5283 records/second. Loss is 0.088130176. Sequential2290a28's hyper parameters: Current learning rate is 0.010698619878035732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38208/60000][Iteration 4349][Wall Clock 547.999853733s] Trained 64 records in 0.109015187 seconds. Throughput is 587.07416 records/second. Loss is 0.07927851. Sequential2290a28's hyper parameters: Current learning rate is 0.010697475395806589. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38272/60000][Iteration 4350][Wall Clock 548.123689501s] Trained 64 records in 0.123835768 seconds. Throughput is 516.81354 records/second. Loss is 0.12054738. Sequential2290a28's hyper parameters: Current learning rate is 0.010696331158412663. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38336/60000][Iteration 4351][Wall Clock 548.245116759s] Trained 64 records in 0.121427258 seconds. Throughput is 527.0645 records/second. Loss is 0.22265674. Sequential2290a28's hyper parameters: Current learning rate is 0.0106951871657754. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 4352][Wall Clock 548.399950801s] Trained 64 records in 0.154834042 seconds. Throughput is 413.3458 records/second. Loss is 0.12551686. Sequential2290a28's hyper parameters: Current learning rate is 0.010694043417816277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38464/60000][Iteration 4353][Wall Clock 548.553451936s] Trained 64 records in 0.153501135 seconds. Throughput is 416.93503 records/second. Loss is 0.20039904. Sequential2290a28's hyper parameters: Current learning rate is 0.0106928999144568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38528/60000][Iteration 4354][Wall Clock 548.660551068s] Trained 64 records in 0.107099132 seconds. Throughput is 597.5772 records/second. Loss is 0.1279763. Sequential2290a28's hyper parameters: Current learning rate is 0.010691756655618518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38592/60000][Iteration 4355][Wall Clock 548.776285549s] Trained 64 records in 0.115734481 seconds. Throughput is 552.9899 records/second. Loss is 0.14710112. Sequential2290a28's hyper parameters: Current learning rate is 0.010690613641223007. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 4356][Wall Clock 548.870579863s] Trained 64 records in 0.094294314 seconds. Throughput is 678.72595 records/second. Loss is 0.24712518. Sequential2290a28's hyper parameters: Current learning rate is 0.010689470871191877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:51 INFO  DistriOptimizer$:408 - [Epoch 5 38720/60000][Iteration 4357][Wall Clock 548.970235868s] Trained 64 records in 0.099656005 seconds. Throughput is 642.20917 records/second. Loss is 0.08446096. Sequential2290a28's hyper parameters: Current learning rate is 0.010688328345446772. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 38784/60000][Iteration 4358][Wall Clock 549.081261922s] Trained 64 records in 0.111026054 seconds. Throughput is 576.4413 records/second. Loss is 0.06184645. Sequential2290a28's hyper parameters: Current learning rate is 0.010687186063909374. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 38848/60000][Iteration 4359][Wall Clock 549.210178108s] Trained 64 records in 0.128916186 seconds. Throughput is 496.44656 records/second. Loss is 0.21207863. Sequential2290a28's hyper parameters: Current learning rate is 0.01068604402650139. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 4360][Wall Clock 549.309788167s] Trained 64 records in 0.099610059 seconds. Throughput is 642.5054 records/second. Loss is 0.08460827. Sequential2290a28's hyper parameters: Current learning rate is 0.010684902233144567. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 38976/60000][Iteration 4361][Wall Clock 549.421582126s] Trained 64 records in 0.111793959 seconds. Throughput is 572.48175 records/second. Loss is 0.08472913. Sequential2290a28's hyper parameters: Current learning rate is 0.010683760683760684. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 39040/60000][Iteration 4362][Wall Clock 549.518833262s] Trained 64 records in 0.097251136 seconds. Throughput is 658.08997 records/second. Loss is 0.18978105. Sequential2290a28's hyper parameters: Current learning rate is 0.010682619378271552. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 39104/60000][Iteration 4363][Wall Clock 549.643227665s] Trained 64 records in 0.124394403 seconds. Throughput is 514.4926 records/second. Loss is 0.11720332. Sequential2290a28's hyper parameters: Current learning rate is 0.010681478316599017. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 4364][Wall Clock 549.763571665s] Trained 64 records in 0.120344 seconds. Throughput is 531.80884 records/second. Loss is 0.06383776. Sequential2290a28's hyper parameters: Current learning rate is 0.010680337498664958. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 39232/60000][Iteration 4365][Wall Clock 549.842170661s] Trained 64 records in 0.078598996 seconds. Throughput is 814.25977 records/second. Loss is 0.25521463. Sequential2290a28's hyper parameters: Current learning rate is 0.010679196924391286. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:52 INFO  DistriOptimizer$:408 - [Epoch 5 39296/60000][Iteration 4366][Wall Clock 549.944286021s] Trained 64 records in 0.10211536 seconds. Throughput is 626.7421 records/second. Loss is 0.1649367. Sequential2290a28's hyper parameters: Current learning rate is 0.010678056593699947. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39360/60000][Iteration 4367][Wall Clock 550.075407786s] Trained 64 records in 0.131121765 seconds. Throughput is 488.09592 records/second. Loss is 0.19987279. Sequential2290a28's hyper parameters: Current learning rate is 0.010676916506512918. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 4368][Wall Clock 550.162552242s] Trained 64 records in 0.087144456 seconds. Throughput is 734.4127 records/second. Loss is 0.12058236. Sequential2290a28's hyper parameters: Current learning rate is 0.010675776662752214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39488/60000][Iteration 4369][Wall Clock 550.312210948s] Trained 64 records in 0.149658706 seconds. Throughput is 427.63965 records/second. Loss is 0.14954883. Sequential2290a28's hyper parameters: Current learning rate is 0.01067463706233988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39552/60000][Iteration 4370][Wall Clock 550.485151662s] Trained 64 records in 0.172940714 seconds. Throughput is 370.069 records/second. Loss is 0.11436117. Sequential2290a28's hyper parameters: Current learning rate is 0.010673497705197993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39616/60000][Iteration 4371][Wall Clock 550.593040441s] Trained 64 records in 0.107888779 seconds. Throughput is 593.2035 records/second. Loss is 0.14496244. Sequential2290a28's hyper parameters: Current learning rate is 0.010672358591248666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 4372][Wall Clock 550.709352447s] Trained 64 records in 0.116312006 seconds. Throughput is 550.24414 records/second. Loss is 0.16321604. Sequential2290a28's hyper parameters: Current learning rate is 0.010671219720414044. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39744/60000][Iteration 4373][Wall Clock 550.845004581s] Trained 64 records in 0.135652134 seconds. Throughput is 471.79498 records/second. Loss is 0.17708008. Sequential2290a28's hyper parameters: Current learning rate is 0.010670081092616303. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:53 INFO  DistriOptimizer$:408 - [Epoch 5 39808/60000][Iteration 4374][Wall Clock 550.978117851s] Trained 64 records in 0.13311327 seconds. Throughput is 480.79355 records/second. Loss is 0.19635323. Sequential2290a28's hyper parameters: Current learning rate is 0.010668942707777658. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 39872/60000][Iteration 4375][Wall Clock 551.076436694s] Trained 64 records in 0.098318843 seconds. Throughput is 650.94336 records/second. Loss is 0.046768107. Sequential2290a28's hyper parameters: Current learning rate is 0.010667804565820354. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 4376][Wall Clock 551.151082706s] Trained 64 records in 0.074646012 seconds. Throughput is 857.38007 records/second. Loss is 0.14481366. Sequential2290a28's hyper parameters: Current learning rate is 0.010666666666666666. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40000/60000][Iteration 4377][Wall Clock 551.300285222s] Trained 64 records in 0.149202516 seconds. Throughput is 428.9472 records/second. Loss is 0.16095085. Sequential2290a28's hyper parameters: Current learning rate is 0.010665529010238909. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40064/60000][Iteration 4378][Wall Clock 551.417084705s] Trained 64 records in 0.116799483 seconds. Throughput is 547.94763 records/second. Loss is 0.09490703. Sequential2290a28's hyper parameters: Current learning rate is 0.010664391596459422. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40128/60000][Iteration 4379][Wall Clock 551.517608848s] Trained 64 records in 0.100524143 seconds. Throughput is 636.66296 records/second. Loss is 0.14983082. Sequential2290a28's hyper parameters: Current learning rate is 0.010663254425250587. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 4380][Wall Clock 551.609846729s] Trained 64 records in 0.092237881 seconds. Throughput is 693.8581 records/second. Loss is 0.07533531. Sequential2290a28's hyper parameters: Current learning rate is 0.010662117496534812. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40256/60000][Iteration 4381][Wall Clock 551.696297519s] Trained 64 records in 0.08645079 seconds. Throughput is 740.30554 records/second. Loss is 0.119455285. Sequential2290a28's hyper parameters: Current learning rate is 0.010660980810234543. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40320/60000][Iteration 4382][Wall Clock 551.809689341s] Trained 64 records in 0.113391822 seconds. Throughput is 564.4146 records/second. Loss is 0.22142375. Sequential2290a28's hyper parameters: Current learning rate is 0.010659844366272252. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:54 INFO  DistriOptimizer$:408 - [Epoch 5 40384/60000][Iteration 4383][Wall Clock 551.886121682s] Trained 64 records in 0.076432341 seconds. Throughput is 837.3419 records/second. Loss is 0.17434466. Sequential2290a28's hyper parameters: Current learning rate is 0.010658708164570454. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 4384][Wall Clock 552.018449977s] Trained 64 records in 0.132328295 seconds. Throughput is 483.6456 records/second. Loss is 0.16354233. Sequential2290a28's hyper parameters: Current learning rate is 0.01065757220505169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40512/60000][Iteration 4385][Wall Clock 552.154235485s] Trained 64 records in 0.135785508 seconds. Throughput is 471.3316 records/second. Loss is 0.07615082. Sequential2290a28's hyper parameters: Current learning rate is 0.010656436487638534. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40576/60000][Iteration 4386][Wall Clock 552.275014046s] Trained 64 records in 0.120778561 seconds. Throughput is 529.8954 records/second. Loss is 0.07837747. Sequential2290a28's hyper parameters: Current learning rate is 0.010655301012253596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40640/60000][Iteration 4387][Wall Clock 552.352176906s] Trained 64 records in 0.07716286 seconds. Throughput is 829.41455 records/second. Loss is 0.07828169. Sequential2290a28's hyper parameters: Current learning rate is 0.010654165778819518. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 4388][Wall Clock 552.471396661s] Trained 64 records in 0.119219755 seconds. Throughput is 536.8238 records/second. Loss is 0.17358664. Sequential2290a28's hyper parameters: Current learning rate is 0.010653030787258974. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40768/60000][Iteration 4389][Wall Clock 552.554141213s] Trained 64 records in 0.082744552 seconds. Throughput is 773.4648 records/second. Loss is 0.066319644. Sequential2290a28's hyper parameters: Current learning rate is 0.010651896037494673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40832/60000][Iteration 4390][Wall Clock 552.651797109s] Trained 64 records in 0.097655896 seconds. Throughput is 655.3624 records/second. Loss is 0.12750721. Sequential2290a28's hyper parameters: Current learning rate is 0.010650761529449356. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40896/60000][Iteration 4391][Wall Clock 552.742055684s] Trained 64 records in 0.090258575 seconds. Throughput is 709.0739 records/second. Loss is 0.076972455. Sequential2290a28's hyper parameters: Current learning rate is 0.010649627263045794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:55 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 4392][Wall Clock 552.853597518s] Trained 64 records in 0.111541834 seconds. Throughput is 573.77576 records/second. Loss is 0.07182625. Sequential2290a28's hyper parameters: Current learning rate is 0.010648493238206793. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41024/60000][Iteration 4393][Wall Clock 553.078046043s] Trained 64 records in 0.224448525 seconds. Throughput is 285.1433 records/second. Loss is 0.16435313. Sequential2290a28's hyper parameters: Current learning rate is 0.010647359454855196. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41088/60000][Iteration 4394][Wall Clock 553.224237521s] Trained 64 records in 0.146191478 seconds. Throughput is 437.782 records/second. Loss is 0.09734593. Sequential2290a28's hyper parameters: Current learning rate is 0.010646225912913872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41152/60000][Iteration 4395][Wall Clock 553.316453065s] Trained 64 records in 0.092215544 seconds. Throughput is 694.0261 records/second. Loss is 0.050120257. Sequential2290a28's hyper parameters: Current learning rate is 0.010645092612305727. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 4396][Wall Clock 553.429722646s] Trained 64 records in 0.113269581 seconds. Throughput is 565.02374 records/second. Loss is 0.10308254. Sequential2290a28's hyper parameters: Current learning rate is 0.010643959552953698. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41280/60000][Iteration 4397][Wall Clock 553.557943914s] Trained 64 records in 0.128221268 seconds. Throughput is 499.13715 records/second. Loss is 0.08681165. Sequential2290a28's hyper parameters: Current learning rate is 0.010642826734780758. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41344/60000][Iteration 4398][Wall Clock 553.679651578s] Trained 64 records in 0.121707664 seconds. Throughput is 525.8502 records/second. Loss is 0.1360106. Sequential2290a28's hyper parameters: Current learning rate is 0.010641694157709908. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41408/60000][Iteration 4399][Wall Clock 553.841675658s] Trained 64 records in 0.16202408 seconds. Throughput is 395.00302 records/second. Loss is 0.11605482. Sequential2290a28's hyper parameters: Current learning rate is 0.010640561821664184. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:56 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 4400][Wall Clock 553.944807082s] Trained 64 records in 0.103131424 seconds. Throughput is 620.56744 records/second. Loss is 0.07560469. Sequential2290a28's hyper parameters: Current learning rate is 0.010639429726566656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41536/60000][Iteration 4401][Wall Clock 554.084797451s] Trained 64 records in 0.139990369 seconds. Throughput is 457.1743 records/second. Loss is 0.15906517. Sequential2290a28's hyper parameters: Current learning rate is 0.010638297872340427. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41600/60000][Iteration 4402][Wall Clock 554.232854787s] Trained 64 records in 0.148057336 seconds. Throughput is 432.26495 records/second. Loss is 0.08414981. Sequential2290a28's hyper parameters: Current learning rate is 0.010637166258908627. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41664/60000][Iteration 4403][Wall Clock 554.372962969s] Trained 64 records in 0.140108182 seconds. Throughput is 456.7899 records/second. Loss is 0.06550353. Sequential2290a28's hyper parameters: Current learning rate is 0.010636034886194426. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 4404][Wall Clock 554.473422209s] Trained 64 records in 0.10045924 seconds. Throughput is 637.0743 records/second. Loss is 0.14620203. Sequential2290a28's hyper parameters: Current learning rate is 0.010634903754121025. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41792/60000][Iteration 4405][Wall Clock 554.641414271s] Trained 64 records in 0.167992062 seconds. Throughput is 380.9704 records/second. Loss is 0.07588559. Sequential2290a28's hyper parameters: Current learning rate is 0.010633772862611655. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41856/60000][Iteration 4406][Wall Clock 554.818699056s] Trained 64 records in 0.177284785 seconds. Throughput is 361.00107 records/second. Loss is 0.07432911. Sequential2290a28's hyper parameters: Current learning rate is 0.01063264221158958. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:57 INFO  DistriOptimizer$:408 - [Epoch 5 41920/60000][Iteration 4407][Wall Clock 554.911955285s] Trained 64 records in 0.093256229 seconds. Throughput is 686.28125 records/second. Loss is 0.101579204. Sequential2290a28's hyper parameters: Current learning rate is 0.010631511800978098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 4408][Wall Clock 554.993611346s] Trained 64 records in 0.081656061 seconds. Throughput is 783.77527 records/second. Loss is 0.09692441. Sequential2290a28's hyper parameters: Current learning rate is 0.010630381630700542. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42048/60000][Iteration 4409][Wall Clock 555.090666154s] Trained 64 records in 0.097054808 seconds. Throughput is 659.4212 records/second. Loss is 0.13773398. Sequential2290a28's hyper parameters: Current learning rate is 0.010629251700680272. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42112/60000][Iteration 4410][Wall Clock 555.174437603s] Trained 64 records in 0.083771449 seconds. Throughput is 763.9834 records/second. Loss is 0.15273133. Sequential2290a28's hyper parameters: Current learning rate is 0.010628122010840685. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42176/60000][Iteration 4411][Wall Clock 555.267020238s] Trained 64 records in 0.092582635 seconds. Throughput is 691.27435 records/second. Loss is 0.16009958. Sequential2290a28's hyper parameters: Current learning rate is 0.010626992561105207. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 4412][Wall Clock 555.348514109s] Trained 64 records in 0.081493871 seconds. Throughput is 785.33514 records/second. Loss is 0.12016794. Sequential2290a28's hyper parameters: Current learning rate is 0.010625863351397301. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42304/60000][Iteration 4413][Wall Clock 555.445168219s] Trained 64 records in 0.09665411 seconds. Throughput is 662.15497 records/second. Loss is 0.074917026. Sequential2290a28's hyper parameters: Current learning rate is 0.010624734381640459. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42368/60000][Iteration 4414][Wall Clock 555.517547694s] Trained 64 records in 0.072379475 seconds. Throughput is 884.2285 records/second. Loss is 0.06691943. Sequential2290a28's hyper parameters: Current learning rate is 0.010623605651758206. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42432/60000][Iteration 4415][Wall Clock 555.611440775s] Trained 64 records in 0.093893081 seconds. Throughput is 681.62634 records/second. Loss is 0.294817. Sequential2290a28's hyper parameters: Current learning rate is 0.010622477161674103. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 4416][Wall Clock 555.750792771s] Trained 64 records in 0.139351996 seconds. Throughput is 459.26865 records/second. Loss is 0.28099766. Sequential2290a28's hyper parameters: Current learning rate is 0.010621348911311737. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:58 INFO  DistriOptimizer$:408 - [Epoch 5 42560/60000][Iteration 4417][Wall Clock 555.907492124s] Trained 64 records in 0.156699353 seconds. Throughput is 408.4254 records/second. Loss is 0.070518486. Sequential2290a28's hyper parameters: Current learning rate is 0.010620220900594732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 42624/60000][Iteration 4418][Wall Clock 556.058315477s] Trained 64 records in 0.150823353 seconds. Throughput is 424.33746 records/second. Loss is 0.21231854. Sequential2290a28's hyper parameters: Current learning rate is 0.010619093129446746. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 42688/60000][Iteration 4419][Wall Clock 556.202877937s] Trained 64 records in 0.14456246 seconds. Throughput is 442.71524 records/second. Loss is 0.11343127. Sequential2290a28's hyper parameters: Current learning rate is 0.010617965597791464. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 4420][Wall Clock 556.301765771s] Trained 64 records in 0.098887834 seconds. Throughput is 647.19794 records/second. Loss is 0.071327016. Sequential2290a28's hyper parameters: Current learning rate is 0.010616838305552607. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 42816/60000][Iteration 4421][Wall Clock 556.426554299s] Trained 64 records in 0.124788528 seconds. Throughput is 512.8677 records/second. Loss is 0.12066268. Sequential2290a28's hyper parameters: Current learning rate is 0.010615711252653929. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 42880/60000][Iteration 4422][Wall Clock 556.517977121s] Trained 64 records in 0.091422822 seconds. Throughput is 700.04407 records/second. Loss is 0.11617976. Sequential2290a28's hyper parameters: Current learning rate is 0.010614584439019211. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 42944/60000][Iteration 4423][Wall Clock 556.587970288s] Trained 64 records in 0.069993167 seconds. Throughput is 914.37494 records/second. Loss is 0.099899784. Sequential2290a28's hyper parameters: Current learning rate is 0.010613457864572278. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 4424][Wall Clock 556.665855269s] Trained 64 records in 0.077884981 seconds. Throughput is 821.72455 records/second. Loss is 0.10001641. Sequential2290a28's hyper parameters: Current learning rate is 0.010612331529236973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 43072/60000][Iteration 4425][Wall Clock 556.760239498s] Trained 64 records in 0.094384229 seconds. Throughput is 678.07935 records/second. Loss is 0.14719597. Sequential2290a28's hyper parameters: Current learning rate is 0.010611205432937181. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:22:59 INFO  DistriOptimizer$:408 - [Epoch 5 43136/60000][Iteration 4426][Wall Clock 556.871100691s] Trained 64 records in 0.110861193 seconds. Throughput is 577.2985 records/second. Loss is 0.06483328. Sequential2290a28's hyper parameters: Current learning rate is 0.010610079575596816. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43200/60000][Iteration 4427][Wall Clock 556.991326858s] Trained 64 records in 0.120226167 seconds. Throughput is 532.33 records/second. Loss is 0.09802702. Sequential2290a28's hyper parameters: Current learning rate is 0.010608953957139825. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 4428][Wall Clock 557.123147154s] Trained 64 records in 0.131820296 seconds. Throughput is 485.50946 records/second. Loss is 0.21720463. Sequential2290a28's hyper parameters: Current learning rate is 0.010607828577490187. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43328/60000][Iteration 4429][Wall Clock 557.254207468s] Trained 64 records in 0.131060314 seconds. Throughput is 488.32477 records/second. Loss is 0.109247416. Sequential2290a28's hyper parameters: Current learning rate is 0.010606703436571913. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43392/60000][Iteration 4430][Wall Clock 557.342291975s] Trained 64 records in 0.088084507 seconds. Throughput is 726.575 records/second. Loss is 0.16032952. Sequential2290a28's hyper parameters: Current learning rate is 0.010605578534309046. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43456/60000][Iteration 4431][Wall Clock 557.479265596s] Trained 64 records in 0.136973621 seconds. Throughput is 467.24326 records/second. Loss is 0.2071555. Sequential2290a28's hyper parameters: Current learning rate is 0.010604453870625662. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 4432][Wall Clock 557.618907189s] Trained 64 records in 0.139641593 seconds. Throughput is 458.31616 records/second. Loss is 0.10787769. Sequential2290a28's hyper parameters: Current learning rate is 0.01060332944544587. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43584/60000][Iteration 4433][Wall Clock 557.701871805s] Trained 64 records in 0.082964616 seconds. Throughput is 771.4132 records/second. Loss is 0.118874885. Sequential2290a28's hyper parameters: Current learning rate is 0.010602205258693808. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43648/60000][Iteration 4434][Wall Clock 557.780941478s] Trained 64 records in 0.079069673 seconds. Throughput is 809.4127 records/second. Loss is 0.24144284. Sequential2290a28's hyper parameters: Current learning rate is 0.01060108131029365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:00 INFO  DistriOptimizer$:408 - [Epoch 5 43712/60000][Iteration 4435][Wall Clock 557.881879764s] Trained 64 records in 0.100938286 seconds. Throughput is 634.0508 records/second. Loss is 0.2550979. Sequential2290a28's hyper parameters: Current learning rate is 0.0105999576001696. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 4436][Wall Clock 557.991218382s] Trained 64 records in 0.109338618 seconds. Throughput is 585.3376 records/second. Loss is 0.12883. Sequential2290a28's hyper parameters: Current learning rate is 0.010598834128245893. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 43840/60000][Iteration 4437][Wall Clock 558.155203971s] Trained 64 records in 0.163985589 seconds. Throughput is 390.27817 records/second. Loss is 0.0863985. Sequential2290a28's hyper parameters: Current learning rate is 0.0105977108944468. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 43904/60000][Iteration 4438][Wall Clock 558.273414766s] Trained 64 records in 0.118210795 seconds. Throughput is 541.4057 records/second. Loss is 0.19320017. Sequential2290a28's hyper parameters: Current learning rate is 0.01059658789869662. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 43968/60000][Iteration 4439][Wall Clock 558.400061892s] Trained 64 records in 0.126647126 seconds. Throughput is 505.3411 records/second. Loss is 0.07721599. Sequential2290a28's hyper parameters: Current learning rate is 0.010595465140919687. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 4440][Wall Clock 558.483017033s] Trained 64 records in 0.082955141 seconds. Throughput is 771.5013 records/second. Loss is 0.11314326. Sequential2290a28's hyper parameters: Current learning rate is 0.010594342621040365. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 44096/60000][Iteration 4441][Wall Clock 558.575459031s] Trained 64 records in 0.092441998 seconds. Throughput is 692.326 records/second. Loss is 0.23124537. Sequential2290a28's hyper parameters: Current learning rate is 0.010593220338983052. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 44160/60000][Iteration 4442][Wall Clock 558.662270529s] Trained 64 records in 0.086811498 seconds. Throughput is 737.22955 records/second. Loss is 0.122568786. Sequential2290a28's hyper parameters: Current learning rate is 0.010592098294672175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 44224/60000][Iteration 4443][Wall Clock 558.78477789s] Trained 64 records in 0.122507361 seconds. Throughput is 522.4176 records/second. Loss is 0.12638077. Sequential2290a28's hyper parameters: Current learning rate is 0.010590976488032196. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:01 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 4444][Wall Clock 558.872078628s] Trained 64 records in 0.087300738 seconds. Throughput is 733.098 records/second. Loss is 0.18061312. Sequential2290a28's hyper parameters: Current learning rate is 0.01058985491898761. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44352/60000][Iteration 4445][Wall Clock 558.969848139s] Trained 64 records in 0.097769511 seconds. Throughput is 654.60077 records/second. Loss is 0.15436499. Sequential2290a28's hyper parameters: Current learning rate is 0.010588733587462939. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44416/60000][Iteration 4446][Wall Clock 559.108472962s] Trained 64 records in 0.138624823 seconds. Throughput is 461.6778 records/second. Loss is 0.13123581. Sequential2290a28's hyper parameters: Current learning rate is 0.010587612493382742. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44480/60000][Iteration 4447][Wall Clock 559.232639567s] Trained 64 records in 0.124166605 seconds. Throughput is 515.43646 records/second. Loss is 0.09938424. Sequential2290a28's hyper parameters: Current learning rate is 0.010586491636671608. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 4448][Wall Clock 559.339530775s] Trained 64 records in 0.106891208 seconds. Throughput is 598.7396 records/second. Loss is 0.103337735. Sequential2290a28's hyper parameters: Current learning rate is 0.010585371017254154. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44608/60000][Iteration 4449][Wall Clock 559.465080578s] Trained 64 records in 0.125549803 seconds. Throughput is 509.75784 records/second. Loss is 0.082002334. Sequential2290a28's hyper parameters: Current learning rate is 0.010584250635055038. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44672/60000][Iteration 4450][Wall Clock 559.556747611s] Trained 64 records in 0.091667033 seconds. Throughput is 698.179 records/second. Loss is 0.06084497. Sequential2290a28's hyper parameters: Current learning rate is 0.01058313048999894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44736/60000][Iteration 4451][Wall Clock 559.652481813s] Trained 64 records in 0.095734202 seconds. Throughput is 668.51764 records/second. Loss is 0.21609. Sequential2290a28's hyper parameters: Current learning rate is 0.010582010582010581. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 4452][Wall Clock 559.75484912s] Trained 64 records in 0.102367307 seconds. Throughput is 625.19965 records/second. Loss is 0.16163217. Sequential2290a28's hyper parameters: Current learning rate is 0.010580890911014707. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:02 INFO  DistriOptimizer$:408 - [Epoch 5 44864/60000][Iteration 4453][Wall Clock 559.86510246s] Trained 64 records in 0.11025334 seconds. Throughput is 580.48126 records/second. Loss is 0.13441518. Sequential2290a28's hyper parameters: Current learning rate is 0.010579771476936098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 44928/60000][Iteration 4454][Wall Clock 560.048667365s] Trained 64 records in 0.183564905 seconds. Throughput is 348.65054 records/second. Loss is 0.14665926. Sequential2290a28's hyper parameters: Current learning rate is 0.010578652279699566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 44992/60000][Iteration 4455][Wall Clock 560.156813359s] Trained 64 records in 0.108145994 seconds. Throughput is 591.7926 records/second. Loss is 0.23684295. Sequential2290a28's hyper parameters: Current learning rate is 0.010577533319229955. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 4456][Wall Clock 560.296824683s] Trained 64 records in 0.140011324 seconds. Throughput is 457.10587 records/second. Loss is 0.28314453. Sequential2290a28's hyper parameters: Current learning rate is 0.010576414595452142. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 45120/60000][Iteration 4457][Wall Clock 560.418563406s] Trained 64 records in 0.121738723 seconds. Throughput is 525.71606 records/second. Loss is 0.14135708. Sequential2290a28's hyper parameters: Current learning rate is 0.010575296108291032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 45184/60000][Iteration 4458][Wall Clock 560.525782262s] Trained 64 records in 0.107218856 seconds. Throughput is 596.9099 records/second. Loss is 0.17249133. Sequential2290a28's hyper parameters: Current learning rate is 0.010574177857671566. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 45248/60000][Iteration 4459][Wall Clock 560.634254523s] Trained 64 records in 0.108472261 seconds. Throughput is 590.01263 records/second. Loss is 0.06886514. Sequential2290a28's hyper parameters: Current learning rate is 0.010573059843518714. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 4460][Wall Clock 560.734456469s] Trained 64 records in 0.100201946 seconds. Throughput is 638.71014 records/second. Loss is 0.043120436. Sequential2290a28's hyper parameters: Current learning rate is 0.01057194206575748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:03 INFO  DistriOptimizer$:408 - [Epoch 5 45376/60000][Iteration 4461][Wall Clock 560.879203042s] Trained 64 records in 0.144746573 seconds. Throughput is 442.1521 records/second. Loss is 0.11722532. Sequential2290a28's hyper parameters: Current learning rate is 0.010570824524312896. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45440/60000][Iteration 4462][Wall Clock 560.984842395s] Trained 64 records in 0.105639353 seconds. Throughput is 605.83484 records/second. Loss is 0.08699856. Sequential2290a28's hyper parameters: Current learning rate is 0.010569707219110032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45504/60000][Iteration 4463][Wall Clock 561.084233121s] Trained 64 records in 0.099390726 seconds. Throughput is 643.9233 records/second. Loss is 0.14333051. Sequential2290a28's hyper parameters: Current learning rate is 0.01056859015007398. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 4464][Wall Clock 561.234839035s] Trained 64 records in 0.150605914 seconds. Throughput is 424.9501 records/second. Loss is 0.2306098. Sequential2290a28's hyper parameters: Current learning rate is 0.010567473317129874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45632/60000][Iteration 4465][Wall Clock 561.358781633s] Trained 64 records in 0.123942598 seconds. Throughput is 516.36804 records/second. Loss is 0.16511759. Sequential2290a28's hyper parameters: Current learning rate is 0.010566356720202874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45696/60000][Iteration 4466][Wall Clock 561.508801809s] Trained 64 records in 0.150020176 seconds. Throughput is 426.60925 records/second. Loss is 0.1094529. Sequential2290a28's hyper parameters: Current learning rate is 0.010565240359218173. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45760/60000][Iteration 4467][Wall Clock 561.590545232s] Trained 64 records in 0.081743423 seconds. Throughput is 782.93756 records/second. Loss is 0.1094019. Sequential2290a28's hyper parameters: Current learning rate is 0.010564124234100993. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 4468][Wall Clock 561.748994414s] Trained 64 records in 0.158449182 seconds. Throughput is 403.91498 records/second. Loss is 0.19351488. Sequential2290a28's hyper parameters: Current learning rate is 0.010563008344776591. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:04 INFO  DistriOptimizer$:408 - [Epoch 5 45888/60000][Iteration 4469][Wall Clock 561.899056438s] Trained 64 records in 0.150062024 seconds. Throughput is 426.49033 records/second. Loss is 0.031166192. Sequential2290a28's hyper parameters: Current learning rate is 0.010561892691170256. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 45952/60000][Iteration 4470][Wall Clock 562.085023115s] Trained 64 records in 0.185966677 seconds. Throughput is 344.14767 records/second. Loss is 0.29303324. Sequential2290a28's hyper parameters: Current learning rate is 0.010560777273207308. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46016/60000][Iteration 4471][Wall Clock 562.180348115s] Trained 64 records in 0.095325 seconds. Throughput is 671.3873 records/second. Loss is 0.19251171. Sequential2290a28's hyper parameters: Current learning rate is 0.010559662090813094. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 4472][Wall Clock 562.30084585s] Trained 64 records in 0.120497735 seconds. Throughput is 531.1303 records/second. Loss is 0.16781734. Sequential2290a28's hyper parameters: Current learning rate is 0.010558547143912998. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46144/60000][Iteration 4473][Wall Clock 562.393248876s] Trained 64 records in 0.092403026 seconds. Throughput is 692.61804 records/second. Loss is 0.13844737. Sequential2290a28's hyper parameters: Current learning rate is 0.010557432432432432. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46208/60000][Iteration 4474][Wall Clock 562.509193328s] Trained 64 records in 0.115944452 seconds. Throughput is 551.98846 records/second. Loss is 0.18768694. Sequential2290a28's hyper parameters: Current learning rate is 0.010556317956296843. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46272/60000][Iteration 4475][Wall Clock 562.612109875s] Trained 64 records in 0.102916547 seconds. Throughput is 621.8631 records/second. Loss is 0.107828125. Sequential2290a28's hyper parameters: Current learning rate is 0.010555203715431708. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 4476][Wall Clock 562.706467243s] Trained 64 records in 0.094357368 seconds. Throughput is 678.2724 records/second. Loss is 0.14647105. Sequential2290a28's hyper parameters: Current learning rate is 0.010554089709762533. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:05 INFO  DistriOptimizer$:408 - [Epoch 5 46400/60000][Iteration 4477][Wall Clock 562.856453847s] Trained 64 records in 0.149986604 seconds. Throughput is 426.70477 records/second. Loss is 0.16405043. Sequential2290a28's hyper parameters: Current learning rate is 0.01055297593921486. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46464/60000][Iteration 4478][Wall Clock 562.961569474s] Trained 64 records in 0.105115627 seconds. Throughput is 608.85333 records/second. Loss is 0.11108652. Sequential2290a28's hyper parameters: Current learning rate is 0.010551862403714255. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46528/60000][Iteration 4479][Wall Clock 563.03500874s] Trained 64 records in 0.073439266 seconds. Throughput is 871.46844 records/second. Loss is 0.07305463. Sequential2290a28's hyper parameters: Current learning rate is 0.010550749103186327. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 4480][Wall Clock 563.173644435s] Trained 64 records in 0.138635695 seconds. Throughput is 461.64157 records/second. Loss is 0.09727074. Sequential2290a28's hyper parameters: Current learning rate is 0.010549636037556705. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46656/60000][Iteration 4481][Wall Clock 563.288445746s] Trained 64 records in 0.114801311 seconds. Throughput is 557.4849 records/second. Loss is 0.29609692. Sequential2290a28's hyper parameters: Current learning rate is 0.010548523206751056. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46720/60000][Iteration 4482][Wall Clock 563.432222335s] Trained 64 records in 0.143776589 seconds. Throughput is 445.13504 records/second. Loss is 0.20995292. Sequential2290a28's hyper parameters: Current learning rate is 0.010547410610695074. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46784/60000][Iteration 4483][Wall Clock 563.552787214s] Trained 64 records in 0.120564879 seconds. Throughput is 530.83453 records/second. Loss is 0.0910381. Sequential2290a28's hyper parameters: Current learning rate is 0.01054629824931449. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 4484][Wall Clock 563.650797794s] Trained 64 records in 0.09801058 seconds. Throughput is 652.9907 records/second. Loss is 0.09431765. Sequential2290a28's hyper parameters: Current learning rate is 0.010545186122535062. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46912/60000][Iteration 4485][Wall Clock 563.749012992s] Trained 64 records in 0.098215198 seconds. Throughput is 651.6303 records/second. Loss is 0.12758607. Sequential2290a28's hyper parameters: Current learning rate is 0.010544074230282582. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:06 INFO  DistriOptimizer$:408 - [Epoch 5 46976/60000][Iteration 4486][Wall Clock 563.85356034s] Trained 64 records in 0.104547348 seconds. Throughput is 612.1628 records/second. Loss is 0.2260886. Sequential2290a28's hyper parameters: Current learning rate is 0.010542962572482868. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47040/60000][Iteration 4487][Wall Clock 563.944846531s] Trained 64 records in 0.091286191 seconds. Throughput is 701.0918 records/second. Loss is 0.064798. Sequential2290a28's hyper parameters: Current learning rate is 0.010541851149061775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 4488][Wall Clock 564.038769563s] Trained 64 records in 0.093923032 seconds. Throughput is 681.409 records/second. Loss is 0.16329974. Sequential2290a28's hyper parameters: Current learning rate is 0.010540739959945188. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47168/60000][Iteration 4489][Wall Clock 564.161528443s] Trained 64 records in 0.12275888 seconds. Throughput is 521.3472 records/second. Loss is 0.12864652. Sequential2290a28's hyper parameters: Current learning rate is 0.010539629005059021. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47232/60000][Iteration 4490][Wall Clock 564.286067317s] Trained 64 records in 0.124538874 seconds. Throughput is 513.89575 records/second. Loss is 0.14251226. Sequential2290a28's hyper parameters: Current learning rate is 0.010538518284329222. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47296/60000][Iteration 4491][Wall Clock 564.404543855s] Trained 64 records in 0.118476538 seconds. Throughput is 540.19135 records/second. Loss is 0.11110856. Sequential2290a28's hyper parameters: Current learning rate is 0.01053740779768177. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 4492][Wall Clock 564.494611725s] Trained 64 records in 0.09006787 seconds. Throughput is 710.57526 records/second. Loss is 0.13874933. Sequential2290a28's hyper parameters: Current learning rate is 0.010536297545042672. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47424/60000][Iteration 4493][Wall Clock 564.583326027s] Trained 64 records in 0.088714302 seconds. Throughput is 721.41693 records/second. Loss is 0.029096246. Sequential2290a28's hyper parameters: Current learning rate is 0.01053518752633797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47488/60000][Iteration 4494][Wall Clock 564.714900614s] Trained 64 records in 0.131574587 seconds. Throughput is 486.41614 records/second. Loss is 0.1011641. Sequential2290a28's hyper parameters: Current learning rate is 0.010534077741493732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:07 INFO  DistriOptimizer$:408 - [Epoch 5 47552/60000][Iteration 4495][Wall Clock 564.866226419s] Trained 64 records in 0.151325805 seconds. Throughput is 422.92853 records/second. Loss is 0.3932363. Sequential2290a28's hyper parameters: Current learning rate is 0.010532968190436065. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 4496][Wall Clock 564.94167972s] Trained 64 records in 0.075453301 seconds. Throughput is 848.2067 records/second. Loss is 0.20676367. Sequential2290a28's hyper parameters: Current learning rate is 0.010531858873091101. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 47680/60000][Iteration 4497][Wall Clock 565.035036222s] Trained 64 records in 0.093356502 seconds. Throughput is 685.54407 records/second. Loss is 0.13221379. Sequential2290a28's hyper parameters: Current learning rate is 0.010530749789385004. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 47744/60000][Iteration 4498][Wall Clock 565.125709731s] Trained 64 records in 0.090673509 seconds. Throughput is 705.8291 records/second. Loss is 0.21954295. Sequential2290a28's hyper parameters: Current learning rate is 0.010529640939243972. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 47808/60000][Iteration 4499][Wall Clock 565.275941417s] Trained 64 records in 0.150231686 seconds. Throughput is 426.00867 records/second. Loss is 0.07610003. Sequential2290a28's hyper parameters: Current learning rate is 0.010528532322594231. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 4500][Wall Clock 565.40600096s] Trained 64 records in 0.130059543 seconds. Throughput is 492.0823 records/second. Loss is 0.19501497. Sequential2290a28's hyper parameters: Current learning rate is 0.010527423939362039. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 47936/60000][Iteration 4501][Wall Clock 565.521206061s] Trained 64 records in 0.115205101 seconds. Throughput is 555.53094 records/second. Loss is 0.17004415. Sequential2290a28's hyper parameters: Current learning rate is 0.010526315789473686. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 48000/60000][Iteration 4502][Wall Clock 565.632305646s] Trained 64 records in 0.111099585 seconds. Throughput is 576.05975 records/second. Loss is 0.078438364. Sequential2290a28's hyper parameters: Current learning rate is 0.01052520787285549. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 48064/60000][Iteration 4503][Wall Clock 565.767582466s] Trained 64 records in 0.13527682 seconds. Throughput is 473.10394 records/second. Loss is 0.189865. Sequential2290a28's hyper parameters: Current learning rate is 0.010524100189433803. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:08 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 4504][Wall Clock 565.880128442s] Trained 64 records in 0.112545976 seconds. Throughput is 568.6565 records/second. Loss is 0.19676444. Sequential2290a28's hyper parameters: Current learning rate is 0.01052299273913501. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48192/60000][Iteration 4505][Wall Clock 565.998457361s] Trained 64 records in 0.118328919 seconds. Throughput is 540.86523 records/second. Loss is 0.088723555. Sequential2290a28's hyper parameters: Current learning rate is 0.010521885521885523. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48256/60000][Iteration 4506][Wall Clock 566.1461751s] Trained 64 records in 0.147717739 seconds. Throughput is 433.25873 records/second. Loss is 0.08897408. Sequential2290a28's hyper parameters: Current learning rate is 0.010520778537611783. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48320/60000][Iteration 4507][Wall Clock 566.231076439s] Trained 64 records in 0.084901339 seconds. Throughput is 753.81616 records/second. Loss is 0.057651713. Sequential2290a28's hyper parameters: Current learning rate is 0.01051967178624027. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 4508][Wall Clock 566.329970332s] Trained 64 records in 0.098893893 seconds. Throughput is 647.15826 records/second. Loss is 0.21803883. Sequential2290a28's hyper parameters: Current learning rate is 0.010518565267697485. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48448/60000][Iteration 4509][Wall Clock 566.472630177s] Trained 64 records in 0.142659845 seconds. Throughput is 448.6196 records/second. Loss is 0.16032448. Sequential2290a28's hyper parameters: Current learning rate is 0.01051745898190997. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48512/60000][Iteration 4510][Wall Clock 566.561335558s] Trained 64 records in 0.088705381 seconds. Throughput is 721.48944 records/second. Loss is 0.12530604. Sequential2290a28's hyper parameters: Current learning rate is 0.01051635292880429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48576/60000][Iteration 4511][Wall Clock 566.728568351s] Trained 64 records in 0.167232793 seconds. Throughput is 382.70004 records/second. Loss is 0.2422262. Sequential2290a28's hyper parameters: Current learning rate is 0.010515247108307044. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:09 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 4512][Wall Clock 566.870726829s] Trained 64 records in 0.142158478 seconds. Throughput is 450.20178 records/second. Loss is 0.106011346. Sequential2290a28's hyper parameters: Current learning rate is 0.010514141520344864. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:10 INFO  DistriOptimizer$:408 - [Epoch 5 48704/60000][Iteration 4513][Wall Clock 567.001861145s] Trained 64 records in 0.131134316 seconds. Throughput is 488.04922 records/second. Loss is 0.0916462. Sequential2290a28's hyper parameters: Current learning rate is 0.010513036164844407. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:10 INFO  DistriOptimizer$:408 - [Epoch 5 48768/60000][Iteration 4514][Wall Clock 567.141465489s] Trained 64 records in 0.139604344 seconds. Throughput is 458.43845 records/second. Loss is 0.18127804. Sequential2290a28's hyper parameters: Current learning rate is 0.010511931041732366. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:10 INFO  DistriOptimizer$:408 - [Epoch 5 48832/60000][Iteration 4515][Wall Clock 567.299626413s] Trained 64 records in 0.158160924 seconds. Throughput is 404.65115 records/second. Loss is 0.12346537. Sequential2290a28's hyper parameters: Current learning rate is 0.010510826150935463. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:10 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 4516][Wall Clock 567.451227425s] Trained 64 records in 0.151601012 seconds. Throughput is 422.16077 records/second. Loss is 0.09977095. Sequential2290a28's hyper parameters: Current learning rate is 0.010509721492380452. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:10 INFO  DistriOptimizer$:408 - [Epoch 5 48960/60000][Iteration 4517][Wall Clock 567.691484133s] Trained 64 records in 0.240256708 seconds. Throughput is 266.38174 records/second. Loss is 0.15914783. Sequential2290a28's hyper parameters: Current learning rate is 0.010508617065994116. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:10 INFO  DistriOptimizer$:408 - [Epoch 5 49024/60000][Iteration 4518][Wall Clock 567.885292254s] Trained 64 records in 0.193808121 seconds. Throughput is 330.2235 records/second. Loss is 0.049186036. Sequential2290a28's hyper parameters: Current learning rate is 0.010507512871703269. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:11 INFO  DistriOptimizer$:408 - [Epoch 5 49088/60000][Iteration 4519][Wall Clock 568.092121286s] Trained 64 records in 0.206829032 seconds. Throughput is 309.43433 records/second. Loss is 0.20097771. Sequential2290a28's hyper parameters: Current learning rate is 0.010506408909434755. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:11 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 4520][Wall Clock 568.40408652s] Trained 64 records in 0.311965234 seconds. Throughput is 205.15106 records/second. Loss is 0.14101207. Sequential2290a28's hyper parameters: Current learning rate is 0.010505305179115455. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:11 INFO  DistriOptimizer$:408 - [Epoch 5 49216/60000][Iteration 4521][Wall Clock 568.483323151s] Trained 64 records in 0.079236631 seconds. Throughput is 807.7072 records/second. Loss is 0.18824087. Sequential2290a28's hyper parameters: Current learning rate is 0.01050420168067227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:11 INFO  DistriOptimizer$:408 - [Epoch 5 49280/60000][Iteration 4522][Wall Clock 568.642722183s] Trained 64 records in 0.159399032 seconds. Throughput is 401.5081 records/second. Loss is 0.090457. Sequential2290a28's hyper parameters: Current learning rate is 0.01050309841403214. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:11 INFO  DistriOptimizer$:408 - [Epoch 5 49344/60000][Iteration 4523][Wall Clock 568.824165086s] Trained 64 records in 0.181442903 seconds. Throughput is 352.72806 records/second. Loss is 0.07433479. Sequential2290a28's hyper parameters: Current learning rate is 0.010501995379122032. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 4524][Wall Clock 569.020838893s] Trained 64 records in 0.196673807 seconds. Throughput is 325.4119 records/second. Loss is 0.085943416. Sequential2290a28's hyper parameters: Current learning rate is 0.01050089257586895. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49472/60000][Iteration 4525][Wall Clock 569.120390114s] Trained 64 records in 0.099551221 seconds. Throughput is 642.88513 records/second. Loss is 0.12619829. Sequential2290a28's hyper parameters: Current learning rate is 0.010499790004199917. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49536/60000][Iteration 4526][Wall Clock 569.23650263s] Trained 64 records in 0.116112516 seconds. Throughput is 551.1895 records/second. Loss is 0.08193134. Sequential2290a28's hyper parameters: Current learning rate is 0.010498687664041995. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49600/60000][Iteration 4527][Wall Clock 569.33866446s] Trained 64 records in 0.10216183 seconds. Throughput is 626.45703 records/second. Loss is 0.10838473. Sequential2290a28's hyper parameters: Current learning rate is 0.010497585555322276. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 4528][Wall Clock 569.476719706s] Trained 64 records in 0.138055246 seconds. Throughput is 463.58252 records/second. Loss is 0.08464798. Sequential2290a28's hyper parameters: Current learning rate is 0.01049648367796788. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49728/60000][Iteration 4529][Wall Clock 569.609295142s] Trained 64 records in 0.132575436 seconds. Throughput is 482.74402 records/second. Loss is 0.18741071. Sequential2290a28's hyper parameters: Current learning rate is 0.01049538203190596. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:12 INFO  DistriOptimizer$:408 - [Epoch 5 49792/60000][Iteration 4530][Wall Clock 569.753231241s] Trained 64 records in 0.143936099 seconds. Throughput is 444.64175 records/second. Loss is 0.16469868. Sequential2290a28's hyper parameters: Current learning rate is 0.0104942806170637. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 49856/60000][Iteration 4531][Wall Clock 569.96573188s] Trained 64 records in 0.212500639 seconds. Throughput is 301.17557 records/second. Loss is 0.0988747. Sequential2290a28's hyper parameters: Current learning rate is 0.01049317943336831. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 4532][Wall Clock 570.058015152s] Trained 64 records in 0.092283272 seconds. Throughput is 693.5168 records/second. Loss is 0.2493102. Sequential2290a28's hyper parameters: Current learning rate is 0.010492078480747036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 49984/60000][Iteration 4533][Wall Clock 570.20206359s] Trained 64 records in 0.144048438 seconds. Throughput is 444.29498 records/second. Loss is 0.25947776. Sequential2290a28's hyper parameters: Current learning rate is 0.01049097775912715. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 50048/60000][Iteration 4534][Wall Clock 570.352217614s] Trained 64 records in 0.150154024 seconds. Throughput is 426.229 records/second. Loss is 0.11226695. Sequential2290a28's hyper parameters: Current learning rate is 0.010489877268435959. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 50112/60000][Iteration 4535][Wall Clock 570.53954998s] Trained 64 records in 0.187332366 seconds. Throughput is 341.6388 records/second. Loss is 0.10943759. Sequential2290a28's hyper parameters: Current learning rate is 0.010488777008600797. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 4536][Wall Clock 570.768163528s] Trained 64 records in 0.228613548 seconds. Throughput is 279.9484 records/second. Loss is 0.118597955. Sequential2290a28's hyper parameters: Current learning rate is 0.01048767697954903. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:13 INFO  DistriOptimizer$:408 - [Epoch 5 50240/60000][Iteration 4537][Wall Clock 570.851673888s] Trained 64 records in 0.08351036 seconds. Throughput is 766.37195 records/second. Loss is 0.0568084. Sequential2290a28's hyper parameters: Current learning rate is 0.010486577181208054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50304/60000][Iteration 4538][Wall Clock 570.965662645s] Trained 64 records in 0.113988757 seconds. Throughput is 561.45886 records/second. Loss is 0.081881784. Sequential2290a28's hyper parameters: Current learning rate is 0.010485477613505295. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50368/60000][Iteration 4539][Wall Clock 571.070937973s] Trained 64 records in 0.105275328 seconds. Throughput is 607.92975 records/second. Loss is 0.10463606. Sequential2290a28's hyper parameters: Current learning rate is 0.010484378276368212. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 4540][Wall Clock 571.181874279s] Trained 64 records in 0.110936306 seconds. Throughput is 576.9076 records/second. Loss is 0.2029035. Sequential2290a28's hyper parameters: Current learning rate is 0.01048327916972429. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50496/60000][Iteration 4541][Wall Clock 571.34195068s] Trained 64 records in 0.160076401 seconds. Throughput is 399.8091 records/second. Loss is 0.091567785. Sequential2290a28's hyper parameters: Current learning rate is 0.010482180293501049. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50560/60000][Iteration 4542][Wall Clock 571.466226155s] Trained 64 records in 0.124275475 seconds. Throughput is 514.9849 records/second. Loss is 0.098332316. Sequential2290a28's hyper parameters: Current learning rate is 0.010481081647626036. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50624/60000][Iteration 4543][Wall Clock 571.616044726s] Trained 64 records in 0.149818571 seconds. Throughput is 427.18335 records/second. Loss is 0.10979934. Sequential2290a28's hyper parameters: Current learning rate is 0.010479983232026828. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 4544][Wall Clock 571.744099301s] Trained 64 records in 0.128054575 seconds. Throughput is 499.7869 records/second. Loss is 0.06866742. Sequential2290a28's hyper parameters: Current learning rate is 0.010478885046631038. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:14 INFO  DistriOptimizer$:408 - [Epoch 5 50752/60000][Iteration 4545][Wall Clock 571.852326547s] Trained 64 records in 0.108227246 seconds. Throughput is 591.3483 records/second. Loss is 0.24163423. Sequential2290a28's hyper parameters: Current learning rate is 0.010477787091366304. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 50816/60000][Iteration 4546][Wall Clock 572.022930959s] Trained 64 records in 0.170604412 seconds. Throughput is 375.13684 records/second. Loss is 0.07045722. Sequential2290a28's hyper parameters: Current learning rate is 0.010476689366160294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 50880/60000][Iteration 4547][Wall Clock 572.181823801s] Trained 64 records in 0.158892842 seconds. Throughput is 402.7872 records/second. Loss is 0.19777617. Sequential2290a28's hyper parameters: Current learning rate is 0.010475591870940708. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 4548][Wall Clock 572.294456707s] Trained 64 records in 0.112632906 seconds. Throughput is 568.2176 records/second. Loss is 0.073386915. Sequential2290a28's hyper parameters: Current learning rate is 0.010474494605635277. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 51008/60000][Iteration 4549][Wall Clock 572.380432731s] Trained 64 records in 0.085976024 seconds. Throughput is 744.39355 records/second. Loss is 0.10078297. Sequential2290a28's hyper parameters: Current learning rate is 0.010473397570171763. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 51072/60000][Iteration 4550][Wall Clock 572.458805675s] Trained 64 records in 0.078372944 seconds. Throughput is 816.6084 records/second. Loss is 0.09376299. Sequential2290a28's hyper parameters: Current learning rate is 0.010472300764477955. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 51136/60000][Iteration 4551][Wall Clock 572.555023904s] Trained 64 records in 0.096218229 seconds. Throughput is 665.1546 records/second. Loss is 0.10424068. Sequential2290a28's hyper parameters: Current learning rate is 0.010471204188481674. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 4552][Wall Clock 572.640491521s] Trained 64 records in 0.085467617 seconds. Throughput is 748.82166 records/second. Loss is 0.28207418. Sequential2290a28's hyper parameters: Current learning rate is 0.010470107842110773. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:15 INFO  DistriOptimizer$:408 - [Epoch 5 51264/60000][Iteration 4553][Wall Clock 572.780204932s] Trained 64 records in 0.139713411 seconds. Throughput is 458.0806 records/second. Loss is 0.13421786. Sequential2290a28's hyper parameters: Current learning rate is 0.010469011725293131. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51328/60000][Iteration 4554][Wall Clock 572.929816684s] Trained 64 records in 0.149611752 seconds. Throughput is 427.77386 records/second. Loss is 0.13894172. Sequential2290a28's hyper parameters: Current learning rate is 0.010467915837956662. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51392/60000][Iteration 4555][Wall Clock 573.081744054s] Trained 64 records in 0.15192737 seconds. Throughput is 421.25394 records/second. Loss is 0.09810179. Sequential2290a28's hyper parameters: Current learning rate is 0.010466820180029307. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 4556][Wall Clock 573.16546215s] Trained 64 records in 0.083718096 seconds. Throughput is 764.4703 records/second. Loss is 0.10170031. Sequential2290a28's hyper parameters: Current learning rate is 0.010465724751439037. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51520/60000][Iteration 4557][Wall Clock 573.315126457s] Trained 64 records in 0.149664307 seconds. Throughput is 427.62366 records/second. Loss is 0.16381086. Sequential2290a28's hyper parameters: Current learning rate is 0.010464629552113856. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51584/60000][Iteration 4558][Wall Clock 573.410081117s] Trained 64 records in 0.09495466 seconds. Throughput is 674.00586 records/second. Loss is 0.1353218. Sequential2290a28's hyper parameters: Current learning rate is 0.010463534581981794. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51648/60000][Iteration 4559][Wall Clock 573.567011316s] Trained 64 records in 0.156930199 seconds. Throughput is 407.82465 records/second. Loss is 0.07553309. Sequential2290a28's hyper parameters: Current learning rate is 0.010462439840970915. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 4560][Wall Clock 573.668081733s] Trained 64 records in 0.101070417 seconds. Throughput is 633.22186 records/second. Loss is 0.16898471. Sequential2290a28's hyper parameters: Current learning rate is 0.010461345329009311. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:16 INFO  DistriOptimizer$:408 - [Epoch 5 51776/60000][Iteration 4561][Wall Clock 573.801188164s] Trained 64 records in 0.133106431 seconds. Throughput is 480.81827 records/second. Loss is 0.06801698. Sequential2290a28's hyper parameters: Current learning rate is 0.010460251046025106. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 51840/60000][Iteration 4562][Wall Clock 573.93498055s] Trained 64 records in 0.133792386 seconds. Throughput is 478.3531 records/second. Loss is 0.05673975. Sequential2290a28's hyper parameters: Current learning rate is 0.01045915699194645. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 51904/60000][Iteration 4563][Wall Clock 574.052387466s] Trained 64 records in 0.117406916 seconds. Throughput is 545.1127 records/second. Loss is 0.15318412. Sequential2290a28's hyper parameters: Current learning rate is 0.010458063166701528. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 4564][Wall Clock 574.177566214s] Trained 64 records in 0.125178748 seconds. Throughput is 511.26886 records/second. Loss is 0.16892502. Sequential2290a28's hyper parameters: Current learning rate is 0.010456969570218551. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 52032/60000][Iteration 4565][Wall Clock 574.260194854s] Trained 64 records in 0.08262864 seconds. Throughput is 774.54987 records/second. Loss is 0.11656015. Sequential2290a28's hyper parameters: Current learning rate is 0.010455876202425763. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 52096/60000][Iteration 4566][Wall Clock 574.415416264s] Trained 64 records in 0.15522141 seconds. Throughput is 412.31427 records/second. Loss is 0.14415585. Sequential2290a28's hyper parameters: Current learning rate is 0.010454783063251438. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 52160/60000][Iteration 4567][Wall Clock 574.562615103s] Trained 64 records in 0.147198839 seconds. Throughput is 434.78604 records/second. Loss is 0.06695067. Sequential2290a28's hyper parameters: Current learning rate is 0.010453690152623877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 4568][Wall Clock 574.665490909s] Trained 64 records in 0.102875806 seconds. Throughput is 622.1093 records/second. Loss is 0.11906129. Sequential2290a28's hyper parameters: Current learning rate is 0.010452597470471413. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:17 INFO  DistriOptimizer$:408 - [Epoch 5 52288/60000][Iteration 4569][Wall Clock 574.753253799s] Trained 64 records in 0.08776289 seconds. Throughput is 729.2376 records/second. Loss is 0.11721584. Sequential2290a28's hyper parameters: Current learning rate is 0.010451505016722408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52352/60000][Iteration 4570][Wall Clock 574.874506533s] Trained 64 records in 0.121252734 seconds. Throughput is 527.8232 records/second. Loss is 0.07894255. Sequential2290a28's hyper parameters: Current learning rate is 0.010450412791305257. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52416/60000][Iteration 4571][Wall Clock 575.065631357s] Trained 64 records in 0.191124824 seconds. Throughput is 334.85968 records/second. Loss is 0.08810577. Sequential2290a28's hyper parameters: Current learning rate is 0.01044932079414838. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 4572][Wall Clock 575.215518824s] Trained 64 records in 0.149887467 seconds. Throughput is 426.987 records/second. Loss is 0.2727946. Sequential2290a28's hyper parameters: Current learning rate is 0.010448229025180231. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52544/60000][Iteration 4573][Wall Clock 575.335617316s] Trained 64 records in 0.120098492 seconds. Throughput is 532.89594 records/second. Loss is 0.20515406. Sequential2290a28's hyper parameters: Current learning rate is 0.010447137484329294. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52608/60000][Iteration 4574][Wall Clock 575.435562293s] Trained 64 records in 0.099944977 seconds. Throughput is 640.35236 records/second. Loss is 0.034344085. Sequential2290a28's hyper parameters: Current learning rate is 0.010446046171524078. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52672/60000][Iteration 4575][Wall Clock 575.578116162s] Trained 64 records in 0.142553869 seconds. Throughput is 448.9531 records/second. Loss is 0.056287937. Sequential2290a28's hyper parameters: Current learning rate is 0.010444955086693127. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 4576][Wall Clock 575.674305562s] Trained 64 records in 0.0961894 seconds. Throughput is 665.35394 records/second. Loss is 0.18588898. Sequential2290a28's hyper parameters: Current learning rate is 0.010443864229765013. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:18 INFO  DistriOptimizer$:408 - [Epoch 5 52800/60000][Iteration 4577][Wall Clock 575.779346733s] Trained 64 records in 0.105041171 seconds. Throughput is 609.2849 records/second. Loss is 0.15819508. Sequential2290a28's hyper parameters: Current learning rate is 0.010442773600668337. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 52864/60000][Iteration 4578][Wall Clock 575.84491832s] Trained 64 records in 0.065571587 seconds. Throughput is 976.03253 records/second. Loss is 0.10295518. Sequential2290a28's hyper parameters: Current learning rate is 0.010441683199331732. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 52928/60000][Iteration 4579][Wall Clock 576.015174666s] Trained 64 records in 0.170256346 seconds. Throughput is 375.90375 records/second. Loss is 0.105397455. Sequential2290a28's hyper parameters: Current learning rate is 0.01044059302568386. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 4580][Wall Clock 576.143354319s] Trained 64 records in 0.128179653 seconds. Throughput is 499.2992 records/second. Loss is 0.089196965. Sequential2290a28's hyper parameters: Current learning rate is 0.010439503079653408. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 53056/60000][Iteration 4581][Wall Clock 576.226676576s] Trained 64 records in 0.083322257 seconds. Throughput is 768.1021 records/second. Loss is 0.2037631. Sequential2290a28's hyper parameters: Current learning rate is 0.010438413361169102. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 53120/60000][Iteration 4582][Wall Clock 576.302348819s] Trained 64 records in 0.075672243 seconds. Throughput is 845.7526 records/second. Loss is 0.088321246. Sequential2290a28's hyper parameters: Current learning rate is 0.010437323870159693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 53184/60000][Iteration 4583][Wall Clock 576.448296509s] Trained 64 records in 0.14594769 seconds. Throughput is 438.51328 records/second. Loss is 0.12861681. Sequential2290a28's hyper parameters: Current learning rate is 0.010436234606553955. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 4584][Wall Clock 576.57660949s] Trained 64 records in 0.128312981 seconds. Throughput is 498.78043 records/second. Loss is 0.1301549. Sequential2290a28's hyper parameters: Current learning rate is 0.010435145570280704. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 53312/60000][Iteration 4585][Wall Clock 576.697392096s] Trained 64 records in 0.120782606 seconds. Throughput is 529.8776 records/second. Loss is 0.14261451. Sequential2290a28's hyper parameters: Current learning rate is 0.010434056761268781. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:19 INFO  DistriOptimizer$:408 - [Epoch 5 53376/60000][Iteration 4586][Wall Clock 576.821255908s] Trained 64 records in 0.123863812 seconds. Throughput is 516.69653 records/second. Loss is 0.14528054. Sequential2290a28's hyper parameters: Current learning rate is 0.010432968179447054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53440/60000][Iteration 4587][Wall Clock 576.91360904s] Trained 64 records in 0.092353132 seconds. Throughput is 692.9922 records/second. Loss is 0.14687628. Sequential2290a28's hyper parameters: Current learning rate is 0.010431879824744418. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 4588][Wall Clock 576.997136824s] Trained 64 records in 0.083527784 seconds. Throughput is 766.21216 records/second. Loss is 0.15203816. Sequential2290a28's hyper parameters: Current learning rate is 0.01043079169708981. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53568/60000][Iteration 4589][Wall Clock 577.0866838s] Trained 64 records in 0.089546976 seconds. Throughput is 714.7087 records/second. Loss is 0.09371845. Sequential2290a28's hyper parameters: Current learning rate is 0.010429703796412181. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53632/60000][Iteration 4590][Wall Clock 577.177779373s] Trained 64 records in 0.091095573 seconds. Throughput is 702.55884 records/second. Loss is 0.0810592. Sequential2290a28's hyper parameters: Current learning rate is 0.010428616122640524. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53696/60000][Iteration 4591][Wall Clock 577.27843128s] Trained 64 records in 0.100651907 seconds. Throughput is 635.85486 records/second. Loss is 0.08477666. Sequential2290a28's hyper parameters: Current learning rate is 0.010427528675703858. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 4592][Wall Clock 577.39691028s] Trained 64 records in 0.118479 seconds. Throughput is 540.1801 records/second. Loss is 0.060967002. Sequential2290a28's hyper parameters: Current learning rate is 0.010426441455531227. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53824/60000][Iteration 4593][Wall Clock 577.492948001s] Trained 64 records in 0.096037721 seconds. Throughput is 666.4048 records/second. Loss is 0.27748084. Sequential2290a28's hyper parameters: Current learning rate is 0.010425354462051709. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53888/60000][Iteration 4594][Wall Clock 577.583821427s] Trained 64 records in 0.090873426 seconds. Throughput is 704.2763 records/second. Loss is 0.12804143. Sequential2290a28's hyper parameters: Current learning rate is 0.010424267695194412. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:20 INFO  DistriOptimizer$:408 - [Epoch 5 53952/60000][Iteration 4595][Wall Clock 577.748249356s] Trained 64 records in 0.164427929 seconds. Throughput is 389.22827 records/second. Loss is 0.107809894. Sequential2290a28's hyper parameters: Current learning rate is 0.010423181154888472. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 4596][Wall Clock 577.840203952s] Trained 64 records in 0.091954596 seconds. Throughput is 695.99567 records/second. Loss is 0.16480175. Sequential2290a28's hyper parameters: Current learning rate is 0.010422094841063054. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54080/60000][Iteration 4597][Wall Clock 577.941569616s] Trained 64 records in 0.101365664 seconds. Throughput is 631.3775 records/second. Loss is 0.1298487. Sequential2290a28's hyper parameters: Current learning rate is 0.010421008753647354. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54144/60000][Iteration 4598][Wall Clock 578.061253087s] Trained 64 records in 0.119683471 seconds. Throughput is 534.74384 records/second. Loss is 0.14045894. Sequential2290a28's hyper parameters: Current learning rate is 0.010419922892570595. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54208/60000][Iteration 4599][Wall Clock 578.179033397s] Trained 64 records in 0.11778031 seconds. Throughput is 543.3845 records/second. Loss is 0.11897433. Sequential2290a28's hyper parameters: Current learning rate is 0.010418837257762034. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 4600][Wall Clock 578.305167086s] Trained 64 records in 0.126133689 seconds. Throughput is 507.39813 records/second. Loss is 0.1107196. Sequential2290a28's hyper parameters: Current learning rate is 0.010417751849150954. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54336/60000][Iteration 4601][Wall Clock 578.402849206s] Trained 64 records in 0.09768212 seconds. Throughput is 655.18646 records/second. Loss is 0.0846701. Sequential2290a28's hyper parameters: Current learning rate is 0.010416666666666668. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54400/60000][Iteration 4602][Wall Clock 578.53433262s] Trained 64 records in 0.131483414 seconds. Throughput is 486.7534 records/second. Loss is 0.21229193. Sequential2290a28's hyper parameters: Current learning rate is 0.010415581710238517. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54464/60000][Iteration 4603][Wall Clock 578.615090916s] Trained 64 records in 0.080758296 seconds. Throughput is 792.4882 records/second. Loss is 0.08949283. Sequential2290a28's hyper parameters: Current learning rate is 0.010414496979795877. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:21 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 4604][Wall Clock 578.699238192s] Trained 64 records in 0.084147276 seconds. Throughput is 760.5713 records/second. Loss is 0.10429438. Sequential2290a28's hyper parameters: Current learning rate is 0.010413412475268145. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54592/60000][Iteration 4605][Wall Clock 578.832884827s] Trained 64 records in 0.133646635 seconds. Throughput is 478.87476 records/second. Loss is 0.2655776. Sequential2290a28's hyper parameters: Current learning rate is 0.010412328196584756. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54656/60000][Iteration 4606][Wall Clock 578.946291322s] Trained 64 records in 0.113406495 seconds. Throughput is 564.34155 records/second. Loss is 0.052736223. Sequential2290a28's hyper parameters: Current learning rate is 0.010411244143675169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54720/60000][Iteration 4607][Wall Clock 579.064754855s] Trained 64 records in 0.118463533 seconds. Throughput is 540.2507 records/second. Loss is 0.2621062. Sequential2290a28's hyper parameters: Current learning rate is 0.010410160316468874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 4608][Wall Clock 579.148806633s] Trained 64 records in 0.084051778 seconds. Throughput is 761.43536 records/second. Loss is 0.1329832. Sequential2290a28's hyper parameters: Current learning rate is 0.01040907671489539. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54848/60000][Iteration 4609][Wall Clock 579.304648178s] Trained 64 records in 0.155841545 seconds. Throughput is 410.67355 records/second. Loss is 0.05974486. Sequential2290a28's hyper parameters: Current learning rate is 0.010407993338884262. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54912/60000][Iteration 4610][Wall Clock 579.416650349s] Trained 64 records in 0.112002171 seconds. Throughput is 571.4175 records/second. Loss is 0.067191996. Sequential2290a28's hyper parameters: Current learning rate is 0.010406910188365074. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 54976/60000][Iteration 4611][Wall Clock 579.538583277s] Trained 64 records in 0.121932928 seconds. Throughput is 524.8787 records/second. Loss is 0.13234314. Sequential2290a28's hyper parameters: Current learning rate is 0.01040582726326743. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 4612][Wall Clock 579.635182751s] Trained 64 records in 0.096599474 seconds. Throughput is 662.5295 records/second. Loss is 0.13277155. Sequential2290a28's hyper parameters: Current learning rate is 0.010404744563520965. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:22 INFO  DistriOptimizer$:408 - [Epoch 5 55104/60000][Iteration 4613][Wall Clock 579.744816652s] Trained 64 records in 0.109633901 seconds. Throughput is 583.76105 records/second. Loss is 0.15056698. Sequential2290a28's hyper parameters: Current learning rate is 0.010403662089055347. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55168/60000][Iteration 4614][Wall Clock 579.843175752s] Trained 64 records in 0.0983591 seconds. Throughput is 650.67694 records/second. Loss is 0.10934012. Sequential2290a28's hyper parameters: Current learning rate is 0.01040257983980027. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55232/60000][Iteration 4615][Wall Clock 579.934412984s] Trained 64 records in 0.091237232 seconds. Throughput is 701.468 records/second. Loss is 0.096734606. Sequential2290a28's hyper parameters: Current learning rate is 0.01040149781568546. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 4616][Wall Clock 580.051887027s] Trained 64 records in 0.117474043 seconds. Throughput is 544.8012 records/second. Loss is 0.19649865. Sequential2290a28's hyper parameters: Current learning rate is 0.010400416016640665. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55360/60000][Iteration 4617][Wall Clock 580.145087534s] Trained 64 records in 0.093200507 seconds. Throughput is 686.6916 records/second. Loss is 0.08505341. Sequential2290a28's hyper parameters: Current learning rate is 0.010399334442595673. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55424/60000][Iteration 4618][Wall Clock 580.221853225s] Trained 64 records in 0.076765691 seconds. Throughput is 833.70575 records/second. Loss is 0.1269848. Sequential2290a28's hyper parameters: Current learning rate is 0.010398253093480296. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55488/60000][Iteration 4619][Wall Clock 580.360465596s] Trained 64 records in 0.138612371 seconds. Throughput is 461.71924 records/second. Loss is 0.073076785. Sequential2290a28's hyper parameters: Current learning rate is 0.010397171969224371. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 4620][Wall Clock 580.508357296s] Trained 64 records in 0.1478917 seconds. Throughput is 432.74908 records/second. Loss is 0.036285676. Sequential2290a28's hyper parameters: Current learning rate is 0.010396091069757772. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55616/60000][Iteration 4621][Wall Clock 580.632523061s] Trained 64 records in 0.124165765 seconds. Throughput is 515.44 records/second. Loss is 0.2391601. Sequential2290a28's hyper parameters: Current learning rate is 0.010395010395010396. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:23 INFO  DistriOptimizer$:408 - [Epoch 5 55680/60000][Iteration 4622][Wall Clock 580.736209764s] Trained 64 records in 0.103686703 seconds. Throughput is 617.244 records/second. Loss is 0.15521556. Sequential2290a28's hyper parameters: Current learning rate is 0.010393929944912172. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 55744/60000][Iteration 4623][Wall Clock 580.942439159s] Trained 64 records in 0.206229395 seconds. Throughput is 310.33405 records/second. Loss is 0.09726768. Sequential2290a28's hyper parameters: Current learning rate is 0.010392849719393058. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 4624][Wall Clock 581.039187781s] Trained 64 records in 0.096748622 seconds. Throughput is 661.5081 records/second. Loss is 0.10692861. Sequential2290a28's hyper parameters: Current learning rate is 0.010391769718383041. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 55872/60000][Iteration 4625][Wall Clock 581.143470012s] Trained 64 records in 0.104282231 seconds. Throughput is 613.7191 records/second. Loss is 0.2026625. Sequential2290a28's hyper parameters: Current learning rate is 0.010390689941812137. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 55936/60000][Iteration 4626][Wall Clock 581.238893297s] Trained 64 records in 0.095423285 seconds. Throughput is 670.6958 records/second. Loss is 0.20492812. Sequential2290a28's hyper parameters: Current learning rate is 0.01038961038961039. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 56000/60000][Iteration 4627][Wall Clock 581.321865795s] Trained 64 records in 0.082972498 seconds. Throughput is 771.3399 records/second. Loss is 0.11211563. Sequential2290a28's hyper parameters: Current learning rate is 0.010388531061707874. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 4628][Wall Clock 581.425044774s] Trained 64 records in 0.103178979 seconds. Throughput is 620.2814 records/second. Loss is 0.115081996. Sequential2290a28's hyper parameters: Current learning rate is 0.010387451958034694. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 56128/60000][Iteration 4629][Wall Clock 581.533006249s] Trained 64 records in 0.107961475 seconds. Throughput is 592.8041 records/second. Loss is 0.10286453. Sequential2290a28's hyper parameters: Current learning rate is 0.01038637307852098. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 56192/60000][Iteration 4630][Wall Clock 581.639990389s] Trained 64 records in 0.10698414 seconds. Throughput is 598.21954 records/second. Loss is 0.0803776. Sequential2290a28's hyper parameters: Current learning rate is 0.010385294423096894. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:24 INFO  DistriOptimizer$:408 - [Epoch 5 56256/60000][Iteration 4631][Wall Clock 581.729951772s] Trained 64 records in 0.089961383 seconds. Throughput is 711.4164 records/second. Loss is 0.09287842. Sequential2290a28's hyper parameters: Current learning rate is 0.010384215991692626. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 4632][Wall Clock 581.809768259s] Trained 64 records in 0.079816487 seconds. Throughput is 801.8393 records/second. Loss is 0.078621335. Sequential2290a28's hyper parameters: Current learning rate is 0.010383137784238397. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56384/60000][Iteration 4633][Wall Clock 581.899162656s] Trained 64 records in 0.089394397 seconds. Throughput is 715.9285 records/second. Loss is 0.089373484. Sequential2290a28's hyper parameters: Current learning rate is 0.010382059800664452. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56448/60000][Iteration 4634][Wall Clock 581.983057734s] Trained 64 records in 0.083895078 seconds. Throughput is 762.8576 records/second. Loss is 0.08833497. Sequential2290a28's hyper parameters: Current learning rate is 0.01038098204090107. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56512/60000][Iteration 4635][Wall Clock 582.141107763s] Trained 64 records in 0.158050029 seconds. Throughput is 404.93506 records/second. Loss is 0.09963779. Sequential2290a28's hyper parameters: Current learning rate is 0.010379904504878554. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 4636][Wall Clock 582.257206116s] Trained 64 records in 0.116098353 seconds. Throughput is 551.2568 records/second. Loss is 0.12140815. Sequential2290a28's hyper parameters: Current learning rate is 0.010378827192527244. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56640/60000][Iteration 4637][Wall Clock 582.376574873s] Trained 64 records in 0.119368757 seconds. Throughput is 536.1537 records/second. Loss is 0.15767485. Sequential2290a28's hyper parameters: Current learning rate is 0.0103777501037775. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56704/60000][Iteration 4638][Wall Clock 582.494981962s] Trained 64 records in 0.118407089 seconds. Throughput is 540.5082 records/second. Loss is 0.16114466. Sequential2290a28's hyper parameters: Current learning rate is 0.010376673238559718. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56768/60000][Iteration 4639][Wall Clock 582.617287548s] Trained 64 records in 0.122305586 seconds. Throughput is 523.2794 records/second. Loss is 0.3194053. Sequential2290a28's hyper parameters: Current learning rate is 0.010375596596804317. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:25 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 4640][Wall Clock 582.755163135s] Trained 64 records in 0.137875587 seconds. Throughput is 464.1866 records/second. Loss is 0.24533042. Sequential2290a28's hyper parameters: Current learning rate is 0.010374520178441747. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 56896/60000][Iteration 4641][Wall Clock 582.875205173s] Trained 64 records in 0.120042038 seconds. Throughput is 533.14655 records/second. Loss is 0.18458593. Sequential2290a28's hyper parameters: Current learning rate is 0.010373443983402491. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 56960/60000][Iteration 4642][Wall Clock 582.978549153s] Trained 64 records in 0.10334398 seconds. Throughput is 619.291 records/second. Loss is 0.15546212. Sequential2290a28's hyper parameters: Current learning rate is 0.010372368011617053. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57024/60000][Iteration 4643][Wall Clock 583.076761634s] Trained 64 records in 0.098212481 seconds. Throughput is 651.6483 records/second. Loss is 0.09908368. Sequential2290a28's hyper parameters: Current learning rate is 0.010371292263015973. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 4644][Wall Clock 583.152836738s] Trained 64 records in 0.076075104 seconds. Throughput is 841.27386 records/second. Loss is 0.073953435. Sequential2290a28's hyper parameters: Current learning rate is 0.010370216737529815. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57152/60000][Iteration 4645][Wall Clock 583.254917469s] Trained 64 records in 0.102080731 seconds. Throughput is 626.9548 records/second. Loss is 0.08253319. Sequential2290a28's hyper parameters: Current learning rate is 0.010369141435089175. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57216/60000][Iteration 4646][Wall Clock 583.394553323s] Trained 64 records in 0.139635854 seconds. Throughput is 458.335 records/second. Loss is 0.043714635. Sequential2290a28's hyper parameters: Current learning rate is 0.010368066355624676. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57280/60000][Iteration 4647][Wall Clock 583.494287225s] Trained 64 records in 0.099733902 seconds. Throughput is 641.7076 records/second. Loss is 0.341344. Sequential2290a28's hyper parameters: Current learning rate is 0.01036699149906697. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 4648][Wall Clock 583.570255007s] Trained 64 records in 0.075967782 seconds. Throughput is 842.4624 records/second. Loss is 0.08285507. Sequential2290a28's hyper parameters: Current learning rate is 0.01036591686534674. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57408/60000][Iteration 4649][Wall Clock 583.667512684s] Trained 64 records in 0.097257677 seconds. Throughput is 658.0458 records/second. Loss is 0.38865018. Sequential2290a28's hyper parameters: Current learning rate is 0.010364842454394693. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:26 INFO  DistriOptimizer$:408 - [Epoch 5 57472/60000][Iteration 4650][Wall Clock 583.754750147s] Trained 64 records in 0.087237463 seconds. Throughput is 733.62976 records/second. Loss is 0.18165702. Sequential2290a28's hyper parameters: Current learning rate is 0.010363768266141568. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57536/60000][Iteration 4651][Wall Clock 583.849759739s] Trained 64 records in 0.095009592 seconds. Throughput is 673.61615 records/second. Loss is 0.18996757. Sequential2290a28's hyper parameters: Current learning rate is 0.010362694300518133. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 4652][Wall Clock 583.94668024s] Trained 64 records in 0.096920501 seconds. Throughput is 660.335 records/second. Loss is 0.1373694. Sequential2290a28's hyper parameters: Current learning rate is 0.010361620557455185. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57664/60000][Iteration 4653][Wall Clock 584.057214609s] Trained 64 records in 0.110534369 seconds. Throughput is 579.00543 records/second. Loss is 0.1736224. Sequential2290a28's hyper parameters: Current learning rate is 0.010360547036883548. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57728/60000][Iteration 4654][Wall Clock 584.158472665s] Trained 64 records in 0.101258056 seconds. Throughput is 632.04846 records/second. Loss is 0.02954863. Sequential2290a28's hyper parameters: Current learning rate is 0.010359473738734071. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57792/60000][Iteration 4655][Wall Clock 584.24299127s] Trained 64 records in 0.084518605 seconds. Throughput is 757.22974 records/second. Loss is 0.16207758. Sequential2290a28's hyper parameters: Current learning rate is 0.010358400662937643. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 4656][Wall Clock 584.329388389s] Trained 64 records in 0.086397119 seconds. Throughput is 740.76544 records/second. Loss is 0.115759015. Sequential2290a28's hyper parameters: Current learning rate is 0.010357327809425169. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57920/60000][Iteration 4657][Wall Clock 584.416938801s] Trained 64 records in 0.087550412 seconds. Throughput is 731.00745 records/second. Loss is 0.14552909. Sequential2290a28's hyper parameters: Current learning rate is 0.010356255178127589. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 57984/60000][Iteration 4658][Wall Clock 584.516991343s] Trained 64 records in 0.100052542 seconds. Throughput is 639.6639 records/second. Loss is 0.19698122. Sequential2290a28's hyper parameters: Current learning rate is 0.010355182768975872. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 58048/60000][Iteration 4659][Wall Clock 584.618372142s] Trained 64 records in 0.101380799 seconds. Throughput is 631.2832 records/second. Loss is 0.098343424. Sequential2290a28's hyper parameters: Current learning rate is 0.010354110581901015. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:27 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 4660][Wall Clock 584.702194914s] Trained 64 records in 0.083822772 seconds. Throughput is 763.5157 records/second. Loss is 0.18704107. Sequential2290a28's hyper parameters: Current learning rate is 0.01035303861683404. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58176/60000][Iteration 4661][Wall Clock 584.831293896s] Trained 64 records in 0.129098982 seconds. Throughput is 495.74365 records/second. Loss is 0.16729474. Sequential2290a28's hyper parameters: Current learning rate is 0.010351966873706004. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58240/60000][Iteration 4662][Wall Clock 584.916349831s] Trained 64 records in 0.085055935 seconds. Throughput is 752.44604 records/second. Loss is 0.119028784. Sequential2290a28's hyper parameters: Current learning rate is 0.010350895352447988. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58304/60000][Iteration 4663][Wall Clock 585.042485728s] Trained 64 records in 0.126135897 seconds. Throughput is 507.38925 records/second. Loss is 0.104449496. Sequential2290a28's hyper parameters: Current learning rate is 0.0103498240529911. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 4664][Wall Clock 585.137645813s] Trained 64 records in 0.095160085 seconds. Throughput is 672.5509 records/second. Loss is 0.123796776. Sequential2290a28's hyper parameters: Current learning rate is 0.01034875297526648. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58432/60000][Iteration 4665][Wall Clock 585.24738977s] Trained 64 records in 0.109743957 seconds. Throughput is 583.1756 records/second. Loss is 0.18861347. Sequential2290a28's hyper parameters: Current learning rate is 0.010347682119205297. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58496/60000][Iteration 4666][Wall Clock 585.340460311s] Trained 64 records in 0.093070541 seconds. Throughput is 687.65045 records/second. Loss is 0.1423336. Sequential2290a28's hyper parameters: Current learning rate is 0.010346611484738748. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58560/60000][Iteration 4667][Wall Clock 585.448968402s] Trained 64 records in 0.108508091 seconds. Throughput is 589.8178 records/second. Loss is 0.2410703. Sequential2290a28's hyper parameters: Current learning rate is 0.010345541071798055. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 4668][Wall Clock 585.538990218s] Trained 64 records in 0.090021816 seconds. Throughput is 710.9388 records/second. Loss is 0.11390908. Sequential2290a28's hyper parameters: Current learning rate is 0.010344470880314472. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:28 INFO  DistriOptimizer$:408 - [Epoch 5 58688/60000][Iteration 4669][Wall Clock 585.63682622s] Trained 64 records in 0.097836002 seconds. Throughput is 654.15594 records/second. Loss is 0.105614126. Sequential2290a28's hyper parameters: Current learning rate is 0.01034340091021928. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 58752/60000][Iteration 4670][Wall Clock 585.768090998s] Trained 64 records in 0.131264778 seconds. Throughput is 487.56415 records/second. Loss is 0.16574702. Sequential2290a28's hyper parameters: Current learning rate is 0.010342331161443789. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 58816/60000][Iteration 4671][Wall Clock 585.885123192s] Trained 64 records in 0.117032194 seconds. Throughput is 546.8581 records/second. Loss is 0.18304242. Sequential2290a28's hyper parameters: Current learning rate is 0.010341261633919338. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 4672][Wall Clock 585.965728829s] Trained 64 records in 0.080605637 seconds. Throughput is 793.9892 records/second. Loss is 0.045148555. Sequential2290a28's hyper parameters: Current learning rate is 0.010340192327577293. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 58944/60000][Iteration 4673][Wall Clock 586.054048138s] Trained 64 records in 0.088319309 seconds. Throughput is 724.6434 records/second. Loss is 0.06126693. Sequential2290a28's hyper parameters: Current learning rate is 0.01033912324234905. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 59008/60000][Iteration 4674][Wall Clock 586.123673548s] Trained 64 records in 0.06962541 seconds. Throughput is 919.20465 records/second. Loss is 0.1541892. Sequential2290a28's hyper parameters: Current learning rate is 0.010338054378166029. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 59072/60000][Iteration 4675][Wall Clock 586.2447191s] Trained 64 records in 0.121045552 seconds. Throughput is 528.72656 records/second. Loss is 0.06927806. Sequential2290a28's hyper parameters: Current learning rate is 0.010336985734959685. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 4676][Wall Clock 586.400234817s] Trained 64 records in 0.155515717 seconds. Throughput is 411.53397 records/second. Loss is 0.24043788. Sequential2290a28's hyper parameters: Current learning rate is 0.0103359173126615. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 59200/60000][Iteration 4677][Wall Clock 586.49072397s] Trained 64 records in 0.090489153 seconds. Throughput is 707.2671 records/second. Loss is 0.08267752. Sequential2290a28's hyper parameters: Current learning rate is 0.010334849111202976. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 59264/60000][Iteration 4678][Wall Clock 586.583961058s] Trained 64 records in 0.093237088 seconds. Throughput is 686.4221 records/second. Loss is 0.2141199. Sequential2290a28's hyper parameters: Current learning rate is 0.010333781130515656. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:29 INFO  DistriOptimizer$:408 - [Epoch 5 59328/60000][Iteration 4679][Wall Clock 586.709829414s] Trained 64 records in 0.125868356 seconds. Throughput is 508.46777 records/second. Loss is 0.1395592. Sequential2290a28's hyper parameters: Current learning rate is 0.010332713370531101. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 4680][Wall Clock 586.833433048s] Trained 64 records in 0.123603634 seconds. Throughput is 517.7841 records/second. Loss is 0.20053084. Sequential2290a28's hyper parameters: Current learning rate is 0.010331645831180907. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59456/60000][Iteration 4681][Wall Clock 586.933114529s] Trained 64 records in 0.099681481 seconds. Throughput is 642.04504 records/second. Loss is 0.2277289. Sequential2290a28's hyper parameters: Current learning rate is 0.010330578512396695. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59520/60000][Iteration 4682][Wall Clock 587.033961223s] Trained 64 records in 0.100846694 seconds. Throughput is 634.62665 records/second. Loss is 0.060202878. Sequential2290a28's hyper parameters: Current learning rate is 0.010329511414110114. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59584/60000][Iteration 4683][Wall Clock 587.174545877s] Trained 64 records in 0.140584654 seconds. Throughput is 455.24173 records/second. Loss is 0.14102739. Sequential2290a28's hyper parameters: Current learning rate is 0.010328444536252842. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 4684][Wall Clock 587.259651157s] Trained 64 records in 0.08510528 seconds. Throughput is 752.00977 records/second. Loss is 0.19020954. Sequential2290a28's hyper parameters: Current learning rate is 0.010327377878756584. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59712/60000][Iteration 4685][Wall Clock 587.355860786s] Trained 64 records in 0.096209629 seconds. Throughput is 665.21405 records/second. Loss is 0.083620384. Sequential2290a28's hyper parameters: Current learning rate is 0.010326311441553077. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59776/60000][Iteration 4686][Wall Clock 587.446115878s] Trained 64 records in 0.090255092 seconds. Throughput is 709.1013 records/second. Loss is 0.18159342. Sequential2290a28's hyper parameters: Current learning rate is 0.010325245224574084. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59840/60000][Iteration 4687][Wall Clock 587.570203601s] Trained 64 records in 0.124087723 seconds. Throughput is 515.76416 records/second. Loss is 0.14346528. Sequential2290a28's hyper parameters: Current learning rate is 0.010324179227751393. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 4688][Wall Clock 587.662882298s] Trained 64 records in 0.092678697 seconds. Throughput is 690.55786 records/second. Loss is 0.14222096. Sequential2290a28's hyper parameters: Current learning rate is 0.010323113451016826. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:30 INFO  DistriOptimizer$:408 - [Epoch 5 59968/60000][Iteration 4689][Wall Clock 587.733582463s] Trained 64 records in 0.070700165 seconds. Throughput is 905.2312 records/second. Loss is 0.21418571. Sequential2290a28's hyper parameters: Current learning rate is 0.010322047894302229. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:31 INFO  DistriOptimizer$:408 - [Epoch 5 60032/60000][Iteration 4690][Wall Clock 587.802854477s] Trained 64 records in 0.069272014 seconds. Throughput is 923.89404 records/second. Loss is 0.20581205. Sequential2290a28's hyper parameters: Current learning rate is 0.010320982557539478. Current dampening is 1.7976931348623157E308.  
2019-10-24 03:23:31 INFO  DistriOptimizer$:452 - [Epoch 5 60032/60000][Iteration 4690][Wall Clock 587.802854477s] Epoch finished. Wall clock time is 589808.235323 ms
2019-10-24 03:23:31 INFO  DistriOptimizer$:111 - [Epoch 5 60032/60000][Iteration 4690][Wall Clock 587.802854477s] Validate model...
2019-10-24 03:23:32 INFO  DistriOptimizer$:178 - [Epoch 5 60032/60000][Iteration 4690][Wall Clock 587.802854477s] validate model throughput is 10722.513 records/second
2019-10-24 03:23:32 INFO  DistriOptimizer$:181 - [Epoch 5 60032/60000][Iteration 4690][Wall Clock 587.802854477s] Top1Accuracy is Accuracy(correct: 9636, count: 10000, accuracy: 0.9636)
2019-10-24 03:23:32 INFO  DistriOptimizer$:221 - [Wall Clock 589.808235323s] Save model to /tmp/lenet5/20191024_031340
2019-10-24 03:23:32 INFO  DistriOptimizer$:226 - [Wall Clock 589.808235323s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@b5fef19 to /tmp/lenet5/20191024_031340
('Extracting', '~/bd/datasets/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.963500022888, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.999400019646, total_num: 10000, method: Top5Accuracy
Evaluated result: 0.124114774168, total_num: 313, method: Loss
