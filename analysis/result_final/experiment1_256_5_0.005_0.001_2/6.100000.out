2019-10-26 12:14:18 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-26 12:14:19 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-26 12:14:19 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-26 12:14:19 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-26 12:14:19 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-26 12:14:19 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-26 12:14:19 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-26 12:14:19 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-26 12:14:19 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43337.
2019-10-26 12:14:19 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-26 12:14:19 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-26 12:14:19 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-26 12:14:19 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-26 12:14:19 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-b779c77a-981f-4054-956c-2acb9884caf4
2019-10-26 12:14:19 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-26 12:14:19 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-26 12:14:19 INFO  log:192 - Logging initialized @1580ms
2019-10-26 12:14:19 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-26 12:14:19 INFO  Server:414 - Started @1634ms
2019-10-26 12:14:19 INFO  AbstractConnector:278 - Started ServerConnector@72928d16{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-26 12:14:19 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@486dff93{/jobs,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dae0596{/jobs/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cf93b5c{/jobs/job,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fa18210{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@628ebcc7{/stages,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67a85811{/stages/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c4cab77{/stages/stage,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d8c4991{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@14425444{/stages/pool,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b8cf84f{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c48645a{/storage,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53276a83{/storage/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55c1e4d7{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29f330a0{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16a6fb70{/environment,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7e3de855{/environment/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24005c19{/executors,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@14460e09{/executors/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@359a1a8a{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2474232c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@232432f{/static,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f5bd140{/,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76a4bb2e{/api,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@465adb90{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@210708ef{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-26 12:14:19 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4040
2019-10-26 12:14:19 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:43337/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1572092059923
2019-10-26 12:14:19 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:43337/files/lenet5.py with timestamp 1572092059938
2019-10-26 12:14:19 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-12f56479-44ed-4013-a973-e9fd077ca80e/userFiles-8ca22373-d027-41dc-802f-ab631fbb5b67/lenet5.py
2019-10-26 12:14:19 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:43337/files/bigdl-0.8.0-python-api.zip with timestamp 1572092059944
2019-10-26 12:14:19 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-12f56479-44ed-4013-a973-e9fd077ca80e/userFiles-8ca22373-d027-41dc-802f-ab631fbb5b67/bigdl-0.8.0-python-api.zip
2019-10-26 12:14:19 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-26 12:14:20 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 29 ms (0 ms spent in bootstraps)
2019-10-26 12:14:20 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191026121420-0036
2019-10-26 12:14:20 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191026121420-0036/0 on worker-20191026103528-10.164.0.15-38323 (10.164.0.15:38323) with 1 core(s)
2019-10-26 12:14:20 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191026121420-0036/0 on hostPort 10.164.0.15:38323 with 1 core(s), 1024.0 MB RAM
2019-10-26 12:14:20 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42627.
2019-10-26 12:14:20 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:42627
2019-10-26 12:14:20 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-26 12:14:20 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191026121420-0036/0 is now RUNNING
2019-10-26 12:14:20 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 42627, None)
2019-10-26 12:14:20 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:42627 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 42627, None)
2019-10-26 12:14:20 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 42627, None)
2019-10-26 12:14:20 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 42627, None)
2019-10-26 12:14:20 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7fc121f6{/metrics/json,null,AVAILABLE,@Spark}
2019-10-26 12:14:23 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.15:53756) with ID 0
2019-10-26 12:14:23 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-26 12:14:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.15:36299 with 413.9 MB RAM, BlockManagerId(0, 10.164.0.15, 36299, None)
2019-10-26 12:14:23 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-26 12:14:23 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-26 12:14:23 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 19
2019-10-26 12:14:23 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.005
('Extracting', '~/bd/datasets/mnist/train-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-26 12:14:24 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-26 12:14:41 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-26 12:14:42 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-26 12:14:42 INFO  DistriOptimizer$:154 - Count dataset
2019-10-26 12:14:42 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.417386922s
2019-10-26 12:14:42 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-26 12:14:42 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-26 12:14:42 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.018687738s
2019-10-26 12:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 1][Wall Clock 1.120886443s] Trained 256 records in 1.120886443 seconds. Throughput is 228.39067 records/second. Loss is 2.3175285. Sequentialefab4c68's hyper parameters: Current learning rate is 0.005. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:43 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 2][Wall Clock 1.439886479s] Trained 256 records in 0.319000036 seconds. Throughput is 802.50775 records/second. Loss is 2.3141682. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004999000199960009. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 3][Wall Clock 1.751898541s] Trained 256 records in 0.312012062 seconds. Throughput is 820.4811 records/second. Loss is 2.3172126. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004998000799680128. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 4][Wall Clock 2.006379216s] Trained 256 records in 0.254480675 seconds. Throughput is 1005.9702 records/second. Loss is 2.312261. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049970017989206484. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:44 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 5][Wall Clock 2.252364521s] Trained 256 records in 0.245985305 seconds. Throughput is 1040.7126 records/second. Loss is 2.3028972. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004996003197442047. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 6][Wall Clock 2.488906878s] Trained 256 records in 0.236542357 seconds. Throughput is 1082.2585 records/second. Loss is 2.3057091. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004995004995004996. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 7][Wall Clock 2.691601038s] Trained 256 records in 0.20269416 seconds. Throughput is 1262.9866 records/second. Loss is 2.307034. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004994007191370355. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 8][Wall Clock 2.922989471s] Trained 256 records in 0.231388433 seconds. Throughput is 1106.3647 records/second. Loss is 2.3078394. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004993009786299181. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 9][Wall Clock 3.167327841s] Trained 256 records in 0.24433837 seconds. Throughput is 1047.7274 records/second. Loss is 2.306891. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049920127795527154. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:45 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 10][Wall Clock 3.334863696s] Trained 256 records in 0.167535855 seconds. Throughput is 1528.0311 records/second. Loss is 2.311968. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004991016170892394. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 11][Wall Clock 3.494871828s] Trained 256 records in 0.160008132 seconds. Throughput is 1599.9187 records/second. Loss is 2.3073704. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00499001996007984. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 12][Wall Clock 3.666719792s] Trained 256 records in 0.171847964 seconds. Throughput is 1489.6888 records/second. Loss is 2.3119125. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004989024146876871. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 13][Wall Clock 3.836341441s] Trained 256 records in 0.169621649 seconds. Throughput is 1509.2413 records/second. Loss is 2.3031898. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004988028731045491. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 14][Wall Clock 3.981206489s] Trained 256 records in 0.144865048 seconds. Throughput is 1767.1619 records/second. Loss is 2.3110147. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004987033712347896. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 15][Wall Clock 4.236991234s] Trained 256 records in 0.255784745 seconds. Throughput is 1000.84155 records/second. Loss is 2.312744. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004986039090546471. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:46 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 16][Wall Clock 4.389297936s] Trained 256 records in 0.152306702 seconds. Throughput is 1680.819 records/second. Loss is 2.3128133. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049850448654037895. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 17][Wall Clock 4.522077633s] Trained 256 records in 0.132779697 seconds. Throughput is 1928.0055 records/second. Loss is 2.3084722. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004984051036682615. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 18][Wall Clock 4.709086935s] Trained 256 records in 0.187009302 seconds. Throughput is 1368.9159 records/second. Loss is 2.2992225. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004983057604145903. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 19][Wall Clock 4.890251632s] Trained 256 records in 0.181164697 seconds. Throughput is 1413.0789 records/second. Loss is 2.3057656. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004982064567556795. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 20][Wall Clock 5.084247859s] Trained 256 records in 0.193996227 seconds. Throughput is 1319.6133 records/second. Loss is 2.2999969. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004981071926678621. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:47 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 21][Wall Clock 5.291133189s] Trained 256 records in 0.20688533 seconds. Throughput is 1237.4005 records/second. Loss is 2.3065012. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049800796812749. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 22][Wall Clock 5.460933432s] Trained 256 records in 0.169800243 seconds. Throughput is 1507.6539 records/second. Loss is 2.3031192. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004979087831109341. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 23][Wall Clock 5.61598053s] Trained 256 records in 0.155047098 seconds. Throughput is 1651.1111 records/second. Loss is 2.3075762. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004978096375945838. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 24][Wall Clock 5.788304366s] Trained 256 records in 0.172323836 seconds. Throughput is 1485.5751 records/second. Loss is 2.2932107. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004977105315548477. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 25][Wall Clock 5.959478993s] Trained 256 records in 0.171174627 seconds. Throughput is 1495.5487 records/second. Loss is 2.2988105. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004976114649681529. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 26][Wall Clock 6.143827329s] Trained 256 records in 0.184348336 seconds. Throughput is 1388.6754 records/second. Loss is 2.2993686. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049751243781094535. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:48 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 27][Wall Clock 6.37077418s] Trained 256 records in 0.226946851 seconds. Throughput is 1128.0175 records/second. Loss is 2.3010902. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004974134500596895. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 28][Wall Clock 6.543403126s] Trained 256 records in 0.172628946 seconds. Throughput is 1482.9495 records/second. Loss is 2.2998397. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004973145016908693. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 29][Wall Clock 6.754989764s] Trained 256 records in 0.211586638 seconds. Throughput is 1209.9062 records/second. Loss is 2.295131. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004972155926809865. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 30][Wall Clock 6.920938679s] Trained 256 records in 0.165948915 seconds. Throughput is 1542.6434 records/second. Loss is 2.3035455. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00497116723006562. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 31][Wall Clock 7.05969374s] Trained 256 records in 0.138755061 seconds. Throughput is 1844.9777 records/second. Loss is 2.304096. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004970178926441352. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 32][Wall Clock 7.226154436s] Trained 256 records in 0.166460696 seconds. Throughput is 1537.9006 records/second. Loss is 2.3011842. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004969191015702644. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:49 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 33][Wall Clock 7.406175547s] Trained 256 records in 0.180021111 seconds. Throughput is 1422.0554 records/second. Loss is 2.3013988. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004968203497615262. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 34][Wall Clock 7.53442966s] Trained 256 records in 0.128254113 seconds. Throughput is 1996.0374 records/second. Loss is 2.2988887. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004967216371945162. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 35][Wall Clock 7.663878544s] Trained 256 records in 0.129448884 seconds. Throughput is 1977.6145 records/second. Loss is 2.3041632. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004966229638458483. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 36][Wall Clock 7.823450074s] Trained 256 records in 0.15957153 seconds. Throughput is 1604.2963 records/second. Loss is 2.2970815. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00496524329692155. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 37][Wall Clock 7.991363088s] Trained 256 records in 0.167913014 seconds. Throughput is 1524.5989 records/second. Loss is 2.2980907. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004964257347100873. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 38][Wall Clock 8.117640159s] Trained 256 records in 0.126277071 seconds. Throughput is 2027.288 records/second. Loss is 2.2929769. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004963271788763152. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:50 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 39][Wall Clock 8.296999214s] Trained 256 records in 0.179359055 seconds. Throughput is 1427.3047 records/second. Loss is 2.301929. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049622866216752675. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 40][Wall Clock 8.428468819s] Trained 256 records in 0.131469605 seconds. Throughput is 1947.2181 records/second. Loss is 2.2935328. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004961301845604287. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 41][Wall Clock 8.555350467s] Trained 256 records in 0.126881648 seconds. Throughput is 2017.6283 records/second. Loss is 2.287701. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00496031746031746. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 42][Wall Clock 8.683511591s] Trained 256 records in 0.128161124 seconds. Throughput is 1997.4857 records/second. Loss is 2.2917345. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004959333465582226. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 43][Wall Clock 8.810096202s] Trained 256 records in 0.126584611 seconds. Throughput is 2022.3628 records/second. Loss is 2.2948718. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004958349861166204. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 44][Wall Clock 8.974524314s] Trained 256 records in 0.164428112 seconds. Throughput is 1556.9114 records/second. Loss is 2.2853594. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049573666468372005. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 45][Wall Clock 9.17468049s] Trained 256 records in 0.200156176 seconds. Throughput is 1279.0012 records/second. Loss is 2.2937977. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004956383822363204. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 46][Wall Clock 9.288400193s] Trained 256 records in 0.113719703 seconds. Throughput is 2251.1492 records/second. Loss is 2.2908099. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004955401387512389. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:51 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 47][Wall Clock 9.406881019s] Trained 256 records in 0.118480826 seconds. Throughput is 2160.6873 records/second. Loss is 2.2906182. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004954419342053111. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 48][Wall Clock 9.527836039s] Trained 256 records in 0.12095502 seconds. Throughput is 2116.4893 records/second. Loss is 2.2871337. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004953437685753913. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 49][Wall Clock 9.651675417s] Trained 256 records in 0.123839378 seconds. Throughput is 2067.1938 records/second. Loss is 2.277056. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004952456418383518. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 50][Wall Clock 9.780211807s] Trained 256 records in 0.12853639 seconds. Throughput is 1991.6539 records/second. Loss is 2.2969742. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004951475539710834. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 51][Wall Clock 9.91241652s] Trained 256 records in 0.132204713 seconds. Throughput is 1936.3909 records/second. Loss is 2.285036. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049504950495049506. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 52][Wall Clock 10.076095573s] Trained 256 records in 0.163679053 seconds. Throughput is 1564.0365 records/second. Loss is 2.2802546. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004949514947535142. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 53][Wall Clock 10.201768092s] Trained 256 records in 0.125672519 seconds. Throughput is 2037.0404 records/second. Loss is 2.2894912. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004948535233570864. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:52 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 54][Wall Clock 10.345586926s] Trained 256 records in 0.143818834 seconds. Throughput is 1780.0171 records/second. Loss is 2.2857413. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004947555907381754. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 55][Wall Clock 10.475085976s] Trained 256 records in 0.12949905 seconds. Throughput is 1976.8485 records/second. Loss is 2.2930133. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004946576968737634. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 56][Wall Clock 10.596932939s] Trained 256 records in 0.121846963 seconds. Throughput is 2100.996 records/second. Loss is 2.2846491. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004945598417408507. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 57][Wall Clock 10.725145778s] Trained 256 records in 0.128212839 seconds. Throughput is 1996.6799 records/second. Loss is 2.2911549. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004944620253164556. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 58][Wall Clock 10.869300023s] Trained 256 records in 0.144154245 seconds. Throughput is 1775.8755 records/second. Loss is 2.290207. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004943642475776152. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 59][Wall Clock 10.987297721s] Trained 256 records in 0.117997698 seconds. Throughput is 2169.534 records/second. Loss is 2.2894282. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049426650850138395. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 60][Wall Clock 11.110590562s] Trained 256 records in 0.123292841 seconds. Throughput is 2076.3574 records/second. Loss is 2.2891304. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00494168808064835. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 61][Wall Clock 11.235865802s] Trained 256 records in 0.12527524 seconds. Throughput is 2043.5004 records/second. Loss is 2.289962. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004940711462450593. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:53 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 62][Wall Clock 11.366244702s] Trained 256 records in 0.1303789 seconds. Throughput is 1963.5078 records/second. Loss is 2.2752597. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049397352301916615. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 63][Wall Clock 11.50056413s] Trained 256 records in 0.134319428 seconds. Throughput is 1905.9045 records/second. Loss is 2.2871215. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004938759383642829. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 64][Wall Clock 11.645389122s] Trained 256 records in 0.144824992 seconds. Throughput is 1767.6506 records/second. Loss is 2.278553. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004937783922575548. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 65][Wall Clock 11.757760865s] Trained 256 records in 0.112371743 seconds. Throughput is 2278.1528 records/second. Loss is 2.2734241. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049368088467614535. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 66][Wall Clock 11.877251932s] Trained 256 records in 0.119491067 seconds. Throughput is 2142.4194 records/second. Loss is 2.2814357. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00493583415597236. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 67][Wall Clock 11.995179562s] Trained 256 records in 0.11792763 seconds. Throughput is 2170.8228 records/second. Loss is 2.273411. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00493485984998026. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 68][Wall Clock 12.104314949s] Trained 256 records in 0.109135387 seconds. Throughput is 2345.7102 records/second. Loss is 2.2842765. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049338859285573316. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 69][Wall Clock 12.236031654s] Trained 256 records in 0.131716705 seconds. Throughput is 1943.5653 records/second. Loss is 2.2787068. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004932912391475927. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:54 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 70][Wall Clock 12.363155843s] Trained 256 records in 0.127124189 seconds. Throughput is 2013.7788 records/second. Loss is 2.281465. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004931939238508582. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 71][Wall Clock 12.475425481s] Trained 256 records in 0.112269638 seconds. Throughput is 2280.2246 records/second. Loss is 2.2838516. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004930966469428008. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 72][Wall Clock 12.606098079s] Trained 256 records in 0.130672598 seconds. Throughput is 1959.0946 records/second. Loss is 2.2827435. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004929994084007099. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 73][Wall Clock 12.736071641s] Trained 256 records in 0.129973562 seconds. Throughput is 1969.6313 records/second. Loss is 2.2739086. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004929022082018928. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 74][Wall Clock 12.852725582s] Trained 256 records in 0.116653941 seconds. Throughput is 2194.5251 records/second. Loss is 2.2793267. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004928050463236744. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 75][Wall Clock 12.971664217s] Trained 256 records in 0.118938635 seconds. Throughput is 2152.3704 records/second. Loss is 2.2853346. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004927079227433978. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 76][Wall Clock 13.1519576s] Trained 256 records in 0.180293383 seconds. Throughput is 1419.908 records/second. Loss is 2.2671814. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004926108374384237. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 77][Wall Clock 13.26345357s] Trained 256 records in 0.11149597 seconds. Throughput is 2296.047 records/second. Loss is 2.2683244. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004925137903861307. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:55 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 78][Wall Clock 13.380835078s] Trained 256 records in 0.117381508 seconds. Throughput is 2180.9229 records/second. Loss is 2.27507. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004924167815639157. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 79][Wall Clock 13.506531436s] Trained 256 records in 0.125696358 seconds. Throughput is 2036.654 records/second. Loss is 2.278976. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004923198109491926. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 80][Wall Clock 13.627398024s] Trained 256 records in 0.120866588 seconds. Throughput is 2118.0378 records/second. Loss is 2.2732093. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004922228785193936. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 81][Wall Clock 13.748931105s] Trained 256 records in 0.121533081 seconds. Throughput is 2106.4224 records/second. Loss is 2.263152. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004921259842519685. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 82][Wall Clock 13.906610057s] Trained 256 records in 0.157678952 seconds. Throughput is 1623.5522 records/second. Loss is 2.281902. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00492029128124385. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 83][Wall Clock 14.019896345s] Trained 256 records in 0.113286288 seconds. Throughput is 2259.7617 records/second. Loss is 2.2684007. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049193231011412835. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 84][Wall Clock 14.138007323s] Trained 256 records in 0.118110978 seconds. Throughput is 2167.4531 records/second. Loss is 2.2716248. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004918355301987016. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 85][Wall Clock 14.25603137s] Trained 256 records in 0.118024047 seconds. Throughput is 2169.0496 records/second. Loss is 2.26805. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049173878835562556. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:56 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 86][Wall Clock 14.386930961s] Trained 256 records in 0.130899591 seconds. Throughput is 1955.6974 records/second. Loss is 2.2636728. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004916420845624386. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 87][Wall Clock 14.510634521s] Trained 256 records in 0.12370356 seconds. Throughput is 2069.4634 records/second. Loss is 2.2641165. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004915454187966968. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 88][Wall Clock 14.633221685s] Trained 256 records in 0.122587164 seconds. Throughput is 2088.31 records/second. Loss is 2.2643726. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00491448791035974. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 89][Wall Clock 14.742601836s] Trained 256 records in 0.109380151 seconds. Throughput is 2340.4612 records/second. Loss is 2.2597442. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004913522012578616. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 90][Wall Clock 14.865717458s] Trained 256 records in 0.123115622 seconds. Throughput is 2079.3462 records/second. Loss is 2.2715325. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0049125564943996855. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 91][Wall Clock 14.992916416s] Trained 256 records in 0.127198958 seconds. Throughput is 2012.595 records/second. Loss is 2.2680595. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004911591355599214. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 92][Wall Clock 15.106846199s] Trained 256 records in 0.113929783 seconds. Throughput is 2246.998 records/second. Loss is 2.2700741. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004910626595953644. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 93][Wall Clock 15.232304598s] Trained 256 records in 0.125458399 seconds. Throughput is 2040.517 records/second. Loss is 2.2732835. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004909662215239592. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:57 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 94][Wall Clock 15.363921047s] Trained 256 records in 0.131616449 seconds. Throughput is 1945.0458 records/second. Loss is 2.2602985. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004908698213233851. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 95][Wall Clock 15.475886507s] Trained 256 records in 0.11196546 seconds. Throughput is 2286.4194 records/second. Loss is 2.268263. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004907734589713389. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 96][Wall Clock 15.583841083s] Trained 256 records in 0.107954576 seconds. Throughput is 2371.3677 records/second. Loss is 2.2696657. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004906771344455349. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 97][Wall Clock 15.69648865s] Trained 256 records in 0.112647567 seconds. Throughput is 2272.5745 records/second. Loss is 2.270625. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004905808477237048. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 98][Wall Clock 15.820538522s] Trained 256 records in 0.124049872 seconds. Throughput is 2063.686 records/second. Loss is 2.2695172. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004904845987835982. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 99][Wall Clock 15.93111619s] Trained 256 records in 0.110577668 seconds. Throughput is 2315.115 records/second. Loss is 2.2510781. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004903883876029815. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 100][Wall Clock 16.112906212s] Trained 256 records in 0.181790022 seconds. Throughput is 1408.2181 records/second. Loss is 2.271971. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004902922141596391. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:58 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 101][Wall Clock 16.268341562s] Trained 256 records in 0.15543535 seconds. Throughput is 1646.9869 records/second. Loss is 2.2598789. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004901960784313725. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 102][Wall Clock 16.434488267s] Trained 256 records in 0.166146705 seconds. Throughput is 1540.8069 records/second. Loss is 2.266339. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004900999803960008. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 103][Wall Clock 16.545103128s] Trained 256 records in 0.110614861 seconds. Throughput is 2314.3364 records/second. Loss is 2.2643745. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004900039200313603. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 104][Wall Clock 16.669121757s] Trained 256 records in 0.124018629 seconds. Throughput is 2064.206 records/second. Loss is 2.2527082. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004899078973153047. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 105][Wall Clock 16.815060072s] Trained 256 records in 0.145938315 seconds. Throughput is 1754.1656 records/second. Loss is 2.2648873. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004898119122257054. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 106][Wall Clock 16.933244071s] Trained 256 records in 0.118183999 seconds. Throughput is 2166.1138 records/second. Loss is 2.2673378. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004897159647404506. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 107][Wall Clock 17.061603758s] Trained 256 records in 0.128359687 seconds. Throughput is 1994.3956 records/second. Loss is 2.2585993. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004896200548374461. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 108][Wall Clock 17.174454115s] Trained 256 records in 0.112850357 seconds. Throughput is 2268.4907 records/second. Loss is 2.2619567. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004895241824946152. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 109][Wall Clock 17.292694545s] Trained 256 records in 0.11824043 seconds. Throughput is 2165.08 records/second. Loss is 2.2734478. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004894283476898981. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:14:59 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 110][Wall Clock 17.404924573s] Trained 256 records in 0.112230028 seconds. Throughput is 2281.0295 records/second. Loss is 2.2548256. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004893325504012527. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 111][Wall Clock 17.529193996s] Trained 256 records in 0.124269423 seconds. Throughput is 2060.04 records/second. Loss is 2.2591186. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004892367906066536. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 112][Wall Clock 17.640445307s] Trained 256 records in 0.111251311 seconds. Throughput is 2301.0964 records/second. Loss is 2.257161. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004891410682840931. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 113][Wall Clock 17.748250707s] Trained 256 records in 0.1078054 seconds. Throughput is 2374.6492 records/second. Loss is 2.2494245. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004890453834115806. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 114][Wall Clock 17.891962896s] Trained 256 records in 0.143712189 seconds. Throughput is 1781.338 records/second. Loss is 2.257179. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004889497359671426. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 115][Wall Clock 18.009032688s] Trained 256 records in 0.117069792 seconds. Throughput is 2186.7297 records/second. Loss is 2.2510707. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004888541259288229. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 116][Wall Clock 18.130557421s] Trained 256 records in 0.121524733 seconds. Throughput is 2106.567 records/second. Loss is 2.2563126. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004887585532746824. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:00 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 117][Wall Clock 18.258327251s] Trained 256 records in 0.12776983 seconds. Throughput is 2003.6029 records/second. Loss is 2.2601082. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048866301798279905. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 118][Wall Clock 18.406870145s] Trained 256 records in 0.148542894 seconds. Throughput is 1723.4078 records/second. Loss is 2.2472072. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004885675200312683. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 119][Wall Clock 18.52608291s] Trained 256 records in 0.119212765 seconds. Throughput is 2147.4211 records/second. Loss is 2.2580965. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004884720593982024. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 120][Wall Clock 18.65679913s] Trained 256 records in 0.13071622 seconds. Throughput is 1958.4409 records/second. Loss is 2.247029. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004883766360617308. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 121][Wall Clock 18.78441133s] Trained 256 records in 0.1276122 seconds. Throughput is 2006.0778 records/second. Loss is 2.2585008. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048828125. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 122][Wall Clock 18.921235156s] Trained 256 records in 0.136823826 seconds. Throughput is 1871.019 records/second. Loss is 2.2617211. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004881859011911736. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 123][Wall Clock 19.043100882s] Trained 256 records in 0.121865726 seconds. Throughput is 2100.6726 records/second. Loss is 2.2504146. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004880905896134323. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 124][Wall Clock 19.156085593s] Trained 256 records in 0.112984711 seconds. Throughput is 2265.7932 records/second. Loss is 2.2555687. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004879953152449737. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:01 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 125][Wall Clock 19.279909968s] Trained 256 records in 0.123824375 seconds. Throughput is 2067.4443 records/second. Loss is 2.2335873. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004879000780640125. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 126][Wall Clock 19.412280571s] Trained 256 records in 0.132370603 seconds. Throughput is 1933.9641 records/second. Loss is 2.2412426. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004878048780487806. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 127][Wall Clock 19.535163112s] Trained 256 records in 0.122882541 seconds. Throughput is 2083.2903 records/second. Loss is 2.24845. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004877097151775264. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 128][Wall Clock 19.679581434s] Trained 256 records in 0.144418322 seconds. Throughput is 1772.6282 records/second. Loss is 2.252696. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048761458942851565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 129][Wall Clock 19.843386581s] Trained 256 records in 0.163805147 seconds. Throughput is 1562.8325 records/second. Loss is 2.267314. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004875195007800312. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 130][Wall Clock 19.95483189s] Trained 256 records in 0.111445309 seconds. Throughput is 2297.0908 records/second. Loss is 2.2514021. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004874244492103724. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 131][Wall Clock 20.060667119s] Trained 256 records in 0.105835229 seconds. Throughput is 2418.8542 records/second. Loss is 2.240982. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004873294346978557. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 132][Wall Clock 20.208698963s] Trained 256 records in 0.148031844 seconds. Throughput is 1729.3577 records/second. Loss is 2.240554. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004872344572208147. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:02 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 133][Wall Clock 20.367065816s] Trained 256 records in 0.158366853 seconds. Throughput is 1616.4999 records/second. Loss is 2.244205. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004871395167575994. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 134][Wall Clock 20.474607477s] Trained 256 records in 0.107541661 seconds. Throughput is 2380.473 records/second. Loss is 2.248543. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004870446132865771. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 135][Wall Clock 20.582474753s] Trained 256 records in 0.107867276 seconds. Throughput is 2373.2869 records/second. Loss is 2.2507348. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004869497467861317. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 136][Wall Clock 20.696693688s] Trained 256 records in 0.114218935 seconds. Throughput is 2241.3096 records/second. Loss is 2.239358. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004868549172346641. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 137][Wall Clock 20.836610935s] Trained 256 records in 0.139917247 seconds. Throughput is 1829.6528 records/second. Loss is 2.2519076. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004867601246105919. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 138][Wall Clock 20.946348907s] Trained 256 records in 0.109737972 seconds. Throughput is 2332.8298 records/second. Loss is 2.2473135. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004866653688923496. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 139][Wall Clock 21.114296873s] Trained 256 records in 0.167947966 seconds. Throughput is 1524.2816 records/second. Loss is 2.2377923. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004865706500583884. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:03 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 140][Wall Clock 21.269345479s] Trained 256 records in 0.155048606 seconds. Throughput is 1651.0951 records/second. Loss is 2.2441564. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004864759680871765. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 141][Wall Clock 21.412546792s] Trained 256 records in 0.143201313 seconds. Throughput is 1787.6932 records/second. Loss is 2.2478976. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048638132295719845. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 142][Wall Clock 21.525859027s] Trained 256 records in 0.113312235 seconds. Throughput is 2259.2441 records/second. Loss is 2.2447028. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004862867146469559. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 143][Wall Clock 21.636670701s] Trained 256 records in 0.110811674 seconds. Throughput is 2310.2258 records/second. Loss is 2.252253. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048619214313496695. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 144][Wall Clock 21.752280813s] Trained 256 records in 0.115610112 seconds. Throughput is 2214.339 records/second. Loss is 2.2563443. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004860976083997667. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 145][Wall Clock 21.876773939s] Trained 256 records in 0.124493126 seconds. Throughput is 2056.3384 records/second. Loss is 2.2336216. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004860031104199068. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 146][Wall Clock 21.988998069s] Trained 256 records in 0.11222413 seconds. Throughput is 2281.1494 records/second. Loss is 2.2338345. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004859086491739554. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 147][Wall Clock 22.103341532s] Trained 256 records in 0.114343463 seconds. Throughput is 2238.8687 records/second. Loss is 2.241174. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004858142246404976. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:04 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 148][Wall Clock 22.263375576s] Trained 256 records in 0.160034044 seconds. Throughput is 1599.6597 records/second. Loss is 2.2234285. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004857198367981348. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 149][Wall Clock 22.419843388s] Trained 256 records in 0.156467812 seconds. Throughput is 1636.1193 records/second. Loss is 2.2329183. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004856254856254856. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 150][Wall Clock 22.581700461s] Trained 256 records in 0.161857073 seconds. Throughput is 1581.6423 records/second. Loss is 2.234056. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004855311711011847. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 151][Wall Clock 22.71507398s] Trained 256 records in 0.133373519 seconds. Throughput is 1919.4216 records/second. Loss is 2.2354307. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048543689320388345. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 152][Wall Clock 22.825709296s] Trained 256 records in 0.110635316 seconds. Throughput is 2313.9084 records/second. Loss is 2.2352898. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048534265191225. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 153][Wall Clock 22.981184064s] Trained 256 records in 0.155474768 seconds. Throughput is 1646.5695 records/second. Loss is 2.2235825. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00485248447204969. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 154][Wall Clock 23.089890141s] Trained 256 records in 0.108706077 seconds. Throughput is 2354.974 records/second. Loss is 2.2289877. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004851542790607413. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 155][Wall Clock 23.19526801s] Trained 256 records in 0.105377869 seconds. Throughput is 2429.3525 records/second. Loss is 2.2298923. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004850601474582848. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:05 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 156][Wall Clock 23.305594956s] Trained 256 records in 0.110326946 seconds. Throughput is 2320.376 records/second. Loss is 2.2333236. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004849660523763337. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 157][Wall Clock 23.418269573s] Trained 256 records in 0.112674617 seconds. Throughput is 2272.029 records/second. Loss is 2.2218628. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004848719937936385. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 158][Wall Clock 23.535238381s] Trained 256 records in 0.116968808 seconds. Throughput is 2188.6177 records/second. Loss is 2.2297235. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004847779716889664. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 159][Wall Clock 23.695192861s] Trained 256 records in 0.15995448 seconds. Throughput is 1600.4554 records/second. Loss is 2.2331886. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004846839860411012. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 160][Wall Clock 23.800623843s] Trained 256 records in 0.105430982 seconds. Throughput is 2428.1287 records/second. Loss is 2.2369406. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004845900368288428. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 161][Wall Clock 23.915144297s] Trained 256 records in 0.114520454 seconds. Throughput is 2235.4084 records/second. Loss is 2.2335458. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048449612403100775. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 162][Wall Clock 24.038304566s] Trained 256 records in 0.123160269 seconds. Throughput is 2078.5925 records/second. Loss is 2.2146676. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00484402247626429. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 163][Wall Clock 24.141605016s] Trained 256 records in 0.10330045 seconds. Throughput is 2478.208 records/second. Loss is 2.2280493. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048430840759395586. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:06 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 164][Wall Clock 24.254959357s] Trained 256 records in 0.113354341 seconds. Throughput is 2258.405 records/second. Loss is 2.2207608. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00484214603912454. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 165][Wall Clock 24.410802389s] Trained 256 records in 0.155843032 seconds. Throughput is 1642.6785 records/second. Loss is 2.2165182. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048412083656080565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 166][Wall Clock 24.543189348s] Trained 256 records in 0.132386959 seconds. Throughput is 1933.7253 records/second. Loss is 2.2263649. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004840271055179091. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 167][Wall Clock 24.657115366s] Trained 256 records in 0.113926018 seconds. Throughput is 2247.0723 records/second. Loss is 2.2259095. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004839334107626791. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 168][Wall Clock 24.765374541s] Trained 256 records in 0.108259175 seconds. Throughput is 2364.6956 records/second. Loss is 2.2197695. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004838397522740468. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 169][Wall Clock 24.881879457s] Trained 256 records in 0.116504916 seconds. Throughput is 2197.3323 records/second. Loss is 2.2228131. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004837461300309597. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 170][Wall Clock 24.992306316s] Trained 256 records in 0.110426859 seconds. Throughput is 2318.2766 records/second. Loss is 2.223348. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048365254401238145. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 171][Wall Clock 25.116450928s] Trained 256 records in 0.124144612 seconds. Throughput is 2062.1113 records/second. Loss is 2.2301865. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004835589941972921. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 172][Wall Clock 25.222575799s] Trained 256 records in 0.106124871 seconds. Throughput is 2412.2527 records/second. Loss is 2.2171042. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004834654805646877. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:07 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 173][Wall Clock 25.327637252s] Trained 256 records in 0.105061453 seconds. Throughput is 2436.669 records/second. Loss is 2.2105465. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004833720030935808. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 174][Wall Clock 25.431057213s] Trained 256 records in 0.103419961 seconds. Throughput is 2475.3442 records/second. Loss is 2.219747. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004832785617630002. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 175][Wall Clock 25.539022377s] Trained 256 records in 0.107965164 seconds. Throughput is 2371.1353 records/second. Loss is 2.2180505. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004831851565519908. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 176][Wall Clock 25.660679107s] Trained 256 records in 0.12165673 seconds. Throughput is 2104.2815 records/second. Loss is 2.2249177. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004830917874396136. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 177][Wall Clock 25.766347645s] Trained 256 records in 0.105668538 seconds. Throughput is 2422.6702 records/second. Loss is 2.2137566. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00482998454404946. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 178][Wall Clock 25.872101001s] Trained 256 records in 0.105753356 seconds. Throughput is 2420.727 records/second. Loss is 2.217977. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004829051574270813. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 179][Wall Clock 25.992969755s] Trained 256 records in 0.120868754 seconds. Throughput is 2117.9998 records/second. Loss is 2.2218642. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004828118964851294. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 180][Wall Clock 26.139002717s] Trained 256 records in 0.146032962 seconds. Throughput is 1753.0289 records/second. Loss is 2.223794. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048271867155821584. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 181][Wall Clock 26.247911133s] Trained 256 records in 0.108908416 seconds. Throughput is 2350.5989 records/second. Loss is 2.223459. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004826254826254826. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:08 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 182][Wall Clock 26.375504278s] Trained 256 records in 0.127593145 seconds. Throughput is 2006.3774 records/second. Loss is 2.217532. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004825323296660877. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 183][Wall Clock 26.482770397s] Trained 256 records in 0.107266119 seconds. Throughput is 2386.5876 records/second. Loss is 2.2110133. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00482439212659205. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 184][Wall Clock 26.602278841s] Trained 256 records in 0.119508444 seconds. Throughput is 2142.108 records/second. Loss is 2.2038834. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004823461315840247. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 185][Wall Clock 26.712140205s] Trained 256 records in 0.109861364 seconds. Throughput is 2330.2095 records/second. Loss is 2.2147822. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048225308641975315. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 186][Wall Clock 26.822949381s] Trained 256 records in 0.110809176 seconds. Throughput is 2310.278 records/second. Loss is 2.2021372. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048216007714561235. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 187][Wall Clock 26.9332332s] Trained 256 records in 0.110283819 seconds. Throughput is 2321.2834 records/second. Loss is 2.2181005. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004820671037408407. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 188][Wall Clock 27.088850029s] Trained 256 records in 0.155616829 seconds. Throughput is 1645.0663 records/second. Loss is 2.2318685. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004819741661846924. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 189][Wall Clock 27.206119163s] Trained 256 records in 0.117269134 seconds. Throughput is 2183.0127 records/second. Loss is 2.2135105. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004818812644564379. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:09 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 190][Wall Clock 27.327089671s] Trained 256 records in 0.120970508 seconds. Throughput is 2116.2183 records/second. Loss is 2.2100334. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004817883985353632. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 191][Wall Clock 27.439115625s] Trained 256 records in 0.112025954 seconds. Throughput is 2285.1848 records/second. Loss is 2.1978962. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004816955684007707. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 192][Wall Clock 27.57339741s] Trained 256 records in 0.134281785 seconds. Throughput is 1906.4387 records/second. Loss is 2.2102633. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004816027740319784. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 193][Wall Clock 27.676710711s] Trained 256 records in 0.103313301 seconds. Throughput is 2477.8997 records/second. Loss is 2.2097533. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0048151001540832055. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 194][Wall Clock 27.792233368s] Trained 256 records in 0.115522657 seconds. Throughput is 2216.0154 records/second. Loss is 2.2238798. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00481417292509147. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 195][Wall Clock 27.893497911s] Trained 256 records in 0.101264543 seconds. Throughput is 2528.032 records/second. Loss is 2.2058518. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004813246053138237. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 196][Wall Clock 27.995696012s] Trained 256 records in 0.102198101 seconds. Throughput is 2504.939 records/second. Loss is 2.204763. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004812319538017325. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 197][Wall Clock 28.097814625s] Trained 256 records in 0.102118613 seconds. Throughput is 2506.8887 records/second. Loss is 2.1985815. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004811393379522711. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 198][Wall Clock 28.237588327s] Trained 256 records in 0.139773702 seconds. Throughput is 1831.532 records/second. Loss is 2.2042665. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004810467577448528. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:10 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 199][Wall Clock 28.351900001s] Trained 256 records in 0.114311674 seconds. Throughput is 2239.4912 records/second. Loss is 2.1940136. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004809542131589072. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 200][Wall Clock 28.476837481s] Trained 256 records in 0.12493748 seconds. Throughput is 2049.025 records/second. Loss is 2.2052724. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004808617041738796. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 201][Wall Clock 28.625784488s] Trained 256 records in 0.148947007 seconds. Throughput is 1718.7322 records/second. Loss is 2.2013514. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004807692307692308. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 202][Wall Clock 28.779454588s] Trained 256 records in 0.1536701 seconds. Throughput is 1665.9064 records/second. Loss is 2.2004948. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004806767929244376. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 203][Wall Clock 28.887139139s] Trained 256 records in 0.107684551 seconds. Throughput is 2377.314 records/second. Loss is 2.1907794. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004805843906189927. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 204][Wall Clock 28.988066555s] Trained 256 records in 0.100927416 seconds. Throughput is 2536.4763 records/second. Loss is 2.1978824. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004804920238324044. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 205][Wall Clock 29.090470179s] Trained 256 records in 0.102403624 seconds. Throughput is 2499.9114 records/second. Loss is 2.210724. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004803996925441968. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 206][Wall Clock 29.191413841s] Trained 256 records in 0.100943662 seconds. Throughput is 2536.068 records/second. Loss is 2.1937728. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004803073967339097. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:11 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 207][Wall Clock 29.293475557s] Trained 256 records in 0.102061716 seconds. Throughput is 2508.2861 records/second. Loss is 2.2098446. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004802151363810988. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 208][Wall Clock 29.396557042s] Trained 256 records in 0.103081485 seconds. Throughput is 2483.4722 records/second. Loss is 2.2055728. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004801229114653351. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 209][Wall Clock 29.497427945s] Trained 256 records in 0.100870903 seconds. Throughput is 2537.8975 records/second. Loss is 2.1828232. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004800307219662058. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 210][Wall Clock 29.615920732s] Trained 256 records in 0.118492787 seconds. Throughput is 2160.469 records/second. Loss is 2.196828. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004799385678633135. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 211][Wall Clock 29.725119584s] Trained 256 records in 0.109198852 seconds. Throughput is 2344.347 records/second. Loss is 2.201897. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047984644913627635. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 212][Wall Clock 29.828185363s] Trained 256 records in 0.103065779 seconds. Throughput is 2483.8506 records/second. Loss is 2.1933188. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004797543657647284. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 213][Wall Clock 29.932877042s] Trained 256 records in 0.104691679 seconds. Throughput is 2445.2756 records/second. Loss is 2.2073345. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004796623177283193. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 214][Wall Clock 30.03094483s] Trained 256 records in 0.098067788 seconds. Throughput is 2610.4392 records/second. Loss is 2.1893754. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00479570305006714. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 215][Wall Clock 30.131568919s] Trained 256 records in 0.100624089 seconds. Throughput is 2544.1223 records/second. Loss is 2.182701. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004794783275795934. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 216][Wall Clock 30.242650581s] Trained 256 records in 0.111081662 seconds. Throughput is 2304.6108 records/second. Loss is 2.2015355. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004793863854266539. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:12 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 217][Wall Clock 30.340693746s] Trained 256 records in 0.098043165 seconds. Throughput is 2611.0947 records/second. Loss is 2.182411. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004792944785276075. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 218][Wall Clock 30.451234917s] Trained 256 records in 0.110541171 seconds. Throughput is 2315.8792 records/second. Loss is 2.2091115. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004792026068621813. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 219][Wall Clock 30.554438412s] Trained 256 records in 0.103203495 seconds. Throughput is 2480.5361 records/second. Loss is 2.1917937. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004791107704101188. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 220][Wall Clock 30.658045725s] Trained 256 records in 0.103607313 seconds. Throughput is 2470.8682 records/second. Loss is 2.1859522. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004790189691511784. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 221][Wall Clock 30.782909983s] Trained 256 records in 0.124864258 seconds. Throughput is 2050.2263 records/second. Loss is 2.1713579. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004789272030651341. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 222][Wall Clock 30.883666232s] Trained 256 records in 0.100756249 seconds. Throughput is 2540.7854 records/second. Loss is 2.1868887. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004788354721317755. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 223][Wall Clock 30.991864205s] Trained 256 records in 0.108197973 seconds. Throughput is 2366.0332 records/second. Loss is 2.1658938. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004787437763309077. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 224][Wall Clock 31.092222654s] Trained 256 records in 0.100358449 seconds. Throughput is 2550.8564 records/second. Loss is 2.1768222. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047865211564235115. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 225][Wall Clock 31.196684789s] Trained 256 records in 0.104462135 seconds. Throughput is 2450.649 records/second. Loss is 2.1848025. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047856049004594186. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:13 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 226][Wall Clock 31.304808801s] Trained 256 records in 0.108124012 seconds. Throughput is 2367.6516 records/second. Loss is 2.192691. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004784688995215312. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 227][Wall Clock 31.457623103s] Trained 256 records in 0.152814302 seconds. Throughput is 1675.236 records/second. Loss is 2.1680992. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004783773440489859. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 228][Wall Clock 31.608462106s] Trained 256 records in 0.150839003 seconds. Throughput is 1697.1738 records/second. Loss is 2.1905453. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004782858236081882. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 229][Wall Clock 31.713408514s] Trained 256 records in 0.104946408 seconds. Throughput is 2439.3403 records/second. Loss is 2.1700065. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004781943381790359. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 230][Wall Clock 31.816491412s] Trained 256 records in 0.103082898 seconds. Throughput is 2483.4382 records/second. Loss is 2.176775. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004781028877414419. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 231][Wall Clock 31.926231376s] Trained 256 records in 0.109739964 seconds. Throughput is 2332.7874 records/second. Loss is 2.1770372. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004780114722753346. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 232][Wall Clock 32.044262035s] Trained 256 records in 0.118030659 seconds. Throughput is 2168.928 records/second. Loss is 2.167864. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004779200917606577. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 233][Wall Clock 32.190187447s] Trained 256 records in 0.145925412 seconds. Throughput is 1754.3208 records/second. Loss is 2.1680112. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047782874617737. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:14 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 234][Wall Clock 32.295612984s] Trained 256 records in 0.105425537 seconds. Throughput is 2428.2542 records/second. Loss is 2.1626832. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004777374355054462. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:15 INFO  DistriOptimizer$:408 - [Epoch 1 60160/60000][Iteration 235][Wall Clock 32.4065281s] Trained 256 records in 0.110915116 seconds. Throughput is 2308.0713 records/second. Loss is 2.1661203. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004776461597248758. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:15 INFO  DistriOptimizer$:452 - [Epoch 1 60160/60000][Iteration 235][Wall Clock 32.4065281s] Epoch finished. Wall clock time is 32486.65844 ms
2019-10-26 12:15:15 INFO  DistriOptimizer$:111 - [Epoch 1 60160/60000][Iteration 235][Wall Clock 32.4065281s] Validate model...
2019-10-26 12:15:16 INFO  DistriOptimizer$:178 - [Epoch 1 60160/60000][Iteration 235][Wall Clock 32.4065281s] validate model throughput is 9834.864 records/second
2019-10-26 12:15:16 INFO  DistriOptimizer$:181 - [Epoch 1 60160/60000][Iteration 235][Wall Clock 32.4065281s] Top1Accuracy is Accuracy(correct: 5140, count: 10000, accuracy: 0.514)
2019-10-26 12:15:16 INFO  DistriOptimizer$:221 - [Wall Clock 32.48665844s] Save model to /tmp/lenet5/20191026_121442
2019-10-26 12:15:16 INFO  DistriOptimizer$:226 - [Wall Clock 32.48665844s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@13b5664a to /tmp/lenet5/20191026_121442
2019-10-26 12:15:16 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 236][Wall Clock 32.636023097s] Trained 256 records in 0.149364657 seconds. Throughput is 1713.9263 records/second. Loss is 2.1736252. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004775549188156638. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:16 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 237][Wall Clock 32.756832066s] Trained 256 records in 0.120808969 seconds. Throughput is 2119.048 records/second. Loss is 2.1791413. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004774637127578305. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:16 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 238][Wall Clock 32.881644345s] Trained 256 records in 0.124812279 seconds. Throughput is 2051.08 records/second. Loss is 2.1624517. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004773725415314111. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:16 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 239][Wall Clock 33.002762555s] Trained 256 records in 0.12111821 seconds. Throughput is 2113.6375 records/second. Loss is 2.177547. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004772814051164567. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:16 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 240][Wall Clock 33.153742021s] Trained 256 records in 0.150979466 seconds. Throughput is 1695.5948 records/second. Loss is 2.1661704. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00477190303493033. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:16 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 241][Wall Clock 33.333543515s] Trained 256 records in 0.179801494 seconds. Throughput is 1423.7924 records/second. Loss is 2.172099. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004770992366412214. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 242][Wall Clock 33.49080537s] Trained 256 records in 0.157261855 seconds. Throughput is 1627.8583 records/second. Loss is 2.1576715. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004770082045411181. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 243][Wall Clock 33.654019719s] Trained 256 records in 0.163214349 seconds. Throughput is 1568.4895 records/second. Loss is 2.1720998. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004769172071728348. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 244][Wall Clock 33.802865233s] Trained 256 records in 0.148845514 seconds. Throughput is 1719.904 records/second. Loss is 2.166092. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004768262445164982. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 245][Wall Clock 33.904219502s] Trained 256 records in 0.101354269 seconds. Throughput is 2525.794 records/second. Loss is 2.1749904. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004767353165522502. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 246][Wall Clock 34.023235951s] Trained 256 records in 0.119016449 seconds. Throughput is 2150.9631 records/second. Loss is 2.1565049. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004766444232602479. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 247][Wall Clock 34.138186975s] Trained 256 records in 0.114951024 seconds. Throughput is 2227.0354 records/second. Loss is 2.158559. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004765535646206634. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:17 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 248][Wall Clock 34.256326687s] Trained 256 records in 0.118139712 seconds. Throughput is 2166.9258 records/second. Loss is 2.1531427. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004764627406136841. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 249][Wall Clock 34.355986957s] Trained 256 records in 0.09966027 seconds. Throughput is 2568.7268 records/second. Loss is 2.1631737. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004763719512195122. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 250][Wall Clock 34.476627396s] Trained 256 records in 0.120640439 seconds. Throughput is 2122.008 records/second. Loss is 2.1631243. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047628119641836535. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 251][Wall Clock 34.584204271s] Trained 256 records in 0.107576875 seconds. Throughput is 2379.6936 records/second. Loss is 2.1644876. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047619047619047615. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 252][Wall Clock 34.708642843s] Trained 256 records in 0.124438572 seconds. Throughput is 2057.24 records/second. Loss is 2.16327. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004760997905160921. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 253][Wall Clock 34.818894344s] Trained 256 records in 0.110251501 seconds. Throughput is 2321.9639 records/second. Loss is 2.1423447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00476009139375476. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 254][Wall Clock 34.925658477s] Trained 256 records in 0.106764133 seconds. Throughput is 2397.809 records/second. Loss is 2.147916. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047591852274890545. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 255][Wall Clock 35.034646446s] Trained 256 records in 0.108987969 seconds. Throughput is 2348.883 records/second. Loss is 2.1535423. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00475827940616673. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 256][Wall Clock 35.153956689s] Trained 256 records in 0.119310243 seconds. Throughput is 2145.6665 records/second. Loss is 2.1633759. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004757373929590867. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:18 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 257][Wall Clock 35.297628086s] Trained 256 records in 0.143671397 seconds. Throughput is 1781.8439 records/second. Loss is 2.138194. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004756468797564689. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 258][Wall Clock 35.413982851s] Trained 256 records in 0.116354765 seconds. Throughput is 2200.1677 records/second. Loss is 2.1404035. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004755564009891573. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 259][Wall Clock 35.535189815s] Trained 256 records in 0.121206964 seconds. Throughput is 2112.0898 records/second. Loss is 2.1436462. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004754659566375047. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 260][Wall Clock 35.635256725s] Trained 256 records in 0.10006691 seconds. Throughput is 2558.2883 records/second. Loss is 2.1425047. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004753755466818787. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 261][Wall Clock 35.740408687s] Trained 256 records in 0.105151962 seconds. Throughput is 2434.5718 records/second. Loss is 2.1466296. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004752851711026616. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 262][Wall Clock 35.840644095s] Trained 256 records in 0.100235408 seconds. Throughput is 2553.9875 records/second. Loss is 2.1429238. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004751948298802509. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 263][Wall Clock 35.948830155s] Trained 256 records in 0.10818606 seconds. Throughput is 2366.2937 records/second. Loss is 2.151339. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00475104522995059. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 264][Wall Clock 36.097692844s] Trained 256 records in 0.148862689 seconds. Throughput is 1719.7056 records/second. Loss is 2.138377. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004750142504275128. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 265][Wall Clock 36.197581248s] Trained 256 records in 0.099888404 seconds. Throughput is 2562.8599 records/second. Loss is 2.15723. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004749240121580548. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:19 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 266][Wall Clock 36.304839332s] Trained 256 records in 0.107258084 seconds. Throughput is 2386.7666 records/second. Loss is 2.1509125. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004748338081671416. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 267][Wall Clock 36.407278606s] Trained 256 records in 0.102439274 seconds. Throughput is 2499.0415 records/second. Loss is 2.1436627. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00474743638435245. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 268][Wall Clock 36.525877536s] Trained 256 records in 0.11859893 seconds. Throughput is 2158.5354 records/second. Loss is 2.1342587. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004746535029428517. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 269][Wall Clock 36.624987283s] Trained 256 records in 0.099109747 seconds. Throughput is 2582.995 records/second. Loss is 2.1289158. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004745634016704631. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 270][Wall Clock 36.74997406s] Trained 256 records in 0.124986777 seconds. Throughput is 2048.2168 records/second. Loss is 2.130829. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004744733345985955. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 271][Wall Clock 36.860941969s] Trained 256 records in 0.110967909 seconds. Throughput is 2306.9731 records/second. Loss is 2.138313. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004743833017077799. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 272][Wall Clock 36.964549884s] Trained 256 records in 0.103607915 seconds. Throughput is 2470.8538 records/second. Loss is 2.1229641. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00474293302978562. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 273][Wall Clock 37.096008862s] Trained 256 records in 0.131458978 seconds. Throughput is 1947.3755 records/second. Loss is 2.1292334. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004742033383915023. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 274][Wall Clock 37.198255523s] Trained 256 records in 0.102246661 seconds. Throughput is 2503.7493 records/second. Loss is 2.1375024. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004741134079271762. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:20 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 275][Wall Clock 37.304552855s] Trained 256 records in 0.106297332 seconds. Throughput is 2408.3389 records/second. Loss is 2.1267378. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004740235115661737. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 276][Wall Clock 37.409716321s] Trained 256 records in 0.105163466 seconds. Throughput is 2434.3057 records/second. Loss is 2.1446104. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004739336492890996. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 277][Wall Clock 37.51808801s] Trained 256 records in 0.108371689 seconds. Throughput is 2362.2405 records/second. Loss is 2.1209202. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004738438210765732. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 278][Wall Clock 37.622788825s] Trained 256 records in 0.104700815 seconds. Throughput is 2445.062 records/second. Loss is 2.151186. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004737540269092287. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 279][Wall Clock 37.721620693s] Trained 256 records in 0.098831868 seconds. Throughput is 2590.2576 records/second. Loss is 2.1366982. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00473664266767715. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 280][Wall Clock 37.823186462s] Trained 256 records in 0.101565769 seconds. Throughput is 2520.5342 records/second. Loss is 2.111147. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004735745406326956. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 281][Wall Clock 37.931059684s] Trained 256 records in 0.107873222 seconds. Throughput is 2373.156 records/second. Loss is 2.1243467. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004734848484848485. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 282][Wall Clock 38.034332952s] Trained 256 records in 0.103273268 seconds. Throughput is 2478.8604 records/second. Loss is 2.129828. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004733951903048665. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 283][Wall Clock 38.167947397s] Trained 256 records in 0.133614445 seconds. Throughput is 1915.9604 records/second. Loss is 2.1298394. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00473305566073457. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:21 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 284][Wall Clock 38.27546162s] Trained 256 records in 0.107514223 seconds. Throughput is 2381.0803 records/second. Loss is 2.1215038. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00473215975771342. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 285][Wall Clock 38.378002485s] Trained 256 records in 0.102540865 seconds. Throughput is 2496.5657 records/second. Loss is 2.1156225. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004731264193792582. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 286][Wall Clock 38.476969165s] Trained 256 records in 0.09896668 seconds. Throughput is 2586.7292 records/second. Loss is 2.1195543. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004730368968779565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 287][Wall Clock 38.57768953s] Trained 256 records in 0.100720365 seconds. Throughput is 2541.6904 records/second. Loss is 2.1226888. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004729474082482028. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 288][Wall Clock 38.681653814s] Trained 256 records in 0.103964284 seconds. Throughput is 2462.384 records/second. Loss is 2.1188705. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004728579534707775. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 289][Wall Clock 38.850456256s] Trained 256 records in 0.168802442 seconds. Throughput is 1516.5658 records/second. Loss is 2.1102781. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00472768532526475. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 290][Wall Clock 38.953403035s] Trained 256 records in 0.102946779 seconds. Throughput is 2486.7217 records/second. Loss is 2.1232154. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004726791453961051. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 291][Wall Clock 39.071359469s] Trained 256 records in 0.117956434 seconds. Throughput is 2170.2927 records/second. Loss is 2.0961676. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004725897920604915. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 292][Wall Clock 39.178361801s] Trained 256 records in 0.107002332 seconds. Throughput is 2392.4712 records/second. Loss is 2.1091282. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004725004725004725. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:22 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 293][Wall Clock 39.292116191s] Trained 256 records in 0.11375439 seconds. Throughput is 2250.4626 records/second. Loss is 2.0992696. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00472411186696901. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 294][Wall Clock 39.401792855s] Trained 256 records in 0.109676664 seconds. Throughput is 2334.1338 records/second. Loss is 2.1238601. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004723219346306443. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 295][Wall Clock 39.525612702s] Trained 256 records in 0.123819847 seconds. Throughput is 2067.5198 records/second. Loss is 2.115901. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004722327162825841. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 296][Wall Clock 39.665407628s] Trained 256 records in 0.139794926 seconds. Throughput is 1831.2538 records/second. Loss is 2.095395. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004721435316336167. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 297][Wall Clock 39.790230262s] Trained 256 records in 0.124822634 seconds. Throughput is 2050.9102 records/second. Loss is 2.0966408. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004720543806646526. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 298][Wall Clock 39.894533414s] Trained 256 records in 0.104303152 seconds. Throughput is 2454.384 records/second. Loss is 2.0877178. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00471965263356617. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 299][Wall Clock 40.003193375s] Trained 256 records in 0.108659961 seconds. Throughput is 2355.9736 records/second. Loss is 2.08273. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004718761796904492. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 300][Wall Clock 40.104407107s] Trained 256 records in 0.101213732 seconds. Throughput is 2529.301 records/second. Loss is 2.109693. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004717871296471032. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 301][Wall Clock 40.215421703s] Trained 256 records in 0.111014596 seconds. Throughput is 2306.0032 records/second. Loss is 2.091095. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047169811320754715. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:23 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 302][Wall Clock 40.321767864s] Trained 256 records in 0.106346161 seconds. Throughput is 2407.2332 records/second. Loss is 2.0984776. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047160913035276366. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 303][Wall Clock 40.431236491s] Trained 256 records in 0.109468627 seconds. Throughput is 2338.5696 records/second. Loss is 2.0860116. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004715201810637495. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 304][Wall Clock 40.529807504s] Trained 256 records in 0.098571013 seconds. Throughput is 2597.1125 records/second. Loss is 2.1081681. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004714312653215162. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 305][Wall Clock 40.630415039s] Trained 256 records in 0.100607535 seconds. Throughput is 2544.541 records/second. Loss is 2.1035838. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047134238310708905. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 306][Wall Clock 40.729140613s] Trained 256 records in 0.098725574 seconds. Throughput is 2593.0464 records/second. Loss is 2.0924537. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004712535344015081. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 307][Wall Clock 40.831213339s] Trained 256 records in 0.102072726 seconds. Throughput is 2508.0159 records/second. Loss is 2.1048312. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004711647191858274. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 308][Wall Clock 40.934142758s] Trained 256 records in 0.102929419 seconds. Throughput is 2487.141 records/second. Loss is 2.062638. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004710759374411156. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 309][Wall Clock 41.101094167s] Trained 256 records in 0.166951409 seconds. Throughput is 1533.3804 records/second. Loss is 2.0823913. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004709871891484551. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 310][Wall Clock 41.203173896s] Trained 256 records in 0.102079729 seconds. Throughput is 2507.8438 records/second. Loss is 2.1171362. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0047089847428894325. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:24 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 311][Wall Clock 41.303516147s] Trained 256 records in 0.100342251 seconds. Throughput is 2551.2683 records/second. Loss is 2.0721116. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004708097928436911. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 312][Wall Clock 41.40593904s] Trained 256 records in 0.102422893 seconds. Throughput is 2499.4412 records/second. Loss is 2.1081815. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004707211447938241. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 313][Wall Clock 41.516507417s] Trained 256 records in 0.110568377 seconds. Throughput is 2315.3093 records/second. Loss is 2.1063519. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00470632530120482. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 314][Wall Clock 41.659506958s] Trained 256 records in 0.142999541 seconds. Throughput is 1790.2155 records/second. Loss is 2.0725725. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004705439488048184. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 315][Wall Clock 41.81066666s] Trained 256 records in 0.151159702 seconds. Throughput is 1693.573 records/second. Loss is 2.0755143. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004704554008280015. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 316][Wall Clock 41.96126914s] Trained 256 records in 0.15060248 seconds. Throughput is 1699.8392 records/second. Loss is 2.0935676. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004703668861712136. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 317][Wall Clock 42.091484783s] Trained 256 records in 0.130215643 seconds. Throughput is 1965.9696 records/second. Loss is 2.0452332. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004702784048156509. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 318][Wall Clock 42.192007599s] Trained 256 records in 0.100522816 seconds. Throughput is 2546.6855 records/second. Loss is 2.0955143. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00470189956742524. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:25 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 319][Wall Clock 42.306532795s] Trained 256 records in 0.114525196 seconds. Throughput is 2235.316 records/second. Loss is 2.1006203. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004701015419330575. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 320][Wall Clock 42.407740336s] Trained 256 records in 0.101207541 seconds. Throughput is 2529.4558 records/second. Loss is 2.094702. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004700131603684903. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 321][Wall Clock 42.516617116s] Trained 256 records in 0.10887678 seconds. Throughput is 2351.282 records/second. Loss is 2.0714552. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004699248120300752. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 322][Wall Clock 42.627179433s] Trained 256 records in 0.110562317 seconds. Throughput is 2315.4363 records/second. Loss is 2.0729423. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004698364968990791. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 323][Wall Clock 42.735493236s] Trained 256 records in 0.108313803 seconds. Throughput is 2363.503 records/second. Loss is 2.0782888. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004697482149567831. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 324][Wall Clock 42.836367487s] Trained 256 records in 0.100874251 seconds. Throughput is 2537.813 records/second. Loss is 2.0516305. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004696599661844825. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 325][Wall Clock 42.936761326s] Trained 256 records in 0.100393839 seconds. Throughput is 2549.9573 records/second. Loss is 2.089014. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046957175056348615. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 326][Wall Clock 43.039208151s] Trained 256 records in 0.102446825 seconds. Throughput is 2498.8574 records/second. Loss is 2.074359. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004694835680751174. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 327][Wall Clock 43.144941403s] Trained 256 records in 0.105733252 seconds. Throughput is 2421.1873 records/second. Loss is 2.0657563. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004693954187007136. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:26 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 328][Wall Clock 43.246802208s] Trained 256 records in 0.101860805 seconds. Throughput is 2513.2336 records/second. Loss is 2.0591338. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004693073024216257. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 329][Wall Clock 43.348449492s] Trained 256 records in 0.101647284 seconds. Throughput is 2518.513 records/second. Loss is 2.0783021. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004692192192192192. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 330][Wall Clock 43.507209327s] Trained 256 records in 0.158759835 seconds. Throughput is 1612.4985 records/second. Loss is 2.0745676. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046913116907487335. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 331][Wall Clock 43.610178112s] Trained 256 records in 0.102968785 seconds. Throughput is 2486.1904 records/second. Loss is 2.0706704. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004690431519699812. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 332][Wall Clock 43.709842375s] Trained 256 records in 0.099664263 seconds. Throughput is 2568.6238 records/second. Loss is 2.038528. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004689551678859501. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 333][Wall Clock 43.810971676s] Trained 256 records in 0.101129301 seconds. Throughput is 2531.4128 records/second. Loss is 2.065107. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046886721680420105. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 334][Wall Clock 43.909088077s] Trained 256 records in 0.098116401 seconds. Throughput is 2609.146 records/second. Loss is 2.0709603. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004687792987061692. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 335][Wall Clock 44.006005911s] Trained 256 records in 0.096917834 seconds. Throughput is 2641.4128 records/second. Loss is 2.059685. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004686914135733034. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 336][Wall Clock 44.110542792s] Trained 256 records in 0.104536881 seconds. Throughput is 2448.8965 records/second. Loss is 2.0574749. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004686035613870666. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 337][Wall Clock 44.216897302s] Trained 256 records in 0.10635451 seconds. Throughput is 2407.0442 records/second. Loss is 2.0333657. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046851574212893555. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:27 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 338][Wall Clock 44.315226988s] Trained 256 records in 0.098329686 seconds. Throughput is 2603.4863 records/second. Loss is 2.0505843. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00468427955780401. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 339][Wall Clock 44.417931342s] Trained 256 records in 0.102704354 seconds. Throughput is 2492.5916 records/second. Loss is 2.0658958. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004683402023229674. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 340][Wall Clock 44.519804692s] Trained 256 records in 0.10187335 seconds. Throughput is 2512.924 records/second. Loss is 2.0544918. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004682524817381532. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 341][Wall Clock 44.624789915s] Trained 256 records in 0.104985223 seconds. Throughput is 2438.4385 records/second. Loss is 2.041901. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046816479400749065. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 342][Wall Clock 44.727292825s] Trained 256 records in 0.10250291 seconds. Throughput is 2497.49 records/second. Loss is 2.058059. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004680771391125257. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 343][Wall Clock 44.827525633s] Trained 256 records in 0.100232808 seconds. Throughput is 2554.054 records/second. Loss is 2.0465243. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004679895170348184. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 344][Wall Clock 44.927331156s] Trained 256 records in 0.099805523 seconds. Throughput is 2564.9883 records/second. Loss is 2.0627832. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004679019277559424. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 345][Wall Clock 45.047186932s] Trained 256 records in 0.119855776 seconds. Throughput is 2135.9004 records/second. Loss is 2.022344. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004678143712574851. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 346][Wall Clock 45.164455839s] Trained 256 records in 0.117268907 seconds. Throughput is 2183.0168 records/second. Loss is 2.0693944. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004677268475210478. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:28 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 347][Wall Clock 45.264432267s] Trained 256 records in 0.099976428 seconds. Throughput is 2560.6035 records/second. Loss is 2.0380135. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004676393565282455. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 348][Wall Clock 45.363870398s] Trained 256 records in 0.099438131 seconds. Throughput is 2574.465 records/second. Loss is 2.0330572. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046755189826070695. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 349][Wall Clock 45.462821897s] Trained 256 records in 0.098951499 seconds. Throughput is 2587.1262 records/second. Loss is 2.0617218. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004674644727000747. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 350][Wall Clock 45.563465692s] Trained 256 records in 0.100643795 seconds. Throughput is 2543.6243 records/second. Loss is 2.045264. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004673770798280052. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 351][Wall Clock 45.662452328s] Trained 256 records in 0.098986636 seconds. Throughput is 2586.2078 records/second. Loss is 2.0145466. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004672897196261682. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 352][Wall Clock 45.774032796s] Trained 256 records in 0.111580468 seconds. Throughput is 2294.3083 records/second. Loss is 2.02379. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004672023920762474. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 353][Wall Clock 45.883191362s] Trained 256 records in 0.109158566 seconds. Throughput is 2345.2122 records/second. Loss is 2.0238936. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004671150971599402. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 354][Wall Clock 45.985774472s] Trained 256 records in 0.10258311 seconds. Throughput is 2495.5376 records/second. Loss is 2.03367. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004670278348589576. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 355][Wall Clock 46.083860833s] Trained 256 records in 0.098086361 seconds. Throughput is 2609.9448 records/second. Loss is 2.0373144. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004669406051550243. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 356][Wall Clock 46.185976867s] Trained 256 records in 0.102116034 seconds. Throughput is 2506.9521 records/second. Loss is 2.031687. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004668534080298786. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:29 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 357][Wall Clock 46.288365273s] Trained 256 records in 0.102388406 seconds. Throughput is 2500.2832 records/second. Loss is 2.0191822. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046676624346527265. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 358][Wall Clock 46.391523277s] Trained 256 records in 0.103158004 seconds. Throughput is 2481.6301 records/second. Loss is 2.0475733. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004666791114429718. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 359][Wall Clock 46.492003652s] Trained 256 records in 0.100480375 seconds. Throughput is 2547.7612 records/second. Loss is 2.016793. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004665920119447555. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 360][Wall Clock 46.594019673s] Trained 256 records in 0.102016021 seconds. Throughput is 2509.4097 records/second. Loss is 2.0388126. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046650494495241645. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 361][Wall Clock 46.692767666s] Trained 256 records in 0.098747993 seconds. Throughput is 2592.4578 records/second. Loss is 2.0113425. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046641791044776115. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 362][Wall Clock 46.793143576s] Trained 256 records in 0.10037591 seconds. Throughput is 2550.4126 records/second. Loss is 2.0374782. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004663309084126096. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 363][Wall Clock 46.897610147s] Trained 256 records in 0.104466571 seconds. Throughput is 2450.5447 records/second. Loss is 2.014918. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004662439388287952. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 364][Wall Clock 47.001070516s] Trained 256 records in 0.103460369 seconds. Throughput is 2474.3774 records/second. Loss is 2.0100408. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004661570016781652. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 365][Wall Clock 47.099818916s] Trained 256 records in 0.0987484 seconds. Throughput is 2592.447 records/second. Loss is 2.0405996. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004660700969425802. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 366][Wall Clock 47.20644053s] Trained 256 records in 0.106621614 seconds. Throughput is 2401.0142 records/second. Loss is 2.0090532. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004659832246039143. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:30 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 367][Wall Clock 47.308302889s] Trained 256 records in 0.101862359 seconds. Throughput is 2513.1953 records/second. Loss is 2.0158646. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004658963846440552. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 368][Wall Clock 47.412730729s] Trained 256 records in 0.10442784 seconds. Throughput is 2451.4536 records/second. Loss is 2.0057175. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004658095770449041. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 369][Wall Clock 47.526664973s] Trained 256 records in 0.113934244 seconds. Throughput is 2246.9102 records/second. Loss is 2.0418363. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004657228017883756. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 370][Wall Clock 47.630606224s] Trained 256 records in 0.103941251 seconds. Throughput is 2462.9297 records/second. Loss is 2.012096. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004656360588563978. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 371][Wall Clock 47.732924322s] Trained 256 records in 0.102318098 seconds. Throughput is 2502.001 records/second. Loss is 2.0092642. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004655493482309124. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 372][Wall Clock 47.852291974s] Trained 256 records in 0.119367652 seconds. Throughput is 2144.6345 records/second. Loss is 2.0110464. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004654626698938745. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 373][Wall Clock 47.952408939s] Trained 256 records in 0.100116965 seconds. Throughput is 2557.009 records/second. Loss is 2.0036647. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004653760238272524. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 374][Wall Clock 48.051932258s] Trained 256 records in 0.099523319 seconds. Throughput is 2572.2615 records/second. Loss is 1.9999791. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004652894100130281. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:31 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 375][Wall Clock 48.151025794s] Trained 256 records in 0.099093536 seconds. Throughput is 2583.4177 records/second. Loss is 1.9974568. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004652028284331969. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 376][Wall Clock 48.334450232s] Trained 256 records in 0.183424438 seconds. Throughput is 1395.67 records/second. Loss is 2.0007207. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004651162790697674. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 377][Wall Clock 48.448632703s] Trained 256 records in 0.114182471 seconds. Throughput is 2242.0254 records/second. Loss is 1.9821398. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004650297619047619. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 378][Wall Clock 48.557655588s] Trained 256 records in 0.109022885 seconds. Throughput is 2348.1309 records/second. Loss is 1.9933323. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004649432769202158. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 379][Wall Clock 48.659528947s] Trained 256 records in 0.101873359 seconds. Throughput is 2512.9238 records/second. Loss is 2.0120502. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046485682409817776. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 380][Wall Clock 48.756367604s] Trained 256 records in 0.096838657 seconds. Throughput is 2643.5723 records/second. Loss is 1.993374. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046477040342071015. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 381][Wall Clock 48.865397483s] Trained 256 records in 0.109029879 seconds. Throughput is 2347.9802 records/second. Loss is 1.9802945. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004646840148698885. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 382][Wall Clock 48.972792772s] Trained 256 records in 0.107395289 seconds. Throughput is 2383.7173 records/second. Loss is 1.9802756. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004645976584278015. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 383][Wall Clock 49.082398313s] Trained 256 records in 0.109605541 seconds. Throughput is 2335.6482 records/second. Loss is 1.9831178. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004645113340765515. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 384][Wall Clock 49.194451251s] Trained 256 records in 0.112052938 seconds. Throughput is 2284.6343 records/second. Loss is 1.9684939. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004644250417982537. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:32 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 385][Wall Clock 49.295833129s] Trained 256 records in 0.101381878 seconds. Throughput is 2525.1062 records/second. Loss is 1.9894323. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046433878157503715. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 386][Wall Clock 49.397185233s] Trained 256 records in 0.101352104 seconds. Throughput is 2525.848 records/second. Loss is 2.0242152. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004642525533890437. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 387][Wall Clock 49.502934454s] Trained 256 records in 0.105749221 seconds. Throughput is 2420.8215 records/second. Loss is 1.9590389. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004641663572224285. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 388][Wall Clock 49.657486708s] Trained 256 records in 0.154552254 seconds. Throughput is 1656.3977 records/second. Loss is 1.9933729. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004640801930573603. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 389][Wall Clock 49.754555223s] Trained 256 records in 0.097068515 seconds. Throughput is 2637.3123 records/second. Loss is 1.9764792. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004639940608760208. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 390][Wall Clock 49.852843827s] Trained 256 records in 0.098288604 seconds. Throughput is 2604.5747 records/second. Loss is 1.9491241. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004639079606606049. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 391][Wall Clock 49.953108077s] Trained 256 records in 0.10026425 seconds. Throughput is 2553.253 records/second. Loss is 1.9809842. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00463821892393321. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 392][Wall Clock 50.05985812s] Trained 256 records in 0.106750043 seconds. Throughput is 2398.1255 records/second. Loss is 1.9558436. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004637358560563903. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 393][Wall Clock 50.160719508s] Trained 256 records in 0.100861388 seconds. Throughput is 2538.137 records/second. Loss is 1.9971515. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004636498516320474. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:33 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 394][Wall Clock 50.273397782s] Trained 256 records in 0.112678274 seconds. Throughput is 2271.9553 records/second. Loss is 1.985803. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004635638791025403. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 395][Wall Clock 50.37131188s] Trained 256 records in 0.097914098 seconds. Throughput is 2614.5366 records/second. Loss is 1.9649869. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004634779384501298. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 396][Wall Clock 50.470457728s] Trained 256 records in 0.099145848 seconds. Throughput is 2582.0547 records/second. Loss is 1.9561594. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046339202965708995. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 397][Wall Clock 50.570244426s] Trained 256 records in 0.099786698 seconds. Throughput is 2565.4722 records/second. Loss is 1.9929442. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004633061527057079. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 398][Wall Clock 50.666460285s] Trained 256 records in 0.096215859 seconds. Throughput is 2660.684 records/second. Loss is 1.9972016. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004632203075782843. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 399][Wall Clock 50.77931852s] Trained 256 records in 0.112858235 seconds. Throughput is 2268.3325 records/second. Loss is 1.9641385. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004631344942571322. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 400][Wall Clock 50.877198228s] Trained 256 records in 0.097879708 seconds. Throughput is 2615.4553 records/second. Loss is 1.9622071. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004630487127245786. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 401][Wall Clock 50.984878925s] Trained 256 records in 0.107680697 seconds. Throughput is 2377.3992 records/second. Loss is 1.9476935. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004629629629629629. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 402][Wall Clock 51.085536424s] Trained 256 records in 0.100657499 seconds. Throughput is 2543.2778 records/second. Loss is 1.9256558. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00462877244954638. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 403][Wall Clock 51.184476406s] Trained 256 records in 0.098939982 seconds. Throughput is 2587.427 records/second. Loss is 1.9709139. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004627915586819697. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:34 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 404][Wall Clock 51.281927269s] Trained 256 records in 0.097450863 seconds. Throughput is 2626.965 records/second. Loss is 1.9516684. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004627059041273367. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 405][Wall Clock 51.379266305s] Trained 256 records in 0.097339036 seconds. Throughput is 2629.983 records/second. Loss is 1.9664178. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046262028127313105. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 406][Wall Clock 51.475828355s] Trained 256 records in 0.09656205 seconds. Throughput is 2651.145 records/second. Loss is 1.9685446. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004625346901017576. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 407][Wall Clock 51.573094399s] Trained 256 records in 0.097266044 seconds. Throughput is 2631.9565 records/second. Loss is 1.9725871. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004624491305956345. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 408][Wall Clock 51.670418695s] Trained 256 records in 0.097324296 seconds. Throughput is 2630.381 records/second. Loss is 1.9547869. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046236360273719255. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 409][Wall Clock 51.767002017s] Trained 256 records in 0.096583322 seconds. Throughput is 2650.561 records/second. Loss is 1.9298075. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004622781065088758. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 410][Wall Clock 51.922717908s] Trained 256 records in 0.155715891 seconds. Throughput is 1644.0197 records/second. Loss is 1.9528209. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046219264189314106. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 411][Wall Clock 52.020294836s] Trained 256 records in 0.097576928 seconds. Throughput is 2623.571 records/second. Loss is 1.9716716. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004621072088724584. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:35 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 412][Wall Clock 52.173930945s] Trained 256 records in 0.153636109 seconds. Throughput is 1666.2749 records/second. Loss is 1.9307489. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004620218074293106. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 413][Wall Clock 52.321618038s] Trained 256 records in 0.147687093 seconds. Throughput is 1733.3945 records/second. Loss is 1.9317411. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004619364375461937. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 414][Wall Clock 52.469328549s] Trained 256 records in 0.147710511 seconds. Throughput is 1733.1196 records/second. Loss is 1.9391056. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004618510992056161. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 415][Wall Clock 52.614219932s] Trained 256 records in 0.144891383 seconds. Throughput is 1766.8408 records/second. Loss is 1.9385366. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004617657923900997. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 416][Wall Clock 52.709108642s] Trained 256 records in 0.09488871 seconds. Throughput is 2697.8975 records/second. Loss is 1.9796427. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046168051708217915. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 417][Wall Clock 52.806201642s] Trained 256 records in 0.097093 seconds. Throughput is 2636.6472 records/second. Loss is 1.9163004. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004615952732644018. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 418][Wall Clock 52.928003803s] Trained 256 records in 0.121802161 seconds. Throughput is 2101.769 records/second. Loss is 1.9330854. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0046151006091932805. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 419][Wall Clock 53.035262331s] Trained 256 records in 0.107258528 seconds. Throughput is 2386.7566 records/second. Loss is 1.9148272. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004614248800295311. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 420][Wall Clock 53.167180511s] Trained 256 records in 0.13191818 seconds. Throughput is 1940.5968 records/second. Loss is 1.9217322. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004613397305775973. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:36 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 421][Wall Clock 53.263285521s] Trained 256 records in 0.09610501 seconds. Throughput is 2663.753 records/second. Loss is 1.9490211. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004612546125461255. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 422][Wall Clock 53.365549714s] Trained 256 records in 0.102264193 seconds. Throughput is 2503.3198 records/second. Loss is 1.958122. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004611695259177273. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 423][Wall Clock 53.458333915s] Trained 256 records in 0.092784201 seconds. Throughput is 2759.0903 records/second. Loss is 1.9449207. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004610844706750277. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 424][Wall Clock 53.553753229s] Trained 256 records in 0.095419314 seconds. Throughput is 2682.895 records/second. Loss is 1.9265379. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004609994468006639. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 425][Wall Clock 53.649705146s] Trained 256 records in 0.095951917 seconds. Throughput is 2668.003 records/second. Loss is 1.918496. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004609144542772861. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 426][Wall Clock 53.742958999s] Trained 256 records in 0.093253853 seconds. Throughput is 2745.1948 records/second. Loss is 1.9123044. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004608294930875576. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 427][Wall Clock 53.851256755s] Trained 256 records in 0.108297756 seconds. Throughput is 2363.8533 records/second. Loss is 1.9297726. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004607445632141541. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 428][Wall Clock 53.946117572s] Trained 256 records in 0.094860817 seconds. Throughput is 2698.6907 records/second. Loss is 1.9327047. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004606596646397642. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 429][Wall Clock 54.044665568s] Trained 256 records in 0.098547996 seconds. Throughput is 2597.719 records/second. Loss is 1.894232. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004605747973470892. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 430][Wall Clock 54.141499265s] Trained 256 records in 0.096833697 seconds. Throughput is 2643.7078 records/second. Loss is 1.9190618. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004604899613188432. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:37 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 431][Wall Clock 54.236179367s] Trained 256 records in 0.094680102 seconds. Throughput is 2703.8416 records/second. Loss is 1.9190269. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004604051565377532. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 432][Wall Clock 54.331061302s] Trained 256 records in 0.094881935 seconds. Throughput is 2698.0898 records/second. Loss is 1.8974233. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004603203829865586. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 433][Wall Clock 54.425380484s] Trained 256 records in 0.094319182 seconds. Throughput is 2714.1882 records/second. Loss is 1.9025288. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004602356406480118. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 434][Wall Clock 54.519886096s] Trained 256 records in 0.094505612 seconds. Throughput is 2708.8337 records/second. Loss is 1.9092915. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004601509295048776. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 435][Wall Clock 54.614550033s] Trained 256 records in 0.094663937 seconds. Throughput is 2704.3032 records/second. Loss is 1.9042263. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004600662495399338. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 436][Wall Clock 54.713522435s] Trained 256 records in 0.098972402 seconds. Throughput is 2586.5796 records/second. Loss is 1.8867192. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004599816007359706. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 437][Wall Clock 54.809092954s] Trained 256 records in 0.095570519 seconds. Throughput is 2678.6504 records/second. Loss is 1.9052145. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004598969830757911. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 438][Wall Clock 54.90390962s] Trained 256 records in 0.094816666 seconds. Throughput is 2699.9475 records/second. Loss is 1.8934984. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045981239654221085. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 439][Wall Clock 54.998232806s] Trained 256 records in 0.094323186 seconds. Throughput is 2714.0728 records/second. Loss is 1.9147613. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045972784111805816. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 440][Wall Clock 55.093885941s] Trained 256 records in 0.095653135 seconds. Throughput is 2676.337 records/second. Loss is 1.9124019. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004596433167861739. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 441][Wall Clock 55.189765919s] Trained 256 records in 0.095879978 seconds. Throughput is 2670.0046 records/second. Loss is 1.8943478. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004595588235294118. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:38 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 442][Wall Clock 55.287188837s] Trained 256 records in 0.097422918 seconds. Throughput is 2627.7185 records/second. Loss is 1.8902832. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004594743613306377. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 443][Wall Clock 55.389695051s] Trained 256 records in 0.102506214 seconds. Throughput is 2497.4097 records/second. Loss is 1.895921. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004593899301727306. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 444][Wall Clock 55.489263541s] Trained 256 records in 0.09956849 seconds. Throughput is 2571.0945 records/second. Loss is 1.8867447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045930553003858164. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 445][Wall Clock 55.60443336s] Trained 256 records in 0.115169819 seconds. Throughput is 2222.8047 records/second. Loss is 1.9034936. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004592211609110948. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 446][Wall Clock 55.700359134s] Trained 256 records in 0.095925774 seconds. Throughput is 2668.7302 records/second. Loss is 1.8846977. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004591368227731864. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 447][Wall Clock 55.795242079s] Trained 256 records in 0.094882945 seconds. Throughput is 2698.0613 records/second. Loss is 1.8940101. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004590525156077855. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 448][Wall Clock 55.892199659s] Trained 256 records in 0.09695758 seconds. Throughput is 2640.3298 records/second. Loss is 1.8886725. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004589682393978337. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 449][Wall Clock 55.986050511s] Trained 256 records in 0.093850852 seconds. Throughput is 2727.7324 records/second. Loss is 1.8771007. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004588839941262849. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 450][Wall Clock 56.080158244s] Trained 256 records in 0.094107733 seconds. Throughput is 2720.2866 records/second. Loss is 1.8832479. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004587997797761057. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 451][Wall Clock 56.183104271s] Trained 256 records in 0.102946027 seconds. Throughput is 2486.74 records/second. Loss is 1.9218129. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004587155963302752. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:39 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 452][Wall Clock 56.289943929s] Trained 256 records in 0.106839658 seconds. Throughput is 2396.114 records/second. Loss is 1.8752601. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00458631443771785. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 453][Wall Clock 56.383408781s] Trained 256 records in 0.093464852 seconds. Throughput is 2738.9976 records/second. Loss is 1.8675984. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045854732208363905. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 454][Wall Clock 56.476532353s] Trained 256 records in 0.093123572 seconds. Throughput is 2749.0354 records/second. Loss is 1.8623291. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045846323124885385. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 455][Wall Clock 56.57052404s] Trained 256 records in 0.093991687 seconds. Throughput is 2723.645 records/second. Loss is 1.8783268. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004583791712504584. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 456][Wall Clock 56.676373628s] Trained 256 records in 0.105849588 seconds. Throughput is 2418.5261 records/second. Loss is 1.8660778. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00458295142071494. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 457][Wall Clock 56.774368703s] Trained 256 records in 0.097995075 seconds. Throughput is 2612.3762 records/second. Loss is 1.854418. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004582111436950147. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 458][Wall Clock 56.874825966s] Trained 256 records in 0.100457263 seconds. Throughput is 2548.3472 records/second. Loss is 1.9060379. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004581271761040865. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 459][Wall Clock 56.969108329s] Trained 256 records in 0.094282363 seconds. Throughput is 2715.248 records/second. Loss is 1.840269. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004580432392817882. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 460][Wall Clock 57.062438402s] Trained 256 records in 0.093330073 seconds. Throughput is 2742.9531 records/second. Loss is 1.8349612. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045795933321121085. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 461][Wall Clock 57.159538844s] Trained 256 records in 0.097100442 seconds. Throughput is 2636.4453 records/second. Loss is 1.8582475. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004578754578754578. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:40 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 462][Wall Clock 57.256537091s] Trained 256 records in 0.096998247 seconds. Throughput is 2639.223 records/second. Loss is 1.8431833. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004577916132576451. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 463][Wall Clock 57.351338877s] Trained 256 records in 0.094801786 seconds. Throughput is 2700.371 records/second. Loss is 1.8413665. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045770779934090075. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 464][Wall Clock 57.444723671s] Trained 256 records in 0.093384794 seconds. Throughput is 2741.3457 records/second. Loss is 1.8947396. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004576240161083654. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 465][Wall Clock 57.541589175s] Trained 256 records in 0.096865504 seconds. Throughput is 2642.8396 records/second. Loss is 1.9022201. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004575402635431918. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 466][Wall Clock 57.634009124s] Trained 256 records in 0.092419949 seconds. Throughput is 2769.9646 records/second. Loss is 1.8507937. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004574565416285453. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 467][Wall Clock 57.729225015s] Trained 256 records in 0.095215891 seconds. Throughput is 2688.6267 records/second. Loss is 1.8931725. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004573728503476034. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 468][Wall Clock 57.822665364s] Trained 256 records in 0.093440349 seconds. Throughput is 2739.7158 records/second. Loss is 1.8819317. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004572891896835559. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 469][Wall Clock 57.919053427s] Trained 256 records in 0.096388063 seconds. Throughput is 2655.9304 records/second. Loss is 1.883817. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00457205559619605. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:408 - [Epoch 2 60160/60000][Iteration 470][Wall Clock 58.02387452s] Trained 256 records in 0.104821093 seconds. Throughput is 2442.2566 records/second. Loss is 1.8613447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00457121960138965. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:41 INFO  DistriOptimizer$:452 - [Epoch 2 60160/60000][Iteration 470][Wall Clock 58.02387452s] Epoch finished. Wall clock time is 59190.48084 ms
2019-10-26 12:15:41 INFO  DistriOptimizer$:111 - [Epoch 2 60160/60000][Iteration 470][Wall Clock 58.02387452s] Validate model...
2019-10-26 12:15:42 INFO  DistriOptimizer$:178 - [Epoch 2 60160/60000][Iteration 470][Wall Clock 58.02387452s] validate model throughput is 11434.615 records/second
2019-10-26 12:15:42 INFO  DistriOptimizer$:181 - [Epoch 2 60160/60000][Iteration 470][Wall Clock 58.02387452s] Top1Accuracy is Accuracy(correct: 6284, count: 10000, accuracy: 0.6284)
2019-10-26 12:15:42 INFO  DistriOptimizer$:221 - [Wall Clock 59.19048084s] Save model to /tmp/lenet5/20191026_121442
2019-10-26 12:15:42 INFO  DistriOptimizer$:226 - [Wall Clock 59.19048084s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@13b5664a to /tmp/lenet5/20191026_121442
2019-10-26 12:15:42 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 471][Wall Clock 59.359510745s] Trained 256 records in 0.169029905 seconds. Throughput is 1514.5249 records/second. Loss is 1.853082. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004570383912248629. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:42 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 472][Wall Clock 59.45376373s] Trained 256 records in 0.094252985 seconds. Throughput is 2716.0942 records/second. Loss is 1.8801343. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045695485286053735. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 473][Wall Clock 59.552184786s] Trained 256 records in 0.098421056 seconds. Throughput is 2601.0693 records/second. Loss is 1.8371462. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004568713450292397. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 474][Wall Clock 59.648251472s] Trained 256 records in 0.096066686 seconds. Throughput is 2664.8157 records/second. Loss is 1.8217893. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004567878677142335. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 475][Wall Clock 59.753340152s] Trained 256 records in 0.10508868 seconds. Throughput is 2436.0378 records/second. Loss is 1.8034062. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004567044208987943. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 476][Wall Clock 59.906309084s] Trained 256 records in 0.152968932 seconds. Throughput is 1673.5425 records/second. Loss is 1.794374. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004566210045662101. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 477][Wall Clock 60.009372608s] Trained 256 records in 0.103063524 seconds. Throughput is 2483.905 records/second. Loss is 1.8566091. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004565376186997809. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 478][Wall Clock 60.108682245s] Trained 256 records in 0.099309637 seconds. Throughput is 2577.7961 records/second. Loss is 1.8070493. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004564542632828191. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 479][Wall Clock 60.204422578s] Trained 256 records in 0.095740333 seconds. Throughput is 2673.8992 records/second. Loss is 1.80478. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045637093829864915. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 480][Wall Clock 60.300458342s] Trained 256 records in 0.096035764 seconds. Throughput is 2665.6736 records/second. Loss is 1.8395897. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004562876437306077. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 481][Wall Clock 60.397118553s] Trained 256 records in 0.096660211 seconds. Throughput is 2648.4526 records/second. Loss is 1.8178734. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004562043795620438. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:43 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 482][Wall Clock 60.495602367s] Trained 256 records in 0.098483814 seconds. Throughput is 2599.4119 records/second. Loss is 1.8261884. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045612114577631814. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 483][Wall Clock 60.592699757s] Trained 256 records in 0.09709739 seconds. Throughput is 2636.528 records/second. Loss is 1.8052602. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004560379423568041. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 484][Wall Clock 60.686554146s] Trained 256 records in 0.093854389 seconds. Throughput is 2727.6294 records/second. Loss is 1.8205072. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004559547692868867. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 485][Wall Clock 60.78580614s] Trained 256 records in 0.099251994 seconds. Throughput is 2579.2932 records/second. Loss is 1.7975036. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004558716265499635. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 486][Wall Clock 60.882768135s] Trained 256 records in 0.096961995 seconds. Throughput is 2640.2097 records/second. Loss is 1.7940861. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00455788514129444. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 487][Wall Clock 60.977127722s] Trained 256 records in 0.094359587 seconds. Throughput is 2713.026 records/second. Loss is 1.8431338. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004557054320087496. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 488][Wall Clock 61.072123931s] Trained 256 records in 0.094996209 seconds. Throughput is 2694.8445 records/second. Loss is 1.805046. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00455622380171314. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 489][Wall Clock 61.16738679s] Trained 256 records in 0.095262859 seconds. Throughput is 2687.3013 records/second. Loss is 1.8254563. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004555393586005831. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 490][Wall Clock 61.261688488s] Trained 256 records in 0.094301698 seconds. Throughput is 2714.6912 records/second. Loss is 1.7776899. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045545636728001465. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 491][Wall Clock 61.363340141s] Trained 256 records in 0.101651653 seconds. Throughput is 2518.4048 records/second. Loss is 1.8085363. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004553734061930783. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:44 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 492][Wall Clock 61.459661899s] Trained 256 records in 0.096321758 seconds. Throughput is 2657.7588 records/second. Loss is 1.7854536. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004552904753232562. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 493][Wall Clock 61.572850894s] Trained 256 records in 0.113188995 seconds. Throughput is 2261.7039 records/second. Loss is 1.7777331. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004552075746540422. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 494][Wall Clock 61.670769575s] Trained 256 records in 0.097918681 seconds. Throughput is 2614.4143 records/second. Loss is 1.8233697. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004551247041689423. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 495][Wall Clock 61.771485192s] Trained 256 records in 0.100715617 seconds. Throughput is 2541.8105 records/second. Loss is 1.8155011. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004550418638514743. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 496][Wall Clock 61.868531761s] Trained 256 records in 0.097046569 seconds. Throughput is 2637.909 records/second. Loss is 1.8082656. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004549590536851684. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 497][Wall Clock 61.964203776s] Trained 256 records in 0.095672015 seconds. Throughput is 2675.8086 records/second. Loss is 1.7714816. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004548762736535663. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 498][Wall Clock 62.060450582s] Trained 256 records in 0.096246806 seconds. Throughput is 2659.8284 records/second. Loss is 1.8156714. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00454793523740222. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 499][Wall Clock 62.155810656s] Trained 256 records in 0.095360074 seconds. Throughput is 2684.5618 records/second. Loss is 1.792894. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004547108039287014. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 500][Wall Clock 62.253647775s] Trained 256 records in 0.097837119 seconds. Throughput is 2616.5938 records/second. Loss is 1.785794. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004546281142025823. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 501][Wall Clock 62.357445857s] Trained 256 records in 0.103798082 seconds. Throughput is 2466.327 records/second. Loss is 1.8046488. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004545454545454545. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:45 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 502][Wall Clock 62.452994703s] Trained 256 records in 0.095548846 seconds. Throughput is 2679.2578 records/second. Loss is 1.8023323. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004544628249409198. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 503][Wall Clock 62.545994786s] Trained 256 records in 0.093000083 seconds. Throughput is 2752.6858 records/second. Loss is 1.7762058. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045438022537259174. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 504][Wall Clock 62.640558463s] Trained 256 records in 0.094563677 seconds. Throughput is 2707.1704 records/second. Loss is 1.7723743. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004542976558240959. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 505][Wall Clock 62.738099864s] Trained 256 records in 0.097541401 seconds. Throughput is 2624.5266 records/second. Loss is 1.7941371. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004542151162790698. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 506][Wall Clock 62.83316632s] Trained 256 records in 0.095066456 seconds. Throughput is 2692.853 records/second. Loss is 1.769699. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004541326067211626. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 507][Wall Clock 62.928901379s] Trained 256 records in 0.095735059 seconds. Throughput is 2674.0466 records/second. Loss is 1.812534. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004540501271340356. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 508][Wall Clock 63.027264674s] Trained 256 records in 0.098363295 seconds. Throughput is 2602.597 records/second. Loss is 1.7855256. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045396767750136196. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 509][Wall Clock 63.121621173s] Trained 256 records in 0.094356499 seconds. Throughput is 2713.1147 records/second. Loss is 1.8071282. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004538852578068265. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 510][Wall Clock 63.219516281s] Trained 256 records in 0.097895108 seconds. Throughput is 2615.044 records/second. Loss is 1.7481089. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00453802868034126. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 511][Wall Clock 63.315628908s] Trained 256 records in 0.096112627 seconds. Throughput is 2663.542 records/second. Loss is 1.7548612. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004537205081669691. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:46 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 512][Wall Clock 63.423468128s] Trained 256 records in 0.10783922 seconds. Throughput is 2373.9045 records/second. Loss is 1.7432988. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004536381781890764. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 513][Wall Clock 63.527724077s] Trained 256 records in 0.104255949 seconds. Throughput is 2455.4954 records/second. Loss is 1.745149. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045355587808417995. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 514][Wall Clock 63.622367271s] Trained 256 records in 0.094643194 seconds. Throughput is 2704.8962 records/second. Loss is 1.7828666. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045347360783602395. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 515][Wall Clock 63.71704192s] Trained 256 records in 0.094674649 seconds. Throughput is 2703.9973 records/second. Loss is 1.7803752. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004533913674283642. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 516][Wall Clock 63.811012249s] Trained 256 records in 0.093970329 seconds. Throughput is 2724.2642 records/second. Loss is 1.7737441. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004533091568449683. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 517][Wall Clock 63.906376793s] Trained 256 records in 0.095364544 seconds. Throughput is 2684.436 records/second. Loss is 1.7472019. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045322697606961565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 518][Wall Clock 64.012543981s] Trained 256 records in 0.106167188 seconds. Throughput is 2411.291 records/second. Loss is 1.7605032. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004531448250860976. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 519][Wall Clock 64.114637805s] Trained 256 records in 0.102093824 seconds. Throughput is 2507.4973 records/second. Loss is 1.7087542. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004530627038782168. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 520][Wall Clock 64.212221944s] Trained 256 records in 0.097584139 seconds. Throughput is 2623.3772 records/second. Loss is 1.7762041. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00452980612429788. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 521][Wall Clock 64.305814314s] Trained 256 records in 0.09359237 seconds. Throughput is 2735.2659 records/second. Loss is 1.8010944. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004528985507246376. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 522][Wall Clock 64.401094683s] Trained 256 records in 0.095280369 seconds. Throughput is 2686.8074 records/second. Loss is 1.7791337. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004528165187466038. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:47 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 523][Wall Clock 64.492837614s] Trained 256 records in 0.091742931 seconds. Throughput is 2790.4058 records/second. Loss is 1.7219845. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004527345164795364. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 524][Wall Clock 64.588074211s] Trained 256 records in 0.095236597 seconds. Throughput is 2688.0422 records/second. Loss is 1.7309176. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004526525439072967. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 525][Wall Clock 64.685862047s] Trained 256 records in 0.097787836 seconds. Throughput is 2617.9126 records/second. Loss is 1.7630106. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004525706010137582. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 526][Wall Clock 64.835548604s] Trained 256 records in 0.149686557 seconds. Throughput is 1710.2404 records/second. Loss is 1.8033208. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004524886877828055. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 527][Wall Clock 64.983176836s] Trained 256 records in 0.147628232 seconds. Throughput is 1734.0857 records/second. Loss is 1.7425747. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004524068041983352. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 528][Wall Clock 65.079547515s] Trained 256 records in 0.096370679 seconds. Throughput is 2656.4097 records/second. Loss is 1.7283498. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045232495024425555. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 529][Wall Clock 65.184959513s] Trained 256 records in 0.105411998 seconds. Throughput is 2428.566 records/second. Loss is 1.7201992. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004522431259044863. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 530][Wall Clock 65.284950103s] Trained 256 records in 0.09999059 seconds. Throughput is 2560.241 records/second. Loss is 1.7432142. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00452161331162959. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 531][Wall Clock 65.387528261s] Trained 256 records in 0.102578158 seconds. Throughput is 2495.658 records/second. Loss is 1.7518158. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004520795660036166. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:48 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 532][Wall Clock 65.488466412s] Trained 256 records in 0.100938151 seconds. Throughput is 2536.2065 records/second. Loss is 1.7655661. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00451997830410414. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 533][Wall Clock 65.615837072s] Trained 256 records in 0.12737066 seconds. Throughput is 2009.8821 records/second. Loss is 1.7650421. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004519161243673174. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 534][Wall Clock 65.711513724s] Trained 256 records in 0.095676652 seconds. Throughput is 2675.679 records/second. Loss is 1.7484922. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004518344478583047. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 535][Wall Clock 65.809274918s] Trained 256 records in 0.097761194 seconds. Throughput is 2618.626 records/second. Loss is 1.7231774. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004517528008673654. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 536][Wall Clock 65.905225632s] Trained 256 records in 0.095950714 seconds. Throughput is 2668.0364 records/second. Loss is 1.7226185. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004516711833785005. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 537][Wall Clock 66.002842917s] Trained 256 records in 0.097617285 seconds. Throughput is 2622.4863 records/second. Loss is 1.7171713. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004515895953757226. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 538][Wall Clock 66.09738044s] Trained 256 records in 0.094537523 seconds. Throughput is 2707.9194 records/second. Loss is 1.7561255. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004515080368430558. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 539][Wall Clock 66.196455657s] Trained 256 records in 0.099075217 seconds. Throughput is 2583.8953 records/second. Loss is 1.7465855. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00451426507764536. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 540][Wall Clock 66.29606104s] Trained 256 records in 0.099605383 seconds. Throughput is 2570.1423 records/second. Loss is 1.6891152. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004513450081242101. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 541][Wall Clock 66.391048692s] Trained 256 records in 0.094987652 seconds. Throughput is 2695.0872 records/second. Loss is 1.7219305. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004512635379061372. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:49 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 542][Wall Clock 66.4959654s] Trained 256 records in 0.104916708 seconds. Throughput is 2440.0308 records/second. Loss is 1.7359505. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004511820970943873. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 543][Wall Clock 66.656587261s] Trained 256 records in 0.160621861 seconds. Throughput is 1593.8054 records/second. Loss is 1.7068486. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004511006856730422. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 544][Wall Clock 66.762972601s] Trained 256 records in 0.10638534 seconds. Throughput is 2406.3464 records/second. Loss is 1.6835796. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004510193036261952. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 545][Wall Clock 66.85942062s] Trained 256 records in 0.096448019 seconds. Throughput is 2654.2795 records/second. Loss is 1.746696. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004509379509379509. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 546][Wall Clock 66.955087618s] Trained 256 records in 0.095666998 seconds. Throughput is 2675.949 records/second. Loss is 1.6997409. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004508566275924256. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 547][Wall Clock 67.052616114s] Trained 256 records in 0.097528496 seconds. Throughput is 2624.8738 records/second. Loss is 1.709683. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004507753335737469. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 548][Wall Clock 67.14812221s] Trained 256 records in 0.095506096 seconds. Throughput is 2680.4573 records/second. Loss is 1.6490436. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045069406886605375. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 549][Wall Clock 67.241179809s] Trained 256 records in 0.093057599 seconds. Throughput is 2750.9844 records/second. Loss is 1.6988466. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004506128334534968. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 550][Wall Clock 67.334437221s] Trained 256 records in 0.093257412 seconds. Throughput is 2745.09 records/second. Loss is 1.655714. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00450531627320238. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:50 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 551][Wall Clock 67.436948198s] Trained 256 records in 0.102510977 seconds. Throughput is 2497.2937 records/second. Loss is 1.7250842. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045045045045045045. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 552][Wall Clock 67.530662588s] Trained 256 records in 0.09371439 seconds. Throughput is 2731.704 records/second. Loss is 1.6539764. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004503693028283192. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 553][Wall Clock 67.624983293s] Trained 256 records in 0.094320705 seconds. Throughput is 2714.1443 records/second. Loss is 1.6993414. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045028818443804035. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 554][Wall Clock 67.721761226s] Trained 256 records in 0.096777933 seconds. Throughput is 2645.2312 records/second. Loss is 1.6780823. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0045020709526382135. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 555][Wall Clock 67.816509664s] Trained 256 records in 0.094748438 seconds. Throughput is 2701.8916 records/second. Loss is 1.7209349. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004501260352898812. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 556][Wall Clock 67.910637913s] Trained 256 records in 0.094128249 seconds. Throughput is 2719.6936 records/second. Loss is 1.7194372. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004500450045004501. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 557][Wall Clock 68.002890918s] Trained 256 records in 0.092253005 seconds. Throughput is 2774.9773 records/second. Loss is 1.7197877. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004499640028797696. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 558][Wall Clock 68.099163353s] Trained 256 records in 0.096272435 seconds. Throughput is 2659.1206 records/second. Loss is 1.6535785. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004498830304120929. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 559][Wall Clock 68.191417435s] Trained 256 records in 0.092254082 seconds. Throughput is 2774.945 records/second. Loss is 1.6516335. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004498020870816841. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 560][Wall Clock 68.28228312s] Trained 256 records in 0.090865685 seconds. Throughput is 2817.3452 records/second. Loss is 1.7018814. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004497211728728188. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 561][Wall Clock 68.377637034s] Trained 256 records in 0.095353914 seconds. Throughput is 2684.735 records/second. Loss is 1.6853892. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044964028776978415. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:51 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 562][Wall Clock 68.470206034s] Trained 256 records in 0.092569 seconds. Throughput is 2765.5046 records/second. Loss is 1.6692367. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004495594317568782. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 563][Wall Clock 68.563213119s] Trained 256 records in 0.093007085 seconds. Throughput is 2752.4785 records/second. Loss is 1.7324611. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004494786048184107. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 564][Wall Clock 68.657248786s] Trained 256 records in 0.094035667 seconds. Throughput is 2722.371 records/second. Loss is 1.6752067. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004493978069387021. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 565][Wall Clock 68.75622311s] Trained 256 records in 0.098974324 seconds. Throughput is 2586.5293 records/second. Loss is 1.6758912. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004493170381020848. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 566][Wall Clock 68.849839232s] Trained 256 records in 0.093616122 seconds. Throughput is 2734.5718 records/second. Loss is 1.674597. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004492362982929021. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 567][Wall Clock 68.944583389s] Trained 256 records in 0.094744157 seconds. Throughput is 2702.0137 records/second. Loss is 1.6914166. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044915558749550845. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 568][Wall Clock 69.063205188s] Trained 256 records in 0.118621799 seconds. Throughput is 2158.1194 records/second. Loss is 1.7229662. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004490749056942698. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 569][Wall Clock 69.166414037s] Trained 256 records in 0.103208849 seconds. Throughput is 2480.4075 records/second. Loss is 1.6859565. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004489942528735633. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 570][Wall Clock 69.263644791s] Trained 256 records in 0.097230754 seconds. Throughput is 2632.9119 records/second. Loss is 1.6693447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00448913629017777. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 571][Wall Clock 69.358442953s] Trained 256 records in 0.094798162 seconds. Throughput is 2700.4744 records/second. Loss is 1.6823257. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004488330341113105. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:52 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 572][Wall Clock 69.455156826s] Trained 256 records in 0.096713873 seconds. Throughput is 2646.9834 records/second. Loss is 1.6057279. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004487524681385747. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 573][Wall Clock 69.55107927s] Trained 256 records in 0.095922444 seconds. Throughput is 2668.8228 records/second. Loss is 1.682851. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004486719310839914. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 574][Wall Clock 69.646878913s] Trained 256 records in 0.095799643 seconds. Throughput is 2672.244 records/second. Loss is 1.6242839. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004485914229319935. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 575][Wall Clock 69.740774331s] Trained 256 records in 0.093895418 seconds. Throughput is 2726.4375 records/second. Loss is 1.6771941. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004485109436670255. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 576][Wall Clock 69.843610466s] Trained 256 records in 0.102836135 seconds. Throughput is 2489.3975 records/second. Loss is 1.6744839. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004484304932735426. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 577][Wall Clock 69.938020621s] Trained 256 records in 0.094410155 seconds. Throughput is 2711.5725 records/second. Loss is 1.6989733. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004483500717360115. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 578][Wall Clock 70.032271661s] Trained 256 records in 0.09425104 seconds. Throughput is 2716.1504 records/second. Loss is 1.6258619. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004482696790389098. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 579][Wall Clock 70.126053415s] Trained 256 records in 0.093781754 seconds. Throughput is 2729.7422 records/second. Loss is 1.5914458. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044818931516672645. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 580][Wall Clock 70.219134366s] Trained 256 records in 0.093080951 seconds. Throughput is 2750.2942 records/second. Loss is 1.6762034. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004481089801039614. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 581][Wall Clock 70.312127657s] Trained 256 records in 0.092993291 seconds. Throughput is 2752.8867 records/second. Loss is 1.6775868. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004480286738351254. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:53 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 582][Wall Clock 70.404847902s] Trained 256 records in 0.092720245 seconds. Throughput is 2760.9934 records/second. Loss is 1.6067696. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004479483963447411. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 583][Wall Clock 70.497376638s] Trained 256 records in 0.092528736 seconds. Throughput is 2766.708 records/second. Loss is 1.6602087. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004478681476173414. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 584][Wall Clock 70.598209373s] Trained 256 records in 0.100832735 seconds. Throughput is 2538.858 records/second. Loss is 1.6861169. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004477879276374709. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 585][Wall Clock 70.692422458s] Trained 256 records in 0.094213085 seconds. Throughput is 2717.2446 records/second. Loss is 1.6928636. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004477077363896848. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 586][Wall Clock 70.784955393s] Trained 256 records in 0.092532935 seconds. Throughput is 2766.5825 records/second. Loss is 1.640303. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004476275738585497. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 587][Wall Clock 70.877980519s] Trained 256 records in 0.093025126 seconds. Throughput is 2751.9446 records/second. Loss is 1.6817484. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004475474400286431. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 588][Wall Clock 70.974376653s] Trained 256 records in 0.096396134 seconds. Throughput is 2655.7083 records/second. Loss is 1.6277065. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004474673348845534. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 589][Wall Clock 71.069218449s] Trained 256 records in 0.094841796 seconds. Throughput is 2699.232 records/second. Loss is 1.6603411. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004473872584108805. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 590][Wall Clock 71.162973272s] Trained 256 records in 0.093754823 seconds. Throughput is 2730.5264 records/second. Loss is 1.6263441. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004473072105922348. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 591][Wall Clock 71.256090426s] Trained 256 records in 0.093117154 seconds. Throughput is 2749.2249 records/second. Loss is 1.6326452. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004472271914132379. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 592][Wall Clock 71.354929287s] Trained 256 records in 0.098838861 seconds. Throughput is 2590.0745 records/second. Loss is 1.6740464. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004471472008585226. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:54 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 593][Wall Clock 71.45999054s] Trained 256 records in 0.105061253 seconds. Throughput is 2436.6738 records/second. Loss is 1.6265184. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004470672389127324. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 594][Wall Clock 71.567062292s] Trained 256 records in 0.107071752 seconds. Throughput is 2390.9202 records/second. Loss is 1.6227372. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004469873055605221. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 595][Wall Clock 71.667510553s] Trained 256 records in 0.100448261 seconds. Throughput is 2548.5757 records/second. Loss is 1.6521302. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00446907400786557. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 596][Wall Clock 71.762295917s] Trained 256 records in 0.094785364 seconds. Throughput is 2700.8389 records/second. Loss is 1.6374004. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004468275245755138. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 597][Wall Clock 71.892141671s] Trained 256 records in 0.129845754 seconds. Throughput is 1971.5701 records/second. Loss is 1.6023445. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004467476769120801. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 598][Wall Clock 71.989050654s] Trained 256 records in 0.096908983 seconds. Throughput is 2641.6538 records/second. Loss is 1.5848305. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044666785778095415. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 599][Wall Clock 72.084192435s] Trained 256 records in 0.095141781 seconds. Throughput is 2690.721 records/second. Loss is 1.6525201. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004465880671668454. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 600][Wall Clock 72.185625206s] Trained 256 records in 0.101432771 seconds. Throughput is 2523.839 records/second. Loss is 1.6401201. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00446508305054474. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 601][Wall Clock 72.288168041s] Trained 256 records in 0.102542835 seconds. Throughput is 2496.5178 records/second. Loss is 1.6069028. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004464285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 602][Wall Clock 72.384104208s] Trained 256 records in 0.095936167 seconds. Throughput is 2668.4412 records/second. Loss is 1.6018442. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004463488662738797. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:55 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 603][Wall Clock 72.482307611s] Trained 256 records in 0.098203403 seconds. Throughput is 2606.8342 records/second. Loss is 1.6259136. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004462691895751517. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 604][Wall Clock 72.637074582s] Trained 256 records in 0.154766971 seconds. Throughput is 1654.0996 records/second. Loss is 1.6102676. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004461895413171515. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 605][Wall Clock 72.732577219s] Trained 256 records in 0.095502637 seconds. Throughput is 2680.5542 records/second. Loss is 1.6060035. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004461099214846539. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 606][Wall Clock 72.830222275s] Trained 256 records in 0.097645056 seconds. Throughput is 2621.7405 records/second. Loss is 1.6270977. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044603033006244425. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 607][Wall Clock 72.923952171s] Trained 256 records in 0.093729896 seconds. Throughput is 2731.2522 records/second. Loss is 1.5539999. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004459507670353193. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 608][Wall Clock 73.017949558s] Trained 256 records in 0.093997387 seconds. Throughput is 2723.48 records/second. Loss is 1.5755196. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004458712323880863. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 609][Wall Clock 73.113408131s] Trained 256 records in 0.095458573 seconds. Throughput is 2681.7915 records/second. Loss is 1.5796596. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004457917261055635. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 610][Wall Clock 73.210434047s] Trained 256 records in 0.097025916 seconds. Throughput is 2638.4702 records/second. Loss is 1.5664338. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004457122481725798. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 611][Wall Clock 73.307898043s] Trained 256 records in 0.097463996 seconds. Throughput is 2626.611 records/second. Loss is 1.606579. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00445632798573975. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:56 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 612][Wall Clock 73.402309942s] Trained 256 records in 0.094411899 seconds. Throughput is 2711.5225 records/second. Loss is 1.5958806. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004455533772945999. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 613][Wall Clock 73.496596381s] Trained 256 records in 0.094286439 seconds. Throughput is 2715.1306 records/second. Loss is 1.6075999. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004454739843193158. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 614][Wall Clock 73.590410708s] Trained 256 records in 0.093814327 seconds. Throughput is 2728.7942 records/second. Loss is 1.6095409. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004453946196329948. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 615][Wall Clock 73.685135143s] Trained 256 records in 0.094724435 seconds. Throughput is 2702.5762 records/second. Loss is 1.5211878. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004453152832205202. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 616][Wall Clock 73.780143839s] Trained 256 records in 0.095008696 seconds. Throughput is 2694.4902 records/second. Loss is 1.5875362. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004452359750667854. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 617][Wall Clock 73.87594144s] Trained 256 records in 0.095797601 seconds. Throughput is 2672.3008 records/second. Loss is 1.5952556. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004451566951566952. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 618][Wall Clock 73.976850003s] Trained 256 records in 0.100908563 seconds. Throughput is 2536.9502 records/second. Loss is 1.6021029. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004450774434751647. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 619][Wall Clock 74.074425914s] Trained 256 records in 0.097575911 seconds. Throughput is 2623.5984 records/second. Loss is 1.6007103. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044499822000712. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 620][Wall Clock 74.170805928s] Trained 256 records in 0.096380014 seconds. Throughput is 2656.1523 records/second. Loss is 1.5696602. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004449190247374979. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 621][Wall Clock 74.270154224s] Trained 256 records in 0.099348296 seconds. Throughput is 2576.793 records/second. Loss is 1.5856688. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004448398576512455. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 622][Wall Clock 74.367272962s] Trained 256 records in 0.097118738 seconds. Throughput is 2635.9487 records/second. Loss is 1.524956. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004447607187333214. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:57 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 623][Wall Clock 74.462019682s] Trained 256 records in 0.09474672 seconds. Throughput is 2701.9407 records/second. Loss is 1.6401551. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004446816079686944. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 624][Wall Clock 74.556040737s] Trained 256 records in 0.094021055 seconds. Throughput is 2722.7944 records/second. Loss is 1.6293991. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044460252534234395. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 625][Wall Clock 74.651859315s] Trained 256 records in 0.095818578 seconds. Throughput is 2671.7156 records/second. Loss is 1.52135. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004445234708392603. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 626][Wall Clock 74.751941314s] Trained 256 records in 0.100081999 seconds. Throughput is 2557.9023 records/second. Loss is 1.5519447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044444444444444444. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 627][Wall Clock 74.851260218s] Trained 256 records in 0.099318904 seconds. Throughput is 2577.5557 records/second. Loss is 1.6074113. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00444365446142908. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 628][Wall Clock 74.944486481s] Trained 256 records in 0.093226263 seconds. Throughput is 2746.0073 records/second. Loss is 1.5724926. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00444286475919673. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 629][Wall Clock 75.037320615s] Trained 256 records in 0.092834134 seconds. Throughput is 2757.6062 records/second. Loss is 1.5371646. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004442075337597726. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 630][Wall Clock 75.130560972s] Trained 256 records in 0.093240357 seconds. Throughput is 2745.5923 records/second. Loss is 1.5953083. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004441286196482502. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 631][Wall Clock 75.226021525s] Trained 256 records in 0.095460553 seconds. Throughput is 2681.7358 records/second. Loss is 1.5374659. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004440497335701599. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 632][Wall Clock 75.319446553s] Trained 256 records in 0.093425028 seconds. Throughput is 2740.165 records/second. Loss is 1.5858617. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004439708755105665. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:58 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 633][Wall Clock 75.414456067s] Trained 256 records in 0.095009514 seconds. Throughput is 2694.467 records/second. Loss is 1.5818369. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004438920454545454. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 634][Wall Clock 75.521896079s] Trained 256 records in 0.107440012 seconds. Throughput is 2382.725 records/second. Loss is 1.5445999. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044381324338718265. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 635][Wall Clock 75.615321073s] Trained 256 records in 0.093424994 seconds. Throughput is 2740.1663 records/second. Loss is 1.5553514. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004437344692935747. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 636][Wall Clock 75.766879099s] Trained 256 records in 0.151558026 seconds. Throughput is 1689.1221 records/second. Loss is 1.5406731. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044365572315882874. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 637][Wall Clock 75.907907997s] Trained 256 records in 0.141028898 seconds. Throughput is 1815.2308 records/second. Loss is 1.5600919. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044357700496806245. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 638][Wall Clock 76.05323488s] Trained 256 records in 0.145326883 seconds. Throughput is 1761.546 records/second. Loss is 1.5141321. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044349831470640415. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 639][Wall Clock 76.18636558s] Trained 256 records in 0.1331307 seconds. Throughput is 1922.9224 records/second. Loss is 1.5479124. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004434196523589926. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 640][Wall Clock 76.284240061s] Trained 256 records in 0.097874481 seconds. Throughput is 2615.595 records/second. Loss is 1.5565213. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004433410179109772. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:15:59 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 641][Wall Clock 76.379913303s] Trained 256 records in 0.095673242 seconds. Throughput is 2675.7744 records/second. Loss is 1.6081014. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004432624113475177. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 642][Wall Clock 76.494968866s] Trained 256 records in 0.115055563 seconds. Throughput is 2225.012 records/second. Loss is 1.5495281. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044318383265378476. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 643][Wall Clock 76.601409572s] Trained 256 records in 0.106440706 seconds. Throughput is 2405.095 records/second. Loss is 1.5697988. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004431052818149592. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 644][Wall Clock 76.706327454s] Trained 256 records in 0.104917882 seconds. Throughput is 2440.0034 records/second. Loss is 1.539995. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004430267588162325. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 645][Wall Clock 76.803837514s] Trained 256 records in 0.09751006 seconds. Throughput is 2625.37 records/second. Loss is 1.5567555. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004429482636428065. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 646][Wall Clock 76.898296838s] Trained 256 records in 0.094459324 seconds. Throughput is 2710.1611 records/second. Loss is 1.558629. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044286979627989375. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 647][Wall Clock 76.990833862s] Trained 256 records in 0.092537024 seconds. Throughput is 2766.4602 records/second. Loss is 1.5126343. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00442791356712717. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 648][Wall Clock 77.08394645s] Trained 256 records in 0.093112588 seconds. Throughput is 2749.3596 records/second. Loss is 1.5277199. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004427129449265097. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 649][Wall Clock 77.179112028s] Trained 256 records in 0.095165578 seconds. Throughput is 2690.048 records/second. Loss is 1.5370601. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004426345609065156. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 650][Wall Clock 77.276772735s] Trained 256 records in 0.097660707 seconds. Throughput is 2621.3203 records/second. Loss is 1.5250918. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044255620463798905. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 651][Wall Clock 77.379945995s] Trained 256 records in 0.10317326 seconds. Throughput is 2481.263 records/second. Loss is 1.5369458. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004424778761061948. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:00 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 652][Wall Clock 77.475165873s] Trained 256 records in 0.095219878 seconds. Throughput is 2688.5142 records/second. Loss is 1.4860082. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044239957529640765. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 653][Wall Clock 77.5718966s] Trained 256 records in 0.096730727 seconds. Throughput is 2646.5222 records/second. Loss is 1.5310761. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004423213021939137. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 654][Wall Clock 77.669027414s] Trained 256 records in 0.097130814 seconds. Throughput is 2635.6208 records/second. Loss is 1.5244339. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004422430567840085. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 655][Wall Clock 77.762518228s] Trained 256 records in 0.093490814 seconds. Throughput is 2738.2368 records/second. Loss is 1.4990063. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044216483905199855. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 656][Wall Clock 77.858852531s] Trained 256 records in 0.096334303 seconds. Throughput is 2657.4128 records/second. Loss is 1.5424598. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004420866489832007. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 657][Wall Clock 77.960349337s] Trained 256 records in 0.101496806 seconds. Throughput is 2522.2468 records/second. Loss is 1.5433577. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00442008486562942. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 658][Wall Clock 78.057363228s] Trained 256 records in 0.097013891 seconds. Throughput is 2638.7974 records/second. Loss is 1.5099527. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004419303517765601. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 659][Wall Clock 78.153954703s] Trained 256 records in 0.096591475 seconds. Throughput is 2650.3374 records/second. Loss is 1.5165403. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044185224460940265. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 660][Wall Clock 78.244642075s] Trained 256 records in 0.090687372 seconds. Throughput is 2822.8848 records/second. Loss is 1.483259. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004417741650468281. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 661][Wall Clock 78.339593156s] Trained 256 records in 0.094951081 seconds. Throughput is 2696.1252 records/second. Loss is 1.4688966. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004416961130742049. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:01 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 662][Wall Clock 78.474421169s] Trained 256 records in 0.134828013 seconds. Throughput is 1898.7152 records/second. Loss is 1.5380902. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004416180886769122. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 663][Wall Clock 78.569516097s] Trained 256 records in 0.095094928 seconds. Throughput is 2692.0469 records/second. Loss is 1.4967456. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044154009184033905. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 664][Wall Clock 78.677434149s] Trained 256 records in 0.107918052 seconds. Throughput is 2372.1702 records/second. Loss is 1.4910597. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004414621225498852. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 665][Wall Clock 78.805604955s] Trained 256 records in 0.128170806 seconds. Throughput is 1997.3347 records/second. Loss is 1.5094881. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004413841807909605. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 666][Wall Clock 78.907371243s] Trained 256 records in 0.101766288 seconds. Throughput is 2515.5679 records/second. Loss is 1.5278065. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044130626654898504. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 667][Wall Clock 78.999870948s] Trained 256 records in 0.092499705 seconds. Throughput is 2767.5764 records/second. Loss is 1.5169663. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004412283798093893. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 668][Wall Clock 79.155102634s] Trained 256 records in 0.155231686 seconds. Throughput is 1649.1478 records/second. Loss is 1.5305535. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044115052055761425. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 669][Wall Clock 79.288711258s] Trained 256 records in 0.133608624 seconds. Throughput is 1916.044 records/second. Loss is 1.532187. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004410726887791108. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:02 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 670][Wall Clock 79.387335498s] Trained 256 records in 0.09862424 seconds. Throughput is 2595.711 records/second. Loss is 1.4229455. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004409948844593403. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 671][Wall Clock 79.484096311s] Trained 256 records in 0.096760813 seconds. Throughput is 2645.6992 records/second. Loss is 1.4892144. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004409171075837743. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 672][Wall Clock 79.586274488s] Trained 256 records in 0.102178177 seconds. Throughput is 2505.4272 records/second. Loss is 1.4925365. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004408393581378945. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 673][Wall Clock 79.730259472s] Trained 256 records in 0.143984984 seconds. Throughput is 1777.9631 records/second. Loss is 1.5132936. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004407616361071932. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 674][Wall Clock 79.827502302s] Trained 256 records in 0.09724283 seconds. Throughput is 2632.5847 records/second. Loss is 1.4913236. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004406839414771726. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 675][Wall Clock 79.926477855s] Trained 256 records in 0.098975553 seconds. Throughput is 2586.4973 records/second. Loss is 1.456918. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0044060627423334504. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 676][Wall Clock 80.023666979s] Trained 256 records in 0.097189124 seconds. Throughput is 2634.0396 records/second. Loss is 1.4248959. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004405286343612335. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 677][Wall Clock 80.118297714s] Trained 256 records in 0.094630735 seconds. Throughput is 2705.2522 records/second. Loss is 1.4968088. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004404510218463707. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 678][Wall Clock 80.213630782s] Trained 256 records in 0.095333068 seconds. Throughput is 2685.322 records/second. Loss is 1.4564645. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004403734366742998. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 679][Wall Clock 80.308161522s] Trained 256 records in 0.09453074 seconds. Throughput is 2708.1138 records/second. Loss is 1.4761505. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004402958788305742. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:03 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 680][Wall Clock 80.401901393s] Trained 256 records in 0.093739871 seconds. Throughput is 2730.9617 records/second. Loss is 1.4967117. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004402183483007572. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 681][Wall Clock 80.496608867s] Trained 256 records in 0.094707474 seconds. Throughput is 2703.06 records/second. Loss is 1.4560516. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004401408450704225. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 682][Wall Clock 80.596522009s] Trained 256 records in 0.099913142 seconds. Throughput is 2562.2256 records/second. Loss is 1.5461036. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00440063369125154. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 683][Wall Clock 80.695623298s] Trained 256 records in 0.099101289 seconds. Throughput is 2583.2156 records/second. Loss is 1.5290457. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004399859204505456. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 684][Wall Clock 80.79103048s] Trained 256 records in 0.095407182 seconds. Throughput is 2683.236 records/second. Loss is 1.5355439. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004399084990322013. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 685][Wall Clock 80.887825533s] Trained 256 records in 0.096795053 seconds. Throughput is 2644.7632 records/second. Loss is 1.482114. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004398311048557354. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 686][Wall Clock 80.981833674s] Trained 256 records in 0.094008141 seconds. Throughput is 2723.1685 records/second. Loss is 1.4233274. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043975373790677225. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 687][Wall Clock 81.07403925s] Trained 256 records in 0.092205576 seconds. Throughput is 2776.4048 records/second. Loss is 1.4799472. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004396763981709462. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 688][Wall Clock 81.167018425s] Trained 256 records in 0.092979175 seconds. Throughput is 2753.3047 records/second. Loss is 1.433718. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043959908563390195. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 689][Wall Clock 81.262601547s] Trained 256 records in 0.095583122 seconds. Throughput is 2678.297 records/second. Loss is 1.4901128. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00439521800281294. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 690][Wall Clock 81.358862703s] Trained 256 records in 0.096261156 seconds. Throughput is 2659.432 records/second. Loss is 1.4714952. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004394445420987872. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:04 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 691][Wall Clock 81.461170442s] Trained 256 records in 0.102307739 seconds. Throughput is 2502.2546 records/second. Loss is 1.4295205. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004393673110720563. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 692][Wall Clock 81.617597698s] Trained 256 records in 0.156427256 seconds. Throughput is 1636.5435 records/second. Loss is 1.4315766. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004392901071867861. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 693][Wall Clock 81.766295432s] Trained 256 records in 0.148697734 seconds. Throughput is 1721.6133 records/second. Loss is 1.406635. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004392129304286718. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 694][Wall Clock 81.867880237s] Trained 256 records in 0.101584805 seconds. Throughput is 2520.0618 records/second. Loss is 1.439226. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004391357807834183. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 695][Wall Clock 81.962609313s] Trained 256 records in 0.094729076 seconds. Throughput is 2702.4438 records/second. Loss is 1.4548755. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043905865823674044. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 696][Wall Clock 82.066622941s] Trained 256 records in 0.104013628 seconds. Throughput is 2461.2158 records/second. Loss is 1.4266119. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004389815627743635. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 697][Wall Clock 82.161136357s] Trained 256 records in 0.094513416 seconds. Throughput is 2708.61 records/second. Loss is 1.5093365. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004389044943820225. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 698][Wall Clock 82.259833591s] Trained 256 records in 0.098697234 seconds. Throughput is 2593.791 records/second. Loss is 1.4764398. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004388274530454626. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 699][Wall Clock 82.356204834s] Trained 256 records in 0.096371243 seconds. Throughput is 2656.394 records/second. Loss is 1.4249489. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043875043875043875. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:05 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 700][Wall Clock 82.451879565s] Trained 256 records in 0.095674731 seconds. Throughput is 2675.7327 records/second. Loss is 1.4004343. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004386734514827163. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:06 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 701][Wall Clock 82.548263198s] Trained 256 records in 0.096383633 seconds. Throughput is 2656.0527 records/second. Loss is 1.4695987. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043859649122807015. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:06 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 702][Wall Clock 82.641463287s] Trained 256 records in 0.093200089 seconds. Throughput is 2746.7786 records/second. Loss is 1.4308904. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004385195579722855. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:06 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 703][Wall Clock 82.735202258s] Trained 256 records in 0.093738971 seconds. Throughput is 2730.9878 records/second. Loss is 1.4772263. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043844265170115745. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:06 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 704][Wall Clock 82.828951424s] Trained 256 records in 0.093749166 seconds. Throughput is 2730.691 records/second. Loss is 1.4389243. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00438365772400491. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:06 INFO  DistriOptimizer$:408 - [Epoch 3 60160/60000][Iteration 705][Wall Clock 82.932066747s] Trained 256 records in 0.103115323 seconds. Throughput is 2482.6572 records/second. Loss is 1.491414. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00438288920056101. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:06 INFO  DistriOptimizer$:452 - [Epoch 3 60160/60000][Iteration 705][Wall Clock 82.932066747s] Epoch finished. Wall clock time is 83918.717063 ms
2019-10-26 12:16:06 INFO  DistriOptimizer$:111 - [Epoch 3 60160/60000][Iteration 705][Wall Clock 82.932066747s] Validate model...
2019-10-26 12:16:07 INFO  DistriOptimizer$:178 - [Epoch 3 60160/60000][Iteration 705][Wall Clock 82.932066747s] validate model throughput is 11750.645 records/second
2019-10-26 12:16:07 INFO  DistriOptimizer$:181 - [Epoch 3 60160/60000][Iteration 705][Wall Clock 82.932066747s] Top1Accuracy is Accuracy(correct: 6963, count: 10000, accuracy: 0.6963)
2019-10-26 12:16:07 INFO  DistriOptimizer$:221 - [Wall Clock 83.918717063s] Save model to /tmp/lenet5/20191026_121442
2019-10-26 12:16:07 INFO  DistriOptimizer$:226 - [Wall Clock 83.918717063s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@13b5664a to /tmp/lenet5/20191026_121442
2019-10-26 12:16:07 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 706][Wall Clock 84.07803309s] Trained 256 records in 0.159316027 seconds. Throughput is 1606.869 records/second. Loss is 1.4504421. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043821209465381246. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:07 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 707][Wall Clock 84.170512725s] Trained 256 records in 0.092479635 seconds. Throughput is 2768.1772 records/second. Loss is 1.4439986. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004381352961794602. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:07 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 708][Wall Clock 84.265966228s] Trained 256 records in 0.095453503 seconds. Throughput is 2681.934 records/second. Loss is 1.4192374. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004380585246188891. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:07 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 709][Wall Clock 84.360568225s] Trained 256 records in 0.094601997 seconds. Throughput is 2706.074 records/second. Loss is 1.4135977. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004379817799579537. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:07 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 710][Wall Clock 84.454311871s] Trained 256 records in 0.093743646 seconds. Throughput is 2730.8518 records/second. Loss is 1.4287978. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004379050621825188. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:07 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 711][Wall Clock 84.54789207s] Trained 256 records in 0.093580199 seconds. Throughput is 2735.6213 records/second. Loss is 1.4252218. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043782837127845885. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 712][Wall Clock 84.688943488s] Trained 256 records in 0.141051418 seconds. Throughput is 1814.941 records/second. Loss is 1.4117061. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043775170723165824. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 713][Wall Clock 84.793614104s] Trained 256 records in 0.104670616 seconds. Throughput is 2445.7676 records/second. Loss is 1.4541095. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004376750700280112. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 714][Wall Clock 84.887230119s] Trained 256 records in 0.093616015 seconds. Throughput is 2734.5747 records/second. Loss is 1.4090496. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00437598459653422. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 715][Wall Clock 84.980986028s] Trained 256 records in 0.093755909 seconds. Throughput is 2730.4946 records/second. Loss is 1.4138064. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004375218760938047. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 716][Wall Clock 85.075318096s] Trained 256 records in 0.094332068 seconds. Throughput is 2713.8174 records/second. Loss is 1.4677248. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004374453193350831. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 717][Wall Clock 85.17062981s] Trained 256 records in 0.095311714 seconds. Throughput is 2685.9238 records/second. Loss is 1.415989. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004373687893631911. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 718][Wall Clock 85.26970397s] Trained 256 records in 0.09907416 seconds. Throughput is 2583.9229 records/second. Loss is 1.4085753. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004372922861640721. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 719][Wall Clock 85.374678027s] Trained 256 records in 0.104974057 seconds. Throughput is 2438.6978 records/second. Loss is 1.435193. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004372158097236796. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:08 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 720][Wall Clock 85.471485792s] Trained 256 records in 0.096807765 seconds. Throughput is 2644.416 records/second. Loss is 1.3834527. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00437139360027977. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 721][Wall Clock 85.571610623s] Trained 256 records in 0.100124831 seconds. Throughput is 2556.8083 records/second. Loss is 1.3825834. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00437062937062937. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 722][Wall Clock 85.675588507s] Trained 256 records in 0.103977884 seconds. Throughput is 2462.062 records/second. Loss is 1.4495891. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004369865408145429. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 723][Wall Clock 85.770692334s] Trained 256 records in 0.095103827 seconds. Throughput is 2691.795 records/second. Loss is 1.4311786. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004369101712687871. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 724][Wall Clock 85.862417664s] Trained 256 records in 0.09172533 seconds. Throughput is 2790.9412 records/second. Loss is 1.3469315. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004368338284116722. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 725][Wall Clock 85.958179299s] Trained 256 records in 0.095761635 seconds. Throughput is 2673.3044 records/second. Loss is 1.4413569. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004367575122292103. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 726][Wall Clock 86.05178997s] Trained 256 records in 0.093610671 seconds. Throughput is 2734.731 records/second. Loss is 1.4336028. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004366812227074236. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 727][Wall Clock 86.152520964s] Trained 256 records in 0.100730994 seconds. Throughput is 2541.4224 records/second. Loss is 1.4520456. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004366049598323437. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 728][Wall Clock 86.28601328s] Trained 256 records in 0.133492316 seconds. Throughput is 1917.7133 records/second. Loss is 1.4055352. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004365287235900122. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 729][Wall Clock 86.37918433s] Trained 256 records in 0.09317105 seconds. Throughput is 2747.6345 records/second. Loss is 1.387474. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004364525139664805. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:09 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 730][Wall Clock 86.473256588s] Trained 256 records in 0.094072258 seconds. Throughput is 2721.3123 records/second. Loss is 1.3898233. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004363763309478094. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 731][Wall Clock 86.564925973s] Trained 256 records in 0.091669385 seconds. Throughput is 2792.6443 records/second. Loss is 1.3490019. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004363001745200699. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 732][Wall Clock 86.658579212s] Trained 256 records in 0.093653239 seconds. Throughput is 2733.488 records/second. Loss is 1.3837336. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004362240446693423. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 733][Wall Clock 86.765693169s] Trained 256 records in 0.107113957 seconds. Throughput is 2389.978 records/second. Loss is 1.359526. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004361479413817167. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 734][Wall Clock 86.867085823s] Trained 256 records in 0.101392654 seconds. Throughput is 2524.8376 records/second. Loss is 1.4123225. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004360718646432932. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 735][Wall Clock 86.961975249s] Trained 256 records in 0.094889426 seconds. Throughput is 2697.877 records/second. Loss is 1.3717804. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004359958144401814. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 736][Wall Clock 87.057376854s] Trained 256 records in 0.095401605 seconds. Throughput is 2683.3928 records/second. Loss is 1.4224727. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004359197907585004. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 737][Wall Clock 87.152092978s] Trained 256 records in 0.094716124 seconds. Throughput is 2702.8132 records/second. Loss is 1.3891625. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004358437935843794. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 738][Wall Clock 87.246009709s] Trained 256 records in 0.093916731 seconds. Throughput is 2725.8188 records/second. Loss is 1.3695604. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004357678229039568. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 739][Wall Clock 87.33897632s] Trained 256 records in 0.092966611 seconds. Throughput is 2753.6768 records/second. Loss is 1.3708693. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00435691878703381. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 740][Wall Clock 87.437368206s] Trained 256 records in 0.098391886 seconds. Throughput is 2601.8406 records/second. Loss is 1.3804617. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043561596096880996. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:10 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 741][Wall Clock 87.53095657s] Trained 256 records in 0.093588364 seconds. Throughput is 2735.3828 records/second. Loss is 1.377817. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004355400696864111. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 742][Wall Clock 87.624715828s] Trained 256 records in 0.093759258 seconds. Throughput is 2730.397 records/second. Loss is 1.4055694. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004354642048423619. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 743][Wall Clock 87.72122909s] Trained 256 records in 0.096513262 seconds. Throughput is 2652.485 records/second. Loss is 1.3641944. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004353883664228492. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 744][Wall Clock 87.823131554s] Trained 256 records in 0.101902464 seconds. Throughput is 2512.2063 records/second. Loss is 1.3584559. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004353125544140693. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 745][Wall Clock 87.919426653s] Trained 256 records in 0.096295099 seconds. Throughput is 2658.4946 records/second. Loss is 1.3272362. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004352367688022284. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 746][Wall Clock 88.013382737s] Trained 256 records in 0.093956084 seconds. Throughput is 2724.6772 records/second. Loss is 1.3822609. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004351610095735422. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 747][Wall Clock 88.10683401s] Trained 256 records in 0.093451273 seconds. Throughput is 2739.3955 records/second. Loss is 1.3612893. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00435085276714236. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 748][Wall Clock 88.19830909s] Trained 256 records in 0.09147508 seconds. Throughput is 2798.5764 records/second. Loss is 1.4125549. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004350095702105447. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 749][Wall Clock 88.292889581s] Trained 256 records in 0.094580491 seconds. Throughput is 2706.6892 records/second. Loss is 1.4175835. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004349338900487126. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 750][Wall Clock 88.387462904s] Trained 256 records in 0.094573323 seconds. Throughput is 2706.8943 records/second. Loss is 1.3296595. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043485823621499395. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:11 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 751][Wall Clock 88.481066932s] Trained 256 records in 0.093604028 seconds. Throughput is 2734.925 records/second. Loss is 1.3785369. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004347826086956522. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 752][Wall Clock 88.575679844s] Trained 256 records in 0.094612912 seconds. Throughput is 2705.7617 records/second. Loss is 1.3881948. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004347070074769606. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 753][Wall Clock 88.678493471s] Trained 256 records in 0.102813627 seconds. Throughput is 2489.9424 records/second. Loss is 1.3775415. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043463143254520165. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 754][Wall Clock 88.770421616s] Trained 256 records in 0.091928145 seconds. Throughput is 2784.7837 records/second. Loss is 1.3815175. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004345558838866678. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 755][Wall Clock 88.865563642s] Trained 256 records in 0.095142026 seconds. Throughput is 2690.714 records/second. Loss is 1.3825322. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043448036148766075. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 756][Wall Clock 88.960192728s] Trained 256 records in 0.094629086 seconds. Throughput is 2705.2993 records/second. Loss is 1.359262. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004344048653344918. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 757][Wall Clock 89.055401625s] Trained 256 records in 0.095208897 seconds. Throughput is 2688.8242 records/second. Loss is 1.3544842. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004343293954134816. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 758][Wall Clock 89.149054517s] Trained 256 records in 0.093652892 seconds. Throughput is 2733.498 records/second. Loss is 1.4374082. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004342539517109606. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 759][Wall Clock 89.241587482s] Trained 256 records in 0.092532965 seconds. Throughput is 2766.5818 records/second. Loss is 1.3238351. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004341785342132685. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 760][Wall Clock 89.335459227s] Trained 256 records in 0.093871745 seconds. Throughput is 2727.1252 records/second. Loss is 1.3924896. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004341031429067547. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 761][Wall Clock 89.430425901s] Trained 256 records in 0.094966674 seconds. Throughput is 2695.6826 records/second. Loss is 1.3175273. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004340277777777778. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:12 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 762][Wall Clock 89.525077084s] Trained 256 records in 0.094651183 seconds. Throughput is 2704.6677 records/second. Loss is 1.3442634. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004339524388127061. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 763][Wall Clock 89.621951674s] Trained 256 records in 0.09687459 seconds. Throughput is 2642.5918 records/second. Loss is 1.348698. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043387712599791736. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 764][Wall Clock 89.714781367s] Trained 256 records in 0.092829693 seconds. Throughput is 2757.7385 records/second. Loss is 1.4002211. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004338018393197987. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 765][Wall Clock 89.810951353s] Trained 256 records in 0.096169986 seconds. Throughput is 2661.9531 records/second. Loss is 1.3327745. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004337265787647467. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 766][Wall Clock 89.910147977s] Trained 256 records in 0.099196624 seconds. Throughput is 2580.7332 records/second. Loss is 1.3434829. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004336513443191674. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 767][Wall Clock 90.014544363s] Trained 256 records in 0.104396386 seconds. Throughput is 2452.1921 records/second. Loss is 1.3265456. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004335761359694762. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 768][Wall Clock 90.122236114s] Trained 256 records in 0.107691751 seconds. Throughput is 2377.1553 records/second. Loss is 1.2515684. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004335009537020981. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 769][Wall Clock 90.216919347s] Trained 256 records in 0.094683233 seconds. Throughput is 2703.7522 records/second. Loss is 1.3214766. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004334257975034675. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 770][Wall Clock 90.313393838s] Trained 256 records in 0.096474491 seconds. Throughput is 2653.5513 records/second. Loss is 1.343647. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004333506673600278. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 771][Wall Clock 90.41872286s] Trained 256 records in 0.105329022 seconds. Throughput is 2430.4792 records/second. Loss is 1.3253536. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004332755632582323. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:13 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 772][Wall Clock 90.512451581s] Trained 256 records in 0.093728721 seconds. Throughput is 2731.2866 records/second. Loss is 1.3111404. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004332004851845435. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 773][Wall Clock 90.606162177s] Trained 256 records in 0.093710596 seconds. Throughput is 2731.815 records/second. Loss is 1.3433065. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004331254331254331. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 774][Wall Clock 90.699574074s] Trained 256 records in 0.093411897 seconds. Throughput is 2740.5503 records/second. Loss is 1.3460132. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004330504070673826. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 775][Wall Clock 90.792124917s] Trained 256 records in 0.092550843 seconds. Throughput is 2766.047 records/second. Loss is 1.3610953. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004329754069968826. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 776][Wall Clock 90.885649028s] Trained 256 records in 0.093524111 seconds. Throughput is 2737.262 records/second. Loss is 1.3269696. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004329004329004329. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 777][Wall Clock 90.978291287s] Trained 256 records in 0.092642259 seconds. Throughput is 2763.3176 records/second. Loss is 1.3014371. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00432825484764543. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 778][Wall Clock 91.074794238s] Trained 256 records in 0.096502951 seconds. Throughput is 2652.7686 records/second. Loss is 1.3343394. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004327505625757314. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 779][Wall Clock 91.168208226s] Trained 256 records in 0.093413988 seconds. Throughput is 2740.489 records/second. Loss is 1.3173947. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004326756663205262. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 780][Wall Clock 91.259196332s] Trained 256 records in 0.090988106 seconds. Throughput is 2813.5544 records/second. Loss is 1.3328396. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004326007959854646. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 781][Wall Clock 91.353661149s] Trained 256 records in 0.094464817 seconds. Throughput is 2710.0037 records/second. Loss is 1.2879499. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004325259515570935. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:14 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 782][Wall Clock 91.454592794s] Trained 256 records in 0.100931645 seconds. Throughput is 2536.37 records/second. Loss is 1.30539. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043245113302196846. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 783][Wall Clock 91.546712607s] Trained 256 records in 0.092119813 seconds. Throughput is 2778.9895 records/second. Loss is 1.2788743. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004323763403666551. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 784][Wall Clock 91.641526877s] Trained 256 records in 0.09481427 seconds. Throughput is 2700.0154 records/second. Loss is 1.3341761. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004323015735777278. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 785][Wall Clock 91.741018523s] Trained 256 records in 0.099491646 seconds. Throughput is 2573.0803 records/second. Loss is 1.3061347. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004322268326417704. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 786][Wall Clock 91.84668094s] Trained 256 records in 0.105662417 seconds. Throughput is 2422.8103 records/second. Loss is 1.2913814. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00432152117545376. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 787][Wall Clock 91.975985692s] Trained 256 records in 0.129304752 seconds. Throughput is 1979.819 records/second. Loss is 1.3260567. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004320774282751469. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 788][Wall Clock 92.070748965s] Trained 256 records in 0.094763273 seconds. Throughput is 2701.4685 records/second. Loss is 1.2777485. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043200276481769485. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 789][Wall Clock 92.163738002s] Trained 256 records in 0.092989037 seconds. Throughput is 2753.0127 records/second. Loss is 1.3119837. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004319281271596406. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 790][Wall Clock 92.256586405s] Trained 256 records in 0.092848403 seconds. Throughput is 2757.1826 records/second. Loss is 1.3121948. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004318535152876145. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 791][Wall Clock 92.35229853s] Trained 256 records in 0.095712125 seconds. Throughput is 2674.6873 records/second. Loss is 1.2936344. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004317789291882556. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:15 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 792][Wall Clock 92.448327487s] Trained 256 records in 0.096028957 seconds. Throughput is 2665.8625 records/second. Loss is 1.3206058. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004317043688482128. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 793][Wall Clock 92.545532999s] Trained 256 records in 0.097205512 seconds. Throughput is 2633.5955 records/second. Loss is 1.3491. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004316298342541436. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 794][Wall Clock 92.65036701s] Trained 256 records in 0.104834011 seconds. Throughput is 2441.9556 records/second. Loss is 1.2950022. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004315553253927153. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 795][Wall Clock 92.746415006s] Trained 256 records in 0.096047996 seconds. Throughput is 2665.334 records/second. Loss is 1.2828854. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00431480842250604. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 796][Wall Clock 92.844954269s] Trained 256 records in 0.098539263 seconds. Throughput is 2597.9492 records/second. Loss is 1.2271297. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004314063848144953. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 797][Wall Clock 92.940535807s] Trained 256 records in 0.095581538 seconds. Throughput is 2678.3416 records/second. Loss is 1.2724922. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004313319530710835. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 798][Wall Clock 93.033599517s] Trained 256 records in 0.09306371 seconds. Throughput is 2750.8037 records/second. Loss is 1.2870017. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004312575470070726. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 799][Wall Clock 93.127535101s] Trained 256 records in 0.093935584 seconds. Throughput is 2725.2717 records/second. Loss is 1.2821231. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004311831666091756. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 800][Wall Clock 93.221706683s] Trained 256 records in 0.094171582 seconds. Throughput is 2718.4421 records/second. Loss is 1.329377. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004311088118641145. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 801][Wall Clock 93.317737015s] Trained 256 records in 0.096030332 seconds. Throughput is 2665.8245 records/second. Loss is 1.30698. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004310344827586208. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 802][Wall Clock 93.41369412s] Trained 256 records in 0.095957105 seconds. Throughput is 2667.8586 records/second. Loss is 1.2896574. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043096017927943455. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:16 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 803][Wall Clock 93.50638327s] Trained 256 records in 0.09268915 seconds. Throughput is 2761.92 records/second. Loss is 1.2434953. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0043088590141330575. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 804][Wall Clock 93.600180179s] Trained 256 records in 0.093796909 seconds. Throughput is 2729.301 records/second. Loss is 1.3135624. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004308116491469929. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 805][Wall Clock 93.700051789s] Trained 256 records in 0.09987161 seconds. Throughput is 2563.291 records/second. Loss is 1.2694664. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004307374224672639. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 806][Wall Clock 93.800974069s] Trained 256 records in 0.10092228 seconds. Throughput is 2536.6055 records/second. Loss is 1.322011. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004306632213608958. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 807][Wall Clock 93.895848478s] Trained 256 records in 0.094874409 seconds. Throughput is 2698.304 records/second. Loss is 1.2756486. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004305890458146745. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 808][Wall Clock 93.995126913s] Trained 256 records in 0.099278435 seconds. Throughput is 2578.6062 records/second. Loss is 1.2356402. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004305148958153952. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 809][Wall Clock 94.098507216s] Trained 256 records in 0.103380303 seconds. Throughput is 2476.294 records/second. Loss is 1.2793503. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004304407713498623. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 810][Wall Clock 94.194491147s] Trained 256 records in 0.095983931 seconds. Throughput is 2667.113 records/second. Loss is 1.266952. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00430366672404889. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 811][Wall Clock 94.287089757s] Trained 256 records in 0.09259861 seconds. Throughput is 2764.6204 records/second. Loss is 1.2906795. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004302925989672978. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 812][Wall Clock 94.380238737s] Trained 256 records in 0.09314898 seconds. Throughput is 2748.2856 records/second. Loss is 1.30238. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004302185510239202. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:17 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 813][Wall Clock 94.474333577s] Trained 256 records in 0.09409484 seconds. Throughput is 2720.6592 records/second. Loss is 1.2734846. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004301445285615967. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 814][Wall Clock 94.569049439s] Trained 256 records in 0.094715862 seconds. Throughput is 2702.8208 records/second. Loss is 1.2871729. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00430070531567177. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 815][Wall Clock 94.662063783s] Trained 256 records in 0.093014344 seconds. Throughput is 2752.2637 records/second. Loss is 1.2436304. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004299965600275198. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 816][Wall Clock 94.757748547s] Trained 256 records in 0.095684764 seconds. Throughput is 2675.452 records/second. Loss is 1.2435352. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004299226139294927. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 817][Wall Clock 94.850007429s] Trained 256 records in 0.092258882 seconds. Throughput is 2774.8005 records/second. Loss is 1.2450397. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004298486932599725. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 818][Wall Clock 94.954621293s] Trained 256 records in 0.104613864 seconds. Throughput is 2447.0945 records/second. Loss is 1.2966527. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042977479800584495. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 819][Wall Clock 95.057904438s] Trained 256 records in 0.103283145 seconds. Throughput is 2478.6233 records/second. Loss is 1.2961725. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004297009281540048. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 820][Wall Clock 95.15576098s] Trained 256 records in 0.097856542 seconds. Throughput is 2616.0745 records/second. Loss is 1.3093997. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004296270836913559. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 821][Wall Clock 95.253958534s] Trained 256 records in 0.098197554 seconds. Throughput is 2606.9895 records/second. Loss is 1.2530633. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00429553264604811. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 822][Wall Clock 95.344812102s] Trained 256 records in 0.090853568 seconds. Throughput is 2817.721 records/second. Loss is 1.2875592. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004294794708812918. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:18 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 823][Wall Clock 95.449697371s] Trained 256 records in 0.104885269 seconds. Throughput is 2440.7622 records/second. Loss is 1.1704336. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004294057025077293. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 824][Wall Clock 95.548990786s] Trained 256 records in 0.099293415 seconds. Throughput is 2578.2173 records/second. Loss is 1.2790502. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00429331959471063. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 825][Wall Clock 95.644108577s] Trained 256 records in 0.095117791 seconds. Throughput is 2691.3997 records/second. Loss is 1.2611339. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004292582417582417. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 826][Wall Clock 95.739827304s] Trained 256 records in 0.095718727 seconds. Throughput is 2674.5027 records/second. Loss is 1.2414187. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004291845493562232. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 827][Wall Clock 95.83594295s] Trained 256 records in 0.096115646 seconds. Throughput is 2663.458 records/second. Loss is 1.2360919. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004291108822519739. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 828][Wall Clock 95.929070765s] Trained 256 records in 0.093127815 seconds. Throughput is 2748.9102 records/second. Loss is 1.1621575. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004290372404324696. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 829][Wall Clock 96.023614786s] Trained 256 records in 0.094544021 seconds. Throughput is 2707.7334 records/second. Loss is 1.2332394. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004289636238846946. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 830][Wall Clock 96.116075054s] Trained 256 records in 0.092460268 seconds. Throughput is 2768.7568 records/second. Loss is 1.1813787. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004288900325956425. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 831][Wall Clock 96.210565456s] Trained 256 records in 0.094490402 seconds. Throughput is 2709.2698 records/second. Loss is 1.1902369. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004288164665523156. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 832][Wall Clock 96.304916336s] Trained 256 records in 0.09435088 seconds. Throughput is 2713.2761 records/second. Loss is 1.2105054. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004287429257417253. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 833][Wall Clock 96.399156354s] Trained 256 records in 0.094240018 seconds. Throughput is 2716.468 records/second. Loss is 1.2746305. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004286694101508916. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:19 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 834][Wall Clock 96.494328993s] Trained 256 records in 0.095172639 seconds. Throughput is 2689.8489 records/second. Loss is 1.2069025. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004285959197668438. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 835][Wall Clock 96.586785464s] Trained 256 records in 0.092456471 seconds. Throughput is 2768.8706 records/second. Loss is 1.22748. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004285224545766198. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 836][Wall Clock 96.690538898s] Trained 256 records in 0.103753434 seconds. Throughput is 2467.3882 records/second. Loss is 1.2736759. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004284490145672665. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 837][Wall Clock 96.797416556s] Trained 256 records in 0.106877658 seconds. Throughput is 2395.2622 records/second. Loss is 1.184108. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004283755997258396. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 838][Wall Clock 96.889086013s] Trained 256 records in 0.091669457 seconds. Throughput is 2792.6423 records/second. Loss is 1.307308. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004283022100394038. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 839][Wall Clock 96.980056907s] Trained 256 records in 0.090970894 seconds. Throughput is 2814.087 records/second. Loss is 1.2287018. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004282288454950325. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 840][Wall Clock 97.074038189s] Trained 256 records in 0.093981282 seconds. Throughput is 2723.9468 records/second. Loss is 1.1952686. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004281555060798082. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 841][Wall Clock 97.166284074s] Trained 256 records in 0.092245885 seconds. Throughput is 2775.1917 records/second. Loss is 1.2270746. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00428082191780822. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 842][Wall Clock 97.259399725s] Trained 256 records in 0.093115651 seconds. Throughput is 2749.2693 records/second. Loss is 1.2364472. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004280089025851737. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 843][Wall Clock 97.376666831s] Trained 256 records in 0.117267106 seconds. Throughput is 2183.0503 records/second. Loss is 1.218084. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004279356384799726. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:20 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 844][Wall Clock 97.474676005s] Trained 256 records in 0.098009174 seconds. Throughput is 2612.0002 records/second. Loss is 1.189296. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004278623994523361. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 845][Wall Clock 97.566907608s] Trained 256 records in 0.092231603 seconds. Throughput is 2775.6213 records/second. Loss is 1.2110344. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004277891854893908. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 846][Wall Clock 97.667224468s] Trained 256 records in 0.10031686 seconds. Throughput is 2551.914 records/second. Loss is 1.2156725. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00427715996578272. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 847][Wall Clock 97.804787119s] Trained 256 records in 0.137562651 seconds. Throughput is 1860.9703 records/second. Loss is 1.1711305. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004276428327061239. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 848][Wall Clock 97.900038166s] Trained 256 records in 0.095251047 seconds. Throughput is 2687.6345 records/second. Loss is 1.2647121. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004275696938600992. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 849][Wall Clock 97.993840307s] Trained 256 records in 0.093802141 seconds. Throughput is 2729.149 records/second. Loss is 1.2908856. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004274965800273598. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 850][Wall Clock 98.084970074s] Trained 256 records in 0.091129767 seconds. Throughput is 2809.181 records/second. Loss is 1.2934936. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042742349119507615. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 851][Wall Clock 98.177733151s] Trained 256 records in 0.092763077 seconds. Throughput is 2759.7188 records/second. Loss is 1.2534639. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004273504273504274. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 852][Wall Clock 98.271836188s] Trained 256 records in 0.094103037 seconds. Throughput is 2720.4224 records/second. Loss is 1.2159668. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004272773884806016. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 853][Wall Clock 98.377513851s] Trained 256 records in 0.105677663 seconds. Throughput is 2422.4607 records/second. Loss is 1.2280444. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042720437457279565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:21 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 854][Wall Clock 98.470877727s] Trained 256 records in 0.093363876 seconds. Throughput is 2741.96 records/second. Loss is 1.1797414. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004271313856142149. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 855][Wall Clock 98.568702427s] Trained 256 records in 0.0978247 seconds. Throughput is 2616.926 records/second. Loss is 1.2445033. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004270584215920738. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 856][Wall Clock 98.661814408s] Trained 256 records in 0.093111981 seconds. Throughput is 2749.3774 records/second. Loss is 1.1784041. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004269854824935952. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 857][Wall Clock 98.755692539s] Trained 256 records in 0.093878131 seconds. Throughput is 2726.9397 records/second. Loss is 1.2139843. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00426912568306011. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 858][Wall Clock 98.849964907s] Trained 256 records in 0.094272368 seconds. Throughput is 2715.536 records/second. Loss is 1.1933724. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004268396790165614. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 859][Wall Clock 98.944687604s] Trained 256 records in 0.094722697 seconds. Throughput is 2702.6257 records/second. Loss is 1.2392447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004267668146124957. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 860][Wall Clock 99.040288977s] Trained 256 records in 0.095601373 seconds. Throughput is 2677.786 records/second. Loss is 1.2047191. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004266939750810719. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 861][Wall Clock 99.134857484s] Trained 256 records in 0.094568507 seconds. Throughput is 2707.0322 records/second. Loss is 1.2518857. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004266211604095563. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 862][Wall Clock 99.229314427s] Trained 256 records in 0.094456943 seconds. Throughput is 2710.2297 records/second. Loss is 1.1734201. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042654837058522434. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 863][Wall Clock 99.32235779s] Trained 256 records in 0.093043363 seconds. Throughput is 2751.4053 records/second. Loss is 1.1425943. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004264756055953599. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 864][Wall Clock 99.41960668s] Trained 256 records in 0.09724889 seconds. Throughput is 2632.421 records/second. Loss is 1.2610741. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004264028654272557. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:22 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 865][Wall Clock 99.520915452s] Trained 256 records in 0.101308772 seconds. Throughput is 2526.9282 records/second. Loss is 1.1655517. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004263301500682128. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 866][Wall Clock 99.625959291s] Trained 256 records in 0.105043839 seconds. Throughput is 2437.078 records/second. Loss is 1.2251699. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004262574595055414. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 867][Wall Clock 99.721124849s] Trained 256 records in 0.095165558 seconds. Throughput is 2690.0488 records/second. Loss is 1.1883833. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042618479372655985. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 868][Wall Clock 99.818877188s] Trained 256 records in 0.097752339 seconds. Throughput is 2618.863 records/second. Loss is 1.1519186. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004261121527185955. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 869][Wall Clock 99.914867565s] Trained 256 records in 0.095990377 seconds. Throughput is 2666.934 records/second. Loss is 1.1153264. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004260395364689844. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 870][Wall Clock 100.009912193s] Trained 256 records in 0.095044628 seconds. Throughput is 2693.4714 records/second. Loss is 1.2262545. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004259669449650707. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 871][Wall Clock 100.109484236s] Trained 256 records in 0.099572043 seconds. Throughput is 2571.003 records/second. Loss is 1.153039. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004258943781942079. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 872][Wall Clock 100.20410984s] Trained 256 records in 0.094625604 seconds. Throughput is 2705.3987 records/second. Loss is 1.2641073. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042582183614375746. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 873][Wall Clock 100.298840127s] Trained 256 records in 0.094730287 seconds. Throughput is 2702.4092 records/second. Loss is 1.15157. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042574931880109. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 874][Wall Clock 100.403124195s] Trained 256 records in 0.104284068 seconds. Throughput is 2454.8333 records/second. Loss is 1.2661276. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004256768261535842. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:23 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 875][Wall Clock 100.495222597s] Trained 256 records in 0.092098402 seconds. Throughput is 2779.6357 records/second. Loss is 1.2033644. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004256043581886278. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 876][Wall Clock 100.593718686s] Trained 256 records in 0.098496089 seconds. Throughput is 2599.0881 records/second. Loss is 1.220736. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00425531914893617. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 877][Wall Clock 100.688049462s] Trained 256 records in 0.094330776 seconds. Throughput is 2713.8545 records/second. Loss is 1.1994721. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004254594962559565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 878][Wall Clock 100.782389292s] Trained 256 records in 0.09433983 seconds. Throughput is 2713.594 records/second. Loss is 1.2150908. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004253871022630594. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 879][Wall Clock 100.876523167s] Trained 256 records in 0.094133875 seconds. Throughput is 2719.531 records/second. Loss is 1.1709114. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004253147329023477. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 880][Wall Clock 101.009264829s] Trained 256 records in 0.132741662 seconds. Throughput is 1928.5581 records/second. Loss is 1.2351645. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004252423881612519. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 881][Wall Clock 101.141681064s] Trained 256 records in 0.132416235 seconds. Throughput is 1933.2977 records/second. Loss is 1.1917175. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004251700680272109. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 882][Wall Clock 101.235573626s] Trained 256 records in 0.093892562 seconds. Throughput is 2726.5205 records/second. Loss is 1.1938617. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004250977724876722. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 883][Wall Clock 101.335867408s] Trained 256 records in 0.100293782 seconds. Throughput is 2552.5012 records/second. Loss is 1.1953586. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004250255015300917. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:24 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 884][Wall Clock 101.492829484s] Trained 256 records in 0.156962076 seconds. Throughput is 1630.9672 records/second. Loss is 1.1937456. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004249532551419344. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 885][Wall Clock 101.590692723s] Trained 256 records in 0.097863239 seconds. Throughput is 2615.8953 records/second. Loss is 1.2027053. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00424881033310673. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 886][Wall Clock 101.693576955s] Trained 256 records in 0.102884232 seconds. Throughput is 2488.2336 records/second. Loss is 1.2064896. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004248088360237893. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 887][Wall Clock 101.81164528s] Trained 256 records in 0.118068325 seconds. Throughput is 2168.236 records/second. Loss is 1.0966972. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004247366632687734. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 888][Wall Clock 101.916077089s] Trained 256 records in 0.104431809 seconds. Throughput is 2451.3604 records/second. Loss is 1.2018827. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004246645150331238. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 889][Wall Clock 102.014141322s] Trained 256 records in 0.098064233 seconds. Throughput is 2610.5337 records/second. Loss is 1.1608882. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004245923913043478. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 890][Wall Clock 102.112902421s] Trained 256 records in 0.098761099 seconds. Throughput is 2592.1138 records/second. Loss is 1.2147764. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042452029206996094. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 891][Wall Clock 102.21126443s] Trained 256 records in 0.098362009 seconds. Throughput is 2602.6309 records/second. Loss is 1.1538882. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004244482173174873. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 892][Wall Clock 102.3193183s] Trained 256 records in 0.10805387 seconds. Throughput is 2369.1887 records/second. Loss is 1.1650472. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004243761670344594. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:25 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 893][Wall Clock 102.447772704s] Trained 256 records in 0.128454404 seconds. Throughput is 1992.925 records/second. Loss is 1.1813065. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004243041412084182. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 894][Wall Clock 102.571285498s] Trained 256 records in 0.123512794 seconds. Throughput is 2072.6597 records/second. Loss is 1.1345884. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004242321398269132. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 895][Wall Clock 102.665883285s] Trained 256 records in 0.094597787 seconds. Throughput is 2706.1943 records/second. Loss is 1.1629224. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004241601628775025. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 896][Wall Clock 102.761040655s] Trained 256 records in 0.09515737 seconds. Throughput is 2690.2803 records/second. Loss is 1.1819905. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004240882103477523. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 897][Wall Clock 102.856328933s] Trained 256 records in 0.095288278 seconds. Throughput is 2686.5845 records/second. Loss is 1.1642734. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004240162822252374. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 898][Wall Clock 102.950740642s] Trained 256 records in 0.094411709 seconds. Throughput is 2711.528 records/second. Loss is 1.2112838. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004239443784975411. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 899][Wall Clock 103.043417646s] Trained 256 records in 0.092677004 seconds. Throughput is 2762.2817 records/second. Loss is 1.199702. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00423872499152255. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 900][Wall Clock 103.137869558s] Trained 256 records in 0.094451912 seconds. Throughput is 2710.374 records/second. Loss is 1.2118713. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004238006441769792. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 901][Wall Clock 103.234500839s] Trained 256 records in 0.096631281 seconds. Throughput is 2649.2456 records/second. Loss is 1.2218482. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00423728813559322. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 902][Wall Clock 103.331206631s] Trained 256 records in 0.096705792 seconds. Throughput is 2647.2043 records/second. Loss is 1.1343094. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004236570072869005. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:26 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 903][Wall Clock 103.430399066s] Trained 256 records in 0.099192435 seconds. Throughput is 2580.842 records/second. Loss is 1.1377038. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042358522534733985. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 904][Wall Clock 103.58106835s] Trained 256 records in 0.150669284 seconds. Throughput is 1699.0856 records/second. Loss is 1.1536483. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042351346772827375. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 905][Wall Clock 103.725219679s] Trained 256 records in 0.144151329 seconds. Throughput is 1775.9115 records/second. Loss is 1.1312445. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004234417344173441. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 906][Wall Clock 103.830576051s] Trained 256 records in 0.105356372 seconds. Throughput is 2429.8481 records/second. Loss is 1.1326668. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004233700254022015. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 907][Wall Clock 103.934535732s] Trained 256 records in 0.103959681 seconds. Throughput is 2462.4932 records/second. Loss is 1.1216025. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004232983406705046. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 908][Wall Clock 104.036989563s] Trained 256 records in 0.102453831 seconds. Throughput is 2498.6865 records/second. Loss is 1.1071731. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004232266802099204. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 909][Wall Clock 104.14083767s] Trained 256 records in 0.103848107 seconds. Throughput is 2465.139 records/second. Loss is 1.1952049. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004231550440081246. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 910][Wall Clock 104.23561625s] Trained 256 records in 0.09477858 seconds. Throughput is 2701.0322 records/second. Loss is 1.162858. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004230834320528008. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 911][Wall Clock 104.336450101s] Trained 256 records in 0.100833851 seconds. Throughput is 2538.83 records/second. Loss is 1.087501. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004230118443316413. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:27 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 912][Wall Clock 104.429118129s] Trained 256 records in 0.092668028 seconds. Throughput is 2762.5493 records/second. Loss is 1.1419467. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004229402808323465. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 913][Wall Clock 104.523739897s] Trained 256 records in 0.094621768 seconds. Throughput is 2705.5085 records/second. Loss is 1.1288832. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042286874154262525. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 914][Wall Clock 104.620262942s] Trained 256 records in 0.096523045 seconds. Throughput is 2652.2163 records/second. Loss is 1.1192819. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004227972264501945. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 915][Wall Clock 104.714273465s] Trained 256 records in 0.094010523 seconds. Throughput is 2723.0994 records/second. Loss is 1.1169783. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004227257355427798. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 916][Wall Clock 104.810241007s] Trained 256 records in 0.095967542 seconds. Throughput is 2667.5686 records/second. Loss is 1.1674231. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004226542688081149. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 917][Wall Clock 104.905827339s] Trained 256 records in 0.095586332 seconds. Throughput is 2678.2073 records/second. Loss is 1.0763215. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042258282623394185. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 918][Wall Clock 105.008262146s] Trained 256 records in 0.102434807 seconds. Throughput is 2499.1506 records/second. Loss is 1.1379647. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004225114078080109. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 919][Wall Clock 105.133800682s] Trained 256 records in 0.125538536 seconds. Throughput is 2039.2144 records/second. Loss is 1.1351517. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004224400135180805. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 920][Wall Clock 105.234970096s] Trained 256 records in 0.101169414 seconds. Throughput is 2530.409 records/second. Loss is 1.1237812. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004223686433519175. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 921][Wall Clock 105.32662156s] Trained 256 records in 0.091651464 seconds. Throughput is 2793.1907 records/second. Loss is 1.1259071. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004222972972972973. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:28 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 922][Wall Clock 105.423935743s] Trained 256 records in 0.097314183 seconds. Throughput is 2630.6545 records/second. Loss is 1.1206763. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004222259753420031. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 923][Wall Clock 105.516108897s] Trained 256 records in 0.092173154 seconds. Throughput is 2777.3813 records/second. Loss is 1.1448661. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004221546774738264. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 924][Wall Clock 105.615982141s] Trained 256 records in 0.099873244 seconds. Throughput is 2563.249 records/second. Loss is 1.0967953. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004220834036805673. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 925][Wall Clock 105.71051453s] Trained 256 records in 0.094532389 seconds. Throughput is 2708.0667 records/second. Loss is 1.1444734. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004220121539500337. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 926][Wall Clock 105.805531168s] Trained 256 records in 0.095016638 seconds. Throughput is 2694.2651 records/second. Loss is 1.1111774. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004219409282700422. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 927][Wall Clock 105.901528819s] Trained 256 records in 0.095997651 seconds. Throughput is 2666.732 records/second. Loss is 1.1764599. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004218697266284171. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 928][Wall Clock 105.995943429s] Trained 256 records in 0.09441461 seconds. Throughput is 2711.4448 records/second. Loss is 1.1366799. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004217985490129914. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 929][Wall Clock 106.087190946s] Trained 256 records in 0.091247517 seconds. Throughput is 2805.556 records/second. Loss is 1.1316856. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004217273954116059. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 930][Wall Clock 106.17994332s] Trained 256 records in 0.092752374 seconds. Throughput is 2760.037 records/second. Loss is 1.121309. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042165626581211. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 931][Wall Clock 106.288645972s] Trained 256 records in 0.108702652 seconds. Throughput is 2355.0483 records/second. Loss is 1.1009557. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004215851602023609. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 932][Wall Clock 106.384906629s] Trained 256 records in 0.096260657 seconds. Throughput is 2659.4458 records/second. Loss is 1.0751222. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004215140785702243. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:29 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 933][Wall Clock 106.479644771s] Trained 256 records in 0.094738142 seconds. Throughput is 2702.1853 records/second. Loss is 1.1058267. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004214430209035739. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 934][Wall Clock 106.572169328s] Trained 256 records in 0.092524557 seconds. Throughput is 2766.833 records/second. Loss is 1.1535391. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004213719871902916. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 935][Wall Clock 106.680561763s] Trained 256 records in 0.108392435 seconds. Throughput is 2361.7886 records/second. Loss is 1.0220811. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004213009774182676. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 936][Wall Clock 106.780026716s] Trained 256 records in 0.099464953 seconds. Throughput is 2573.771 records/second. Loss is 1.1011951. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004212299915754001. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 937][Wall Clock 106.880350301s] Trained 256 records in 0.100323585 seconds. Throughput is 2551.743 records/second. Loss is 1.1739168. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042115902964959566. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 938][Wall Clock 106.975427613s] Trained 256 records in 0.095077312 seconds. Throughput is 2692.5457 records/second. Loss is 1.1720434. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004210880916287687. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 939][Wall Clock 107.070024688s] Trained 256 records in 0.094597075 seconds. Throughput is 2706.2148 records/second. Loss is 1.0958134. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004210171775008421. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:408 - [Epoch 4 60160/60000][Iteration 940][Wall Clock 107.165658019s] Trained 256 records in 0.095633331 seconds. Throughput is 2676.891 records/second. Loss is 1.1053115. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004209462872537465. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:30 INFO  DistriOptimizer$:452 - [Epoch 4 60160/60000][Iteration 940][Wall Clock 107.165658019s] Epoch finished. Wall clock time is 108114.769818 ms
2019-10-26 12:16:30 INFO  DistriOptimizer$:111 - [Epoch 4 60160/60000][Iteration 940][Wall Clock 107.165658019s] Validate model...
2019-10-26 12:16:31 INFO  DistriOptimizer$:178 - [Epoch 4 60160/60000][Iteration 940][Wall Clock 107.165658019s] validate model throughput is 8996.317 records/second
2019-10-26 12:16:31 INFO  DistriOptimizer$:181 - [Epoch 4 60160/60000][Iteration 940][Wall Clock 107.165658019s] Top1Accuracy is Accuracy(correct: 7540, count: 10000, accuracy: 0.754)
2019-10-26 12:16:31 INFO  DistriOptimizer$:221 - [Wall Clock 108.114769818s] Save model to /tmp/lenet5/20191026_121442
2019-10-26 12:16:31 INFO  DistriOptimizer$:226 - [Wall Clock 108.114769818s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@13b5664a to /tmp/lenet5/20191026_121442
2019-10-26 12:16:31 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 941][Wall Clock 108.217692269s] Trained 256 records in 0.102922451 seconds. Throughput is 2487.3096 records/second. Loss is 1.0498891. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004208754208754209. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 942][Wall Clock 108.317426709s] Trained 256 records in 0.09973444 seconds. Throughput is 2566.8164 records/second. Loss is 1.0981823. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042080457835381255. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 943][Wall Clock 108.419772909s] Trained 256 records in 0.1023462 seconds. Throughput is 2501.3142 records/second. Loss is 1.0980964. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004207337596768764. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 944][Wall Clock 108.515386226s] Trained 256 records in 0.095613317 seconds. Throughput is 2677.4514 records/second. Loss is 1.0961145. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004206629648325761. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 945][Wall Clock 108.609952403s] Trained 256 records in 0.094566177 seconds. Throughput is 2707.099 records/second. Loss is 1.0610603. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0042059219380888285. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 946][Wall Clock 108.703462654s] Trained 256 records in 0.093510251 seconds. Throughput is 2737.668 records/second. Loss is 1.1113932. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004205214465937763. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 947][Wall Clock 108.798134252s] Trained 256 records in 0.094671598 seconds. Throughput is 2704.0845 records/second. Loss is 1.1150218. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004204507231752439. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 948][Wall Clock 108.892583189s] Trained 256 records in 0.094448937 seconds. Throughput is 2710.4592 records/second. Loss is 1.0505486. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004203800235412813. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 949][Wall Clock 109.045374159s] Trained 256 records in 0.15279097 seconds. Throughput is 1675.4917 records/second. Loss is 1.0325154. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004203093476798924. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 950][Wall Clock 109.137502909s] Trained 256 records in 0.09212875 seconds. Throughput is 2778.72 records/second. Loss is 1.1767055. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00420238695579089. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:32 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 951][Wall Clock 109.241951745s] Trained 256 records in 0.104448836 seconds. Throughput is 2450.961 records/second. Loss is 1.1007657. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004201680672268908. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 952][Wall Clock 109.392314237s] Trained 256 records in 0.150362492 seconds. Throughput is 1702.5522 records/second. Loss is 1.1361358. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004200974626113259. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 953][Wall Clock 109.485994186s] Trained 256 records in 0.093679949 seconds. Throughput is 2732.7085 records/second. Loss is 1.1050394. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004200268817204302. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 954][Wall Clock 109.579069186s] Trained 256 records in 0.093075 seconds. Throughput is 2750.47 records/second. Loss is 1.0984433. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004199563245422476. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 955][Wall Clock 109.6745098s] Trained 256 records in 0.095440614 seconds. Throughput is 2682.2964 records/second. Loss is 1.069525. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004198857910648304. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 956][Wall Clock 109.774517615s] Trained 256 records in 0.100007815 seconds. Throughput is 2559.7998 records/second. Loss is 1.034479. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041981528127623844. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 957][Wall Clock 109.877853315s] Trained 256 records in 0.1033357 seconds. Throughput is 2477.3625 records/second. Loss is 1.1076149. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041974479516454. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 958][Wall Clock 109.968675465s] Trained 256 records in 0.09082215 seconds. Throughput is 2818.6956 records/second. Loss is 1.0982282. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004196743327178109. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 959][Wall Clock 110.062575789s] Trained 256 records in 0.093900324 seconds. Throughput is 2726.2952 records/second. Loss is 1.1081249. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004196038939241357. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 960][Wall Clock 110.155393528s] Trained 256 records in 0.092817739 seconds. Throughput is 2758.0935 records/second. Loss is 1.1186578. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00419533478771606. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:33 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 961][Wall Clock 110.248774792s] Trained 256 records in 0.093381264 seconds. Throughput is 2741.4492 records/second. Loss is 1.0394138. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041946308724832215. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 962][Wall Clock 110.343750643s] Trained 256 records in 0.094975851 seconds. Throughput is 2695.422 records/second. Loss is 1.0811942. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004193927193423923. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 963][Wall Clock 110.437530185s] Trained 256 records in 0.093779542 seconds. Throughput is 2729.8064 records/second. Loss is 1.0727804. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004193223750419322. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 964][Wall Clock 110.54765934s] Trained 256 records in 0.110129155 seconds. Throughput is 2324.5435 records/second. Loss is 1.0978826. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004192520543350662. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 965][Wall Clock 110.707669231s] Trained 256 records in 0.160009891 seconds. Throughput is 1599.9011 records/second. Loss is 1.0792501. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004191817572099262. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 966][Wall Clock 110.850379912s] Trained 256 records in 0.142710681 seconds. Throughput is 1793.839 records/second. Loss is 1.0792644. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004191114836546521. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 967][Wall Clock 110.943191355s] Trained 256 records in 0.092811443 seconds. Throughput is 2758.2805 records/second. Loss is 1.0475698. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004190412336573919. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 968][Wall Clock 111.035488718s] Trained 256 records in 0.092297363 seconds. Throughput is 2773.6438 records/second. Loss is 1.1085669. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004189710072063014. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 969][Wall Clock 111.129122671s] Trained 256 records in 0.093633953 seconds. Throughput is 2734.051 records/second. Loss is 1.0453913. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041890080428954425. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:34 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 970][Wall Clock 111.223713741s] Trained 256 records in 0.09459107 seconds. Throughput is 2706.3865 records/second. Loss is 1.0390322. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041883062489529235. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 971][Wall Clock 111.315832973s] Trained 256 records in 0.092119232 seconds. Throughput is 2779.007 records/second. Loss is 1.0182163. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004187604690117253. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 972][Wall Clock 111.410193605s] Trained 256 records in 0.094360632 seconds. Throughput is 2712.9958 records/second. Loss is 1.0965247. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004186903366270307. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 973][Wall Clock 111.506443315s] Trained 256 records in 0.09624971 seconds. Throughput is 2659.7483 records/second. Loss is 0.97083294. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004186202277294039. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 974][Wall Clock 111.599560248s] Trained 256 records in 0.093116933 seconds. Throughput is 2749.2314 records/second. Loss is 0.97438335. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041855014230704835. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 975][Wall Clock 111.696549261s] Trained 256 records in 0.096989013 seconds. Throughput is 2639.474 records/second. Loss is 1.0770121. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004184800803481754. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 976][Wall Clock 111.788670487s] Trained 256 records in 0.092121226 seconds. Throughput is 2778.9468 records/second. Loss is 1.0846694. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041841004184100415. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 977][Wall Clock 111.882950001s] Trained 256 records in 0.094279514 seconds. Throughput is 2715.33 records/second. Loss is 1.1104497. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004183400267737617. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 978][Wall Clock 111.975828486s] Trained 256 records in 0.092878485 seconds. Throughput is 2756.2896 records/second. Loss is 1.0240732. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004182700351346829. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 979][Wall Clock 112.072626023s] Trained 256 records in 0.096797537 seconds. Throughput is 2644.6956 records/second. Loss is 1.0520031. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004182000669120107. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 980][Wall Clock 112.170580199s] Trained 256 records in 0.097954176 seconds. Throughput is 2613.467 records/second. Loss is 1.0975386. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041813012209399565. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:35 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 981][Wall Clock 112.275639634s] Trained 256 records in 0.105059435 seconds. Throughput is 2436.7158 records/second. Loss is 1.0906937. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004180602006688964. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 982][Wall Clock 112.367972831s] Trained 256 records in 0.092333197 seconds. Throughput is 2772.5671 records/second. Loss is 1.074343. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004179903026249791. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 983][Wall Clock 112.460593448s] Trained 256 records in 0.092620617 seconds. Throughput is 2763.9634 records/second. Loss is 1.1720918. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004179204279505182. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 984][Wall Clock 112.555576009s] Trained 256 records in 0.094982561 seconds. Throughput is 2695.2314 records/second. Loss is 1.0915698. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004178505766337957. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 985][Wall Clock 112.649804368s] Trained 256 records in 0.094228359 seconds. Throughput is 2716.8042 records/second. Loss is 1.0026853. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004177807486631016. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 986][Wall Clock 112.744405426s] Trained 256 records in 0.094601058 seconds. Throughput is 2706.1008 records/second. Loss is 1.0484834. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004177109440267335. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 987][Wall Clock 112.840319487s] Trained 256 records in 0.095914061 seconds. Throughput is 2669.0562 records/second. Loss is 1.0497798. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00417641162712997. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 988][Wall Clock 112.935699958s] Trained 256 records in 0.095380471 seconds. Throughput is 2683.9875 records/second. Loss is 1.042421. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041757140471020545. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 989][Wall Clock 113.030017778s] Trained 256 records in 0.09431782 seconds. Throughput is 2714.2273 records/second. Loss is 1.0473555. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004175016700066801. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 990][Wall Clock 113.125549678s] Trained 256 records in 0.0955319 seconds. Throughput is 2679.7332 records/second. Loss is 1.0653206. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004174319585907497. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:36 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 991][Wall Clock 113.221461199s] Trained 256 records in 0.095911521 seconds. Throughput is 2669.1267 records/second. Loss is 1.0391976. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004173622704507513. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 992][Wall Clock 113.323096022s] Trained 256 records in 0.101634823 seconds. Throughput is 2518.8218 records/second. Loss is 1.0873377. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004172926055750293. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 993][Wall Clock 113.416871496s] Trained 256 records in 0.093775474 seconds. Throughput is 2729.9248 records/second. Loss is 1.0360422. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00417222963951936. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 994][Wall Clock 113.512184136s] Trained 256 records in 0.09531264 seconds. Throughput is 2685.8977 records/second. Loss is 1.0062717. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004171533455698315. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 995][Wall Clock 113.603771339s] Trained 256 records in 0.091587203 seconds. Throughput is 2795.1504 records/second. Loss is 1.0431142. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004170837504170837. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 996][Wall Clock 113.699784113s] Trained 256 records in 0.096012774 seconds. Throughput is 2666.312 records/second. Loss is 1.1018093. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004170141784820684. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 997][Wall Clock 113.793523741s] Trained 256 records in 0.093739628 seconds. Throughput is 2730.9688 records/second. Loss is 0.97567564. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004169446297531688. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 998][Wall Clock 113.887680448s] Trained 256 records in 0.094156707 seconds. Throughput is 2718.8716 records/second. Loss is 1.050101. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00416875104218776. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 999][Wall Clock 113.979111741s] Trained 256 records in 0.091431293 seconds. Throughput is 2799.9167 records/second. Loss is 0.9876625. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004168056018672891. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 1000][Wall Clock 114.073031363s] Trained 256 records in 0.093919622 seconds. Throughput is 2725.735 records/second. Loss is 1.0411894. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004167361226871146. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 1001][Wall Clock 114.164869304s] Trained 256 records in 0.091837941 seconds. Throughput is 2787.5188 records/second. Loss is 1.0914018. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004166666666666667. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:37 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 1002][Wall Clock 114.25710623s] Trained 256 records in 0.092236926 seconds. Throughput is 2775.461 records/second. Loss is 1.0246466. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004165972337943676. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 1003][Wall Clock 114.35152038s] Trained 256 records in 0.09441415 seconds. Throughput is 2711.458 records/second. Loss is 1.0802907. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004165278240586471. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 1004][Wall Clock 114.443672442s] Trained 256 records in 0.092152062 seconds. Throughput is 2778.017 records/second. Loss is 1.0398036. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041645843744794265. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 1005][Wall Clock 114.536047253s] Trained 256 records in 0.092374811 seconds. Throughput is 2771.3184 records/second. Loss is 0.97366405. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041638907395069955. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 1006][Wall Clock 114.63182117s] Trained 256 records in 0.095773917 seconds. Throughput is 2672.9614 records/second. Loss is 0.9652019. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004163197335553705. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 1007][Wall Clock 114.732122669s] Trained 256 records in 0.100301499 seconds. Throughput is 2552.305 records/second. Loss is 1.0676391. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004162504162504162. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 1008][Wall Clock 114.827340342s] Trained 256 records in 0.095217673 seconds. Throughput is 2688.5764 records/second. Loss is 1.0634156. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00416181122024305. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 1009][Wall Clock 114.928905264s] Trained 256 records in 0.101564922 seconds. Throughput is 2520.5552 records/second. Loss is 1.0466521. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004161118508655127. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 1010][Wall Clock 115.022161662s] Trained 256 records in 0.093256398 seconds. Throughput is 2745.1199 records/second. Loss is 1.0270752. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041604260276252285. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 1011][Wall Clock 115.115597703s] Trained 256 records in 0.093436041 seconds. Throughput is 2739.842 records/second. Loss is 1.0284523. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00415973377703827. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:38 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 1012][Wall Clock 115.212425461s] Trained 256 records in 0.096827758 seconds. Throughput is 2643.8699 records/second. Loss is 1.050325. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004159041756779239. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 1013][Wall Clock 115.307295735s] Trained 256 records in 0.094870274 seconds. Throughput is 2698.4216 records/second. Loss is 1.0943574. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004158349966733201. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 1014][Wall Clock 115.404748328s] Trained 256 records in 0.097452593 seconds. Throughput is 2626.9182 records/second. Loss is 1.004428. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004157658406785299. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 1015][Wall Clock 115.498167261s] Trained 256 records in 0.093418933 seconds. Throughput is 2740.3438 records/second. Loss is 0.95315987. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004156967076820751. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 1016][Wall Clock 115.592652155s] Trained 256 records in 0.094484894 seconds. Throughput is 2709.4277 records/second. Loss is 1.0392537. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004156275976724855. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 1017][Wall Clock 115.702540607s] Trained 256 records in 0.109888452 seconds. Throughput is 2329.6353 records/second. Loss is 1.0624622. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004155585106382979. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 1018][Wall Clock 115.797508639s] Trained 256 records in 0.094968032 seconds. Throughput is 2695.644 records/second. Loss is 0.99592775. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041548944656805715. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 1019][Wall Clock 115.891554542s] Trained 256 records in 0.094045903 seconds. Throughput is 2722.0752 records/second. Loss is 1.0369935. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004154204054503157. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 1020][Wall Clock 115.981090092s] Trained 256 records in 0.08953555 seconds. Throughput is 2859.1995 records/second. Loss is 1.0508624. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004153513872736335. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 1021][Wall Clock 116.073144024s] Trained 256 records in 0.092053932 seconds. Throughput is 2780.9783 records/second. Loss is 1.0727439. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004152823920265781. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 1022][Wall Clock 116.168261008s] Trained 256 records in 0.095116984 seconds. Throughput is 2691.4226 records/second. Loss is 0.9931611. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004152134196977246. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:39 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 1023][Wall Clock 116.259586144s] Trained 256 records in 0.091325136 seconds. Throughput is 2803.1714 records/second. Loss is 1.0094817. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004151444702756559. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 1024][Wall Clock 116.365552749s] Trained 256 records in 0.105966605 seconds. Throughput is 2415.8555 records/second. Loss is 0.9442766. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041507554374896225. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 1025][Wall Clock 116.458781849s] Trained 256 records in 0.0932291 seconds. Throughput is 2745.9238 records/second. Loss is 1.0427635. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004150066401062417. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 1026][Wall Clock 116.552516096s] Trained 256 records in 0.093734247 seconds. Throughput is 2731.1255 records/second. Loss is 1.0075592. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004149377593360996. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 1027][Wall Clock 116.647845019s] Trained 256 records in 0.095328923 seconds. Throughput is 2685.439 records/second. Loss is 0.99735445. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00414868901427149. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 1028][Wall Clock 116.741571481s] Trained 256 records in 0.093726462 seconds. Throughput is 2731.3523 records/second. Loss is 1.0336839. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004148000663680106. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 1029][Wall Clock 116.83527652s] Trained 256 records in 0.093705039 seconds. Throughput is 2731.977 records/second. Loss is 1.048155. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004147312541473125. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 1030][Wall Clock 116.928614256s] Trained 256 records in 0.093337736 seconds. Throughput is 2742.7278 records/second. Loss is 1.0351231. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004146624647536905. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 1031][Wall Clock 117.021883113s] Trained 256 records in 0.093268857 seconds. Throughput is 2744.7532 records/second. Loss is 0.9710995. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041459369817578775. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 1032][Wall Clock 117.11450042s] Trained 256 records in 0.092617307 seconds. Throughput is 2764.062 records/second. Loss is 0.993835. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00414524954402255. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:40 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 1033][Wall Clock 117.208574272s] Trained 256 records in 0.094073852 seconds. Throughput is 2721.266 records/second. Loss is 0.9712926. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004144562334217507. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 1034][Wall Clock 117.305310697s] Trained 256 records in 0.096736425 seconds. Throughput is 2646.3662 records/second. Loss is 0.9229972. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004143875352229405. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 1035][Wall Clock 117.39985021s] Trained 256 records in 0.094539513 seconds. Throughput is 2707.8623 records/second. Loss is 0.97944194. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004143188597944978. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 1036][Wall Clock 117.503394042s] Trained 256 records in 0.103543832 seconds. Throughput is 2472.3828 records/second. Loss is 1.0009345. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004142502071251036. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 1037][Wall Clock 117.599005366s] Trained 256 records in 0.095611324 seconds. Throughput is 2677.507 records/second. Loss is 1.0539948. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00414181577203446. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 1038][Wall Clock 117.698048199s] Trained 256 records in 0.099042833 seconds. Throughput is 2584.7402 records/second. Loss is 0.9980238. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004141129700182209. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 1039][Wall Clock 117.793285466s] Trained 256 records in 0.095237267 seconds. Throughput is 2688.0232 records/second. Loss is 1.0080421. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004140443855581318. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 1040][Wall Clock 117.888502055s] Trained 256 records in 0.095216589 seconds. Throughput is 2688.6072 records/second. Loss is 0.94297624. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004139758238118894. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 1041][Wall Clock 117.98311805s] Trained 256 records in 0.094615995 seconds. Throughput is 2705.6736 records/second. Loss is 0.99194217. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041390728476821195. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 1042][Wall Clock 118.078291408s] Trained 256 records in 0.095173358 seconds. Throughput is 2689.8284 records/second. Loss is 1.0186576. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004138387684158252. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 1043][Wall Clock 118.176531975s] Trained 256 records in 0.098240567 seconds. Throughput is 2605.8481 records/second. Loss is 0.97849554. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004137702747434625. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:41 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 1044][Wall Clock 118.269569359s] Trained 256 records in 0.093037384 seconds. Throughput is 2751.5823 records/second. Loss is 0.99362314. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041370180373986425. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 1045][Wall Clock 118.362193529s] Trained 256 records in 0.09262417 seconds. Throughput is 2763.8574 records/second. Loss is 0.97488713. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00413633355393779. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 1046][Wall Clock 118.455058996s] Trained 256 records in 0.092865467 seconds. Throughput is 2756.676 records/second. Loss is 0.9729052. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041356492969396195. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 1047][Wall Clock 118.550323902s] Trained 256 records in 0.095264906 seconds. Throughput is 2687.2437 records/second. Loss is 1.0177478. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004134965266291763. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 1048][Wall Clock 118.643965611s] Trained 256 records in 0.093641709 seconds. Throughput is 2733.8247 records/second. Loss is 1.0313352. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004134281461881925. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 1049][Wall Clock 118.738472819s] Trained 256 records in 0.094507208 seconds. Throughput is 2708.788 records/second. Loss is 0.96313876. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004133597883597883. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 1050][Wall Clock 118.833200757s] Trained 256 records in 0.094727938 seconds. Throughput is 2702.476 records/second. Loss is 0.99435693. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004132914531327492. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 1051][Wall Clock 118.926482381s] Trained 256 records in 0.093281624 seconds. Throughput is 2744.3774 records/second. Loss is 1.0076276. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004132231404958678. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 1052][Wall Clock 119.025618916s] Trained 256 records in 0.099136535 seconds. Throughput is 2582.2974 records/second. Loss is 1.0062996. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041315485043794415. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 1053][Wall Clock 119.121053263s] Trained 256 records in 0.095434347 seconds. Throughput is 2682.4724 records/second. Loss is 1.0039122. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004130865829477859. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:42 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 1054][Wall Clock 119.212671923s] Trained 256 records in 0.09161866 seconds. Throughput is 2794.1907 records/second. Loss is 0.98478365. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004130183380142078. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 1055][Wall Clock 119.304893442s] Trained 256 records in 0.092221519 seconds. Throughput is 2775.9248 records/second. Loss is 0.9672239. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004129501156260323. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 1056][Wall Clock 119.398561549s] Trained 256 records in 0.093668107 seconds. Throughput is 2733.054 records/second. Loss is 0.95884234. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004128819157720892. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 1057][Wall Clock 119.492024668s] Trained 256 records in 0.093463119 seconds. Throughput is 2739.0483 records/second. Loss is 1.0107784. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004128137384412153. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 1058][Wall Clock 119.59113872s] Trained 256 records in 0.099114052 seconds. Throughput is 2582.883 records/second. Loss is 0.9895354. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041274558362225525. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 1059][Wall Clock 119.688754967s] Trained 256 records in 0.097616247 seconds. Throughput is 2622.5142 records/second. Loss is 0.9662611. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004126774513040607. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 1060][Wall Clock 119.786261828s] Trained 256 records in 0.097506861 seconds. Throughput is 2625.4563 records/second. Loss is 1.0637761. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00412609341475491. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 1061][Wall Clock 119.886294303s] Trained 256 records in 0.100032475 seconds. Throughput is 2559.1687 records/second. Loss is 0.97152287. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004125412541254126. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 1062][Wall Clock 119.981577895s] Trained 256 records in 0.095283592 seconds. Throughput is 2686.7166 records/second. Loss is 0.9755662. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004124731892426993. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 1063][Wall Clock 120.076383742s] Trained 256 records in 0.094805847 seconds. Throughput is 2700.2554 records/second. Loss is 1.1082247. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004124051468162323. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:43 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 1064][Wall Clock 120.183733734s] Trained 256 records in 0.107349992 seconds. Throughput is 2384.7231 records/second. Loss is 0.9820758. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004123371268349002. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 1065][Wall Clock 120.277909901s] Trained 256 records in 0.094176167 seconds. Throughput is 2718.3098 records/second. Loss is 0.97794133. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041226912928759895. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 1066][Wall Clock 120.372135612s] Trained 256 records in 0.094225711 seconds. Throughput is 2716.8806 records/second. Loss is 1.018609. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004122011541632316. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 1067][Wall Clock 120.470408703s] Trained 256 records in 0.098273091 seconds. Throughput is 2604.9858 records/second. Loss is 0.9928632. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004121332014507088. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 1068][Wall Clock 120.56648876s] Trained 256 records in 0.096080057 seconds. Throughput is 2664.4448 records/second. Loss is 0.95661074. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041206527113894845. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 1069][Wall Clock 120.661430554s] Trained 256 records in 0.094941794 seconds. Throughput is 2696.389 records/second. Loss is 1.0091382. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004119973632168754. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 1070][Wall Clock 120.765294736s] Trained 256 records in 0.103864182 seconds. Throughput is 2464.7573 records/second. Loss is 0.9913005. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004119294776734223. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 1071][Wall Clock 120.869699708s] Trained 256 records in 0.104404972 seconds. Throughput is 2451.9905 records/second. Loss is 0.964905. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004118616144975288. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 1072][Wall Clock 120.967110341s] Trained 256 records in 0.097410633 seconds. Throughput is 2628.0498 records/second. Loss is 0.9334033. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00411793773678142. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 1073][Wall Clock 121.065447649s] Trained 256 records in 0.098337308 seconds. Throughput is 2603.2847 records/second. Loss is 0.9721503. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004117259552042161. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 1074][Wall Clock 121.157731897s] Trained 256 records in 0.092284248 seconds. Throughput is 2774.0378 records/second. Loss is 0.97552395. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004116581590647127. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:44 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 1075][Wall Clock 121.256727186s] Trained 256 records in 0.098995289 seconds. Throughput is 2585.9817 records/second. Loss is 0.98469174. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004115903852486006. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 1076][Wall Clock 121.351961993s] Trained 256 records in 0.095234807 seconds. Throughput is 2688.093 records/second. Loss is 0.90305907. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004115226337448559. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 1077][Wall Clock 121.460591684s] Trained 256 records in 0.108629691 seconds. Throughput is 2356.6301 records/second. Loss is 1.0066684. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004114549045424621. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 1078][Wall Clock 121.559384319s] Trained 256 records in 0.098792635 seconds. Throughput is 2591.2864 records/second. Loss is 0.89077526. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004113871976304097. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 1079][Wall Clock 121.655981793s] Trained 256 records in 0.096597474 seconds. Throughput is 2650.1729 records/second. Loss is 0.9978479. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004113195129976966. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 1080][Wall Clock 121.750124367s] Trained 256 records in 0.094142574 seconds. Throughput is 2719.2798 records/second. Loss is 0.9910419. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004112518506333279. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 1081][Wall Clock 121.850718786s] Trained 256 records in 0.100594419 seconds. Throughput is 2544.8728 records/second. Loss is 0.899365. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004111842105263158. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 1082][Wall Clock 121.944440383s] Trained 256 records in 0.093721597 seconds. Throughput is 2731.4941 records/second. Loss is 0.99665046. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041111659266568. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 1083][Wall Clock 122.040016279s] Trained 256 records in 0.095575896 seconds. Throughput is 2678.4995 records/second. Loss is 0.9781496. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004110489970404472. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 1084][Wall Clock 122.133668586s] Trained 256 records in 0.093652307 seconds. Throughput is 2733.5151 records/second. Loss is 0.9675682. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004109814236396514. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:45 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 1085][Wall Clock 122.226363021s] Trained 256 records in 0.092694435 seconds. Throughput is 2761.7625 records/second. Loss is 1.0090901. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00410913872452334. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 1086][Wall Clock 122.318303584s] Trained 256 records in 0.091940563 seconds. Throughput is 2784.4077 records/second. Loss is 0.98528486. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004108463434675432. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 1087][Wall Clock 122.415076841s] Trained 256 records in 0.096773257 seconds. Throughput is 2645.359 records/second. Loss is 0.95875627. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004107788366743345. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 1088][Wall Clock 122.518437328s] Trained 256 records in 0.103360487 seconds. Throughput is 2476.7686 records/second. Loss is 0.96209615. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041071135206177094. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 1089][Wall Clock 122.623772321s] Trained 256 records in 0.105334993 seconds. Throughput is 2430.3416 records/second. Loss is 0.90819716. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004106438896189225. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 1090][Wall Clock 122.723089701s] Trained 256 records in 0.09931738 seconds. Throughput is 2577.5952 records/second. Loss is 0.98018813. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004105764493348662. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 1091][Wall Clock 122.822984564s] Trained 256 records in 0.099894863 seconds. Throughput is 2562.6943 records/second. Loss is 0.8883339. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004105090311986864. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 1092][Wall Clock 122.923106947s] Trained 256 records in 0.100122383 seconds. Throughput is 2556.8708 records/second. Loss is 0.9192913. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004104416351994746. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 1093][Wall Clock 123.01754472s] Trained 256 records in 0.094437773 seconds. Throughput is 2710.7798 records/second. Loss is 0.9901548. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0041037426132632965. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 1094][Wall Clock 123.111355625s] Trained 256 records in 0.093810905 seconds. Throughput is 2728.8938 records/second. Loss is 0.92928624. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004103069095683571. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:46 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 1095][Wall Clock 123.206455395s] Trained 256 records in 0.09509977 seconds. Throughput is 2691.9097 records/second. Loss is 0.8905667. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004102395799146701. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 1096][Wall Clock 123.304531103s] Trained 256 records in 0.098075708 seconds. Throughput is 2610.2283 records/second. Loss is 0.94103205. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004101722723543888. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 1097][Wall Clock 123.399719935s] Trained 256 records in 0.095188832 seconds. Throughput is 2689.391 records/second. Loss is 0.9521679. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004101049868766404. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 1098][Wall Clock 123.493301084s] Trained 256 records in 0.093581149 seconds. Throughput is 2735.5938 records/second. Loss is 0.9991801. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004100377234705593. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 1099][Wall Clock 123.589288104s] Trained 256 records in 0.09598702 seconds. Throughput is 2667.027 records/second. Loss is 0.9359259. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040997048212528696. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 1100][Wall Clock 123.686366899s] Trained 256 records in 0.097078795 seconds. Throughput is 2637.0332 records/second. Loss is 0.93032634. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004099032628299721. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 1101][Wall Clock 123.782491612s] Trained 256 records in 0.096124713 seconds. Throughput is 2663.2068 records/second. Loss is 0.9578304. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004098360655737705. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 1102][Wall Clock 123.877873346s] Trained 256 records in 0.095381734 seconds. Throughput is 2683.952 records/second. Loss is 0.8781245. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00409768890345845. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 1103][Wall Clock 123.972613906s] Trained 256 records in 0.09474056 seconds. Throughput is 2702.1162 records/second. Loss is 0.95040244. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004097017371353655. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 1104][Wall Clock 124.067202207s] Trained 256 records in 0.094588301 seconds. Throughput is 2706.4658 records/second. Loss is 0.99319327. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004096346059315091. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 1105][Wall Clock 124.160482696s] Trained 256 records in 0.093280489 seconds. Throughput is 2744.4111 records/second. Loss is 1.0088327. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040956749672346. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:47 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 1106][Wall Clock 124.256200915s] Trained 256 records in 0.095718219 seconds. Throughput is 2674.5168 records/second. Loss is 0.9423146. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004095004095004095. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 1107][Wall Clock 124.352335323s] Trained 256 records in 0.096134408 seconds. Throughput is 2662.9382 records/second. Loss is 0.9851675. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004094333442515558. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 1108][Wall Clock 124.445455338s] Trained 256 records in 0.093120015 seconds. Throughput is 2749.1404 records/second. Loss is 0.9279837. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040936630096610445. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 1109][Wall Clock 124.539203885s] Trained 256 records in 0.093748547 seconds. Throughput is 2730.709 records/second. Loss is 1.0066097. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004092992796332679. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 1110][Wall Clock 124.633282168s] Trained 256 records in 0.094078283 seconds. Throughput is 2721.1382 records/second. Loss is 0.9051106. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004092322802422655. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 1111][Wall Clock 124.72471437s] Trained 256 records in 0.091432202 seconds. Throughput is 2799.889 records/second. Loss is 0.9369254. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004091653027823241. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 1112][Wall Clock 124.819570211s] Trained 256 records in 0.094855841 seconds. Throughput is 2698.8323 records/second. Loss is 0.9093095. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004090983472426772. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 1113][Wall Clock 124.914997682s] Trained 256 records in 0.095427471 seconds. Throughput is 2682.6658 records/second. Loss is 0.94055647. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004090314136125654. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 1114][Wall Clock 125.009201765s] Trained 256 records in 0.094204083 seconds. Throughput is 2717.5044 records/second. Loss is 0.9798067. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004089645018812368. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 1115][Wall Clock 125.102950872s] Trained 256 records in 0.093749107 seconds. Throughput is 2730.6926 records/second. Loss is 0.90324444. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040889761203794575. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:48 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 1116][Wall Clock 125.196280939s] Trained 256 records in 0.093330067 seconds. Throughput is 2742.9531 records/second. Loss is 0.9942623. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004088307440719542. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 1117][Wall Clock 125.294037252s] Trained 256 records in 0.097756313 seconds. Throughput is 2618.7568 records/second. Loss is 0.8828884. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004087638979725311. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 1118][Wall Clock 125.38874448s] Trained 256 records in 0.094707228 seconds. Throughput is 2703.0671 records/second. Loss is 0.92150116. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004086970737289521. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 1119][Wall Clock 125.485247019s] Trained 256 records in 0.096502539 seconds. Throughput is 2652.7798 records/second. Loss is 0.9506787. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004086302713305002. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 1120][Wall Clock 125.580755915s] Trained 256 records in 0.095508896 seconds. Throughput is 2680.3787 records/second. Loss is 0.90706414. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004085634907664651. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 1121][Wall Clock 125.675893967s] Trained 256 records in 0.095138052 seconds. Throughput is 2690.8267 records/second. Loss is 0.9301185. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004084967320261438. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 1122][Wall Clock 125.770234887s] Trained 256 records in 0.09434092 seconds. Throughput is 2713.5627 records/second. Loss is 0.90494335. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040842999509884004. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 1123][Wall Clock 125.869908224s] Trained 256 records in 0.099673337 seconds. Throughput is 2568.39 records/second. Loss is 0.8775967. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004083632799738648. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 1124][Wall Clock 125.966659929s] Trained 256 records in 0.096751705 seconds. Throughput is 2645.9482 records/second. Loss is 0.8963954. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004082965866405356. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 1125][Wall Clock 126.061349963s] Trained 256 records in 0.094690034 seconds. Throughput is 2703.558 records/second. Loss is 0.90254605. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004082299150881776. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 1126][Wall Clock 126.155717329s] Trained 256 records in 0.094367366 seconds. Throughput is 2712.8022 records/second. Loss is 0.95005643. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004081632653061224. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:49 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 1127][Wall Clock 126.249609893s] Trained 256 records in 0.093892564 seconds. Throughput is 2726.5205 records/second. Loss is 0.94451225. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004080966372837088. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 1128][Wall Clock 126.342560855s] Trained 256 records in 0.092950962 seconds. Throughput is 2754.1404 records/second. Loss is 0.90944296. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004080300310102824. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 1129][Wall Clock 126.435826138s] Trained 256 records in 0.093265283 seconds. Throughput is 2744.8586 records/second. Loss is 0.9289529. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004079634464751959. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 1130][Wall Clock 126.531734388s] Trained 256 records in 0.09590825 seconds. Throughput is 2669.2178 records/second. Loss is 0.86774355. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004078968836678088. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 1131][Wall Clock 126.627280646s] Trained 256 records in 0.095546258 seconds. Throughput is 2679.3303 records/second. Loss is 0.8771504. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004078303425774878. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 1132][Wall Clock 126.719714402s] Trained 256 records in 0.092433756 seconds. Throughput is 2769.551 records/second. Loss is 0.91600937. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004077638231936063. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 1133][Wall Clock 126.818796046s] Trained 256 records in 0.099081644 seconds. Throughput is 2583.7278 records/second. Loss is 0.9248092. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040769732550554475. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 1134][Wall Clock 126.908414098s] Trained 256 records in 0.089618052 seconds. Throughput is 2856.5674 records/second. Loss is 0.8898134. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004076308495026904. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 1135][Wall Clock 127.00216572s] Trained 256 records in 0.093751622 seconds. Throughput is 2730.6194 records/second. Loss is 0.9622932. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004075643951744376. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 1136][Wall Clock 127.095470599s] Trained 256 records in 0.093304879 seconds. Throughput is 2743.6936 records/second. Loss is 0.93915194. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004074979625101874. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:50 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 1137][Wall Clock 127.189221013s] Trained 256 records in 0.093750414 seconds. Throughput is 2730.6545 records/second. Loss is 0.9522504. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004074315514993481. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 1138][Wall Clock 127.281271855s] Trained 256 records in 0.092050842 seconds. Throughput is 2781.0718 records/second. Loss is 0.9497894. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004073651621313346. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 1139][Wall Clock 127.37445094s] Trained 256 records in 0.093179085 seconds. Throughput is 2747.3977 records/second. Loss is 0.89295. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004072987943955686. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 1140][Wall Clock 127.471482925s] Trained 256 records in 0.097031985 seconds. Throughput is 2638.3052 records/second. Loss is 0.86349845. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004072324482814791. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 1141][Wall Clock 127.566144412s] Trained 256 records in 0.094661487 seconds. Throughput is 2704.3733 records/second. Loss is 0.9072354. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004071661237785016. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 1142][Wall Clock 127.668750041s] Trained 256 records in 0.102605629 seconds. Throughput is 2494.99 records/second. Loss is 0.94217825. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004070998208760788. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 1143][Wall Clock 127.763358798s] Trained 256 records in 0.094608757 seconds. Throughput is 2705.8806 records/second. Loss is 0.88582706. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004070335395636601. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 1144][Wall Clock 127.856235047s] Trained 256 records in 0.092876249 seconds. Throughput is 2756.356 records/second. Loss is 0.97579026. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004069672798307017. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 1145][Wall Clock 127.949003967s] Trained 256 records in 0.09276892 seconds. Throughput is 2759.545 records/second. Loss is 0.9455324. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004069010416666666. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 1146][Wall Clock 128.043168129s] Trained 256 records in 0.094164162 seconds. Throughput is 2718.6562 records/second. Loss is 0.9535522. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040683482506102524. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 1147][Wall Clock 128.138816409s] Trained 256 records in 0.09564828 seconds. Throughput is 2676.4727 records/second. Loss is 0.9092411. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004067686300032541. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:51 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 1148][Wall Clock 128.235088265s] Trained 256 records in 0.096271856 seconds. Throughput is 2659.1365 records/second. Loss is 0.94976234. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004067024564828371. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 1149][Wall Clock 128.329182989s] Trained 256 records in 0.094094724 seconds. Throughput is 2720.6626 records/second. Loss is 0.9452888. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004066363044892648. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 1150][Wall Clock 128.421586203s] Trained 256 records in 0.092403214 seconds. Throughput is 2770.4666 records/second. Loss is 0.88464105. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004065701740120345. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 1151][Wall Clock 128.515262247s] Trained 256 records in 0.093676044 seconds. Throughput is 2732.8225 records/second. Loss is 0.93334717. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040650406504065045. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 1152][Wall Clock 128.609737193s] Trained 256 records in 0.094474946 seconds. Throughput is 2709.7131 records/second. Loss is 0.88418615. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004064379775646236. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 1153][Wall Clock 128.701025854s] Trained 256 records in 0.091288661 seconds. Throughput is 2804.2913 records/second. Loss is 0.92927134. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004063719115734721. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 1154][Wall Clock 128.797817798s] Trained 256 records in 0.096791944 seconds. Throughput is 2644.8481 records/second. Loss is 0.9106873. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004063058670567203. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 1155][Wall Clock 128.893941179s] Trained 256 records in 0.096123381 seconds. Throughput is 2663.244 records/second. Loss is 0.92233866. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004062398440038999. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 1156][Wall Clock 128.986758618s] Trained 256 records in 0.092817439 seconds. Throughput is 2758.1023 records/second. Loss is 0.8814432. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004061738424045491. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 1157][Wall Clock 129.079974496s] Trained 256 records in 0.093215878 seconds. Throughput is 2746.3132 records/second. Loss is 0.90146655. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004061078622482131. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:52 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 1158][Wall Clock 129.172401351s] Trained 256 records in 0.092426855 seconds. Throughput is 2769.7578 records/second. Loss is 0.97335017. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004060419035244437. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 1159][Wall Clock 129.265246236s] Trained 256 records in 0.092844885 seconds. Throughput is 2757.2869 records/second. Loss is 0.9158761. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004059759662227996. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 1160][Wall Clock 129.356646272s] Trained 256 records in 0.091400036 seconds. Throughput is 2800.8743 records/second. Loss is 0.8922247. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004059100503328463. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 1161][Wall Clock 129.451910097s] Trained 256 records in 0.095263825 seconds. Throughput is 2687.274 records/second. Loss is 0.90509826. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004058441558441559. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 1162][Wall Clock 129.544531349s] Trained 256 records in 0.092621252 seconds. Throughput is 2763.9446 records/second. Loss is 0.85232466. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004057782827463074. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 1163][Wall Clock 129.638164703s] Trained 256 records in 0.093633354 seconds. Throughput is 2734.0684 records/second. Loss is 0.8559345. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004057124310288867. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 1164][Wall Clock 129.730190381s] Trained 256 records in 0.092025678 seconds. Throughput is 2781.8323 records/second. Loss is 0.9224131. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004056466006814864. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 1165][Wall Clock 129.839755421s] Trained 256 records in 0.10956504 seconds. Throughput is 2336.5117 records/second. Loss is 0.92744255. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004055807916937054. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 1166][Wall Clock 129.935083564s] Trained 256 records in 0.095328143 seconds. Throughput is 2685.461 records/second. Loss is 0.91110253. Sequentialefab4c68's hyper parameters: Current learning rate is 0.0040551500405515. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 1167][Wall Clock 130.028487843s] Trained 256 records in 0.093404279 seconds. Throughput is 2740.774 records/second. Loss is 0.85614955. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00405449237755433. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 1168][Wall Clock 130.123945832s] Trained 256 records in 0.095457989 seconds. Throughput is 2681.808 records/second. Loss is 0.859321. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004053834927841738. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:53 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 1169][Wall Clock 130.217038364s] Trained 256 records in 0.093092532 seconds. Throughput is 2749.9521 records/second. Loss is 0.8804044. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004053177691309987. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 1170][Wall Clock 130.311119408s] Trained 256 records in 0.094081044 seconds. Throughput is 2721.0583 records/second. Loss is 0.89237285. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004052520667855406. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 1171][Wall Clock 130.404106062s] Trained 256 records in 0.092986654 seconds. Throughput is 2753.0833 records/second. Loss is 0.9177374. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004051863857374392. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 1172][Wall Clock 130.503374735s] Trained 256 records in 0.099268673 seconds. Throughput is 2578.8599 records/second. Loss is 0.91585803. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00405120725976341. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 1173][Wall Clock 130.598146165s] Trained 256 records in 0.09477143 seconds. Throughput is 2701.236 records/second. Loss is 0.9427928. Sequentialefab4c68's hyper parameters: Current learning rate is 0.00405055087491899. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 1174][Wall Clock 130.692358093s] Trained 256 records in 0.094211928 seconds. Throughput is 2717.278 records/second. Loss is 0.9238447. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004049894702737729. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:408 - [Epoch 5 60160/60000][Iteration 1175][Wall Clock 130.789807623s] Trained 256 records in 0.09744953 seconds. Throughput is 2627.0007 records/second. Loss is 0.9163797. Sequentialefab4c68's hyper parameters: Current learning rate is 0.004049238743116294. Current dampening is 1.7976931348623157E308.  
2019-10-26 12:16:54 INFO  DistriOptimizer$:452 - [Epoch 5 60160/60000][Iteration 1175][Wall Clock 130.789807623s] Epoch finished. Wall clock time is 132000.162662 ms
2019-10-26 12:16:54 INFO  DistriOptimizer$:111 - [Epoch 5 60160/60000][Iteration 1175][Wall Clock 130.789807623s] Validate model...
2019-10-26 12:16:55 INFO  DistriOptimizer$:178 - [Epoch 5 60160/60000][Iteration 1175][Wall Clock 130.789807623s] validate model throughput is 10730.198 records/second
2019-10-26 12:16:55 INFO  DistriOptimizer$:181 - [Epoch 5 60160/60000][Iteration 1175][Wall Clock 130.789807623s] Top1Accuracy is Accuracy(correct: 7951, count: 10000, accuracy: 0.7951)
2019-10-26 12:16:55 INFO  DistriOptimizer$:221 - [Wall Clock 132.000162662s] Save model to /tmp/lenet5/20191026_121442
2019-10-26 12:16:55 INFO  DistriOptimizer$:226 - [Wall Clock 132.000162662s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@13b5664a to /tmp/lenet5/20191026_121442
('Extracting', '~/bd/datasets/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '~/bd/datasets/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.795199990273, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.98290002346, total_num: 10000, method: Top5Accuracy
Evaluated result: 0.874126076698, total_num: 79, method: Loss
