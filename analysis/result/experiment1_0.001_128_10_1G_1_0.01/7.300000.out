2019-10-14 23:10:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-14 23:10:49 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-14 23:10:49 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-14 23:10:49 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-14 23:10:49 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-14 23:10:49 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-14 23:10:49 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-14 23:10:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-14 23:10:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 34163.
2019-10-14 23:10:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-14 23:10:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-14 23:10:50 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-14 23:10:50 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-14 23:10:50 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-d54a36ed-8555-4e26-918e-e4f65018804a
2019-10-14 23:10:50 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-14 23:10:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-14 23:10:50 INFO  log:192 - Logging initialized @3032ms
2019-10-14 23:10:50 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-14 23:10:50 INFO  Server:414 - Started @3180ms
2019-10-14 23:10:50 INFO  AbstractConnector:278 - Started ServerConnector@3dbabec8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-14 23:10:50 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@409db3bf{/jobs,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17d93580{/jobs/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f45648{/jobs/job,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@448d7804{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1aa62020{/stages,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ac0632a{/stages/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ddb7a7f{/stages/stage,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@205504e0{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@661b8a17{/stages/pool,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f3fe7f0{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29d22acd{/storage,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21284913{/storage/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1bd93413{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bb940ff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43059907{/environment,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@200630a5{/environment/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@722df11a{/executors,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43a2e918{/executors/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2c809dca{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d9203e7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20aa906e{/static,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72e6dd06{/,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6671d13b{/api,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ffa90e5{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@235e1065{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-14 23:10:50 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4040
2019-10-14 23:10:50 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:34163/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571094650842
2019-10-14 23:10:50 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:34163/files/lenet5.py with timestamp 1571094650895
2019-10-14 23:10:50 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-aafd9425-3a35-4d13-9b64-37624558c6aa/userFiles-d41b2cd4-58db-46a5-89cc-9ab961054241/lenet5.py
2019-10-14 23:10:50 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:34163/files/bigdl-0.8.0-python-api.zip with timestamp 1571094650911
2019-10-14 23:10:50 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-aafd9425-3a35-4d13-9b64-37624558c6aa/userFiles-d41b2cd4-58db-46a5-89cc-9ab961054241/bigdl-0.8.0-python-api.zip
2019-10-14 23:10:51 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-14 23:10:51 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 93 ms (0 ms spent in bootstraps)
2019-10-14 23:10:51 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191014231051-0055
2019-10-14 23:10:51 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191014231051-0055/0 on worker-20191014155229-10.164.0.3-45141 (10.164.0.3:45141) with 1 core(s)
2019-10-14 23:10:51 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191014231051-0055/0 on hostPort 10.164.0.3:45141 with 1 core(s), 1024.0 MB RAM
2019-10-14 23:10:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46219.
2019-10-14 23:10:51 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:46219
2019-10-14 23:10:51 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-14 23:10:51 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191014231051-0055/0 is now RUNNING
2019-10-14 23:10:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 46219, None)
2019-10-14 23:10:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:46219 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 46219, None)
2019-10-14 23:10:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 46219, None)
2019-10-14 23:10:51 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 46219, None)
2019-10-14 23:10:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@500cfdce{/metrics/json,null,AVAILABLE,@Spark}
2019-10-14 23:10:54 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.3:44222) with ID 0
2019-10-14 23:10:54 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-14 23:10:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.3:37501 with 413.9 MB RAM, BlockManagerId(0, 10.164.0.3, 37501, None)
2019-10-14 23:10:54 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-14 23:10:54 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-14 23:10:54 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 18
2019-10-14 23:10:54 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.001
('Extracting', '/tmp/mnist/train-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-14 23:10:56 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-14 23:11:13 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-14 23:11:14 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-14 23:11:14 INFO  DistriOptimizer$:154 - Count dataset
2019-10-14 23:11:14 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.408651582s
2019-10-14 23:11:14 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-14 23:11:14 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-14 23:11:14 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.038615845s
2019-10-14 23:11:15 INFO  DistriOptimizer$:408 - [Epoch 1 128/60000][Iteration 1][Wall Clock 0.723608448s] Trained 128 records in 0.723608448 seconds. Throughput is 176.89125 records/second. Loss is 2.3035877. Sequentialdaab25a8's hyper parameters: Current learning rate is 0.001. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:15 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 2][Wall Clock 1.019035554s] Trained 128 records in 0.295427106 seconds. Throughput is 433.271 records/second. Loss is 2.290421. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.990009990009992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:16 INFO  DistriOptimizer$:408 - [Epoch 1 384/60000][Iteration 3][Wall Clock 1.25893881s] Trained 128 records in 0.239903256 seconds. Throughput is 533.5484 records/second. Loss is 2.291321. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.98003992015968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:16 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 4][Wall Clock 1.506409318s] Trained 128 records in 0.247470508 seconds. Throughput is 517.23334 records/second. Loss is 2.2964625. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.970089730807579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:16 INFO  DistriOptimizer$:408 - [Epoch 1 640/60000][Iteration 5][Wall Clock 1.735614404s] Trained 128 records in 0.229205086 seconds. Throughput is 558.45184 records/second. Loss is 2.2948883. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.9601593625498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:16 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 6][Wall Clock 1.95476522s] Trained 128 records in 0.219150816 seconds. Throughput is 584.0727 records/second. Loss is 2.3065145. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.950248756218907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:17 INFO  DistriOptimizer$:408 - [Epoch 1 896/60000][Iteration 7][Wall Clock 2.143911322s] Trained 128 records in 0.189146102 seconds. Throughput is 676.7255 records/second. Loss is 2.3114605. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.940357852882705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:17 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 8][Wall Clock 2.594581025s] Trained 128 records in 0.450669703 seconds. Throughput is 284.02176 records/second. Loss is 2.299747. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.9304865938431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:17 INFO  DistriOptimizer$:408 - [Epoch 1 1152/60000][Iteration 9][Wall Clock 2.797951651s] Trained 128 records in 0.203370626 seconds. Throughput is 629.39276 records/second. Loss is 2.3123858. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.92063492063492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:17 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 10][Wall Clock 2.97101525s] Trained 128 records in 0.173063599 seconds. Throughput is 739.6125 records/second. Loss is 2.304434. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.91080277502478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:18 INFO  DistriOptimizer$:408 - [Epoch 1 1408/60000][Iteration 11][Wall Clock 3.152341103s] Trained 128 records in 0.181325853 seconds. Throughput is 705.9115 records/second. Loss is 2.3004572. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.900990099009901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:18 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 12][Wall Clock 3.328542566s] Trained 128 records in 0.176201463 seconds. Throughput is 726.44116 records/second. Loss is 2.308224. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.891196834817015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:18 INFO  DistriOptimizer$:408 - [Epoch 1 1664/60000][Iteration 13][Wall Clock 3.519424841s] Trained 128 records in 0.190882275 seconds. Throughput is 670.5704 records/second. Loss is 2.3078945. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.881422924901185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:18 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 14][Wall Clock 3.717250921s] Trained 128 records in 0.19782608 seconds. Throughput is 647.033 records/second. Loss is 2.3108363. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.87166831194472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:18 INFO  DistriOptimizer$:408 - [Epoch 1 1920/60000][Iteration 15][Wall Clock 3.913458791s] Trained 128 records in 0.19620787 seconds. Throughput is 652.3694 records/second. Loss is 2.3048034. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.861932938856016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 16][Wall Clock 4.083362979s] Trained 128 records in 0.169904188 seconds. Throughput is 753.3658 records/second. Loss is 2.3198009. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.852216748768474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2176/60000][Iteration 17][Wall Clock 4.256538651s] Trained 128 records in 0.173175672 seconds. Throughput is 739.1338 records/second. Loss is 2.3082373. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.84251968503937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 18][Wall Clock 4.405704035s] Trained 128 records in 0.149165384 seconds. Throughput is 858.108 records/second. Loss is 2.3068876. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.832841691248771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2432/60000][Iteration 19][Wall Clock 4.547080802s] Trained 128 records in 0.141376767 seconds. Throughput is 905.38214 records/second. Loss is 2.2981074. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.823182711198428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 20][Wall Clock 4.732897848s] Trained 128 records in 0.185817046 seconds. Throughput is 688.8496 records/second. Loss is 2.3031871. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.813542688910698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2688/60000][Iteration 21][Wall Clock 4.899684639s] Trained 128 records in 0.166786791 seconds. Throughput is 767.4469 records/second. Loss is 2.3009396. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.80392156862745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:19 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 22][Wall Clock 5.069046717s] Trained 128 records in 0.169362078 seconds. Throughput is 755.7772 records/second. Loss is 2.3013563. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.794319294809011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:20 INFO  DistriOptimizer$:408 - [Epoch 1 2944/60000][Iteration 23][Wall Clock 5.235829993s] Trained 128 records in 0.166783276 seconds. Throughput is 767.4631 records/second. Loss is 2.2993743. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.784735812133072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:20 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 24][Wall Clock 5.401080972s] Trained 128 records in 0.165250979 seconds. Throughput is 774.5794 records/second. Loss is 2.3027785. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.775171065493646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:20 INFO  DistriOptimizer$:408 - [Epoch 1 3200/60000][Iteration 25][Wall Clock 5.548250014s] Trained 128 records in 0.147169042 seconds. Throughput is 869.74817 records/second. Loss is 2.3067205. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.765625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:20 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 26][Wall Clock 5.732054081s] Trained 128 records in 0.183804067 seconds. Throughput is 696.39374 records/second. Loss is 2.2933056. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.756097560975611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:20 INFO  DistriOptimizer$:408 - [Epoch 1 3456/60000][Iteration 27][Wall Clock 5.888037462s] Trained 128 records in 0.155983381 seconds. Throughput is 820.6002 records/second. Loss is 2.282277. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.746588693957114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:20 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 28][Wall Clock 6.014472761s] Trained 128 records in 0.126435299 seconds. Throughput is 1012.37555 records/second. Loss is 2.290735. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.737098344693283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:21 INFO  DistriOptimizer$:408 - [Epoch 1 3712/60000][Iteration 29][Wall Clock 6.175050861s] Trained 128 records in 0.1605781 seconds. Throughput is 797.1199 records/second. Loss is 2.3097222. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.727626459143969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:21 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 30][Wall Clock 6.340557214s] Trained 128 records in 0.165506353 seconds. Throughput is 773.3842 records/second. Loss is 2.2997427. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.718172983479106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:21 INFO  DistriOptimizer$:408 - [Epoch 1 3968/60000][Iteration 31][Wall Clock 6.486191835s] Trained 128 records in 0.145634621 seconds. Throughput is 878.91187 records/second. Loss is 2.298668. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.70873786407767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:21 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 32][Wall Clock 6.659867416s] Trained 128 records in 0.173675581 seconds. Throughput is 737.0063 records/second. Loss is 2.2929044. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.699321047526674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:21 INFO  DistriOptimizer$:408 - [Epoch 1 4224/60000][Iteration 33][Wall Clock 6.833484862s] Trained 128 records in 0.173617446 seconds. Throughput is 737.25305 records/second. Loss is 2.3045008. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.689922480620155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:21 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 34][Wall Clock 6.993885942s] Trained 128 records in 0.16040108 seconds. Throughput is 797.99963 records/second. Loss is 2.30432. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.680542110358181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 4480/60000][Iteration 35][Wall Clock 7.128684868s] Trained 128 records in 0.134798926 seconds. Throughput is 949.56244 records/second. Loss is 2.2912855. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.671179883945841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 36][Wall Clock 7.278180124s] Trained 128 records in 0.149495256 seconds. Throughput is 856.2144 records/second. Loss is 2.3014212. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.661835748792271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 4736/60000][Iteration 37][Wall Clock 7.428220824s] Trained 128 records in 0.1500407 seconds. Throughput is 853.10187 records/second. Loss is 2.3022175. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.652509652509653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 38][Wall Clock 7.584766712s] Trained 128 records in 0.156545888 seconds. Throughput is 817.6516 records/second. Loss is 2.3045352. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.643201542912248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 4992/60000][Iteration 39][Wall Clock 7.720513229s] Trained 128 records in 0.135746517 seconds. Throughput is 942.9339 records/second. Loss is 2.2825377. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.633911368015414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 40][Wall Clock 7.870705551s] Trained 128 records in 0.150192322 seconds. Throughput is 852.24066 records/second. Loss is 2.2936158. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.624639076034649E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:22 INFO  DistriOptimizer$:408 - [Epoch 1 5248/60000][Iteration 41][Wall Clock 8.027948954s] Trained 128 records in 0.157243403 seconds. Throughput is 814.0246 records/second. Loss is 2.3069296. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.615384615384615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 42][Wall Clock 8.17803763s] Trained 128 records in 0.150088676 seconds. Throughput is 852.8291 records/second. Loss is 2.3027887. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.606147934678195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 5504/60000][Iteration 43][Wall Clock 8.301413075s] Trained 128 records in 0.123375445 seconds. Throughput is 1037.4836 records/second. Loss is 2.304527. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.596928982725527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 44][Wall Clock 8.452023513s] Trained 128 records in 0.150610438 seconds. Throughput is 849.87476 records/second. Loss is 2.2991571. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.587727708533078E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 5760/60000][Iteration 45][Wall Clock 8.582622059s] Trained 128 records in 0.130598546 seconds. Throughput is 980.1028 records/second. Loss is 2.3071437. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.578544061302681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 46][Wall Clock 8.72674375s] Trained 128 records in 0.144121691 seconds. Throughput is 888.13837 records/second. Loss is 2.2989988. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.569377990430623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 6016/60000][Iteration 47][Wall Clock 8.865847666s] Trained 128 records in 0.139103916 seconds. Throughput is 920.17535 records/second. Loss is 2.2983057. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.560229445506692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:23 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 48][Wall Clock 9.004714615s] Trained 128 records in 0.138866949 seconds. Throughput is 921.7456 records/second. Loss is 2.2875037. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.551098376313277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 6272/60000][Iteration 49][Wall Clock 9.140624654s] Trained 128 records in 0.135910039 seconds. Throughput is 941.7995 records/second. Loss is 2.2965317. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.541984732824427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 50][Wall Clock 9.283743686s] Trained 128 records in 0.143119032 seconds. Throughput is 894.3604 records/second. Loss is 2.2969716. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.532888465204958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 6528/60000][Iteration 51][Wall Clock 9.415257784s] Trained 128 records in 0.131514098 seconds. Throughput is 973.27966 records/second. Loss is 2.2971551. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.523809523809524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 52][Wall Clock 9.573310208s] Trained 128 records in 0.158052424 seconds. Throughput is 809.85785 records/second. Loss is 2.29717. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.514747859181732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 6784/60000][Iteration 53][Wall Clock 9.71558098s] Trained 128 records in 0.142270772 seconds. Throughput is 899.6929 records/second. Loss is 2.3056014. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.505703422053232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 54][Wall Clock 9.829486619s] Trained 128 records in 0.113905639 seconds. Throughput is 1123.7372 records/second. Loss is 2.303743. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.49667616334283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:24 INFO  DistriOptimizer$:408 - [Epoch 1 7040/60000][Iteration 55][Wall Clock 9.94848965s] Trained 128 records in 0.119003031 seconds. Throughput is 1075.6029 records/second. Loss is 2.2942736. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.487666034155598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 56][Wall Clock 10.077484317s] Trained 128 records in 0.128994667 seconds. Throughput is 992.28906 records/second. Loss is 2.296339. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.478672985781991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7296/60000][Iteration 57][Wall Clock 10.212148691s] Trained 128 records in 0.134664374 seconds. Throughput is 950.5112 records/second. Loss is 2.3017225. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.46969696969697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 58][Wall Clock 10.329830052s] Trained 128 records in 0.117681361 seconds. Throughput is 1087.6829 records/second. Loss is 2.2947776. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.460737937559131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7552/60000][Iteration 59][Wall Clock 10.44871275s] Trained 128 records in 0.118882698 seconds. Throughput is 1076.6915 records/second. Loss is 2.305937. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.45179584120983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 60][Wall Clock 10.608232451s] Trained 128 records in 0.159519701 seconds. Throughput is 802.4087 records/second. Loss is 2.2993186. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.442870632672333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7808/60000][Iteration 61][Wall Clock 10.744045368s] Trained 128 records in 0.135812917 seconds. Throughput is 942.4729 records/second. Loss is 2.2973857. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.433962264150943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 62][Wall Clock 10.872747617s] Trained 128 records in 0.128702249 seconds. Throughput is 994.5436 records/second. Loss is 2.2900345. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.425070688030161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:25 INFO  DistriOptimizer$:408 - [Epoch 1 8064/60000][Iteration 63][Wall Clock 11.006549363s] Trained 128 records in 0.133801746 seconds. Throughput is 956.6393 records/second. Loss is 2.2968788. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.416195856873823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 64][Wall Clock 11.128220998s] Trained 128 records in 0.121671635 seconds. Throughput is 1052.0118 records/second. Loss is 2.305521. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.407337723424271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8320/60000][Iteration 65][Wall Clock 11.249402634s] Trained 128 records in 0.121181636 seconds. Throughput is 1056.2656 records/second. Loss is 2.298606. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.398496240601503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 66][Wall Clock 11.360631427s] Trained 128 records in 0.111228793 seconds. Throughput is 1150.7811 records/second. Loss is 2.2985315. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.389671361502348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8576/60000][Iteration 67][Wall Clock 11.469122961s] Trained 128 records in 0.108491534 seconds. Throughput is 1179.8156 records/second. Loss is 2.3019526. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.380863039399625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 68][Wall Clock 11.585985733s] Trained 128 records in 0.116862772 seconds. Throughput is 1095.3018 records/second. Loss is 2.2923417. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.372071227741331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8832/60000][Iteration 69][Wall Clock 11.715887302s] Trained 128 records in 0.129901569 seconds. Throughput is 985.36145 records/second. Loss is 2.283038. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.363295880149813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 70][Wall Clock 11.841048859s] Trained 128 records in 0.125161557 seconds. Throughput is 1022.6782 records/second. Loss is 2.2947598. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.354536950420954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:26 INFO  DistriOptimizer$:408 - [Epoch 1 9088/60000][Iteration 71][Wall Clock 11.961539717s] Trained 128 records in 0.120490858 seconds. Throughput is 1062.3213 records/second. Loss is 2.2879398. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.345794392523364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 72][Wall Clock 12.076256449s] Trained 128 records in 0.114716732 seconds. Throughput is 1115.7919 records/second. Loss is 2.2952614. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.337068160597573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9344/60000][Iteration 73][Wall Clock 12.196453834s] Trained 128 records in 0.120197385 seconds. Throughput is 1064.915 records/second. Loss is 2.299521. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.328358208955224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 74][Wall Clock 12.331062157s] Trained 128 records in 0.134608323 seconds. Throughput is 950.907 records/second. Loss is 2.2871912. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.319664492078286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9600/60000][Iteration 75][Wall Clock 12.483083538s] Trained 128 records in 0.152021381 seconds. Throughput is 841.9868 records/second. Loss is 2.2959495. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.31098696461825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 76][Wall Clock 12.615516016s] Trained 128 records in 0.132432478 seconds. Throughput is 966.5303 records/second. Loss is 2.289687. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.302325581395349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9856/60000][Iteration 77][Wall Clock 12.722904346s] Trained 128 records in 0.10738833 seconds. Throughput is 1191.9358 records/second. Loss is 2.2889555. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.293680297397769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 78][Wall Clock 12.862314547s] Trained 128 records in 0.139410201 seconds. Throughput is 918.1538 records/second. Loss is 2.2902825. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.285051067780873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:27 INFO  DistriOptimizer$:408 - [Epoch 1 10112/60000][Iteration 79][Wall Clock 12.987487487s] Trained 128 records in 0.12517294 seconds. Throughput is 1022.5852 records/second. Loss is 2.3025002. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.276437847866418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 80][Wall Clock 13.118018983s] Trained 128 records in 0.130531496 seconds. Throughput is 980.60626 records/second. Loss is 2.2933724. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.267840593141798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 10368/60000][Iteration 81][Wall Clock 13.230684691s] Trained 128 records in 0.112665708 seconds. Throughput is 1136.1044 records/second. Loss is 2.307487. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.259259259259259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 82][Wall Clock 13.356371186s] Trained 128 records in 0.125686495 seconds. Throughput is 1018.4069 records/second. Loss is 2.284806. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.250693802035153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 10624/60000][Iteration 83][Wall Clock 13.515830882s] Trained 128 records in 0.159459696 seconds. Throughput is 802.7107 records/second. Loss is 2.297975. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.242144177449168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 84][Wall Clock 13.6314958s] Trained 128 records in 0.115664918 seconds. Throughput is 1106.6449 records/second. Loss is 2.2818894. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.233610341643583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 10880/60000][Iteration 85][Wall Clock 13.750417687s] Trained 128 records in 0.118921887 seconds. Throughput is 1076.3368 records/second. Loss is 2.2992027. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.225092250922509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 86][Wall Clock 13.869104718s] Trained 128 records in 0.118687031 seconds. Throughput is 1078.4666 records/second. Loss is 2.289238. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.216589861751152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:28 INFO  DistriOptimizer$:408 - [Epoch 1 11136/60000][Iteration 87][Wall Clock 13.98479816s] Trained 128 records in 0.115693442 seconds. Throughput is 1106.3721 records/second. Loss is 2.2929661. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.208103130755064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 88][Wall Clock 14.088144135s] Trained 128 records in 0.103345975 seconds. Throughput is 1238.5581 records/second. Loss is 2.3063447. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.199632014719412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 11392/60000][Iteration 89][Wall Clock 14.19087035s] Trained 128 records in 0.102726215 seconds. Throughput is 1246.0305 records/second. Loss is 2.296794. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.191176470588235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 90][Wall Clock 14.324813216s] Trained 128 records in 0.133942866 seconds. Throughput is 955.6313 records/second. Loss is 2.2940009. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.182736455463729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 11648/60000][Iteration 91][Wall Clock 14.428728495s] Trained 128 records in 0.103915279 seconds. Throughput is 1231.7726 records/second. Loss is 2.295374. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.174311926605504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 92][Wall Clock 14.544308674s] Trained 128 records in 0.115580179 seconds. Throughput is 1107.4563 records/second. Loss is 2.3026774. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.165902841429881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 11904/60000][Iteration 93][Wall Clock 14.648597715s] Trained 128 records in 0.104289041 seconds. Throughput is 1227.3582 records/second. Loss is 2.2873385. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.157509157509158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 94][Wall Clock 14.751634045s] Trained 128 records in 0.10303633 seconds. Throughput is 1242.2803 records/second. Loss is 2.2975535. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.149130832570906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 12160/60000][Iteration 95][Wall Clock 14.859249519s] Trained 128 records in 0.107615474 seconds. Throughput is 1189.42 records/second. Loss is 2.2949975. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.140767824497258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:29 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 96][Wall Clock 14.968820516s] Trained 128 records in 0.109570997 seconds. Throughput is 1168.1924 records/second. Loss is 2.3012307. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.132420091324202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 12416/60000][Iteration 97][Wall Clock 15.101137268s] Trained 128 records in 0.132316752 seconds. Throughput is 967.3756 records/second. Loss is 2.283269. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.124087591240876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 98][Wall Clock 15.241008674s] Trained 128 records in 0.139871406 seconds. Throughput is 915.1263 records/second. Loss is 2.290451. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.11577028258888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 12672/60000][Iteration 99][Wall Clock 15.363561397s] Trained 128 records in 0.122552723 seconds. Throughput is 1044.4485 records/second. Loss is 2.286391. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.107468123861566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 100][Wall Clock 15.476281258s] Trained 128 records in 0.112719861 seconds. Throughput is 1135.5585 records/second. Loss is 2.2886248. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.099181073703367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 12928/60000][Iteration 101][Wall Clock 15.579632895s] Trained 128 records in 0.103351637 seconds. Throughput is 1238.4902 records/second. Loss is 2.290345. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.090909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 102][Wall Clock 15.68948428s] Trained 128 records in 0.109851385 seconds. Throughput is 1165.2107 records/second. Loss is 2.2861588. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.082652134423252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 13184/60000][Iteration 103][Wall Clock 15.795486954s] Trained 128 records in 0.106002674 seconds. Throughput is 1207.5167 records/second. Loss is 2.2766373. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.074410163339383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:30 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 104][Wall Clock 15.910612807s] Trained 128 records in 0.115125853 seconds. Throughput is 1111.8268 records/second. Loss is 2.2905946. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.066183136899365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 13440/60000][Iteration 105][Wall Clock 16.022366202s] Trained 128 records in 0.111753395 seconds. Throughput is 1145.379 records/second. Loss is 2.2978992. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.057971014492753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 106][Wall Clock 16.13520194s] Trained 128 records in 0.112835738 seconds. Throughput is 1134.3925 records/second. Loss is 2.2854364. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.049773755656109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 13696/60000][Iteration 107][Wall Clock 16.251303529s] Trained 128 records in 0.116101589 seconds. Throughput is 1102.4828 records/second. Loss is 2.2877142. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.041591320072332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 108][Wall Clock 16.362770993s] Trained 128 records in 0.111467464 seconds. Throughput is 1148.3171 records/second. Loss is 2.2972739. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.03342366757001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 13952/60000][Iteration 109][Wall Clock 16.476613033s] Trained 128 records in 0.11384204 seconds. Throughput is 1124.365 records/second. Loss is 2.2925785. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.025270758122743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 110][Wall Clock 16.586433461s] Trained 128 records in 0.109820428 seconds. Throughput is 1165.5391 records/second. Loss is 2.3014634. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.017132551848513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 14208/60000][Iteration 111][Wall Clock 16.698004536s] Trained 128 records in 0.111571075 seconds. Throughput is 1147.2507 records/second. Loss is 2.2888675. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.009009009009008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 112][Wall Clock 16.819666435s] Trained 128 records in 0.121661899 seconds. Throughput is 1052.096 records/second. Loss is 2.3059955. Sequentialdaab25a8's hyper parameters: Current learning rate is 9.000900090009002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:31 INFO  DistriOptimizer$:408 - [Epoch 1 14464/60000][Iteration 113][Wall Clock 16.932593584s] Trained 128 records in 0.112927149 seconds. Throughput is 1133.4741 records/second. Loss is 2.292019. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.992805755395683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 114][Wall Clock 17.038055692s] Trained 128 records in 0.105462108 seconds. Throughput is 1213.706 records/second. Loss is 2.307141. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.984725965858042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 14720/60000][Iteration 115][Wall Clock 17.191688182s] Trained 128 records in 0.15363249 seconds. Throughput is 833.1571 records/second. Loss is 2.2975545. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.976660682226211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 116][Wall Clock 17.306327443s] Trained 128 records in 0.114639261 seconds. Throughput is 1116.5459 records/second. Loss is 2.285663. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.968609865470852E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 14976/60000][Iteration 117][Wall Clock 17.430805608s] Trained 128 records in 0.124478165 seconds. Throughput is 1028.2928 records/second. Loss is 2.2881117. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.960573476702508E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 118][Wall Clock 17.537298475s] Trained 128 records in 0.106492867 seconds. Throughput is 1201.9584 records/second. Loss is 2.2944503. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.952551477170994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 15232/60000][Iteration 119][Wall Clock 17.645022025s] Trained 128 records in 0.10772355 seconds. Throughput is 1188.2267 records/second. Loss is 2.297668. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.944543828264757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 120][Wall Clock 17.762614886s] Trained 128 records in 0.117592861 seconds. Throughput is 1088.5015 records/second. Loss is 2.2940881. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.936550491510277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 15488/60000][Iteration 121][Wall Clock 17.881253104s] Trained 128 records in 0.118638218 seconds. Throughput is 1078.9104 records/second. Loss is 2.2914875. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.928571428571428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:32 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 122][Wall Clock 17.996707134s] Trained 128 records in 0.11545403 seconds. Throughput is 1108.6664 records/second. Loss is 2.298948. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.920606601248885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 15744/60000][Iteration 123][Wall Clock 18.105690478s] Trained 128 records in 0.108983344 seconds. Throughput is 1174.4913 records/second. Loss is 2.3001347. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.912655971479501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 124][Wall Clock 18.259484679s] Trained 128 records in 0.153794201 seconds. Throughput is 832.28107 records/second. Loss is 2.2984164. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.904719501335708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 16000/60000][Iteration 125][Wall Clock 18.376639105s] Trained 128 records in 0.117154426 seconds. Throughput is 1092.5751 records/second. Loss is 2.295446. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.896797153024911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 126][Wall Clock 18.493647903s] Trained 128 records in 0.117008798 seconds. Throughput is 1093.9348 records/second. Loss is 2.2853627. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.888888888888889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 16256/60000][Iteration 127][Wall Clock 18.60867256s] Trained 128 records in 0.115024657 seconds. Throughput is 1112.8049 records/second. Loss is 2.285386. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.880994671403199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 128][Wall Clock 18.735786524s] Trained 128 records in 0.127113964 seconds. Throughput is 1006.9704 records/second. Loss is 2.2971976. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.873114463176575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 16512/60000][Iteration 129][Wall Clock 18.839074221s] Trained 128 records in 0.103287697 seconds. Throughput is 1239.257 records/second. Loss is 2.2994633. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.865248226950354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:33 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 130][Wall Clock 18.939056643s] Trained 128 records in 0.099982422 seconds. Throughput is 1280.225 records/second. Loss is 2.2920687. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.857395925597874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 16768/60000][Iteration 131][Wall Clock 19.03980913s] Trained 128 records in 0.100752487 seconds. Throughput is 1270.4401 records/second. Loss is 2.2900827. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.849557522123895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 132][Wall Clock 19.138407448s] Trained 128 records in 0.098598318 seconds. Throughput is 1298.1967 records/second. Loss is 2.3072426. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.841732979664015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17024/60000][Iteration 133][Wall Clock 19.244006309s] Trained 128 records in 0.105598861 seconds. Throughput is 1212.1343 records/second. Loss is 2.2837489. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.833922261484098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 134][Wall Clock 19.390637379s] Trained 128 records in 0.14663107 seconds. Throughput is 872.9391 records/second. Loss is 2.2942915. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.8261253309797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17280/60000][Iteration 135][Wall Clock 19.492215454s] Trained 128 records in 0.101578075 seconds. Throughput is 1260.1145 records/second. Loss is 2.3016293. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.818342151675486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 136][Wall Clock 19.604214924s] Trained 128 records in 0.11199947 seconds. Throughput is 1142.8625 records/second. Loss is 2.2946908. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.81057268722467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17536/60000][Iteration 137][Wall Clock 19.712048996s] Trained 128 records in 0.107834072 seconds. Throughput is 1187.0089 records/second. Loss is 2.301483. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.80281690140845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 138][Wall Clock 19.811114489s] Trained 128 records in 0.099065493 seconds. Throughput is 1292.0746 records/second. Loss is 2.2945082. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.795074758135445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:34 INFO  DistriOptimizer$:408 - [Epoch 1 17792/60000][Iteration 139][Wall Clock 19.939934514s] Trained 128 records in 0.128820025 seconds. Throughput is 993.6343 records/second. Loss is 2.2981386. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.787346221441125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 140][Wall Clock 20.060450799s] Trained 128 records in 0.120516285 seconds. Throughput is 1062.0972 records/second. Loss is 2.2894804. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.77963125548727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18048/60000][Iteration 141][Wall Clock 20.164752519s] Trained 128 records in 0.10430172 seconds. Throughput is 1227.2089 records/second. Loss is 2.289443. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.771929824561403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 142][Wall Clock 20.26521364s] Trained 128 records in 0.100461121 seconds. Throughput is 1274.1248 records/second. Loss is 2.2834623. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.764241893076249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18304/60000][Iteration 143][Wall Clock 20.363250193s] Trained 128 records in 0.098036553 seconds. Throughput is 1305.6355 records/second. Loss is 2.3066528. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.756567425569178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 144][Wall Clock 20.474215489s] Trained 128 records in 0.110965296 seconds. Throughput is 1153.5138 records/second. Loss is 2.2984538. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.748906386701663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18560/60000][Iteration 145][Wall Clock 20.598901008s] Trained 128 records in 0.124685519 seconds. Throughput is 1026.5828 records/second. Loss is 2.2929227. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.74125874125874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 146][Wall Clock 20.72567685s] Trained 128 records in 0.126775842 seconds. Throughput is 1009.65607 records/second. Loss is 2.2918563. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.733624454148472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18816/60000][Iteration 147][Wall Clock 20.827946397s] Trained 128 records in 0.102269547 seconds. Throughput is 1251.5945 records/second. Loss is 2.2951667. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.726003490401397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:35 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 148][Wall Clock 20.932084959s] Trained 128 records in 0.104138562 seconds. Throughput is 1229.1316 records/second. Loss is 2.2878156. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.718395815170009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19072/60000][Iteration 149][Wall Clock 21.035444988s] Trained 128 records in 0.103360029 seconds. Throughput is 1238.3898 records/second. Loss is 2.2868087. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.710801393728224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 150][Wall Clock 21.13777574s] Trained 128 records in 0.102330752 seconds. Throughput is 1250.846 records/second. Loss is 2.2849503. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.703220191470844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19328/60000][Iteration 151][Wall Clock 21.238904047s] Trained 128 records in 0.101128307 seconds. Throughput is 1265.7188 records/second. Loss is 2.2804358. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.695652173913044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 152][Wall Clock 21.340213391s] Trained 128 records in 0.101309344 seconds. Throughput is 1263.457 records/second. Loss is 2.2910924. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.688097306689834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19584/60000][Iteration 153][Wall Clock 21.447959515s] Trained 128 records in 0.107746124 seconds. Throughput is 1187.9778 records/second. Loss is 2.2862885. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.680555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 154][Wall Clock 21.547114591s] Trained 128 records in 0.099155076 seconds. Throughput is 1290.9072 records/second. Loss is 2.3020384. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.673026886383347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19840/60000][Iteration 155][Wall Clock 21.671405097s] Trained 128 records in 0.124290506 seconds. Throughput is 1029.8453 records/second. Loss is 2.2813146. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.665511265164645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 156][Wall Clock 21.769879529s] Trained 128 records in 0.098474432 seconds. Throughput is 1299.8297 records/second. Loss is 2.28467. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.658008658008658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 20096/60000][Iteration 157][Wall Clock 21.880251197s] Trained 128 records in 0.110371668 seconds. Throughput is 1159.7179 records/second. Loss is 2.2877965. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.65051903114187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:36 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 158][Wall Clock 21.977841983s] Trained 128 records in 0.097590786 seconds. Throughput is 1311.5992 records/second. Loss is 2.286303. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.64304235090752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 20352/60000][Iteration 159][Wall Clock 22.073017318s] Trained 128 records in 0.095175335 seconds. Throughput is 1344.8862 records/second. Loss is 2.279345. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.635578583765113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 160][Wall Clock 22.182861978s] Trained 128 records in 0.10984466 seconds. Throughput is 1165.282 records/second. Loss is 2.295422. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.628127696289905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 20608/60000][Iteration 161][Wall Clock 22.282313017s] Trained 128 records in 0.099451039 seconds. Throughput is 1287.0654 records/second. Loss is 2.2975805. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.620689655172415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 162][Wall Clock 22.385488365s] Trained 128 records in 0.103175348 seconds. Throughput is 1240.6064 records/second. Loss is 2.28415. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.613264427217916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 20864/60000][Iteration 163][Wall Clock 22.480551528s] Trained 128 records in 0.095063163 seconds. Throughput is 1346.4731 records/second. Loss is 2.2966442. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.605851979345956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 164][Wall Clock 22.576312663s] Trained 128 records in 0.095761135 seconds. Throughput is 1336.6592 records/second. Loss is 2.2845113. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.598452278589854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 21120/60000][Iteration 165][Wall Clock 22.676406988s] Trained 128 records in 0.100094325 seconds. Throughput is 1278.7938 records/second. Loss is 2.293869. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.591065292096221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 166][Wall Clock 22.793531971s] Trained 128 records in 0.117124983 seconds. Throughput is 1092.8497 records/second. Loss is 2.2954893. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.583690987124463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:37 INFO  DistriOptimizer$:408 - [Epoch 1 21376/60000][Iteration 167][Wall Clock 22.89363012s] Trained 128 records in 0.100098149 seconds. Throughput is 1278.745 records/second. Loss is 2.2867758. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.576329331046313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 168][Wall Clock 23.021373809s] Trained 128 records in 0.127743689 seconds. Throughput is 1002.0064 records/second. Loss is 2.2928514. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.568980291345329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 21632/60000][Iteration 169][Wall Clock 23.12687772s] Trained 128 records in 0.105503911 seconds. Throughput is 1213.2252 records/second. Loss is 2.2871375. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.561643835616439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 170][Wall Clock 23.224277992s] Trained 128 records in 0.097400272 seconds. Throughput is 1314.1647 records/second. Loss is 2.2820652. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.55431993156544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 21888/60000][Iteration 171][Wall Clock 23.328474694s] Trained 128 records in 0.104196702 seconds. Throughput is 1228.4458 records/second. Loss is 2.2904754. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.547008547008548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 172][Wall Clock 23.455232436s] Trained 128 records in 0.126757742 seconds. Throughput is 1009.80023 records/second. Loss is 2.2979584. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.539709649871904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 22144/60000][Iteration 173][Wall Clock 23.558038596s] Trained 128 records in 0.10280616 seconds. Throughput is 1245.0616 records/second. Loss is 2.2854908. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.532423208191127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 174][Wall Clock 23.660968861s] Trained 128 records in 0.102930265 seconds. Throughput is 1243.5604 records/second. Loss is 2.2889807. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.525149190110827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 22400/60000][Iteration 175][Wall Clock 23.772515245s] Trained 128 records in 0.111546384 seconds. Throughput is 1147.5048 records/second. Loss is 2.2929683. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.517887563884158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 176][Wall Clock 23.867383334s] Trained 128 records in 0.094868089 seconds. Throughput is 1349.242 records/second. Loss is 2.2819822. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.51063829787234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:38 INFO  DistriOptimizer$:408 - [Epoch 1 22656/60000][Iteration 177][Wall Clock 23.96003393s] Trained 128 records in 0.092650596 seconds. Throughput is 1381.5347 records/second. Loss is 2.2933366. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.503401360544218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 178][Wall Clock 24.089319375s] Trained 128 records in 0.129285445 seconds. Throughput is 990.0574 records/second. Loss is 2.2900178. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.496176720475786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 22912/60000][Iteration 179][Wall Clock 24.221439114s] Trained 128 records in 0.132119739 seconds. Throughput is 968.8181 records/second. Loss is 2.2898629. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.488964346349746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 180][Wall Clock 24.331477809s] Trained 128 records in 0.110038695 seconds. Throughput is 1163.2272 records/second. Loss is 2.2895098. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.481764206955047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 23168/60000][Iteration 181][Wall Clock 24.431549267s] Trained 128 records in 0.100071458 seconds. Throughput is 1279.0859 records/second. Loss is 2.2869947. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.474576271186442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 182][Wall Clock 24.531981297s] Trained 128 records in 0.10043203 seconds. Throughput is 1274.4938 records/second. Loss is 2.2802794. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.46740050804403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 23424/60000][Iteration 183][Wall Clock 24.637782203s] Trained 128 records in 0.105800906 seconds. Throughput is 1209.8196 records/second. Loss is 2.2959955. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.460236886632827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 184][Wall Clock 24.751979581s] Trained 128 records in 0.114197378 seconds. Throughput is 1120.8663 records/second. Loss is 2.2845197. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.453085376162299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:39 INFO  DistriOptimizer$:408 - [Epoch 1 23680/60000][Iteration 185][Wall Clock 24.85473526s] Trained 128 records in 0.102755679 seconds. Throughput is 1245.6732 records/second. Loss is 2.2859488. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.445945945945946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 186][Wall Clock 24.961715668s] Trained 128 records in 0.106980408 seconds. Throughput is 1196.4808 records/second. Loss is 2.2788672. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.438818565400844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 23936/60000][Iteration 187][Wall Clock 25.0619001s] Trained 128 records in 0.100184432 seconds. Throughput is 1277.6436 records/second. Loss is 2.2947311. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.431703204047218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 188][Wall Clock 25.163678555s] Trained 128 records in 0.101778455 seconds. Throughput is 1257.6335 records/second. Loss is 2.282272. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.424599831508003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24192/60000][Iteration 189][Wall Clock 25.263307016s] Trained 128 records in 0.099628461 seconds. Throughput is 1284.7734 records/second. Loss is 2.2991676. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.417508417508418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 190][Wall Clock 25.378454165s] Trained 128 records in 0.115147149 seconds. Throughput is 1111.6211 records/second. Loss is 2.2936575. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.410428931875525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24448/60000][Iteration 191][Wall Clock 25.488897814s] Trained 128 records in 0.110443649 seconds. Throughput is 1158.962 records/second. Loss is 2.2784903. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.403361344537816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 192][Wall Clock 25.628288642s] Trained 128 records in 0.139390828 seconds. Throughput is 918.2814 records/second. Loss is 2.2817044. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.396305625524769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24704/60000][Iteration 193][Wall Clock 25.726410019s] Trained 128 records in 0.098121377 seconds. Throughput is 1304.5068 records/second. Loss is 2.2875013. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.389261744966444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 194][Wall Clock 25.820867377s] Trained 128 records in 0.094457358 seconds. Throughput is 1355.1089 records/second. Loss is 2.275896. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.382229673093043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:40 INFO  DistriOptimizer$:408 - [Epoch 1 24960/60000][Iteration 195][Wall Clock 25.928749238s] Trained 128 records in 0.107881861 seconds. Throughput is 1186.483 records/second. Loss is 2.280805. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.375209380234506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 196][Wall Clock 26.023714327s] Trained 128 records in 0.094965089 seconds. Throughput is 1347.8638 records/second. Loss is 2.2787325. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.368200836820083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25216/60000][Iteration 197][Wall Clock 26.114458916s] Trained 128 records in 0.090744589 seconds. Throughput is 1410.5524 records/second. Loss is 2.2891037. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.361204013377927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 198][Wall Clock 26.217057033s] Trained 128 records in 0.102598117 seconds. Throughput is 1247.5863 records/second. Loss is 2.2807012. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.35421888053467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25472/60000][Iteration 199][Wall Clock 26.320571439s] Trained 128 records in 0.103514406 seconds. Throughput is 1236.5428 records/second. Loss is 2.279362. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.347245409015025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 200][Wall Clock 26.418526154s] Trained 128 records in 0.097954715 seconds. Throughput is 1306.7263 records/second. Loss is 2.297934. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.340283569641367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25728/60000][Iteration 201][Wall Clock 26.519941009s] Trained 128 records in 0.101414855 seconds. Throughput is 1262.1426 records/second. Loss is 2.2780719. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 202][Wall Clock 26.618524869s] Trained 128 records in 0.09858386 seconds. Throughput is 1298.387 records/second. Loss is 2.281463. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.326394671107411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 25984/60000][Iteration 203][Wall Clock 26.758344134s] Trained 128 records in 0.139819265 seconds. Throughput is 915.4675 records/second. Loss is 2.2819831. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.319467554076539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:41 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 204][Wall Clock 26.858279718s] Trained 128 records in 0.099935584 seconds. Throughput is 1280.8251 records/second. Loss is 2.2875705. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.312551953449709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 26240/60000][Iteration 205][Wall Clock 26.955250135s] Trained 128 records in 0.096970417 seconds. Throughput is 1319.9902 records/second. Loss is 2.2856705. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.305647840531562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 206][Wall Clock 27.049662927s] Trained 128 records in 0.094412792 seconds. Throughput is 1355.7485 records/second. Loss is 2.2859924. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.298755186721991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 26496/60000][Iteration 207][Wall Clock 27.148089013s] Trained 128 records in 0.098426086 seconds. Throughput is 1300.4683 records/second. Loss is 2.2837396. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.291873963515755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 208][Wall Clock 27.244259268s] Trained 128 records in 0.096170255 seconds. Throughput is 1330.9729 records/second. Loss is 2.2840042. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.285004142502071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 26752/60000][Iteration 209][Wall Clock 27.348939767s] Trained 128 records in 0.104680499 seconds. Throughput is 1222.7683 records/second. Loss is 2.293449. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.278145695364238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 210][Wall Clock 27.443690141s] Trained 128 records in 0.094750374 seconds. Throughput is 1350.9181 records/second. Loss is 2.2840617. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.271298593879239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 27008/60000][Iteration 211][Wall Clock 27.540567619s] Trained 128 records in 0.096877478 seconds. Throughput is 1321.2565 records/second. Loss is 2.287617. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.264462809917356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 212][Wall Clock 27.659753659s] Trained 128 records in 0.11918604 seconds. Throughput is 1073.9513 records/second. Loss is 2.2853286. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.257638315441783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 27264/60000][Iteration 213][Wall Clock 27.777225701s] Trained 128 records in 0.117472042 seconds. Throughput is 1089.621 records/second. Loss is 2.2834172. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.250825082508251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:42 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 214][Wall Clock 27.872236509s] Trained 128 records in 0.095010808 seconds. Throughput is 1347.2151 records/second. Loss is 2.28913. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.244023083264633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 27520/60000][Iteration 215][Wall Clock 27.972040196s] Trained 128 records in 0.099803687 seconds. Throughput is 1282.5177 records/second. Loss is 2.2947567. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.237232289950577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 216][Wall Clock 28.075332789s] Trained 128 records in 0.103292593 seconds. Throughput is 1239.1982 records/second. Loss is 2.2893417. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.230452674897119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 27776/60000][Iteration 217][Wall Clock 28.168481168s] Trained 128 records in 0.093148379 seconds. Throughput is 1374.1516 records/second. Loss is 2.2819. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.223684210526316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 218][Wall Clock 28.271525954s] Trained 128 records in 0.103044786 seconds. Throughput is 1242.1783 records/second. Loss is 2.2888372. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.216926869350862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 28032/60000][Iteration 219][Wall Clock 28.371085971s] Trained 128 records in 0.099560017 seconds. Throughput is 1285.6567 records/second. Loss is 2.283163. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.210180623973728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 220][Wall Clock 28.472082053s] Trained 128 records in 0.100996082 seconds. Throughput is 1267.3759 records/second. Loss is 2.2824953. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.203445447087776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 28288/60000][Iteration 221][Wall Clock 28.580076509s] Trained 128 records in 0.107994456 seconds. Throughput is 1185.246 records/second. Loss is 2.2770567. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.19672131147541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 222][Wall Clock 28.677133218s] Trained 128 records in 0.097056709 seconds. Throughput is 1318.8167 records/second. Loss is 2.2864559. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.190008190008189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 28544/60000][Iteration 223][Wall Clock 28.772521028s] Trained 128 records in 0.09538781 seconds. Throughput is 1341.8905 records/second. Loss is 2.2798147. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.183306055646482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:43 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 224][Wall Clock 28.867944629s] Trained 128 records in 0.095423601 seconds. Throughput is 1341.3872 records/second. Loss is 2.291215. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.176614881439083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 28800/60000][Iteration 225][Wall Clock 28.965247343s] Trained 128 records in 0.097302714 seconds. Throughput is 1315.4823 records/second. Loss is 2.2729263. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.169934640522876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 226][Wall Clock 29.064335766s] Trained 128 records in 0.099088423 seconds. Throughput is 1291.7755 records/second. Loss is 2.288364. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.163265306122448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29056/60000][Iteration 227][Wall Clock 29.157490487s] Trained 128 records in 0.093154721 seconds. Throughput is 1374.0581 records/second. Loss is 2.286677. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.156606851549756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 228][Wall Clock 29.258598894s] Trained 128 records in 0.101108407 seconds. Throughput is 1265.9679 records/second. Loss is 2.291052. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.149959250203749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29312/60000][Iteration 229][Wall Clock 29.383128331s] Trained 128 records in 0.124529437 seconds. Throughput is 1027.8694 records/second. Loss is 2.295571. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.143322475570033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 230][Wall Clock 29.471952864s] Trained 128 records in 0.088824533 seconds. Throughput is 1441.0433 records/second. Loss is 2.2902305. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.136696501220504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29568/60000][Iteration 231][Wall Clock 29.569917591s] Trained 128 records in 0.097964727 seconds. Throughput is 1306.5928 records/second. Loss is 2.28459. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.130081300813008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 232][Wall Clock 29.658378473s] Trained 128 records in 0.088460882 seconds. Throughput is 1446.9672 records/second. Loss is 2.2776053. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.123476848090983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29824/60000][Iteration 233][Wall Clock 29.760167194s] Trained 128 records in 0.101788721 seconds. Throughput is 1257.5067 records/second. Loss is 2.2747781. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.116883116883117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:44 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 234][Wall Clock 29.856117909s] Trained 128 records in 0.095950715 seconds. Throughput is 1334.0182 records/second. Loss is 2.2835906. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.110300081103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30080/60000][Iteration 235][Wall Clock 29.960790606s] Trained 128 records in 0.104672697 seconds. Throughput is 1222.8595 records/second. Loss is 2.281187. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.103727714748785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 236][Wall Clock 30.067479904s] Trained 128 records in 0.106689298 seconds. Throughput is 1199.7455 records/second. Loss is 2.2865696. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.097165991902834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30336/60000][Iteration 237][Wall Clock 30.158618402s] Trained 128 records in 0.091138498 seconds. Throughput is 1404.4559 records/second. Loss is 2.272185. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.090614886731392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 238][Wall Clock 30.259367331s] Trained 128 records in 0.100748929 seconds. Throughput is 1270.485 records/second. Loss is 2.2900512. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.084074373484236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30592/60000][Iteration 239][Wall Clock 30.359972855s] Trained 128 records in 0.100605524 seconds. Throughput is 1272.2959 records/second. Loss is 2.28532. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.077544426494346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 240][Wall Clock 30.461804936s] Trained 128 records in 0.101832081 seconds. Throughput is 1256.9712 records/second. Loss is 2.2783542. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.071025020177562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30848/60000][Iteration 241][Wall Clock 30.566634153s] Trained 128 records in 0.104829217 seconds. Throughput is 1221.0337 records/second. Loss is 2.2860053. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.064516129032258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 242][Wall Clock 30.681586646s] Trained 128 records in 0.114952493 seconds. Throughput is 1113.5035 records/second. Loss is 2.2854724. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.058017727639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:45 INFO  DistriOptimizer$:408 - [Epoch 1 31104/60000][Iteration 243][Wall Clock 30.806156083s] Trained 128 records in 0.124569437 seconds. Throughput is 1027.5393 records/second. Loss is 2.290691. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.051529790660225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 244][Wall Clock 30.928999986s] Trained 128 records in 0.122843903 seconds. Throughput is 1041.9728 records/second. Loss is 2.2857518. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.045052292839904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 31360/60000][Iteration 245][Wall Clock 31.058158439s] Trained 128 records in 0.129158453 seconds. Throughput is 991.03076 records/second. Loss is 2.284039. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.038585209003215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 246][Wall Clock 31.182693721s] Trained 128 records in 0.124535282 seconds. Throughput is 1027.8212 records/second. Loss is 2.2882156. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.032128514056224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 31616/60000][Iteration 247][Wall Clock 31.279573945s] Trained 128 records in 0.096880224 seconds. Throughput is 1321.219 records/second. Loss is 2.2904544. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.025682182985554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 248][Wall Clock 31.386378933s] Trained 128 records in 0.106804988 seconds. Throughput is 1198.4459 records/second. Loss is 2.2812133. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.01924619085806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 31872/60000][Iteration 249][Wall Clock 31.499971898s] Trained 128 records in 0.113592965 seconds. Throughput is 1126.8303 records/second. Loss is 2.2753131. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.012820512820513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 250][Wall Clock 31.61125835s] Trained 128 records in 0.111286452 seconds. Throughput is 1150.1849 records/second. Loss is 2.2695854. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.006405124099279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 32128/60000][Iteration 251][Wall Clock 31.731752543s] Trained 128 records in 0.120494193 seconds. Throughput is 1062.2919 records/second. Loss is 2.2821193. Sequentialdaab25a8's hyper parameters: Current learning rate is 8.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:46 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 252][Wall Clock 31.846347131s] Trained 128 records in 0.114594588 seconds. Throughput is 1116.9812 records/second. Loss is 2.2805283. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.993605115907275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 32384/60000][Iteration 253][Wall Clock 31.943432867s] Trained 128 records in 0.097085736 seconds. Throughput is 1318.4222 records/second. Loss is 2.278128. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.987220447284345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 254][Wall Clock 32.043008847s] Trained 128 records in 0.09957598 seconds. Throughput is 1285.4506 records/second. Loss is 2.2844777. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.980845969672785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 32640/60000][Iteration 255][Wall Clock 32.150755604s] Trained 128 records in 0.107746757 seconds. Throughput is 1187.9708 records/second. Loss is 2.282035. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.974481658692185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 256][Wall Clock 32.269631332s] Trained 128 records in 0.118875728 seconds. Throughput is 1076.7548 records/second. Loss is 2.284653. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.968127490039842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 32896/60000][Iteration 257][Wall Clock 32.362830959s] Trained 128 records in 0.093199627 seconds. Throughput is 1373.3961 records/second. Loss is 2.2841501. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.961783439490446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 258][Wall Clock 32.454660652s] Trained 128 records in 0.091829693 seconds. Throughput is 1393.8846 records/second. Loss is 2.289999. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.955449482895783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 33152/60000][Iteration 259][Wall Clock 32.54522309s] Trained 128 records in 0.090562438 seconds. Throughput is 1413.3895 records/second. Loss is 2.2863255. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.94912559618442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 260][Wall Clock 32.64103371s] Trained 128 records in 0.09581062 seconds. Throughput is 1335.9688 records/second. Loss is 2.2887416. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.942811755361399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 33408/60000][Iteration 261][Wall Clock 32.740875194s] Trained 128 records in 0.099841484 seconds. Throughput is 1282.0322 records/second. Loss is 2.2879603. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.936507936507937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:47 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 262][Wall Clock 32.837886927s] Trained 128 records in 0.097011733 seconds. Throughput is 1319.4281 records/second. Loss is 2.2819965. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.930214115781125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 33664/60000][Iteration 263][Wall Clock 32.927473658s] Trained 128 records in 0.089586731 seconds. Throughput is 1428.7831 records/second. Loss is 2.2778432. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.92393026941363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 264][Wall Clock 33.042906284s] Trained 128 records in 0.115432626 seconds. Throughput is 1108.872 records/second. Loss is 2.271175. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.917656373713382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 33920/60000][Iteration 265][Wall Clock 33.147403188s] Trained 128 records in 0.104496904 seconds. Throughput is 1224.9166 records/second. Loss is 2.2782965. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.911392405063291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 266][Wall Clock 33.247792297s] Trained 128 records in 0.100389109 seconds. Throughput is 1275.0387 records/second. Loss is 2.2759132. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.905138339920949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34176/60000][Iteration 267][Wall Clock 33.342357339s] Trained 128 records in 0.094565042 seconds. Throughput is 1353.5658 records/second. Loss is 2.2815647. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.898894154818325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 268][Wall Clock 33.466005332s] Trained 128 records in 0.123647993 seconds. Throughput is 1035.1968 records/second. Loss is 2.2888002. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.892659826361485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34432/60000][Iteration 269][Wall Clock 33.568507859s] Trained 128 records in 0.102502527 seconds. Throughput is 1248.7498 records/second. Loss is 2.2911217. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.886435331230284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 270][Wall Clock 33.658476382s] Trained 128 records in 0.089968523 seconds. Throughput is 1422.7197 records/second. Loss is 2.2796803. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.880220646178092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34688/60000][Iteration 271][Wall Clock 33.753141652s] Trained 128 records in 0.09466527 seconds. Throughput is 1352.1327 records/second. Loss is 2.2843626. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.874015748031496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:48 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 272][Wall Clock 33.867399341s] Trained 128 records in 0.114257689 seconds. Throughput is 1120.2748 records/second. Loss is 2.286244. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.867820613690009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 34944/60000][Iteration 273][Wall Clock 33.958306325s] Trained 128 records in 0.090906984 seconds. Throughput is 1408.0326 records/second. Loss is 2.2852511. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.861635220125787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 274][Wall Clock 34.082363473s] Trained 128 records in 0.124057148 seconds. Throughput is 1031.7825 records/second. Loss is 2.2743688. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.855459544383346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35200/60000][Iteration 275][Wall Clock 34.181520483s] Trained 128 records in 0.09915701 seconds. Throughput is 1290.882 records/second. Loss is 2.275387. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.849293563579278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 276][Wall Clock 34.295561099s] Trained 128 records in 0.114040616 seconds. Throughput is 1122.4071 records/second. Loss is 2.2766662. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.843137254901962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35456/60000][Iteration 277][Wall Clock 34.41028879s] Trained 128 records in 0.114727691 seconds. Throughput is 1115.6853 records/second. Loss is 2.2786114. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.836990595611285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 278][Wall Clock 34.526426229s] Trained 128 records in 0.116137439 seconds. Throughput is 1102.1425 records/second. Loss is 2.281879. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.83085356303837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35712/60000][Iteration 279][Wall Clock 34.640446548s] Trained 128 records in 0.114020319 seconds. Throughput is 1122.6069 records/second. Loss is 2.2796583. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.82472613458529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 280][Wall Clock 34.736418074s] Trained 128 records in 0.095971526 seconds. Throughput is 1333.7289 records/second. Loss is 2.285709. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.818608287724786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:49 INFO  DistriOptimizer$:408 - [Epoch 1 35968/60000][Iteration 281][Wall Clock 34.826886448s] Trained 128 records in 0.090468374 seconds. Throughput is 1414.859 records/second. Loss is 2.2848163. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.8125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 282][Wall Clock 34.916935049s] Trained 128 records in 0.090048601 seconds. Throughput is 1421.4546 records/second. Loss is 2.2887688. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.806401249024199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36224/60000][Iteration 283][Wall Clock 35.009865248s] Trained 128 records in 0.092930199 seconds. Throughput is 1377.3779 records/second. Loss is 2.2845914. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.8003120124805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 284][Wall Clock 35.104398385s] Trained 128 records in 0.094533137 seconds. Throughput is 1354.0226 records/second. Loss is 2.2862856. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.79423226812159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36480/60000][Iteration 285][Wall Clock 35.220253873s] Trained 128 records in 0.115855488 seconds. Throughput is 1104.8247 records/second. Loss is 2.2760022. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.78816199376947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 286][Wall Clock 35.315597075s] Trained 128 records in 0.095343202 seconds. Throughput is 1342.5183 records/second. Loss is 2.2860763. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.782101167315175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36736/60000][Iteration 287][Wall Clock 35.415373302s] Trained 128 records in 0.099776227 seconds. Throughput is 1282.8707 records/second. Loss is 2.2650614. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.776049766718507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 288][Wall Clock 35.512004417s] Trained 128 records in 0.096631115 seconds. Throughput is 1324.6251 records/second. Loss is 2.2846706. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.770007770007771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 36992/60000][Iteration 289][Wall Clock 35.615036326s] Trained 128 records in 0.103031909 seconds. Throughput is 1242.3335 records/second. Loss is 2.2656944. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.763975155279503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 290][Wall Clock 35.720353561s] Trained 128 records in 0.105317235 seconds. Throughput is 1215.3756 records/second. Loss is 2.2780435. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.757951900698217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:50 INFO  DistriOptimizer$:408 - [Epoch 1 37248/60000][Iteration 291][Wall Clock 35.819655851s] Trained 128 records in 0.09930229 seconds. Throughput is 1288.9934 records/second. Loss is 2.2679708. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.751937984496124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 292][Wall Clock 35.909888681s] Trained 128 records in 0.09023283 seconds. Throughput is 1418.5525 records/second. Loss is 2.274323. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.74593338497289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 37504/60000][Iteration 293][Wall Clock 36.000129379s] Trained 128 records in 0.090240698 seconds. Throughput is 1418.4288 records/second. Loss is 2.2766242. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.739938080495357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 294][Wall Clock 36.098202751s] Trained 128 records in 0.098073372 seconds. Throughput is 1305.1453 records/second. Loss is 2.2808812. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.733952049497294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 37760/60000][Iteration 295][Wall Clock 36.190634603s] Trained 128 records in 0.092431852 seconds. Throughput is 1384.8041 records/second. Loss is 2.2809181. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.727975270479134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 296][Wall Clock 36.306496624s] Trained 128 records in 0.115862021 seconds. Throughput is 1104.7623 records/second. Loss is 2.2872164. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.722007722007723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 38016/60000][Iteration 297][Wall Clock 36.421176892s] Trained 128 records in 0.114680268 seconds. Throughput is 1116.1467 records/second. Loss is 2.2881727. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.716049382716049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 298][Wall Clock 36.517028284s] Trained 128 records in 0.095851392 seconds. Throughput is 1335.4005 records/second. Loss is 2.2754412. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.710100231303008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 38272/60000][Iteration 299][Wall Clock 36.631239692s] Trained 128 records in 0.114211408 seconds. Throughput is 1120.7286 records/second. Loss is 2.282397. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.704160246533128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 300][Wall Clock 36.728193109s] Trained 128 records in 0.096953417 seconds. Throughput is 1320.2217 records/second. Loss is 2.276545. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.698229407236336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:51 INFO  DistriOptimizer$:408 - [Epoch 1 38528/60000][Iteration 301][Wall Clock 36.84691795s] Trained 128 records in 0.118724841 seconds. Throughput is 1078.1232 records/second. Loss is 2.2825587. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.692307692307692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 302][Wall Clock 36.939886648s] Trained 128 records in 0.092968698 seconds. Throughput is 1376.8075 records/second. Loss is 2.2774467. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.686395080707148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 38784/60000][Iteration 303][Wall Clock 37.034841044s] Trained 128 records in 0.094954396 seconds. Throughput is 1348.0155 records/second. Loss is 2.2872381. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.680491551459293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 304][Wall Clock 37.12748547s] Trained 128 records in 0.092644426 seconds. Throughput is 1381.6266 records/second. Loss is 2.280214. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.674597083653109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39040/60000][Iteration 305][Wall Clock 37.220693405s] Trained 128 records in 0.093207935 seconds. Throughput is 1373.2737 records/second. Loss is 2.2695277. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.668711656441718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 306][Wall Clock 37.317882224s] Trained 128 records in 0.097188819 seconds. Throughput is 1317.0239 records/second. Loss is 2.2885938. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.662835249042146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39296/60000][Iteration 307][Wall Clock 37.411149473s] Trained 128 records in 0.093267249 seconds. Throughput is 1372.4003 records/second. Loss is 2.2716222. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.656967840735069E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 308][Wall Clock 37.503170267s] Trained 128 records in 0.092020794 seconds. Throughput is 1390.99 records/second. Loss is 2.2934408. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.651109410864576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39552/60000][Iteration 309][Wall Clock 37.595284956s] Trained 128 records in 0.092114689 seconds. Throughput is 1389.5721 records/second. Loss is 2.2772222. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.645259938837921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 310][Wall Clock 37.695431371s] Trained 128 records in 0.100146415 seconds. Throughput is 1278.1287 records/second. Loss is 2.2601376. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.639419404125287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:52 INFO  DistriOptimizer$:408 - [Epoch 1 39808/60000][Iteration 311][Wall Clock 37.800552802s] Trained 128 records in 0.105121431 seconds. Throughput is 1217.6394 records/second. Loss is 2.283736. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.633587786259542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 312][Wall Clock 37.892602742s] Trained 128 records in 0.09204994 seconds. Throughput is 1390.5496 records/second. Loss is 2.271843. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.627765064836003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40064/60000][Iteration 313][Wall Clock 37.998418766s] Trained 128 records in 0.105816024 seconds. Throughput is 1209.6467 records/second. Loss is 2.268148. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.621951219512195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 314][Wall Clock 38.104763915s] Trained 128 records in 0.106345149 seconds. Throughput is 1203.628 records/second. Loss is 2.2814865. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.616146230007616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40320/60000][Iteration 315][Wall Clock 38.199883588s] Trained 128 records in 0.095119673 seconds. Throughput is 1345.6733 records/second. Loss is 2.2804518. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.6103500761035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 316][Wall Clock 38.295707791s] Trained 128 records in 0.095824203 seconds. Throughput is 1335.7794 records/second. Loss is 2.265334. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.604562737642586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40576/60000][Iteration 317][Wall Clock 38.385536394s] Trained 128 records in 0.089828603 seconds. Throughput is 1424.9359 records/second. Loss is 2.2700818. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.598784194528875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 318][Wall Clock 38.480391926s] Trained 128 records in 0.094855532 seconds. Throughput is 1349.4205 records/second. Loss is 2.2763355. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.593014426727411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40832/60000][Iteration 319][Wall Clock 38.578286325s] Trained 128 records in 0.097894399 seconds. Throughput is 1307.5314 records/second. Loss is 2.2781866. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.587253414264037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 320][Wall Clock 38.670803329s] Trained 128 records in 0.092517004 seconds. Throughput is 1383.5294 records/second. Loss is 2.28525. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.58150113722517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 41088/60000][Iteration 321][Wall Clock 38.760865391s] Trained 128 records in 0.090062062 seconds. Throughput is 1421.2422 records/second. Loss is 2.2771046. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.575757575757576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:53 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 322][Wall Clock 38.853698669s] Trained 128 records in 0.092833278 seconds. Throughput is 1378.8159 records/second. Loss is 2.2754264. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.57002271006813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 41344/60000][Iteration 323][Wall Clock 38.94532553s] Trained 128 records in 0.091626861 seconds. Throughput is 1396.9702 records/second. Loss is 2.2758687. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.564296520423601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 324][Wall Clock 39.033638679s] Trained 128 records in 0.088313149 seconds. Throughput is 1449.3878 records/second. Loss is 2.2937636. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.558578987150416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 41600/60000][Iteration 325][Wall Clock 39.131628009s] Trained 128 records in 0.09798933 seconds. Throughput is 1306.2646 records/second. Loss is 2.2830253. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.552870090634441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 326][Wall Clock 39.229330306s] Trained 128 records in 0.097702297 seconds. Throughput is 1310.1023 records/second. Loss is 2.2679791. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.547169811320755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 41856/60000][Iteration 327][Wall Clock 39.32245597s] Trained 128 records in 0.093125664 seconds. Throughput is 1374.4868 records/second. Loss is 2.2668288. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.541478129713424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 328][Wall Clock 39.416093885s] Trained 128 records in 0.093637915 seconds. Throughput is 1366.9677 records/second. Loss is 2.2842066. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.535795026375283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 42112/60000][Iteration 329][Wall Clock 39.517825344s] Trained 128 records in 0.101731459 seconds. Throughput is 1258.2146 records/second. Loss is 2.274011. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.53012048192771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 330][Wall Clock 39.608756198s] Trained 128 records in 0.090930854 seconds. Throughput is 1407.663 records/second. Loss is 2.273516. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.524454477050415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 42368/60000][Iteration 331][Wall Clock 39.702958685s] Trained 128 records in 0.094202487 seconds. Throughput is 1358.7751 records/second. Loss is 2.2782257. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.518796992481202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:54 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 332][Wall Clock 39.798668249s] Trained 128 records in 0.095709564 seconds. Throughput is 1337.3794 records/second. Loss is 2.265102. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.513148009015778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 42624/60000][Iteration 333][Wall Clock 39.887412404s] Trained 128 records in 0.088744155 seconds. Throughput is 1442.3485 records/second. Loss is 2.266858. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.507507507507507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 334][Wall Clock 39.978218899s] Trained 128 records in 0.090806495 seconds. Throughput is 1409.5908 records/second. Loss is 2.2823267. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.501875468867217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 42880/60000][Iteration 335][Wall Clock 40.073215788s] Trained 128 records in 0.094996889 seconds. Throughput is 1347.4125 records/second. Loss is 2.2734938. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.496251874062968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 336][Wall Clock 40.179044477s] Trained 128 records in 0.105828689 seconds. Throughput is 1209.502 records/second. Loss is 2.2743158. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.49063670411985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43136/60000][Iteration 337][Wall Clock 40.289125251s] Trained 128 records in 0.110080774 seconds. Throughput is 1162.7826 records/second. Loss is 2.2700438. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.48502994011976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 338][Wall Clock 40.388819963s] Trained 128 records in 0.099694712 seconds. Throughput is 1283.9197 records/second. Loss is 2.271154. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.479431563201197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43392/60000][Iteration 339][Wall Clock 40.485954284s] Trained 128 records in 0.097134321 seconds. Throughput is 1317.7628 records/second. Loss is 2.277245. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.473841554559044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 340][Wall Clock 40.578208117s] Trained 128 records in 0.092253833 seconds. Throughput is 1387.4762 records/second. Loss is 2.2753592. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.468259895444362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43648/60000][Iteration 341][Wall Clock 40.670338404s] Trained 128 records in 0.092130287 seconds. Throughput is 1389.3368 records/second. Loss is 2.2865965. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.462686567164179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 342][Wall Clock 40.766939306s] Trained 128 records in 0.096600902 seconds. Throughput is 1325.0393 records/second. Loss is 2.2668881. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.457121551081283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:55 INFO  DistriOptimizer$:408 - [Epoch 1 43904/60000][Iteration 343][Wall Clock 40.86007609s] Trained 128 records in 0.093136784 seconds. Throughput is 1374.3226 records/second. Loss is 2.278006. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.451564828614009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 344][Wall Clock 40.953572697s] Trained 128 records in 0.093496607 seconds. Throughput is 1369.0337 records/second. Loss is 2.2781591. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.446016381236039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44160/60000][Iteration 345][Wall Clock 41.045807848s] Trained 128 records in 0.092235151 seconds. Throughput is 1387.7573 records/second. Loss is 2.261607. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.44047619047619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 346][Wall Clock 41.140908371s] Trained 128 records in 0.095100523 seconds. Throughput is 1345.9442 records/second. Loss is 2.270944. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.434944237918215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44416/60000][Iteration 347][Wall Clock 41.237539532s] Trained 128 records in 0.096631161 seconds. Throughput is 1324.6245 records/second. Loss is 2.2741933. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.429420505200594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 348][Wall Clock 41.327821606s] Trained 128 records in 0.090282074 seconds. Throughput is 1417.7787 records/second. Loss is 2.2794046. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.423904974016333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44672/60000][Iteration 349][Wall Clock 41.417741064s] Trained 128 records in 0.089919458 seconds. Throughput is 1423.4962 records/second. Loss is 2.2826042. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.418397626112759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 350][Wall Clock 41.506423908s] Trained 128 records in 0.088682844 seconds. Throughput is 1443.3457 records/second. Loss is 2.2761948. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.412898443291328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 44928/60000][Iteration 351][Wall Clock 41.601253695s] Trained 128 records in 0.094829787 seconds. Throughput is 1349.7869 records/second. Loss is 2.2795668. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.407407407407407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 352][Wall Clock 41.721148699s] Trained 128 records in 0.119895004 seconds. Throughput is 1067.6008 records/second. Loss is 2.2758229. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.401924500370097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:56 INFO  DistriOptimizer$:408 - [Epoch 1 45184/60000][Iteration 353][Wall Clock 41.811568532s] Trained 128 records in 0.090419833 seconds. Throughput is 1415.6185 records/second. Loss is 2.2740364. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.396449704142013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 354][Wall Clock 41.902512192s] Trained 128 records in 0.09094366 seconds. Throughput is 1407.4648 records/second. Loss is 2.2669828. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.390983000739098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 45440/60000][Iteration 355][Wall Clock 41.996400318s] Trained 128 records in 0.093888126 seconds. Throughput is 1363.3247 records/second. Loss is 2.2759674. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.385524372230428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 356][Wall Clock 42.099339138s] Trained 128 records in 0.10293882 seconds. Throughput is 1243.457 records/second. Loss is 2.2675164. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.380073800738007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 45696/60000][Iteration 357][Wall Clock 42.194758207s] Trained 128 records in 0.095419069 seconds. Throughput is 1341.4509 records/second. Loss is 2.2693474. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.374631268436579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 358][Wall Clock 42.292735654s] Trained 128 records in 0.097977447 seconds. Throughput is 1306.4231 records/second. Loss is 2.2832136. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.369196757553427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 45952/60000][Iteration 359][Wall Clock 42.383876022s] Trained 128 records in 0.091140368 seconds. Throughput is 1404.4271 records/second. Loss is 2.277695. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.363770250368188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 360][Wall Clock 42.484241738s] Trained 128 records in 0.100365716 seconds. Throughput is 1275.3359 records/second. Loss is 2.273359. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.358351729212656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 46208/60000][Iteration 361][Wall Clock 42.580381151s] Trained 128 records in 0.096139413 seconds. Throughput is 1331.3998 records/second. Loss is 2.2740376. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.352941176470589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 362][Wall Clock 42.679599117s] Trained 128 records in 0.099217966 seconds. Throughput is 1290.089 records/second. Loss is 2.2729154. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.347538574577517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:57 INFO  DistriOptimizer$:408 - [Epoch 1 46464/60000][Iteration 363][Wall Clock 42.780199095s] Trained 128 records in 0.100599978 seconds. Throughput is 1272.3661 records/second. Loss is 2.2784781. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.342143906020558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 364][Wall Clock 42.866959669s] Trained 128 records in 0.086760574 seconds. Throughput is 1475.3245 records/second. Loss is 2.2693214. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.336757153338225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 46720/60000][Iteration 365][Wall Clock 42.956268151s] Trained 128 records in 0.089308482 seconds. Throughput is 1433.2345 records/second. Loss is 2.2771792. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.331378299120236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 366][Wall Clock 43.050626677s] Trained 128 records in 0.094358526 seconds. Throughput is 1356.5282 records/second. Loss is 2.2756515. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.326007326007326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 46976/60000][Iteration 367][Wall Clock 43.143051409s] Trained 128 records in 0.092424732 seconds. Throughput is 1384.9106 records/second. Loss is 2.2678826. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.320644216691068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 368][Wall Clock 43.236346543s] Trained 128 records in 0.093295134 seconds. Throughput is 1371.9901 records/second. Loss is 2.2762198. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.31528895391368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47232/60000][Iteration 369][Wall Clock 43.356027617s] Trained 128 records in 0.119681074 seconds. Throughput is 1069.5092 records/second. Loss is 2.2686474. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.309941520467837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 370][Wall Clock 43.449508616s] Trained 128 records in 0.093480999 seconds. Throughput is 1369.2622 records/second. Loss is 2.2754152. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.304601899196494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47488/60000][Iteration 371][Wall Clock 43.54269134s] Trained 128 records in 0.093182724 seconds. Throughput is 1373.6451 records/second. Loss is 2.2760973. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.2992700729927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 372][Wall Clock 43.637853451s] Trained 128 records in 0.095162111 seconds. Throughput is 1345.0731 records/second. Loss is 2.2700725. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.293946024799417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47744/60000][Iteration 373][Wall Clock 43.734121409s] Trained 128 records in 0.096267958 seconds. Throughput is 1329.6221 records/second. Loss is 2.266301. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.28862973760933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:58 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 374][Wall Clock 43.829377046s] Trained 128 records in 0.095255637 seconds. Throughput is 1343.7526 records/second. Loss is 2.2721272. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.283321194464676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48000/60000][Iteration 375][Wall Clock 43.916818213s] Trained 128 records in 0.087441167 seconds. Throughput is 1463.8413 records/second. Loss is 2.2781272. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.278020378457059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 376][Wall Clock 44.013752779s] Trained 128 records in 0.096934566 seconds. Throughput is 1320.4784 records/second. Loss is 2.2723777. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.272727272727273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48256/60000][Iteration 377][Wall Clock 44.119212909s] Trained 128 records in 0.10546013 seconds. Throughput is 1213.7289 records/second. Loss is 2.2749116. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.267441860465117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 378][Wall Clock 44.214724069s] Trained 128 records in 0.09551116 seconds. Throughput is 1340.1575 records/second. Loss is 2.2723207. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.262164124909223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48512/60000][Iteration 379][Wall Clock 44.331675594s] Trained 128 records in 0.116951525 seconds. Throughput is 1094.4706 records/second. Loss is 2.2787228. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.25689404934688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 380][Wall Clock 44.428026442s] Trained 128 records in 0.096350848 seconds. Throughput is 1328.4781 records/second. Loss is 2.2667723. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.251631617113851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48768/60000][Iteration 381][Wall Clock 44.522868488s] Trained 128 records in 0.094842046 seconds. Throughput is 1349.6124 records/second. Loss is 2.2668283. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.246376811594204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 382][Wall Clock 44.617689016s] Trained 128 records in 0.094820528 seconds. Throughput is 1349.9187 records/second. Loss is 2.2722752. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.241129616220131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 49024/60000][Iteration 383][Wall Clock 44.716762137s] Trained 128 records in 0.099073121 seconds. Throughput is 1291.9751 records/second. Loss is 2.2818816. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.23589001447178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:11:59 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 384][Wall Clock 44.81933927s] Trained 128 records in 0.102577133 seconds. Throughput is 1247.8414 records/second. Loss is 2.2755723. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.230657989877079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 49280/60000][Iteration 385][Wall Clock 44.920816448s] Trained 128 records in 0.101477178 seconds. Throughput is 1261.3674 records/second. Loss is 2.2792041. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.225433526011561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 386][Wall Clock 45.016423454s] Trained 128 records in 0.095607006 seconds. Throughput is 1338.8141 records/second. Loss is 2.2728362. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.220216606498195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 49536/60000][Iteration 387][Wall Clock 45.106331146s] Trained 128 records in 0.089907692 seconds. Throughput is 1423.6824 records/second. Loss is 2.2763252. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.215007215007215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 388][Wall Clock 45.206064202s] Trained 128 records in 0.099733056 seconds. Throughput is 1283.426 records/second. Loss is 2.2667642. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.209805335255948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 49792/60000][Iteration 389][Wall Clock 45.31795965s] Trained 128 records in 0.111895448 seconds. Throughput is 1143.9249 records/second. Loss is 2.257329. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.204610951008646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 390][Wall Clock 45.41449792s] Trained 128 records in 0.09653827 seconds. Throughput is 1325.899 records/second. Loss is 2.2672539. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.199424046076314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 50048/60000][Iteration 391][Wall Clock 45.506424353s] Trained 128 records in 0.091926433 seconds. Throughput is 1392.4177 records/second. Loss is 2.2636948. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.194244604316546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 392][Wall Clock 45.598231458s] Trained 128 records in 0.091807105 seconds. Throughput is 1394.2277 records/second. Loss is 2.2668269. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.189072609633358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 50304/60000][Iteration 393][Wall Clock 45.689913824s] Trained 128 records in 0.091682366 seconds. Throughput is 1396.1245 records/second. Loss is 2.264951. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.183908045977012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:00 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 394][Wall Clock 45.783061237s] Trained 128 records in 0.093147413 seconds. Throughput is 1374.1659 records/second. Loss is 2.2794483. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.178750897343862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 50560/60000][Iteration 395][Wall Clock 45.875689495s] Trained 128 records in 0.092628258 seconds. Throughput is 1381.8678 records/second. Loss is 2.2617505. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.173601147776183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 396][Wall Clock 45.966722183s] Trained 128 records in 0.091032688 seconds. Throughput is 1406.0883 records/second. Loss is 2.2775211. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.168458781362007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 50816/60000][Iteration 397][Wall Clock 46.058469065s] Trained 128 records in 0.091746882 seconds. Throughput is 1395.1428 records/second. Loss is 2.2608385. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.163323782234958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 398][Wall Clock 46.150463857s] Trained 128 records in 0.091994792 seconds. Throughput is 1391.383 records/second. Loss is 2.2667313. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.158196134574087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51072/60000][Iteration 399][Wall Clock 46.24096479s] Trained 128 records in 0.090500933 seconds. Throughput is 1414.35 records/second. Loss is 2.258683. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.15307582260372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 400][Wall Clock 46.331560483s] Trained 128 records in 0.090595693 seconds. Throughput is 1412.8707 records/second. Loss is 2.2795904. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.147962830593281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51328/60000][Iteration 401][Wall Clock 46.419683495s] Trained 128 records in 0.088123012 seconds. Throughput is 1452.5151 records/second. Loss is 2.2730012. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.142857142857144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 402][Wall Clock 46.511555141s] Trained 128 records in 0.091871646 seconds. Throughput is 1393.248 records/second. Loss is 2.264425. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.137758743754461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51584/60000][Iteration 403][Wall Clock 46.603675275s] Trained 128 records in 0.092120134 seconds. Throughput is 1389.49 records/second. Loss is 2.2633665. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.132667617689015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 404][Wall Clock 46.694849213s] Trained 128 records in 0.091173938 seconds. Throughput is 1403.9099 records/second. Loss is 2.2757366. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.127583749109052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:01 INFO  DistriOptimizer$:408 - [Epoch 1 51840/60000][Iteration 405][Wall Clock 46.784614891s] Trained 128 records in 0.089765678 seconds. Throughput is 1425.9348 records/second. Loss is 2.2752101. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.122507122507123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 406][Wall Clock 46.872677773s] Trained 128 records in 0.088062882 seconds. Throughput is 1453.5068 records/second. Loss is 2.273346. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.117437722419929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52096/60000][Iteration 407][Wall Clock 46.96186415s] Trained 128 records in 0.089186377 seconds. Throughput is 1435.1968 records/second. Loss is 2.277773. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.112375533428164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 408][Wall Clock 47.049880703s] Trained 128 records in 0.088016553 seconds. Throughput is 1454.2719 records/second. Loss is 2.273615. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.107320540156361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52352/60000][Iteration 409][Wall Clock 47.138718522s] Trained 128 records in 0.088837819 seconds. Throughput is 1440.8279 records/second. Loss is 2.2643213. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.102272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 410][Wall Clock 47.227643713s] Trained 128 records in 0.088925191 seconds. Throughput is 1439.4121 records/second. Loss is 2.26779. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.097232079489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52608/60000][Iteration 411][Wall Clock 47.319020866s] Trained 128 records in 0.091377153 seconds. Throughput is 1400.7877 records/second. Loss is 2.2763815. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.092198581560283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 412][Wall Clock 47.43696501s] Trained 128 records in 0.117944144 seconds. Throughput is 1085.2595 records/second. Loss is 2.276357. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.087172218284905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52864/60000][Iteration 413][Wall Clock 47.530176635s] Trained 128 records in 0.093211625 seconds. Throughput is 1373.2192 records/second. Loss is 2.2665992. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.08215297450425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 414][Wall Clock 47.641693632s] Trained 128 records in 0.111516997 seconds. Throughput is 1147.8071 records/second. Loss is 2.2638557. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.077140835102619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:02 INFO  DistriOptimizer$:408 - [Epoch 1 53120/60000][Iteration 415][Wall Clock 47.758957162s] Trained 128 records in 0.11726353 seconds. Throughput is 1091.5585 records/second. Loss is 2.2684712. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.072135785007071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 416][Wall Clock 47.875785196s] Trained 128 records in 0.116828034 seconds. Throughput is 1095.6274 records/second. Loss is 2.2621288. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.067137809187279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 53376/60000][Iteration 417][Wall Clock 47.972482183s] Trained 128 records in 0.096696987 seconds. Throughput is 1323.7228 records/second. Loss is 2.2761059. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.062146892655368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 418][Wall Clock 48.063266649s] Trained 128 records in 0.090784466 seconds. Throughput is 1409.9329 records/second. Loss is 2.2848043. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.057163020465773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 53632/60000][Iteration 419][Wall Clock 48.153367773s] Trained 128 records in 0.090101124 seconds. Throughput is 1420.626 records/second. Loss is 2.271571. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.052186177715093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 420][Wall Clock 48.24420479s] Trained 128 records in 0.090837017 seconds. Throughput is 1409.1172 records/second. Loss is 2.2717247. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.047216349541931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 53888/60000][Iteration 421][Wall Clock 48.337665081s] Trained 128 records in 0.093460291 seconds. Throughput is 1369.5656 records/second. Loss is 2.269193. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.042253521126761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 422][Wall Clock 48.428026666s] Trained 128 records in 0.090361585 seconds. Throughput is 1416.5311 records/second. Loss is 2.260501. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.037297677691766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 54144/60000][Iteration 423][Wall Clock 48.520481276s] Trained 128 records in 0.09245461 seconds. Throughput is 1384.4631 records/second. Loss is 2.266655. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.032348804500703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 424][Wall Clock 48.621743349s] Trained 128 records in 0.101262073 seconds. Throughput is 1264.0469 records/second. Loss is 2.2725549. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.027406886858749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 54400/60000][Iteration 425][Wall Clock 48.720997264s] Trained 128 records in 0.099253915 seconds. Throughput is 1289.6217 records/second. Loss is 2.2795484. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.02247191011236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:03 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 426][Wall Clock 48.809791464s] Trained 128 records in 0.0887942 seconds. Throughput is 1441.5355 records/second. Loss is 2.2695386. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.017543859649122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 54656/60000][Iteration 427][Wall Clock 48.899812518s] Trained 128 records in 0.090021054 seconds. Throughput is 1421.8896 records/second. Loss is 2.263491. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.012622720897617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 428][Wall Clock 48.990630529s] Trained 128 records in 0.090818011 seconds. Throughput is 1409.4121 records/second. Loss is 2.2647014. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.00770847932726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 54912/60000][Iteration 429][Wall Clock 49.083636103s] Trained 128 records in 0.093005574 seconds. Throughput is 1376.2616 records/second. Loss is 2.268734. Sequentialdaab25a8's hyper parameters: Current learning rate is 7.002801120448179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 430][Wall Clock 49.176297884s] Trained 128 records in 0.092661781 seconds. Throughput is 1381.3678 records/second. Loss is 2.2601597. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.997900629811056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55168/60000][Iteration 431][Wall Clock 49.268124862s] Trained 128 records in 0.091826978 seconds. Throughput is 1393.9259 records/second. Loss is 2.2571685. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.993006993006993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 432][Wall Clock 49.368366264s] Trained 128 records in 0.100241402 seconds. Throughput is 1276.9175 records/second. Loss is 2.2742999. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.988120195667365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55424/60000][Iteration 433][Wall Clock 49.459101019s] Trained 128 records in 0.090734755 seconds. Throughput is 1410.7053 records/second. Loss is 2.2740626. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.983240223463687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 434][Wall Clock 49.550921728s] Trained 128 records in 0.091820709 seconds. Throughput is 1394.021 records/second. Loss is 2.2810383. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.978367062107466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55680/60000][Iteration 435][Wall Clock 49.643255128s] Trained 128 records in 0.0923334 seconds. Throughput is 1386.2806 records/second. Loss is 2.2685847. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.973500697350071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:04 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 436][Wall Clock 49.735806725s] Trained 128 records in 0.092551597 seconds. Throughput is 1383.0123 records/second. Loss is 2.2673647. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.968641114982578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 55936/60000][Iteration 437][Wall Clock 49.824724234s] Trained 128 records in 0.088917509 seconds. Throughput is 1439.5365 records/second. Loss is 2.2557223. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.963788300835655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 438][Wall Clock 49.924550278s] Trained 128 records in 0.099826044 seconds. Throughput is 1282.2305 records/second. Loss is 2.257982. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.958942240779402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56192/60000][Iteration 439][Wall Clock 50.011970502s] Trained 128 records in 0.087420224 seconds. Throughput is 1464.192 records/second. Loss is 2.2944906. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.954102920723227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 440][Wall Clock 50.102875779s] Trained 128 records in 0.090905277 seconds. Throughput is 1408.0591 records/second. Loss is 2.2744286. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.949270326615705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56448/60000][Iteration 441][Wall Clock 50.211943164s] Trained 128 records in 0.109067385 seconds. Throughput is 1173.5864 records/second. Loss is 2.2700965. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.944444444444445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 442][Wall Clock 50.306301358s] Trained 128 records in 0.094358194 seconds. Throughput is 1356.533 records/second. Loss is 2.2699447. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.939625260235947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56704/60000][Iteration 443][Wall Clock 50.399233678s] Trained 128 records in 0.09293232 seconds. Throughput is 1377.3464 records/second. Loss is 2.2599208. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.934812760055479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 444][Wall Clock 50.492813077s] Trained 128 records in 0.093579399 seconds. Throughput is 1367.8225 records/second. Loss is 2.2640252. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.93000693000693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 56960/60000][Iteration 445][Wall Clock 50.582020377s] Trained 128 records in 0.0892073 seconds. Throughput is 1434.8601 records/second. Loss is 2.2674747. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.925207756232687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 446][Wall Clock 50.674766766s] Trained 128 records in 0.092746389 seconds. Throughput is 1380.1075 records/second. Loss is 2.2816095. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.920415224913495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:05 INFO  DistriOptimizer$:408 - [Epoch 1 57216/60000][Iteration 447][Wall Clock 50.762592404s] Trained 128 records in 0.087825638 seconds. Throughput is 1457.4331 records/second. Loss is 2.2637131. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.915629322268327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 448][Wall Clock 50.849379945s] Trained 128 records in 0.086787541 seconds. Throughput is 1474.866 records/second. Loss is 2.2679694. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.91085003455425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 57472/60000][Iteration 449][Wall Clock 50.957323789s] Trained 128 records in 0.107943844 seconds. Throughput is 1185.8018 records/second. Loss is 2.2706034. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.906077348066299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 450][Wall Clock 51.058972789s] Trained 128 records in 0.101649 seconds. Throughput is 1259.2352 records/second. Loss is 2.2709181. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.901311249137336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 57728/60000][Iteration 451][Wall Clock 51.150346943s] Trained 128 records in 0.091374154 seconds. Throughput is 1400.8339 records/second. Loss is 2.2705863. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.896551724137932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 452][Wall Clock 51.242271946s] Trained 128 records in 0.091925003 seconds. Throughput is 1392.4395 records/second. Loss is 2.2541456. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.891798759476223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 57984/60000][Iteration 453][Wall Clock 51.336453981s] Trained 128 records in 0.094182035 seconds. Throughput is 1359.0702 records/second. Loss is 2.2567332. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.887052341597796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 454][Wall Clock 51.428530777s] Trained 128 records in 0.092076796 seconds. Throughput is 1390.1439 records/second. Loss is 2.2593853. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.882312456985547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 58240/60000][Iteration 455][Wall Clock 51.51718459s] Trained 128 records in 0.088653813 seconds. Throughput is 1443.8184 records/second. Loss is 2.2629194. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.87757909215956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 456][Wall Clock 51.607101254s] Trained 128 records in 0.089916664 seconds. Throughput is 1423.5404 records/second. Loss is 2.2561944. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.872852233676975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 58496/60000][Iteration 457][Wall Clock 51.706308993s] Trained 128 records in 0.099207739 seconds. Throughput is 1290.2219 records/second. Loss is 2.275424. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.868131868131869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:06 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 458][Wall Clock 51.795178644s] Trained 128 records in 0.088869651 seconds. Throughput is 1440.3116 records/second. Loss is 2.265006. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.863417982155113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 58752/60000][Iteration 459][Wall Clock 51.88409698s] Trained 128 records in 0.088918336 seconds. Throughput is 1439.5231 records/second. Loss is 2.2785614. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.858710562414267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 460][Wall Clock 51.971376727s] Trained 128 records in 0.087279747 seconds. Throughput is 1466.5487 records/second. Loss is 2.2666035. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.854009595613433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59008/60000][Iteration 461][Wall Clock 52.05967534s] Trained 128 records in 0.088298613 seconds. Throughput is 1449.6265 records/second. Loss is 2.2701633. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.849315068493151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 462][Wall Clock 52.152740218s] Trained 128 records in 0.093064878 seconds. Throughput is 1375.3846 records/second. Loss is 2.253438. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.844626967830253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59264/60000][Iteration 463][Wall Clock 52.240547903s] Trained 128 records in 0.087807685 seconds. Throughput is 1457.7312 records/second. Loss is 2.265937. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.839945280437756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 464][Wall Clock 52.344448929s] Trained 128 records in 0.103901026 seconds. Throughput is 1231.9417 records/second. Loss is 2.2613149. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.835269993164729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59520/60000][Iteration 465][Wall Clock 52.431920109s] Trained 128 records in 0.08747118 seconds. Throughput is 1463.3391 records/second. Loss is 2.270477. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.830601092896175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 466][Wall Clock 52.545473729s] Trained 128 records in 0.11355362 seconds. Throughput is 1127.2208 records/second. Loss is 2.255847. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.825938566552901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59776/60000][Iteration 467][Wall Clock 52.633072277s] Trained 128 records in 0.087598548 seconds. Throughput is 1461.2114 records/second. Loss is 2.260673. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.821282401091405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:07 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 468][Wall Clock 52.720810583s] Trained 128 records in 0.087738306 seconds. Throughput is 1458.8839 records/second. Loss is 2.265095. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.816632583503749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:08 INFO  DistriOptimizer$:408 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.808531901s] Trained 128 records in 0.087721318 seconds. Throughput is 1459.1664 records/second. Loss is 2.2622197. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.811989100817438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:08 INFO  DistriOptimizer$:452 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.808531901s] Epoch finished. Wall clock time is 53125.2511 ms
2019-10-14 23:12:08 INFO  DistriOptimizer$:111 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.808531901s] Validate model...
2019-10-14 23:12:09 INFO  DistriOptimizer$:178 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.808531901s] validate model throughput is 9764.2295 records/second
2019-10-14 23:12:09 INFO  DistriOptimizer$:181 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.808531901s] Top1Accuracy is Accuracy(correct: 1756, count: 10000, accuracy: 0.1756)
2019-10-14 23:12:09 INFO  DistriOptimizer$:221 - [Wall Clock 53.1252511s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:12:09 INFO  DistriOptimizer$:226 - [Wall Clock 53.1252511s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 128/60000][Iteration 470][Wall Clock 53.276505553s] Trained 128 records in 0.151254453 seconds. Throughput is 846.25604 records/second. Loss is 2.2796347. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.807351940095302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 471][Wall Clock 53.375549164s] Trained 128 records in 0.099043611 seconds. Throughput is 1292.36 records/second. Loss is 2.2594845. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.802721088435375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 384/60000][Iteration 472][Wall Clock 53.488802837s] Trained 128 records in 0.113253673 seconds. Throughput is 1130.2062 records/second. Loss is 2.2688782. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.798096532970768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 473][Wall Clock 53.593744966s] Trained 128 records in 0.104942129 seconds. Throughput is 1219.7198 records/second. Loss is 2.263706. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.793478260869565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 640/60000][Iteration 474][Wall Clock 53.689061053s] Trained 128 records in 0.095316087 seconds. Throughput is 1342.9003 records/second. Loss is 2.2680647. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.788866259334691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 475][Wall Clock 53.779863955s] Trained 128 records in 0.090802902 seconds. Throughput is 1409.6466 records/second. Loss is 2.261974. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.7842605156038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:09 INFO  DistriOptimizer$:408 - [Epoch 2 896/60000][Iteration 476][Wall Clock 53.873538286s] Trained 128 records in 0.093674331 seconds. Throughput is 1366.4363 records/second. Loss is 2.2649353. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.779661016949152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 477][Wall Clock 53.964572526s] Trained 128 records in 0.09103424 seconds. Throughput is 1406.0643 records/second. Loss is 2.270192. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.775067750677507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1152/60000][Iteration 478][Wall Clock 54.057090407s] Trained 128 records in 0.092517881 seconds. Throughput is 1383.5164 records/second. Loss is 2.2661214. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.770480704129993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 479][Wall Clock 54.146626347s] Trained 128 records in 0.08953594 seconds. Throughput is 1429.5936 records/second. Loss is 2.250757. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.765899864682003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1408/60000][Iteration 480][Wall Clock 54.24559456s] Trained 128 records in 0.098968213 seconds. Throughput is 1293.3445 records/second. Loss is 2.2545042. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.76132521974307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 481][Wall Clock 54.33535045s] Trained 128 records in 0.08975589 seconds. Throughput is 1426.0902 records/second. Loss is 2.2536733. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.756756756756757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1664/60000][Iteration 482][Wall Clock 54.424961948s] Trained 128 records in 0.089611498 seconds. Throughput is 1428.3881 records/second. Loss is 2.2509172. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.752194463200541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 483][Wall Clock 54.516778566s] Trained 128 records in 0.091816618 seconds. Throughput is 1394.0831 records/second. Loss is 2.254391. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.747638326585695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 1920/60000][Iteration 484][Wall Clock 54.608403562s] Trained 128 records in 0.091624996 seconds. Throughput is 1396.9987 records/second. Loss is 2.2640123. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.743088334457181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 485][Wall Clock 54.696184631s] Trained 128 records in 0.087781069 seconds. Throughput is 1458.1731 records/second. Loss is 2.2627997. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.738544474393531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 2176/60000][Iteration 486][Wall Clock 54.797399296s] Trained 128 records in 0.101214665 seconds. Throughput is 1264.6389 records/second. Loss is 2.2534924. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.734006734006734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:10 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 487][Wall Clock 54.897178665s] Trained 128 records in 0.099779369 seconds. Throughput is 1282.8303 records/second. Loss is 2.263163. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.729475100942127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 2432/60000][Iteration 488][Wall Clock 54.980714691s] Trained 128 records in 0.083536026 seconds. Throughput is 1532.273 records/second. Loss is 2.2781858. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.724949562878278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 489][Wall Clock 55.072668353s] Trained 128 records in 0.091953662 seconds. Throughput is 1392.0054 records/second. Loss is 2.2600284. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.720430107526882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 2688/60000][Iteration 490][Wall Clock 55.163712259s] Trained 128 records in 0.091043906 seconds. Throughput is 1405.915 records/second. Loss is 2.2751436. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.71591672263264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 491][Wall Clock 55.253289743s] Trained 128 records in 0.089577484 seconds. Throughput is 1428.9305 records/second. Loss is 2.2658892. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.711409395973154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 2944/60000][Iteration 492][Wall Clock 55.344772296s] Trained 128 records in 0.091482553 seconds. Throughput is 1399.174 records/second. Loss is 2.2608104. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.706908115358819E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 493][Wall Clock 55.432516213s] Trained 128 records in 0.087743917 seconds. Throughput is 1458.7906 records/second. Loss is 2.2645233. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.702412868632708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 3200/60000][Iteration 494][Wall Clock 55.538869024s] Trained 128 records in 0.106352811 seconds. Throughput is 1203.5413 records/second. Loss is 2.2689633. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.697923643670463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 495][Wall Clock 55.62636066s] Trained 128 records in 0.087491636 seconds. Throughput is 1462.997 records/second. Loss is 2.2633815. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.693440428380187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 3456/60000][Iteration 496][Wall Clock 55.733080584s] Trained 128 records in 0.106719924 seconds. Throughput is 1199.4011 records/second. Loss is 2.2692385. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.688963210702341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:11 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 497][Wall Clock 55.858365949s] Trained 128 records in 0.125285365 seconds. Throughput is 1021.66754 records/second. Loss is 2.2677996. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.684491978609626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 3712/60000][Iteration 498][Wall Clock 55.943420046s] Trained 128 records in 0.085054097 seconds. Throughput is 1504.9246 records/second. Loss is 2.267416. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.680026720106881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 499][Wall Clock 56.03468259s] Trained 128 records in 0.091262544 seconds. Throughput is 1402.547 records/second. Loss is 2.2570734. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.675567423230974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 3968/60000][Iteration 500][Wall Clock 56.130466473s] Trained 128 records in 0.095783883 seconds. Throughput is 1336.3418 records/second. Loss is 2.2564745. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.6711140760507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 501][Wall Clock 56.218931858s] Trained 128 records in 0.088465385 seconds. Throughput is 1446.8936 records/second. Loss is 2.2651467. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.666666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4224/60000][Iteration 502][Wall Clock 56.310918398s] Trained 128 records in 0.09198654 seconds. Throughput is 1391.5079 records/second. Loss is 2.2659693. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.662225183211193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 503][Wall Clock 56.402470205s] Trained 128 records in 0.091551807 seconds. Throughput is 1398.1155 records/second. Loss is 2.2588117. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.657789613848203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4480/60000][Iteration 504][Wall Clock 56.49422513s] Trained 128 records in 0.091754925 seconds. Throughput is 1395.0204 records/second. Loss is 2.2653687. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.653359946773121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 505][Wall Clock 56.585279045s] Trained 128 records in 0.091053915 seconds. Throughput is 1405.7605 records/second. Loss is 2.2595396. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.648936170212766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4736/60000][Iteration 506][Wall Clock 56.678747582s] Trained 128 records in 0.093468537 seconds. Throughput is 1369.4447 records/second. Loss is 2.2731845. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.64451827242525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 507][Wall Clock 56.76997739s] Trained 128 records in 0.091229808 seconds. Throughput is 1403.0502 records/second. Loss is 2.2515974. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.640106241699868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:12 INFO  DistriOptimizer$:408 - [Epoch 2 4992/60000][Iteration 508][Wall Clock 56.858510469s] Trained 128 records in 0.088533079 seconds. Throughput is 1445.7872 records/second. Loss is 2.252914. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.635700066357001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 509][Wall Clock 56.949200324s] Trained 128 records in 0.090689855 seconds. Throughput is 1411.4038 records/second. Loss is 2.2639425. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.63129973474801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5248/60000][Iteration 510][Wall Clock 57.041963596s] Trained 128 records in 0.092763272 seconds. Throughput is 1379.8564 records/second. Loss is 2.268133. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.626905235255137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 511][Wall Clock 57.130875592s] Trained 128 records in 0.088911996 seconds. Throughput is 1439.6257 records/second. Loss is 2.2518828. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.622516556291391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5504/60000][Iteration 512][Wall Clock 57.241573114s] Trained 128 records in 0.110697522 seconds. Throughput is 1156.3041 records/second. Loss is 2.2697725. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.618133686300463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 513][Wall Clock 57.335828531s] Trained 128 records in 0.094255417 seconds. Throughput is 1358.0121 records/second. Loss is 2.2593594. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.613756613756613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5760/60000][Iteration 514][Wall Clock 57.4245525s] Trained 128 records in 0.088723969 seconds. Throughput is 1442.6766 records/second. Loss is 2.2593577. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.609385327164574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 515][Wall Clock 57.510856778s] Trained 128 records in 0.086304278 seconds. Throughput is 1483.1246 records/second. Loss is 2.2558675. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.605019815059445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 6016/60000][Iteration 516][Wall Clock 57.598881929s] Trained 128 records in 0.088025151 seconds. Throughput is 1454.1299 records/second. Loss is 2.2566168. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.600660066006601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 517][Wall Clock 57.698522832s] Trained 128 records in 0.099640903 seconds. Throughput is 1284.6129 records/second. Loss is 2.2681143. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.596306068601583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 6272/60000][Iteration 518][Wall Clock 57.785586262s] Trained 128 records in 0.08706343 seconds. Throughput is 1470.1925 records/second. Loss is 2.2689955. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.591957811470007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:13 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 519][Wall Clock 57.873749121s] Trained 128 records in 0.088162859 seconds. Throughput is 1451.8585 records/second. Loss is 2.2570534. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.587615283267457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 6528/60000][Iteration 520][Wall Clock 57.961042941s] Trained 128 records in 0.08729382 seconds. Throughput is 1466.3123 records/second. Loss is 2.2593257. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.583278472679394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 521][Wall Clock 58.055255571s] Trained 128 records in 0.09421263 seconds. Throughput is 1358.6289 records/second. Loss is 2.2650194. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.578947368421052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 6784/60000][Iteration 522][Wall Clock 58.152086678s] Trained 128 records in 0.096831107 seconds. Throughput is 1321.8893 records/second. Loss is 2.2544641. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.574621959237344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 523][Wall Clock 58.242355526s] Trained 128 records in 0.090268848 seconds. Throughput is 1417.9863 records/second. Loss is 2.2553053. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.57030223390276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 7040/60000][Iteration 524][Wall Clock 58.331204998s] Trained 128 records in 0.088849472 seconds. Throughput is 1440.6389 records/second. Loss is 2.2719574. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.565988181221273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 525][Wall Clock 58.417973365s] Trained 128 records in 0.086768367 seconds. Throughput is 1475.192 records/second. Loss is 2.257644. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.561679790026247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 7296/60000][Iteration 526][Wall Clock 58.505539587s] Trained 128 records in 0.087566222 seconds. Throughput is 1461.7509 records/second. Loss is 2.2594872. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.557377049180328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 527][Wall Clock 58.59924863s] Trained 128 records in 0.093709043 seconds. Throughput is 1365.93 records/second. Loss is 2.2548776. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.55307994757536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 7552/60000][Iteration 528][Wall Clock 58.708243061s] Trained 128 records in 0.108994431 seconds. Throughput is 1174.372 records/second. Loss is 2.2548392. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.548788474132285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:14 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 529][Wall Clock 58.82267964s] Trained 128 records in 0.114436579 seconds. Throughput is 1118.5234 records/second. Loss is 2.2673216. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.544502617801048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 7808/60000][Iteration 530][Wall Clock 58.924386018s] Trained 128 records in 0.101706378 seconds. Throughput is 1258.5248 records/second. Loss is 2.2596335. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.540222367560497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 531][Wall Clock 59.012639679s] Trained 128 records in 0.088253661 seconds. Throughput is 1450.3647 records/second. Loss is 2.2643447. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.5359477124183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8064/60000][Iteration 532][Wall Clock 59.103893145s] Trained 128 records in 0.091253466 seconds. Throughput is 1402.6864 records/second. Loss is 2.2634118. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.531678641410842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 533][Wall Clock 59.200400138s] Trained 128 records in 0.096506993 seconds. Throughput is 1326.3287 records/second. Loss is 2.2680962. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.527415143603133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8320/60000][Iteration 534][Wall Clock 59.314817897s] Trained 128 records in 0.114417759 seconds. Throughput is 1118.7074 records/second. Loss is 2.275536. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.523157208088716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 535][Wall Clock 59.416026412s] Trained 128 records in 0.101208515 seconds. Throughput is 1264.7157 records/second. Loss is 2.2603903. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.51890482398957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8576/60000][Iteration 536][Wall Clock 59.518413726s] Trained 128 records in 0.102387314 seconds. Throughput is 1250.1549 records/second. Loss is 2.265567. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.514657980456025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 537][Wall Clock 59.607010029s] Trained 128 records in 0.088596303 seconds. Throughput is 1444.7556 records/second. Loss is 2.2655623. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.510416666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8832/60000][Iteration 538][Wall Clock 59.711653585s] Trained 128 records in 0.104643556 seconds. Throughput is 1223.2001 records/second. Loss is 2.2815442. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.506180871828237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 539][Wall Clock 59.802259132s] Trained 128 records in 0.090605547 seconds. Throughput is 1412.717 records/second. Loss is 2.2622201. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.501950585175553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:15 INFO  DistriOptimizer$:408 - [Epoch 2 9088/60000][Iteration 540][Wall Clock 59.888281783s] Trained 128 records in 0.086022651 seconds. Throughput is 1487.9801 records/second. Loss is 2.2715132. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.49772579597141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 541][Wall Clock 59.974902207s] Trained 128 records in 0.086620424 seconds. Throughput is 1477.7114 records/second. Loss is 2.2696776. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.493506493506494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9344/60000][Iteration 542][Wall Clock 60.06853338s] Trained 128 records in 0.093631173 seconds. Throughput is 1367.0662 records/second. Loss is 2.269154. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.489292667099287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 543][Wall Clock 60.164579613s] Trained 128 records in 0.096046233 seconds. Throughput is 1332.6915 records/second. Loss is 2.2612019. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.485084306095979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9600/60000][Iteration 544][Wall Clock 60.253700362s] Trained 128 records in 0.089120749 seconds. Throughput is 1436.2537 records/second. Loss is 2.2599254. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.480881399870381E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 545][Wall Clock 60.343009866s] Trained 128 records in 0.089309504 seconds. Throughput is 1433.2181 records/second. Loss is 2.272048. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.476683937823834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9856/60000][Iteration 546][Wall Clock 60.432903862s] Trained 128 records in 0.089893996 seconds. Throughput is 1423.8993 records/second. Loss is 2.2496717. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.472491909385113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 547][Wall Clock 60.535625773s] Trained 128 records in 0.102721911 seconds. Throughput is 1246.0826 records/second. Loss is 2.2582896. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.468305304010349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 10112/60000][Iteration 548][Wall Clock 60.646460165s] Trained 128 records in 0.110834392 seconds. Throughput is 1154.8762 records/second. Loss is 2.2549672. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.464124111182935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 549][Wall Clock 60.743431792s] Trained 128 records in 0.096971627 seconds. Throughput is 1319.9738 records/second. Loss is 2.2621331. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.459948320413437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:16 INFO  DistriOptimizer$:408 - [Epoch 2 10368/60000][Iteration 550][Wall Clock 60.855426288s] Trained 128 records in 0.111994496 seconds. Throughput is 1142.9133 records/second. Loss is 2.2468174. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.45577792123951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 551][Wall Clock 60.946105069s] Trained 128 records in 0.090678781 seconds. Throughput is 1411.576 records/second. Loss is 2.2578757. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.451612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 10624/60000][Iteration 552][Wall Clock 61.03345513s] Trained 128 records in 0.087350061 seconds. Throughput is 1465.3682 records/second. Loss is 2.257157. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.447453255963893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 553][Wall Clock 61.121046899s] Trained 128 records in 0.087591769 seconds. Throughput is 1461.3246 records/second. Loss is 2.2688007. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.443298969072165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 10880/60000][Iteration 554][Wall Clock 61.213627401s] Trained 128 records in 0.092580502 seconds. Throughput is 1382.5804 records/second. Loss is 2.2549686. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.439150032195751E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 555][Wall Clock 61.304220746s] Trained 128 records in 0.090593345 seconds. Throughput is 1412.9073 records/second. Loss is 2.26822. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.435006435006435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11136/60000][Iteration 556][Wall Clock 61.389679555s] Trained 128 records in 0.085458809 seconds. Throughput is 1497.7976 records/second. Loss is 2.2581208. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.430868167202571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 557][Wall Clock 61.475782606s] Trained 128 records in 0.086103051 seconds. Throughput is 1486.5907 records/second. Loss is 2.2584312. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.426735218508997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11392/60000][Iteration 558][Wall Clock 61.562628329s] Trained 128 records in 0.086845723 seconds. Throughput is 1473.8779 records/second. Loss is 2.2556348. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.422607578676943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 559][Wall Clock 61.645812613s] Trained 128 records in 0.083184284 seconds. Throughput is 1538.7522 records/second. Loss is 2.259253. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.418485237483953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11648/60000][Iteration 560][Wall Clock 61.73311351s] Trained 128 records in 0.087300897 seconds. Throughput is 1466.1934 records/second. Loss is 2.2591782. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.414368184733803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:17 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 561][Wall Clock 61.818338041s] Trained 128 records in 0.085224531 seconds. Throughput is 1501.9149 records/second. Loss is 2.2649302. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.41025641025641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 11904/60000][Iteration 562][Wall Clock 61.905121153s] Trained 128 records in 0.086783112 seconds. Throughput is 1474.9414 records/second. Loss is 2.256061. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.406149903907752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 563][Wall Clock 62.00478439s] Trained 128 records in 0.099663237 seconds. Throughput is 1284.3252 records/second. Loss is 2.2557025. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.402048655569782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12160/60000][Iteration 564][Wall Clock 62.102182109s] Trained 128 records in 0.097397719 seconds. Throughput is 1314.1991 records/second. Loss is 2.2578065. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.397952655150352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 565][Wall Clock 62.201864798s] Trained 128 records in 0.099682689 seconds. Throughput is 1284.0745 records/second. Loss is 2.2591221. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.39386189258312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12416/60000][Iteration 566][Wall Clock 62.308633313s] Trained 128 records in 0.106768515 seconds. Throughput is 1198.8552 records/second. Loss is 2.2631857. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.389776357827476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 567][Wall Clock 62.395996926s] Trained 128 records in 0.087363613 seconds. Throughput is 1465.1409 records/second. Loss is 2.2578115. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.385696040868455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12672/60000][Iteration 568][Wall Clock 62.485412693s] Trained 128 records in 0.089415767 seconds. Throughput is 1431.5149 records/second. Loss is 2.2661452. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.381620931716655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 569][Wall Clock 62.577373793s] Trained 128 records in 0.0919611 seconds. Throughput is 1391.8928 records/second. Loss is 2.256611. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.377551020408163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 12928/60000][Iteration 570][Wall Clock 62.665753327s] Trained 128 records in 0.088379534 seconds. Throughput is 1448.2992 records/second. Loss is 2.250687. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.373486297004462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 571][Wall Clock 62.751456453s] Trained 128 records in 0.085703126 seconds. Throughput is 1493.5277 records/second. Loss is 2.267363. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.369426751592356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:18 INFO  DistriOptimizer$:408 - [Epoch 2 13184/60000][Iteration 572][Wall Clock 62.857797758s] Trained 128 records in 0.106341305 seconds. Throughput is 1203.6715 records/second. Loss is 2.2746985. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.365372374283895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 573][Wall Clock 62.940217688s] Trained 128 records in 0.08241993 seconds. Throughput is 1553.0223 records/second. Loss is 2.27738. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.361323155216284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 13440/60000][Iteration 574][Wall Clock 63.029070012s] Trained 128 records in 0.088852324 seconds. Throughput is 1440.5927 records/second. Loss is 2.2535179. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.357279084551812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 575][Wall Clock 63.118028908s] Trained 128 records in 0.088958896 seconds. Throughput is 1438.8668 records/second. Loss is 2.2549489. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.353240152477764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 13696/60000][Iteration 576][Wall Clock 63.207067803s] Trained 128 records in 0.089038895 seconds. Throughput is 1437.574 records/second. Loss is 2.261946. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.349206349206348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 577][Wall Clock 63.295496423s] Trained 128 records in 0.08842862 seconds. Throughput is 1447.4952 records/second. Loss is 2.254118. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.345177664974619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 13952/60000][Iteration 578][Wall Clock 63.387756673s] Trained 128 records in 0.09226025 seconds. Throughput is 1387.3798 records/second. Loss is 2.2533078. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.341154090044388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 579][Wall Clock 63.475255429s] Trained 128 records in 0.087498756 seconds. Throughput is 1462.8779 records/second. Loss is 2.255113. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.337135614702155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 14208/60000][Iteration 580][Wall Clock 63.567429334s] Trained 128 records in 0.092173905 seconds. Throughput is 1388.6793 records/second. Loss is 2.2605438. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.333122229259025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 581][Wall Clock 63.655320205s] Trained 128 records in 0.087890871 seconds. Throughput is 1456.3514 records/second. Loss is 2.253145. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.329113924050633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 14464/60000][Iteration 582][Wall Clock 63.743284198s] Trained 128 records in 0.087963993 seconds. Throughput is 1455.1409 records/second. Loss is 2.2515075. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.325110689437065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:19 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 583][Wall Clock 63.83047953s] Trained 128 records in 0.087195332 seconds. Throughput is 1467.9685 records/second. Loss is 2.2586854. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.321112515802782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 14720/60000][Iteration 584][Wall Clock 63.916985016s] Trained 128 records in 0.086505486 seconds. Throughput is 1479.6749 records/second. Loss is 2.26225. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.317119393556539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 585][Wall Clock 64.004252714s] Trained 128 records in 0.087267698 seconds. Throughput is 1466.7512 records/second. Loss is 2.262747. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.313131313131313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 14976/60000][Iteration 586][Wall Clock 64.091303889s] Trained 128 records in 0.087051175 seconds. Throughput is 1470.3994 records/second. Loss is 2.2514052. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.309148264984228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 587][Wall Clock 64.179590191s] Trained 128 records in 0.088286302 seconds. Throughput is 1449.8285 records/second. Loss is 2.2613685. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.30517023959647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15232/60000][Iteration 588][Wall Clock 64.279483571s] Trained 128 records in 0.09989338 seconds. Throughput is 1281.3661 records/second. Loss is 2.2547522. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.30119722747322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 589][Wall Clock 64.377990344s] Trained 128 records in 0.098506773 seconds. Throughput is 1299.4031 records/second. Loss is 2.2632844. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.297229219143577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15488/60000][Iteration 590][Wall Clock 64.467695701s] Trained 128 records in 0.089705357 seconds. Throughput is 1426.8937 records/second. Loss is 2.2539566. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.293266205160479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 591][Wall Clock 64.58473496s] Trained 128 records in 0.117039259 seconds. Throughput is 1093.6501 records/second. Loss is 2.2733755. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.28930817610063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15744/60000][Iteration 592][Wall Clock 64.67651992s] Trained 128 records in 0.09178496 seconds. Throughput is 1394.564 records/second. Loss is 2.2698023. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.285355122564425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 593][Wall Clock 64.766253638s] Trained 128 records in 0.089733718 seconds. Throughput is 1426.4426 records/second. Loss is 2.2562308. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.28140703517588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:20 INFO  DistriOptimizer$:408 - [Epoch 2 16000/60000][Iteration 594][Wall Clock 64.857037577s] Trained 128 records in 0.090783939 seconds. Throughput is 1409.941 records/second. Loss is 2.2547736. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.277463904582549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 595][Wall Clock 64.943590752s] Trained 128 records in 0.086553175 seconds. Throughput is 1478.8597 records/second. Loss is 2.2536495. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.273525721455459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16256/60000][Iteration 596][Wall Clock 65.035369719s] Trained 128 records in 0.091778967 seconds. Throughput is 1394.6552 records/second. Loss is 2.256034. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.269592476489029E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 597][Wall Clock 65.135053807s] Trained 128 records in 0.099684088 seconds. Throughput is 1284.0565 records/second. Loss is 2.2612777. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.265664160401002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16512/60000][Iteration 598][Wall Clock 65.224793284s] Trained 128 records in 0.089739477 seconds. Throughput is 1426.3511 records/second. Loss is 2.2599344. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.261740763932373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 599][Wall Clock 65.311610846s] Trained 128 records in 0.086817562 seconds. Throughput is 1474.3561 records/second. Loss is 2.2458265. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.257822277847309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16768/60000][Iteration 600][Wall Clock 65.401803146s] Trained 128 records in 0.0901923 seconds. Throughput is 1419.1898 records/second. Loss is 2.2655835. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.253908692933083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 601][Wall Clock 65.498501611s] Trained 128 records in 0.096698465 seconds. Throughput is 1323.7025 records/second. Loss is 2.2657108. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.25E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 17024/60000][Iteration 602][Wall Clock 65.583991009s] Trained 128 records in 0.085489398 seconds. Throughput is 1497.2616 records/second. Loss is 2.2587266. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.246096189881325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 603][Wall Clock 65.67556083s] Trained 128 records in 0.091569821 seconds. Throughput is 1397.8405 records/second. Loss is 2.2625515. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.24219725343321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 17280/60000][Iteration 604][Wall Clock 65.763411195s] Trained 128 records in 0.087850365 seconds. Throughput is 1457.0231 records/second. Loss is 2.248611. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.238303181534623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:21 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 605][Wall Clock 65.850500392s] Trained 128 records in 0.087089197 seconds. Throughput is 1469.7576 records/second. Loss is 2.2532787. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.234413965087282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 17536/60000][Iteration 606][Wall Clock 65.939824476s] Trained 128 records in 0.089324084 seconds. Throughput is 1432.9841 records/second. Loss is 2.2461972. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.230529595015577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 607][Wall Clock 66.027035707s] Trained 128 records in 0.087211231 seconds. Throughput is 1467.7009 records/second. Loss is 2.2578886. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.226650062266502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 17792/60000][Iteration 608][Wall Clock 66.115463346s] Trained 128 records in 0.088427639 seconds. Throughput is 1447.5112 records/second. Loss is 2.2517793. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.222775357809583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 609][Wall Clock 66.204454596s] Trained 128 records in 0.08899125 seconds. Throughput is 1438.3438 records/second. Loss is 2.2568169. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.218905472636816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18048/60000][Iteration 610][Wall Clock 66.292528669s] Trained 128 records in 0.088074073 seconds. Throughput is 1453.3221 records/second. Loss is 2.254456. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.215040397762586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 611][Wall Clock 66.380190216s] Trained 128 records in 0.087661547 seconds. Throughput is 1460.1613 records/second. Loss is 2.2605288. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.211180124223603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18304/60000][Iteration 612][Wall Clock 66.467690916s] Trained 128 records in 0.0875007 seconds. Throughput is 1462.8455 records/second. Loss is 2.2608726. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.207324643078833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 613][Wall Clock 66.555121742s] Trained 128 records in 0.087430826 seconds. Throughput is 1464.0145 records/second. Loss is 2.263231. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.203473945409429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18560/60000][Iteration 614][Wall Clock 66.655402564s] Trained 128 records in 0.100280822 seconds. Throughput is 1276.4155 records/second. Loss is 2.2584572. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.199628022318661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 615][Wall Clock 66.748280072s] Trained 128 records in 0.092877508 seconds. Throughput is 1378.1593 records/second. Loss is 2.2618837. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.195786864931846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:22 INFO  DistriOptimizer$:408 - [Epoch 2 18816/60000][Iteration 616][Wall Clock 66.834385351s] Trained 128 records in 0.086105279 seconds. Throughput is 1486.5522 records/second. Loss is 2.2662091. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.191950464396285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 617][Wall Clock 66.920765067s] Trained 128 records in 0.086379716 seconds. Throughput is 1481.8293 records/second. Loss is 2.259697. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.188118811881188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19072/60000][Iteration 618][Wall Clock 67.008540337s] Trained 128 records in 0.08777527 seconds. Throughput is 1458.2695 records/second. Loss is 2.262057. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.184291898577613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 619][Wall Clock 67.095902512s] Trained 128 records in 0.087362175 seconds. Throughput is 1465.1649 records/second. Loss is 2.2426593. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.180469715698394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19328/60000][Iteration 620][Wall Clock 67.189299181s] Trained 128 records in 0.093396669 seconds. Throughput is 1370.4985 records/second. Loss is 2.246653. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.176652254478073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 621][Wall Clock 67.277702014s] Trained 128 records in 0.088402833 seconds. Throughput is 1447.9175 records/second. Loss is 2.2487905. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.172839506172839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19584/60000][Iteration 622][Wall Clock 67.37389459s] Trained 128 records in 0.096192576 seconds. Throughput is 1330.6641 records/second. Loss is 2.2612844. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.169031462060457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 623][Wall Clock 67.453760117s] Trained 128 records in 0.079865527 seconds. Throughput is 1602.694 records/second. Loss is 2.2599463. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.165228113440197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19840/60000][Iteration 624][Wall Clock 67.54677578s] Trained 128 records in 0.093015663 seconds. Throughput is 1376.1123 records/second. Loss is 2.2528896. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.161429451632779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 625][Wall Clock 67.641371253s] Trained 128 records in 0.094595473 seconds. Throughput is 1353.1304 records/second. Loss is 2.2547314. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.157635467980296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 20096/60000][Iteration 626][Wall Clock 67.729200514s] Trained 128 records in 0.087829261 seconds. Throughput is 1457.373 records/second. Loss is 2.254717. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.153846153846154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:23 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 627][Wall Clock 67.81630749s] Trained 128 records in 0.087106976 seconds. Throughput is 1469.4575 records/second. Loss is 2.2491996. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.150061500615006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 20352/60000][Iteration 628][Wall Clock 67.92484291s] Trained 128 records in 0.10853542 seconds. Throughput is 1179.3385 records/second. Loss is 2.257958. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.146281499692687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 629][Wall Clock 68.032284629s] Trained 128 records in 0.107441719 seconds. Throughput is 1191.3436 records/second. Loss is 2.2548776. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.142506142506142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 20608/60000][Iteration 630][Wall Clock 68.120426308s] Trained 128 records in 0.088141679 seconds. Throughput is 1452.2074 records/second. Loss is 2.2519765. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.138735420503377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 631][Wall Clock 68.207091914s] Trained 128 records in 0.086665606 seconds. Throughput is 1476.9412 records/second. Loss is 2.2431786. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.134969325153375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 20864/60000][Iteration 632][Wall Clock 68.298258356s] Trained 128 records in 0.091166442 seconds. Throughput is 1404.0254 records/second. Loss is 2.2492836. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.131207847946045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 633][Wall Clock 68.389929317s] Trained 128 records in 0.091670961 seconds. Throughput is 1396.2982 records/second. Loss is 2.2616727. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.127450980392157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 21120/60000][Iteration 634][Wall Clock 68.480049923s] Trained 128 records in 0.090120606 seconds. Throughput is 1420.3188 records/second. Loss is 2.2424662. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.12369871402327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 635][Wall Clock 68.580287623s] Trained 128 records in 0.1002377 seconds. Throughput is 1276.9647 records/second. Loss is 2.2548547. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.119951040391677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 21376/60000][Iteration 636][Wall Clock 68.666926411s] Trained 128 records in 0.086638788 seconds. Throughput is 1477.3983 records/second. Loss is 2.2567194. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.116207951070336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:24 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 637][Wall Clock 68.762994592s] Trained 128 records in 0.096068181 seconds. Throughput is 1332.3871 records/second. Loss is 2.2599335. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.112469437652812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 21632/60000][Iteration 638][Wall Clock 68.873723408s] Trained 128 records in 0.110728816 seconds. Throughput is 1155.9773 records/second. Loss is 2.2532487. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.108735491753207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 639][Wall Clock 68.996236376s] Trained 128 records in 0.122512968 seconds. Throughput is 1044.7874 records/second. Loss is 2.2546432. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.105006105006105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 21888/60000][Iteration 640][Wall Clock 69.11177815s] Trained 128 records in 0.115541774 seconds. Throughput is 1107.8245 records/second. Loss is 2.2524061. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.101281269066504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 641][Wall Clock 69.200168127s] Trained 128 records in 0.088389977 seconds. Throughput is 1448.1279 records/second. Loss is 2.2423854. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.097560975609756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22144/60000][Iteration 642][Wall Clock 69.286857848s] Trained 128 records in 0.086689721 seconds. Throughput is 1476.5304 records/second. Loss is 2.2514634. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.093845216331506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 643][Wall Clock 69.393617503s] Trained 128 records in 0.106759655 seconds. Throughput is 1198.9548 records/second. Loss is 2.2443478. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.090133982947626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22400/60000][Iteration 644][Wall Clock 69.479365302s] Trained 128 records in 0.085747799 seconds. Throughput is 1492.7496 records/second. Loss is 2.239755. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.086427267194157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 645][Wall Clock 69.566481517s] Trained 128 records in 0.087116215 seconds. Throughput is 1469.3018 records/second. Loss is 2.2490954. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.082725060827251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22656/60000][Iteration 646][Wall Clock 69.653539842s] Trained 128 records in 0.087058325 seconds. Throughput is 1470.2787 records/second. Loss is 2.2475138. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.079027355623101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 647][Wall Clock 69.741849433s] Trained 128 records in 0.088309591 seconds. Throughput is 1449.4462 records/second. Loss is 2.2514718. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.075334143377886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:25 INFO  DistriOptimizer$:408 - [Epoch 2 22912/60000][Iteration 648][Wall Clock 69.834887357s] Trained 128 records in 0.093037924 seconds. Throughput is 1375.7831 records/second. Loss is 2.253882. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.071645415907711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 649][Wall Clock 69.924515502s] Trained 128 records in 0.089628145 seconds. Throughput is 1428.1228 records/second. Loss is 2.2503464. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.067961165048543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23168/60000][Iteration 650][Wall Clock 70.012486334s] Trained 128 records in 0.087970832 seconds. Throughput is 1455.0277 records/second. Loss is 2.2435112. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.064281382656155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 651][Wall Clock 70.102569959s] Trained 128 records in 0.090083625 seconds. Throughput is 1420.902 records/second. Loss is 2.251062. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.060606060606061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23424/60000][Iteration 652][Wall Clock 70.191483929s] Trained 128 records in 0.08891397 seconds. Throughput is 1439.5938 records/second. Loss is 2.2673678. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.056935190793458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 653][Wall Clock 70.27717693s] Trained 128 records in 0.085693001 seconds. Throughput is 1493.7042 records/second. Loss is 2.2607071. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.053268765133171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23680/60000][Iteration 654][Wall Clock 70.369059231s] Trained 128 records in 0.091882301 seconds. Throughput is 1393.0865 records/second. Loss is 2.252681. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.049606775559589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 655][Wall Clock 70.455514701s] Trained 128 records in 0.08645547 seconds. Throughput is 1480.5309 records/second. Loss is 2.2478397. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.045949214026603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 23936/60000][Iteration 656][Wall Clock 70.54385495s] Trained 128 records in 0.088340249 seconds. Throughput is 1448.9431 records/second. Loss is 2.2419035. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.042296072507553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 657][Wall Clock 70.634063527s] Trained 128 records in 0.090208577 seconds. Throughput is 1418.9338 records/second. Loss is 2.255824. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.038647342995169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 24192/60000][Iteration 658][Wall Clock 70.722428746s] Trained 128 records in 0.088365219 seconds. Throughput is 1448.5337 records/second. Loss is 2.2600808. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.035003017501509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:26 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 659][Wall Clock 70.81447743s] Trained 128 records in 0.092048684 seconds. Throughput is 1390.5685 records/second. Loss is 2.259255. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.031363088057902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 24448/60000][Iteration 660][Wall Clock 70.906808506s] Trained 128 records in 0.092331076 seconds. Throughput is 1386.3156 records/second. Loss is 2.2610724. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.027727546714888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 661][Wall Clock 71.005303566s] Trained 128 records in 0.09849506 seconds. Throughput is 1299.5576 records/second. Loss is 2.25356. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.024096385542168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 24704/60000][Iteration 662][Wall Clock 71.09775227s] Trained 128 records in 0.092448704 seconds. Throughput is 1384.5516 records/second. Loss is 2.2509174. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.020469596628537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 663][Wall Clock 71.222058017s] Trained 128 records in 0.124305747 seconds. Throughput is 1029.7191 records/second. Loss is 2.2573903. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.016847172081829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 24960/60000][Iteration 664][Wall Clock 71.319128371s] Trained 128 records in 0.097070354 seconds. Throughput is 1318.6312 records/second. Loss is 2.2508125. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.013229104028864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 665][Wall Clock 71.415622191s] Trained 128 records in 0.09649382 seconds. Throughput is 1326.5099 records/second. Loss is 2.2629166. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.009615384615384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 25216/60000][Iteration 666][Wall Clock 71.507091463s] Trained 128 records in 0.091469272 seconds. Throughput is 1399.3771 records/second. Loss is 2.2513955. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.006006006006006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 667][Wall Clock 71.604061302s] Trained 128 records in 0.096969839 seconds. Throughput is 1319.9982 records/second. Loss is 2.2441804. Sequentialdaab25a8's hyper parameters: Current learning rate is 6.002400960384154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 25472/60000][Iteration 668][Wall Clock 71.712075216s] Trained 128 records in 0.108013914 seconds. Throughput is 1185.0325 records/second. Loss is 2.2653039. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.998800239952009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:27 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 669][Wall Clock 71.80918364s] Trained 128 records in 0.097108424 seconds. Throughput is 1318.1143 records/second. Loss is 2.2385721. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.995203836930455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 25728/60000][Iteration 670][Wall Clock 71.899695588s] Trained 128 records in 0.090511948 seconds. Throughput is 1414.178 records/second. Loss is 2.249263. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.991611743559018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 671][Wall Clock 71.987115888s] Trained 128 records in 0.0874203 seconds. Throughput is 1464.1908 records/second. Loss is 2.247953. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.988023952095808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 25984/60000][Iteration 672][Wall Clock 72.079536776s] Trained 128 records in 0.092420888 seconds. Throughput is 1384.9683 records/second. Loss is 2.2533393. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.984440454817474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 673][Wall Clock 72.210560504s] Trained 128 records in 0.131023728 seconds. Throughput is 976.92224 records/second. Loss is 2.2594776. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.980861244019139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26240/60000][Iteration 674][Wall Clock 72.303910024s] Trained 128 records in 0.09334952 seconds. Throughput is 1371.1908 records/second. Loss is 2.2503672. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.977286312014345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 675][Wall Clock 72.393514133s] Trained 128 records in 0.089604109 seconds. Throughput is 1428.5059 records/second. Loss is 2.2476559. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.973715651135007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26496/60000][Iteration 676][Wall Clock 72.486204292s] Trained 128 records in 0.092690159 seconds. Throughput is 1380.9448 records/second. Loss is 2.2527342. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.970149253731343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 677][Wall Clock 72.575720459s] Trained 128 records in 0.089516167 seconds. Throughput is 1429.9093 records/second. Loss is 2.2617362. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.966587112171837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26752/60000][Iteration 678][Wall Clock 72.670173223s] Trained 128 records in 0.094452764 seconds. Throughput is 1355.1748 records/second. Loss is 2.2501678. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.963029218843172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:28 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 679][Wall Clock 72.762357698s] Trained 128 records in 0.092184475 seconds. Throughput is 1388.5201 records/second. Loss is 2.2582297. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.95947556615018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27008/60000][Iteration 680][Wall Clock 72.850162008s] Trained 128 records in 0.08780431 seconds. Throughput is 1457.7872 records/second. Loss is 2.244953. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.955926146515783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 681][Wall Clock 72.938822674s] Trained 128 records in 0.088660666 seconds. Throughput is 1443.7068 records/second. Loss is 2.2505066. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.952380952380952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27264/60000][Iteration 682][Wall Clock 73.027216901s] Trained 128 records in 0.088394227 seconds. Throughput is 1448.0583 records/second. Loss is 2.2416034. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.94883997620464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 683][Wall Clock 73.128025804s] Trained 128 records in 0.100808903 seconds. Throughput is 1269.7291 records/second. Loss is 2.2550943. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.945303210463734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27520/60000][Iteration 684][Wall Clock 73.215914563s] Trained 128 records in 0.087888759 seconds. Throughput is 1456.3865 records/second. Loss is 2.25287. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.941770647653001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 685][Wall Clock 73.306258375s] Trained 128 records in 0.090343812 seconds. Throughput is 1416.8098 records/second. Loss is 2.2566302. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.938242280285035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27776/60000][Iteration 686][Wall Clock 73.395691834s] Trained 128 records in 0.089433459 seconds. Throughput is 1431.2317 records/second. Loss is 2.2518325. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.934718100890207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 687][Wall Clock 73.490002296s] Trained 128 records in 0.094310462 seconds. Throughput is 1357.2195 records/second. Loss is 2.2365909. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.931198102016608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 28032/60000][Iteration 688][Wall Clock 73.589617916s] Trained 128 records in 0.09961562 seconds. Throughput is 1284.9391 records/second. Loss is 2.2658727. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.927682276229994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 689][Wall Clock 73.679054179s] Trained 128 records in 0.089436263 seconds. Throughput is 1431.1868 records/second. Loss is 2.2467349. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.924170616113743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:29 INFO  DistriOptimizer$:408 - [Epoch 2 28288/60000][Iteration 690][Wall Clock 73.779451822s] Trained 128 records in 0.100397643 seconds. Throughput is 1274.9303 records/second. Loss is 2.2531383. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.920663114268798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 691][Wall Clock 73.862138715s] Trained 128 records in 0.082686893 seconds. Throughput is 1548.0083 records/second. Loss is 2.2534258. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.91715976331361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 28544/60000][Iteration 692][Wall Clock 73.943063715s] Trained 128 records in 0.080925 seconds. Throughput is 1581.7114 records/second. Loss is 2.2388256. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.913660555884092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 693][Wall Clock 74.033673304s] Trained 128 records in 0.090609589 seconds. Throughput is 1412.654 records/second. Loss is 2.2619388. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.91016548463357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 28800/60000][Iteration 694][Wall Clock 74.147003467s] Trained 128 records in 0.113330163 seconds. Throughput is 1129.4434 records/second. Loss is 2.2600832. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.906674542232723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 695][Wall Clock 74.259297256s] Trained 128 records in 0.112293789 seconds. Throughput is 1139.8672 records/second. Loss is 2.242992. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.90318772136954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 29056/60000][Iteration 696][Wall Clock 74.373199077s] Trained 128 records in 0.113901821 seconds. Throughput is 1123.7748 records/second. Loss is 2.256071. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.899705014749262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 697][Wall Clock 74.466064114s] Trained 128 records in 0.092865037 seconds. Throughput is 1378.3444 records/second. Loss is 2.2594476. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.896226415094339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 29312/60000][Iteration 698][Wall Clock 74.568807013s] Trained 128 records in 0.102742899 seconds. Throughput is 1245.8282 records/second. Loss is 2.2435708. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.892751915144372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 699][Wall Clock 74.652165913s] Trained 128 records in 0.0833589 seconds. Throughput is 1535.5289 records/second. Loss is 2.244022. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.889281507656067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:30 INFO  DistriOptimizer$:408 - [Epoch 2 29568/60000][Iteration 700][Wall Clock 74.739030018s] Trained 128 records in 0.086864105 seconds. Throughput is 1473.566 records/second. Loss is 2.2471597. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.885815185403178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 701][Wall Clock 74.827699649s] Trained 128 records in 0.088669631 seconds. Throughput is 1443.5608 records/second. Loss is 2.2558162. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.88235294117647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 29824/60000][Iteration 702][Wall Clock 74.914361635s] Trained 128 records in 0.086661986 seconds. Throughput is 1477.0028 records/second. Loss is 2.255997. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.878894767783657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 703][Wall Clock 75.002517262s] Trained 128 records in 0.088155627 seconds. Throughput is 1451.9777 records/second. Loss is 2.2524574. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.875440658049354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30080/60000][Iteration 704][Wall Clock 75.090429509s] Trained 128 records in 0.087912247 seconds. Throughput is 1455.9973 records/second. Loss is 2.2481415. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.871990604815032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 705][Wall Clock 75.178586044s] Trained 128 records in 0.088156535 seconds. Throughput is 1451.9626 records/second. Loss is 2.2477095. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.868544600938967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30336/60000][Iteration 706][Wall Clock 75.266693445s] Trained 128 records in 0.088107401 seconds. Throughput is 1452.7725 records/second. Loss is 2.2456381. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.865102639296188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 707][Wall Clock 75.352393958s] Trained 128 records in 0.085700513 seconds. Throughput is 1493.5734 records/second. Loss is 2.2499099. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.86166471277843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30592/60000][Iteration 708][Wall Clock 75.440440753s] Trained 128 records in 0.088046795 seconds. Throughput is 1453.7723 records/second. Loss is 2.2468386. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.858230814294084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 709][Wall Clock 75.52794097s] Trained 128 records in 0.087500217 seconds. Throughput is 1462.8535 records/second. Loss is 2.24801. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.85480093676815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30848/60000][Iteration 710][Wall Clock 75.615540169s] Trained 128 records in 0.087599199 seconds. Throughput is 1461.2007 records/second. Loss is 2.2411866. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.851375073142189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 711][Wall Clock 75.707519215s] Trained 128 records in 0.091979046 seconds. Throughput is 1391.6212 records/second. Loss is 2.247495. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.847953216374269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:31 INFO  DistriOptimizer$:408 - [Epoch 2 31104/60000][Iteration 712][Wall Clock 75.810392542s] Trained 128 records in 0.102873327 seconds. Throughput is 1244.2487 records/second. Loss is 2.2530875. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.844535359438925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 713][Wall Clock 75.90241184s] Trained 128 records in 0.092019298 seconds. Throughput is 1391.0126 records/second. Loss is 2.2530482. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.841121495327103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 31360/60000][Iteration 714][Wall Clock 75.990885187s] Trained 128 records in 0.088473347 seconds. Throughput is 1446.7633 records/second. Loss is 2.2355103. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.837711617046118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 715][Wall Clock 76.086960242s] Trained 128 records in 0.096075055 seconds. Throughput is 1332.2916 records/second. Loss is 2.2557304. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.834305717619604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 31616/60000][Iteration 716][Wall Clock 76.191918695s] Trained 128 records in 0.104958453 seconds. Throughput is 1219.5302 records/second. Loss is 2.2461061. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.830903790087465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 717][Wall Clock 76.270549908s] Trained 128 records in 0.078631213 seconds. Throughput is 1627.8523 records/second. Loss is 2.2490363. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.827505827505828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 31872/60000][Iteration 718][Wall Clock 76.348240832s] Trained 128 records in 0.077690924 seconds. Throughput is 1647.5542 records/second. Loss is 2.245291. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.824111822947001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 719][Wall Clock 76.436259087s] Trained 128 records in 0.088018255 seconds. Throughput is 1454.2438 records/second. Loss is 2.2448242. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.820721769499418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 32128/60000][Iteration 720][Wall Clock 76.521509745s] Trained 128 records in 0.085250658 seconds. Throughput is 1501.4546 records/second. Loss is 2.2415817. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.817335660267598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 721][Wall Clock 76.606160024s] Trained 128 records in 0.084650279 seconds. Throughput is 1512.1038 records/second. Loss is 2.239761. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.813953488372093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 32384/60000][Iteration 722][Wall Clock 76.698086957s] Trained 128 records in 0.091926933 seconds. Throughput is 1392.4103 records/second. Loss is 2.2456508. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.810575246949448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:32 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 723][Wall Clock 76.782097828s] Trained 128 records in 0.084010871 seconds. Throughput is 1523.6124 records/second. Loss is 2.2391937. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.807200929152149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 32640/60000][Iteration 724][Wall Clock 76.873892828s] Trained 128 records in 0.091795 seconds. Throughput is 1394.4115 records/second. Loss is 2.2291965. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.803830528148578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 725][Wall Clock 76.960831636s] Trained 128 records in 0.086938808 seconds. Throughput is 1472.2999 records/second. Loss is 2.249119. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.80046403712297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 32896/60000][Iteration 726][Wall Clock 77.048982863s] Trained 128 records in 0.088151227 seconds. Throughput is 1452.0502 records/second. Loss is 2.2429974. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.797101449275362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 727][Wall Clock 77.140408825s] Trained 128 records in 0.091425962 seconds. Throughput is 1400.0399 records/second. Loss is 2.2481263. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.793742757821553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33152/60000][Iteration 728][Wall Clock 77.230936567s] Trained 128 records in 0.090527742 seconds. Throughput is 1413.9312 records/second. Loss is 2.2585585. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.790387955993052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 729][Wall Clock 77.31947334s] Trained 128 records in 0.088536773 seconds. Throughput is 1445.7269 records/second. Loss is 2.2512934. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.787037037037037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33408/60000][Iteration 730][Wall Clock 77.408078513s] Trained 128 records in 0.088605173 seconds. Throughput is 1444.611 records/second. Loss is 2.2535288. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.78368999421631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 731][Wall Clock 77.494866713s] Trained 128 records in 0.0867882 seconds. Throughput is 1474.8549 records/second. Loss is 2.2409601. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.780346820809249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33664/60000][Iteration 732][Wall Clock 77.580241711s] Trained 128 records in 0.085374998 seconds. Throughput is 1499.268 records/second. Loss is 2.2373953. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.777007510109764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 733][Wall Clock 77.667892802s] Trained 128 records in 0.087651091 seconds. Throughput is 1460.3356 records/second. Loss is 2.2502859. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.773672055427252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:33 INFO  DistriOptimizer$:408 - [Epoch 2 33920/60000][Iteration 734][Wall Clock 77.756348546s] Trained 128 records in 0.088455744 seconds. Throughput is 1447.0513 records/second. Loss is 2.2504265. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.770340450086555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 735][Wall Clock 77.844461882s] Trained 128 records in 0.088113336 seconds. Throughput is 1452.6746 records/second. Loss is 2.2387037. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.767012687427913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34176/60000][Iteration 736][Wall Clock 77.932056748s] Trained 128 records in 0.087594866 seconds. Throughput is 1461.2728 records/second. Loss is 2.249204. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.763688760806917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 737][Wall Clock 78.019297678s] Trained 128 records in 0.08724093 seconds. Throughput is 1467.2013 records/second. Loss is 2.2517176. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.76036866359447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34432/60000][Iteration 738][Wall Clock 78.10605247s] Trained 128 records in 0.086754792 seconds. Throughput is 1475.4229 records/second. Loss is 2.2562788. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.757052389176741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 739][Wall Clock 78.192793514s] Trained 128 records in 0.086741044 seconds. Throughput is 1475.6566 records/second. Loss is 2.2576833. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.753739930955121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34688/60000][Iteration 740][Wall Clock 78.279119098s] Trained 128 records in 0.086325584 seconds. Throughput is 1482.7585 records/second. Loss is 2.2526858. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.750431282346176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 741][Wall Clock 78.382422463s] Trained 128 records in 0.103303365 seconds. Throughput is 1239.069 records/second. Loss is 2.236885. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.747126436781609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 34944/60000][Iteration 742][Wall Clock 78.467903635s] Trained 128 records in 0.085481172 seconds. Throughput is 1497.4058 records/second. Loss is 2.2506037. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.743825387708214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 743][Wall Clock 78.545856102s] Trained 128 records in 0.077952467 seconds. Throughput is 1642.0262 records/second. Loss is 2.2437258. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.74052812858783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 35200/60000][Iteration 744][Wall Clock 78.638209294s] Trained 128 records in 0.092353192 seconds. Throughput is 1385.9834 records/second. Loss is 2.2455728. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.737234652897304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:34 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 745][Wall Clock 78.727299263s] Trained 128 records in 0.089089969 seconds. Throughput is 1436.7499 records/second. Loss is 2.2534375. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.733944954128441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 35456/60000][Iteration 746][Wall Clock 78.816189401s] Trained 128 records in 0.088890138 seconds. Throughput is 1439.9799 records/second. Loss is 2.2498372. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.730659025787965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 747][Wall Clock 78.907966842s] Trained 128 records in 0.091777441 seconds. Throughput is 1394.6782 records/second. Loss is 2.2510173. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.72737686139748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 35712/60000][Iteration 748][Wall Clock 78.995884888s] Trained 128 records in 0.087918046 seconds. Throughput is 1455.9014 records/second. Loss is 2.2391868. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.724098454493418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 749][Wall Clock 79.094805345s] Trained 128 records in 0.098920457 seconds. Throughput is 1293.969 records/second. Loss is 2.2494402. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.720823798627002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 35968/60000][Iteration 750][Wall Clock 79.178066139s] Trained 128 records in 0.083260794 seconds. Throughput is 1537.3381 records/second. Loss is 2.2503679. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.717552887364208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 751][Wall Clock 79.268427761s] Trained 128 records in 0.090361622 seconds. Throughput is 1416.5305 records/second. Loss is 2.2474318. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.714285714285715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 36224/60000][Iteration 752][Wall Clock 79.365822536s] Trained 128 records in 0.097394775 seconds. Throughput is 1314.2389 records/second. Loss is 2.251201. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.711022272986865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 753][Wall Clock 79.452427524s] Trained 128 records in 0.086604988 seconds. Throughput is 1477.9749 records/second. Loss is 2.2444818. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.707762557077625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 36480/60000][Iteration 754][Wall Clock 79.538464712s] Trained 128 records in 0.086037188 seconds. Throughput is 1487.7288 records/second. Loss is 2.2555823. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.704506560182544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 755][Wall Clock 79.631086207s] Trained 128 records in 0.092621495 seconds. Throughput is 1381.9686 records/second. Loss is 2.2501612. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.701254275940707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:35 INFO  DistriOptimizer$:408 - [Epoch 2 36736/60000][Iteration 756][Wall Clock 79.717254282s] Trained 128 records in 0.086168075 seconds. Throughput is 1485.469 records/second. Loss is 2.2509637. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.698005698005699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 757][Wall Clock 79.805013457s] Trained 128 records in 0.087759175 seconds. Throughput is 1458.537 records/second. Loss is 2.2510843. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.694760820045558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 36992/60000][Iteration 758][Wall Clock 79.891785673s] Trained 128 records in 0.086772216 seconds. Throughput is 1475.1265 records/second. Loss is 2.2450895. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.691519635742744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 759][Wall Clock 79.983436913s] Trained 128 records in 0.09165124 seconds. Throughput is 1396.5988 records/second. Loss is 2.2444088. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.688282138794084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37248/60000][Iteration 760][Wall Clock 80.075446326s] Trained 128 records in 0.092009413 seconds. Throughput is 1391.1621 records/second. Loss is 2.2509878. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.685048322910746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 761][Wall Clock 80.165097809s] Trained 128 records in 0.089651483 seconds. Throughput is 1427.7511 records/second. Loss is 2.2499933. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.681818181818182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37504/60000][Iteration 762][Wall Clock 80.256679728s] Trained 128 records in 0.091581919 seconds. Throughput is 1397.6558 records/second. Loss is 2.249717. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.678591709256105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 763][Wall Clock 80.348495406s] Trained 128 records in 0.091815678 seconds. Throughput is 1394.0974 records/second. Loss is 2.250345. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.675368898978433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37760/60000][Iteration 764][Wall Clock 80.443939774s] Trained 128 records in 0.095444368 seconds. Throughput is 1341.0953 records/second. Loss is 2.2578266. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.672149744753262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 765][Wall Clock 80.535108529s] Trained 128 records in 0.091168755 seconds. Throughput is 1403.9897 records/second. Loss is 2.2373433. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.668934240362812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 38016/60000][Iteration 766][Wall Clock 80.623417102s] Trained 128 records in 0.088308573 seconds. Throughput is 1449.4629 records/second. Loss is 2.2344668. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.665722379603399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:36 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 767][Wall Clock 80.71976165s] Trained 128 records in 0.096344548 seconds. Throughput is 1328.5651 records/second. Loss is 2.2321622. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.662514156285391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 38272/60000][Iteration 768][Wall Clock 80.833091986s] Trained 128 records in 0.113330336 seconds. Throughput is 1129.4417 records/second. Loss is 2.2468033. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.659309564233164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 769][Wall Clock 80.913145047s] Trained 128 records in 0.080053061 seconds. Throughput is 1598.9395 records/second. Loss is 2.2514992. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.656108597285068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 38528/60000][Iteration 770][Wall Clock 81.005600604s] Trained 128 records in 0.092455557 seconds. Throughput is 1384.449 records/second. Loss is 2.2437022. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.652911249293386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 771][Wall Clock 81.092181536s] Trained 128 records in 0.086580932 seconds. Throughput is 1478.3856 records/second. Loss is 2.2489896. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.649717514124294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 38784/60000][Iteration 772][Wall Clock 81.180479221s] Trained 128 records in 0.088297685 seconds. Throughput is 1449.6416 records/second. Loss is 2.2348468. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.646527385657821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 773][Wall Clock 81.267366704s] Trained 128 records in 0.086887483 seconds. Throughput is 1473.1696 records/second. Loss is 2.247478. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.64334085778781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 39040/60000][Iteration 774][Wall Clock 81.355753913s] Trained 128 records in 0.088387209 seconds. Throughput is 1448.1733 records/second. Loss is 2.2476492. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.640157924421883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 775][Wall Clock 81.449555616s] Trained 128 records in 0.093801703 seconds. Throughput is 1364.5808 records/second. Loss is 2.250254. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.636978579481398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 39296/60000][Iteration 776][Wall Clock 81.53560852s] Trained 128 records in 0.086052904 seconds. Throughput is 1487.4572 records/second. Loss is 2.2421808. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.633802816901409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 777][Wall Clock 81.621384921s] Trained 128 records in 0.085776401 seconds. Throughput is 1492.2518 records/second. Loss is 2.2423136. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.630630630630631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:37 INFO  DistriOptimizer$:408 - [Epoch 2 39552/60000][Iteration 778][Wall Clock 81.707217056s] Trained 128 records in 0.085832135 seconds. Throughput is 1491.283 records/second. Loss is 2.24495. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.6274620146314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 779][Wall Clock 81.7969143s] Trained 128 records in 0.089697244 seconds. Throughput is 1427.0227 records/second. Loss is 2.244412. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.624296962879641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 39808/60000][Iteration 780][Wall Clock 81.883978323s] Trained 128 records in 0.087064023 seconds. Throughput is 1470.1825 records/second. Loss is 2.2239034. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.621135469364812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 781][Wall Clock 81.969234944s] Trained 128 records in 0.085256621 seconds. Throughput is 1501.3496 records/second. Loss is 2.2481534. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.617977528089888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40064/60000][Iteration 782][Wall Clock 82.055621s] Trained 128 records in 0.086386056 seconds. Throughput is 1481.7206 records/second. Loss is 2.2296705. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.614823133071308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 783][Wall Clock 82.143616544s] Trained 128 records in 0.087995544 seconds. Throughput is 1454.6191 records/second. Loss is 2.2488358. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.611672278338945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40320/60000][Iteration 784][Wall Clock 82.230833861s] Trained 128 records in 0.087217317 seconds. Throughput is 1467.5985 records/second. Loss is 2.2380922. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.608524957936063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 785][Wall Clock 82.319210708s] Trained 128 records in 0.088376847 seconds. Throughput is 1448.3431 records/second. Loss is 2.2528992. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.605381165919282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40576/60000][Iteration 786][Wall Clock 82.410638744s] Trained 128 records in 0.091428036 seconds. Throughput is 1400.0082 records/second. Loss is 2.2466588. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.602240896358543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 787][Wall Clock 82.499161241s] Trained 128 records in 0.088522497 seconds. Throughput is 1445.9602 records/second. Loss is 2.24661. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.599104143337066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40832/60000][Iteration 788][Wall Clock 82.58948968s] Trained 128 records in 0.090328439 seconds. Throughput is 1417.0509 records/second. Loss is 2.242116. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.595970900951316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 789][Wall Clock 82.677092067s] Trained 128 records in 0.087602387 seconds. Throughput is 1461.1475 records/second. Loss is 2.238356. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.592841163310962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:38 INFO  DistriOptimizer$:408 - [Epoch 2 41088/60000][Iteration 790][Wall Clock 82.765397258s] Trained 128 records in 0.088305191 seconds. Throughput is 1449.5184 records/second. Loss is 2.248222. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.589714924538849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 791][Wall Clock 82.853587637s] Trained 128 records in 0.088190379 seconds. Throughput is 1451.4055 records/second. Loss is 2.2402546. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.586592178770949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41344/60000][Iteration 792][Wall Clock 82.951760916s] Trained 128 records in 0.098173279 seconds. Throughput is 1303.8171 records/second. Loss is 2.2441368. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.583472920156337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 793][Wall Clock 83.039257585s] Trained 128 records in 0.087496669 seconds. Throughput is 1462.9128 records/second. Loss is 2.2532978. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.580357142857143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41600/60000][Iteration 794][Wall Clock 83.130263545s] Trained 128 records in 0.09100596 seconds. Throughput is 1406.5013 records/second. Loss is 2.2384853. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.577244841048521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 795][Wall Clock 83.231144575s] Trained 128 records in 0.10088103 seconds. Throughput is 1268.8213 records/second. Loss is 2.2479665. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.574136008918618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41856/60000][Iteration 796][Wall Clock 83.324415705s] Trained 128 records in 0.09327113 seconds. Throughput is 1372.3433 records/second. Loss is 2.2307513. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.571030640668524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 797][Wall Clock 83.415845112s] Trained 128 records in 0.091429407 seconds. Throughput is 1399.9872 records/second. Loss is 2.249952. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.567928730512249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 42112/60000][Iteration 798][Wall Clock 83.50398894s] Trained 128 records in 0.088143828 seconds. Throughput is 1452.172 records/second. Loss is 2.244476. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.564830272676684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 799][Wall Clock 83.592377141s] Trained 128 records in 0.088388201 seconds. Throughput is 1448.157 records/second. Loss is 2.237871. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.561735261401557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 42368/60000][Iteration 800][Wall Clock 83.684506279s] Trained 128 records in 0.092129138 seconds. Throughput is 1389.3541 records/second. Loss is 2.2585504. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.558643690939412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:39 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 801][Wall Clock 83.764775863s] Trained 128 records in 0.080269584 seconds. Throughput is 1594.6265 records/second. Loss is 2.2466226. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.555555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 42624/60000][Iteration 802][Wall Clock 83.850075215s] Trained 128 records in 0.085299352 seconds. Throughput is 1500.5977 records/second. Loss is 2.2500472. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.552470849528039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 803][Wall Clock 83.940007087s] Trained 128 records in 0.089931872 seconds. Throughput is 1423.2996 records/second. Loss is 2.252034. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.549389567147614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 42880/60000][Iteration 804][Wall Clock 84.02915851s] Trained 128 records in 0.089151423 seconds. Throughput is 1435.7595 records/second. Loss is 2.232665. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.546311702717693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 805][Wall Clock 84.114423922s] Trained 128 records in 0.085265412 seconds. Throughput is 1501.1948 records/second. Loss is 2.2476962. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.543237250554324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43136/60000][Iteration 806][Wall Clock 84.201855659s] Trained 128 records in 0.087431737 seconds. Throughput is 1463.9993 records/second. Loss is 2.248392. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.540166204986149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 807][Wall Clock 84.291158783s] Trained 128 records in 0.089303124 seconds. Throughput is 1433.3206 records/second. Loss is 2.246113. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.537098560354374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43392/60000][Iteration 808][Wall Clock 84.379795477s] Trained 128 records in 0.088636694 seconds. Throughput is 1444.0972 records/second. Loss is 2.247497. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.534034311012729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 809][Wall Clock 84.465692059s] Trained 128 records in 0.085896582 seconds. Throughput is 1490.1641 records/second. Loss is 2.2563932. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.530973451327434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43648/60000][Iteration 810][Wall Clock 84.554561507s] Trained 128 records in 0.088869448 seconds. Throughput is 1440.3151 records/second. Loss is 2.2431927. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.52791597567717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 811][Wall Clock 84.650670672s] Trained 128 records in 0.096109165 seconds. Throughput is 1331.8188 records/second. Loss is 2.247251. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.524861878453039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:40 INFO  DistriOptimizer$:408 - [Epoch 2 43904/60000][Iteration 812][Wall Clock 84.73942966s] Trained 128 records in 0.088758988 seconds. Throughput is 1442.1074 records/second. Loss is 2.2436392. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.521811154058532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 813][Wall Clock 84.82728105s] Trained 128 records in 0.08785139 seconds. Throughput is 1457.006 records/second. Loss is 2.242011. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.518763796909492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44160/60000][Iteration 814][Wall Clock 84.915854975s] Trained 128 records in 0.088573925 seconds. Throughput is 1445.1206 records/second. Loss is 2.2443855. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.515719801434087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 815][Wall Clock 85.004283376s] Trained 128 records in 0.088428401 seconds. Throughput is 1447.4988 records/second. Loss is 2.24623. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.512679162072767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44416/60000][Iteration 816][Wall Clock 85.092217433s] Trained 128 records in 0.087934057 seconds. Throughput is 1455.6362 records/second. Loss is 2.254688. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.509641873278238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 817][Wall Clock 85.18395513s] Trained 128 records in 0.091737697 seconds. Throughput is 1395.2825 records/second. Loss is 2.2466097. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.506607929515418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44672/60000][Iteration 818][Wall Clock 85.28210932s] Trained 128 records in 0.09815419 seconds. Throughput is 1304.0707 records/second. Loss is 2.2360847. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.50357732526142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 819][Wall Clock 85.361783717s] Trained 128 records in 0.079674397 seconds. Throughput is 1606.5386 records/second. Loss is 2.2375178. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.5005500550055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 44928/60000][Iteration 820][Wall Clock 85.444308551s] Trained 128 records in 0.082524834 seconds. Throughput is 1551.0482 records/second. Loss is 2.2361705. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.497526113249038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 821][Wall Clock 85.531100775s] Trained 128 records in 0.086792224 seconds. Throughput is 1474.7865 records/second. Loss is 2.2417157. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.494505494505495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 45184/60000][Iteration 822][Wall Clock 85.618388775s] Trained 128 records in 0.087288 seconds. Throughput is 1466.41 records/second. Loss is 2.229843. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.491488193300384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:41 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 823][Wall Clock 85.70910746s] Trained 128 records in 0.090718685 seconds. Throughput is 1410.9552 records/second. Loss is 2.2505927. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.488474204171241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 45440/60000][Iteration 824][Wall Clock 85.79445245s] Trained 128 records in 0.08534499 seconds. Throughput is 1499.795 records/second. Loss is 2.243744. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.485463521667581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 825][Wall Clock 85.881762429s] Trained 128 records in 0.087309979 seconds. Throughput is 1466.0409 records/second. Loss is 2.2340255. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.482456140350877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 45696/60000][Iteration 826][Wall Clock 85.984908397s] Trained 128 records in 0.103145968 seconds. Throughput is 1240.9598 records/second. Loss is 2.2489855. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.47945205479452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 827][Wall Clock 86.079472574s] Trained 128 records in 0.094564177 seconds. Throughput is 1353.5781 records/second. Loss is 2.2388458. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.47645125958379E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 45952/60000][Iteration 828][Wall Clock 86.169718583s] Trained 128 records in 0.090246009 seconds. Throughput is 1418.3453 records/second. Loss is 2.2391822. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.473453749315818E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 829][Wall Clock 86.263309237s] Trained 128 records in 0.093590654 seconds. Throughput is 1367.658 records/second. Loss is 2.246979. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.470459518599562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 46208/60000][Iteration 830][Wall Clock 86.353938319s] Trained 128 records in 0.090629082 seconds. Throughput is 1412.3502 records/second. Loss is 2.2510822. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.467468562055768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 831][Wall Clock 86.441085132s] Trained 128 records in 0.087146813 seconds. Throughput is 1468.7858 records/second. Loss is 2.230283. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.46448087431694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 46464/60000][Iteration 832][Wall Clock 86.527523256s] Trained 128 records in 0.086438124 seconds. Throughput is 1480.828 records/second. Loss is 2.221551. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.461496450027308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 833][Wall Clock 86.615182977s] Trained 128 records in 0.087659721 seconds. Throughput is 1460.1917 records/second. Loss is 2.2201326. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.458515283842794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:42 INFO  DistriOptimizer$:408 - [Epoch 2 46720/60000][Iteration 834][Wall Clock 86.70264326s] Trained 128 records in 0.087460283 seconds. Throughput is 1463.5215 records/second. Loss is 2.242891. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.455537370430988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 835][Wall Clock 86.791731062s] Trained 128 records in 0.089087802 seconds. Throughput is 1436.7848 records/second. Loss is 2.2495785. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.452562704471102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 46976/60000][Iteration 836][Wall Clock 86.877821206s] Trained 128 records in 0.086090144 seconds. Throughput is 1486.8136 records/second. Loss is 2.242439. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.449591280653951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 837][Wall Clock 86.964045641s] Trained 128 records in 0.086224435 seconds. Throughput is 1484.4979 records/second. Loss is 2.2484026. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.446623093681918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47232/60000][Iteration 838][Wall Clock 87.051250167s] Trained 128 records in 0.087204526 seconds. Throughput is 1467.8137 records/second. Loss is 2.2388887. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.443658138268917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 839][Wall Clock 87.138321534s] Trained 128 records in 0.087071367 seconds. Throughput is 1470.0585 records/second. Loss is 2.2416863. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.44069640914037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47488/60000][Iteration 840][Wall Clock 87.224064989s] Trained 128 records in 0.085743455 seconds. Throughput is 1492.8253 records/second. Loss is 2.2311416. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.437737901033171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 841][Wall Clock 87.313230859s] Trained 128 records in 0.08916587 seconds. Throughput is 1435.5269 records/second. Loss is 2.2426822. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.434782608695652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47744/60000][Iteration 842][Wall Clock 87.43708241s] Trained 128 records in 0.123851551 seconds. Throughput is 1033.4954 records/second. Loss is 2.2473507. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.431830526887562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 843][Wall Clock 87.535581762s] Trained 128 records in 0.098499352 seconds. Throughput is 1299.501 records/second. Loss is 2.2522466. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.428881650380022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 48000/60000][Iteration 844][Wall Clock 87.61178249s] Trained 128 records in 0.076200728 seconds. Throughput is 1679.7739 records/second. Loss is 2.2353306. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.425935973955507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:43 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 845][Wall Clock 87.705727773s] Trained 128 records in 0.093945283 seconds. Throughput is 1362.4952 records/second. Loss is 2.2388148. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.422993492407809E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 48256/60000][Iteration 846][Wall Clock 87.790029103s] Trained 128 records in 0.08430133 seconds. Throughput is 1518.3628 records/second. Loss is 2.2406998. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.420054200542005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 847][Wall Clock 87.875818575s] Trained 128 records in 0.085789472 seconds. Throughput is 1492.0245 records/second. Loss is 2.2441127. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.417118093174431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 48512/60000][Iteration 848][Wall Clock 87.964962788s] Trained 128 records in 0.089144213 seconds. Throughput is 1435.8756 records/second. Loss is 2.2572672. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.414185165132648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 849][Wall Clock 88.053263289s] Trained 128 records in 0.088300501 seconds. Throughput is 1449.5953 records/second. Loss is 2.2226977. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.411255411255411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 48768/60000][Iteration 850][Wall Clock 88.137954851s] Trained 128 records in 0.084691562 seconds. Throughput is 1511.3666 records/second. Loss is 2.2454994. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.408328826392645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 851][Wall Clock 88.241736648s] Trained 128 records in 0.103781797 seconds. Throughput is 1233.3569 records/second. Loss is 2.240091. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.405405405405405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 49024/60000][Iteration 852][Wall Clock 88.332904335s] Trained 128 records in 0.091167687 seconds. Throughput is 1404.0062 records/second. Loss is 2.2382379. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.402485143165856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 853][Wall Clock 88.421321921s] Trained 128 records in 0.088417586 seconds. Throughput is 1447.6758 records/second. Loss is 2.2452686. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.399568034557236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 49280/60000][Iteration 854][Wall Clock 88.510671781s] Trained 128 records in 0.08934986 seconds. Throughput is 1432.5708 records/second. Loss is 2.2492101. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.396654074473826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 855][Wall Clock 88.598781098s] Trained 128 records in 0.088109317 seconds. Throughput is 1452.7408 records/second. Loss is 2.232407. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.393743257820927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:44 INFO  DistriOptimizer$:408 - [Epoch 2 49536/60000][Iteration 856][Wall Clock 88.691055097s] Trained 128 records in 0.092273999 seconds. Throughput is 1387.1731 records/second. Loss is 2.2332816. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.390835579514825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 857][Wall Clock 88.779150324s] Trained 128 records in 0.088095227 seconds. Throughput is 1452.9731 records/second. Loss is 2.2305737. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.38793103448276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 49792/60000][Iteration 858][Wall Clock 88.865601023s] Trained 128 records in 0.086450699 seconds. Throughput is 1480.6127 records/second. Loss is 2.247645. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.385029617662897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 859][Wall Clock 88.955564513s] Trained 128 records in 0.08996349 seconds. Throughput is 1422.7994 records/second. Loss is 2.2280412. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.382131324004305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50048/60000][Iteration 860][Wall Clock 89.045706306s] Trained 128 records in 0.090141793 seconds. Throughput is 1419.985 records/second. Loss is 2.2310834. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.379236148466918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 861][Wall Clock 89.138295429s] Trained 128 records in 0.092589123 seconds. Throughput is 1382.4518 records/second. Loss is 2.244824. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.376344086021505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50304/60000][Iteration 862][Wall Clock 89.226554561s] Trained 128 records in 0.088259132 seconds. Throughput is 1450.2749 records/second. Loss is 2.2331483. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.373455131649651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 863][Wall Clock 89.314719009s] Trained 128 records in 0.088164448 seconds. Throughput is 1451.8324 records/second. Loss is 2.245853. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.370569280343716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50560/60000][Iteration 864][Wall Clock 89.403799507s] Trained 128 records in 0.089080498 seconds. Throughput is 1436.9026 records/second. Loss is 2.2281837. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.367686527106817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 865][Wall Clock 89.489843896s] Trained 128 records in 0.086044389 seconds. Throughput is 1487.6044 records/second. Loss is 2.2384572. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.36480686695279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50816/60000][Iteration 866][Wall Clock 89.576012595s] Trained 128 records in 0.086168699 seconds. Throughput is 1485.4583 records/second. Loss is 2.2368448. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.361930294906167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:45 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 867][Wall Clock 89.663827373s] Trained 128 records in 0.087814778 seconds. Throughput is 1457.6134 records/second. Loss is 2.2426069. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.359056806002144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51072/60000][Iteration 868][Wall Clock 89.750344208s] Trained 128 records in 0.086516835 seconds. Throughput is 1479.4808 records/second. Loss is 2.2302597. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.356186395286556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 869][Wall Clock 89.842569905s] Trained 128 records in 0.092225697 seconds. Throughput is 1387.8994 records/second. Loss is 2.2415226. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.353319057815846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51328/60000][Iteration 870][Wall Clock 89.926109318s] Trained 128 records in 0.083539413 seconds. Throughput is 1532.2109 records/second. Loss is 2.2265136. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.350454788657035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 871][Wall Clock 90.009105973s] Trained 128 records in 0.082996655 seconds. Throughput is 1542.2308 records/second. Loss is 2.2446432. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.347593582887701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51584/60000][Iteration 872][Wall Clock 90.104746182s] Trained 128 records in 0.095640209 seconds. Throughput is 1338.3492 records/second. Loss is 2.2435403. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.344735435595939E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 873][Wall Clock 90.193256875s] Trained 128 records in 0.088510693 seconds. Throughput is 1446.153 records/second. Loss is 2.246029. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.341880341880342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51840/60000][Iteration 874][Wall Clock 90.287221677s] Trained 128 records in 0.093964802 seconds. Throughput is 1362.2123 records/second. Loss is 2.2291784. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.339028296849973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 875][Wall Clock 90.375865971s] Trained 128 records in 0.088644294 seconds. Throughput is 1443.9734 records/second. Loss is 2.24144. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.336179295624333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 52096/60000][Iteration 876][Wall Clock 90.462553114s] Trained 128 records in 0.086687143 seconds. Throughput is 1476.5742 records/second. Loss is 2.2558644. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 877][Wall Clock 90.555287533s] Trained 128 records in 0.092734419 seconds. Throughput is 1380.2858 records/second. Loss is 2.2400167. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.330490405117271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 52352/60000][Iteration 878][Wall Clock 90.640209475s] Trained 128 records in 0.084921942 seconds. Throughput is 1507.2665 records/second. Loss is 2.2275696. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.327650506126798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:46 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 879][Wall Clock 90.726474209s] Trained 128 records in 0.086264734 seconds. Throughput is 1483.8044 records/second. Loss is 2.24226. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.324813631522896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 52608/60000][Iteration 880][Wall Clock 90.814131476s] Trained 128 records in 0.087657267 seconds. Throughput is 1460.2327 records/second. Loss is 2.257958. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.321979776476849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 881][Wall Clock 90.901431597s] Trained 128 records in 0.087300121 seconds. Throughput is 1466.2064 records/second. Loss is 2.2377088. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.319148936170213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 52864/60000][Iteration 882][Wall Clock 90.988680035s] Trained 128 records in 0.087248438 seconds. Throughput is 1467.075 records/second. Loss is 2.2395577. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.31632110579479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 883][Wall Clock 91.093545414s] Trained 128 records in 0.104865379 seconds. Throughput is 1220.6125 records/second. Loss is 2.238124. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.313496280552603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 53120/60000][Iteration 884][Wall Clock 91.183126258s] Trained 128 records in 0.089580844 seconds. Throughput is 1428.877 records/second. Loss is 2.2321494. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.310674455655868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 885][Wall Clock 91.294033347s] Trained 128 records in 0.110907089 seconds. Throughput is 1154.1191 records/second. Loss is 2.2486968. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.307855626326964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 53376/60000][Iteration 886][Wall Clock 91.408785822s] Trained 128 records in 0.114752475 seconds. Throughput is 1115.4443 records/second. Loss is 2.2324986. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.305039787798409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 887][Wall Clock 91.509995094s] Trained 128 records in 0.101209272 seconds. Throughput is 1264.7062 records/second. Loss is 2.2392294. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.302226935312831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 53632/60000][Iteration 888][Wall Clock 91.601856949s] Trained 128 records in 0.091861855 seconds. Throughput is 1393.3967 records/second. Loss is 2.2369435. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.299417064122947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:47 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 889][Wall Clock 91.694619821s] Trained 128 records in 0.092762872 seconds. Throughput is 1379.8624 records/second. Loss is 2.2311664. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.296610169491525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 53888/60000][Iteration 890][Wall Clock 91.785154641s] Trained 128 records in 0.09053482 seconds. Throughput is 1413.8207 records/second. Loss is 2.21821. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.293806246691371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 891][Wall Clock 91.8791735s] Trained 128 records in 0.094018859 seconds. Throughput is 1361.429 records/second. Loss is 2.2552414. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.29100529100529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54144/60000][Iteration 892][Wall Clock 91.976076048s] Trained 128 records in 0.096902548 seconds. Throughput is 1320.9147 records/second. Loss is 2.2360804. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.288207297726071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 893][Wall Clock 92.080108428s] Trained 128 records in 0.10403238 seconds. Throughput is 1230.3861 records/second. Loss is 2.2325246. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.285412262156448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54400/60000][Iteration 894][Wall Clock 92.210515103s] Trained 128 records in 0.130406675 seconds. Throughput is 981.5448 records/second. Loss is 2.2358418. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.282620179609086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 895][Wall Clock 92.306589584s] Trained 128 records in 0.096074481 seconds. Throughput is 1332.2997 records/second. Loss is 2.2219818. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.279831045406547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54656/60000][Iteration 896][Wall Clock 92.42237262s] Trained 128 records in 0.115783036 seconds. Throughput is 1105.516 records/second. Loss is 2.246908. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.277044854881266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 897][Wall Clock 92.51262668s] Trained 128 records in 0.09025406 seconds. Throughput is 1418.2188 records/second. Loss is 2.2245874. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.274261603375528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 54912/60000][Iteration 898][Wall Clock 92.609515116s] Trained 128 records in 0.096888436 seconds. Throughput is 1321.107 records/second. Loss is 2.2385502. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.271481286241434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:48 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 899][Wall Clock 92.704309947s] Trained 128 records in 0.094794831 seconds. Throughput is 1350.2845 records/second. Loss is 2.2330356. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.268703898840885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55168/60000][Iteration 900][Wall Clock 92.796104226s] Trained 128 records in 0.091794279 seconds. Throughput is 1394.4224 records/second. Loss is 2.2428386. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.26592943654555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 901][Wall Clock 92.885960994s] Trained 128 records in 0.089856768 seconds. Throughput is 1424.4893 records/second. Loss is 2.2512028. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.263157894736842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55424/60000][Iteration 902][Wall Clock 92.987585666s] Trained 128 records in 0.101624672 seconds. Throughput is 1259.5366 records/second. Loss is 2.242275. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.260389268805891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 903][Wall Clock 93.069881527s] Trained 128 records in 0.082295861 seconds. Throughput is 1555.3639 records/second. Loss is 2.231765. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.257623554153522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55680/60000][Iteration 904][Wall Clock 93.167021771s] Trained 128 records in 0.097140244 seconds. Throughput is 1317.6825 records/second. Loss is 2.2403045. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.254860746190226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 905][Wall Clock 93.257362834s] Trained 128 records in 0.090341063 seconds. Throughput is 1416.8529 records/second. Loss is 2.2303598. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.252100840336135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 55936/60000][Iteration 906][Wall Clock 93.347474082s] Trained 128 records in 0.090111248 seconds. Throughput is 1420.4664 records/second. Loss is 2.246747. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.249343832020997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 907][Wall Clock 93.447735556s] Trained 128 records in 0.100261474 seconds. Throughput is 1276.6619 records/second. Loss is 2.2432427. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.246589716684155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 56192/60000][Iteration 908][Wall Clock 93.538452997s] Trained 128 records in 0.090717441 seconds. Throughput is 1410.9745 records/second. Loss is 2.2390497. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.243838489774515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:49 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 909][Wall Clock 93.635500715s] Trained 128 records in 0.097047718 seconds. Throughput is 1318.9388 records/second. Loss is 2.2308605. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.241090146750524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 56448/60000][Iteration 910][Wall Clock 93.72470166s] Trained 128 records in 0.089200945 seconds. Throughput is 1434.9624 records/second. Loss is 2.2477386. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.238344683080147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 911][Wall Clock 93.814225917s] Trained 128 records in 0.089524257 seconds. Throughput is 1429.7802 records/second. Loss is 2.24632. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.235602094240837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 56704/60000][Iteration 912][Wall Clock 93.91134937s] Trained 128 records in 0.097123453 seconds. Throughput is 1317.9103 records/second. Loss is 2.2368765. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.232862375719519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 913][Wall Clock 94.001627754s] Trained 128 records in 0.090278384 seconds. Throughput is 1417.8365 records/second. Loss is 2.2348878. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.230125523012553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 56960/60000][Iteration 914][Wall Clock 94.111849317s] Trained 128 records in 0.110221563 seconds. Throughput is 1161.2972 records/second. Loss is 2.2422113. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.227391531625719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 915][Wall Clock 94.205869426s] Trained 128 records in 0.094020109 seconds. Throughput is 1361.4109 records/second. Loss is 2.2361486. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.22466039707419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 57216/60000][Iteration 916][Wall Clock 94.298743249s] Trained 128 records in 0.092873823 seconds. Throughput is 1378.2139 records/second. Loss is 2.238617. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.221932114882506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 917][Wall Clock 94.38791091s] Trained 128 records in 0.089167661 seconds. Throughput is 1435.498 records/second. Loss is 2.2346456. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.219206680584552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 57472/60000][Iteration 918][Wall Clock 94.478832772s] Trained 128 records in 0.090921862 seconds. Throughput is 1407.8022 records/second. Loss is 2.2342432. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.216484089723526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 919][Wall Clock 94.577889284s] Trained 128 records in 0.099056512 seconds. Throughput is 1292.1917 records/second. Loss is 2.2447174. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.213764337851929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:50 INFO  DistriOptimizer$:408 - [Epoch 2 57728/60000][Iteration 920][Wall Clock 94.670263167s] Trained 128 records in 0.092373883 seconds. Throughput is 1385.673 records/second. Loss is 2.2300167. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.211047420531526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 921][Wall Clock 94.759073493s] Trained 128 records in 0.088810326 seconds. Throughput is 1441.2739 records/second. Loss is 2.2430916. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.208333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 57984/60000][Iteration 922][Wall Clock 94.855689989s] Trained 128 records in 0.096616496 seconds. Throughput is 1324.8254 records/second. Loss is 2.2335505. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.205622071837585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 923][Wall Clock 94.949923865s] Trained 128 records in 0.094233876 seconds. Throughput is 1358.3225 records/second. Loss is 2.2432797. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.202913631633714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58240/60000][Iteration 924][Wall Clock 95.044480985s] Trained 128 records in 0.09455712 seconds. Throughput is 1353.6791 records/second. Loss is 2.230585. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.200208008320332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 925][Wall Clock 95.142039883s] Trained 128 records in 0.097558898 seconds. Throughput is 1312.028 records/second. Loss is 2.2244365. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.197505197505198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58496/60000][Iteration 926][Wall Clock 95.234079118s] Trained 128 records in 0.092039235 seconds. Throughput is 1390.7113 records/second. Loss is 2.2304971. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.194805194805195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 927][Wall Clock 95.334594083s] Trained 128 records in 0.100514965 seconds. Throughput is 1273.4423 records/second. Loss is 2.2411244. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.192107995846313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58752/60000][Iteration 928][Wall Clock 95.420821427s] Trained 128 records in 0.086227344 seconds. Throughput is 1484.4479 records/second. Loss is 2.2457619. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.189413596263622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 929][Wall Clock 95.509345804s] Trained 128 records in 0.088524377 seconds. Throughput is 1445.9293 records/second. Loss is 2.2366593. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.186721991701245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 59008/60000][Iteration 930][Wall Clock 95.599424576s] Trained 128 records in 0.090078772 seconds. Throughput is 1420.9785 records/second. Loss is 2.2425578. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.184033177812338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:51 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 931][Wall Clock 95.687569111s] Trained 128 records in 0.088144535 seconds. Throughput is 1452.1604 records/second. Loss is 2.2228515. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.181347150259067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 59264/60000][Iteration 932][Wall Clock 95.773045818s] Trained 128 records in 0.085476707 seconds. Throughput is 1497.484 records/second. Loss is 2.2163467. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.178663904712584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 933][Wall Clock 95.860033156s] Trained 128 records in 0.086987338 seconds. Throughput is 1471.4785 records/second. Loss is 2.234765. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.175983436853002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 59520/60000][Iteration 934][Wall Clock 95.95159654s] Trained 128 records in 0.091563384 seconds. Throughput is 1397.9387 records/second. Loss is 2.2311716. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.173305742369374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 935][Wall Clock 96.041190827s] Trained 128 records in 0.089594287 seconds. Throughput is 1428.6625 records/second. Loss is 2.2344756. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.170630816959668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 59776/60000][Iteration 936][Wall Clock 96.130726797s] Trained 128 records in 0.08953597 seconds. Throughput is 1429.5931 records/second. Loss is 2.2345278. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.167958656330749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 937][Wall Clock 96.248886739s] Trained 128 records in 0.118159942 seconds. Throughput is 1083.2775 records/second. Loss is 2.2219043. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.165289256198347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:408 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.342549553s] Trained 128 records in 0.093662814 seconds. Throughput is 1366.6042 records/second. Loss is 2.2295637. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.162622612287042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:52 INFO  DistriOptimizer$:452 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.342549553s] Epoch finished. Wall clock time is 97759.855324 ms
2019-10-14 23:12:52 INFO  DistriOptimizer$:111 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.342549553s] Validate model...
2019-10-14 23:12:53 INFO  DistriOptimizer$:178 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.342549553s] validate model throughput is 12148.391 records/second
2019-10-14 23:12:53 INFO  DistriOptimizer$:181 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.342549553s] Top1Accuracy is Accuracy(correct: 3327, count: 10000, accuracy: 0.3327)
2019-10-14 23:12:53 INFO  DistriOptimizer$:221 - [Wall Clock 97.759855324s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:12:53 INFO  DistriOptimizer$:226 - [Wall Clock 97.759855324s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:12:53 INFO  DistriOptimizer$:408 - [Epoch 3 128/60000][Iteration 939][Wall Clock 97.894934054s] Trained 128 records in 0.13507873 seconds. Throughput is 947.5955 records/second. Loss is 2.2483754. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.159958720330237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:53 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 940][Wall Clock 97.988463216s] Trained 128 records in 0.093529162 seconds. Throughput is 1368.5571 records/second. Loss is 2.2219388. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.157297576070139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:53 INFO  DistriOptimizer$:408 - [Epoch 3 384/60000][Iteration 941][Wall Clock 98.075656972s] Trained 128 records in 0.087193756 seconds. Throughput is 1467.995 records/second. Loss is 2.2175345. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.154639175257732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:53 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 942][Wall Clock 98.163512865s] Trained 128 records in 0.087855893 seconds. Throughput is 1456.9314 records/second. Loss is 2.2261426. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.151983513652757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 640/60000][Iteration 943][Wall Clock 98.262660645s] Trained 128 records in 0.09914778 seconds. Throughput is 1291.0022 records/second. Loss is 2.2388587. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.149330587023687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 944][Wall Clock 98.372907374s] Trained 128 records in 0.110246729 seconds. Throughput is 1161.0322 records/second. Loss is 2.2352836. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.14668039114771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 896/60000][Iteration 945][Wall Clock 98.462835538s] Trained 128 records in 0.089928164 seconds. Throughput is 1423.3583 records/second. Loss is 2.2266464. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.1440329218107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 946][Wall Clock 98.553572754s] Trained 128 records in 0.090737216 seconds. Throughput is 1410.667 records/second. Loss is 2.2156298. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.141388174807198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1152/60000][Iteration 947][Wall Clock 98.645255265s] Trained 128 records in 0.091682511 seconds. Throughput is 1396.1223 records/second. Loss is 2.2336533. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.138746145940391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 948][Wall Clock 98.736098945s] Trained 128 records in 0.09084368 seconds. Throughput is 1409.0138 records/second. Loss is 2.2261908. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.136106831022085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1408/60000][Iteration 949][Wall Clock 98.825774436s] Trained 128 records in 0.089675491 seconds. Throughput is 1427.3688 records/second. Loss is 2.2246234. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.13347022587269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 950][Wall Clock 98.91325865s] Trained 128 records in 0.087484214 seconds. Throughput is 1463.1212 records/second. Loss is 2.2348003. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.13083632632119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1664/60000][Iteration 951][Wall Clock 99.000939219s] Trained 128 records in 0.087680569 seconds. Throughput is 1459.8445 records/second. Loss is 2.224199. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.128205128205128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:54 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 952][Wall Clock 99.118797833s] Trained 128 records in 0.117858614 seconds. Throughput is 1086.0471 records/second. Loss is 2.2329295. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.125576627370579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 1920/60000][Iteration 953][Wall Clock 99.210858023s] Trained 128 records in 0.09206019 seconds. Throughput is 1390.3947 records/second. Loss is 2.2235506. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.122950819672131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 954][Wall Clock 99.300740417s] Trained 128 records in 0.089882394 seconds. Throughput is 1424.0831 records/second. Loss is 2.2425423. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.120327700972862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2176/60000][Iteration 955][Wall Clock 99.388721218s] Trained 128 records in 0.087980801 seconds. Throughput is 1454.8629 records/second. Loss is 2.2321444. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.117707267144319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 956][Wall Clock 99.479972835s] Trained 128 records in 0.091251617 seconds. Throughput is 1402.7148 records/second. Loss is 2.2319627. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.115089514066496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2432/60000][Iteration 957][Wall Clock 99.56902962s] Trained 128 records in 0.089056785 seconds. Throughput is 1437.2853 records/second. Loss is 2.2284422. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.112474437627812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 958][Wall Clock 99.658891668s] Trained 128 records in 0.089862048 seconds. Throughput is 1424.4055 records/second. Loss is 2.225666. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.109862033725089E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2688/60000][Iteration 959][Wall Clock 99.749926855s] Trained 128 records in 0.091035187 seconds. Throughput is 1406.0497 records/second. Loss is 2.2351344. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.107252298263534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 960][Wall Clock 99.839680958s] Trained 128 records in 0.089754103 seconds. Throughput is 1426.1187 records/second. Loss is 2.23383. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.104645227156713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 2944/60000][Iteration 961][Wall Clock 99.92985238s] Trained 128 records in 0.090171422 seconds. Throughput is 1419.5186 records/second. Loss is 2.2508843. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.102040816326531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 962][Wall Clock 100.017725237s] Trained 128 records in 0.087872857 seconds. Throughput is 1456.65 records/second. Loss is 2.2370205. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.099439061703213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:55 INFO  DistriOptimizer$:408 - [Epoch 3 3200/60000][Iteration 963][Wall Clock 100.107342641s] Trained 128 records in 0.089617404 seconds. Throughput is 1428.2941 records/second. Loss is 2.2245328. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.096839959225281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 964][Wall Clock 100.194956152s] Trained 128 records in 0.087613511 seconds. Throughput is 1460.9619 records/second. Loss is 2.2300198. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.094243504839531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 3456/60000][Iteration 965][Wall Clock 100.283480048s] Trained 128 records in 0.088523896 seconds. Throughput is 1445.9373 records/second. Loss is 2.2340999. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.091649694501019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 966][Wall Clock 100.37270284s] Trained 128 records in 0.089222792 seconds. Throughput is 1434.6111 records/second. Loss is 2.2473912. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.089058524173028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 3712/60000][Iteration 967][Wall Clock 100.466350828s] Trained 128 records in 0.093647988 seconds. Throughput is 1366.8207 records/second. Loss is 2.2284312. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.08646998982706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 968][Wall Clock 100.555755788s] Trained 128 records in 0.08940496 seconds. Throughput is 1431.6879 records/second. Loss is 2.2500975. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.083884087442806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 3968/60000][Iteration 969][Wall Clock 100.655253284s] Trained 128 records in 0.099497496 seconds. Throughput is 1286.4645 records/second. Loss is 2.2203414. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.081300813008131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 970][Wall Clock 100.751769728s] Trained 128 records in 0.096516444 seconds. Throughput is 1326.1989 records/second. Loss is 2.2297127. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.078720162519046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 4224/60000][Iteration 971][Wall Clock 100.84505551s] Trained 128 records in 0.093285782 seconds. Throughput is 1372.1276 records/second. Loss is 2.2275038. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.076142131979696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 972][Wall Clock 100.932834133s] Trained 128 records in 0.087778623 seconds. Throughput is 1458.2139 records/second. Loss is 2.2313166. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.073566717402334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 4480/60000][Iteration 973][Wall Clock 101.028216996s] Trained 128 records in 0.095382863 seconds. Throughput is 1341.9602 records/second. Loss is 2.2351758. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.070993914807302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:56 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 974][Wall Clock 101.117324147s] Trained 128 records in 0.089107151 seconds. Throughput is 1436.4729 records/second. Loss is 2.219308. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.068423720223011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 4736/60000][Iteration 975][Wall Clock 101.207134964s] Trained 128 records in 0.089810817 seconds. Throughput is 1425.218 records/second. Loss is 2.229332. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.065856129685917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 976][Wall Clock 101.298491012s] Trained 128 records in 0.091356048 seconds. Throughput is 1401.1115 records/second. Loss is 2.2371762. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.063291139240507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 4992/60000][Iteration 977][Wall Clock 101.396217362s] Trained 128 records in 0.09772635 seconds. Throughput is 1309.7798 records/second. Loss is 2.2214003. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.060728744939271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 978][Wall Clock 101.483856348s] Trained 128 records in 0.087638986 seconds. Throughput is 1460.5371 records/second. Loss is 2.214976. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.058168942842691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5248/60000][Iteration 979][Wall Clock 101.574229193s] Trained 128 records in 0.090372845 seconds. Throughput is 1416.3546 records/second. Loss is 2.230457. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.055611729019212E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 980][Wall Clock 101.666602865s] Trained 128 records in 0.092373672 seconds. Throughput is 1385.6763 records/second. Loss is 2.2232022. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.053057099545225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5504/60000][Iteration 981][Wall Clock 101.756944946s] Trained 128 records in 0.090342081 seconds. Throughput is 1416.8369 records/second. Loss is 2.2189345. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.05050505050505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 982][Wall Clock 101.846524567s] Trained 128 records in 0.089579621 seconds. Throughput is 1428.8965 records/second. Loss is 2.2187858. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.047955577990914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5760/60000][Iteration 983][Wall Clock 101.945333274s] Trained 128 records in 0.098808707 seconds. Throughput is 1295.4324 records/second. Loss is 2.2311199. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.045408678102926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 984][Wall Clock 102.034600057s] Trained 128 records in 0.089266783 seconds. Throughput is 1433.904 records/second. Loss is 2.225396. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.042864346949066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:57 INFO  DistriOptimizer$:408 - [Epoch 3 6016/60000][Iteration 985][Wall Clock 102.123738214s] Trained 128 records in 0.089138157 seconds. Throughput is 1435.9731 records/second. Loss is 2.2264004. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.040322580645161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 986][Wall Clock 102.219249727s] Trained 128 records in 0.095511513 seconds. Throughput is 1340.1526 records/second. Loss is 2.2491896. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.037783375314862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6272/60000][Iteration 987][Wall Clock 102.308934523s] Trained 128 records in 0.089684796 seconds. Throughput is 1427.2207 records/second. Loss is 2.2345798. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.035246727089627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 988][Wall Clock 102.397876324s] Trained 128 records in 0.088941801 seconds. Throughput is 1439.1434 records/second. Loss is 2.243138. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.032712632108706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6528/60000][Iteration 989][Wall Clock 102.489508417s] Trained 128 records in 0.091632093 seconds. Throughput is 1396.8905 records/second. Loss is 2.2461185. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.030181086519115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 990][Wall Clock 102.582149655s] Trained 128 records in 0.092641238 seconds. Throughput is 1381.6742 records/second. Loss is 2.2389386. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.027652086475616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6784/60000][Iteration 991][Wall Clock 102.672320003s] Trained 128 records in 0.090170348 seconds. Throughput is 1419.5354 records/second. Loss is 2.2230518. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.025125628140704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 992][Wall Clock 102.782923398s] Trained 128 records in 0.110603395 seconds. Throughput is 1157.2882 records/second. Loss is 2.2465222. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.02260170768458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 7040/60000][Iteration 993][Wall Clock 102.87192785s] Trained 128 records in 0.089004452 seconds. Throughput is 1438.1304 records/second. Loss is 2.2195354. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.020080321285141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 994][Wall Clock 102.961842587s] Trained 128 records in 0.089914737 seconds. Throughput is 1423.5708 records/second. Loss is 2.243414. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.017561465127949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:58 INFO  DistriOptimizer$:408 - [Epoch 3 7296/60000][Iteration 995][Wall Clock 103.085303296s] Trained 128 records in 0.123460709 seconds. Throughput is 1036.7671 records/second. Loss is 2.2288697. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.015045135406219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 996][Wall Clock 103.195950583s] Trained 128 records in 0.110647287 seconds. Throughput is 1156.8291 records/second. Loss is 2.230683. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.012531328320802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 7552/60000][Iteration 997][Wall Clock 103.285095041s] Trained 128 records in 0.089144458 seconds. Throughput is 1435.8716 records/second. Loss is 2.2184691. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.01002004008016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 998][Wall Clock 103.375798977s] Trained 128 records in 0.090703936 seconds. Throughput is 1411.1847 records/second. Loss is 2.2300713. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.007511266900351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 7808/60000][Iteration 999][Wall Clock 103.465390992s] Trained 128 records in 0.089592015 seconds. Throughput is 1428.6987 records/second. Loss is 2.2344537. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.005005005005005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 1000][Wall Clock 103.55224171s] Trained 128 records in 0.086850718 seconds. Throughput is 1473.7932 records/second. Loss is 2.2372875. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.002501250625312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 8064/60000][Iteration 1001][Wall Clock 103.640353697s] Trained 128 records in 0.088111987 seconds. Throughput is 1452.6968 records/second. Loss is 2.2254734. Sequentialdaab25a8's hyper parameters: Current learning rate is 5.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 1002][Wall Clock 103.72800032s] Trained 128 records in 0.087646623 seconds. Throughput is 1460.4099 records/second. Loss is 2.2230098. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.997501249375311E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 8320/60000][Iteration 1003][Wall Clock 103.827785928s] Trained 128 records in 0.099785608 seconds. Throughput is 1282.7501 records/second. Loss is 2.2378285. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.995004995004996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 1004][Wall Clock 103.912387641s] Trained 128 records in 0.084601713 seconds. Throughput is 1512.9717 records/second. Loss is 2.2201781. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.992511233150274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 8576/60000][Iteration 1005][Wall Clock 104.001819688s] Trained 128 records in 0.089432047 seconds. Throughput is 1431.2543 records/second. Loss is 2.2279348. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.99001996007984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:12:59 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 1006][Wall Clock 104.090927425s] Trained 128 records in 0.089107737 seconds. Throughput is 1436.4634 records/second. Loss is 2.2424839. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.987531172069826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 8832/60000][Iteration 1007][Wall Clock 104.178871895s] Trained 128 records in 0.08794447 seconds. Throughput is 1455.4639 records/second. Loss is 2.2351463. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.985044865403788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 1008][Wall Clock 104.271121963s] Trained 128 records in 0.092250068 seconds. Throughput is 1387.5328 records/second. Loss is 2.2211566. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.982561036372695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9088/60000][Iteration 1009][Wall Clock 104.367607822s] Trained 128 records in 0.096485859 seconds. Throughput is 1326.6193 records/second. Loss is 2.2431755. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.9800796812749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 1010][Wall Clock 104.463021096s] Trained 128 records in 0.095413274 seconds. Throughput is 1341.5323 records/second. Loss is 2.2311883. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.977600796416126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9344/60000][Iteration 1011][Wall Clock 104.556649616s] Trained 128 records in 0.09362852 seconds. Throughput is 1367.1049 records/second. Loss is 2.2304995. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.975124378109454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 1012][Wall Clock 104.647253907s] Trained 128 records in 0.090604291 seconds. Throughput is 1412.7366 records/second. Loss is 2.2280478. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.972650422675286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9600/60000][Iteration 1013][Wall Clock 104.736859504s] Trained 128 records in 0.089605597 seconds. Throughput is 1428.4822 records/second. Loss is 2.2304554. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.970178926441352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 1014][Wall Clock 104.82917659s] Trained 128 records in 0.092317086 seconds. Throughput is 1386.5255 records/second. Loss is 2.2362456. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.967709885742673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9856/60000][Iteration 1015][Wall Clock 104.920773943s] Trained 128 records in 0.091597353 seconds. Throughput is 1397.4203 records/second. Loss is 2.2307088. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.965243296921549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 1016][Wall Clock 105.009326695s] Trained 128 records in 0.088552752 seconds. Throughput is 1445.4661 records/second. Loss is 2.2329798. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.962779156327543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:00 INFO  DistriOptimizer$:408 - [Epoch 3 10112/60000][Iteration 1017][Wall Clock 105.102722929s] Trained 128 records in 0.093396234 seconds. Throughput is 1370.505 records/second. Loss is 2.2370718. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.96031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 1018][Wall Clock 105.191401042s] Trained 128 records in 0.088678113 seconds. Throughput is 1443.4226 records/second. Loss is 2.2244756. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.957858205255329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 10368/60000][Iteration 1019][Wall Clock 105.279306888s] Trained 128 records in 0.087905846 seconds. Throughput is 1456.1034 records/second. Loss is 2.2205563. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.95540138751239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 1020][Wall Clock 105.378252157s] Trained 128 records in 0.098945269 seconds. Throughput is 1293.6445 records/second. Loss is 2.239621. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.952947003467063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 10624/60000][Iteration 1021][Wall Clock 105.461595032s] Trained 128 records in 0.083342875 seconds. Throughput is 1535.8242 records/second. Loss is 2.2304356. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.950495049504951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 1022][Wall Clock 105.549303472s] Trained 128 records in 0.08770844 seconds. Throughput is 1459.3806 records/second. Loss is 2.2265356. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.948045522018803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 10880/60000][Iteration 1023][Wall Clock 105.63351457s] Trained 128 records in 0.084211098 seconds. Throughput is 1519.9897 records/second. Loss is 2.22519. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.945598417408506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 1024][Wall Clock 105.722158344s] Trained 128 records in 0.088643774 seconds. Throughput is 1443.9818 records/second. Loss is 2.224315. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.943153732081067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 11136/60000][Iteration 1025][Wall Clock 105.810700564s] Trained 128 records in 0.08854222 seconds. Throughput is 1445.638 records/second. Loss is 2.226034. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.940711462450593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 1026][Wall Clock 105.899497291s] Trained 128 records in 0.088796727 seconds. Throughput is 1441.4945 records/second. Loss is 2.2283432. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.938271604938272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 11392/60000][Iteration 1027][Wall Clock 105.990008629s] Trained 128 records in 0.090511338 seconds. Throughput is 1414.1875 records/second. Loss is 2.2298126. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.93583415597236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:01 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 1028][Wall Clock 106.091466838s] Trained 128 records in 0.101458209 seconds. Throughput is 1261.6033 records/second. Loss is 2.2237327. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.933399111988159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 11648/60000][Iteration 1029][Wall Clock 106.179893273s] Trained 128 records in 0.088426435 seconds. Throughput is 1447.531 records/second. Loss is 2.2239053. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.930966469428008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 1030][Wall Clock 106.293491384s] Trained 128 records in 0.113598111 seconds. Throughput is 1126.7793 records/second. Loss is 2.2244883. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.928536224741252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 11904/60000][Iteration 1031][Wall Clock 106.41025019s] Trained 128 records in 0.116758806 seconds. Throughput is 1096.277 records/second. Loss is 2.2240725. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.926108374384236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 1032][Wall Clock 106.498895315s] Trained 128 records in 0.088645125 seconds. Throughput is 1443.9598 records/second. Loss is 2.2308776. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.923682914820286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12160/60000][Iteration 1033][Wall Clock 106.586498397s] Trained 128 records in 0.087603082 seconds. Throughput is 1461.1357 records/second. Loss is 2.2219572. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.921259842519685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 1034][Wall Clock 106.674468704s] Trained 128 records in 0.087970307 seconds. Throughput is 1455.0364 records/second. Loss is 2.2288163. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.918839153959666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12416/60000][Iteration 1035][Wall Clock 106.762283438s] Trained 128 records in 0.087814734 seconds. Throughput is 1457.6141 records/second. Loss is 2.2340107. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.916420845624386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 1036][Wall Clock 106.850829346s] Trained 128 records in 0.088545908 seconds. Throughput is 1445.5778 records/second. Loss is 2.220878. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.914004914004914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12672/60000][Iteration 1037][Wall Clock 106.939176523s] Trained 128 records in 0.088347177 seconds. Throughput is 1448.8296 records/second. Loss is 2.2314398. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.911591355599214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 1038][Wall Clock 107.027686961s] Trained 128 records in 0.088510438 seconds. Throughput is 1446.1571 records/second. Loss is 2.2131047. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.909180166912126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:02 INFO  DistriOptimizer$:408 - [Epoch 3 12928/60000][Iteration 1039][Wall Clock 107.118392846s] Trained 128 records in 0.090705885 seconds. Throughput is 1411.1543 records/second. Loss is 2.2311852. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.906771344455348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 1040][Wall Clock 107.211201841s] Trained 128 records in 0.092808995 seconds. Throughput is 1379.1768 records/second. Loss is 2.231583. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.904364884747426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13184/60000][Iteration 1041][Wall Clock 107.297003926s] Trained 128 records in 0.085802085 seconds. Throughput is 1491.8052 records/second. Loss is 2.223937. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.901960784313725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 1042][Wall Clock 107.392013805s] Trained 128 records in 0.095009879 seconds. Throughput is 1347.2284 records/second. Loss is 2.2281618. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.899559039686428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13440/60000][Iteration 1043][Wall Clock 107.481364761s] Trained 128 records in 0.089350956 seconds. Throughput is 1432.5532 records/second. Loss is 2.2364244. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.897159647404506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 1044][Wall Clock 107.572395455s] Trained 128 records in 0.091030694 seconds. Throughput is 1406.1191 records/second. Loss is 2.2276149. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.894762604013705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13696/60000][Iteration 1045][Wall Clock 107.672230422s] Trained 128 records in 0.099834967 seconds. Throughput is 1282.116 records/second. Loss is 2.2189562. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.892367906066536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 1046][Wall Clock 107.758534702s] Trained 128 records in 0.08630428 seconds. Throughput is 1483.1246 records/second. Loss is 2.2272892. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.88997555012225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 13952/60000][Iteration 1047][Wall Clock 107.842170489s] Trained 128 records in 0.083635787 seconds. Throughput is 1530.4454 records/second. Loss is 2.2349877. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.887585532746823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 1048][Wall Clock 107.930730265s] Trained 128 records in 0.088559776 seconds. Throughput is 1445.3514 records/second. Loss is 2.2371976. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.885197850512947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 14208/60000][Iteration 1049][Wall Clock 108.019095553s] Trained 128 records in 0.088365288 seconds. Throughput is 1448.5326 records/second. Loss is 2.2211447. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8828125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:03 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 1050][Wall Clock 108.108440527s] Trained 128 records in 0.089344974 seconds. Throughput is 1432.6492 records/second. Loss is 2.2269623. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.880429477794046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 14464/60000][Iteration 1051][Wall Clock 108.195662571s] Trained 128 records in 0.087222044 seconds. Throughput is 1467.5189 records/second. Loss is 2.2260942. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8780487804878054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 1052][Wall Clock 108.285468603s] Trained 128 records in 0.089806032 seconds. Throughput is 1425.294 records/second. Loss is 2.2072122. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8756704046806434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 14720/60000][Iteration 1053][Wall Clock 108.37450504s] Trained 128 records in 0.089036437 seconds. Throughput is 1437.6138 records/second. Loss is 2.2366636. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.873294346978557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 1054][Wall Clock 108.471505248s] Trained 128 records in 0.097000208 seconds. Throughput is 1319.5847 records/second. Loss is 2.2276342. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.870920603994155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 14976/60000][Iteration 1055][Wall Clock 108.558159336s] Trained 128 records in 0.086654088 seconds. Throughput is 1477.1375 records/second. Loss is 2.2264547. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8685491723466403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 1056][Wall Clock 108.645542512s] Trained 128 records in 0.087383176 seconds. Throughput is 1464.8129 records/second. Loss is 2.246556. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.866180048661801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 15232/60000][Iteration 1057][Wall Clock 108.734539195s] Trained 128 records in 0.088996683 seconds. Throughput is 1438.2559 records/second. Loss is 2.2217383. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8638132295719845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 1058][Wall Clock 108.82247234s] Trained 128 records in 0.087933145 seconds. Throughput is 1455.6514 records/second. Loss is 2.2297513. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.861448711716092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 15488/60000][Iteration 1059][Wall Clock 108.912194389s] Trained 128 records in 0.089722049 seconds. Throughput is 1426.628 records/second. Loss is 2.2216632. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.859086491739553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 1060][Wall Clock 109.015742927s] Trained 128 records in 0.103548538 seconds. Throughput is 1236.1353 records/second. Loss is 2.222294. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8567265662943174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:04 INFO  DistriOptimizer$:408 - [Epoch 3 15744/60000][Iteration 1061][Wall Clock 109.107036016s] Trained 128 records in 0.091293089 seconds. Throughput is 1402.0776 records/second. Loss is 2.2219107. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.854368932038835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 1062][Wall Clock 109.206670059s] Trained 128 records in 0.099634043 seconds. Throughput is 1284.7014 records/second. Loss is 2.2361112. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.85201358563804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16000/60000][Iteration 1063][Wall Clock 109.297706551s] Trained 128 records in 0.091036492 seconds. Throughput is 1406.0295 records/second. Loss is 2.2168293. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.849660523763336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 1064][Wall Clock 109.391025859s] Trained 128 records in 0.093319308 seconds. Throughput is 1371.6348 records/second. Loss is 2.2169492. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8473097430925844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16256/60000][Iteration 1065][Wall Clock 109.481302908s] Trained 128 records in 0.090277049 seconds. Throughput is 1417.8577 records/second. Loss is 2.2120903. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8449612403100775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 1066][Wall Clock 109.569537012s] Trained 128 records in 0.088234104 seconds. Throughput is 1450.6863 records/second. Loss is 2.223846. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8426150121065375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16512/60000][Iteration 1067][Wall Clock 109.666887316s] Trained 128 records in 0.097350304 seconds. Throughput is 1314.8392 records/second. Loss is 2.224794. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8402710551790907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 1068][Wall Clock 109.761107716s] Trained 128 records in 0.0942204 seconds. Throughput is 1358.5168 records/second. Loss is 2.2362752. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.837929366231253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16768/60000][Iteration 1069][Wall Clock 109.850842074s] Trained 128 records in 0.089734358 seconds. Throughput is 1426.4324 records/second. Loss is 2.2094724. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8355899419729207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 1070][Wall Clock 109.937157956s] Trained 128 records in 0.086315882 seconds. Throughput is 1482.9252 records/second. Loss is 2.2276196. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.833252779120348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 17024/60000][Iteration 1071][Wall Clock 110.032803296s] Trained 128 records in 0.09564534 seconds. Throughput is 1338.2775 records/second. Loss is 2.2083786. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8309178743961346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:05 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 1072][Wall Clock 110.12894783s] Trained 128 records in 0.096144534 seconds. Throughput is 1331.329 records/second. Loss is 2.2256193. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.828585224529214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 17280/60000][Iteration 1073][Wall Clock 110.223023409s] Trained 128 records in 0.094075579 seconds. Throughput is 1360.6082 records/second. Loss is 2.2117753. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8262548262548264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 1074][Wall Clock 110.313548782s] Trained 128 records in 0.090525373 seconds. Throughput is 1413.9683 records/second. Loss is 2.2244453. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.82392667631452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 17536/60000][Iteration 1075][Wall Clock 110.409002572s] Trained 128 records in 0.09545379 seconds. Throughput is 1340.963 records/second. Loss is 2.2143085. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.821600771456124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 1076][Wall Clock 110.502790491s] Trained 128 records in 0.093787919 seconds. Throughput is 1364.7814 records/second. Loss is 2.2226548. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8192771084337347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 17792/60000][Iteration 1077][Wall Clock 110.596687548s] Trained 128 records in 0.093897057 seconds. Throughput is 1363.195 records/second. Loss is 2.2068756. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.816955684007707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 1078][Wall Clock 110.690925225s] Trained 128 records in 0.094237677 seconds. Throughput is 1358.2678 records/second. Loss is 2.2284708. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.814636494944632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 18048/60000][Iteration 1079][Wall Clock 110.789455343s] Trained 128 records in 0.098530118 seconds. Throughput is 1299.0951 records/second. Loss is 2.2334998. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8123195380173235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 1080][Wall Clock 110.873926122s] Trained 128 records in 0.084470779 seconds. Throughput is 1515.3169 records/second. Loss is 2.2197108. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8100048100048107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 18304/60000][Iteration 1081][Wall Clock 110.967447594s] Trained 128 records in 0.093521472 seconds. Throughput is 1368.6697 records/second. Loss is 2.2366357. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8076923076923074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:06 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 1082][Wall Clock 111.056556704s] Trained 128 records in 0.08910911 seconds. Throughput is 1436.4413 records/second. Loss is 2.2254212. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.805382027871216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 18560/60000][Iteration 1083][Wall Clock 111.144751205s] Trained 128 records in 0.088194501 seconds. Throughput is 1451.3376 records/second. Loss is 2.221774. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8030739673390974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 1084][Wall Clock 111.23149341s] Trained 128 records in 0.086742205 seconds. Throughput is 1475.6368 records/second. Loss is 2.223478. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.8007681228996637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 18816/60000][Iteration 1085][Wall Clock 111.319347641s] Trained 128 records in 0.087854231 seconds. Throughput is 1456.9589 records/second. Loss is 2.212163. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.798464491362764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 1086][Wall Clock 111.407907633s] Trained 128 records in 0.088559992 seconds. Throughput is 1445.3479 records/second. Loss is 2.2048697. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7961630695443646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19072/60000][Iteration 1087][Wall Clock 111.504245168s] Trained 128 records in 0.096337535 seconds. Throughput is 1328.6617 records/second. Loss is 2.2378173. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.793863854266538E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 1088][Wall Clock 111.594857309s] Trained 128 records in 0.090612141 seconds. Throughput is 1412.6143 records/second. Loss is 2.203797. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7915668423574516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19328/60000][Iteration 1089][Wall Clock 111.683601227s] Trained 128 records in 0.088743918 seconds. Throughput is 1442.3524 records/second. Loss is 2.2185884. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.789272030651341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 1090][Wall Clock 111.774094786s] Trained 128 records in 0.090493559 seconds. Throughput is 1414.4653 records/second. Loss is 2.2193015. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.786979415988511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19584/60000][Iteration 1091][Wall Clock 111.863171933s] Trained 128 records in 0.089077147 seconds. Throughput is 1436.9567 records/second. Loss is 2.2159433. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7846889952153117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 1092][Wall Clock 111.953659485s] Trained 128 records in 0.090487552 seconds. Throughput is 1414.5592 records/second. Loss is 2.2233536. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.782400765184122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:07 INFO  DistriOptimizer$:408 - [Epoch 3 19840/60000][Iteration 1093][Wall Clock 112.044398802s] Trained 128 records in 0.090739317 seconds. Throughput is 1410.6344 records/second. Loss is 2.2290814. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.780114722753346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 1094][Wall Clock 112.140655854s] Trained 128 records in 0.096257052 seconds. Throughput is 1329.7727 records/second. Loss is 2.2159977. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.777830864787387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20096/60000][Iteration 1095][Wall Clock 112.229396478s] Trained 128 records in 0.088740624 seconds. Throughput is 1442.4059 records/second. Loss is 2.2163186. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7755491881566373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 1096][Wall Clock 112.321464973s] Trained 128 records in 0.092068495 seconds. Throughput is 1390.2693 records/second. Loss is 2.223221. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.773269689737471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20352/60000][Iteration 1097][Wall Clock 112.437486778s] Trained 128 records in 0.116021805 seconds. Throughput is 1103.2408 records/second. Loss is 2.2165673. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7709923664122136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 1098][Wall Clock 112.525313073s] Trained 128 records in 0.087826295 seconds. Throughput is 1457.4222 records/second. Loss is 2.222579. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.768717215069147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20608/60000][Iteration 1099][Wall Clock 112.616483356s] Trained 128 records in 0.091170283 seconds. Throughput is 1403.9663 records/second. Loss is 2.2158275. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.766444232602479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 1100][Wall Clock 112.707479193s] Trained 128 records in 0.090995837 seconds. Throughput is 1406.6578 records/second. Loss is 2.2092786. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.764173415912339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20864/60000][Iteration 1101][Wall Clock 112.7980613s] Trained 128 records in 0.090582107 seconds. Throughput is 1413.0825 records/second. Loss is 2.2223055. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.761904761904762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 1102][Wall Clock 112.88936974s] Trained 128 records in 0.09130844 seconds. Throughput is 1401.8419 records/second. Loss is 2.2277863. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.759638267491671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 21120/60000][Iteration 1103][Wall Clock 112.981883313s] Trained 128 records in 0.092513573 seconds. Throughput is 1383.5807 records/second. Loss is 2.2335112. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.757373929590865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:08 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 1104][Wall Clock 113.075828098s] Trained 128 records in 0.093944785 seconds. Throughput is 1362.5024 records/second. Loss is 2.2257564. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.755111745126011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 21376/60000][Iteration 1105][Wall Clock 113.175994649s] Trained 128 records in 0.100166551 seconds. Throughput is 1277.8717 records/second. Loss is 2.2040057. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.752851711026616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 1106][Wall Clock 113.25832175s] Trained 128 records in 0.082327101 seconds. Throughput is 1554.7737 records/second. Loss is 2.2246547. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7505938242280285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 21632/60000][Iteration 1107][Wall Clock 113.34824769s] Trained 128 records in 0.08992594 seconds. Throughput is 1423.3936 records/second. Loss is 2.222167. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.748338081671415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 1108][Wall Clock 113.438713358s] Trained 128 records in 0.090465668 seconds. Throughput is 1414.9015 records/second. Loss is 2.2086282. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.746084480303749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 21888/60000][Iteration 1109][Wall Clock 113.525758527s] Trained 128 records in 0.087045169 seconds. Throughput is 1470.5009 records/second. Loss is 2.2006707. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.743833017077799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 1110][Wall Clock 113.614972853s] Trained 128 records in 0.089214326 seconds. Throughput is 1434.7472 records/second. Loss is 2.2158504. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.74158368895211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 22144/60000][Iteration 1111][Wall Clock 113.704386231s] Trained 128 records in 0.089413378 seconds. Throughput is 1431.5532 records/second. Loss is 2.217715. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.739336492890995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 1112][Wall Clock 113.792118715s] Trained 128 records in 0.087732484 seconds. Throughput is 1458.9806 records/second. Loss is 2.2192945. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.73709142586452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 22400/60000][Iteration 1113][Wall Clock 113.880872197s] Trained 128 records in 0.088753482 seconds. Throughput is 1442.1969 records/second. Loss is 2.2203588. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.734848484848485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 1114][Wall Clock 113.972412525s] Trained 128 records in 0.091540328 seconds. Throughput is 1398.2908 records/second. Loss is 2.2103357. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.73260766682442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:09 INFO  DistriOptimizer$:408 - [Epoch 3 22656/60000][Iteration 1115][Wall Clock 114.062101398s] Trained 128 records in 0.089688873 seconds. Throughput is 1427.1559 records/second. Loss is 2.2185254. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7303689687795653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 1116][Wall Clock 114.150153547s] Trained 128 records in 0.088052149 seconds. Throughput is 1453.6841 records/second. Loss is 2.2171159. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7281323877068556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 22912/60000][Iteration 1117][Wall Clock 114.239158815s] Trained 128 records in 0.089005268 seconds. Throughput is 1438.1171 records/second. Loss is 2.22182. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.725897920604915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 1118][Wall Clock 114.328766405s] Trained 128 records in 0.08960759 seconds. Throughput is 1428.4504 records/second. Loss is 2.2082355. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.723665564478035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23168/60000][Iteration 1119][Wall Clock 114.417573053s] Trained 128 records in 0.088806648 seconds. Throughput is 1441.3335 records/second. Loss is 2.220583. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7214353163361653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 1120][Wall Clock 114.510448138s] Trained 128 records in 0.092875085 seconds. Throughput is 1378.1952 records/second. Loss is 2.2199583. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.719207173194904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23424/60000][Iteration 1121][Wall Clock 114.593749805s] Trained 128 records in 0.083301667 seconds. Throughput is 1536.584 records/second. Loss is 2.2202165. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.716981132075472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 1122][Wall Clock 114.680429678s] Trained 128 records in 0.086679873 seconds. Throughput is 1476.698 records/second. Loss is 2.2268796. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.714757190004715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23680/60000][Iteration 1123][Wall Clock 114.767466592s] Trained 128 records in 0.087036914 seconds. Throughput is 1470.6404 records/second. Loss is 2.2111864. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7125353440150805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 1124][Wall Clock 114.855682928s] Trained 128 records in 0.088216336 seconds. Throughput is 1450.9784 records/second. Loss is 2.2420318. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7103155911446063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 23936/60000][Iteration 1125][Wall Clock 114.94302103s] Trained 128 records in 0.087338102 seconds. Throughput is 1465.5687 records/second. Loss is 2.2159042. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7080979284369113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:10 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 1126][Wall Clock 115.029430612s] Trained 128 records in 0.086409582 seconds. Throughput is 1481.3171 records/second. Loss is 2.2200644. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.7058823529411766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24192/60000][Iteration 1127][Wall Clock 115.116443706s] Trained 128 records in 0.087013094 seconds. Throughput is 1471.043 records/second. Loss is 2.236027. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.703668861712135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 1128][Wall Clock 115.204877181s] Trained 128 records in 0.088433475 seconds. Throughput is 1447.4156 records/second. Loss is 2.2372448. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.701457451810062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24448/60000][Iteration 1129][Wall Clock 115.292668729s] Trained 128 records in 0.087791548 seconds. Throughput is 1457.9991 records/second. Loss is 2.2166915. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6992481203007516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 1130][Wall Clock 115.380227819s] Trained 128 records in 0.08755909 seconds. Throughput is 1461.87 records/second. Loss is 2.2131617. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.697040864255519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24704/60000][Iteration 1131][Wall Clock 115.477327307s] Trained 128 records in 0.097099488 seconds. Throughput is 1318.2356 records/second. Loss is 2.2193978. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.694835680751174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 1132][Wall Clock 115.563003906s] Trained 128 records in 0.085676599 seconds. Throughput is 1493.9902 records/second. Loss is 2.221175. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.692632566870014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 24960/60000][Iteration 1133][Wall Clock 115.653779023s] Trained 128 records in 0.090775117 seconds. Throughput is 1410.078 records/second. Loss is 2.229374. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6904315196998124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 1134][Wall Clock 115.74163737s] Trained 128 records in 0.087858347 seconds. Throughput is 1456.8906 records/second. Loss is 2.2151237. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6882325363338024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 25216/60000][Iteration 1135][Wall Clock 115.828367767s] Trained 128 records in 0.086730397 seconds. Throughput is 1475.8378 records/second. Loss is 2.2249901. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.686035613870665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 1136][Wall Clock 115.915060498s] Trained 128 records in 0.086692731 seconds. Throughput is 1476.4791 records/second. Loss is 2.2191331. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6838407494145204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 25472/60000][Iteration 1137][Wall Clock 116.002549955s] Trained 128 records in 0.087489457 seconds. Throughput is 1463.0334 records/second. Loss is 2.2111413. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6816479400749064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:11 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 1138][Wall Clock 116.088667076s] Trained 128 records in 0.086117121 seconds. Throughput is 1486.3479 records/second. Loss is 2.2237947. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.679457182966776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 25728/60000][Iteration 1139][Wall Clock 116.176750992s] Trained 128 records in 0.088083916 seconds. Throughput is 1453.1598 records/second. Loss is 2.2233896. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.677268475210477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 1140][Wall Clock 116.263567809s] Trained 128 records in 0.086816817 seconds. Throughput is 1474.3688 records/second. Loss is 2.2218442. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6750818139317435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 25984/60000][Iteration 1141][Wall Clock 116.354233847s] Trained 128 records in 0.090666038 seconds. Throughput is 1411.7744 records/second. Loss is 2.2017055. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.672897196261682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 1142][Wall Clock 116.449160297s] Trained 128 records in 0.09492645 seconds. Throughput is 1348.4125 records/second. Loss is 2.224428. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.670714619336759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26240/60000][Iteration 1143][Wall Clock 116.54309261s] Trained 128 records in 0.093932313 seconds. Throughput is 1362.6833 records/second. Loss is 2.2337825. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6685340802987853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 1144][Wall Clock 116.631568459s] Trained 128 records in 0.088475849 seconds. Throughput is 1446.7225 records/second. Loss is 2.227725. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6663555762949143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26496/60000][Iteration 1145][Wall Clock 116.730255212s] Trained 128 records in 0.098686753 seconds. Throughput is 1297.0332 records/second. Loss is 2.2225225. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.664179104477612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 1146][Wall Clock 116.81935016s] Trained 128 records in 0.089094948 seconds. Throughput is 1436.6697 records/second. Loss is 2.2186253. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.662004662004662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26752/60000][Iteration 1147][Wall Clock 116.898973394s] Trained 128 records in 0.079623234 seconds. Throughput is 1607.5709 records/second. Loss is 2.2170682. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.659832246039143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 1148][Wall Clock 116.985849793s] Trained 128 records in 0.086876399 seconds. Throughput is 1473.3575 records/second. Loss is 2.210168. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6576618537494174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:12 INFO  DistriOptimizer$:408 - [Epoch 3 27008/60000][Iteration 1149][Wall Clock 117.071740677s] Trained 128 records in 0.085890884 seconds. Throughput is 1490.263 records/second. Loss is 2.2212088. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.655493482309125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 1150][Wall Clock 117.156668244s] Trained 128 records in 0.084927567 seconds. Throughput is 1507.1667 records/second. Loss is 2.222038. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6533271288971617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27264/60000][Iteration 1151][Wall Clock 117.243218348s] Trained 128 records in 0.086550104 seconds. Throughput is 1478.9122 records/second. Loss is 2.2037318. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6511627906976736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 1152][Wall Clock 117.329009799s] Trained 128 records in 0.085791451 seconds. Throughput is 1491.9901 records/second. Loss is 2.2243052. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.649000464900047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27520/60000][Iteration 1153][Wall Clock 117.426741357s] Trained 128 records in 0.097731558 seconds. Throughput is 1309.71 records/second. Loss is 2.2180655. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6468401486988845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 1154][Wall Clock 117.514679787s] Trained 128 records in 0.08793843 seconds. Throughput is 1455.5638 records/second. Loss is 2.2101164. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6446818392940084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27776/60000][Iteration 1155][Wall Clock 117.601818987s] Trained 128 records in 0.0871392 seconds. Throughput is 1468.9142 records/second. Loss is 2.2192311. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6425255338904364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 1156][Wall Clock 117.698037779s] Trained 128 records in 0.096218792 seconds. Throughput is 1330.3014 records/second. Loss is 2.2329543. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6403712296983754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 28032/60000][Iteration 1157][Wall Clock 117.783480951s] Trained 128 records in 0.085443172 seconds. Throughput is 1498.0718 records/second. Loss is 2.1990263. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.63821892393321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 1158][Wall Clock 117.864692616s] Trained 128 records in 0.081211665 seconds. Throughput is 1576.1283 records/second. Loss is 2.226894. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.636068613815484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 28288/60000][Iteration 1159][Wall Clock 117.953592948s] Trained 128 records in 0.088900332 seconds. Throughput is 1439.8146 records/second. Loss is 2.2290063. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.633920296570899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:13 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 1160][Wall Clock 118.042215639s] Trained 128 records in 0.088622691 seconds. Throughput is 1444.3254 records/second. Loss is 2.212148. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6317739694302923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 28544/60000][Iteration 1161][Wall Clock 118.129704589s] Trained 128 records in 0.08748895 seconds. Throughput is 1463.0419 records/second. Loss is 2.2074363. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.629629629629629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 1162][Wall Clock 118.21635506s] Trained 128 records in 0.086650471 seconds. Throughput is 1477.1992 records/second. Loss is 2.2061756. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6274872744099955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 28800/60000][Iteration 1163][Wall Clock 118.302815233s] Trained 128 records in 0.086460173 seconds. Throughput is 1480.4504 records/second. Loss is 2.2100313. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6253469010175765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 1164][Wall Clock 118.390101466s] Trained 128 records in 0.087286233 seconds. Throughput is 1466.4397 records/second. Loss is 2.2307532. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.623208506703652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29056/60000][Iteration 1165][Wall Clock 118.477229725s] Trained 128 records in 0.087128259 seconds. Throughput is 1469.0985 records/second. Loss is 2.2123404. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6210720887245846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 1166][Wall Clock 118.565375426s] Trained 128 records in 0.088145701 seconds. Throughput is 1452.1411 records/second. Loss is 2.2335355. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6189376443418013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29312/60000][Iteration 1167][Wall Clock 118.654584809s] Trained 128 records in 0.089209383 seconds. Throughput is 1434.8267 records/second. Loss is 2.2238326. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6168051708217917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 1168][Wall Clock 118.741106754s] Trained 128 records in 0.086521945 seconds. Throughput is 1479.3934 records/second. Loss is 2.204931. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.614674665436087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29568/60000][Iteration 1169][Wall Clock 118.831094168s] Trained 128 records in 0.089987414 seconds. Throughput is 1422.4211 records/second. Loss is 2.2125833. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.6125461254612545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 1170][Wall Clock 118.928589907s] Trained 128 records in 0.097495739 seconds. Throughput is 1312.8778 records/second. Loss is 2.2318664. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.610419548178884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:14 INFO  DistriOptimizer$:408 - [Epoch 3 29824/60000][Iteration 1171][Wall Clock 119.015592229s] Trained 128 records in 0.087002322 seconds. Throughput is 1471.2251 records/second. Loss is 2.2191556. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.608294930875576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 1172][Wall Clock 119.095613823s] Trained 128 records in 0.080021594 seconds. Throughput is 1599.5681 records/second. Loss is 2.2216434. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.606172270842929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30080/60000][Iteration 1173][Wall Clock 119.183719148s] Trained 128 records in 0.088105325 seconds. Throughput is 1452.8065 records/second. Loss is 2.2113318. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.604051565377533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 1174][Wall Clock 119.274964393s] Trained 128 records in 0.091245245 seconds. Throughput is 1402.8129 records/second. Loss is 2.2170472. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.601932811780948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30336/60000][Iteration 1175][Wall Clock 119.364562273s] Trained 128 records in 0.08959788 seconds. Throughput is 1428.6052 records/second. Loss is 2.2057796. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.599816007359706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 1176][Wall Clock 119.459141622s] Trained 128 records in 0.094579349 seconds. Throughput is 1353.361 records/second. Loss is 2.222473. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5977011494252877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30592/60000][Iteration 1177][Wall Clock 119.549448944s] Trained 128 records in 0.090307322 seconds. Throughput is 1417.3822 records/second. Loss is 2.2132075. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5955882352941176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 1178][Wall Clock 119.637815282s] Trained 128 records in 0.088366338 seconds. Throughput is 1448.5154 records/second. Loss is 2.2168686. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5934772622875517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30848/60000][Iteration 1179][Wall Clock 119.726368747s] Trained 128 records in 0.088553465 seconds. Throughput is 1445.4545 records/second. Loss is 2.2093918. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5913682277318646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 1180][Wall Clock 119.812313519s] Trained 128 records in 0.085944772 seconds. Throughput is 1489.3285 records/second. Loss is 2.2121515. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5892611289582373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 31104/60000][Iteration 1181][Wall Clock 119.900975101s] Trained 128 records in 0.088661582 seconds. Throughput is 1443.6918 records/second. Loss is 2.189317. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.587155963302753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:15 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 1182][Wall Clock 119.99619636s] Trained 128 records in 0.095221259 seconds. Throughput is 1344.2377 records/second. Loss is 2.2345066. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.585052728106373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 31360/60000][Iteration 1183][Wall Clock 120.084887117s] Trained 128 records in 0.088690757 seconds. Throughput is 1443.2169 records/second. Loss is 2.2363095. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5829514207149406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 1184][Wall Clock 120.175572774s] Trained 128 records in 0.090685657 seconds. Throughput is 1411.469 records/second. Loss is 2.2244103. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5808520384791576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 31616/60000][Iteration 1185][Wall Clock 120.262791356s] Trained 128 records in 0.087218582 seconds. Throughput is 1467.5771 records/second. Loss is 2.2273552. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.578754578754579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 1186][Wall Clock 120.35159888s] Trained 128 records in 0.088807524 seconds. Throughput is 1441.3193 records/second. Loss is 2.229922. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.576659038901602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 31872/60000][Iteration 1187][Wall Clock 120.440841603s] Trained 128 records in 0.089242723 seconds. Throughput is 1434.2905 records/second. Loss is 2.204121. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.574565416285453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 1188][Wall Clock 120.529266578s] Trained 128 records in 0.088424975 seconds. Throughput is 1447.5548 records/second. Loss is 2.2379615. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5724737082761767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32128/60000][Iteration 1189][Wall Clock 120.617708216s] Trained 128 records in 0.088441638 seconds. Throughput is 1447.2821 records/second. Loss is 2.2368743. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5703839122486294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 1190][Wall Clock 120.713206279s] Trained 128 records in 0.095498063 seconds. Throughput is 1340.3413 records/second. Loss is 2.2181761. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5682960255824577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32384/60000][Iteration 1191][Wall Clock 120.804929823s] Trained 128 records in 0.091723544 seconds. Throughput is 1395.4977 records/second. Loss is 2.2254596. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.566210045662101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 1192][Wall Clock 120.891145504s] Trained 128 records in 0.086215681 seconds. Throughput is 1484.6487 records/second. Loss is 2.2305446. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.564125969876769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32640/60000][Iteration 1193][Wall Clock 120.977485207s] Trained 128 records in 0.086339703 seconds. Throughput is 1482.5161 records/second. Loss is 2.217764. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.562043795620438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:16 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 1194][Wall Clock 121.063155665s] Trained 128 records in 0.085670458 seconds. Throughput is 1494.0973 records/second. Loss is 2.2216532. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5599635202918376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 32896/60000][Iteration 1195][Wall Clock 121.157843591s] Trained 128 records in 0.094687926 seconds. Throughput is 1351.8091 records/second. Loss is 2.2122757. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.55788514129444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 1196][Wall Clock 121.242956443s] Trained 128 records in 0.085112852 seconds. Throughput is 1503.8856 records/second. Loss is 2.1973166. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.555808656036446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33152/60000][Iteration 1197][Wall Clock 121.333782502s] Trained 128 records in 0.090826059 seconds. Throughput is 1409.2872 records/second. Loss is 2.2165935. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.553734061930784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 1198][Wall Clock 121.419925969s] Trained 128 records in 0.086143467 seconds. Throughput is 1485.8933 records/second. Loss is 2.228587. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.551661356395084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33408/60000][Iteration 1199][Wall Clock 121.506210199s] Trained 128 records in 0.08628423 seconds. Throughput is 1483.4692 records/second. Loss is 2.1997173. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5495905368516835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 1200][Wall Clock 121.597135251s] Trained 128 records in 0.090925052 seconds. Throughput is 1407.7528 records/second. Loss is 2.2234652. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.547521600727604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33664/60000][Iteration 1201][Wall Clock 121.70537406s] Trained 128 records in 0.108238809 seconds. Throughput is 1182.5703 records/second. Loss is 2.22321. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5454545454545455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 1202][Wall Clock 121.792677126s] Trained 128 records in 0.087303066 seconds. Throughput is 1466.157 records/second. Loss is 2.2047374. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5433893684688776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 33920/60000][Iteration 1203][Wall Clock 121.879748881s] Trained 128 records in 0.087071755 seconds. Throughput is 1470.0519 records/second. Loss is 2.20051. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.541326067211626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 1204][Wall Clock 121.966890402s] Trained 128 records in 0.087141521 seconds. Throughput is 1468.875 records/second. Loss is 2.2283227. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.539264639128461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:17 INFO  DistriOptimizer$:408 - [Epoch 3 34176/60000][Iteration 1205][Wall Clock 122.053498767s] Trained 128 records in 0.086608365 seconds. Throughput is 1477.9172 records/second. Loss is 2.2128859. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.537205081669692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 1206][Wall Clock 122.140528943s] Trained 128 records in 0.087030176 seconds. Throughput is 1470.7543 records/second. Loss is 2.2077997. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.535147392290249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 34432/60000][Iteration 1207][Wall Clock 122.236577175s] Trained 128 records in 0.096048232 seconds. Throughput is 1332.6638 records/second. Loss is 2.2083483. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5330915684496827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 1208][Wall Clock 122.325738529s] Trained 128 records in 0.089161354 seconds. Throughput is 1435.5996 records/second. Loss is 2.2075167. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5310376076121433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 34688/60000][Iteration 1209][Wall Clock 122.415835282s] Trained 128 records in 0.090096753 seconds. Throughput is 1420.695 records/second. Loss is 2.2102108. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5289855072463763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 1210][Wall Clock 122.504809553s] Trained 128 records in 0.088974271 seconds. Throughput is 1438.618 records/second. Loss is 2.2337048. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.526935264825713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 34944/60000][Iteration 1211][Wall Clock 122.592813785s] Trained 128 records in 0.088004232 seconds. Throughput is 1454.4755 records/second. Loss is 2.2034838. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5248868778280545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 1212][Wall Clock 122.683021657s] Trained 128 records in 0.090207872 seconds. Throughput is 1418.9448 records/second. Loss is 2.2024703. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5228403437358656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 35200/60000][Iteration 1213][Wall Clock 122.775419181s] Trained 128 records in 0.092397524 seconds. Throughput is 1385.3185 records/second. Loss is 2.2184825. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.520795660036167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 1214][Wall Clock 122.863321114s] Trained 128 records in 0.087901933 seconds. Throughput is 1456.1682 records/second. Loss is 2.202574. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5187528242205153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 35456/60000][Iteration 1215][Wall Clock 122.951410146s] Trained 128 records in 0.088089032 seconds. Throughput is 1453.0753 records/second. Loss is 2.211028. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.516711833785005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:18 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 1216][Wall Clock 123.037513503s] Trained 128 records in 0.086103357 seconds. Throughput is 1486.5854 records/second. Loss is 2.2145872. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5146726862302486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 35712/60000][Iteration 1217][Wall Clock 123.128542134s] Trained 128 records in 0.091028631 seconds. Throughput is 1406.151 records/second. Loss is 2.2239318. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5126353790613715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 1218][Wall Clock 123.216661876s] Trained 128 records in 0.088119742 seconds. Throughput is 1452.5688 records/second. Loss is 2.2197208. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.510599909788002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 35968/60000][Iteration 1219][Wall Clock 123.304962034s] Trained 128 records in 0.088300158 seconds. Throughput is 1449.601 records/second. Loss is 2.2076685. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5085662759242564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 1220][Wall Clock 123.403149165s] Trained 128 records in 0.098187131 seconds. Throughput is 1303.6332 records/second. Loss is 2.2086935. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.506534474988733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36224/60000][Iteration 1221][Wall Clock 123.485741098s] Trained 128 records in 0.082591933 seconds. Throughput is 1549.7881 records/second. Loss is 2.2042658. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.504504504504505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 1222][Wall Clock 123.574104677s] Trained 128 records in 0.088363579 seconds. Throughput is 1448.5605 records/second. Loss is 2.2003844. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.5024763619990995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36480/60000][Iteration 1223][Wall Clock 123.685744736s] Trained 128 records in 0.111640059 seconds. Throughput is 1146.5419 records/second. Loss is 2.2123818. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.500450045004501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 1224][Wall Clock 123.784549393s] Trained 128 records in 0.098804657 seconds. Throughput is 1295.4855 records/second. Loss is 2.2127097. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.49842555105713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36736/60000][Iteration 1225][Wall Clock 123.872527287s] Trained 128 records in 0.087977894 seconds. Throughput is 1454.9109 records/second. Loss is 2.210366. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4964028776978414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 1226][Wall Clock 123.960647827s] Trained 128 records in 0.08812054 seconds. Throughput is 1452.5558 records/second. Loss is 2.2087674. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4943820224719103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:19 INFO  DistriOptimizer$:408 - [Epoch 3 36992/60000][Iteration 1227][Wall Clock 124.04891853s] Trained 128 records in 0.088270703 seconds. Throughput is 1450.0847 records/second. Loss is 2.2209756. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.492362982929021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 1228][Wall Clock 124.135882788s] Trained 128 records in 0.086964258 seconds. Throughput is 1471.869 records/second. Loss is 2.1993241. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.490345756623259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37248/60000][Iteration 1229][Wall Clock 124.226198902s] Trained 128 records in 0.090316114 seconds. Throughput is 1417.2443 records/second. Loss is 2.2123826. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4883303411131066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 1230][Wall Clock 124.31620467s] Trained 128 records in 0.090005768 seconds. Throughput is 1422.1311 records/second. Loss is 2.2249627. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4863167339614175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37504/60000][Iteration 1231][Wall Clock 124.401957525s] Trained 128 records in 0.085752855 seconds. Throughput is 1492.6617 records/second. Loss is 2.207105. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.484304932735426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 1232][Wall Clock 124.489708274s] Trained 128 records in 0.087750749 seconds. Throughput is 1458.677 records/second. Loss is 2.2022102. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4822949350067237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37760/60000][Iteration 1233][Wall Clock 124.589044648s] Trained 128 records in 0.099336374 seconds. Throughput is 1288.5511 records/second. Loss is 2.205113. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.480286738351254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 1234][Wall Clock 124.671154306s] Trained 128 records in 0.082109658 seconds. Throughput is 1558.8909 records/second. Loss is 2.200247. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.478280340349306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 38016/60000][Iteration 1235][Wall Clock 124.752999152s] Trained 128 records in 0.081844846 seconds. Throughput is 1563.9348 records/second. Loss is 2.2127008. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.476275738585497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 1236][Wall Clock 124.835980366s] Trained 128 records in 0.082981214 seconds. Throughput is 1542.5178 records/second. Loss is 2.2077518. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.474272930648769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 38272/60000][Iteration 1237][Wall Clock 124.9236439s] Trained 128 records in 0.087663534 seconds. Throughput is 1460.1283 records/second. Loss is 2.210579. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.47227191413238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:20 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 1238][Wall Clock 125.008757346s] Trained 128 records in 0.085113446 seconds. Throughput is 1503.8752 records/second. Loss is 2.219627. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.470272686633885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 38528/60000][Iteration 1239][Wall Clock 125.092722633s] Trained 128 records in 0.083965287 seconds. Throughput is 1524.4395 records/second. Loss is 2.1979804. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4682752457551384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 1240][Wall Clock 125.18379237s] Trained 128 records in 0.091069737 seconds. Throughput is 1405.5164 records/second. Loss is 2.2123387. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.466279589102278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 38784/60000][Iteration 1241][Wall Clock 125.273376999s] Trained 128 records in 0.089584629 seconds. Throughput is 1428.8165 records/second. Loss is 2.2090523. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.464285714285714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 1242][Wall Clock 125.363551562s] Trained 128 records in 0.090174563 seconds. Throughput is 1419.469 records/second. Loss is 2.2226717. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.462293618920125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39040/60000][Iteration 1243][Wall Clock 125.452367724s] Trained 128 records in 0.088816162 seconds. Throughput is 1441.1792 records/second. Loss is 2.2129138. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4603033006244426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 1244][Wall Clock 125.541213679s] Trained 128 records in 0.088845955 seconds. Throughput is 1440.6959 records/second. Loss is 2.2158272. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.458314757021845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39296/60000][Iteration 1245][Wall Clock 125.638768714s] Trained 128 records in 0.097555035 seconds. Throughput is 1312.08 records/second. Loss is 2.2014954. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4563279857397507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 1246][Wall Clock 125.720540944s] Trained 128 records in 0.08177223 seconds. Throughput is 1565.3236 records/second. Loss is 2.216207. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4543429844097997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39552/60000][Iteration 1247][Wall Clock 125.800316934s] Trained 128 records in 0.07977599 seconds. Throughput is 1604.4928 records/second. Loss is 2.2184668. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.452359750667854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 1248][Wall Clock 125.889186579s] Trained 128 records in 0.088869645 seconds. Throughput is 1440.3118 records/second. Loss is 2.2114913. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4503782821539835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:21 INFO  DistriOptimizer$:408 - [Epoch 3 39808/60000][Iteration 1249][Wall Clock 125.977894668s] Trained 128 records in 0.088708089 seconds. Throughput is 1442.9349 records/second. Loss is 2.2204776. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4483985765124553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 1250][Wall Clock 126.064859705s] Trained 128 records in 0.086965037 seconds. Throughput is 1471.8558 records/second. Loss is 2.2289343. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4464206313917296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40064/60000][Iteration 1251][Wall Clock 126.153914545s] Trained 128 records in 0.08905484 seconds. Throughput is 1437.3167 records/second. Loss is 2.2267284. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4444444444444447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 1252][Wall Clock 126.238851806s] Trained 128 records in 0.084937261 seconds. Throughput is 1506.9948 records/second. Loss is 2.208517. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4424700133274093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40320/60000][Iteration 1253][Wall Clock 126.329893982s] Trained 128 records in 0.091042176 seconds. Throughput is 1405.9418 records/second. Loss is 2.2048962. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4404973357015993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 1254][Wall Clock 126.417705228s] Trained 128 records in 0.087811246 seconds. Throughput is 1457.672 records/second. Loss is 2.220585. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.438526409232135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40576/60000][Iteration 1255][Wall Clock 126.505807701s] Trained 128 records in 0.088102473 seconds. Throughput is 1452.8536 records/second. Loss is 2.2134855. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4365572315882877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 1256][Wall Clock 126.592381032s] Trained 128 records in 0.086573331 seconds. Throughput is 1478.5154 records/second. Loss is 2.199319. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4345898004434595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40832/60000][Iteration 1257][Wall Clock 126.685504159s] Trained 128 records in 0.093123127 seconds. Throughput is 1374.5243 records/second. Loss is 2.1964722. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.432624113475177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 1258][Wall Clock 126.773492658s] Trained 128 records in 0.087988499 seconds. Throughput is 1454.7356 records/second. Loss is 2.206909. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4306601683650863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 41088/60000][Iteration 1259][Wall Clock 126.867178681s] Trained 128 records in 0.093686023 seconds. Throughput is 1366.2657 records/second. Loss is 2.2055159. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.428697962798937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 1260][Wall Clock 126.95808004s] Trained 128 records in 0.090901359 seconds. Throughput is 1408.1198 records/second. Loss is 2.2135692. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4267374944665776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:22 INFO  DistriOptimizer$:408 - [Epoch 3 41344/60000][Iteration 1261][Wall Clock 127.038650815s] Trained 128 records in 0.080570775 seconds. Throughput is 1588.6654 records/second. Loss is 2.2154484. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4247787610619474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 1262][Wall Clock 127.142295103s] Trained 128 records in 0.103644288 seconds. Throughput is 1234.9933 records/second. Loss is 2.2007954. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4228217602830603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 41600/60000][Iteration 1263][Wall Clock 127.23127628s] Trained 128 records in 0.088981177 seconds. Throughput is 1438.5066 records/second. Loss is 2.207097. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.4208664898320074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 1264][Wall Clock 127.318250848s] Trained 128 records in 0.086974568 seconds. Throughput is 1471.6946 records/second. Loss is 2.2169356. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.418912947414936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 41856/60000][Iteration 1265][Wall Clock 127.404441606s] Trained 128 records in 0.086190758 seconds. Throughput is 1485.078 records/second. Loss is 2.189825. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.416961130742049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 1266][Wall Clock 127.493614555s] Trained 128 records in 0.089172949 seconds. Throughput is 1435.4128 records/second. Loss is 2.22218. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.415011037527594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 42112/60000][Iteration 1267][Wall Clock 127.581918317s] Trained 128 records in 0.088303762 seconds. Throughput is 1449.5419 records/second. Loss is 2.222338. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.41306266548985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 1268][Wall Clock 127.666939941s] Trained 128 records in 0.085021624 seconds. Throughput is 1505.4994 records/second. Loss is 2.196892. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.411116012351124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 42368/60000][Iteration 1269][Wall Clock 127.752619957s] Trained 128 records in 0.085680016 seconds. Throughput is 1493.9307 records/second. Loss is 2.2031903. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.409171075837743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 1270][Wall Clock 127.85230126s] Trained 128 records in 0.099681303 seconds. Throughput is 1284.0924 records/second. Loss is 2.1969433. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.407227853680035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 42624/60000][Iteration 1271][Wall Clock 127.94184772s] Trained 128 records in 0.08954646 seconds. Throughput is 1429.4257 records/second. Loss is 2.2069228. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.405286343612335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:23 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 1272][Wall Clock 128.021228392s] Trained 128 records in 0.079380672 seconds. Throughput is 1612.4833 records/second. Loss is 2.2158191. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.403346543372964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 42880/60000][Iteration 1273][Wall Clock 128.109289971s] Trained 128 records in 0.088061579 seconds. Throughput is 1453.5283 records/second. Loss is 2.2001133. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.401408450704225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 1274][Wall Clock 128.199146013s] Trained 128 records in 0.089856042 seconds. Throughput is 1424.5007 records/second. Loss is 2.2244833. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3994720633523974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43136/60000][Iteration 1275][Wall Clock 128.288498494s] Trained 128 records in 0.089352481 seconds. Throughput is 1432.5288 records/second. Loss is 2.2126615. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3975373790677223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 1276][Wall Clock 128.382266302s] Trained 128 records in 0.093767808 seconds. Throughput is 1365.0741 records/second. Loss is 2.2138085. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.395604395604395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43392/60000][Iteration 1277][Wall Clock 128.471173888s] Trained 128 records in 0.088907586 seconds. Throughput is 1439.6971 records/second. Loss is 2.1899161. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3936731107205627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 1278][Wall Clock 128.560806053s] Trained 128 records in 0.089632165 seconds. Throughput is 1428.0587 records/second. Loss is 2.2105408. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3917435221783044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43648/60000][Iteration 1279][Wall Clock 128.649353985s] Trained 128 records in 0.088547932 seconds. Throughput is 1445.5448 records/second. Loss is 2.2109807. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.389815627743635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 1280][Wall Clock 128.740455226s] Trained 128 records in 0.091101241 seconds. Throughput is 1405.0302 records/second. Loss is 2.2086835. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3878894251864854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 43904/60000][Iteration 1281][Wall Clock 128.824167206s] Trained 128 records in 0.08371198 seconds. Throughput is 1529.0524 records/second. Loss is 2.2026522. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3859649122807013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 1282][Wall Clock 128.908742815s] Trained 128 records in 0.084575609 seconds. Throughput is 1513.4387 records/second. Loss is 2.20895. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.384042086804034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:24 INFO  DistriOptimizer$:408 - [Epoch 3 44160/60000][Iteration 1283][Wall Clock 128.993884407s] Trained 128 records in 0.085141592 seconds. Throughput is 1503.378 records/second. Loss is 2.205354. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3821209465381246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 1284][Wall Clock 129.079439367s] Trained 128 records in 0.08555496 seconds. Throughput is 1496.1144 records/second. Loss is 2.2097614. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.380201489268507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 44416/60000][Iteration 1285][Wall Clock 129.172489416s] Trained 128 records in 0.093050049 seconds. Throughput is 1375.6038 records/second. Loss is 2.203957. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.378283712784589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 1286][Wall Clock 129.256220568s] Trained 128 records in 0.083731152 seconds. Throughput is 1528.7023 records/second. Loss is 2.2166033. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3763676148796495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 44672/60000][Iteration 1287][Wall Clock 129.352164673s] Trained 128 records in 0.095944105 seconds. Throughput is 1334.1101 records/second. Loss is 2.203873. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.374453193350831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 1288][Wall Clock 129.446611024s] Trained 128 records in 0.094446351 seconds. Throughput is 1355.2667 records/second. Loss is 2.2118878. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3725404459991256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 44928/60000][Iteration 1289][Wall Clock 129.532172235s] Trained 128 records in 0.085561211 seconds. Throughput is 1496.005 records/second. Loss is 2.2002163. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.37062937062937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 1290][Wall Clock 129.617627154s] Trained 128 records in 0.085454919 seconds. Throughput is 1497.8658 records/second. Loss is 2.2244382. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.368719965050241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 45184/60000][Iteration 1291][Wall Clock 129.702806588s] Trained 128 records in 0.085179434 seconds. Throughput is 1502.7102 records/second. Loss is 2.213198. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.366812227074236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 1292][Wall Clock 129.788933819s] Trained 128 records in 0.086127231 seconds. Throughput is 1486.1735 records/second. Loss is 2.209522. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.364906154517678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 45440/60000][Iteration 1293][Wall Clock 129.87656456s] Trained 128 records in 0.087630741 seconds. Throughput is 1460.6747 records/second. Loss is 2.2117257. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3630017452006987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:25 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 1294][Wall Clock 129.963627718s] Trained 128 records in 0.087063158 seconds. Throughput is 1470.1971 records/second. Loss is 2.2076278. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3610989969472303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 45696/60000][Iteration 1295][Wall Clock 130.059288453s] Trained 128 records in 0.095660735 seconds. Throughput is 1338.062 records/second. Loss is 2.1891885. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3591979075850045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 1296][Wall Clock 130.155065553s] Trained 128 records in 0.0957771 seconds. Throughput is 1336.4364 records/second. Loss is 2.2078614. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.357298474945534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 45952/60000][Iteration 1297][Wall Clock 130.239020928s] Trained 128 records in 0.083955375 seconds. Throughput is 1524.6194 records/second. Loss is 2.2002423. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.355400696864111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 1298][Wall Clock 130.327047947s] Trained 128 records in 0.088027019 seconds. Throughput is 1454.099 records/second. Loss is 2.223969. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3535045711798006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46208/60000][Iteration 1299][Wall Clock 130.415308747s] Trained 128 records in 0.0882608 seconds. Throughput is 1450.2474 records/second. Loss is 2.2192886. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.351610095735422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 1300][Wall Clock 130.503070701s] Trained 128 records in 0.087761954 seconds. Throughput is 1458.4907 records/second. Loss is 2.2146823. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3497172683775554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46464/60000][Iteration 1301][Wall Clock 130.605073083s] Trained 128 records in 0.102002382 seconds. Throughput is 1254.8727 records/second. Loss is 2.2086363. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.347826086956522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 1302][Wall Clock 130.691123945s] Trained 128 records in 0.086050862 seconds. Throughput is 1487.4924 records/second. Loss is 2.1922548. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3459365493263795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46720/60000][Iteration 1303][Wall Clock 130.776408118s] Trained 128 records in 0.085284173 seconds. Throughput is 1500.8646 records/second. Loss is 2.2126029. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.344048653344917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 1304][Wall Clock 130.862131839s] Trained 128 records in 0.085723721 seconds. Throughput is 1493.169 records/second. Loss is 2.223105. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.342162396873643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:26 INFO  DistriOptimizer$:408 - [Epoch 3 46976/60000][Iteration 1305][Wall Clock 130.946803317s] Trained 128 records in 0.084671478 seconds. Throughput is 1511.7252 records/second. Loss is 2.2106793. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3402777777777775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 1306][Wall Clock 131.034320759s] Trained 128 records in 0.087517442 seconds. Throughput is 1462.5657 records/second. Loss is 2.209417. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.338394793926248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47232/60000][Iteration 1307][Wall Clock 131.121038085s] Trained 128 records in 0.086717326 seconds. Throughput is 1476.0603 records/second. Loss is 2.2109172. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.336513443191674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 1308][Wall Clock 131.209803369s] Trained 128 records in 0.088765284 seconds. Throughput is 1442.0051 records/second. Loss is 2.2120683. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.334633723450369E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47488/60000][Iteration 1309][Wall Clock 131.302764895s] Trained 128 records in 0.092961526 seconds. Throughput is 1376.9137 records/second. Loss is 2.1897633. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3327556325823227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 1310][Wall Clock 131.401026961s] Trained 128 records in 0.098262066 seconds. Throughput is 1302.639 records/second. Loss is 2.2035925. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3308791684711995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47744/60000][Iteration 1311][Wall Clock 131.499028206s] Trained 128 records in 0.098001245 seconds. Throughput is 1306.106 records/second. Loss is 2.1946857. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.329004329004329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 1312][Wall Clock 131.583588662s] Trained 128 records in 0.084560456 seconds. Throughput is 1513.71 records/second. Loss is 2.1937528. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.327131112072696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 48000/60000][Iteration 1313][Wall Clock 131.668742082s] Trained 128 records in 0.08515342 seconds. Throughput is 1503.1692 records/second. Loss is 2.2073495. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.325259515570934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 1314][Wall Clock 131.757519202s] Trained 128 records in 0.08877712 seconds. Throughput is 1441.813 records/second. Loss is 2.2263799. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.32338953739732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 48256/60000][Iteration 1315][Wall Clock 131.846342734s] Trained 128 records in 0.088823532 seconds. Throughput is 1441.0596 records/second. Loss is 2.2047477. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.32152117545376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:27 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 1316][Wall Clock 131.933431996s] Trained 128 records in 0.087089262 seconds. Throughput is 1469.7563 records/second. Loss is 2.2111456. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3196544276457883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 48512/60000][Iteration 1317][Wall Clock 132.020901008s] Trained 128 records in 0.087469012 seconds. Throughput is 1463.3754 records/second. Loss is 2.2059362. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3177892918825565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 1318][Wall Clock 132.106925338s] Trained 128 records in 0.08602433 seconds. Throughput is 1487.9512 records/second. Loss is 2.2228687. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3159257660768235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 48768/60000][Iteration 1319][Wall Clock 132.192763317s] Trained 128 records in 0.085837979 seconds. Throughput is 1491.1814 records/second. Loss is 2.19939. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.314063848144953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 1320][Wall Clock 132.28086603s] Trained 128 records in 0.088102713 seconds. Throughput is 1452.8497 records/second. Loss is 2.2148957. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3122035360068997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49024/60000][Iteration 1321][Wall Clock 132.368766819s] Trained 128 records in 0.087900789 seconds. Throughput is 1456.1871 records/second. Loss is 2.2101157. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3103448275862063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 1322][Wall Clock 132.450214664s] Trained 128 records in 0.081447845 seconds. Throughput is 1571.5579 records/second. Loss is 2.2101264. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.308487720809996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49280/60000][Iteration 1323][Wall Clock 132.533459899s] Trained 128 records in 0.083245235 seconds. Throughput is 1537.6256 records/second. Loss is 2.1841643. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.306632213608958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 1324][Wall Clock 132.618509021s] Trained 128 records in 0.085049122 seconds. Throughput is 1505.0126 records/second. Loss is 2.1877408. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3047783039173483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49536/60000][Iteration 1325][Wall Clock 132.70703094s] Trained 128 records in 0.088521919 seconds. Throughput is 1445.9695 records/second. Loss is 2.2070696. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.302925989672978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 1326][Wall Clock 132.805968911s] Trained 128 records in 0.098937971 seconds. Throughput is 1293.7399 records/second. Loss is 2.1954029. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.3010752688172043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49792/60000][Iteration 1327][Wall Clock 132.891061324s] Trained 128 records in 0.085092413 seconds. Throughput is 1504.247 records/second. Loss is 2.2090786. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.299226139294927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:28 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 1328][Wall Clock 132.976962129s] Trained 128 records in 0.085900805 seconds. Throughput is 1490.0908 records/second. Loss is 2.2061758. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.297378599054577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50048/60000][Iteration 1329][Wall Clock 133.067199727s] Trained 128 records in 0.090237598 seconds. Throughput is 1418.4775 records/second. Loss is 2.2177904. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2955326460481093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 1330][Wall Clock 133.154263607s] Trained 128 records in 0.08706388 seconds. Throughput is 1470.1849 records/second. Loss is 2.208518. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.293688278231001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50304/60000][Iteration 1331][Wall Clock 133.250777071s] Trained 128 records in 0.096513464 seconds. Throughput is 1326.2399 records/second. Loss is 2.191885. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2918454935622315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 1332][Wall Clock 133.337302601s] Trained 128 records in 0.08652553 seconds. Throughput is 1479.3322 records/second. Loss is 2.206267. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.29000429000429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50560/60000][Iteration 1333][Wall Clock 133.425150821s] Trained 128 records in 0.08784822 seconds. Throughput is 1457.0586 records/second. Loss is 2.2227774. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2881646655231566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 1334][Wall Clock 133.521762526s] Trained 128 records in 0.096611705 seconds. Throughput is 1324.8912 records/second. Loss is 2.1982563. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.286326618088298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50816/60000][Iteration 1335][Wall Clock 133.611869354s] Trained 128 records in 0.090106828 seconds. Throughput is 1420.536 records/second. Loss is 2.21028. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2844901456726646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 1336][Wall Clock 133.706751155s] Trained 128 records in 0.094881801 seconds. Throughput is 1349.0469 records/second. Loss is 2.1927786. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.282655246252677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 51072/60000][Iteration 1337][Wall Clock 133.812389437s] Trained 128 records in 0.105638282 seconds. Throughput is 1211.682 records/second. Loss is 2.1931899. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.280821917808219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:29 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 1338][Wall Clock 133.900614434s] Trained 128 records in 0.088224997 seconds. Throughput is 1450.8359 records/second. Loss is 2.1893566. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2789901583226365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 51328/60000][Iteration 1339][Wall Clock 134.010311379s] Trained 128 records in 0.109696945 seconds. Throughput is 1166.8511 records/second. Loss is 2.202097. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.27715996578272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 1340][Wall Clock 134.125890695s] Trained 128 records in 0.115579316 seconds. Throughput is 1107.4646 records/second. Loss is 2.2112374. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.275331338178709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 51584/60000][Iteration 1341][Wall Clock 134.235705176s] Trained 128 records in 0.109814481 seconds. Throughput is 1165.6022 records/second. Loss is 2.2051113. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.273504273504274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 1342][Wall Clock 134.346099277s] Trained 128 records in 0.110394101 seconds. Throughput is 1159.4823 records/second. Loss is 2.1979833. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.271678769756514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 51840/60000][Iteration 1343][Wall Clock 134.436227698s] Trained 128 records in 0.090128421 seconds. Throughput is 1420.1957 records/second. Loss is 2.2067604. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.269854824935952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 1344][Wall Clock 134.530112271s] Trained 128 records in 0.093884573 seconds. Throughput is 1363.3763 records/second. Loss is 2.2024856. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.268032437046522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 52096/60000][Iteration 1345][Wall Clock 134.622285044s] Trained 128 records in 0.092172773 seconds. Throughput is 1388.6964 records/second. Loss is 2.198648. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2662116040955626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 1346][Wall Clock 134.711831804s] Trained 128 records in 0.08954676 seconds. Throughput is 1429.4208 records/second. Loss is 2.1973333. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.264392324093817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 52352/60000][Iteration 1347][Wall Clock 134.793675074s] Trained 128 records in 0.08184327 seconds. Throughput is 1563.9648 records/second. Loss is 2.2020087. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2625745950554135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 1348][Wall Clock 134.886034939s] Trained 128 records in 0.092359865 seconds. Throughput is 1385.8834 records/second. Loss is 2.196377. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.26075841499787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:30 INFO  DistriOptimizer$:408 - [Epoch 3 52608/60000][Iteration 1349][Wall Clock 134.97341789s] Trained 128 records in 0.087382951 seconds. Throughput is 1464.8167 records/second. Loss is 2.218696. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.258943781942079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 1350][Wall Clock 135.057551545s] Trained 128 records in 0.084133655 seconds. Throughput is 1521.3888 records/second. Loss is 2.2029867. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2571306939123026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 52864/60000][Iteration 1351][Wall Clock 135.141645237s] Trained 128 records in 0.084093692 seconds. Throughput is 1522.1118 records/second. Loss is 2.1996927. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.25531914893617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 1352][Wall Clock 135.22697117s] Trained 128 records in 0.085325933 seconds. Throughput is 1500.1301 records/second. Loss is 2.2064455. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.253509145044662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53120/60000][Iteration 1353][Wall Clock 135.315307391s] Trained 128 records in 0.088336221 seconds. Throughput is 1449.0093 records/second. Loss is 2.195463. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.251700680272108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 1354][Wall Clock 135.40312767s] Trained 128 records in 0.087820279 seconds. Throughput is 1457.5222 records/second. Loss is 2.1977096. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.249893752656184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53376/60000][Iteration 1355][Wall Clock 135.49126434s] Trained 128 records in 0.08813667 seconds. Throughput is 1452.2899 records/second. Loss is 2.2067149. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.248088360237893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 1356][Wall Clock 135.579651916s] Trained 128 records in 0.088387576 seconds. Throughput is 1448.1672 records/second. Loss is 2.1879954. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.246284501061571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53632/60000][Iteration 1357][Wall Clock 135.666267356s] Trained 128 records in 0.08661544 seconds. Throughput is 1477.7965 records/second. Loss is 2.1933818. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.244482173174873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 1358][Wall Clock 135.750474964s] Trained 128 records in 0.084207608 seconds. Throughput is 1520.0526 records/second. Loss is 2.1925795. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2426813746287653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 53888/60000][Iteration 1359][Wall Clock 135.83779925s] Trained 128 records in 0.087324286 seconds. Throughput is 1465.8008 records/second. Loss is 2.194342. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2408821034775233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:31 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 1360][Wall Clock 135.932645873s] Trained 128 records in 0.094846623 seconds. Throughput is 1349.5472 records/second. Loss is 2.199211. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.23908435777872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54144/60000][Iteration 1361][Wall Clock 136.046729409s] Trained 128 records in 0.114083536 seconds. Throughput is 1121.9849 records/second. Loss is 2.2154062. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2372881355932197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 1362][Wall Clock 136.132087763s] Trained 128 records in 0.085358354 seconds. Throughput is 1499.5603 records/second. Loss is 2.211869. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.235493434985176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54400/60000][Iteration 1363][Wall Clock 136.233935242s] Trained 128 records in 0.101847479 seconds. Throughput is 1256.7812 records/second. Loss is 2.1971576. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.233700254022015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 1364][Wall Clock 136.324128776s] Trained 128 records in 0.090193534 seconds. Throughput is 1419.1705 records/second. Loss is 2.2073598. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2319085907744394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54656/60000][Iteration 1365][Wall Clock 136.411762676s] Trained 128 records in 0.0876339 seconds. Throughput is 1460.622 records/second. Loss is 2.1923034. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.230118443316413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 1366][Wall Clock 136.497705458s] Trained 128 records in 0.085942782 seconds. Throughput is 1489.363 records/second. Loss is 2.2082489. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2283298097251583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 54912/60000][Iteration 1367][Wall Clock 136.583323098s] Trained 128 records in 0.08561764 seconds. Throughput is 1495.019 records/second. Loss is 2.2055786. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2265426880811494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 1368][Wall Clock 136.695759729s] Trained 128 records in 0.112436631 seconds. Throughput is 1138.4191 records/second. Loss is 2.2065804. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.224757076468103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 55168/60000][Iteration 1369][Wall Clock 136.795687276s] Trained 128 records in 0.099927547 seconds. Throughput is 1280.9281 records/second. Loss is 2.2027717. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2229729729729727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 1370][Wall Clock 136.885452785s] Trained 128 records in 0.089765509 seconds. Throughput is 1425.9374 records/second. Loss is 2.2109797. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.221190375685944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:32 INFO  DistriOptimizer$:408 - [Epoch 3 55424/60000][Iteration 1371][Wall Clock 136.981600873s] Trained 128 records in 0.096148088 seconds. Throughput is 1331.2797 records/second. Loss is 2.1933413. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.219409282700422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 1372][Wall Clock 137.066417799s] Trained 128 records in 0.084816926 seconds. Throughput is 1509.1328 records/second. Loss is 2.1988163. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2176296921130323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 55680/60000][Iteration 1373][Wall Clock 137.150706628s] Trained 128 records in 0.084288829 seconds. Throughput is 1518.588 records/second. Loss is 2.2187498. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.215851602023609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 1374][Wall Clock 137.239951166s] Trained 128 records in 0.089244538 seconds. Throughput is 1434.2615 records/second. Loss is 2.1997766. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.214075010535187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 55936/60000][Iteration 1375][Wall Clock 137.32790667s] Trained 128 records in 0.087955504 seconds. Throughput is 1455.2812 records/second. Loss is 2.2123308. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2122999157540015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 1376][Wall Clock 137.425234009s] Trained 128 records in 0.097327339 seconds. Throughput is 1315.1495 records/second. Loss is 2.2014465. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.210526315789474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 56192/60000][Iteration 1377][Wall Clock 137.524999144s] Trained 128 records in 0.099765135 seconds. Throughput is 1283.0133 records/second. Loss is 2.1985183. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.208754208754208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 1378][Wall Clock 137.621859316s] Trained 128 records in 0.096860172 seconds. Throughput is 1321.4927 records/second. Loss is 2.1923082. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.206983592763989E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 56448/60000][Iteration 1379][Wall Clock 137.7405284s] Trained 128 records in 0.118669084 seconds. Throughput is 1078.6298 records/second. Loss is 2.211925. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.2052144659377626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 1380][Wall Clock 137.826918771s] Trained 128 records in 0.086390371 seconds. Throughput is 1481.6466 records/second. Loss is 2.2062063. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.203446826397646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:33 INFO  DistriOptimizer$:408 - [Epoch 3 56704/60000][Iteration 1381][Wall Clock 137.913138391s] Trained 128 records in 0.08621962 seconds. Throughput is 1484.5808 records/second. Loss is 2.1896951. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.201680672268908E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 1382][Wall Clock 138.007853635s] Trained 128 records in 0.094715244 seconds. Throughput is 1351.4192 records/second. Loss is 2.203463. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.199916001679966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 56960/60000][Iteration 1383][Wall Clock 138.118821348s] Trained 128 records in 0.110967713 seconds. Throughput is 1153.4886 records/second. Loss is 2.214485. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1981528127623844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 1384][Wall Clock 138.209835152s] Trained 128 records in 0.091013804 seconds. Throughput is 1406.3801 records/second. Loss is 2.2019281. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.19639110365086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57216/60000][Iteration 1385][Wall Clock 138.297992988s] Trained 128 records in 0.088157836 seconds. Throughput is 1451.9413 records/second. Loss is 2.188969. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.194630872483221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 1386][Wall Clock 138.388412063s] Trained 128 records in 0.090419075 seconds. Throughput is 1415.6305 records/second. Loss is 2.2103233. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1928721174004196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57472/60000][Iteration 1387][Wall Clock 138.480884657s] Trained 128 records in 0.092472594 seconds. Throughput is 1384.194 records/second. Loss is 2.1917868. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1911148365465214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 1388][Wall Clock 138.568844316s] Trained 128 records in 0.087959659 seconds. Throughput is 1455.2125 records/second. Loss is 2.1967432. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1893590280687055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57728/60000][Iteration 1389][Wall Clock 138.663721826s] Trained 128 records in 0.09487751 seconds. Throughput is 1349.1079 records/second. Loss is 2.203997. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.187604690117253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 1390][Wall Clock 138.750726044s] Trained 128 records in 0.087004218 seconds. Throughput is 1471.1931 records/second. Loss is 2.197735. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1858518208455416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 57984/60000][Iteration 1391][Wall Clock 138.839526498s] Trained 128 records in 0.088800454 seconds. Throughput is 1441.4341 records/second. Loss is 2.2028708. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1841004184100416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:34 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 1392][Wall Clock 138.930201537s] Trained 128 records in 0.090675039 seconds. Throughput is 1411.6343 records/second. Loss is 2.200328. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.182350480970305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 58240/60000][Iteration 1393][Wall Clock 139.020351675s] Trained 128 records in 0.090150138 seconds. Throughput is 1419.8536 records/second. Loss is 2.1793964. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1806020066889626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 1394][Wall Clock 139.110040286s] Trained 128 records in 0.089688611 seconds. Throughput is 1427.16 records/second. Loss is 2.1996298. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.178854993731718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 58496/60000][Iteration 1395][Wall Clock 139.201144031s] Trained 128 records in 0.091103745 seconds. Throughput is 1404.9916 records/second. Loss is 2.187832. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.177109440267335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 1396][Wall Clock 139.294893015s] Trained 128 records in 0.093748984 seconds. Throughput is 1365.3481 records/second. Loss is 2.191375. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.175365344467641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 58752/60000][Iteration 1397][Wall Clock 139.389372469s] Trained 128 records in 0.094479454 seconds. Throughput is 1354.7919 records/second. Loss is 2.192989. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1736227045075126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 1398][Wall Clock 139.473942657s] Trained 128 records in 0.084570188 seconds. Throughput is 1513.5358 records/second. Loss is 2.1992843. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1718815185648727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 59008/60000][Iteration 1399][Wall Clock 139.564557189s] Trained 128 records in 0.090614532 seconds. Throughput is 1412.5769 records/second. Loss is 2.2091727. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.170141784820684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 1400][Wall Clock 139.659431176s] Trained 128 records in 0.094873987 seconds. Throughput is 1349.158 records/second. Loss is 2.2250319. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1684035014589413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 59264/60000][Iteration 1401][Wall Clock 139.748786908s] Trained 128 records in 0.089355732 seconds. Throughput is 1432.4767 records/second. Loss is 2.212716. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1666666666666664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 1402][Wall Clock 139.837037293s] Trained 128 records in 0.088250385 seconds. Throughput is 1450.4186 records/second. Loss is 2.216299. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1649312786339027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:35 INFO  DistriOptimizer$:408 - [Epoch 3 59520/60000][Iteration 1403][Wall Clock 139.926859751s] Trained 128 records in 0.089822458 seconds. Throughput is 1425.0334 records/second. Loss is 2.1983793. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1631973355537054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:36 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 1404][Wall Clock 140.016246994s] Trained 128 records in 0.089387243 seconds. Throughput is 1431.9717 records/second. Loss is 2.1957974. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.161464835622139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:36 INFO  DistriOptimizer$:408 - [Epoch 3 59776/60000][Iteration 1405][Wall Clock 140.108384715s] Trained 128 records in 0.092137721 seconds. Throughput is 1389.2247 records/second. Loss is 2.203363. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1597337770382697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:36 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 1406][Wall Clock 140.199637278s] Trained 128 records in 0.091252563 seconds. Throughput is 1402.7003 records/second. Loss is 2.204655. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1580041580041577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:36 INFO  DistriOptimizer$:408 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.292281341s] Trained 128 records in 0.092644063 seconds. Throughput is 1381.632 records/second. Loss is 2.1994205. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1562759767248546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:36 INFO  DistriOptimizer$:452 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.292281341s] Epoch finished. Wall clock time is 141439.111267 ms
2019-10-14 23:13:36 INFO  DistriOptimizer$:111 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.292281341s] Validate model...
2019-10-14 23:13:37 INFO  DistriOptimizer$:178 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.292281341s] validate model throughput is 10420.933 records/second
2019-10-14 23:13:37 INFO  DistriOptimizer$:181 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.292281341s] Top1Accuracy is Accuracy(correct: 4098, count: 10000, accuracy: 0.4098)
2019-10-14 23:13:37 INFO  DistriOptimizer$:221 - [Wall Clock 141.439111267s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:13:37 INFO  DistriOptimizer$:226 - [Wall Clock 141.439111267s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:13:37 INFO  DistriOptimizer$:408 - [Epoch 4 128/60000][Iteration 1408][Wall Clock 141.538677436s] Trained 128 records in 0.099566169 seconds. Throughput is 1285.5773 records/second. Loss is 2.184001. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.154549231408392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:37 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 1409][Wall Clock 141.628595266s] Trained 128 records in 0.08991783 seconds. Throughput is 1423.5219 records/second. Loss is 2.1978087. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.152823920265781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:37 INFO  DistriOptimizer$:408 - [Epoch 4 384/60000][Iteration 1410][Wall Clock 141.719952194s] Trained 128 records in 0.091356928 seconds. Throughput is 1401.0979 records/second. Loss is 2.1980038. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.151100041511001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:37 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 1411][Wall Clock 141.80943735s] Trained 128 records in 0.089485156 seconds. Throughput is 1430.4049 records/second. Loss is 2.2119188. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.149377593360996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:37 INFO  DistriOptimizer$:408 - [Epoch 4 640/60000][Iteration 1412][Wall Clock 141.898964505s] Trained 128 records in 0.089527155 seconds. Throughput is 1429.7339 records/second. Loss is 2.1932056. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.14765657403567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:37 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 1413][Wall Clock 142.002921321s] Trained 128 records in 0.103956816 seconds. Throughput is 1231.2805 records/second. Loss is 2.1981616. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1459369817578774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 896/60000][Iteration 1414][Wall Clock 142.098026921s] Trained 128 records in 0.0951056 seconds. Throughput is 1345.8723 records/second. Loss is 2.2097385. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.144218814753419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 1415][Wall Clock 142.188482376s] Trained 128 records in 0.090455455 seconds. Throughput is 1415.0612 records/second. Loss is 2.1815119. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1425020712510365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1152/60000][Iteration 1416][Wall Clock 142.272693242s] Trained 128 records in 0.084210866 seconds. Throughput is 1519.9939 records/second. Loss is 2.1898577. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1407867494824016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 1417][Wall Clock 142.381213023s] Trained 128 records in 0.108519781 seconds. Throughput is 1179.5085 records/second. Loss is 2.1898541. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.139072847682119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1408/60000][Iteration 1418][Wall Clock 142.474730975s] Trained 128 records in 0.093517952 seconds. Throughput is 1368.7212 records/second. Loss is 2.1966493. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1373603640877123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 1419][Wall Clock 142.560471662s] Trained 128 records in 0.085740687 seconds. Throughput is 1492.8735 records/second. Loss is 2.1871982. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1356492969396195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1664/60000][Iteration 1420][Wall Clock 142.647643122s] Trained 128 records in 0.08717146 seconds. Throughput is 1468.3705 records/second. Loss is 2.2021868. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1339396444811904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 1421][Wall Clock 142.742406016s] Trained 128 records in 0.094762894 seconds. Throughput is 1350.7397 records/second. Loss is 2.2131345. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.132231404958678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 1920/60000][Iteration 1422][Wall Clock 142.828811188s] Trained 128 records in 0.086405172 seconds. Throughput is 1481.3928 records/second. Loss is 2.2121613. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1305245766212306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 1423][Wall Clock 142.921105733s] Trained 128 records in 0.092294545 seconds. Throughput is 1386.8643 records/second. Loss is 2.1908646. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.128819157720892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:38 INFO  DistriOptimizer$:408 - [Epoch 4 2176/60000][Iteration 1424][Wall Clock 143.012907302s] Trained 128 records in 0.091801569 seconds. Throughput is 1394.3116 records/second. Loss is 2.1762195. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.127115146512588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 1425][Wall Clock 143.102175366s] Trained 128 records in 0.089268064 seconds. Throughput is 1433.8834 records/second. Loss is 2.1797907. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1254125412541255E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 2432/60000][Iteration 1426][Wall Clock 143.193165742s] Trained 128 records in 0.090990376 seconds. Throughput is 1406.7422 records/second. Loss is 2.1899266. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.123711340206186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 1427][Wall Clock 143.286224232s] Trained 128 records in 0.09305849 seconds. Throughput is 1375.479 records/second. Loss is 2.1955962. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1220115416323167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 2688/60000][Iteration 1428][Wall Clock 143.378270741s] Trained 128 records in 0.092046509 seconds. Throughput is 1390.6014 records/second. Loss is 2.193817. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1203131437989287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 1429][Wall Clock 143.4717954s] Trained 128 records in 0.093524659 seconds. Throughput is 1368.623 records/second. Loss is 2.1912718. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1186161449752884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 2944/60000][Iteration 1430][Wall Clock 143.561822052s] Trained 128 records in 0.090026652 seconds. Throughput is 1421.8011 records/second. Loss is 2.1889486. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.116920543433511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 1431][Wall Clock 143.653572964s] Trained 128 records in 0.091750912 seconds. Throughput is 1395.0815 records/second. Loss is 2.171579. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.11522633744856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 3200/60000][Iteration 1432][Wall Clock 143.740449392s] Trained 128 records in 0.086876428 seconds. Throughput is 1473.357 records/second. Loss is 2.209326. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1135335252982314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 1433][Wall Clock 143.826788131s] Trained 128 records in 0.086338739 seconds. Throughput is 1482.5327 records/second. Loss is 2.2028368. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.111842105263158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 3456/60000][Iteration 1434][Wall Clock 143.913403523s] Trained 128 records in 0.086615392 seconds. Throughput is 1477.7974 records/second. Loss is 2.200486. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1101520756267986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:39 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 1435][Wall Clock 144.00202867s] Trained 128 records in 0.088625147 seconds. Throughput is 1444.2853 records/second. Loss is 2.1981103. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.108463434675431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 3712/60000][Iteration 1436][Wall Clock 144.090059328s] Trained 128 records in 0.088030658 seconds. Throughput is 1454.0388 records/second. Loss is 2.205739. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.106776180698152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 1437][Wall Clock 144.177281369s] Trained 128 records in 0.087222041 seconds. Throughput is 1467.519 records/second. Loss is 2.1971333. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.105090311986864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 3968/60000][Iteration 1438][Wall Clock 144.26512946s] Trained 128 records in 0.087848091 seconds. Throughput is 1457.0607 records/second. Loss is 2.205175. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.1034058268362735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 1439][Wall Clock 144.364239424s] Trained 128 records in 0.099109964 seconds. Throughput is 1291.4948 records/second. Loss is 2.1836889. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.101722723543889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4224/60000][Iteration 1440][Wall Clock 144.442400733s] Trained 128 records in 0.078161309 seconds. Throughput is 1637.6389 records/second. Loss is 2.1928635. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.100041000410004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 1441][Wall Clock 144.523720058s] Trained 128 records in 0.081319325 seconds. Throughput is 1574.0416 records/second. Loss is 2.194977. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.098360655737705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4480/60000][Iteration 1442][Wall Clock 144.612615771s] Trained 128 records in 0.088895713 seconds. Throughput is 1439.8894 records/second. Loss is 2.2144907. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.096681687832856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 1443][Wall Clock 144.703906344s] Trained 128 records in 0.091290573 seconds. Throughput is 1402.1163 records/second. Loss is 2.1762435. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0950040950040947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4736/60000][Iteration 1444][Wall Clock 144.790516158s] Trained 128 records in 0.086609814 seconds. Throughput is 1477.8926 records/second. Loss is 2.1905348. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0933278755628325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 1445][Wall Clock 144.877250691s] Trained 128 records in 0.086734533 seconds. Throughput is 1475.7675 records/second. Loss is 2.1939232. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.091653027823241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:40 INFO  DistriOptimizer$:408 - [Epoch 4 4992/60000][Iteration 1446][Wall Clock 144.964230721s] Trained 128 records in 0.08698003 seconds. Throughput is 1471.6022 records/second. Loss is 2.2033901. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.089979550102249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 1447][Wall Clock 145.05311717s] Trained 128 records in 0.088886449 seconds. Throughput is 1440.0396 records/second. Loss is 2.2030106. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.088307440719543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5248/60000][Iteration 1448][Wall Clock 145.130084908s] Trained 128 records in 0.076967738 seconds. Throughput is 1663.0344 records/second. Loss is 2.2071545. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.086636697997548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 1449][Wall Clock 145.216580994s] Trained 128 records in 0.086496086 seconds. Throughput is 1479.8358 records/second. Loss is 2.1976147. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.084967320261438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5504/60000][Iteration 1450][Wall Clock 145.303641901s] Trained 128 records in 0.087060907 seconds. Throughput is 1470.2351 records/second. Loss is 2.194048. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.083299305839118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 1451][Wall Clock 145.389797441s] Trained 128 records in 0.08615554 seconds. Throughput is 1485.685 records/second. Loss is 2.185076. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.081632653061224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5760/60000][Iteration 1452][Wall Clock 145.48011524s] Trained 128 records in 0.090317799 seconds. Throughput is 1417.2179 records/second. Loss is 2.1808686. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.079967360261118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 1453][Wall Clock 145.566879772s] Trained 128 records in 0.086764532 seconds. Throughput is 1475.2572 records/second. Loss is 2.2034714. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.078303425774878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 6016/60000][Iteration 1454][Wall Clock 145.654684334s] Trained 128 records in 0.087804562 seconds. Throughput is 1457.783 records/second. Loss is 2.1931689. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.076640847941296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 1455][Wall Clock 145.742095703s] Trained 128 records in 0.087411369 seconds. Throughput is 1464.3405 records/second. Loss is 2.1961863. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.074979625101875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 6272/60000][Iteration 1456][Wall Clock 145.82957043s] Trained 128 records in 0.087474727 seconds. Throughput is 1463.2798 records/second. Loss is 2.19859. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.073319755600815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 1457][Wall Clock 145.914824125s] Trained 128 records in 0.085253695 seconds. Throughput is 1501.4012 records/second. Loss is 2.1983616. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0716612377850165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:41 INFO  DistriOptimizer$:408 - [Epoch 4 6528/60000][Iteration 1458][Wall Clock 146.00240825s] Trained 128 records in 0.087584125 seconds. Throughput is 1461.4521 records/second. Loss is 2.2106853. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0700040700040704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 1459][Wall Clock 146.089820512s] Trained 128 records in 0.087412262 seconds. Throughput is 1464.3254 records/second. Loss is 2.1859477. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.068348250610252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 6784/60000][Iteration 1460][Wall Clock 146.177665101s] Trained 128 records in 0.087844589 seconds. Throughput is 1457.1188 records/second. Loss is 2.1849182. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0666937779585197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 1461][Wall Clock 146.263342872s] Trained 128 records in 0.085677771 seconds. Throughput is 1493.9697 records/second. Loss is 2.1912708. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.065040650406504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7040/60000][Iteration 1462][Wall Clock 146.352322064s] Trained 128 records in 0.088979192 seconds. Throughput is 1438.5386 records/second. Loss is 2.20019. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.063388866314506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 1463][Wall Clock 146.439898163s] Trained 128 records in 0.087576099 seconds. Throughput is 1461.586 records/second. Loss is 2.2061198. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.061738424045492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7296/60000][Iteration 1464][Wall Clock 146.527259673s] Trained 128 records in 0.08736151 seconds. Throughput is 1465.1761 records/second. Loss is 2.1967688. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.060089321965083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 1465][Wall Clock 146.626801327s] Trained 128 records in 0.099541654 seconds. Throughput is 1285.8938 records/second. Loss is 2.1949196. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0584415584415587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7552/60000][Iteration 1466][Wall Clock 146.722789357s] Trained 128 records in 0.09598803 seconds. Throughput is 1333.4996 records/second. Loss is 2.1838658. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.056795131845842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 1467][Wall Clock 146.806343039s] Trained 128 records in 0.083553682 seconds. Throughput is 1531.9493 records/second. Loss is 2.1787224. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0551500405515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7808/60000][Iteration 1468][Wall Clock 146.891869789s] Trained 128 records in 0.08552675 seconds. Throughput is 1496.6078 records/second. Loss is 2.190816. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0535062829347385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:42 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 1469][Wall Clock 146.979249312s] Trained 128 records in 0.087379523 seconds. Throughput is 1464.8741 records/second. Loss is 2.1995573. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0518638573743926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8064/60000][Iteration 1470][Wall Clock 147.066803332s] Trained 128 records in 0.08755402 seconds. Throughput is 1461.9546 records/second. Loss is 2.1894424. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0502227622519235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 1471][Wall Clock 147.157445015s] Trained 128 records in 0.090641683 seconds. Throughput is 1412.1538 records/second. Loss is 2.192682. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0485829959514174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8320/60000][Iteration 1472][Wall Clock 147.254535891s] Trained 128 records in 0.097090876 seconds. Throughput is 1318.3525 records/second. Loss is 2.1985261. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.046944556859571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 1473][Wall Clock 147.347365197s] Trained 128 records in 0.092829306 seconds. Throughput is 1378.8749 records/second. Loss is 2.1800294. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.045307443365696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8576/60000][Iteration 1474][Wall Clock 147.439344446s] Trained 128 records in 0.091979249 seconds. Throughput is 1391.6182 records/second. Loss is 2.2097704. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.043671653861707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 1475][Wall Clock 147.529346184s] Trained 128 records in 0.090001738 seconds. Throughput is 1422.1947 records/second. Loss is 2.1935148. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.042037186742118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8832/60000][Iteration 1476][Wall Clock 147.616835499s] Trained 128 records in 0.087489315 seconds. Throughput is 1463.0358 records/second. Loss is 2.2131789. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0404040404040404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 1477][Wall Clock 147.703631325s] Trained 128 records in 0.086795826 seconds. Throughput is 1474.7252 records/second. Loss is 2.1968925. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.038772213247173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 9088/60000][Iteration 1478][Wall Clock 147.789080795s] Trained 128 records in 0.08544947 seconds. Throughput is 1497.9613 records/second. Loss is 2.197429. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.037141703673799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 1479][Wall Clock 147.875683392s] Trained 128 records in 0.086602597 seconds. Throughput is 1478.0157 records/second. Loss is 2.196017. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0355125100887816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:43 INFO  DistriOptimizer$:408 - [Epoch 4 9344/60000][Iteration 1480][Wall Clock 147.964430028s] Trained 128 records in 0.088746636 seconds. Throughput is 1442.3082 records/second. Loss is 2.1825604. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.033884630899556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 1481][Wall Clock 148.051488326s] Trained 128 records in 0.087058298 seconds. Throughput is 1470.2792 records/second. Loss is 2.1803665. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.032258064516129E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 9600/60000][Iteration 1482][Wall Clock 148.139304622s] Trained 128 records in 0.087816296 seconds. Throughput is 1457.5883 records/second. Loss is 2.1853158. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0306328093510683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 1483][Wall Clock 148.224872672s] Trained 128 records in 0.08556805 seconds. Throughput is 1495.8855 records/second. Loss is 2.193594. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0290088638195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 9856/60000][Iteration 1484][Wall Clock 148.31236665s] Trained 128 records in 0.087493978 seconds. Throughput is 1462.9578 records/second. Loss is 2.1836162. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.027386226339106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 1485][Wall Clock 148.400955913s] Trained 128 records in 0.088589263 seconds. Throughput is 1444.8704 records/second. Loss is 2.2021902. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0257648953301127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10112/60000][Iteration 1486][Wall Clock 148.484991175s] Trained 128 records in 0.084035262 seconds. Throughput is 1523.1702 records/second. Loss is 2.195816. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.024144869215291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 1487][Wall Clock 148.571488578s] Trained 128 records in 0.086497403 seconds. Throughput is 1479.8132 records/second. Loss is 2.1969752. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.022526146419952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10368/60000][Iteration 1488][Wall Clock 148.659083742s] Trained 128 records in 0.087595164 seconds. Throughput is 1461.2678 records/second. Loss is 2.195379. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.020908725371934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 1489][Wall Clock 148.744508532s] Trained 128 records in 0.08542479 seconds. Throughput is 1498.3942 records/second. Loss is 2.1872346. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0192926045016077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10624/60000][Iteration 1490][Wall Clock 148.835807052s] Trained 128 records in 0.09129852 seconds. Throughput is 1401.9943 records/second. Loss is 2.204744. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0176777822418646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 1491][Wall Clock 148.916385192s] Trained 128 records in 0.08057814 seconds. Throughput is 1588.5201 records/second. Loss is 2.187209. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.016064257028112E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:44 INFO  DistriOptimizer$:408 - [Epoch 4 10880/60000][Iteration 1492][Wall Clock 148.998574958s] Trained 128 records in 0.082189766 seconds. Throughput is 1557.3715 records/second. Loss is 2.1876357. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.014452027298274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 1493][Wall Clock 149.088047627s] Trained 128 records in 0.089472669 seconds. Throughput is 1430.6045 records/second. Loss is 2.1688256. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.012841091492777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11136/60000][Iteration 1494][Wall Clock 149.176683099s] Trained 128 records in 0.088635472 seconds. Throughput is 1444.1171 records/second. Loss is 2.199134. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0112314480545525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 1495][Wall Clock 149.264962501s] Trained 128 records in 0.088279402 seconds. Throughput is 1449.9418 records/second. Loss is 2.1810975. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.00962309542903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11392/60000][Iteration 1496][Wall Clock 149.354224769s] Trained 128 records in 0.089262268 seconds. Throughput is 1433.9766 records/second. Loss is 2.1827693. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.008016032064128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 1497][Wall Clock 149.44398603s] Trained 128 records in 0.089761261 seconds. Throughput is 1426.0049 records/second. Loss is 2.1990445. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0064102564102563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11648/60000][Iteration 1498][Wall Clock 149.536766586s] Trained 128 records in 0.092780556 seconds. Throughput is 1379.5995 records/second. Loss is 2.1770093. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.004805766920305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 1499][Wall Clock 149.628613311s] Trained 128 records in 0.091846725 seconds. Throughput is 1393.6261 records/second. Loss is 2.175951. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0032025620496394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 11904/60000][Iteration 1500][Wall Clock 149.716357144s] Trained 128 records in 0.087743833 seconds. Throughput is 1458.792 records/second. Loss is 2.1770902. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.001600640256102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 1501][Wall Clock 149.80485101s] Trained 128 records in 0.088493866 seconds. Throughput is 1446.4279 records/second. Loss is 2.2109883. Sequentialdaab25a8's hyper parameters: Current learning rate is 4.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 12160/60000][Iteration 1502][Wall Clock 149.890637486s] Trained 128 records in 0.085786476 seconds. Throughput is 1492.0767 records/second. Loss is 2.1921637. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.998400639744102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:45 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 1503][Wall Clock 149.974722588s] Trained 128 records in 0.084085102 seconds. Throughput is 1522.2673 records/second. Loss is 2.1970522. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9968025579536375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 12416/60000][Iteration 1504][Wall Clock 150.06356106s] Trained 128 records in 0.088838472 seconds. Throughput is 1440.8173 records/second. Loss is 2.1730294. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9952057530962844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 1505][Wall Clock 150.149260935s] Trained 128 records in 0.085699875 seconds. Throughput is 1493.5844 records/second. Loss is 2.2015443. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9936102236421724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 12672/60000][Iteration 1506][Wall Clock 150.234708424s] Trained 128 records in 0.085447489 seconds. Throughput is 1497.996 records/second. Loss is 2.1952076. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9920159680638726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 1507][Wall Clock 150.321669404s] Trained 128 records in 0.08696098 seconds. Throughput is 1471.9246 records/second. Loss is 2.183308. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9904229848363923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 12928/60000][Iteration 1508][Wall Clock 150.408102228s] Trained 128 records in 0.086432824 seconds. Throughput is 1480.919 records/second. Loss is 2.203233. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9888312724371757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 1509][Wall Clock 150.497379952s] Trained 128 records in 0.089277724 seconds. Throughput is 1433.7284 records/second. Loss is 2.1827936. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9872408293460925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 13184/60000][Iteration 1510][Wall Clock 150.584039815s] Trained 128 records in 0.086659863 seconds. Throughput is 1477.0391 records/second. Loss is 2.2057176. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.985651654045436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 1511][Wall Clock 150.671254255s] Trained 128 records in 0.08721444 seconds. Throughput is 1467.6469 records/second. Loss is 2.201443. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.984063745019921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 13440/60000][Iteration 1512][Wall Clock 150.759170283s] Trained 128 records in 0.087916028 seconds. Throughput is 1455.9347 records/second. Loss is 2.20523. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9824771007566706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 1513][Wall Clock 150.846199439s] Trained 128 records in 0.087029156 seconds. Throughput is 1470.7714 records/second. Loss is 2.1823084. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.980891719745223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:46 INFO  DistriOptimizer$:408 - [Epoch 4 13696/60000][Iteration 1514][Wall Clock 150.934047658s] Trained 128 records in 0.087848219 seconds. Throughput is 1457.0586 records/second. Loss is 2.1991699. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9793076004775174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 1515][Wall Clock 151.019446202s] Trained 128 records in 0.085398544 seconds. Throughput is 1498.8545 records/second. Loss is 2.1985993. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9777247414478914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 13952/60000][Iteration 1516][Wall Clock 151.112365735s] Trained 128 records in 0.092919533 seconds. Throughput is 1377.5359 records/second. Loss is 2.193609. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9761431411530816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 1517][Wall Clock 151.194833366s] Trained 128 records in 0.082467631 seconds. Throughput is 1552.1241 records/second. Loss is 2.188955. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.97456279809221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14208/60000][Iteration 1518][Wall Clock 151.282974412s] Trained 128 records in 0.088141046 seconds. Throughput is 1452.2179 records/second. Loss is 2.1766148. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9729837107667853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 1519][Wall Clock 151.374126768s] Trained 128 records in 0.091152356 seconds. Throughput is 1404.2424 records/second. Loss is 2.192596. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9714058776806993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14464/60000][Iteration 1520][Wall Clock 151.46117499s] Trained 128 records in 0.087048222 seconds. Throughput is 1470.4493 records/second. Loss is 2.1913855. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.969829297340214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 1521][Wall Clock 151.552556774s] Trained 128 records in 0.091381784 seconds. Throughput is 1400.7168 records/second. Loss is 2.179892. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.968253968253968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14720/60000][Iteration 1522][Wall Clock 151.639398028s] Trained 128 records in 0.086841254 seconds. Throughput is 1473.9539 records/second. Loss is 2.1919649. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.966679888932963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 1523][Wall Clock 151.725570797s] Trained 128 records in 0.086172769 seconds. Throughput is 1485.3881 records/second. Loss is 2.202918. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9651070578905625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 14976/60000][Iteration 1524][Wall Clock 151.821524705s] Trained 128 records in 0.095953908 seconds. Throughput is 1333.9738 records/second. Loss is 2.187607. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.963535473642489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 1525][Wall Clock 151.909848895s] Trained 128 records in 0.08832419 seconds. Throughput is 1449.2067 records/second. Loss is 2.201095. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.961965134706815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:47 INFO  DistriOptimizer$:408 - [Epoch 4 15232/60000][Iteration 1526][Wall Clock 151.998490182s] Trained 128 records in 0.088641287 seconds. Throughput is 1444.0223 records/second. Loss is 2.2024016. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.96039603960396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 1527][Wall Clock 152.083715321s] Trained 128 records in 0.085225139 seconds. Throughput is 1501.9042 records/second. Loss is 2.1866906. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.958828186856691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 15488/60000][Iteration 1528][Wall Clock 152.172677463s] Trained 128 records in 0.088962142 seconds. Throughput is 1438.8142 records/second. Loss is 2.181285. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.957261574990107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 1529][Wall Clock 152.263403433s] Trained 128 records in 0.09072597 seconds. Throughput is 1410.8418 records/second. Loss is 2.1849794. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9556962025316455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 15744/60000][Iteration 1530][Wall Clock 152.352176084s] Trained 128 records in 0.088772651 seconds. Throughput is 1441.8855 records/second. Loss is 2.2037117. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9541320680110717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 1531][Wall Clock 152.439983152s] Trained 128 records in 0.087807068 seconds. Throughput is 1457.7415 records/second. Loss is 2.186028. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.952569169960474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 16000/60000][Iteration 1532][Wall Clock 152.525250925s] Trained 128 records in 0.085267773 seconds. Throughput is 1501.1533 records/second. Loss is 2.1900742. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.951007506914263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 1533][Wall Clock 152.617053654s] Trained 128 records in 0.091802729 seconds. Throughput is 1394.2941 records/second. Loss is 2.1740887. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9494470774091627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 16256/60000][Iteration 1534][Wall Clock 152.703891033s] Trained 128 records in 0.086837379 seconds. Throughput is 1474.0195 records/second. Loss is 2.1882825. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.947887879984208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 1535][Wall Clock 152.788420391s] Trained 128 records in 0.084529358 seconds. Throughput is 1514.2668 records/second. Loss is 2.1817899. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9463299131807424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 16512/60000][Iteration 1536][Wall Clock 152.875327345s] Trained 128 records in 0.086906954 seconds. Throughput is 1472.8396 records/second. Loss is 2.1726117. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.944773175542406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:48 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 1537][Wall Clock 152.961291605s] Trained 128 records in 0.08596426 seconds. Throughput is 1488.9908 records/second. Loss is 2.1988006. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.943217665615142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 16768/60000][Iteration 1538][Wall Clock 153.0453268s] Trained 128 records in 0.084035195 seconds. Throughput is 1523.1714 records/second. Loss is 2.1866121. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.941663381947182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 1539][Wall Clock 153.138506471s] Trained 128 records in 0.093179671 seconds. Throughput is 1373.6902 records/second. Loss is 2.1813858. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.940110323089046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17024/60000][Iteration 1540][Wall Clock 153.226061731s] Trained 128 records in 0.08755526 seconds. Throughput is 1461.9338 records/second. Loss is 2.1885827. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.938558487593541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 1541][Wall Clock 153.320780711s] Trained 128 records in 0.09471898 seconds. Throughput is 1351.366 records/second. Loss is 2.1802404. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.937007874015748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17280/60000][Iteration 1542][Wall Clock 153.396911389s] Trained 128 records in 0.076130678 seconds. Throughput is 1681.3196 records/second. Loss is 2.199646. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9354584809130267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 1543][Wall Clock 153.48779298s] Trained 128 records in 0.090881591 seconds. Throughput is 1408.426 records/second. Loss is 2.203558. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9339103068450045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17536/60000][Iteration 1544][Wall Clock 153.581542515s] Trained 128 records in 0.093749535 seconds. Throughput is 1365.3401 records/second. Loss is 2.174729. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9323633503735744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 1545][Wall Clock 153.668051797s] Trained 128 records in 0.086509282 seconds. Throughput is 1479.6101 records/second. Loss is 2.190961. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9308176100628933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17792/60000][Iteration 1546][Wall Clock 153.756701209s] Trained 128 records in 0.088649412 seconds. Throughput is 1443.89 records/second. Loss is 2.1787715. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9292730844793717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 1547][Wall Clock 153.849687092s] Trained 128 records in 0.092985883 seconds. Throughput is 1376.553 records/second. Loss is 2.190665. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.927729772191673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:49 INFO  DistriOptimizer$:408 - [Epoch 4 18048/60000][Iteration 1548][Wall Clock 153.936973148s] Trained 128 records in 0.087286056 seconds. Throughput is 1466.4427 records/second. Loss is 2.182143. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.926187671770711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 1549][Wall Clock 154.028920135s] Trained 128 records in 0.091946987 seconds. Throughput is 1392.1064 records/second. Loss is 2.1803205. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.924646781789639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18304/60000][Iteration 1550][Wall Clock 154.114293418s] Trained 128 records in 0.085373283 seconds. Throughput is 1499.2981 records/second. Loss is 2.1982224. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9231071008238524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 1551][Wall Clock 154.202517133s] Trained 128 records in 0.088223715 seconds. Throughput is 1450.857 records/second. Loss is 2.2067177. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.921568627450981E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18560/60000][Iteration 1552][Wall Clock 154.290624031s] Trained 128 records in 0.088106898 seconds. Throughput is 1452.7806 records/second. Loss is 2.18336. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.920031360250882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 1553][Wall Clock 154.378657042s] Trained 128 records in 0.088033011 seconds. Throughput is 1454.0 records/second. Loss is 2.1751008. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9184952978056425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18816/60000][Iteration 1554][Wall Clock 154.46556254s] Trained 128 records in 0.086905498 seconds. Throughput is 1472.8643 records/second. Loss is 2.2018435. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9169604386995695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 1555][Wall Clock 154.573542415s] Trained 128 records in 0.107979875 seconds. Throughput is 1185.4061 records/second. Loss is 2.174103. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.915426781519185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 19072/60000][Iteration 1556][Wall Clock 154.660847541s] Trained 128 records in 0.087305126 seconds. Throughput is 1466.1223 records/second. Loss is 2.1929157. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9138943248532296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 1557][Wall Clock 154.74698527s] Trained 128 records in 0.086137729 seconds. Throughput is 1485.9923 records/second. Loss is 2.176985. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.912363067292645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 19328/60000][Iteration 1558][Wall Clock 154.833750622s] Trained 128 records in 0.086765352 seconds. Throughput is 1475.2433 records/second. Loss is 2.193702. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.910833007430583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:50 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 1559][Wall Clock 154.919229561s] Trained 128 records in 0.085478939 seconds. Throughput is 1497.4448 records/second. Loss is 2.1977584. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.909304143862393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 19584/60000][Iteration 1560][Wall Clock 155.005531405s] Trained 128 records in 0.086301844 seconds. Throughput is 1483.1665 records/second. Loss is 2.1966896. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.907776475185619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 1561][Wall Clock 155.093538182s] Trained 128 records in 0.088006777 seconds. Throughput is 1454.4333 records/second. Loss is 2.1857848. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.90625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 19840/60000][Iteration 1562][Wall Clock 155.181915176s] Trained 128 records in 0.088376994 seconds. Throughput is 1448.3408 records/second. Loss is 2.2041419. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.904724716907458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 1563][Wall Clock 155.270719002s] Trained 128 records in 0.088803826 seconds. Throughput is 1441.3793 records/second. Loss is 2.1877508. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9032006245120994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20096/60000][Iteration 1564][Wall Clock 155.357672277s] Trained 128 records in 0.086953275 seconds. Throughput is 1472.0549 records/second. Loss is 2.19025. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.9016777214202113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 1565][Wall Clock 155.444460959s] Trained 128 records in 0.086788682 seconds. Throughput is 1474.8467 records/second. Loss is 2.1729853. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.90015600624025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20352/60000][Iteration 1566][Wall Clock 155.531958104s] Trained 128 records in 0.087497145 seconds. Throughput is 1462.9049 records/second. Loss is 2.1717074. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.898635477582846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 1567][Wall Clock 155.627756633s] Trained 128 records in 0.095798529 seconds. Throughput is 1336.1375 records/second. Loss is 2.1869833. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.897116134060795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20608/60000][Iteration 1568][Wall Clock 155.721889985s] Trained 128 records in 0.094133352 seconds. Throughput is 1359.7731 records/second. Loss is 2.176288. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8955979742890534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 1569][Wall Clock 155.805941784s] Trained 128 records in 0.084051799 seconds. Throughput is 1522.8705 records/second. Loss is 2.183149. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.894080996884735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20864/60000][Iteration 1570][Wall Clock 155.889996929s] Trained 128 records in 0.084055145 seconds. Throughput is 1522.8098 records/second. Loss is 2.1793056. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.892565200467108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:51 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 1571][Wall Clock 155.979540907s] Trained 128 records in 0.089543978 seconds. Throughput is 1429.4652 records/second. Loss is 2.1873322. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8910505836575873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21120/60000][Iteration 1572][Wall Clock 156.065220348s] Trained 128 records in 0.085679441 seconds. Throughput is 1493.9407 records/second. Loss is 2.1809335. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.889537145079736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 1573][Wall Clock 156.153299667s] Trained 128 records in 0.088079319 seconds. Throughput is 1453.2356 records/second. Loss is 2.2043195. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8880248833592535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21376/60000][Iteration 1574][Wall Clock 156.239361568s] Trained 128 records in 0.086061901 seconds. Throughput is 1487.3015 records/second. Loss is 2.1856287. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.88651379712398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 1575][Wall Clock 156.333640083s] Trained 128 records in 0.094278515 seconds. Throughput is 1357.6794 records/second. Loss is 2.1842213. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8850038850038855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21632/60000][Iteration 1576][Wall Clock 156.421068241s] Trained 128 records in 0.087428158 seconds. Throughput is 1464.0592 records/second. Loss is 2.1912029. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8834951456310677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 1577][Wall Clock 156.508555114s] Trained 128 records in 0.087486873 seconds. Throughput is 1463.0767 records/second. Loss is 2.1857564. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8819875776397513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 21888/60000][Iteration 1578][Wall Clock 156.594541526s] Trained 128 records in 0.085986412 seconds. Throughput is 1488.6073 records/second. Loss is 2.1871665. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.880481179666279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 1579][Wall Clock 156.681826985s] Trained 128 records in 0.087285459 seconds. Throughput is 1466.4528 records/second. Loss is 2.1868057. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.878975950349107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 22144/60000][Iteration 1580][Wall Clock 156.767557216s] Trained 128 records in 0.085730231 seconds. Throughput is 1493.0555 records/second. Loss is 2.1798337. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.87747188832881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 1581][Wall Clock 156.854079124s] Trained 128 records in 0.086521908 seconds. Throughput is 1479.394 records/second. Loss is 2.1820111. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.875968992248062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:52 INFO  DistriOptimizer$:408 - [Epoch 4 22400/60000][Iteration 1582][Wall Clock 156.940708575s] Trained 128 records in 0.086629451 seconds. Throughput is 1477.5576 records/second. Loss is 2.1841533. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.874467260751647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 1583][Wall Clock 157.027425881s] Trained 128 records in 0.086717306 seconds. Throughput is 1476.0605 records/second. Loss is 2.1947272. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.872966692486445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 22656/60000][Iteration 1584][Wall Clock 157.114158844s] Trained 128 records in 0.086732963 seconds. Throughput is 1475.7942 records/second. Loss is 2.194778. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8714672861014324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 1585][Wall Clock 157.206946153s] Trained 128 records in 0.092787309 seconds. Throughput is 1379.499 records/second. Loss is 2.184354. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.869969040247678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 22912/60000][Iteration 1586][Wall Clock 157.295013599s] Trained 128 records in 0.088067446 seconds. Throughput is 1453.4314 records/second. Loss is 2.2029204. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8684719535783365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 1587][Wall Clock 157.381877774s] Trained 128 records in 0.086864175 seconds. Throughput is 1473.565 records/second. Loss is 2.1753023. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.866976024748646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23168/60000][Iteration 1588][Wall Clock 157.469467365s] Trained 128 records in 0.087589591 seconds. Throughput is 1461.3608 records/second. Loss is 2.1878505. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.865481252415926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 1589][Wall Clock 157.557354434s] Trained 128 records in 0.087887069 seconds. Throughput is 1456.4144 records/second. Loss is 2.1792095. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.863987635239567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23424/60000][Iteration 1590][Wall Clock 157.64621733s] Trained 128 records in 0.088862896 seconds. Throughput is 1440.4213 records/second. Loss is 2.189608. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.862495171881035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 1591][Wall Clock 157.738664434s] Trained 128 records in 0.092447104 seconds. Throughput is 1384.5756 records/second. Loss is 2.195104. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8610038610038615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23680/60000][Iteration 1592][Wall Clock 157.837910302s] Trained 128 records in 0.099245868 seconds. Throughput is 1289.7262 records/second. Loss is 2.191617. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.859513701273639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:53 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 1593][Wall Clock 157.926623206s] Trained 128 records in 0.088712904 seconds. Throughput is 1442.8567 records/second. Loss is 2.1867657. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8580246913580245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 23936/60000][Iteration 1594][Wall Clock 158.018523878s] Trained 128 records in 0.091900672 seconds. Throughput is 1392.8081 records/second. Loss is 2.191726. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.856536829926726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 1595][Wall Clock 158.105011866s] Trained 128 records in 0.086487988 seconds. Throughput is 1479.9744 records/second. Loss is 2.1762414. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8550501156515033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24192/60000][Iteration 1596][Wall Clock 158.200327083s] Trained 128 records in 0.095315217 seconds. Throughput is 1342.9125 records/second. Loss is 2.1785233. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8535645472061663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 1597][Wall Clock 158.289699019s] Trained 128 records in 0.089371936 seconds. Throughput is 1432.2169 records/second. Loss is 2.196365. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.852080123266564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24448/60000][Iteration 1598][Wall Clock 158.382518595s] Trained 128 records in 0.092819576 seconds. Throughput is 1379.0194 records/second. Loss is 2.1705732. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.850596842510589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 1599][Wall Clock 158.473178872s] Trained 128 records in 0.090660277 seconds. Throughput is 1411.8643 records/second. Loss is 2.201188. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.849114703618168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24704/60000][Iteration 1600][Wall Clock 158.567211846s] Trained 128 records in 0.094032974 seconds. Throughput is 1361.2246 records/second. Loss is 2.1737144. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.847633705271258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 1601][Wall Clock 158.648841271s] Trained 128 records in 0.081629425 seconds. Throughput is 1568.062 records/second. Loss is 2.186988. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.846153846153846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 24960/60000][Iteration 1602][Wall Clock 158.734840091s] Trained 128 records in 0.08599882 seconds. Throughput is 1488.3926 records/second. Loss is 2.1761346. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8446751249519417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 1603][Wall Clock 158.82559034s] Trained 128 records in 0.090750249 seconds. Throughput is 1410.4645 records/second. Loss is 2.1699474. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8431975403535736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:54 INFO  DistriOptimizer$:408 - [Epoch 4 25216/60000][Iteration 1604][Wall Clock 158.919152241s] Trained 128 records in 0.093561901 seconds. Throughput is 1368.0782 records/second. Loss is 2.1762238. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8417210910487906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 1605][Wall Clock 159.010313792s] Trained 128 records in 0.091161551 seconds. Throughput is 1404.1007 records/second. Loss is 2.1728108. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8402457757296467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 25472/60000][Iteration 1606][Wall Clock 159.097510333s] Trained 128 records in 0.087196541 seconds. Throughput is 1467.9481 records/second. Loss is 2.192899. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8387715930902113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 1607][Wall Clock 159.18829456s] Trained 128 records in 0.090784227 seconds. Throughput is 1409.9365 records/second. Loss is 2.1941676. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8372985418265546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 25728/60000][Iteration 1608][Wall Clock 159.282084759s] Trained 128 records in 0.093790199 seconds. Throughput is 1364.7482 records/second. Loss is 2.18786. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.835826620636747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 1609][Wall Clock 159.372150006s] Trained 128 records in 0.090065247 seconds. Throughput is 1421.1919 records/second. Loss is 2.17688. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.834355828220859E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 25984/60000][Iteration 1610][Wall Clock 159.468427362s] Trained 128 records in 0.096277356 seconds. Throughput is 1329.4923 records/second. Loss is 2.1836314. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.832886163280951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 1611][Wall Clock 159.558473834s] Trained 128 records in 0.090046472 seconds. Throughput is 1421.4882 records/second. Loss is 2.1936307. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8314176245210724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 26240/60000][Iteration 1612][Wall Clock 159.64627258s] Trained 128 records in 0.087798746 seconds. Throughput is 1457.8796 records/second. Loss is 2.190862. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.829950210647262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 1613][Wall Clock 159.736764972s] Trained 128 records in 0.090492392 seconds. Throughput is 1414.4835 records/second. Loss is 2.193604. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8284839203675346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 26496/60000][Iteration 1614][Wall Clock 159.825819813s] Trained 128 records in 0.089054841 seconds. Throughput is 1437.3167 records/second. Loss is 2.167861. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.827018752391887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:55 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 1615][Wall Clock 159.920599417s] Trained 128 records in 0.094779604 seconds. Throughput is 1350.5016 records/second. Loss is 2.1748931. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.825554705432288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 26752/60000][Iteration 1616][Wall Clock 160.011608136s] Trained 128 records in 0.091008719 seconds. Throughput is 1406.4587 records/second. Loss is 2.1790962. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.824091778202677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 1617][Wall Clock 160.100186799s] Trained 128 records in 0.088578663 seconds. Throughput is 1445.0432 records/second. Loss is 2.1665518. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8226299694189603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27008/60000][Iteration 1618][Wall Clock 160.23625886s] Trained 128 records in 0.136072061 seconds. Throughput is 940.6781 records/second. Loss is 2.186153. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8211692777990065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 1619][Wall Clock 160.328200162s] Trained 128 records in 0.091941302 seconds. Throughput is 1392.1925 records/second. Loss is 2.1712132. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8197097020626426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27264/60000][Iteration 1620][Wall Clock 160.420140979s] Trained 128 records in 0.091940817 seconds. Throughput is 1392.2 records/second. Loss is 2.1843033. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8182512409316535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 1621][Wall Clock 160.509971592s] Trained 128 records in 0.089830613 seconds. Throughput is 1424.9039 records/second. Loss is 2.196319. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.816793893129771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27520/60000][Iteration 1622][Wall Clock 160.598886941s] Trained 128 records in 0.088915349 seconds. Throughput is 1439.5715 records/second. Loss is 2.1865396. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8153376573826786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 1623][Wall Clock 160.689256864s] Trained 128 records in 0.090369923 seconds. Throughput is 1416.4004 records/second. Loss is 2.1888235. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8138825324180017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27776/60000][Iteration 1624][Wall Clock 160.779701772s] Trained 128 records in 0.090444908 seconds. Throughput is 1415.2262 records/second. Loss is 2.190939. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.812428516965307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:56 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 1625][Wall Clock 160.87019781s] Trained 128 records in 0.090496038 seconds. Throughput is 1414.4265 records/second. Loss is 2.1768093. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8109756097560977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28032/60000][Iteration 1626][Wall Clock 160.965066091s] Trained 128 records in 0.094868281 seconds. Throughput is 1349.2391 records/second. Loss is 2.1870668. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8095238095238096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 1627][Wall Clock 161.050999852s] Trained 128 records in 0.085933761 seconds. Throughput is 1489.5194 records/second. Loss is 2.1939054. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8080731150038076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28288/60000][Iteration 1628][Wall Clock 161.142597499s] Trained 128 records in 0.091597647 seconds. Throughput is 1397.4158 records/second. Loss is 2.179657. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.8066235249333843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 1629][Wall Clock 161.24128046s] Trained 128 records in 0.098682961 seconds. Throughput is 1297.0831 records/second. Loss is 2.1726825. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.80517503805175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28544/60000][Iteration 1630][Wall Clock 161.338126968s] Trained 128 records in 0.096846508 seconds. Throughput is 1321.6791 records/second. Loss is 2.16668. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.803727653100038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 1631][Wall Clock 161.432127919s] Trained 128 records in 0.094000951 seconds. Throughput is 1361.6884 records/second. Loss is 2.1954472. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.802281368821293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28800/60000][Iteration 1632][Wall Clock 161.535193472s] Trained 128 records in 0.103065553 seconds. Throughput is 1241.9281 records/second. Loss is 2.1999195. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.800836183960471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 1633][Wall Clock 161.628560075s] Trained 128 records in 0.093366603 seconds. Throughput is 1370.94 records/second. Loss is 2.1932552. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7993920972644377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 29056/60000][Iteration 1634][Wall Clock 161.719545738s] Trained 128 records in 0.090985663 seconds. Throughput is 1406.8151 records/second. Loss is 2.1675117. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7979491074819596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 1635][Wall Clock 161.807150049s] Trained 128 records in 0.087604311 seconds. Throughput is 1461.1152 records/second. Loss is 2.1733224. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.796507213363705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:57 INFO  DistriOptimizer$:408 - [Epoch 4 29312/60000][Iteration 1636][Wall Clock 161.900373448s] Trained 128 records in 0.093223399 seconds. Throughput is 1373.0458 records/second. Loss is 2.189187. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7950664136622396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 1637][Wall Clock 161.99149495s] Trained 128 records in 0.091121502 seconds. Throughput is 1404.7179 records/second. Loss is 2.1795287. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7936267071320183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 29568/60000][Iteration 1638][Wall Clock 162.085304962s] Trained 128 records in 0.093810012 seconds. Throughput is 1364.4598 records/second. Loss is 2.1917882. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.792188092529389E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 1639][Wall Clock 162.17493828s] Trained 128 records in 0.089633318 seconds. Throughput is 1428.0404 records/second. Loss is 2.1862502. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.790750568612585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 29824/60000][Iteration 1640][Wall Clock 162.267034666s] Trained 128 records in 0.092096386 seconds. Throughput is 1389.8481 records/second. Loss is 2.1801696. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7893141341417203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 1641][Wall Clock 162.360684014s] Trained 128 records in 0.093649348 seconds. Throughput is 1366.8008 records/second. Loss is 2.165808. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.787878787878788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 30080/60000][Iteration 1642][Wall Clock 162.45293543s] Trained 128 records in 0.092251416 seconds. Throughput is 1387.5126 records/second. Loss is 2.1859598. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.786444528587656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 1643][Wall Clock 162.550726292s] Trained 128 records in 0.097790862 seconds. Throughput is 1308.9158 records/second. Loss is 2.1783648. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7850113550340646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 30336/60000][Iteration 1644][Wall Clock 162.638904252s] Trained 128 records in 0.08817796 seconds. Throughput is 1451.61 records/second. Loss is 2.1900527. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7835792659856227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 1645][Wall Clock 162.725767268s] Trained 128 records in 0.086863016 seconds. Throughput is 1473.5845 records/second. Loss is 2.184279. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7821482602118004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 30592/60000][Iteration 1646][Wall Clock 162.814179371s] Trained 128 records in 0.088412103 seconds. Throughput is 1447.7655 records/second. Loss is 2.1688416. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.780718336483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:58 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 1647][Wall Clock 162.90574857s] Trained 128 records in 0.091569199 seconds. Throughput is 1397.85 records/second. Loss is 2.1685948. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.779289493575208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 30848/60000][Iteration 1648][Wall Clock 163.026800569s] Trained 128 records in 0.121051999 seconds. Throughput is 1057.3969 records/second. Loss is 2.192151. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7778617302606723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 1649][Wall Clock 163.118114595s] Trained 128 records in 0.091314026 seconds. Throughput is 1401.7562 records/second. Loss is 2.1798291. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7764350453172205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31104/60000][Iteration 1650][Wall Clock 163.209140634s] Trained 128 records in 0.091026039 seconds. Throughput is 1406.191 records/second. Loss is 2.1658256. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7750094375235937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 1651][Wall Clock 163.298641742s] Trained 128 records in 0.089501108 seconds. Throughput is 1430.1499 records/second. Loss is 2.1883883. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.773584905660377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31360/60000][Iteration 1652][Wall Clock 163.395841122s] Trained 128 records in 0.09719938 seconds. Throughput is 1316.8809 records/second. Loss is 2.1693976. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7721614485099967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 1653][Wall Clock 163.494447354s] Trained 128 records in 0.098606232 seconds. Throughput is 1298.0924 records/second. Loss is 2.192106. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.770739064856712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31616/60000][Iteration 1654][Wall Clock 163.596161171s] Trained 128 records in 0.101713817 seconds. Throughput is 1258.4329 records/second. Loss is 2.198652. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.769317753486619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 1655][Wall Clock 163.68669528s] Trained 128 records in 0.090534109 seconds. Throughput is 1413.8318 records/second. Loss is 2.1740851. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7678975131876413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 31872/60000][Iteration 1656][Wall Clock 163.776171262s] Trained 128 records in 0.089475982 seconds. Throughput is 1430.5515 records/second. Loss is 2.1894011. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.766478342749529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:13:59 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 1657][Wall Clock 163.866300811s] Trained 128 records in 0.090129549 seconds. Throughput is 1420.178 records/second. Loss is 2.187536. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.765060240963855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32128/60000][Iteration 1658][Wall Clock 163.955427123s] Trained 128 records in 0.089126312 seconds. Throughput is 1436.1641 records/second. Loss is 2.1668723. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.763643206624012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 1659][Wall Clock 164.048490943s] Trained 128 records in 0.09306382 seconds. Throughput is 1375.4003 records/second. Loss is 2.1810334. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.762227238525206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32384/60000][Iteration 1660][Wall Clock 164.14257779s] Trained 128 records in 0.094086847 seconds. Throughput is 1360.4452 records/second. Loss is 2.1747475. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.760812335464461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 1661][Wall Clock 164.2380824s] Trained 128 records in 0.09550461 seconds. Throughput is 1340.2494 records/second. Loss is 2.1774325. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.759398496240601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32640/60000][Iteration 1662][Wall Clock 164.337343989s] Trained 128 records in 0.099261589 seconds. Throughput is 1289.522 records/second. Loss is 2.1865468. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.757985719654265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 1663][Wall Clock 164.433065805s] Trained 128 records in 0.095721816 seconds. Throughput is 1337.2083 records/second. Loss is 2.1883948. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.756574004507889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 32896/60000][Iteration 1664][Wall Clock 164.533576124s] Trained 128 records in 0.100510319 seconds. Throughput is 1273.5011 records/second. Loss is 2.181208. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.755163349605708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 1665][Wall Clock 164.629300228s] Trained 128 records in 0.095724104 seconds. Throughput is 1337.1763 records/second. Loss is 2.1788862. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7537537537537537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 33152/60000][Iteration 1666][Wall Clock 164.722908986s] Trained 128 records in 0.093608758 seconds. Throughput is 1367.3934 records/second. Loss is 2.1596696. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.75234521575985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 1667][Wall Clock 164.81731755s] Trained 128 records in 0.094408564 seconds. Throughput is 1355.8092 records/second. Loss is 2.1713912. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7509377344336085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:00 INFO  DistriOptimizer$:408 - [Epoch 4 33408/60000][Iteration 1668][Wall Clock 164.911770791s] Trained 128 records in 0.094453241 seconds. Throughput is 1355.168 records/second. Loss is 2.1852894. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.749531308586427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 1669][Wall Clock 165.009636636s] Trained 128 records in 0.097865845 seconds. Throughput is 1307.913 records/second. Loss is 2.1860611. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.748125937031484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 33664/60000][Iteration 1670][Wall Clock 165.097929548s] Trained 128 records in 0.088292912 seconds. Throughput is 1449.72 records/second. Loss is 2.189455. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.746721618583739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 1671][Wall Clock 165.191930043s] Trained 128 records in 0.094000495 seconds. Throughput is 1361.695 records/second. Loss is 2.1634295. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.745318352059925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 33920/60000][Iteration 1672][Wall Clock 165.291246789s] Trained 128 records in 0.099316746 seconds. Throughput is 1288.8058 records/second. Loss is 2.1859877. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.743916136278547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 1673][Wall Clock 165.388754875s] Trained 128 records in 0.097508086 seconds. Throughput is 1312.7117 records/second. Loss is 2.1810954. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7425149700598805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 34176/60000][Iteration 1674][Wall Clock 165.495881829s] Trained 128 records in 0.107126954 seconds. Throughput is 1194.844 records/second. Loss is 2.1805174. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.741114852225963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 1675][Wall Clock 165.592627702s] Trained 128 records in 0.096745873 seconds. Throughput is 1323.0538 records/second. Loss is 2.179952. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7397157816005983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 34432/60000][Iteration 1676][Wall Clock 165.709624827s] Trained 128 records in 0.116997125 seconds. Throughput is 1094.044 records/second. Loss is 2.1740992. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.738317757009346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 1677][Wall Clock 165.811160185s] Trained 128 records in 0.101535358 seconds. Throughput is 1260.6447 records/second. Loss is 2.1841412. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.736920777279522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:01 INFO  DistriOptimizer$:408 - [Epoch 4 34688/60000][Iteration 1678][Wall Clock 165.903203506s] Trained 128 records in 0.092043321 seconds. Throughput is 1390.6495 records/second. Loss is 2.1720467. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7355248412401944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 1679][Wall Clock 166.001744869s] Trained 128 records in 0.098541363 seconds. Throughput is 1298.9469 records/second. Loss is 2.1753209. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.734129947722181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 34944/60000][Iteration 1680][Wall Clock 166.097303316s] Trained 128 records in 0.095558447 seconds. Throughput is 1339.4943 records/second. Loss is 2.1802883. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7327360955580435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 1681][Wall Clock 166.19212634s] Trained 128 records in 0.094823024 seconds. Throughput is 1349.883 records/second. Loss is 2.185321. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.73134328358209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35200/60000][Iteration 1682][Wall Clock 166.290575743s] Trained 128 records in 0.098449403 seconds. Throughput is 1300.1603 records/second. Loss is 2.1647048. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.729951510630362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 1683][Wall Clock 166.386191603s] Trained 128 records in 0.09561586 seconds. Throughput is 1338.6901 records/second. Loss is 2.1875975. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7285607755406416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35456/60000][Iteration 1684][Wall Clock 166.483040228s] Trained 128 records in 0.096848625 seconds. Throughput is 1321.6501 records/second. Loss is 2.169049. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7271710771524417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 1685][Wall Clock 166.578136s] Trained 128 records in 0.095095772 seconds. Throughput is 1346.0115 records/second. Loss is 2.1496856. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7257824143070045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35712/60000][Iteration 1686][Wall Clock 166.672523282s] Trained 128 records in 0.094387282 seconds. Throughput is 1356.1149 records/second. Loss is 2.173227. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7243947858472997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 1687][Wall Clock 166.766887225s] Trained 128 records in 0.094363943 seconds. Throughput is 1356.4503 records/second. Loss is 2.1646943. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7230081906180194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:02 INFO  DistriOptimizer$:408 - [Epoch 4 35968/60000][Iteration 1688][Wall Clock 166.862761101s] Trained 128 records in 0.095873876 seconds. Throughput is 1335.0873 records/second. Loss is 2.1784155. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7216226274655747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 1689][Wall Clock 166.958689745s] Trained 128 records in 0.095928644 seconds. Throughput is 1334.3251 records/second. Loss is 2.1736565. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7202380952380956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36224/60000][Iteration 1690][Wall Clock 167.054884304s] Trained 128 records in 0.096194559 seconds. Throughput is 1330.6366 records/second. Loss is 2.1810842. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.718854592785422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 1691][Wall Clock 167.152288491s] Trained 128 records in 0.097404187 seconds. Throughput is 1314.1118 records/second. Loss is 2.1778421. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.717472118959108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36480/60000][Iteration 1692][Wall Clock 167.250392204s] Trained 128 records in 0.098103713 seconds. Throughput is 1304.7417 records/second. Loss is 2.1974874. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.716090672612412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 1693][Wall Clock 167.350319593s] Trained 128 records in 0.099927389 seconds. Throughput is 1280.93 records/second. Loss is 2.169724. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.714710252600297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36736/60000][Iteration 1694][Wall Clock 167.451831706s] Trained 128 records in 0.101512113 seconds. Throughput is 1260.9332 records/second. Loss is 2.1782706. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.713330857779428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 1695][Wall Clock 167.547928922s] Trained 128 records in 0.096097216 seconds. Throughput is 1331.9845 records/second. Loss is 2.1763513. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7119524870081667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 36992/60000][Iteration 1696][Wall Clock 167.653425058s] Trained 128 records in 0.105496136 seconds. Throughput is 1213.3146 records/second. Loss is 2.1779. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7105751391465676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 1697][Wall Clock 167.749644801s] Trained 128 records in 0.096219743 seconds. Throughput is 1330.2883 records/second. Loss is 2.1836717. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7091988130563805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:03 INFO  DistriOptimizer$:408 - [Epoch 4 37248/60000][Iteration 1698][Wall Clock 167.845717873s] Trained 128 records in 0.096073072 seconds. Throughput is 1332.3192 records/second. Loss is 2.1813738. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.707823507601038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 1699][Wall Clock 167.938065243s] Trained 128 records in 0.09234737 seconds. Throughput is 1386.0709 records/second. Loss is 2.180836. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.706449221645664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 37504/60000][Iteration 1700][Wall Clock 168.033439569s] Trained 128 records in 0.095374326 seconds. Throughput is 1342.0803 records/second. Loss is 2.173955. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7050759540570587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 1701][Wall Clock 168.125247164s] Trained 128 records in 0.091807595 seconds. Throughput is 1394.2201 records/second. Loss is 2.1793196. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7037037037037035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 37760/60000][Iteration 1702][Wall Clock 168.218088221s] Trained 128 records in 0.092841057 seconds. Throughput is 1378.7003 records/second. Loss is 2.1949494. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7023324694557573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 1703][Wall Clock 168.318264389s] Trained 128 records in 0.100176168 seconds. Throughput is 1277.749 records/second. Loss is 2.1718216. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.7009622501850485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 38016/60000][Iteration 1704][Wall Clock 168.411080546s] Trained 128 records in 0.092816157 seconds. Throughput is 1379.0702 records/second. Loss is 2.1806872. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6995930447650754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 1705][Wall Clock 168.503699932s] Trained 128 records in 0.092619386 seconds. Throughput is 1382.0 records/second. Loss is 2.1739144. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6982248520710064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 38272/60000][Iteration 1706][Wall Clock 168.595685631s] Trained 128 records in 0.091985699 seconds. Throughput is 1391.5206 records/second. Loss is 2.1777058. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.696857670979667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 1707][Wall Clock 168.68949755s] Trained 128 records in 0.093811919 seconds. Throughput is 1364.4321 records/second. Loss is 2.1652737. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.695491500369549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 38528/60000][Iteration 1708][Wall Clock 168.786200933s] Trained 128 records in 0.096703383 seconds. Throughput is 1323.6353 records/second. Loss is 2.1840656. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6941263391207984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:04 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 1709][Wall Clock 168.885158282s] Trained 128 records in 0.098957349 seconds. Throughput is 1293.4865 records/second. Loss is 2.1814575. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.692762186115214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 38784/60000][Iteration 1710][Wall Clock 168.974999955s] Trained 128 records in 0.089841673 seconds. Throughput is 1424.7286 records/second. Loss is 2.1845145. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6913990402362494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 1711][Wall Clock 169.063762612s] Trained 128 records in 0.088762657 seconds. Throughput is 1442.0479 records/second. Loss is 2.2001832. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6900369003690036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39040/60000][Iteration 1712][Wall Clock 169.155616762s] Trained 128 records in 0.09185415 seconds. Throughput is 1393.5135 records/second. Loss is 2.1641154. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.688675765400221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 1713][Wall Clock 169.246147396s] Trained 128 records in 0.090530634 seconds. Throughput is 1413.886 records/second. Loss is 2.1657515. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6873156342182896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39296/60000][Iteration 1714][Wall Clock 169.33857998s] Trained 128 records in 0.092432584 seconds. Throughput is 1384.7931 records/second. Loss is 2.1901677. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6859565057132326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 1715][Wall Clock 169.426924783s] Trained 128 records in 0.088344803 seconds. Throughput is 1448.8684 records/second. Loss is 2.1783953. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6845983787767134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39552/60000][Iteration 1716][Wall Clock 169.51829295s] Trained 128 records in 0.091368167 seconds. Throughput is 1400.9255 records/second. Loss is 2.196945. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.683241252302026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 1717][Wall Clock 169.608430056s] Trained 128 records in 0.090137106 seconds. Throughput is 1420.0588 records/second. Loss is 2.1826227. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.681885125184094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39808/60000][Iteration 1718][Wall Clock 169.697004312s] Trained 128 records in 0.088574256 seconds. Throughput is 1445.1152 records/second. Loss is 2.1766636. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.68052999631947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 1719][Wall Clock 169.796576521s] Trained 128 records in 0.099572209 seconds. Throughput is 1285.4993 records/second. Loss is 2.1544757. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.679175864606328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:05 INFO  DistriOptimizer$:408 - [Epoch 4 40064/60000][Iteration 1720][Wall Clock 169.884817486s] Trained 128 records in 0.088240965 seconds. Throughput is 1450.5734 records/second. Loss is 2.1873975. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6778227289444644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 1721][Wall Clock 169.970643829s] Trained 128 records in 0.085826343 seconds. Throughput is 1491.3835 records/second. Loss is 2.1952991. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6764705882352946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40320/60000][Iteration 1722][Wall Clock 170.0662138s] Trained 128 records in 0.095569971 seconds. Throughput is 1339.3329 records/second. Loss is 2.1725607. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6751194413818446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 1723][Wall Clock 170.160204799s] Trained 128 records in 0.093990999 seconds. Throughput is 1361.8325 records/second. Loss is 2.1828387. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6737692872887586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40576/60000][Iteration 1724][Wall Clock 170.252756348s] Trained 128 records in 0.092551549 seconds. Throughput is 1383.0131 records/second. Loss is 2.1793044. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6724201248622846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 1725][Wall Clock 170.34828198s] Trained 128 records in 0.095525632 seconds. Throughput is 1339.9545 records/second. Loss is 2.1772377. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.671071953010279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40832/60000][Iteration 1726][Wall Clock 170.441769554s] Trained 128 records in 0.093487574 seconds. Throughput is 1369.1659 records/second. Loss is 2.158505. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.669724770642202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 1727][Wall Clock 170.531870999s] Trained 128 records in 0.090101445 seconds. Throughput is 1420.621 records/second. Loss is 2.158543. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6683785766691124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 41088/60000][Iteration 1728][Wall Clock 170.624192725s] Trained 128 records in 0.092321726 seconds. Throughput is 1386.4559 records/second. Loss is 2.159468. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6670333700036665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 1729][Wall Clock 170.715931318s] Trained 128 records in 0.091738593 seconds. Throughput is 1395.2688 records/second. Loss is 2.1701317. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.665689149560118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 41344/60000][Iteration 1730][Wall Clock 170.80033889s] Trained 128 records in 0.084407572 seconds. Throughput is 1516.4515 records/second. Loss is 2.1803553. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6643459142543056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:06 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 1731][Wall Clock 170.890198791s] Trained 128 records in 0.089859901 seconds. Throughput is 1424.4396 records/second. Loss is 2.1778226. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.663003663003663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 41600/60000][Iteration 1732][Wall Clock 170.975944312s] Trained 128 records in 0.085745521 seconds. Throughput is 1492.7893 records/second. Loss is 2.1834266. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6616623947272064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 1733][Wall Clock 171.064823702s] Trained 128 records in 0.08887939 seconds. Throughput is 1440.1539 records/second. Loss is 2.1818337. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.660322108345534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 41856/60000][Iteration 1734][Wall Clock 171.151650961s] Trained 128 records in 0.086827259 seconds. Throughput is 1474.1915 records/second. Loss is 2.1768453. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6589828027808267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 1735][Wall Clock 171.236964793s] Trained 128 records in 0.085313832 seconds. Throughput is 1500.3429 records/second. Loss is 2.181241. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.65764447695684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42112/60000][Iteration 1736][Wall Clock 171.323246563s] Trained 128 records in 0.08628177 seconds. Throughput is 1483.5116 records/second. Loss is 2.176691. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.656307129798903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 1737][Wall Clock 171.408423157s] Trained 128 records in 0.085176594 seconds. Throughput is 1502.7603 records/second. Loss is 2.1705258. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6549707602339185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42368/60000][Iteration 1738][Wall Clock 171.493003748s] Trained 128 records in 0.084580591 seconds. Throughput is 1513.3495 records/second. Loss is 2.1692863. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6536353671903543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 1739][Wall Clock 171.576602129s] Trained 128 records in 0.083598381 seconds. Throughput is 1531.1301 records/second. Loss is 2.1728601. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.652300949598247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42624/60000][Iteration 1740][Wall Clock 171.660618931s] Trained 128 records in 0.084016802 seconds. Throughput is 1523.5049 records/second. Loss is 2.1585124. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.650967506389193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 1741][Wall Clock 171.74597811s] Trained 128 records in 0.085359179 seconds. Throughput is 1499.5458 records/second. Loss is 2.179546. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.64963503649635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:07 INFO  DistriOptimizer$:408 - [Epoch 4 42880/60000][Iteration 1742][Wall Clock 171.831380726s] Trained 128 records in 0.085402616 seconds. Throughput is 1498.7831 records/second. Loss is 2.1623049. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6483035388544326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 1743][Wall Clock 171.924191861s] Trained 128 records in 0.092811135 seconds. Throughput is 1379.1448 records/second. Loss is 2.2027123. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6469730123997083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43136/60000][Iteration 1744][Wall Clock 172.003558083s] Trained 128 records in 0.079366222 seconds. Throughput is 1612.7767 records/second. Loss is 2.1656964. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.645643456069996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 1745][Wall Clock 172.085505423s] Trained 128 records in 0.08194734 seconds. Throughput is 1561.9786 records/second. Loss is 2.1625834. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.644314868804665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43392/60000][Iteration 1746][Wall Clock 172.165274879s] Trained 128 records in 0.079769456 seconds. Throughput is 1604.6243 records/second. Loss is 2.1527567. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6429872495446266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 1747][Wall Clock 172.252475954s] Trained 128 records in 0.087201075 seconds. Throughput is 1467.8718 records/second. Loss is 2.1574945. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.641660597232338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43648/60000][Iteration 1748][Wall Clock 172.338640697s] Trained 128 records in 0.086164743 seconds. Throughput is 1485.5264 records/second. Loss is 2.188616. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.640334910811795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 1749][Wall Clock 172.42593802s] Trained 128 records in 0.087297323 seconds. Throughput is 1466.2535 records/second. Loss is 2.167891. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6390101892285295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 43904/60000][Iteration 1750][Wall Clock 172.515271116s] Trained 128 records in 0.089333096 seconds. Throughput is 1432.8396 records/second. Loss is 2.1665738. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.637686431429611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 1751][Wall Clock 172.602135579s] Trained 128 records in 0.086864463 seconds. Throughput is 1473.56 records/second. Loss is 2.1883345. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6363636363636367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 44160/60000][Iteration 1752][Wall Clock 172.687532863s] Trained 128 records in 0.085397284 seconds. Throughput is 1498.8767 records/second. Loss is 2.167693. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.635041802980734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 1753][Wall Clock 172.774261677s] Trained 128 records in 0.086728814 seconds. Throughput is 1475.8647 records/second. Loss is 2.1794214. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6337209302325586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:08 INFO  DistriOptimizer$:408 - [Epoch 4 44416/60000][Iteration 1754][Wall Clock 172.868933146s] Trained 128 records in 0.094671469 seconds. Throughput is 1352.0442 records/second. Loss is 2.1724346. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.632401017072285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 1755][Wall Clock 172.952222475s] Trained 128 records in 0.083289329 seconds. Throughput is 1536.8114 records/second. Loss is 2.1570868. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6310820624546115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 44672/60000][Iteration 1756][Wall Clock 173.028434373s] Trained 128 records in 0.076211898 seconds. Throughput is 1679.5277 records/second. Loss is 2.1696727. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6297640653357535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 1757][Wall Clock 173.117244404s] Trained 128 records in 0.088810031 seconds. Throughput is 1441.2786 records/second. Loss is 2.1760743. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.62844702467344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 44928/60000][Iteration 1758][Wall Clock 173.203473784s] Trained 128 records in 0.08622938 seconds. Throughput is 1484.413 records/second. Loss is 2.1737578. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.627130939426913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 1759][Wall Clock 173.290433503s] Trained 128 records in 0.086959719 seconds. Throughput is 1471.9459 records/second. Loss is 2.1768377. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6258158085569254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45184/60000][Iteration 1760][Wall Clock 173.379711342s] Trained 128 records in 0.089277839 seconds. Throughput is 1433.7264 records/second. Loss is 2.168962. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6245016310257333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 1761][Wall Clock 173.468589665s] Trained 128 records in 0.088878323 seconds. Throughput is 1440.1711 records/second. Loss is 2.1708853. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.623188405797102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45440/60000][Iteration 1762][Wall Clock 173.555353867s] Trained 128 records in 0.086764202 seconds. Throughput is 1475.2628 records/second. Loss is 2.174295. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.621876131836291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 1763][Wall Clock 173.646335098s] Trained 128 records in 0.090981231 seconds. Throughput is 1406.8835 records/second. Loss is 2.1790593. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6205648081100655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45696/60000][Iteration 1764][Wall Clock 173.733817559s] Trained 128 records in 0.087482461 seconds. Throughput is 1463.1504 records/second. Loss is 2.1623034. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.619254433586681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:09 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 1765][Wall Clock 173.824501138s] Trained 128 records in 0.090683579 seconds. Throughput is 1411.5015 records/second. Loss is 2.196728. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.61794500723589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 45952/60000][Iteration 1766][Wall Clock 173.914568801s] Trained 128 records in 0.090067663 seconds. Throughput is 1421.1538 records/second. Loss is 2.1873877. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.616636528028933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 1767][Wall Clock 174.006937008s] Trained 128 records in 0.092368207 seconds. Throughput is 1385.7582 records/second. Loss is 2.173802. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6153289949385393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46208/60000][Iteration 1768][Wall Clock 174.100387185s] Trained 128 records in 0.093450177 seconds. Throughput is 1369.7139 records/second. Loss is 2.1840467. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6140224069389226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 1769][Wall Clock 174.188424933s] Trained 128 records in 0.088037748 seconds. Throughput is 1453.9218 records/second. Loss is 2.184043. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6127167630057807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46464/60000][Iteration 1770][Wall Clock 174.2734112s] Trained 128 records in 0.084986267 seconds. Throughput is 1506.1256 records/second. Loss is 2.1698909. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6114120621162876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 1771][Wall Clock 174.35961453s] Trained 128 records in 0.08620333 seconds. Throughput is 1484.8615 records/second. Loss is 2.1540792. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6101083032490973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46720/60000][Iteration 1772][Wall Clock 174.447116459s] Trained 128 records in 0.087501929 seconds. Throughput is 1462.825 records/second. Loss is 2.1757212. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.608805485384338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 1773][Wall Clock 174.534805251s] Trained 128 records in 0.087688792 seconds. Throughput is 1459.7076 records/second. Loss is 2.17155. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.6075036075036075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 46976/60000][Iteration 1774][Wall Clock 174.621265558s] Trained 128 records in 0.086460307 seconds. Throughput is 1480.4481 records/second. Loss is 2.1954732. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.606202668589975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 1775][Wall Clock 174.706974516s] Trained 128 records in 0.085708958 seconds. Throughput is 1493.4261 records/second. Loss is 2.1615462. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.604902667627974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:10 INFO  DistriOptimizer$:408 - [Epoch 4 47232/60000][Iteration 1776][Wall Clock 174.793402124s] Trained 128 records in 0.086427608 seconds. Throughput is 1481.0083 records/second. Loss is 2.162806. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.603603603603603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 1777][Wall Clock 174.88467773s] Trained 128 records in 0.091275606 seconds. Throughput is 1402.3463 records/second. Loss is 2.1841192. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.602305475504323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 47488/60000][Iteration 1778][Wall Clock 174.971020468s] Trained 128 records in 0.086342738 seconds. Throughput is 1482.464 records/second. Loss is 2.1825159. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.601008282319049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 1779][Wall Clock 175.057891572s] Trained 128 records in 0.086871104 seconds. Throughput is 1473.4474 records/second. Loss is 2.1746414. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.599712023038157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 47744/60000][Iteration 1780][Wall Clock 175.151559782s] Trained 128 records in 0.09366821 seconds. Throughput is 1366.5255 records/second. Loss is 2.2018096. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.598416696653473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 1781][Wall Clock 175.237657577s] Trained 128 records in 0.086097795 seconds. Throughput is 1486.6815 records/second. Loss is 2.143765. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.597122302158273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48000/60000][Iteration 1782][Wall Clock 175.336047503s] Trained 128 records in 0.098389926 seconds. Throughput is 1300.9463 records/second. Loss is 2.1580873. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.595828838547285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 1783][Wall Clock 175.423611249s] Trained 128 records in 0.087563746 seconds. Throughput is 1461.7922 records/second. Loss is 2.161715. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.594536304816679E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48256/60000][Iteration 1784][Wall Clock 175.510788648s] Trained 128 records in 0.087177399 seconds. Throughput is 1468.2705 records/second. Loss is 2.1833384. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.593244699964067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 1785][Wall Clock 175.601079739s] Trained 128 records in 0.090291091 seconds. Throughput is 1417.6371 records/second. Loss is 2.1765618. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.591954022988506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48512/60000][Iteration 1786][Wall Clock 175.690551022s] Trained 128 records in 0.089471283 seconds. Throughput is 1430.6267 records/second. Loss is 2.1649442. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5906642728904844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 1787][Wall Clock 175.786403811s] Trained 128 records in 0.095852789 seconds. Throughput is 1335.381 records/second. Loss is 2.1670797. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.589375448671931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:11 INFO  DistriOptimizer$:408 - [Epoch 4 48768/60000][Iteration 1788][Wall Clock 175.873913307s] Trained 128 records in 0.087509496 seconds. Throughput is 1462.6984 records/second. Loss is 2.1852622. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.588087549336204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 1789][Wall Clock 175.961683531s] Trained 128 records in 0.087770224 seconds. Throughput is 1458.3534 records/second. Loss is 2.172188. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5868005738880915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49024/60000][Iteration 1790][Wall Clock 176.057115532s] Trained 128 records in 0.095432001 seconds. Throughput is 1341.2692 records/second. Loss is 2.163642. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.585514521333811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 1791][Wall Clock 176.151695484s] Trained 128 records in 0.094579952 seconds. Throughput is 1353.3524 records/second. Loss is 2.1518946. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5842293906810036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49280/60000][Iteration 1792][Wall Clock 176.264855237s] Trained 128 records in 0.113159753 seconds. Throughput is 1131.1442 records/second. Loss is 2.2008793. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5829451809387314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 1793][Wall Clock 176.370158411s] Trained 128 records in 0.105303174 seconds. Throughput is 1215.5378 records/second. Loss is 2.162069. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.581661891117479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49536/60000][Iteration 1794][Wall Clock 176.45972185s] Trained 128 records in 0.089563439 seconds. Throughput is 1429.1547 records/second. Loss is 2.1858985. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.580379520229144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 1795][Wall Clock 176.545818543s] Trained 128 records in 0.086096693 seconds. Throughput is 1486.7004 records/second. Loss is 2.1538754. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5790980672870435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49792/60000][Iteration 1796][Wall Clock 176.632477245s] Trained 128 records in 0.086658702 seconds. Throughput is 1477.0588 records/second. Loss is 2.194661. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5778175313059033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 1797][Wall Clock 176.729813317s] Trained 128 records in 0.097336072 seconds. Throughput is 1315.0315 records/second. Loss is 2.2119842. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.57653791130186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:12 INFO  DistriOptimizer$:408 - [Epoch 4 50048/60000][Iteration 1798][Wall Clock 176.815936523s] Trained 128 records in 0.086123206 seconds. Throughput is 1486.2429 records/second. Loss is 2.1783373. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5752592062924567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 1799][Wall Clock 176.906279157s] Trained 128 records in 0.090342634 seconds. Throughput is 1416.8282 records/second. Loss is 2.166861. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5739814152966406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50304/60000][Iteration 1800][Wall Clock 176.998423593s] Trained 128 records in 0.092144436 seconds. Throughput is 1389.1234 records/second. Loss is 2.1843767. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.572704537334763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 1801][Wall Clock 177.086365402s] Trained 128 records in 0.087941809 seconds. Throughput is 1455.5079 records/second. Loss is 2.1517298. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.571428571428572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50560/60000][Iteration 1802][Wall Clock 177.175933239s] Trained 128 records in 0.089567837 seconds. Throughput is 1429.0844 records/second. Loss is 2.1708171. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5701535166012135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 1803][Wall Clock 177.262949753s] Trained 128 records in 0.087016514 seconds. Throughput is 1470.9851 records/second. Loss is 2.175891. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5688793718772306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50816/60000][Iteration 1804][Wall Clock 177.350349155s] Trained 128 records in 0.087399402 seconds. Throughput is 1464.5409 records/second. Loss is 2.1755543. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5676061362825543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 1805][Wall Clock 177.43605875s] Trained 128 records in 0.085709595 seconds. Throughput is 1493.415 records/second. Loss is 2.131887. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5663338088445074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 51072/60000][Iteration 1806][Wall Clock 177.528417545s] Trained 128 records in 0.092358795 seconds. Throughput is 1385.8994 records/second. Loss is 2.1637495. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.565062388591801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 1807][Wall Clock 177.612162176s] Trained 128 records in 0.083744631 seconds. Throughput is 1528.4562 records/second. Loss is 2.164961. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.563791874554526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 51328/60000][Iteration 1808][Wall Clock 177.694922807s] Trained 128 records in 0.082760631 seconds. Throughput is 1546.629 records/second. Loss is 2.170432. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.562522265764161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:13 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 1809][Wall Clock 177.782336289s] Trained 128 records in 0.087413482 seconds. Throughput is 1464.305 records/second. Loss is 2.1755967. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5612535612535614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 51584/60000][Iteration 1810][Wall Clock 177.867337749s] Trained 128 records in 0.08500146 seconds. Throughput is 1505.8564 records/second. Loss is 2.1619565. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5599857600569594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 1811][Wall Clock 177.952697165s] Trained 128 records in 0.085359416 seconds. Throughput is 1499.5416 records/second. Loss is 2.1620338. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5587188612099647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 51840/60000][Iteration 1812][Wall Clock 178.03924883s] Trained 128 records in 0.086551665 seconds. Throughput is 1478.8855 records/second. Loss is 2.1882403. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5574528637495557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 1813][Wall Clock 178.126261259s] Trained 128 records in 0.087012429 seconds. Throughput is 1471.0542 records/second. Loss is 2.1680386. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.556187766714082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52096/60000][Iteration 1814][Wall Clock 178.213583064s] Trained 128 records in 0.087321805 seconds. Throughput is 1465.8424 records/second. Loss is 2.1643815. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.554923569143264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 1815][Wall Clock 178.300657263s] Trained 128 records in 0.087074199 seconds. Throughput is 1470.0106 records/second. Loss is 2.1736283. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5536602700781805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52352/60000][Iteration 1816][Wall Clock 178.422408066s] Trained 128 records in 0.121750803 seconds. Throughput is 1051.3278 records/second. Loss is 2.1736372. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.552397868561279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 1817][Wall Clock 178.508296116s] Trained 128 records in 0.08588805 seconds. Throughput is 1490.3121 records/second. Loss is 2.1707635. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.551136363636364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52608/60000][Iteration 1818][Wall Clock 178.604569408s] Trained 128 records in 0.096273292 seconds. Throughput is 1329.5483 records/second. Loss is 2.1762605. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.549875754348598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 1819][Wall Clock 178.699891705s] Trained 128 records in 0.095322297 seconds. Throughput is 1342.8129 records/second. Loss is 2.1641278. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5486160397445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:14 INFO  DistriOptimizer$:408 - [Epoch 4 52864/60000][Iteration 1820][Wall Clock 178.7846642s] Trained 128 records in 0.084772495 seconds. Throughput is 1509.9237 records/second. Loss is 2.165131. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.547357218871941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 1821][Wall Clock 178.869968322s] Trained 128 records in 0.085304122 seconds. Throughput is 1500.5137 records/second. Loss is 2.159566. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5460992907801415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53120/60000][Iteration 1822][Wall Clock 178.956579618s] Trained 128 records in 0.086611296 seconds. Throughput is 1477.8673 records/second. Loss is 2.1971345. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5448422545196744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 1823][Wall Clock 179.044305457s] Trained 128 records in 0.087725839 seconds. Throughput is 1459.0912 records/second. Loss is 2.1751444. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5435861091424523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53376/60000][Iteration 1824][Wall Clock 179.132474097s] Trained 128 records in 0.08816864 seconds. Throughput is 1451.7633 records/second. Loss is 2.1383412. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5423308537017357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 1825][Wall Clock 179.218821883s] Trained 128 records in 0.086347786 seconds. Throughput is 1482.3773 records/second. Loss is 2.1664774. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.541076487252125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53632/60000][Iteration 1826][Wall Clock 179.305498622s] Trained 128 records in 0.086676739 seconds. Throughput is 1476.7515 records/second. Loss is 2.1530168. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5398230088495576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 1827][Wall Clock 179.394574278s] Trained 128 records in 0.089075656 seconds. Throughput is 1436.9807 records/second. Loss is 2.177127. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5385704175513094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 53888/60000][Iteration 1828][Wall Clock 179.481802463s] Trained 128 records in 0.087228185 seconds. Throughput is 1467.4155 records/second. Loss is 2.1788623. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5373187124159886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 1829][Wall Clock 179.574856245s] Trained 128 records in 0.093053782 seconds. Throughput is 1375.5486 records/second. Loss is 2.1652694. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5360678925035356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 54144/60000][Iteration 1830][Wall Clock 179.662897499s] Trained 128 records in 0.088041254 seconds. Throughput is 1453.8639 records/second. Loss is 2.163969. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.534817956875221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 1831][Wall Clock 179.747584952s] Trained 128 records in 0.084687453 seconds. Throughput is 1511.44 records/second. Loss is 2.174211. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5335689045936394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:15 INFO  DistriOptimizer$:408 - [Epoch 4 54400/60000][Iteration 1832][Wall Clock 179.842433596s] Trained 128 records in 0.094848644 seconds. Throughput is 1349.5184 records/second. Loss is 2.1737895. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5323207347227127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 1833][Wall Clock 179.935163397s] Trained 128 records in 0.092729801 seconds. Throughput is 1380.3545 records/second. Loss is 2.177295. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.531073446327684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 54656/60000][Iteration 1834][Wall Clock 180.016408151s] Trained 128 records in 0.081244754 seconds. Throughput is 1575.4863 records/second. Loss is 2.175458. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5298270384751147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 1835][Wall Clock 180.103566836s] Trained 128 records in 0.087158685 seconds. Throughput is 1468.5857 records/second. Loss is 2.1568093. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5285815102328866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 54912/60000][Iteration 1836][Wall Clock 180.193298847s] Trained 128 records in 0.089732011 seconds. Throughput is 1426.4697 records/second. Loss is 2.171366. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.527336860670194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 1837][Wall Clock 180.279233558s] Trained 128 records in 0.085934711 seconds. Throughput is 1489.5028 records/second. Loss is 2.1886885. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.526093088857546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55168/60000][Iteration 1838][Wall Clock 180.364000927s] Trained 128 records in 0.084767369 seconds. Throughput is 1510.015 records/second. Loss is 2.1690369. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.524850193866761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 1839][Wall Clock 180.457666847s] Trained 128 records in 0.09366592 seconds. Throughput is 1366.559 records/second. Loss is 2.1542683. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5236081747709656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55424/60000][Iteration 1840][Wall Clock 180.554300379s] Trained 128 records in 0.096633532 seconds. Throughput is 1324.5919 records/second. Loss is 2.1687841. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.522367030644593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 1841][Wall Clock 180.641692051s] Trained 128 records in 0.087391672 seconds. Throughput is 1464.6704 records/second. Loss is 2.1505322. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5211267605633805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55680/60000][Iteration 1842][Wall Clock 180.727083185s] Trained 128 records in 0.085391134 seconds. Throughput is 1498.9846 records/second. Loss is 2.1676443. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5198873636043646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:16 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 1843][Wall Clock 180.82421336s] Trained 128 records in 0.097130175 seconds. Throughput is 1317.8191 records/second. Loss is 2.163333. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.518648838845883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 55936/60000][Iteration 1844][Wall Clock 180.913043466s] Trained 128 records in 0.088830106 seconds. Throughput is 1440.9529 records/second. Loss is 2.1674657. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5174111853675694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 1845][Wall Clock 180.998826446s] Trained 128 records in 0.08578298 seconds. Throughput is 1492.1375 records/second. Loss is 2.1676457. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.516174402250351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56192/60000][Iteration 1846][Wall Clock 181.091208354s] Trained 128 records in 0.092381908 seconds. Throughput is 1385.5526 records/second. Loss is 2.1622932. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.51493848857645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 1847][Wall Clock 181.177773306s] Trained 128 records in 0.086564952 seconds. Throughput is 1478.6584 records/second. Loss is 2.193287. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5137034434293746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56448/60000][Iteration 1848][Wall Clock 181.265357317s] Trained 128 records in 0.087584011 seconds. Throughput is 1461.454 records/second. Loss is 2.1516554. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5124692658939234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 1849][Wall Clock 181.353823786s] Trained 128 records in 0.088466469 seconds. Throughput is 1446.876 records/second. Loss is 2.1568656. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.51123595505618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56704/60000][Iteration 1850][Wall Clock 181.460270796s] Trained 128 records in 0.10644701 seconds. Throughput is 1202.4762 records/second. Loss is 2.160984. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.51000351000351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 1851][Wall Clock 181.546520425s] Trained 128 records in 0.086249629 seconds. Throughput is 1484.0643 records/second. Loss is 2.1650927. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.508771929824561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 56960/60000][Iteration 1852][Wall Clock 181.631272045s] Trained 128 records in 0.08475162 seconds. Throughput is 1510.2957 records/second. Loss is 2.155908. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.50754121360926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 1853][Wall Clock 181.718501301s] Trained 128 records in 0.087229256 seconds. Throughput is 1467.3976 records/second. Loss is 2.1585574. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.506311360448808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:17 INFO  DistriOptimizer$:408 - [Epoch 4 57216/60000][Iteration 1854][Wall Clock 181.807480757s] Trained 128 records in 0.088979456 seconds. Throughput is 1438.5343 records/second. Loss is 2.164248. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.505082369435682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 1855][Wall Clock 181.894104664s] Trained 128 records in 0.086623907 seconds. Throughput is 1477.6521 records/second. Loss is 2.159496. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.50385423966363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 57472/60000][Iteration 1856][Wall Clock 181.980505428s] Trained 128 records in 0.086400764 seconds. Throughput is 1481.4684 records/second. Loss is 2.1765513. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.502626970227671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 1857][Wall Clock 182.067587671s] Trained 128 records in 0.087082243 seconds. Throughput is 1469.8749 records/second. Loss is 2.1470015. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5014005602240897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 57728/60000][Iteration 1858][Wall Clock 182.170554753s] Trained 128 records in 0.102967082 seconds. Throughput is 1243.1157 records/second. Loss is 2.1667852. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.5001750087504374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 1859][Wall Clock 182.256962235s] Trained 128 records in 0.086407482 seconds. Throughput is 1481.3531 records/second. Loss is 2.177759. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.498950314905528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 57984/60000][Iteration 1860][Wall Clock 182.342425805s] Trained 128 records in 0.08546357 seconds. Throughput is 1497.7142 records/second. Loss is 2.1572037. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.497726477789437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 1861][Wall Clock 182.432206588s] Trained 128 records in 0.089780783 seconds. Throughput is 1425.6948 records/second. Loss is 2.1752532. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.496503496503496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 58240/60000][Iteration 1862][Wall Clock 182.518938456s] Trained 128 records in 0.086731868 seconds. Throughput is 1475.8129 records/second. Loss is 2.1640482. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4952813701502974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 1863][Wall Clock 182.60501336s] Trained 128 records in 0.086074904 seconds. Throughput is 1487.0769 records/second. Loss is 2.163845. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4940600978336826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 58496/60000][Iteration 1864][Wall Clock 182.690916891s] Trained 128 records in 0.085903531 seconds. Throughput is 1490.0435 records/second. Loss is 2.172692. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4928396786587494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:18 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 1865][Wall Clock 182.777585877s] Trained 128 records in 0.086668986 seconds. Throughput is 1476.8835 records/second. Loss is 2.177783. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4916201117318437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 58752/60000][Iteration 1866][Wall Clock 182.865209429s] Trained 128 records in 0.087623552 seconds. Throughput is 1460.7944 records/second. Loss is 2.1463637. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.490401396160558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 1867][Wall Clock 182.950601135s] Trained 128 records in 0.085391706 seconds. Throughput is 1498.9746 records/second. Loss is 2.1749659. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.489183531053733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59008/60000][Iteration 1868][Wall Clock 183.040350415s] Trained 128 records in 0.08974928 seconds. Throughput is 1426.1953 records/second. Loss is 2.1894093. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.487966515521451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 1869][Wall Clock 183.134455597s] Trained 128 records in 0.094105182 seconds. Throughput is 1360.18 records/second. Loss is 2.1641202. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.486750348675035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59264/60000][Iteration 1870][Wall Clock 183.216485751s] Trained 128 records in 0.082030154 seconds. Throughput is 1560.4017 records/second. Loss is 2.155344. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4855350296270483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 1871][Wall Clock 183.308207962s] Trained 128 records in 0.091722211 seconds. Throughput is 1395.5181 records/second. Loss is 2.1555436. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.484320557491289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59520/60000][Iteration 1872][Wall Clock 183.395665873s] Trained 128 records in 0.087457911 seconds. Throughput is 1463.5612 records/second. Loss is 2.1689198. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4831069313827936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 1873][Wall Clock 183.482342323s] Trained 128 records in 0.08667645 seconds. Throughput is 1476.7563 records/second. Loss is 2.1732085. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4818941504178273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59776/60000][Iteration 1874][Wall Clock 183.570065948s] Trained 128 records in 0.087723625 seconds. Throughput is 1459.1279 records/second. Loss is 2.1624935. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4806822137138876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 1875][Wall Clock 183.658024244s] Trained 128 records in 0.087958296 seconds. Throughput is 1455.2351 records/second. Loss is 2.152419. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.479471120389701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:408 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 183.74308032s] Trained 128 records in 0.085056076 seconds. Throughput is 1504.8895 records/second. Loss is 2.154741. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4782608695652176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:19 INFO  DistriOptimizer$:452 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 183.74308032s] Epoch finished. Wall clock time is 185030.5105 ms
2019-10-14 23:14:19 INFO  DistriOptimizer$:111 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 183.74308032s] Validate model...
2019-10-14 23:14:20 INFO  DistriOptimizer$:178 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 183.74308032s] validate model throughput is 12131.66 records/second
2019-10-14 23:14:20 INFO  DistriOptimizer$:181 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 183.74308032s] Top1Accuracy is Accuracy(correct: 4560, count: 10000, accuracy: 0.456)
2019-10-14 23:14:20 INFO  DistriOptimizer$:221 - [Wall Clock 185.0305105s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:14:20 INFO  DistriOptimizer$:226 - [Wall Clock 185.0305105s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:14:20 INFO  DistriOptimizer$:408 - [Epoch 5 128/60000][Iteration 1877][Wall Clock 185.126410553s] Trained 128 records in 0.095900053 seconds. Throughput is 1334.7229 records/second. Loss is 2.1794071. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.477051460361613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 1878][Wall Clock 185.212557909s] Trained 128 records in 0.086147356 seconds. Throughput is 1485.8263 records/second. Loss is 2.1585183. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.475842891901286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 384/60000][Iteration 1879][Wall Clock 185.298175273s] Trained 128 records in 0.085617364 seconds. Throughput is 1495.0238 records/second. Loss is 2.1528327. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4746351633078526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 1880][Wall Clock 185.387544281s] Trained 128 records in 0.089369008 seconds. Throughput is 1432.2639 records/second. Loss is 2.1473324. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.473428273706148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 640/60000][Iteration 1881][Wall Clock 185.474584392s] Trained 128 records in 0.087040111 seconds. Throughput is 1470.5863 records/second. Loss is 2.1588473. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4722222222222224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 1882][Wall Clock 185.578714778s] Trained 128 records in 0.104130386 seconds. Throughput is 1229.2281 records/second. Loss is 2.1537113. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.471017007983339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 896/60000][Iteration 1883][Wall Clock 185.668561499s] Trained 128 records in 0.089846721 seconds. Throughput is 1424.6486 records/second. Loss is 2.1707482. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4698126301179735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 1884][Wall Clock 185.754461465s] Trained 128 records in 0.085899966 seconds. Throughput is 1490.1053 records/second. Loss is 2.1587293. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.46860908775581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 1152/60000][Iteration 1885][Wall Clock 185.840763495s] Trained 128 records in 0.08630203 seconds. Throughput is 1483.1633 records/second. Loss is 2.1513784. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.467406380027739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 1886][Wall Clock 185.928358345s] Trained 128 records in 0.08759485 seconds. Throughput is 1461.2731 records/second. Loss is 2.1721675. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.466204506065858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 1408/60000][Iteration 1887][Wall Clock 186.014386997s] Trained 128 records in 0.086028652 seconds. Throughput is 1487.8765 records/second. Loss is 2.1718307. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.465003465003465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 1888][Wall Clock 186.100477666s] Trained 128 records in 0.086090669 seconds. Throughput is 1486.8046 records/second. Loss is 2.1637247. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4638032559750607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:21 INFO  DistriOptimizer$:408 - [Epoch 5 1664/60000][Iteration 1889][Wall Clock 186.188513904s] Trained 128 records in 0.088036238 seconds. Throughput is 1453.9467 records/second. Loss is 2.1399543. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4626038781163435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 1890][Wall Clock 186.276094579s] Trained 128 records in 0.087580675 seconds. Throughput is 1461.5096 records/second. Loss is 2.153537. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.461405330564209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 1920/60000][Iteration 1891][Wall Clock 186.371765148s] Trained 128 records in 0.095670569 seconds. Throughput is 1337.9246 records/second. Loss is 2.1574914. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4602076124567473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 1892][Wall Clock 186.457445168s] Trained 128 records in 0.08568002 seconds. Throughput is 1493.9305 records/second. Loss is 2.163065. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.459010722933241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2176/60000][Iteration 1893][Wall Clock 186.553040234s] Trained 128 records in 0.095595066 seconds. Throughput is 1338.9812 records/second. Loss is 2.1578941. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.457814661134163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 1894][Wall Clock 186.635874056s] Trained 128 records in 0.082833822 seconds. Throughput is 1545.2626 records/second. Loss is 2.1727693. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.456619426201176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2432/60000][Iteration 1895][Wall Clock 186.720014119s] Trained 128 records in 0.084140063 seconds. Throughput is 1521.273 records/second. Loss is 2.1581151. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.455425017277125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 1896][Wall Clock 186.806614084s] Trained 128 records in 0.086599965 seconds. Throughput is 1478.0605 records/second. Loss is 2.164836. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.454231433506045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2688/60000][Iteration 1897][Wall Clock 186.893840473s] Trained 128 records in 0.087226389 seconds. Throughput is 1467.4458 records/second. Loss is 2.1676526. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4530386740331496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 1898][Wall Clock 186.981364284s] Trained 128 records in 0.087523811 seconds. Throughput is 1462.4592 records/second. Loss is 2.1331685. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4518467380048324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 2944/60000][Iteration 1899][Wall Clock 187.064692074s] Trained 128 records in 0.08332779 seconds. Throughput is 1536.1022 records/second. Loss is 2.148237. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.450655624568668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:22 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 1900][Wall Clock 187.151200423s] Trained 128 records in 0.086508349 seconds. Throughput is 1479.626 records/second. Loss is 2.1730607. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4494653328734045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3200/60000][Iteration 1901][Wall Clock 187.238401348s] Trained 128 records in 0.087200925 seconds. Throughput is 1467.8744 records/second. Loss is 2.1586783. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.448275862068965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 1902][Wall Clock 187.324950061s] Trained 128 records in 0.086548713 seconds. Throughput is 1478.9359 records/second. Loss is 2.1548944. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.447087211306446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3456/60000][Iteration 1903][Wall Clock 187.413357156s] Trained 128 records in 0.088407095 seconds. Throughput is 1447.8477 records/second. Loss is 2.1488. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4458993797381116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 1904][Wall Clock 187.499716005s] Trained 128 records in 0.086358849 seconds. Throughput is 1482.1874 records/second. Loss is 2.1681602. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.444712366517396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3712/60000][Iteration 1905][Wall Clock 187.587309138s] Trained 128 records in 0.087593133 seconds. Throughput is 1461.3018 records/second. Loss is 2.190876. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.443526170798898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 1906][Wall Clock 187.674117195s] Trained 128 records in 0.086808057 seconds. Throughput is 1474.5176 records/second. Loss is 2.1495838. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.442340791738382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 3968/60000][Iteration 1907][Wall Clock 187.760486682s] Trained 128 records in 0.086369487 seconds. Throughput is 1482.0049 records/second. Loss is 2.1535897. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4411562284927734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 1908][Wall Clock 187.857359196s] Trained 128 records in 0.096872514 seconds. Throughput is 1321.3242 records/second. Loss is 2.1350455. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.439972480220158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 4224/60000][Iteration 1909][Wall Clock 187.933354693s] Trained 128 records in 0.075995497 seconds. Throughput is 1684.3103 records/second. Loss is 2.1660712. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4387895460797794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 1910][Wall Clock 188.014539239s] Trained 128 records in 0.081184546 seconds. Throughput is 1576.6548 records/second. Loss is 2.1620085. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4376074252320387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 4480/60000][Iteration 1911][Wall Clock 188.098963444s] Trained 128 records in 0.084424205 seconds. Throughput is 1516.1528 records/second. Loss is 2.1403973. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4364261168384877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:23 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 1912][Wall Clock 188.184843034s] Trained 128 records in 0.08587959 seconds. Throughput is 1490.459 records/second. Loss is 2.1504116. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4352456200618345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 4736/60000][Iteration 1913][Wall Clock 188.270001438s] Trained 128 records in 0.085158404 seconds. Throughput is 1503.0812 records/second. Loss is 2.1316767. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4340659340659343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 1914][Wall Clock 188.358107512s] Trained 128 records in 0.088106074 seconds. Throughput is 1452.7943 records/second. Loss is 2.1443706. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.432887058015791E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 4992/60000][Iteration 1915][Wall Clock 188.449328353s] Trained 128 records in 0.091220841 seconds. Throughput is 1403.1881 records/second. Loss is 2.182842. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4317089910775565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 1916][Wall Clock 188.542332437s] Trained 128 records in 0.093004084 seconds. Throughput is 1376.2837 records/second. Loss is 2.157553. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.430531732418525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5248/60000][Iteration 1917][Wall Clock 188.639747756s] Trained 128 records in 0.097415319 seconds. Throughput is 1313.9617 records/second. Loss is 2.2025833. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.429355281207133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 1918][Wall Clock 188.722684984s] Trained 128 records in 0.082937228 seconds. Throughput is 1543.3359 records/second. Loss is 2.1378465. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4281796366129587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5504/60000][Iteration 1919][Wall Clock 188.818019299s] Trained 128 records in 0.095334315 seconds. Throughput is 1342.6436 records/second. Loss is 2.1613286. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4270047978067166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 1920][Wall Clock 188.912451056s] Trained 128 records in 0.094431757 seconds. Throughput is 1355.4762 records/second. Loss is 2.144957. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4258307639602604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5760/60000][Iteration 1921][Wall Clock 188.999011334s] Trained 128 records in 0.086560278 seconds. Throughput is 1478.7383 records/second. Loss is 2.165644. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4246575342465754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:24 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 1922][Wall Clock 189.090059926s] Trained 128 records in 0.091048592 seconds. Throughput is 1405.8428 records/second. Loss is 2.1823728. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4234851078397807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6016/60000][Iteration 1923][Wall Clock 189.19983285s] Trained 128 records in 0.109772924 seconds. Throughput is 1166.0435 records/second. Loss is 2.1471624. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.422313483915127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 1924][Wall Clock 189.285753663s] Trained 128 records in 0.085920813 seconds. Throughput is 1489.7439 records/second. Loss is 2.1556313. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4211426616489907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6272/60000][Iteration 1925][Wall Clock 189.369597707s] Trained 128 records in 0.083844044 seconds. Throughput is 1526.6439 records/second. Loss is 2.1570964. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.419972640218878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 1926][Wall Clock 189.45770877s] Trained 128 records in 0.088111063 seconds. Throughput is 1452.712 records/second. Loss is 2.1363132. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4188034188034193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6528/60000][Iteration 1927][Wall Clock 189.545679409s] Trained 128 records in 0.087970639 seconds. Throughput is 1455.031 records/second. Loss is 2.1263022. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4176349965823647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 1928][Wall Clock 189.634457196s] Trained 128 records in 0.088777787 seconds. Throughput is 1441.8021 records/second. Loss is 2.1576693. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4164673727365904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6784/60000][Iteration 1929][Wall Clock 189.721506483s] Trained 128 records in 0.087049287 seconds. Throughput is 1470.4313 records/second. Loss is 2.146191. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4153005464480874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 1930][Wall Clock 189.809959731s] Trained 128 records in 0.088453248 seconds. Throughput is 1447.0922 records/second. Loss is 2.1660585. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4141345168999654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 7040/60000][Iteration 1931][Wall Clock 189.894198453s] Trained 128 records in 0.084238722 seconds. Throughput is 1519.4912 records/second. Loss is 2.137433. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.412969283276451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 1932][Wall Clock 189.979507802s] Trained 128 records in 0.085309349 seconds. Throughput is 1500.4218 records/second. Loss is 2.157418. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.41180484476288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 7296/60000][Iteration 1933][Wall Clock 190.065121715s] Trained 128 records in 0.085613913 seconds. Throughput is 1495.0841 records/second. Loss is 2.1545877. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4106412005457026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:25 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 1934][Wall Clock 190.16197566s] Trained 128 records in 0.096853945 seconds. Throughput is 1321.5776 records/second. Loss is 2.1640134. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.409478349812479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 7552/60000][Iteration 1935][Wall Clock 190.244741683s] Trained 128 records in 0.082766023 seconds. Throughput is 1546.5283 records/second. Loss is 2.1594343. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4083162917518747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 1936][Wall Clock 190.327362483s] Trained 128 records in 0.0826208 seconds. Throughput is 1549.2467 records/second. Loss is 2.1727107. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4071550255536625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 7808/60000][Iteration 1937][Wall Clock 190.409957773s] Trained 128 records in 0.08259529 seconds. Throughput is 1549.7252 records/second. Loss is 2.1684096. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.405994550408719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 1938][Wall Clock 190.495402233s] Trained 128 records in 0.08544446 seconds. Throughput is 1498.0492 records/second. Loss is 2.1676557. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4048348655090226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8064/60000][Iteration 1939][Wall Clock 190.581582807s] Trained 128 records in 0.086180574 seconds. Throughput is 1485.2535 records/second. Loss is 2.1521583. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.403675970047652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 1940][Wall Clock 190.666161843s] Trained 128 records in 0.084579036 seconds. Throughput is 1513.3774 records/second. Loss is 2.1469278. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.402517863218782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8320/60000][Iteration 1941][Wall Clock 190.751281369s] Trained 128 records in 0.085119526 seconds. Throughput is 1503.7678 records/second. Loss is 2.1453347. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4013605442176874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 1942][Wall Clock 190.839666986s] Trained 128 records in 0.088385617 seconds. Throughput is 1448.1993 records/second. Loss is 2.1434014. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.4002040122407346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8576/60000][Iteration 1943][Wall Clock 190.938432792s] Trained 128 records in 0.098765806 seconds. Throughput is 1295.9951 records/second. Loss is 2.1957927. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.399048266485384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 1944][Wall Clock 191.028133339s] Trained 128 records in 0.089700547 seconds. Throughput is 1426.9701 records/second. Loss is 2.1338248. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.397893306150187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:26 INFO  DistriOptimizer$:408 - [Epoch 5 8832/60000][Iteration 1945][Wall Clock 191.116302774s] Trained 128 records in 0.088169435 seconds. Throughput is 1451.7502 records/second. Loss is 2.1577868. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3967391304347825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 1946][Wall Clock 191.20241698s] Trained 128 records in 0.086114206 seconds. Throughput is 1486.3982 records/second. Loss is 2.1626556. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.395585738539898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9088/60000][Iteration 1947][Wall Clock 191.289155517s] Trained 128 records in 0.086738537 seconds. Throughput is 1475.6993 records/second. Loss is 2.149231. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.394433129667346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 1948][Wall Clock 191.377940081s] Trained 128 records in 0.088784564 seconds. Throughput is 1441.6921 records/second. Loss is 2.158661. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3932813030200206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9344/60000][Iteration 1949][Wall Clock 191.465293998s] Trained 128 records in 0.087353917 seconds. Throughput is 1465.3036 records/second. Loss is 2.1321094. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3921302578019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 1950][Wall Clock 191.551970382s] Trained 128 records in 0.086676384 seconds. Throughput is 1476.7576 records/second. Loss is 2.151469. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3909799932180403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9600/60000][Iteration 1951][Wall Clock 191.640248103s] Trained 128 records in 0.088277721 seconds. Throughput is 1449.9695 records/second. Loss is 2.1549482. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.389830508474576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 1952][Wall Clock 191.727235434s] Trained 128 records in 0.086987331 seconds. Throughput is 1471.4786 records/second. Loss is 2.148445. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3886818027787193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9856/60000][Iteration 1953][Wall Clock 191.813539885s] Trained 128 records in 0.086304451 seconds. Throughput is 1483.1217 records/second. Loss is 2.1762006. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3875338753387534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 1954][Wall Clock 191.90208183s] Trained 128 records in 0.088541945 seconds. Throughput is 1445.6425 records/second. Loss is 2.1438081. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.386386725364036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 10112/60000][Iteration 1955][Wall Clock 191.987644796s] Trained 128 records in 0.085562966 seconds. Throughput is 1495.9744 records/second. Loss is 2.1543899. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.385240352064997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 1956][Wall Clock 192.074187979s] Trained 128 records in 0.086543183 seconds. Throughput is 1479.0305 records/second. Loss is 2.1503878. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3840947546531303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:27 INFO  DistriOptimizer$:408 - [Epoch 5 10368/60000][Iteration 1957][Wall Clock 192.161022891s] Trained 128 records in 0.086834912 seconds. Throughput is 1474.0614 records/second. Loss is 2.15579. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3829499323410016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 1958][Wall Clock 192.248539844s] Trained 128 records in 0.087516953 seconds. Throughput is 1462.5737 records/second. Loss is 2.1583302. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.381805884342239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 10624/60000][Iteration 1959][Wall Clock 192.334791157s] Trained 128 records in 0.086251313 seconds. Throughput is 1484.0354 records/second. Loss is 2.1658337. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.380662609871535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 1960][Wall Clock 192.43159927s] Trained 128 records in 0.096808113 seconds. Throughput is 1322.2032 records/second. Loss is 2.146774. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.379520108144643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 10880/60000][Iteration 1961][Wall Clock 192.515129134s] Trained 128 records in 0.083529864 seconds. Throughput is 1532.386 records/second. Loss is 2.1671882. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3783783783783786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 1962][Wall Clock 192.591095438s] Trained 128 records in 0.075966304 seconds. Throughput is 1684.9575 records/second. Loss is 2.1540554. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.377237419790611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11136/60000][Iteration 1963][Wall Clock 192.673917125s] Trained 128 records in 0.082821687 seconds. Throughput is 1545.4889 records/second. Loss is 2.1641245. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3760972316002703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 1964][Wall Clock 192.760373999s] Trained 128 records in 0.086456874 seconds. Throughput is 1480.507 records/second. Loss is 2.1397562. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.374957813027337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11392/60000][Iteration 1965][Wall Clock 192.848421206s] Trained 128 records in 0.088047207 seconds. Throughput is 1453.7656 records/second. Loss is 2.1476645. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3738191632928474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 1966][Wall Clock 192.932051758s] Trained 128 records in 0.083630552 seconds. Throughput is 1530.5411 records/second. Loss is 2.1567838. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.372681281618887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11648/60000][Iteration 1967][Wall Clock 193.019327393s] Trained 128 records in 0.087275635 seconds. Throughput is 1466.6178 records/second. Loss is 2.1532333. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3715441672285906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:28 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 1968][Wall Clock 193.110947024s] Trained 128 records in 0.091619631 seconds. Throughput is 1397.0804 records/second. Loss is 2.1693416. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.370407819346141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 11904/60000][Iteration 1969][Wall Clock 193.193697085s] Trained 128 records in 0.082750061 seconds. Throughput is 1546.8267 records/second. Loss is 2.1508071. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3692722371967657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 1970][Wall Clock 193.274827564s] Trained 128 records in 0.081130479 seconds. Throughput is 1577.7054 records/second. Loss is 2.1516616. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.368137420006736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12160/60000][Iteration 1971][Wall Clock 193.359266872s] Trained 128 records in 0.084439308 seconds. Throughput is 1515.8817 records/second. Loss is 2.1582046. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.367003367003367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 1972][Wall Clock 193.444782652s] Trained 128 records in 0.08551578 seconds. Throughput is 1496.7997 records/second. Loss is 2.174417. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.365870077415012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12416/60000][Iteration 1973][Wall Clock 193.529964063s] Trained 128 records in 0.085181411 seconds. Throughput is 1502.6753 records/second. Loss is 2.181725. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3647375504710633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 1974][Wall Clock 193.614963328s] Trained 128 records in 0.084999265 seconds. Throughput is 1505.8954 records/second. Loss is 2.131807. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.363605785401951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12672/60000][Iteration 1975][Wall Clock 193.700692731s] Trained 128 records in 0.085729403 seconds. Throughput is 1493.07 records/second. Loss is 2.1740265. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.362474781439139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 1976][Wall Clock 193.784207067s] Trained 128 records in 0.083514336 seconds. Throughput is 1532.671 records/second. Loss is 2.1804721. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.361344537815126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 12928/60000][Iteration 1977][Wall Clock 193.867424926s] Trained 128 records in 0.083217859 seconds. Throughput is 1538.1313 records/second. Loss is 2.1616066. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.360215053763441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 1978][Wall Clock 193.954438924s] Trained 128 records in 0.087013998 seconds. Throughput is 1471.0277 records/second. Loss is 2.1585052. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.359086328518643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 13184/60000][Iteration 1979][Wall Clock 194.040756002s] Trained 128 records in 0.086317078 seconds. Throughput is 1482.9047 records/second. Loss is 2.1453233. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.35795836131632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:29 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 1980][Wall Clock 194.127699115s] Trained 128 records in 0.086943113 seconds. Throughput is 1472.227 records/second. Loss is 2.1593494. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.356831151393085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 13440/60000][Iteration 1981][Wall Clock 194.213674939s] Trained 128 records in 0.085975824 seconds. Throughput is 1488.7905 records/second. Loss is 2.1658926. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.355704697986577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 1982][Wall Clock 194.299390692s] Trained 128 records in 0.085715753 seconds. Throughput is 1493.3077 records/second. Loss is 2.1521316. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.354579000335458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 13696/60000][Iteration 1983][Wall Clock 194.387890415s] Trained 128 records in 0.088499723 seconds. Throughput is 1446.3322 records/second. Loss is 2.1307766. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3534540576794097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 1984][Wall Clock 194.475172251s] Trained 128 records in 0.087281836 seconds. Throughput is 1466.5135 records/second. Loss is 2.1763473. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3523298692591353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 13952/60000][Iteration 1985][Wall Clock 194.561511342s] Trained 128 records in 0.086339091 seconds. Throughput is 1482.5266 records/second. Loss is 2.1480825. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.351206434316354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 1986][Wall Clock 194.662214403s] Trained 128 records in 0.100703061 seconds. Throughput is 1271.0636 records/second. Loss is 2.1629672. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.350083752093802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 14208/60000][Iteration 1987][Wall Clock 194.749432808s] Trained 128 records in 0.087218405 seconds. Throughput is 1467.5802 records/second. Loss is 2.1563838. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3489618218352315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 1988][Wall Clock 194.82896353s] Trained 128 records in 0.079530722 seconds. Throughput is 1609.4409 records/second. Loss is 2.1661181. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3478406427854036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 14464/60000][Iteration 1989][Wall Clock 194.909696343s] Trained 128 records in 0.080732813 seconds. Throughput is 1585.4767 records/second. Loss is 2.1874516. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3467202141900936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 1990][Wall Clock 194.995501152s] Trained 128 records in 0.085804809 seconds. Throughput is 1491.7578 records/second. Loss is 2.1549366. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.345600535296086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:30 INFO  DistriOptimizer$:408 - [Epoch 5 14720/60000][Iteration 1991][Wall Clock 195.083196244s] Trained 128 records in 0.087695092 seconds. Throughput is 1459.6028 records/second. Loss is 2.174494. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3444816053511704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 1992][Wall Clock 195.17022864s] Trained 128 records in 0.087032396 seconds. Throughput is 1470.7168 records/second. Loss is 2.170979. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3433634236041456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 14976/60000][Iteration 1993][Wall Clock 195.263179365s] Trained 128 records in 0.092950725 seconds. Throughput is 1377.0737 records/second. Loss is 2.1333413. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.342245989304813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 1994][Wall Clock 195.354594107s] Trained 128 records in 0.091414742 seconds. Throughput is 1400.2118 records/second. Loss is 2.1579444. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.341129301703976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15232/60000][Iteration 1995][Wall Clock 195.439143979s] Trained 128 records in 0.084549872 seconds. Throughput is 1513.8994 records/second. Loss is 2.1585298. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3400133600534405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 1996][Wall Clock 195.524637678s] Trained 128 records in 0.085493699 seconds. Throughput is 1497.1864 records/second. Loss is 2.174563. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.33889816360601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15488/60000][Iteration 1997][Wall Clock 195.609444149s] Trained 128 records in 0.084806471 seconds. Throughput is 1509.3187 records/second. Loss is 2.1779535. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.337783711615487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 1998][Wall Clock 195.695015902s] Trained 128 records in 0.085571753 seconds. Throughput is 1495.8208 records/second. Loss is 2.163303. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.33667000333667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15744/60000][Iteration 1999][Wall Clock 195.781894901s] Trained 128 records in 0.086878999 seconds. Throughput is 1473.3135 records/second. Loss is 2.1675684. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.33555703802535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 2000][Wall Clock 195.872980221s] Trained 128 records in 0.09108532 seconds. Throughput is 1405.2758 records/second. Loss is 2.1515965. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3344448149383126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 16000/60000][Iteration 2001][Wall Clock 195.962530283s] Trained 128 records in 0.089550062 seconds. Throughput is 1429.368 records/second. Loss is 2.1429389. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.333333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 2002][Wall Clock 196.050044709s] Trained 128 records in 0.087514426 seconds. Throughput is 1462.6161 records/second. Loss is 2.1648343. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.332222592469177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:31 INFO  DistriOptimizer$:408 - [Epoch 5 16256/60000][Iteration 2003][Wall Clock 196.13608708s] Trained 128 records in 0.086042371 seconds. Throughput is 1487.639 records/second. Loss is 2.14817. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3311125916055963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 2004][Wall Clock 196.222972143s] Trained 128 records in 0.086885063 seconds. Throughput is 1473.2106 records/second. Loss is 2.1471272. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.33000333000333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 16512/60000][Iteration 2005][Wall Clock 196.310618443s] Trained 128 records in 0.0876463 seconds. Throughput is 1460.4154 records/second. Loss is 2.1630082. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3288948069241014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 2006][Wall Clock 196.398744841s] Trained 128 records in 0.088126398 seconds. Throughput is 1452.4592 records/second. Loss is 2.1525161. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3277870216306157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 16768/60000][Iteration 2007][Wall Clock 196.484876839s] Trained 128 records in 0.086131998 seconds. Throughput is 1486.0912 records/second. Loss is 2.1615016. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3266799733865603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 2008][Wall Clock 196.570480805s] Trained 128 records in 0.085603966 seconds. Throughput is 1495.2578 records/second. Loss is 2.1809285. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.325573661456601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 17024/60000][Iteration 2009][Wall Clock 196.657108865s] Trained 128 records in 0.08662806 seconds. Throughput is 1477.5813 records/second. Loss is 2.1720417. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.324468085106383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 2010][Wall Clock 196.742842426s] Trained 128 records in 0.085733561 seconds. Throughput is 1492.9976 records/second. Loss is 2.1403942. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.323363243602526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 17280/60000][Iteration 2011][Wall Clock 196.82857956s] Trained 128 records in 0.085737134 seconds. Throughput is 1492.9354 records/second. Loss is 2.1706445. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.322259136212624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 2012][Wall Clock 196.925337694s] Trained 128 records in 0.096758134 seconds. Throughput is 1322.8862 records/second. Loss is 2.1425977. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3211557622052476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 17536/60000][Iteration 2013][Wall Clock 197.009096484s] Trained 128 records in 0.08375879 seconds. Throughput is 1528.1979 records/second. Loss is 2.1548412. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.320053120849934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:32 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 2014][Wall Clock 197.08715706s] Trained 128 records in 0.078060576 seconds. Throughput is 1639.7522 records/second. Loss is 2.1478152. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3189512114171923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 17792/60000][Iteration 2015][Wall Clock 197.170425342s] Trained 128 records in 0.083268282 seconds. Throughput is 1537.2 records/second. Loss is 2.1399496. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3178500331785003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 2016][Wall Clock 197.257905547s] Trained 128 records in 0.087480205 seconds. Throughput is 1463.1882 records/second. Loss is 2.151432. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.316749585406302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18048/60000][Iteration 2017][Wall Clock 197.345956032s] Trained 128 records in 0.088050485 seconds. Throughput is 1453.7114 records/second. Loss is 2.1556737. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.315649867374005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 2018][Wall Clock 197.433995162s] Trained 128 records in 0.08803913 seconds. Throughput is 1453.8989 records/second. Loss is 2.1441045. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.314550878355983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18304/60000][Iteration 2019][Wall Clock 197.522125954s] Trained 128 records in 0.088130792 seconds. Throughput is 1452.3867 records/second. Loss is 2.1443193. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.313452617627568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 2020][Wall Clock 197.61030833s] Trained 128 records in 0.088182376 seconds. Throughput is 1451.5372 records/second. Loss is 2.1339686. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.312355084465055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18560/60000][Iteration 2021][Wall Clock 197.694343652s] Trained 128 records in 0.084035322 seconds. Throughput is 1523.1691 records/second. Loss is 2.1527581. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3112582781456954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 2022][Wall Clock 197.781826639s] Trained 128 records in 0.087482987 seconds. Throughput is 1463.1416 records/second. Loss is 2.1243327. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3101621979476995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18816/60000][Iteration 2023][Wall Clock 197.868031898s] Trained 128 records in 0.086205259 seconds. Throughput is 1484.8282 records/second. Loss is 2.1247983. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3090668431502316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 2024][Wall Clock 197.954657658s] Trained 128 records in 0.08662576 seconds. Throughput is 1477.6205 records/second. Loss is 2.1348348. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.30797221303341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 19072/60000][Iteration 2025][Wall Clock 198.041428597s] Trained 128 records in 0.086770939 seconds. Throughput is 1475.1483 records/second. Loss is 2.1524541. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3068783068783067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:33 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 2026][Wall Clock 198.131786593s] Trained 128 records in 0.090357996 seconds. Throughput is 1416.5874 records/second. Loss is 2.171641. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3057851239669424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 19328/60000][Iteration 2027][Wall Clock 198.219986784s] Trained 128 records in 0.088200191 seconds. Throughput is 1451.244 records/second. Loss is 2.1495764. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3046926635822867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 2028][Wall Clock 198.305827828s] Trained 128 records in 0.085841044 seconds. Throughput is 1491.1282 records/second. Loss is 2.1678817. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.303600925008259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 19584/60000][Iteration 2029][Wall Clock 198.392215653s] Trained 128 records in 0.086387825 seconds. Throughput is 1481.6902 records/second. Loss is 2.1627777. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3025099075297226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 2030][Wall Clock 198.479595385s] Trained 128 records in 0.087379732 seconds. Throughput is 1464.8706 records/second. Loss is 2.1601567. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.301419610432486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 19840/60000][Iteration 2031][Wall Clock 198.568127715s] Trained 128 records in 0.08853233 seconds. Throughput is 1445.7996 records/second. Loss is 2.154299. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.3003300330033004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 2032][Wall Clock 198.655446176s] Trained 128 records in 0.087318461 seconds. Throughput is 1465.8986 records/second. Loss is 2.1607792. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.299241174529858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 20096/60000][Iteration 2033][Wall Clock 198.741149012s] Trained 128 records in 0.085702836 seconds. Throughput is 1493.5328 records/second. Loss is 2.1375604. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2981530343007914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 2034][Wall Clock 198.828532345s] Trained 128 records in 0.087383333 seconds. Throughput is 1464.8103 records/second. Loss is 2.15341. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.297065611605671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 20352/60000][Iteration 2035][Wall Clock 198.913788566s] Trained 128 records in 0.085256221 seconds. Throughput is 1501.3568 records/second. Loss is 2.168056. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.295978905735003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 2036][Wall Clock 198.999196498s] Trained 128 records in 0.085407932 seconds. Throughput is 1498.6898 records/second. Loss is 2.1364505. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2948929159802305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:34 INFO  DistriOptimizer$:408 - [Epoch 5 20608/60000][Iteration 2037][Wall Clock 199.110460194s] Trained 128 records in 0.111263696 seconds. Throughput is 1150.4202 records/second. Loss is 2.1496966. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2938076416337287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 2038][Wall Clock 199.191869219s] Trained 128 records in 0.081409025 seconds. Throughput is 1572.3073 records/second. Loss is 2.1490932. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.292723081988805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 20864/60000][Iteration 2039][Wall Clock 199.275936874s] Trained 128 records in 0.084067655 seconds. Throughput is 1522.5831 records/second. Loss is 2.145048. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.291639236339697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 2040][Wall Clock 199.356888148s] Trained 128 records in 0.080951274 seconds. Throughput is 1581.1981 records/second. Loss is 2.1589987. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.290556103981573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21120/60000][Iteration 2041][Wall Clock 199.444532715s] Trained 128 records in 0.087644567 seconds. Throughput is 1460.4442 records/second. Loss is 2.148717. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.289473684210526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 2042][Wall Clock 199.533197533s] Trained 128 records in 0.088664818 seconds. Throughput is 1443.6392 records/second. Loss is 2.1481824. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.288391976323578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21376/60000][Iteration 2043][Wall Clock 199.621164387s] Trained 128 records in 0.087966854 seconds. Throughput is 1455.0935 records/second. Loss is 2.151429. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2873109796186715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 2044][Wall Clock 199.709152364s] Trained 128 records in 0.087987977 seconds. Throughput is 1454.7443 records/second. Loss is 2.1493766. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.286230693394676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21632/60000][Iteration 2045][Wall Clock 199.80359024s] Trained 128 records in 0.094437876 seconds. Throughput is 1355.3884 records/second. Loss is 2.1512141. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.28515111695138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 2046][Wall Clock 199.885275604s] Trained 128 records in 0.081685364 seconds. Throughput is 1566.9882 records/second. Loss is 2.144784. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.284072249589491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 21888/60000][Iteration 2047][Wall Clock 199.975875635s] Trained 128 records in 0.090600031 seconds. Throughput is 1412.8031 records/second. Loss is 2.1443436. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2829940906106366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:35 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 2048][Wall Clock 200.060983033s] Trained 128 records in 0.085107398 seconds. Throughput is 1503.982 records/second. Loss is 2.148448. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.281916639317361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22144/60000][Iteration 2049][Wall Clock 200.145521497s] Trained 128 records in 0.084538464 seconds. Throughput is 1514.1036 records/second. Loss is 2.1432638. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2808398950131233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 2050][Wall Clock 200.23143243s] Trained 128 records in 0.085910933 seconds. Throughput is 1489.9152 records/second. Loss is 2.139005. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2797638570022957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22400/60000][Iteration 2051][Wall Clock 200.32203654s] Trained 128 records in 0.09060411 seconds. Throughput is 1412.7394 records/second. Loss is 2.1717072. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.278688524590164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 2052][Wall Clock 200.411494812s] Trained 128 records in 0.089458272 seconds. Throughput is 1430.8347 records/second. Loss is 2.1763985. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2776138970829236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22656/60000][Iteration 2053][Wall Clock 200.497811389s] Trained 128 records in 0.086316577 seconds. Throughput is 1482.9133 records/second. Loss is 2.1565456. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.27653997378768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 2054][Wall Clock 200.584676108s] Trained 128 records in 0.086864719 seconds. Throughput is 1473.5557 records/second. Loss is 2.1347697. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.275466754012447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 22912/60000][Iteration 2055][Wall Clock 200.675863662s] Trained 128 records in 0.091187554 seconds. Throughput is 1403.7003 records/second. Loss is 2.1652834. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.274394237066143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 2056][Wall Clock 200.764363387s] Trained 128 records in 0.088499725 seconds. Throughput is 1446.3322 records/second. Loss is 2.1485758. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.273322422258592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 23168/60000][Iteration 2057][Wall Clock 200.868516352s] Trained 128 records in 0.104152965 seconds. Throughput is 1228.9617 records/second. Loss is 2.15497. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.272251308900524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 2058][Wall Clock 200.955115739s] Trained 128 records in 0.086599387 seconds. Throughput is 1478.0706 records/second. Loss is 2.164892. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2711808963035657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:36 INFO  DistriOptimizer$:408 - [Epoch 5 23424/60000][Iteration 2059][Wall Clock 201.040653016s] Trained 128 records in 0.085537277 seconds. Throughput is 1496.4236 records/second. Loss is 2.1492436. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.270111183780249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 2060][Wall Clock 201.125949626s] Trained 128 records in 0.08529661 seconds. Throughput is 1500.6459 records/second. Loss is 2.1402519. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2690421706440013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 23680/60000][Iteration 2061][Wall Clock 201.213873656s] Trained 128 records in 0.08792403 seconds. Throughput is 1455.8022 records/second. Loss is 2.1726415. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.26797385620915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 2062][Wall Clock 201.299416742s] Trained 128 records in 0.085543086 seconds. Throughput is 1496.3219 records/second. Loss is 2.145793. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.266906239790918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 23936/60000][Iteration 2063][Wall Clock 201.394736588s] Trained 128 records in 0.095319846 seconds. Throughput is 1342.8473 records/second. Loss is 2.156797. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2658393207054214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 2064][Wall Clock 201.474517348s] Trained 128 records in 0.07978076 seconds. Throughput is 1604.3969 records/second. Loss is 2.1741204. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.26477309826967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24192/60000][Iteration 2065][Wall Clock 201.564153525s] Trained 128 records in 0.089636177 seconds. Throughput is 1427.9949 records/second. Loss is 2.1445942. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2637075718015666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 2066][Wall Clock 201.647715492s] Trained 128 records in 0.083561967 seconds. Throughput is 1531.7974 records/second. Loss is 2.1201234. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.262642740619902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24448/60000][Iteration 2067][Wall Clock 201.733312015s] Trained 128 records in 0.085596523 seconds. Throughput is 1495.3878 records/second. Loss is 2.147413. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.261578604044358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 2068][Wall Clock 201.819813896s] Trained 128 records in 0.086501881 seconds. Throughput is 1479.7366 records/second. Loss is 2.1522622. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2605151613955004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24704/60000][Iteration 2069][Wall Clock 201.905287561s] Trained 128 records in 0.085473665 seconds. Throughput is 1497.5374 records/second. Loss is 2.1427488. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.259452411994785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 2070][Wall Clock 201.988501537s] Trained 128 records in 0.083213976 seconds. Throughput is 1538.2031 records/second. Loss is 2.140738. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2583903551645487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:37 INFO  DistriOptimizer$:408 - [Epoch 5 24960/60000][Iteration 2071][Wall Clock 202.084169559s] Trained 128 records in 0.095668022 seconds. Throughput is 1337.9601 records/second. Loss is 2.1569264. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.257328990228013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 2072][Wall Clock 202.168275578s] Trained 128 records in 0.084106019 seconds. Throughput is 1521.8887 records/second. Loss is 2.145283. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.25626831650928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25216/60000][Iteration 2073][Wall Clock 202.253117904s] Trained 128 records in 0.084842326 seconds. Throughput is 1508.681 records/second. Loss is 2.1578212. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.255208333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 2074][Wall Clock 202.337697454s] Trained 128 records in 0.08457955 seconds. Throughput is 1513.3682 records/second. Loss is 2.1392927. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2541490400260335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25472/60000][Iteration 2075][Wall Clock 202.42334496s] Trained 128 records in 0.085647506 seconds. Throughput is 1494.4977 records/second. Loss is 2.153734. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2530904359141186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 2076][Wall Clock 202.510283317s] Trained 128 records in 0.086938357 seconds. Throughput is 1472.3075 records/second. Loss is 2.1586773. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.252032520325203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25728/60000][Iteration 2077][Wall Clock 202.597939502s] Trained 128 records in 0.087656185 seconds. Throughput is 1460.2506 records/second. Loss is 2.1614542. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2509752925877764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 2078][Wall Clock 202.681548776s] Trained 128 records in 0.083609274 seconds. Throughput is 1530.9307 records/second. Loss is 2.14972. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2499187520311994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 25984/60000][Iteration 2079][Wall Clock 202.767496337s] Trained 128 records in 0.085947561 seconds. Throughput is 1489.2803 records/second. Loss is 2.1575446. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2488628979857054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 2080][Wall Clock 202.852821095s] Trained 128 records in 0.085324758 seconds. Throughput is 1500.1508 records/second. Loss is 2.1632996. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.247807729782397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 26240/60000][Iteration 2081][Wall Clock 202.941972804s] Trained 128 records in 0.089151709 seconds. Throughput is 1435.7549 records/second. Loss is 2.1465461. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.246753246753247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:38 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 2082][Wall Clock 203.028916205s] Trained 128 records in 0.086943401 seconds. Throughput is 1472.2222 records/second. Loss is 2.164911. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.245699448231094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 26496/60000][Iteration 2083][Wall Clock 203.113933566s] Trained 128 records in 0.085017361 seconds. Throughput is 1505.5748 records/second. Loss is 2.1349401. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2446463335496434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 2084][Wall Clock 203.198086146s] Trained 128 records in 0.08415258 seconds. Throughput is 1521.0466 records/second. Loss is 2.1559143. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.243593902043464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 26752/60000][Iteration 2085][Wall Clock 203.286715703s] Trained 128 records in 0.088629557 seconds. Throughput is 1444.2135 records/second. Loss is 2.1611125. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2425421530479895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 2086][Wall Clock 203.373466896s] Trained 128 records in 0.086751193 seconds. Throughput is 1475.484 records/second. Loss is 2.156874. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.241491085899514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27008/60000][Iteration 2087][Wall Clock 203.466373947s] Trained 128 records in 0.092907051 seconds. Throughput is 1377.7211 records/second. Loss is 2.1388443. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.240440699935191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 2088][Wall Clock 203.564986149s] Trained 128 records in 0.098612202 seconds. Throughput is 1298.0138 records/second. Loss is 2.1527684. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2393909944930353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27264/60000][Iteration 2089][Wall Clock 203.646687072s] Trained 128 records in 0.081700923 seconds. Throughput is 1566.6898 records/second. Loss is 2.1397614. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.238341968911917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 2090][Wall Clock 203.7297553s] Trained 128 records in 0.083068228 seconds. Throughput is 1540.902 records/second. Loss is 2.1427426. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.237293622531564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27520/60000][Iteration 2091][Wall Clock 203.814148371s] Trained 128 records in 0.084393071 seconds. Throughput is 1516.7123 records/second. Loss is 2.1395512. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2362459546925567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 2092][Wall Clock 203.902846546s] Trained 128 records in 0.088698175 seconds. Throughput is 1443.0962 records/second. Loss is 2.1247358. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.235198964736331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27776/60000][Iteration 2093][Wall Clock 203.990793665s] Trained 128 records in 0.087947119 seconds. Throughput is 1455.4202 records/second. Loss is 2.1642735. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2341526520051744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:39 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 2094][Wall Clock 204.075876826s] Trained 128 records in 0.085083161 seconds. Throughput is 1504.4104 records/second. Loss is 2.1483858. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2331070158422246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28032/60000][Iteration 2095][Wall Clock 204.161200703s] Trained 128 records in 0.085323877 seconds. Throughput is 1500.1663 records/second. Loss is 2.1509373. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.232062055591468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 2096][Wall Clock 204.2533831s] Trained 128 records in 0.092182397 seconds. Throughput is 1388.5514 records/second. Loss is 2.1679316. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.231017770597738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28288/60000][Iteration 2097][Wall Clock 204.33775041s] Trained 128 records in 0.08436731 seconds. Throughput is 1517.1753 records/second. Loss is 2.1441343. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2299741602067185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 2098][Wall Clock 204.417736145s] Trained 128 records in 0.079985735 seconds. Throughput is 1600.2853 records/second. Loss is 2.14512. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2289312237649337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28544/60000][Iteration 2099][Wall Clock 204.504217365s] Trained 128 records in 0.08648122 seconds. Throughput is 1480.0901 records/second. Loss is 2.1604548. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.227888960619755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 2100][Wall Clock 204.589844757s] Trained 128 records in 0.085627392 seconds. Throughput is 1494.8488 records/second. Loss is 2.135913. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2268473701193933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28800/60000][Iteration 2101][Wall Clock 204.675730121s] Trained 128 records in 0.085885364 seconds. Throughput is 1490.3588 records/second. Loss is 2.1399195. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.225806451612903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 2102][Wall Clock 204.76049666s] Trained 128 records in 0.084766539 seconds. Throughput is 1510.0298 records/second. Loss is 2.138909. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2247662044501777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 29056/60000][Iteration 2103][Wall Clock 204.848583636s] Trained 128 records in 0.088086976 seconds. Throughput is 1453.1093 records/second. Loss is 2.1554842. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.223726627981947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 2104][Wall Clock 204.933661553s] Trained 128 records in 0.085077917 seconds. Throughput is 1504.5032 records/second. Loss is 2.1452513. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2226877215597806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:40 INFO  DistriOptimizer$:408 - [Epoch 5 29312/60000][Iteration 2105][Wall Clock 205.022567383s] Trained 128 records in 0.08890583 seconds. Throughput is 1439.7256 records/second. Loss is 2.163281. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2216494845360824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 2106][Wall Clock 205.10923703s] Trained 128 records in 0.086669647 seconds. Throughput is 1476.8723 records/second. Loss is 2.1414979. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2206119162640903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 29568/60000][Iteration 2107][Wall Clock 205.197623691s] Trained 128 records in 0.088386661 seconds. Throughput is 1448.1823 records/second. Loss is 2.1476176. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2195750160978755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 2108][Wall Clock 205.284337365s] Trained 128 records in 0.086713674 seconds. Throughput is 1476.1224 records/second. Loss is 2.126719. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2185387833923396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 29824/60000][Iteration 2109][Wall Clock 205.373522771s] Trained 128 records in 0.089185406 seconds. Throughput is 1435.2123 records/second. Loss is 2.1390185. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2175032175032174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 2110][Wall Clock 205.475115657s] Trained 128 records in 0.101592886 seconds. Throughput is 1259.9308 records/second. Loss is 2.1465805. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.21646831778707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30080/60000][Iteration 2111][Wall Clock 205.567960787s] Trained 128 records in 0.09284513 seconds. Throughput is 1378.6399 records/second. Loss is 2.1506095. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.215434083601286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 2112][Wall Clock 205.652647722s] Trained 128 records in 0.084686935 seconds. Throughput is 1511.4492 records/second. Loss is 2.1524642. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.214400514304082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30336/60000][Iteration 2113][Wall Clock 205.737582326s] Trained 128 records in 0.084934604 seconds. Throughput is 1507.0417 records/second. Loss is 2.1422694. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2133676092544985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 2114][Wall Clock 205.830751661s] Trained 128 records in 0.093169335 seconds. Throughput is 1373.8427 records/second. Loss is 2.150335. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2123353678124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30592/60000][Iteration 2115][Wall Clock 205.916567702s] Trained 128 records in 0.085816041 seconds. Throughput is 1491.5626 records/second. Loss is 2.1700885. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.211303789338472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 2116][Wall Clock 205.996198059s] Trained 128 records in 0.079630357 seconds. Throughput is 1607.4271 records/second. Loss is 2.121582. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2102728731942215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:41 INFO  DistriOptimizer$:408 - [Epoch 5 30848/60000][Iteration 2117][Wall Clock 206.083407079s] Trained 128 records in 0.08720902 seconds. Throughput is 1467.738 records/second. Loss is 2.156518. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2092426187419767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 2118][Wall Clock 206.171175235s] Trained 128 records in 0.087768156 seconds. Throughput is 1458.3878 records/second. Loss is 2.1689463. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.208213025344883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31104/60000][Iteration 2119][Wall Clock 206.258998283s] Trained 128 records in 0.087823048 seconds. Throughput is 1457.4762 records/second. Loss is 2.1468349. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.207184092366902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 2120][Wall Clock 206.348547641s] Trained 128 records in 0.089549358 seconds. Throughput is 1429.3794 records/second. Loss is 2.1488678. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.206155819172812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31360/60000][Iteration 2121][Wall Clock 206.435726133s] Trained 128 records in 0.087178492 seconds. Throughput is 1468.2521 records/second. Loss is 2.1561558. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.205128205128205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 2122][Wall Clock 206.528402249s] Trained 128 records in 0.092676116 seconds. Throughput is 1381.154 records/second. Loss is 2.1308036. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.204101249599487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31616/60000][Iteration 2123][Wall Clock 206.614240215s] Trained 128 records in 0.085837966 seconds. Throughput is 1491.1816 records/second. Loss is 2.1337445. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.203074951953876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 2124][Wall Clock 206.704151287s] Trained 128 records in 0.089911072 seconds. Throughput is 1423.6289 records/second. Loss is 2.1374662. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.202049311559398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 31872/60000][Iteration 2125][Wall Clock 206.79023266s] Trained 128 records in 0.086081373 seconds. Throughput is 1486.9652 records/second. Loss is 2.133525. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.201024327784891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 2126][Wall Clock 206.875812211s] Trained 128 records in 0.085579551 seconds. Throughput is 1495.6844 records/second. Loss is 2.14216. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.2E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 32128/60000][Iteration 2127][Wall Clock 206.962071097s] Trained 128 records in 0.086258886 seconds. Throughput is 1483.905 records/second. Loss is 2.1393826. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1989763275751764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:42 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 2128][Wall Clock 207.04878399s] Trained 128 records in 0.086712893 seconds. Throughput is 1476.1357 records/second. Loss is 2.1599774. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1979533098816753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 32384/60000][Iteration 2129][Wall Clock 207.132977086s] Trained 128 records in 0.084193096 seconds. Throughput is 1520.3147 records/second. Loss is 2.1414478. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.19693094629156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 2130][Wall Clock 207.218105654s] Trained 128 records in 0.085128568 seconds. Throughput is 1503.608 records/second. Loss is 2.151462. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1959092361776926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 32640/60000][Iteration 2131][Wall Clock 207.306909531s] Trained 128 records in 0.088803877 seconds. Throughput is 1441.3784 records/second. Loss is 2.1240935. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.194888178913738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 2132][Wall Clock 207.393486958s] Trained 128 records in 0.086577427 seconds. Throughput is 1478.4453 records/second. Loss is 2.1434975. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1938677738741617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 32896/60000][Iteration 2133][Wall Clock 207.494631557s] Trained 128 records in 0.101144599 seconds. Throughput is 1265.515 records/second. Loss is 2.139082. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1928480204342275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 2134][Wall Clock 207.58517582s] Trained 128 records in 0.090544263 seconds. Throughput is 1413.6732 records/second. Loss is 2.1151786. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.191828917969997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 33152/60000][Iteration 2135][Wall Clock 207.701119402s] Trained 128 records in 0.115943582 seconds. Throughput is 1103.9852 records/second. Loss is 2.1304035. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.190810465858328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 2136][Wall Clock 207.78407569s] Trained 128 records in 0.082956288 seconds. Throughput is 1542.9813 records/second. Loss is 2.151383. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.189792663476874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 33408/60000][Iteration 2137][Wall Clock 207.869309524s] Trained 128 records in 0.085233834 seconds. Throughput is 1501.751 records/second. Loss is 2.1310303. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1887755102040814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 2138][Wall Clock 207.956699848s] Trained 128 records in 0.087390324 seconds. Throughput is 1464.693 records/second. Loss is 2.1624308. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.18775900541919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:43 INFO  DistriOptimizer$:408 - [Epoch 5 33664/60000][Iteration 2139][Wall Clock 208.046474834s] Trained 128 records in 0.089774986 seconds. Throughput is 1425.7869 records/second. Loss is 2.1363. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.186743148502231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 2140][Wall Clock 208.131365648s] Trained 128 records in 0.084890814 seconds. Throughput is 1507.8192 records/second. Loss is 2.1510732. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1857279388340236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 33920/60000][Iteration 2141][Wall Clock 208.210122145s] Trained 128 records in 0.078756497 seconds. Throughput is 1625.2627 records/second. Loss is 2.1605022. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.184713375796178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 2142][Wall Clock 208.298722867s] Trained 128 records in 0.088600722 seconds. Throughput is 1444.6835 records/second. Loss is 2.1419952. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.183699458771092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34176/60000][Iteration 2143][Wall Clock 208.386768385s] Trained 128 records in 0.088045518 seconds. Throughput is 1453.7936 records/second. Loss is 2.1630018. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.182686187141948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 2144][Wall Clock 208.471316156s] Trained 128 records in 0.084547771 seconds. Throughput is 1513.937 records/second. Loss is 2.1338096. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.181673560292714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34432/60000][Iteration 2145][Wall Clock 208.556893671s] Trained 128 records in 0.085577515 seconds. Throughput is 1495.72 records/second. Loss is 2.1463187. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.180661577608142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 2146][Wall Clock 208.640946591s] Trained 128 records in 0.08405292 seconds. Throughput is 1522.8501 records/second. Loss is 2.1479495. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.179650238473768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34688/60000][Iteration 2147][Wall Clock 208.734267694s] Trained 128 records in 0.093321103 seconds. Throughput is 1371.6084 records/second. Loss is 2.1297655. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.178639542275906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 2148][Wall Clock 208.818749871s] Trained 128 records in 0.084482177 seconds. Throughput is 1515.1124 records/second. Loss is 2.1475751. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.177629488401652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 34944/60000][Iteration 2149][Wall Clock 208.904092828s] Trained 128 records in 0.085342957 seconds. Throughput is 1499.8308 records/second. Loss is 2.1680863. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.176620076238882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 2150][Wall Clock 208.98909029s] Trained 128 records in 0.084997462 seconds. Throughput is 1505.9274 records/second. Loss is 2.1319995. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1756113051762465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:44 INFO  DistriOptimizer$:408 - [Epoch 5 35200/60000][Iteration 2151][Wall Clock 209.074233803s] Trained 128 records in 0.085143513 seconds. Throughput is 1503.3441 records/second. Loss is 2.1392064. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1746031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 2152][Wall Clock 209.158017964s] Trained 128 records in 0.083784161 seconds. Throughput is 1527.735 records/second. Loss is 2.1343741. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1735956839098697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 35456/60000][Iteration 2153][Wall Clock 209.243172591s] Trained 128 records in 0.085154627 seconds. Throughput is 1503.1478 records/second. Loss is 2.1518905. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1725888324873094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 2154][Wall Clock 209.328997416s] Trained 128 records in 0.085824825 seconds. Throughput is 1491.41 records/second. Loss is 2.1498823. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.171582619727244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 35712/60000][Iteration 2155][Wall Clock 209.412366135s] Trained 128 records in 0.083368719 seconds. Throughput is 1535.348 records/second. Loss is 2.1538184. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.170577045022194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 2156][Wall Clock 209.498806927s] Trained 128 records in 0.086440792 seconds. Throughput is 1480.7823 records/second. Loss is 2.132518. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.169572107765451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 35968/60000][Iteration 2157][Wall Clock 209.584538643s] Trained 128 records in 0.085731716 seconds. Throughput is 1493.0298 records/second. Loss is 2.1623025. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.168567807351077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 2158][Wall Clock 209.673676438s] Trained 128 records in 0.089137795 seconds. Throughput is 1435.979 records/second. Loss is 2.1667743. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.167564143173899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 36224/60000][Iteration 2159][Wall Clock 209.759662349s] Trained 128 records in 0.085985911 seconds. Throughput is 1488.616 records/second. Loss is 2.1400018. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1665611146295124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 2160][Wall Clock 209.848917821s] Trained 128 records in 0.089255472 seconds. Throughput is 1434.0857 records/second. Loss is 2.1547246. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1655587211142766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 36480/60000][Iteration 2161][Wall Clock 209.935568685s] Trained 128 records in 0.086650864 seconds. Throughput is 1477.1924 records/second. Loss is 2.1802058. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1645569620253165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:45 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 2162][Wall Clock 210.026381823s] Trained 128 records in 0.090813138 seconds. Throughput is 1409.4877 records/second. Loss is 2.1378565. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1635558367605187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 36736/60000][Iteration 2163][Wall Clock 210.111804679s] Trained 128 records in 0.085422856 seconds. Throughput is 1498.428 records/second. Loss is 2.140161. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1625553447185326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 2164][Wall Clock 210.195216615s] Trained 128 records in 0.083411936 seconds. Throughput is 1534.5525 records/second. Loss is 2.1403985. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1615554852987667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 36992/60000][Iteration 2165][Wall Clock 210.291325739s] Trained 128 records in 0.096109124 seconds. Throughput is 1331.8195 records/second. Loss is 2.153906. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1605562579013904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 2166][Wall Clock 210.373588785s] Trained 128 records in 0.082263046 seconds. Throughput is 1555.9843 records/second. Loss is 2.120443. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1595576619273305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37248/60000][Iteration 2167][Wall Clock 210.459911836s] Trained 128 records in 0.086323051 seconds. Throughput is 1482.802 records/second. Loss is 2.1351352. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1585596967782694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 2168][Wall Clock 210.547717642s] Trained 128 records in 0.087805806 seconds. Throughput is 1457.7623 records/second. Loss is 2.1672375. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1575623618566466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37504/60000][Iteration 2169][Wall Clock 210.634216518s] Trained 128 records in 0.086498876 seconds. Throughput is 1479.788 records/second. Loss is 2.1344903. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1565656565656563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 2170][Wall Clock 210.724581691s] Trained 128 records in 0.090365173 seconds. Throughput is 1416.475 records/second. Loss is 2.1406806. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.155569580309246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37760/60000][Iteration 2171][Wall Clock 210.810655024s] Trained 128 records in 0.086073333 seconds. Throughput is 1487.104 records/second. Loss is 2.1177583. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.154574132492114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 2172][Wall Clock 210.901496203s] Trained 128 records in 0.090841179 seconds. Throughput is 1409.0526 records/second. Loss is 2.1385286. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.15357931251971E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:46 INFO  DistriOptimizer$:408 - [Epoch 5 38016/60000][Iteration 2173][Wall Clock 210.991148784s] Trained 128 records in 0.089652581 seconds. Throughput is 1427.7335 records/second. Loss is 2.1452749. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1525851197982345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 2174][Wall Clock 211.075782641s] Trained 128 records in 0.084633857 seconds. Throughput is 1512.3971 records/second. Loss is 2.0979862. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.151591553734636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38272/60000][Iteration 2175][Wall Clock 211.160513267s] Trained 128 records in 0.084730626 seconds. Throughput is 1510.6698 records/second. Loss is 2.1448154. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.15059861373661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 2176][Wall Clock 211.246623003s] Trained 128 records in 0.086109736 seconds. Throughput is 1486.4753 records/second. Loss is 2.1482909. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1496062992125983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38528/60000][Iteration 2177][Wall Clock 211.333168753s] Trained 128 records in 0.08654575 seconds. Throughput is 1478.9866 records/second. Loss is 2.127861. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1486146095717883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 2178][Wall Clock 211.41962389s] Trained 128 records in 0.086455137 seconds. Throughput is 1480.5366 records/second. Loss is 2.1361282. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.147623544224111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38784/60000][Iteration 2179][Wall Clock 211.506600528s] Trained 128 records in 0.086976638 seconds. Throughput is 1471.6595 records/second. Loss is 2.1390169. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1466331025802394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 2180][Wall Clock 211.594228222s] Trained 128 records in 0.087627694 seconds. Throughput is 1460.7255 records/second. Loss is 2.158286. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.145643284051589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 39040/60000][Iteration 2181][Wall Clock 211.680644916s] Trained 128 records in 0.086416694 seconds. Throughput is 1481.1953 records/second. Loss is 2.141887. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1446540880503143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 2182][Wall Clock 211.764288099s] Trained 128 records in 0.083643183 seconds. Throughput is 1530.31 records/second. Loss is 2.1560867. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1436655139893113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 39296/60000][Iteration 2183][Wall Clock 211.847667155s] Trained 128 records in 0.083379056 seconds. Throughput is 1535.1577 records/second. Loss is 2.1558971. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1426775612822125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 2184][Wall Clock 211.932459691s] Trained 128 records in 0.084792536 seconds. Throughput is 1509.5668 records/second. Loss is 2.1597316. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.141690229343387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:47 INFO  DistriOptimizer$:408 - [Epoch 5 39552/60000][Iteration 2185][Wall Clock 212.018062493s] Trained 128 records in 0.085602802 seconds. Throughput is 1495.2781 records/second. Loss is 2.1421144. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.14070351758794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 2186][Wall Clock 212.102346587s] Trained 128 records in 0.084284094 seconds. Throughput is 1518.6732 records/second. Loss is 2.1582341. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.139717425431711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 39808/60000][Iteration 2187][Wall Clock 212.187767452s] Trained 128 records in 0.085420865 seconds. Throughput is 1498.463 records/second. Loss is 2.1360223. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1387319522912746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 2188][Wall Clock 212.275907818s] Trained 128 records in 0.088140366 seconds. Throughput is 1452.229 records/second. Loss is 2.1427758. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.137747097583935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40064/60000][Iteration 2189][Wall Clock 212.364131825s] Trained 128 records in 0.088224007 seconds. Throughput is 1450.8522 records/second. Loss is 2.1603167. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.136762860727729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 2190][Wall Clock 212.455827227s] Trained 128 records in 0.091695402 seconds. Throughput is 1395.926 records/second. Loss is 2.136537. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1357792411414236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40320/60000][Iteration 2191][Wall Clock 212.539478097s] Trained 128 records in 0.08365087 seconds. Throughput is 1530.1693 records/second. Loss is 2.1459534. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1347962382445143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 2192][Wall Clock 212.628381375s] Trained 128 records in 0.088903278 seconds. Throughput is 1439.767 records/second. Loss is 2.145106. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.133813851457224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40576/60000][Iteration 2193][Wall Clock 212.717344199s] Trained 128 records in 0.088962824 seconds. Throughput is 1438.8032 records/second. Loss is 2.1362243. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.132832080200501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 2194][Wall Clock 212.805303094s] Trained 128 records in 0.087958895 seconds. Throughput is 1455.2252 records/second. Loss is 2.1304817. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1318509238960227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40832/60000][Iteration 2195][Wall Clock 212.893068623s] Trained 128 records in 0.087765529 seconds. Throughput is 1458.4314 records/second. Loss is 2.156506. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1308703819661864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:48 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 2196][Wall Clock 212.981157704s] Trained 128 records in 0.088089081 seconds. Throughput is 1453.0746 records/second. Loss is 2.15571. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.129890453834116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41088/60000][Iteration 2197][Wall Clock 213.068449756s] Trained 128 records in 0.087292052 seconds. Throughput is 1466.3419 records/second. Loss is 2.1465428. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1289111389236547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 2198][Wall Clock 213.161612798s] Trained 128 records in 0.093163042 seconds. Throughput is 1373.9354 records/second. Loss is 2.1496625. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1279324366593683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41344/60000][Iteration 2199][Wall Clock 213.249869469s] Trained 128 records in 0.088256671 seconds. Throughput is 1450.3153 records/second. Loss is 2.156035. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1269543464665416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 2200][Wall Clock 213.335336498s] Trained 128 records in 0.085467029 seconds. Throughput is 1497.6536 records/second. Loss is 2.1416721. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.125976867771179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41600/60000][Iteration 2201][Wall Clock 213.42175226s] Trained 128 records in 0.086415762 seconds. Throughput is 1481.2113 records/second. Loss is 2.1278186. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 2202][Wall Clock 213.508774492s] Trained 128 records in 0.087022232 seconds. Throughput is 1470.8885 records/second. Loss is 2.1127808. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1240237425804435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41856/60000][Iteration 2203][Wall Clock 213.594409229s] Trained 128 records in 0.085634737 seconds. Throughput is 1494.7205 records/second. Loss is 2.1524684. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1230480949406624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 2204][Wall Clock 213.681495241s] Trained 128 records in 0.087086012 seconds. Throughput is 1469.8112 records/second. Loss is 2.1328933. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1220730565095225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 42112/60000][Iteration 2205][Wall Clock 213.769964023s] Trained 128 records in 0.088468782 seconds. Throughput is 1446.838 records/second. Loss is 2.14485. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1210986267166043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 2206][Wall Clock 213.855956284s] Trained 128 records in 0.085992261 seconds. Throughput is 1488.506 records/second. Loss is 2.112962. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1201248049921997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 42368/60000][Iteration 2207][Wall Clock 213.940264715s] Trained 128 records in 0.084308431 seconds. Throughput is 1518.2349 records/second. Loss is 2.111683. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1191515907673113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:49 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 2208][Wall Clock 214.025218252s] Trained 128 records in 0.084953537 seconds. Throughput is 1506.7059 records/second. Loss is 2.1327796. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.118178983473652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 42624/60000][Iteration 2209][Wall Clock 214.112262299s] Trained 128 records in 0.087044047 seconds. Throughput is 1470.5199 records/second. Loss is 2.123768. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.117206982543641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 2210][Wall Clock 214.199459011s] Trained 128 records in 0.087196712 seconds. Throughput is 1467.9452 records/second. Loss is 2.1150696. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.116235587410408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 42880/60000][Iteration 2211][Wall Clock 214.286882924s] Trained 128 records in 0.087423913 seconds. Throughput is 1464.1302 records/second. Loss is 2.1048539. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1152647975077883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 2212][Wall Clock 214.37223152s] Trained 128 records in 0.085348596 seconds. Throughput is 1499.7317 records/second. Loss is 2.1181583. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.114294612270321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43136/60000][Iteration 2213][Wall Clock 214.459535625s] Trained 128 records in 0.087304105 seconds. Throughput is 1466.1395 records/second. Loss is 2.1277316. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1133250311332503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 2214][Wall Clock 214.546963334s] Trained 128 records in 0.087427709 seconds. Throughput is 1464.0668 records/second. Loss is 2.1288328. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.112356053532524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43392/60000][Iteration 2215][Wall Clock 214.634981809s] Trained 128 records in 0.088018475 seconds. Throughput is 1454.2401 records/second. Loss is 2.1506586. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1113876789047915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 2216][Wall Clock 214.734412176s] Trained 128 records in 0.099430367 seconds. Throughput is 1287.3331 records/second. Loss is 2.1477494. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.110419906687403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43648/60000][Iteration 2217][Wall Clock 214.819708842s] Trained 128 records in 0.085296666 seconds. Throughput is 1500.6448 records/second. Loss is 2.1232023. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.109452736318408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 2218][Wall Clock 214.909641815s] Trained 128 records in 0.089932973 seconds. Throughput is 1423.2822 records/second. Loss is 2.1420722. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1084861672365556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:50 INFO  DistriOptimizer$:408 - [Epoch 5 43904/60000][Iteration 2219][Wall Clock 214.990477141s] Trained 128 records in 0.080835326 seconds. Throughput is 1583.4661 records/second. Loss is 2.1166768. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.107520198881293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 2220][Wall Clock 215.07624812s] Trained 128 records in 0.085770979 seconds. Throughput is 1492.3463 records/second. Loss is 2.127832. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.106554830692762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44160/60000][Iteration 2221][Wall Clock 215.161768623s] Trained 128 records in 0.085520503 seconds. Throughput is 1496.717 records/second. Loss is 2.1314082. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1055900621118014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 2222][Wall Clock 215.24772953s] Trained 128 records in 0.085960907 seconds. Throughput is 1489.049 records/second. Loss is 2.129396. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.104625892579944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44416/60000][Iteration 2223][Wall Clock 215.333964511s] Trained 128 records in 0.086234981 seconds. Throughput is 1484.3165 records/second. Loss is 2.1308558. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1036623215394165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 2224][Wall Clock 215.428740881s] Trained 128 records in 0.09477637 seconds. Throughput is 1350.5476 records/second. Loss is 2.12285. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.102699348433137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44672/60000][Iteration 2225][Wall Clock 215.513467577s] Trained 128 records in 0.084726696 seconds. Throughput is 1510.7399 records/second. Loss is 2.118864. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.1017369727047146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 2226][Wall Clock 215.599816051s] Trained 128 records in 0.086348474 seconds. Throughput is 1482.3655 records/second. Loss is 2.1121633. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.10077519379845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 44928/60000][Iteration 2227][Wall Clock 215.685526492s] Trained 128 records in 0.085710441 seconds. Throughput is 1493.4003 records/second. Loss is 2.1289194. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0998140111593303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 2228][Wall Clock 215.769334899s] Trained 128 records in 0.083808407 seconds. Throughput is 1527.2931 records/second. Loss is 2.1438673. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.098853424233034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 45184/60000][Iteration 2229][Wall Clock 215.853777444s] Trained 128 records in 0.084442545 seconds. Throughput is 1515.8235 records/second. Loss is 2.1113126. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.097893432465923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 2230][Wall Clock 215.94059914s] Trained 128 records in 0.086821696 seconds. Throughput is 1474.2859 records/second. Loss is 2.120093. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.096934035305048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:51 INFO  DistriOptimizer$:408 - [Epoch 5 45440/60000][Iteration 2231][Wall Clock 216.03506011s] Trained 128 records in 0.09446097 seconds. Throughput is 1355.057 records/second. Loss is 2.1372666. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0959752321981426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 2232][Wall Clock 216.120270579s] Trained 128 records in 0.085210469 seconds. Throughput is 1502.1627 records/second. Loss is 2.1282296. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0950170225936243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 45696/60000][Iteration 2233][Wall Clock 216.20670162s] Trained 128 records in 0.086431041 seconds. Throughput is 1480.9495 records/second. Loss is 2.134759. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.094059405940594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 2234][Wall Clock 216.299462431s] Trained 128 records in 0.092760811 seconds. Throughput is 1379.8931 records/second. Loss is 2.138685. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.093102381688834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 45952/60000][Iteration 2235][Wall Clock 216.384880149s] Trained 128 records in 0.085417718 seconds. Throughput is 1498.5182 records/second. Loss is 2.1537993. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0921459492888067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 2236][Wall Clock 216.46893401s] Trained 128 records in 0.084053861 seconds. Throughput is 1522.8331 records/second. Loss is 2.1269605. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.091190108191654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46208/60000][Iteration 2237][Wall Clock 216.555269736s] Trained 128 records in 0.086335726 seconds. Throughput is 1482.5844 records/second. Loss is 2.138532. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0902348578491963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 2238][Wall Clock 216.639389594s] Trained 128 records in 0.084119858 seconds. Throughput is 1521.6383 records/second. Loss is 2.1253889. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0892801977139327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46464/60000][Iteration 2239][Wall Clock 216.725642007s] Trained 128 records in 0.086252413 seconds. Throughput is 1484.0165 records/second. Loss is 2.1320014. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0883261272390367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 2240][Wall Clock 216.81113641s] Trained 128 records in 0.085494403 seconds. Throughput is 1497.174 records/second. Loss is 2.1243305. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0873726458783575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46720/60000][Iteration 2241][Wall Clock 216.905816132s] Trained 128 records in 0.094679722 seconds. Throughput is 1351.9263 records/second. Loss is 2.150525. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0864197530864197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:52 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 2242][Wall Clock 216.993029808s] Trained 128 records in 0.087213676 seconds. Throughput is 1467.6598 records/second. Loss is 2.1502314. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.08546744831842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 46976/60000][Iteration 2243][Wall Clock 217.085504338s] Trained 128 records in 0.09247453 seconds. Throughput is 1384.1649 records/second. Loss is 2.1505527. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0845157310302283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 2244][Wall Clock 217.1784929s] Trained 128 records in 0.092988562 seconds. Throughput is 1376.5133 records/second. Loss is 2.145006. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0835646006783845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47232/60000][Iteration 2245][Wall Clock 217.264494044s] Trained 128 records in 0.086001144 seconds. Throughput is 1488.3523 records/second. Loss is 2.139008. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0826140567200987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 2246][Wall Clock 217.349913762s] Trained 128 records in 0.085419718 seconds. Throughput is 1498.4832 records/second. Loss is 2.1294343. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.081664098613251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47488/60000][Iteration 2247][Wall Clock 217.434223362s] Trained 128 records in 0.0843096 seconds. Throughput is 1518.2139 records/second. Loss is 2.1346726. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0807147258163895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 2248][Wall Clock 217.520119169s] Trained 128 records in 0.085895807 seconds. Throughput is 1490.1775 records/second. Loss is 2.118776. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.079765937788728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47744/60000][Iteration 2249][Wall Clock 217.614374159s] Trained 128 records in 0.09425499 seconds. Throughput is 1358.0182 records/second. Loss is 2.120368. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.078817733990148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 2250][Wall Clock 217.702489509s] Trained 128 records in 0.08811535 seconds. Throughput is 1452.6414 records/second. Loss is 2.1164072. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.077870113881194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 48000/60000][Iteration 2251][Wall Clock 217.788358513s] Trained 128 records in 0.085869004 seconds. Throughput is 1490.6426 records/second. Loss is 2.1358054. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.076923076923077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 2252][Wall Clock 217.876636639s] Trained 128 records in 0.088278126 seconds. Throughput is 1449.9628 records/second. Loss is 2.1261003. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0759766225776686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:53 INFO  DistriOptimizer$:408 - [Epoch 5 48256/60000][Iteration 2253][Wall Clock 217.96444078s] Trained 128 records in 0.087804141 seconds. Throughput is 1457.79 records/second. Loss is 2.1387134. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.075030750307503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 2254][Wall Clock 218.051949287s] Trained 128 records in 0.087508507 seconds. Throughput is 1462.715 records/second. Loss is 2.123733. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.074085459575776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 48512/60000][Iteration 2255][Wall Clock 218.139560917s] Trained 128 records in 0.08761163 seconds. Throughput is 1460.9933 records/second. Loss is 2.1424272. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.073140749846343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 2256][Wall Clock 218.226566304s] Trained 128 records in 0.087005387 seconds. Throughput is 1471.1733 records/second. Loss is 2.1410854. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0721966205837174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 48768/60000][Iteration 2257][Wall Clock 218.315653436s] Trained 128 records in 0.089087132 seconds. Throughput is 1436.7957 records/second. Loss is 2.1313019. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.071253071253071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 2258][Wall Clock 218.404265219s] Trained 128 records in 0.088611783 seconds. Throughput is 1444.5032 records/second. Loss is 2.1584446. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0703101013202335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 49024/60000][Iteration 2259][Wall Clock 218.493506202s] Trained 128 records in 0.089240983 seconds. Throughput is 1434.3186 records/second. Loss is 2.1404903. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0693677102516884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 2260][Wall Clock 218.581311168s] Trained 128 records in 0.087804966 seconds. Throughput is 1457.7764 records/second. Loss is 2.1189365. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.068425897514575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 49280/60000][Iteration 2261][Wall Clock 218.680315245s] Trained 128 records in 0.099004077 seconds. Throughput is 1292.8761 records/second. Loss is 2.1352422. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.067484662576687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 2262][Wall Clock 218.767703354s] Trained 128 records in 0.087388109 seconds. Throughput is 1464.7302 records/second. Loss is 2.1449068. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0665440049064706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 49536/60000][Iteration 2263][Wall Clock 218.855589866s] Trained 128 records in 0.087886512 seconds. Throughput is 1456.4237 records/second. Loss is 2.1424506. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0656039239730225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:54 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 2264][Wall Clock 218.941196778s] Trained 128 records in 0.085606912 seconds. Throughput is 1495.2064 records/second. Loss is 2.1155124. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.064664419246093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 49792/60000][Iteration 2265][Wall Clock 219.02894205s] Trained 128 records in 0.087745272 seconds. Throughput is 1458.7681 records/second. Loss is 2.126197. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0637254901960784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 2266][Wall Clock 219.129407186s] Trained 128 records in 0.100465136 seconds. Throughput is 1274.0739 records/second. Loss is 2.125003. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0627871362940275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50048/60000][Iteration 2267][Wall Clock 219.217255246s] Trained 128 records in 0.08784806 seconds. Throughput is 1457.0612 records/second. Loss is 2.1351678. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.061849357011635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 2268][Wall Clock 219.304342259s] Trained 128 records in 0.087087013 seconds. Throughput is 1469.7943 records/second. Loss is 2.1388974. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0609121518212427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50304/60000][Iteration 2269][Wall Clock 219.386271638s] Trained 128 records in 0.081929379 seconds. Throughput is 1562.3212 records/second. Loss is 2.1283717. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.059975520195838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 2270][Wall Clock 219.474470452s] Trained 128 records in 0.088198814 seconds. Throughput is 1451.2667 records/second. Loss is 2.1399376. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.059039461609055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50560/60000][Iteration 2271][Wall Clock 219.561133856s] Trained 128 records in 0.086663404 seconds. Throughput is 1476.9788 records/second. Loss is 2.1367285. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.058103975535168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 2272][Wall Clock 219.645326178s] Trained 128 records in 0.084192322 seconds. Throughput is 1520.3287 records/second. Loss is 2.1260777. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0571690614490985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50816/60000][Iteration 2273][Wall Clock 219.733832321s] Trained 128 records in 0.088506143 seconds. Throughput is 1446.2273 records/second. Loss is 2.1486354. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.056234718826406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 2274][Wall Clock 219.817795904s] Trained 128 records in 0.083963583 seconds. Throughput is 1524.4705 records/second. Loss is 2.1370654. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0553009471432935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 51072/60000][Iteration 2275][Wall Clock 219.912647867s] Trained 128 records in 0.094851963 seconds. Throughput is 1349.4713 records/second. Loss is 2.105827. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0543677458766036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:55 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 2276][Wall Clock 219.993760869s] Trained 128 records in 0.081113002 seconds. Throughput is 1578.0454 records/second. Loss is 2.1294258. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.053435114503817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 51328/60000][Iteration 2277][Wall Clock 220.077684716s] Trained 128 records in 0.083923847 seconds. Throughput is 1525.1923 records/second. Loss is 2.1148398. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0525030525030525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 2278][Wall Clock 220.164321115s] Trained 128 records in 0.086636399 seconds. Throughput is 1477.439 records/second. Loss is 2.1299946. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.051571559353067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 51584/60000][Iteration 2279][Wall Clock 220.249817774s] Trained 128 records in 0.085496659 seconds. Throughput is 1497.1345 records/second. Loss is 2.1384628. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.050640634533252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 2280][Wall Clock 220.336193966s] Trained 128 records in 0.086376192 seconds. Throughput is 1481.8899 records/second. Loss is 2.1177742. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.049710277523635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 51840/60000][Iteration 2281][Wall Clock 220.420111596s] Trained 128 records in 0.08391763 seconds. Throughput is 1525.3052 records/second. Loss is 2.115239. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.048780487804878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 2282][Wall Clock 220.505664014s] Trained 128 records in 0.085552418 seconds. Throughput is 1496.1588 records/second. Loss is 2.0938828. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0478512648582747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 52096/60000][Iteration 2283][Wall Clock 220.593245443s] Trained 128 records in 0.087581429 seconds. Throughput is 1461.4971 records/second. Loss is 2.1116714. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.046922608165753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 2284][Wall Clock 220.67812486s] Trained 128 records in 0.084879417 seconds. Throughput is 1508.0216 records/second. Loss is 2.1349716. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.045994517209869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 52352/60000][Iteration 2285][Wall Clock 220.763746037s] Trained 128 records in 0.085621177 seconds. Throughput is 1494.9573 records/second. Loss is 2.120122. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.045066991473812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 2286][Wall Clock 220.851067419s] Trained 128 records in 0.087321382 seconds. Throughput is 1465.8495 records/second. Loss is 2.1079745. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0441400304414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:56 INFO  DistriOptimizer$:408 - [Epoch 5 52608/60000][Iteration 2287][Wall Clock 220.938671751s] Trained 128 records in 0.087604332 seconds. Throughput is 1461.115 records/second. Loss is 2.1336226. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0432136335970786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 2288][Wall Clock 221.024081345s] Trained 128 records in 0.085409594 seconds. Throughput is 1498.6606 records/second. Loss is 2.1444464. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.04228780042592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 52864/60000][Iteration 2289][Wall Clock 221.109300136s] Trained 128 records in 0.085218791 seconds. Throughput is 1502.0161 records/second. Loss is 2.1596189. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0413625304136254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 2290][Wall Clock 221.199900628s] Trained 128 records in 0.090600492 seconds. Throughput is 1412.7959 records/second. Loss is 2.1389136. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.040437823046519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53120/60000][Iteration 2291][Wall Clock 221.29824862s] Trained 128 records in 0.098347992 seconds. Throughput is 1301.5009 records/second. Loss is 2.1358252. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0395136778115504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 2292][Wall Clock 221.385470399s] Trained 128 records in 0.087221779 seconds. Throughput is 1467.5234 records/second. Loss is 2.132374. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.038590094196293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53376/60000][Iteration 2293][Wall Clock 221.477146776s] Trained 128 records in 0.091676377 seconds. Throughput is 1396.2157 records/second. Loss is 2.1413417. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0376670716889426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 2294][Wall Clock 221.564201915s] Trained 128 records in 0.087055139 seconds. Throughput is 1470.3325 records/second. Loss is 2.1297345. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0367446097783173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53632/60000][Iteration 2295][Wall Clock 221.651776621s] Trained 128 records in 0.087574706 seconds. Throughput is 1461.6093 records/second. Loss is 2.144181. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0358227079538557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 2296][Wall Clock 221.736883659s] Trained 128 records in 0.085107038 seconds. Throughput is 1503.9884 records/second. Loss is 2.0997918. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0349013657056146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 53888/60000][Iteration 2297][Wall Clock 221.821246423s] Trained 128 records in 0.084362764 seconds. Throughput is 1517.257 records/second. Loss is 2.1323872. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0339805825242716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 2298][Wall Clock 221.905993795s] Trained 128 records in 0.084747372 seconds. Throughput is 1510.3713 records/second. Loss is 2.1217828. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0330603579011223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:57 INFO  DistriOptimizer$:408 - [Epoch 5 54144/60000][Iteration 2299][Wall Clock 221.993447732s] Trained 128 records in 0.087453937 seconds. Throughput is 1463.6276 records/second. Loss is 2.1308267. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0321406913280777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 2300][Wall Clock 222.079652769s] Trained 128 records in 0.086205037 seconds. Throughput is 1484.832 records/second. Loss is 2.1478145. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.031221582297666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 54400/60000][Iteration 2301][Wall Clock 222.176853377s] Trained 128 records in 0.097200608 seconds. Throughput is 1316.8641 records/second. Loss is 2.1387737. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0303030303030303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 2302][Wall Clock 222.260693365s] Trained 128 records in 0.083839988 seconds. Throughput is 1526.7178 records/second. Loss is 2.1292114. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.029385034837928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 54656/60000][Iteration 2303][Wall Clock 222.34922717s] Trained 128 records in 0.088533805 seconds. Throughput is 1445.7754 records/second. Loss is 2.1329832. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.028467595396729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 2304][Wall Clock 222.43538225s] Trained 128 records in 0.08615508 seconds. Throughput is 1485.693 records/second. Loss is 2.1399937. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.027550711474417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 54912/60000][Iteration 2305][Wall Clock 222.522377974s] Trained 128 records in 0.086995724 seconds. Throughput is 1471.3368 records/second. Loss is 2.1292284. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0266343825665856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 2306][Wall Clock 222.608290213s] Trained 128 records in 0.085912239 seconds. Throughput is 1489.8925 records/second. Loss is 2.1225796. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.02571860816944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 55168/60000][Iteration 2307][Wall Clock 222.695986978s] Trained 128 records in 0.087696765 seconds. Throughput is 1459.5748 records/second. Loss is 2.127443. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0248033877797946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 2308][Wall Clock 222.780719909s] Trained 128 records in 0.084732931 seconds. Throughput is 1510.6288 records/second. Loss is 2.1263008. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.023888720895071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 55424/60000][Iteration 2309][Wall Clock 222.871022685s] Trained 128 records in 0.090302776 seconds. Throughput is 1417.4537 records/second. Loss is 2.1181474. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0229746070133015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:58 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 2310][Wall Clock 222.957387627s] Trained 128 records in 0.086364942 seconds. Throughput is 1482.0829 records/second. Loss is 2.1296568. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.022061045633122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 55680/60000][Iteration 2311][Wall Clock 223.044938967s] Trained 128 records in 0.08755134 seconds. Throughput is 1461.9993 records/second. Loss is 2.1484826. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0211480362537764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 2312][Wall Clock 223.128672624s] Trained 128 records in 0.083733657 seconds. Throughput is 1528.6565 records/second. Loss is 2.1122563. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.020235578375113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 55936/60000][Iteration 2313][Wall Clock 223.212910719s] Trained 128 records in 0.084238095 seconds. Throughput is 1519.5026 records/second. Loss is 2.137114. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.019323671497585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 2314][Wall Clock 223.299872217s] Trained 128 records in 0.086961498 seconds. Throughput is 1471.9158 records/second. Loss is 2.1294827. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0184123151222455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56192/60000][Iteration 2315][Wall Clock 223.384575809s] Trained 128 records in 0.084703592 seconds. Throughput is 1511.152 records/second. Loss is 2.1179287. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0175015087507544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 2316][Wall Clock 223.470505087s] Trained 128 records in 0.085929278 seconds. Throughput is 1489.5972 records/second. Loss is 2.1273358. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0165912518853697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56448/60000][Iteration 2317][Wall Clock 223.56524834s] Trained 128 records in 0.094743253 seconds. Throughput is 1351.0197 records/second. Loss is 2.1585963. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.015681544028951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 2318][Wall Clock 223.650754868s] Trained 128 records in 0.085506528 seconds. Throughput is 1496.9617 records/second. Loss is 2.1466622. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0147723846849563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56704/60000][Iteration 2319][Wall Clock 223.738258262s] Trained 128 records in 0.087503394 seconds. Throughput is 1462.8004 records/second. Loss is 2.1193838. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.013863773357444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 2320][Wall Clock 223.834191986s] Trained 128 records in 0.095933724 seconds. Throughput is 1334.2545 records/second. Loss is 2.124532. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0129557095510696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:14:59 INFO  DistriOptimizer$:408 - [Epoch 5 56960/60000][Iteration 2321][Wall Clock 223.919226139s] Trained 128 records in 0.085034153 seconds. Throughput is 1505.2775 records/second. Loss is 2.1254408. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0120481927710846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 2322][Wall Clock 224.005850505s] Trained 128 records in 0.086624366 seconds. Throughput is 1477.6443 records/second. Loss is 2.1362343. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0111412225233364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57216/60000][Iteration 2323][Wall Clock 224.100812052s] Trained 128 records in 0.094961547 seconds. Throughput is 1347.9141 records/second. Loss is 2.1357143. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0102347983142685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 2324][Wall Clock 224.190171511s] Trained 128 records in 0.089359459 seconds. Throughput is 1432.4169 records/second. Loss is 2.1479118. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.009328919650918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57472/60000][Iteration 2325][Wall Clock 224.279396929s] Trained 128 records in 0.089225418 seconds. Throughput is 1434.5687 records/second. Loss is 2.1142452. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0084235860409147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 2326][Wall Clock 224.378148054s] Trained 128 records in 0.098751125 seconds. Throughput is 1296.1877 records/second. Loss is 2.135757. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.007518796992481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57728/60000][Iteration 2327][Wall Clock 224.465262462s] Trained 128 records in 0.087114408 seconds. Throughput is 1469.3322 records/second. Loss is 2.1110506. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.006614552014432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 2328][Wall Clock 224.550463023s] Trained 128 records in 0.085200561 seconds. Throughput is 1502.3375 records/second. Loss is 2.1311533. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0057108506161706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 57984/60000][Iteration 2329][Wall Clock 224.636754297s] Trained 128 records in 0.086291274 seconds. Throughput is 1483.3481 records/second. Loss is 2.1296856. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0048076923076925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 2330][Wall Clock 224.725534434s] Trained 128 records in 0.088780137 seconds. Throughput is 1441.7639 records/second. Loss is 2.1231427. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.0039050765995795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 58240/60000][Iteration 2331][Wall Clock 224.813293394s] Trained 128 records in 0.08775896 seconds. Throughput is 1458.5405 records/second. Loss is 2.1223905. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.003003003003003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 2332][Wall Clock 224.900388532s] Trained 128 records in 0.087095138 seconds. Throughput is 1469.6572 records/second. Loss is 2.1277378. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.002101471029721E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:00 INFO  DistriOptimizer$:408 - [Epoch 5 58496/60000][Iteration 2333][Wall Clock 224.986469339s] Trained 128 records in 0.086080807 seconds. Throughput is 1486.975 records/second. Loss is 2.10776. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.001200480192077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 2334][Wall Clock 225.073905644s] Trained 128 records in 0.087436305 seconds. Throughput is 1463.9229 records/second. Loss is 2.115864. Sequentialdaab25a8's hyper parameters: Current learning rate is 3.000300030003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 58752/60000][Iteration 2335][Wall Clock 225.160523067s] Trained 128 records in 0.086617423 seconds. Throughput is 1477.7627 records/second. Loss is 2.1281753. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9994001199760045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 2336][Wall Clock 225.246976436s] Trained 128 records in 0.086453369 seconds. Throughput is 1480.5669 records/second. Loss is 2.1396518. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.998500749625188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59008/60000][Iteration 2337][Wall Clock 225.332199649s] Trained 128 records in 0.085223213 seconds. Throughput is 1501.9382 records/second. Loss is 2.1459584. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.997601918465228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 2338][Wall Clock 225.418881404s] Trained 128 records in 0.086681755 seconds. Throughput is 1476.666 records/second. Loss is 2.1343489. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.996703626011387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59264/60000][Iteration 2339][Wall Clock 225.50670348s] Trained 128 records in 0.087822076 seconds. Throughput is 1457.4922 records/second. Loss is 2.114797. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.995805871779509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 2340][Wall Clock 225.59227171s] Trained 128 records in 0.08556823 seconds. Throughput is 1495.8823 records/second. Loss is 2.1255915. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.994908655286014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59520/60000][Iteration 2341][Wall Clock 225.678960884s] Trained 128 records in 0.086689174 seconds. Throughput is 1476.5397 records/second. Loss is 2.1372685. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.994011976047904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 2342][Wall Clock 225.774478484s] Trained 128 records in 0.0955176 seconds. Throughput is 1340.0671 records/second. Loss is 2.1333587. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9931158335827593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59776/60000][Iteration 2343][Wall Clock 225.857977898s] Trained 128 records in 0.083499414 seconds. Throughput is 1532.9448 records/second. Loss is 2.1179392. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.992220227408737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:01 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 2344][Wall Clock 225.939269619s] Trained 128 records in 0.081291721 seconds. Throughput is 1574.576 records/second. Loss is 2.1032097. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.991325157044571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:02 INFO  DistriOptimizer$:408 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 226.026113041s] Trained 128 records in 0.086843422 seconds. Throughput is 1473.917 records/second. Loss is 2.1293173. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.99043062200957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:02 INFO  DistriOptimizer$:452 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 226.026113041s] Epoch finished. Wall clock time is 227161.080791 ms
2019-10-14 23:15:02 INFO  DistriOptimizer$:111 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 226.026113041s] Validate model...
2019-10-14 23:15:02 INFO  DistriOptimizer$:178 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 226.026113041s] validate model throughput is 10694.727 records/second
2019-10-14 23:15:02 INFO  DistriOptimizer$:181 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 226.026113041s] Top1Accuracy is Accuracy(correct: 4949, count: 10000, accuracy: 0.4949)
2019-10-14 23:15:03 INFO  DistriOptimizer$:221 - [Wall Clock 227.161080791s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:15:03 INFO  DistriOptimizer$:226 - [Wall Clock 227.161080791s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 128/60000][Iteration 2346][Wall Clock 227.263528608s] Trained 128 records in 0.102447817 seconds. Throughput is 1249.4166 records/second. Loss is 2.1279986. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.989536621823617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 256/60000][Iteration 2347][Wall Clock 227.353283622s] Trained 128 records in 0.089755014 seconds. Throughput is 1426.1041 records/second. Loss is 2.1163068. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9886431560071725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 384/60000][Iteration 2348][Wall Clock 227.443197194s] Trained 128 records in 0.089913572 seconds. Throughput is 1423.5894 records/second. Loss is 2.1118562. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9877502240812666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 512/60000][Iteration 2349][Wall Clock 227.532733625s] Trained 128 records in 0.089536431 seconds. Throughput is 1429.5857 records/second. Loss is 2.136088. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9868578255675033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 640/60000][Iteration 2350][Wall Clock 227.635041535s] Trained 128 records in 0.10230791 seconds. Throughput is 1251.1251 records/second. Loss is 2.1242013. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.985965959988056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 768/60000][Iteration 2351][Wall Clock 227.725810941s] Trained 128 records in 0.090769406 seconds. Throughput is 1410.1669 records/second. Loss is 2.1269083. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9850746268656717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 896/60000][Iteration 2352][Wall Clock 227.812657476s] Trained 128 records in 0.086846535 seconds. Throughput is 1473.8641 records/second. Loss is 2.1298923. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.984183825723665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 1024/60000][Iteration 2353][Wall Clock 227.927676517s] Trained 128 records in 0.115019041 seconds. Throughput is 1112.8593 records/second. Loss is 2.1306326. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.983293556085919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:03 INFO  DistriOptimizer$:408 - [Epoch 6 1152/60000][Iteration 2354][Wall Clock 228.015237687s] Trained 128 records in 0.08756117 seconds. Throughput is 1461.8352 records/second. Loss is 2.1002603. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.982403817476886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 1280/60000][Iteration 2355][Wall Clock 228.10379071s] Trained 128 records in 0.088553023 seconds. Throughput is 1445.4617 records/second. Loss is 2.096776. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.981514609421586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 1408/60000][Iteration 2356][Wall Clock 228.189463307s] Trained 128 records in 0.085672597 seconds. Throughput is 1494.06 records/second. Loss is 2.0959961. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9806259314456036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 1536/60000][Iteration 2357][Wall Clock 228.276420121s] Trained 128 records in 0.086956814 seconds. Throughput is 1471.995 records/second. Loss is 2.1021092. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.97973778307509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 1664/60000][Iteration 2358][Wall Clock 228.364227313s] Trained 128 records in 0.087807192 seconds. Throughput is 1457.7394 records/second. Loss is 2.11639. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.978850163836759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 1792/60000][Iteration 2359][Wall Clock 228.452633833s] Trained 128 records in 0.08840652 seconds. Throughput is 1447.857 records/second. Loss is 2.110245. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9779630732578913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 1920/60000][Iteration 2360][Wall Clock 228.543227424s] Trained 128 records in 0.090593591 seconds. Throughput is 1412.9034 records/second. Loss is 2.104003. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9770765108663293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 2048/60000][Iteration 2361][Wall Clock 228.631452992s] Trained 128 records in 0.088225568 seconds. Throughput is 1450.8267 records/second. Loss is 2.093757. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9761904761904765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 2176/60000][Iteration 2362][Wall Clock 228.719867013s] Trained 128 records in 0.088414021 seconds. Throughput is 1447.7341 records/second. Loss is 2.130503. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.975304968759298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 2304/60000][Iteration 2363][Wall Clock 228.812434792s] Trained 128 records in 0.092567779 seconds. Throughput is 1382.7705 records/second. Loss is 2.1248713. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.97441998810232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 2432/60000][Iteration 2364][Wall Clock 228.901148912s] Trained 128 records in 0.08871412 seconds. Throughput is 1442.8368 records/second. Loss is 2.1194124. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9735355337496286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 2560/60000][Iteration 2365][Wall Clock 228.988620066s] Trained 128 records in 0.087471154 seconds. Throughput is 1463.3395 records/second. Loss is 2.1105862. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.972651605231867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:04 INFO  DistriOptimizer$:408 - [Epoch 6 2688/60000][Iteration 2366][Wall Clock 229.071450152s] Trained 128 records in 0.082830086 seconds. Throughput is 1545.3322 records/second. Loss is 2.1279805. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9717682020802375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 2816/60000][Iteration 2367][Wall Clock 229.152220879s] Trained 128 records in 0.080770727 seconds. Throughput is 1584.7327 records/second. Loss is 2.09918. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9708853238265005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 2944/60000][Iteration 2368][Wall Clock 229.234080038s] Trained 128 records in 0.081859159 seconds. Throughput is 1563.6614 records/second. Loss is 2.1309133. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9700029700029703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3072/60000][Iteration 2369][Wall Clock 229.320374729s] Trained 128 records in 0.086294691 seconds. Throughput is 1483.2894 records/second. Loss is 2.1243114. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.969121140142518E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3200/60000][Iteration 2370][Wall Clock 229.404008771s] Trained 128 records in 0.083634042 seconds. Throughput is 1530.4773 records/second. Loss is 2.1107147. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9682398337785694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3328/60000][Iteration 2371][Wall Clock 229.489989151s] Trained 128 records in 0.08598038 seconds. Throughput is 1488.7118 records/second. Loss is 2.146149. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.967359050445104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3456/60000][Iteration 2372][Wall Clock 229.574023922s] Trained 128 records in 0.084034771 seconds. Throughput is 1523.1791 records/second. Loss is 2.1503165. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.966478789676654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3584/60000][Iteration 2373][Wall Clock 229.65828053s] Trained 128 records in 0.084256608 seconds. Throughput is 1519.1687 records/second. Loss is 2.145357. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.965599051008304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3712/60000][Iteration 2374][Wall Clock 229.742023131s] Trained 128 records in 0.083742601 seconds. Throughput is 1528.4932 records/second. Loss is 2.129219. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.964719833975689E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3840/60000][Iteration 2375][Wall Clock 229.827685196s] Trained 128 records in 0.085662065 seconds. Throughput is 1494.2437 records/second. Loss is 2.1237895. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.963841138114997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 3968/60000][Iteration 2376][Wall Clock 229.916869311s] Trained 128 records in 0.089184115 seconds. Throughput is 1435.2332 records/second. Loss is 2.1346087. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.962962962962963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 4096/60000][Iteration 2377][Wall Clock 229.995256155s] Trained 128 records in 0.078386844 seconds. Throughput is 1632.9271 records/second. Loss is 2.1214888. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.962085308056872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:05 INFO  DistriOptimizer$:408 - [Epoch 6 4224/60000][Iteration 2378][Wall Clock 230.075573331s] Trained 128 records in 0.080317176 seconds. Throughput is 1593.6815 records/second. Loss is 2.129721. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.961208172934557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 4352/60000][Iteration 2379][Wall Clock 230.174777771s] Trained 128 records in 0.09920444 seconds. Throughput is 1290.2648 records/second. Loss is 2.1449745. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.960331557134399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 4480/60000][Iteration 2380][Wall Clock 230.262644036s] Trained 128 records in 0.087866265 seconds. Throughput is 1456.7594 records/second. Loss is 2.141459. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.959455460195324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 4608/60000][Iteration 2381][Wall Clock 230.350257916s] Trained 128 records in 0.08761388 seconds. Throughput is 1460.9557 records/second. Loss is 2.1365426. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.958579881656805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 4736/60000][Iteration 2382][Wall Clock 230.43852233s] Trained 128 records in 0.088264414 seconds. Throughput is 1450.1881 records/second. Loss is 2.1072762. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.957704821058858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 4864/60000][Iteration 2383][Wall Clock 230.526491072s] Trained 128 records in 0.087968742 seconds. Throughput is 1455.0623 records/second. Loss is 2.1447387. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.956830277942046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 4992/60000][Iteration 2384][Wall Clock 230.617005015s] Trained 128 records in 0.090513943 seconds. Throughput is 1414.1467 records/second. Loss is 2.1395996. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.955956251847473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 5120/60000][Iteration 2385][Wall Clock 230.709676155s] Trained 128 records in 0.09267114 seconds. Throughput is 1381.2283 records/second. Loss is 2.1010585. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.955082742316785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 5248/60000][Iteration 2386][Wall Clock 230.797794922s] Trained 128 records in 0.088118767 seconds. Throughput is 1452.585 records/second. Loss is 2.1067517. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.954209748892171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 5376/60000][Iteration 2387][Wall Clock 230.887070027s] Trained 128 records in 0.089275105 seconds. Throughput is 1433.7704 records/second. Loss is 2.157119. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9533372711163615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 5504/60000][Iteration 2388][Wall Clock 230.974839538s] Trained 128 records in 0.087769511 seconds. Throughput is 1458.3652 records/second. Loss is 2.1070297. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.952465308532625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:06 INFO  DistriOptimizer$:408 - [Epoch 6 5632/60000][Iteration 2389][Wall Clock 231.064820855s] Trained 128 records in 0.089981317 seconds. Throughput is 1422.5175 records/second. Loss is 2.143119. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.95159386068477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 5760/60000][Iteration 2390][Wall Clock 231.163426612s] Trained 128 records in 0.098605757 seconds. Throughput is 1298.0986 records/second. Loss is 2.116237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9507229271171436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 5888/60000][Iteration 2391][Wall Clock 231.24017988s] Trained 128 records in 0.076753268 seconds. Throughput is 1667.6815 records/second. Loss is 2.1007142. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.949852507374631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6016/60000][Iteration 2392][Wall Clock 231.319894196s] Trained 128 records in 0.079714316 seconds. Throughput is 1605.7343 records/second. Loss is 2.1621518. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.948982601002654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6144/60000][Iteration 2393][Wall Clock 231.406610487s] Trained 128 records in 0.086716291 seconds. Throughput is 1476.0779 records/second. Loss is 2.1099696. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9481132075471697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6272/60000][Iteration 2394][Wall Clock 231.492350885s] Trained 128 records in 0.085740398 seconds. Throughput is 1492.8785 records/second. Loss is 2.1335728. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.947244326554671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6400/60000][Iteration 2395][Wall Clock 231.577898593s] Trained 128 records in 0.085547708 seconds. Throughput is 1496.2411 records/second. Loss is 2.1224368. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.946375957572186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6528/60000][Iteration 2396][Wall Clock 231.662521167s] Trained 128 records in 0.084622574 seconds. Throughput is 1512.5988 records/second. Loss is 2.095302. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.945508100147275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6656/60000][Iteration 2397][Wall Clock 231.747090506s] Trained 128 records in 0.084569339 seconds. Throughput is 1513.5509 records/second. Loss is 2.136048. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9446407538280333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6784/60000][Iteration 2398][Wall Clock 231.831631994s] Trained 128 records in 0.084541488 seconds. Throughput is 1514.0496 records/second. Loss is 2.1238704. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.943773918163085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 6912/60000][Iteration 2399][Wall Clock 231.916301951s] Trained 128 records in 0.084669957 seconds. Throughput is 1511.7523 records/second. Loss is 2.1412847. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.942907592701589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:07 INFO  DistriOptimizer$:408 - [Epoch 6 7040/60000][Iteration 2400][Wall Clock 232.000633074s] Trained 128 records in 0.084331123 seconds. Throughput is 1517.8263 records/second. Loss is 2.1571286. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9420417769932336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7168/60000][Iteration 2401][Wall Clock 232.087674086s] Trained 128 records in 0.087041012 seconds. Throughput is 1470.5712 records/second. Loss is 2.1359398. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9411764705882356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7296/60000][Iteration 2402][Wall Clock 232.179567913s] Trained 128 records in 0.091893827 seconds. Throughput is 1392.9119 records/second. Loss is 2.1393888. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9403116730373417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7424/60000][Iteration 2403][Wall Clock 232.257378712s] Trained 128 records in 0.077810799 seconds. Throughput is 1645.0159 records/second. Loss is 2.1094227. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9394473838918284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7552/60000][Iteration 2404][Wall Clock 232.343251933s] Trained 128 records in 0.085873221 seconds. Throughput is 1490.5695 records/second. Loss is 2.1197674. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.938583602703497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7680/60000][Iteration 2405][Wall Clock 232.449789136s] Trained 128 records in 0.106537203 seconds. Throughput is 1201.4583 records/second. Loss is 2.1154. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.937720329024677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7808/60000][Iteration 2406][Wall Clock 232.55054102s] Trained 128 records in 0.100751884 seconds. Throughput is 1270.4478 records/second. Loss is 2.1160116. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.936857562408223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 7936/60000][Iteration 2407][Wall Clock 232.640821778s] Trained 128 records in 0.090280758 seconds. Throughput is 1417.7993 records/second. Loss is 2.103228. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.935995302407516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 8064/60000][Iteration 2408][Wall Clock 232.729435487s] Trained 128 records in 0.088613709 seconds. Throughput is 1444.4717 records/second. Loss is 2.110929. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.93513354857646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 8192/60000][Iteration 2409][Wall Clock 232.816702661s] Trained 128 records in 0.087267174 seconds. Throughput is 1466.76 records/second. Loss is 2.1345613. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9342723004694836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 8320/60000][Iteration 2410][Wall Clock 232.902998295s] Trained 128 records in 0.086295634 seconds. Throughput is 1483.2732 records/second. Loss is 2.135641. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.933411557641537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:08 INFO  DistriOptimizer$:408 - [Epoch 6 8448/60000][Iteration 2411][Wall Clock 232.989160947s] Trained 128 records in 0.086162652 seconds. Throughput is 1485.5625 records/second. Loss is 2.1118243. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.932551319648094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 8576/60000][Iteration 2412][Wall Clock 233.075835519s] Trained 128 records in 0.086674572 seconds. Throughput is 1476.7883 records/second. Loss is 2.1363902. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.931691586045148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 8704/60000][Iteration 2413][Wall Clock 233.162195252s] Trained 128 records in 0.086359733 seconds. Throughput is 1482.1722 records/second. Loss is 2.143094. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.930832356389215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 8832/60000][Iteration 2414][Wall Clock 233.250617498s] Trained 128 records in 0.088422246 seconds. Throughput is 1447.5995 records/second. Loss is 2.1048474. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.929973630237328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 8960/60000][Iteration 2415][Wall Clock 233.337850302s] Trained 128 records in 0.087232804 seconds. Throughput is 1467.3379 records/second. Loss is 2.1343012. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9291154071470416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9088/60000][Iteration 2416][Wall Clock 233.430243254s] Trained 128 records in 0.092392952 seconds. Throughput is 1385.3871 records/second. Loss is 2.1291995. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9282576866764275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9216/60000][Iteration 2417][Wall Clock 233.515575401s] Trained 128 records in 0.085332147 seconds. Throughput is 1500.0209 records/second. Loss is 2.1137316. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.927400468384075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9344/60000][Iteration 2418][Wall Clock 233.602021377s] Trained 128 records in 0.086445976 seconds. Throughput is 1480.6936 records/second. Loss is 2.101542. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.92654375182909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9472/60000][Iteration 2419][Wall Clock 233.691143897s] Trained 128 records in 0.08912252 seconds. Throughput is 1436.2251 records/second. Loss is 2.1122124. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.925687536571094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9600/60000][Iteration 2420][Wall Clock 233.77972786s] Trained 128 records in 0.088583963 seconds. Throughput is 1444.9568 records/second. Loss is 2.1167903. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.924831822170225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9728/60000][Iteration 2421][Wall Clock 233.863753164s] Trained 128 records in 0.084025304 seconds. Throughput is 1523.3507 records/second. Loss is 2.1352832. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9239766081871346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9856/60000][Iteration 2422][Wall Clock 233.949838068s] Trained 128 records in 0.086084904 seconds. Throughput is 1486.9042 records/second. Loss is 2.123942. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9231218941829873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:09 INFO  DistriOptimizer$:408 - [Epoch 6 9984/60000][Iteration 2423][Wall Clock 234.035777055s] Trained 128 records in 0.085938987 seconds. Throughput is 1489.4287 records/second. Loss is 2.127913. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.922267679719462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10112/60000][Iteration 2424][Wall Clock 234.123161159s] Trained 128 records in 0.087384104 seconds. Throughput is 1464.7972 records/second. Loss is 2.1325443. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9214139643587495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10240/60000][Iteration 2425][Wall Clock 234.211017477s] Trained 128 records in 0.087856318 seconds. Throughput is 1456.9243 records/second. Loss is 2.1256783. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9205607476635517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10368/60000][Iteration 2426][Wall Clock 234.297747405s] Trained 128 records in 0.086729928 seconds. Throughput is 1475.8458 records/second. Loss is 2.1061993. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.91970802919708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10496/60000][Iteration 2427][Wall Clock 234.384235859s] Trained 128 records in 0.086488454 seconds. Throughput is 1479.9663 records/second. Loss is 2.1422186. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.918855808523059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10624/60000][Iteration 2428][Wall Clock 234.482780945s] Trained 128 records in 0.098545086 seconds. Throughput is 1298.8978 records/second. Loss is 2.1257246. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.918004085205719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10752/60000][Iteration 2429][Wall Clock 234.563480587s] Trained 128 records in 0.080699642 seconds. Throughput is 1586.1284 records/second. Loss is 2.1146314. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.917152858809802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 10880/60000][Iteration 2430][Wall Clock 234.649905882s] Trained 128 records in 0.086425295 seconds. Throughput is 1481.0479 records/second. Loss is 2.125631. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.916302128900554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 11008/60000][Iteration 2431][Wall Clock 234.738088853s] Trained 128 records in 0.088182971 seconds. Throughput is 1451.5275 records/second. Loss is 2.127489. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.915451895043732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 11136/60000][Iteration 2432][Wall Clock 234.824809898s] Trained 128 records in 0.086721045 seconds. Throughput is 1475.997 records/second. Loss is 2.1080296. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.914602156805596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 11264/60000][Iteration 2433][Wall Clock 234.911694906s] Trained 128 records in 0.086885008 seconds. Throughput is 1473.2117 records/second. Loss is 2.1165762. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.913752913752914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:10 INFO  DistriOptimizer$:408 - [Epoch 6 11392/60000][Iteration 2434][Wall Clock 234.997862055s] Trained 128 records in 0.086167149 seconds. Throughput is 1485.4849 records/second. Loss is 2.1353045. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.912904165452957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 11520/60000][Iteration 2435][Wall Clock 235.082046501s] Trained 128 records in 0.084184446 seconds. Throughput is 1520.471 records/second. Loss is 2.1457825. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9120559114735004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 11648/60000][Iteration 2436][Wall Clock 235.167188469s] Trained 128 records in 0.085141968 seconds. Throughput is 1503.3713 records/second. Loss is 2.1336956. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.911208151382824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 11776/60000][Iteration 2437][Wall Clock 235.253614372s] Trained 128 records in 0.086425903 seconds. Throughput is 1481.0375 records/second. Loss is 2.1444194. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.910360884749709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 11904/60000][Iteration 2438][Wall Clock 235.341012519s] Trained 128 records in 0.087398147 seconds. Throughput is 1464.5619 records/second. Loss is 2.120941. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.909514111143439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12032/60000][Iteration 2439][Wall Clock 235.433611187s] Trained 128 records in 0.092598668 seconds. Throughput is 1382.3093 records/second. Loss is 2.1227431. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9086678301337986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12160/60000][Iteration 2440][Wall Clock 235.527668754s] Trained 128 records in 0.094057567 seconds. Throughput is 1360.8687 records/second. Loss is 2.1444216. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.907822041291073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12288/60000][Iteration 2441][Wall Clock 235.612930765s] Trained 128 records in 0.085262011 seconds. Throughput is 1501.2548 records/second. Loss is 2.121127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9069767441860465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12416/60000][Iteration 2442][Wall Clock 235.697639689s] Trained 128 records in 0.084708924 seconds. Throughput is 1511.0569 records/second. Loss is 2.1296566. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.906131938390003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12544/60000][Iteration 2443][Wall Clock 235.781914029s] Trained 128 records in 0.08427434 seconds. Throughput is 1518.8491 records/second. Loss is 2.114982. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.905287623474724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12672/60000][Iteration 2444][Wall Clock 235.865403714s] Trained 128 records in 0.083489685 seconds. Throughput is 1533.1235 records/second. Loss is 2.1339633. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.904443799012489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12800/60000][Iteration 2445][Wall Clock 235.948817714s] Trained 128 records in 0.083414 seconds. Throughput is 1534.5145 records/second. Loss is 2.1178384. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.9036004645760743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:11 INFO  DistriOptimizer$:408 - [Epoch 6 12928/60000][Iteration 2446][Wall Clock 236.034258136s] Trained 128 records in 0.085440422 seconds. Throughput is 1498.12 records/second. Loss is 2.1060286. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.902757619738752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13056/60000][Iteration 2447][Wall Clock 236.119787061s] Trained 128 records in 0.085528925 seconds. Throughput is 1496.5697 records/second. Loss is 2.126601. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.901915264074289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13184/60000][Iteration 2448][Wall Clock 236.205757353s] Trained 128 records in 0.085970292 seconds. Throughput is 1488.8865 records/second. Loss is 2.0824738. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.901073397156948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13312/60000][Iteration 2449][Wall Clock 236.293543246s] Trained 128 records in 0.087785893 seconds. Throughput is 1458.093 records/second. Loss is 2.1349998. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.900232018561485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13440/60000][Iteration 2450][Wall Clock 236.380987278s] Trained 128 records in 0.087444032 seconds. Throughput is 1463.7935 records/second. Loss is 2.0968494. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.899391127863149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13568/60000][Iteration 2451][Wall Clock 236.486898392s] Trained 128 records in 0.105911114 seconds. Throughput is 1208.5607 records/second. Loss is 2.1121573. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.898550724637681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13696/60000][Iteration 2452][Wall Clock 236.575843802s] Trained 128 records in 0.08894541 seconds. Throughput is 1439.085 records/second. Loss is 2.1418667. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.897710808461316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13824/60000][Iteration 2453][Wall Clock 236.664921031s] Trained 128 records in 0.089077229 seconds. Throughput is 1436.9553 records/second. Loss is 2.1343997. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8968713789107763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 13952/60000][Iteration 2454][Wall Clock 236.764550641s] Trained 128 records in 0.09962961 seconds. Throughput is 1284.7587 records/second. Loss is 2.126886. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8960324355632787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 14080/60000][Iteration 2455][Wall Clock 236.843233037s] Trained 128 records in 0.078682396 seconds. Throughput is 1626.7935 records/second. Loss is 2.1097922. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8951939779965256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 14208/60000][Iteration 2456][Wall Clock 236.922513516s] Trained 128 records in 0.079280479 seconds. Throughput is 1614.521 records/second. Loss is 2.1124165. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.894356005788712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:12 INFO  DistriOptimizer$:408 - [Epoch 6 14336/60000][Iteration 2457][Wall Clock 237.007224924s] Trained 128 records in 0.084711408 seconds. Throughput is 1511.0125 records/second. Loss is 2.117173. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8935185185185184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 14464/60000][Iteration 2458][Wall Clock 237.091258348s] Trained 128 records in 0.084033424 seconds. Throughput is 1523.2035 records/second. Loss is 2.0998316. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8926815157651146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 14592/60000][Iteration 2459][Wall Clock 237.177791196s] Trained 128 records in 0.086532848 seconds. Throughput is 1479.2072 records/second. Loss is 2.1125846. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.891844997108155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 14720/60000][Iteration 2460][Wall Clock 237.265737602s] Trained 128 records in 0.087946406 seconds. Throughput is 1455.4318 records/second. Loss is 2.1059537. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.891008962127783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 14848/60000][Iteration 2461][Wall Clock 237.354154324s] Trained 128 records in 0.088416722 seconds. Throughput is 1447.69 records/second. Loss is 2.118202. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8901734104046245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 14976/60000][Iteration 2462][Wall Clock 237.443344265s] Trained 128 records in 0.089189941 seconds. Throughput is 1435.1394 records/second. Loss is 2.1142452. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.889338341519792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 15104/60000][Iteration 2463][Wall Clock 237.528376559s] Trained 128 records in 0.085032294 seconds. Throughput is 1505.3104 records/second. Loss is 2.086383. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8885037550548814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 15232/60000][Iteration 2464][Wall Clock 237.613938003s] Trained 128 records in 0.085561444 seconds. Throughput is 1496.0009 records/second. Loss is 2.1289713. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8876696505919725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 15360/60000][Iteration 2465][Wall Clock 237.711341402s] Trained 128 records in 0.097403399 seconds. Throughput is 1314.1226 records/second. Loss is 2.1105895. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.886836027713626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 15488/60000][Iteration 2466][Wall Clock 237.800957671s] Trained 128 records in 0.089616269 seconds. Throughput is 1428.3121 records/second. Loss is 2.1036355. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.886002886002886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 15616/60000][Iteration 2467][Wall Clock 237.885502434s] Trained 128 records in 0.084544763 seconds. Throughput is 1513.9908 records/second. Loss is 2.1059585. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8851702250432774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:13 INFO  DistriOptimizer$:408 - [Epoch 6 15744/60000][Iteration 2468][Wall Clock 237.972138917s] Trained 128 records in 0.086636483 seconds. Throughput is 1477.4376 records/second. Loss is 2.1091404. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8843380444188056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 15872/60000][Iteration 2469][Wall Clock 238.056672659s] Trained 128 records in 0.084533742 seconds. Throughput is 1514.1882 records/second. Loss is 2.1251097. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.883506343713956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16000/60000][Iteration 2470][Wall Clock 238.140203869s] Trained 128 records in 0.08353121 seconds. Throughput is 1532.3615 records/second. Loss is 2.1072252. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.882675122513693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16128/60000][Iteration 2471][Wall Clock 238.225401287s] Trained 128 records in 0.085197418 seconds. Throughput is 1502.393 records/second. Loss is 2.1232805. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8818443804034583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16256/60000][Iteration 2472][Wall Clock 238.311964681s] Trained 128 records in 0.086563394 seconds. Throughput is 1478.685 records/second. Loss is 2.1323452. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.881014116969173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16384/60000][Iteration 2473][Wall Clock 238.398752655s] Trained 128 records in 0.086787974 seconds. Throughput is 1474.8586 records/second. Loss is 2.107966. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.880184331797235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16512/60000][Iteration 2474][Wall Clock 238.526585684s] Trained 128 records in 0.127833029 seconds. Throughput is 1001.3062 records/second. Loss is 2.1410086. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8793550244745177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16640/60000][Iteration 2475][Wall Clock 238.613104836s] Trained 128 records in 0.086519152 seconds. Throughput is 1479.4413 records/second. Loss is 2.1070225. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8785261945883704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16768/60000][Iteration 2476][Wall Clock 238.699013228s] Trained 128 records in 0.085908392 seconds. Throughput is 1489.9592 records/second. Loss is 2.108347. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8776978417266187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 16896/60000][Iteration 2477][Wall Clock 238.78363626s] Trained 128 records in 0.084623032 seconds. Throughput is 1512.5906 records/second. Loss is 2.1117964. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8768699654775604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 17024/60000][Iteration 2478][Wall Clock 238.870267682s] Trained 128 records in 0.086631422 seconds. Throughput is 1477.5239 records/second. Loss is 2.1192646. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8760425654299687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:14 INFO  DistriOptimizer$:408 - [Epoch 6 17152/60000][Iteration 2479][Wall Clock 238.970899035s] Trained 128 records in 0.100631353 seconds. Throughput is 1271.9694 records/second. Loss is 2.1284091. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.875215641173088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 17280/60000][Iteration 2480][Wall Clock 239.054623687s] Trained 128 records in 0.083724652 seconds. Throughput is 1528.8209 records/second. Loss is 2.1209674. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.874389192296637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 17408/60000][Iteration 2481][Wall Clock 239.133810361s] Trained 128 records in 0.079186674 seconds. Throughput is 1616.4337 records/second. Loss is 2.1053236. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8735632183908046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 17536/60000][Iteration 2482][Wall Clock 239.224575856s] Trained 128 records in 0.090765495 seconds. Throughput is 1410.2274 records/second. Loss is 2.102076. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.872737719046251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 17664/60000][Iteration 2483][Wall Clock 239.315888015s] Trained 128 records in 0.091312159 seconds. Throughput is 1401.7848 records/second. Loss is 2.1188242. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.871912693854107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 17792/60000][Iteration 2484][Wall Clock 239.403566985s] Trained 128 records in 0.08767897 seconds. Throughput is 1459.8712 records/second. Loss is 2.0974607. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.871088142405972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 17920/60000][Iteration 2485][Wall Clock 239.490628186s] Trained 128 records in 0.087061201 seconds. Throughput is 1470.2301 records/second. Loss is 2.1490054. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.870264064293915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 18048/60000][Iteration 2486][Wall Clock 239.57704651s] Trained 128 records in 0.086418324 seconds. Throughput is 1481.1674 records/second. Loss is 2.095104. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8694404591104734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 18176/60000][Iteration 2487][Wall Clock 239.664696379s] Trained 128 records in 0.087649869 seconds. Throughput is 1460.356 records/second. Loss is 2.1082776. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8686173264486515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 18304/60000][Iteration 2488][Wall Clock 239.749948017s] Trained 128 records in 0.085251638 seconds. Throughput is 1501.4375 records/second. Loss is 2.1116722. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8677946659019213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 18432/60000][Iteration 2489][Wall Clock 239.83416442s] Trained 128 records in 0.084216403 seconds. Throughput is 1519.8939 records/second. Loss is 2.1034122. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8669724770642203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 18560/60000][Iteration 2490][Wall Clock 239.934884279s] Trained 128 records in 0.100719859 seconds. Throughput is 1270.8517 records/second. Loss is 2.102058. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8661507595299513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:15 INFO  DistriOptimizer$:408 - [Epoch 6 18688/60000][Iteration 2491][Wall Clock 240.017943492s] Trained 128 records in 0.083059213 seconds. Throughput is 1541.0692 records/second. Loss is 2.143228. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8653295128939826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 18816/60000][Iteration 2492][Wall Clock 240.10411908s] Trained 128 records in 0.086175588 seconds. Throughput is 1485.3394 records/second. Loss is 2.0917628. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.864508736751647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 18944/60000][Iteration 2493][Wall Clock 240.194811601s] Trained 128 records in 0.090692521 seconds. Throughput is 1411.3623 records/second. Loss is 2.132991. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.86368843069874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19072/60000][Iteration 2494][Wall Clock 240.282519566s] Trained 128 records in 0.087707965 seconds. Throughput is 1459.3885 records/second. Loss is 2.076444. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8628685943315205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19200/60000][Iteration 2495][Wall Clock 240.368818819s] Trained 128 records in 0.086299253 seconds. Throughput is 1483.2109 records/second. Loss is 2.1124723. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8620492272467084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19328/60000][Iteration 2496][Wall Clock 240.455776233s] Trained 128 records in 0.086957414 seconds. Throughput is 1471.9849 records/second. Loss is 2.108841. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.861230329041488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19456/60000][Iteration 2497][Wall Clock 240.545800884s] Trained 128 records in 0.090024651 seconds. Throughput is 1421.8328 records/second. Loss is 2.089289. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.860411899313501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19584/60000][Iteration 2498][Wall Clock 240.656960149s] Trained 128 records in 0.111159265 seconds. Throughput is 1151.501 records/second. Loss is 2.1197553. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8595939376608524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19712/60000][Iteration 2499][Wall Clock 240.746408734s] Trained 128 records in 0.089448585 seconds. Throughput is 1430.9896 records/second. Loss is 2.0977044. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.858776443682104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19840/60000][Iteration 2500][Wall Clock 240.831840208s] Trained 128 records in 0.085431474 seconds. Throughput is 1498.2769 records/second. Loss is 2.102113. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.857959416976279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 19968/60000][Iteration 2501][Wall Clock 240.919633471s] Trained 128 records in 0.087793263 seconds. Throughput is 1457.9707 records/second. Loss is 2.101275. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8571428571428574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:16 INFO  DistriOptimizer$:408 - [Epoch 6 20096/60000][Iteration 2502][Wall Clock 241.004269593s] Trained 128 records in 0.084636122 seconds. Throughput is 1512.3566 records/second. Loss is 2.1293037. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8563267637817766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20224/60000][Iteration 2503][Wall Clock 241.087102513s] Trained 128 records in 0.08283292 seconds. Throughput is 1545.2794 records/second. Loss is 2.1251376. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8555111364934324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20352/60000][Iteration 2504][Wall Clock 241.172392597s] Trained 128 records in 0.085290084 seconds. Throughput is 1500.7606 records/second. Loss is 2.082582. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8546959748786756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20480/60000][Iteration 2505][Wall Clock 241.263696452s] Trained 128 records in 0.091303855 seconds. Throughput is 1401.9124 records/second. Loss is 2.0981162. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8538812785388126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20608/60000][Iteration 2506][Wall Clock 241.357932068s] Trained 128 records in 0.094235616 seconds. Throughput is 1358.2975 records/second. Loss is 2.1369743. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.853067047075606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20736/60000][Iteration 2507][Wall Clock 241.43961119s] Trained 128 records in 0.081679122 seconds. Throughput is 1567.1079 records/second. Loss is 2.1310022. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.852253280091272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20864/60000][Iteration 2508][Wall Clock 241.554524967s] Trained 128 records in 0.114913777 seconds. Throughput is 1113.8787 records/second. Loss is 2.1319537. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8514399771884804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 20992/60000][Iteration 2509][Wall Clock 241.636978481s] Trained 128 records in 0.082453514 seconds. Throughput is 1552.3899 records/second. Loss is 2.1081872. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8506271379703536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 21120/60000][Iteration 2510][Wall Clock 241.721290008s] Trained 128 records in 0.084311527 seconds. Throughput is 1518.1791 records/second. Loss is 2.126501. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8498147620404675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 21248/60000][Iteration 2511][Wall Clock 241.806312836s] Trained 128 records in 0.085022828 seconds. Throughput is 1505.478 records/second. Loss is 2.120569. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.849002849002849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 21376/60000][Iteration 2512][Wall Clock 241.897965444s] Trained 128 records in 0.091652608 seconds. Throughput is 1396.5778 records/second. Loss is 2.1144938. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.848191398461977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:17 INFO  DistriOptimizer$:408 - [Epoch 6 21504/60000][Iteration 2513][Wall Clock 241.982504056s] Trained 128 records in 0.084538612 seconds. Throughput is 1514.1011 records/second. Loss is 2.0988357. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.847380410022779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 21632/60000][Iteration 2514][Wall Clock 242.069170442s] Trained 128 records in 0.086666386 seconds. Throughput is 1476.9279 records/second. Loss is 2.1040306. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.846569883290635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 21760/60000][Iteration 2515][Wall Clock 242.162216952s] Trained 128 records in 0.09304651 seconds. Throughput is 1375.6561 records/second. Loss is 2.1289363. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.845759817871372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 21888/60000][Iteration 2516][Wall Clock 242.247795952s] Trained 128 records in 0.085579 seconds. Throughput is 1495.694 records/second. Loss is 2.1429663. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8449502133712657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22016/60000][Iteration 2517][Wall Clock 242.333922606s] Trained 128 records in 0.086126654 seconds. Throughput is 1486.1833 records/second. Loss is 2.1215186. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.844141069397042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22144/60000][Iteration 2518][Wall Clock 242.423047542s] Trained 128 records in 0.089124936 seconds. Throughput is 1436.1862 records/second. Loss is 2.1381938. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.843332385555872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22272/60000][Iteration 2519][Wall Clock 242.514212951s] Trained 128 records in 0.091165409 seconds. Throughput is 1404.0413 records/second. Loss is 2.0898647. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.842524161455372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22400/60000][Iteration 2520][Wall Clock 242.601720437s] Trained 128 records in 0.087507486 seconds. Throughput is 1462.7319 records/second. Loss is 2.1285927. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.841716396703609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22528/60000][Iteration 2521][Wall Clock 242.688972983s] Trained 128 records in 0.087252546 seconds. Throughput is 1467.006 records/second. Loss is 2.104124. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.840909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22656/60000][Iteration 2522][Wall Clock 242.774252777s] Trained 128 records in 0.085279794 seconds. Throughput is 1500.9418 records/second. Loss is 2.126823. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8401022436807724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22784/60000][Iteration 2523][Wall Clock 242.859385594s] Trained 128 records in 0.085132817 seconds. Throughput is 1503.5331 records/second. Loss is 2.1277063. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8392958546280523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:18 INFO  DistriOptimizer$:408 - [Epoch 6 22912/60000][Iteration 2524][Wall Clock 242.94580791s] Trained 128 records in 0.086422316 seconds. Throughput is 1481.0989 records/second. Loss is 2.1385295. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.838489923360772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23040/60000][Iteration 2525][Wall Clock 243.032549012s] Trained 128 records in 0.086741102 seconds. Throughput is 1475.6556 records/second. Loss is 2.1243691. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8376844494892167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23168/60000][Iteration 2526][Wall Clock 243.116844944s] Trained 128 records in 0.084295932 seconds. Throughput is 1518.4601 records/second. Loss is 2.107465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8368794326241134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23296/60000][Iteration 2527][Wall Clock 243.205209929s] Trained 128 records in 0.088364985 seconds. Throughput is 1448.5375 records/second. Loss is 2.1161742. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8360748723766304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23424/60000][Iteration 2528][Wall Clock 243.291109351s] Trained 128 records in 0.085899422 seconds. Throughput is 1490.1149 records/second. Loss is 2.1404645. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.835270768358378E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23552/60000][Iteration 2529][Wall Clock 243.376707352s] Trained 128 records in 0.085598001 seconds. Throughput is 1495.362 records/second. Loss is 2.1022952. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.834467120181406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23680/60000][Iteration 2530][Wall Clock 243.464140021s] Trained 128 records in 0.087432669 seconds. Throughput is 1463.9836 records/second. Loss is 2.1328173. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8336639274582036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23808/60000][Iteration 2531][Wall Clock 243.549522436s] Trained 128 records in 0.085382415 seconds. Throughput is 1499.1377 records/second. Loss is 2.104592. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8328611898016995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 23936/60000][Iteration 2532][Wall Clock 243.646914795s] Trained 128 records in 0.097392359 seconds. Throughput is 1314.2715 records/second. Loss is 2.1102087. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.832058906825262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 24064/60000][Iteration 2533][Wall Clock 243.727753839s] Trained 128 records in 0.080839044 seconds. Throughput is 1583.3933 records/second. Loss is 2.102126. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8312570781426955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 24192/60000][Iteration 2534][Wall Clock 243.806861484s] Trained 128 records in 0.079107645 seconds. Throughput is 1618.0485 records/second. Loss is 2.1182303. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8304557033682426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 24320/60000][Iteration 2535][Wall Clock 243.889052485s] Trained 128 records in 0.082191001 seconds. Throughput is 1557.3481 records/second. Loss is 2.1077993. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8296547821165814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:19 INFO  DistriOptimizer$:408 - [Epoch 6 24448/60000][Iteration 2536][Wall Clock 243.98012561s] Trained 128 records in 0.091073125 seconds. Throughput is 1405.464 records/second. Loss is 2.1180224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.828854314002829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 24576/60000][Iteration 2537][Wall Clock 244.065942244s] Trained 128 records in 0.085816634 seconds. Throughput is 1491.5522 records/second. Loss is 2.0968533. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.828054298642534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 24704/60000][Iteration 2538][Wall Clock 244.153450742s] Trained 128 records in 0.087508498 seconds. Throughput is 1462.7151 records/second. Loss is 2.1094353. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8272547356516825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 24832/60000][Iteration 2539][Wall Clock 244.239612602s] Trained 128 records in 0.08616186 seconds. Throughput is 1485.5762 records/second. Loss is 2.088793. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.826455624646693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 24960/60000][Iteration 2540][Wall Clock 244.327662935s] Trained 128 records in 0.088050333 seconds. Throughput is 1453.714 records/second. Loss is 2.1252565. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8256569652444194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25088/60000][Iteration 2541][Wall Clock 244.42797312s] Trained 128 records in 0.100310185 seconds. Throughput is 1276.0419 records/second. Loss is 2.0945363. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.824858757062147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25216/60000][Iteration 2542][Wall Clock 244.514064241s] Trained 128 records in 0.086091121 seconds. Throughput is 1486.7968 records/second. Loss is 2.1272035. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.824060999717594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25344/60000][Iteration 2543][Wall Clock 244.603011146s] Trained 128 records in 0.088946905 seconds. Throughput is 1439.0607 records/second. Loss is 2.1167684. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.82326369282891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25472/60000][Iteration 2544][Wall Clock 244.688742371s] Trained 128 records in 0.085731225 seconds. Throughput is 1493.0383 records/second. Loss is 2.1062438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.822466836014677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25600/60000][Iteration 2545][Wall Clock 244.774337245s] Trained 128 records in 0.085594874 seconds. Throughput is 1495.4166 records/second. Loss is 2.1041381. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.821670428893905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25728/60000][Iteration 2546][Wall Clock 244.862506912s] Trained 128 records in 0.088169667 seconds. Throughput is 1451.7465 records/second. Loss is 2.1117618. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.820874471086037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:20 INFO  DistriOptimizer$:408 - [Epoch 6 25856/60000][Iteration 2547][Wall Clock 244.948805589s] Trained 128 records in 0.086298677 seconds. Throughput is 1483.221 records/second. Loss is 2.097462. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8200789622109416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 25984/60000][Iteration 2548][Wall Clock 245.03368116s] Trained 128 records in 0.084875571 seconds. Throughput is 1508.0901 records/second. Loss is 2.102459. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.81928390188892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26112/60000][Iteration 2549][Wall Clock 245.117529657s] Trained 128 records in 0.083848497 seconds. Throughput is 1526.5629 records/second. Loss is 2.1173751. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.818489289740699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26240/60000][Iteration 2550][Wall Clock 245.204739995s] Trained 128 records in 0.087210338 seconds. Throughput is 1467.716 records/second. Loss is 2.1039057. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8176951253874335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26368/60000][Iteration 2551][Wall Clock 245.299365088s] Trained 128 records in 0.094625093 seconds. Throughput is 1352.7068 records/second. Loss is 2.0917368. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.816901408450704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26496/60000][Iteration 2552][Wall Clock 245.38661895s] Trained 128 records in 0.087253862 seconds. Throughput is 1466.9838 records/second. Loss is 2.1201394. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.81610813855252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26624/60000][Iteration 2553][Wall Clock 245.47766418s] Trained 128 records in 0.09104523 seconds. Throughput is 1405.8947 records/second. Loss is 2.0990617. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8153153153153153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26752/60000][Iteration 2554][Wall Clock 245.568043743s] Trained 128 records in 0.090379563 seconds. Throughput is 1416.2494 records/second. Loss is 2.085414. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8145229383619476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 26880/60000][Iteration 2555][Wall Clock 245.653842386s] Trained 128 records in 0.085798643 seconds. Throughput is 1491.8651 records/second. Loss is 2.124788. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8137310073157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 27008/60000][Iteration 2556][Wall Clock 245.743737349s] Trained 128 records in 0.089894963 seconds. Throughput is 1423.8839 records/second. Loss is 2.1108096. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8129395218002813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 27136/60000][Iteration 2557][Wall Clock 245.831440009s] Trained 128 records in 0.08770266 seconds. Throughput is 1459.4768 records/second. Loss is 2.0823762. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8121484814398203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:21 INFO  DistriOptimizer$:408 - [Epoch 6 27264/60000][Iteration 2558][Wall Clock 245.931753172s] Trained 128 records in 0.100313163 seconds. Throughput is 1276.004 records/second. Loss is 2.1242604. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.81135788585887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 27392/60000][Iteration 2559][Wall Clock 246.0099344s] Trained 128 records in 0.078181228 seconds. Throughput is 1637.2217 records/second. Loss is 2.1038496. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.810567734682406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 27520/60000][Iteration 2560][Wall Clock 246.094868256s] Trained 128 records in 0.084933856 seconds. Throughput is 1507.055 records/second. Loss is 2.1184793. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.809778027535825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 27648/60000][Iteration 2561][Wall Clock 246.180451199s] Trained 128 records in 0.085582943 seconds. Throughput is 1495.6251 records/second. Loss is 2.099029. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.808988764044944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 27776/60000][Iteration 2562][Wall Clock 246.268969958s] Trained 128 records in 0.088518759 seconds. Throughput is 1446.0211 records/second. Loss is 2.1160038. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.808199943836001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 27904/60000][Iteration 2563][Wall Clock 246.357253977s] Trained 128 records in 0.088284019 seconds. Throughput is 1449.8661 records/second. Loss is 2.1013432. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8074115665356543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 28032/60000][Iteration 2564][Wall Clock 246.453758906s] Trained 128 records in 0.096504929 seconds. Throughput is 1326.3572 records/second. Loss is 2.1265922. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.806623631770979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 28160/60000][Iteration 2565][Wall Clock 246.546126377s] Trained 128 records in 0.092367471 seconds. Throughput is 1385.7693 records/second. Loss is 2.11416. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.805836139169473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 28288/60000][Iteration 2566][Wall Clock 246.63825152s] Trained 128 records in 0.092125143 seconds. Throughput is 1389.4144 records/second. Loss is 2.129438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8050490883590464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 28416/60000][Iteration 2567][Wall Clock 246.723833942s] Trained 128 records in 0.085582422 seconds. Throughput is 1495.6343 records/second. Loss is 2.1039708. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8042624789680314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 28544/60000][Iteration 2568][Wall Clock 246.841173743s] Trained 128 records in 0.117339801 seconds. Throughput is 1090.849 records/second. Loss is 2.113886. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.803476310625175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:22 INFO  DistriOptimizer$:408 - [Epoch 6 28672/60000][Iteration 2569][Wall Clock 246.944435345s] Trained 128 records in 0.103261602 seconds. Throughput is 1239.5701 records/second. Loss is 2.120736. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.802690582959641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 28800/60000][Iteration 2570][Wall Clock 247.059948517s] Trained 128 records in 0.115513172 seconds. Throughput is 1108.0988 records/second. Loss is 2.1026316. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.801905295601009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 28928/60000][Iteration 2571][Wall Clock 247.145711149s] Trained 128 records in 0.085762632 seconds. Throughput is 1492.4915 records/second. Loss is 2.079186. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.801120448179272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29056/60000][Iteration 2572][Wall Clock 247.232412757s] Trained 128 records in 0.086701608 seconds. Throughput is 1476.3279 records/second. Loss is 2.1397426. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.8003360403248387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29184/60000][Iteration 2573][Wall Clock 247.319924646s] Trained 128 records in 0.087511889 seconds. Throughput is 1462.6584 records/second. Loss is 2.0893595. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.799552071668533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29312/60000][Iteration 2574][Wall Clock 247.405204754s] Trained 128 records in 0.085280108 seconds. Throughput is 1500.9363 records/second. Loss is 2.082222. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.79876854184159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29440/60000][Iteration 2575][Wall Clock 247.493533516s] Trained 128 records in 0.088328762 seconds. Throughput is 1449.1316 records/second. Loss is 2.103437. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.797985450475658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29568/60000][Iteration 2576][Wall Clock 247.580123958s] Trained 128 records in 0.086590442 seconds. Throughput is 1478.2233 records/second. Loss is 2.1077287. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.797202797202797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29696/60000][Iteration 2577][Wall Clock 247.665910024s] Trained 128 records in 0.085786066 seconds. Throughput is 1492.0837 records/second. Loss is 2.1165984. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.796420581655481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29824/60000][Iteration 2578][Wall Clock 247.750765218s] Trained 128 records in 0.084855194 seconds. Throughput is 1508.4521 records/second. Loss is 2.0920084. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.795638803466592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 29952/60000][Iteration 2579][Wall Clock 247.836056143s] Trained 128 records in 0.085290925 seconds. Throughput is 1500.7458 records/second. Loss is 2.1324463. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7948574622694243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:23 INFO  DistriOptimizer$:408 - [Epoch 6 30080/60000][Iteration 2580][Wall Clock 247.920587553s] Trained 128 records in 0.08453141 seconds. Throughput is 1514.23 records/second. Loss is 2.1256013. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.794076557697681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30208/60000][Iteration 2581][Wall Clock 248.007897594s] Trained 128 records in 0.087310041 seconds. Throughput is 1466.0399 records/second. Loss is 2.1201444. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7932960893854746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30336/60000][Iteration 2582][Wall Clock 248.094136691s] Trained 128 records in 0.086239097 seconds. Throughput is 1484.2456 records/second. Loss is 2.1320887. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.792516056967328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30464/60000][Iteration 2583][Wall Clock 248.192117587s] Trained 128 records in 0.097980896 seconds. Throughput is 1306.3772 records/second. Loss is 2.1010325. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7917364600781687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30592/60000][Iteration 2584][Wall Clock 248.279607373s] Trained 128 records in 0.087489786 seconds. Throughput is 1463.028 records/second. Loss is 2.1382427. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7909572983533354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30720/60000][Iteration 2585][Wall Clock 248.365633979s] Trained 128 records in 0.086026606 seconds. Throughput is 1487.9117 records/second. Loss is 2.0819526. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7901785714285713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30848/60000][Iteration 2586][Wall Clock 248.452610871s] Trained 128 records in 0.086976892 seconds. Throughput is 1471.6553 records/second. Loss is 2.1253061. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.789400278940028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 30976/60000][Iteration 2587][Wall Clock 248.537939818s] Trained 128 records in 0.085328947 seconds. Throughput is 1500.0771 records/second. Loss is 2.1055732. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.788622420524261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 31104/60000][Iteration 2588][Wall Clock 248.624417294s] Trained 128 records in 0.086477476 seconds. Throughput is 1480.1543 records/second. Loss is 2.112629. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7878449958182325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 31232/60000][Iteration 2589][Wall Clock 248.715319256s] Trained 128 records in 0.090901962 seconds. Throughput is 1408.1104 records/second. Loss is 2.119909. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.787068004459309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 31360/60000][Iteration 2590][Wall Clock 248.804283256s] Trained 128 records in 0.088964 seconds. Throughput is 1438.7842 records/second. Loss is 2.1314604. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7862914460852607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:24 INFO  DistriOptimizer$:408 - [Epoch 6 31488/60000][Iteration 2591][Wall Clock 248.905037019s] Trained 128 records in 0.100753763 seconds. Throughput is 1270.4241 records/second. Loss is 2.0948489. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.785515320334262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 31616/60000][Iteration 2592][Wall Clock 248.992615873s] Trained 128 records in 0.087578854 seconds. Throughput is 1461.54 records/second. Loss is 2.0934339. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.78473962684489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 31744/60000][Iteration 2593][Wall Clock 249.084114861s] Trained 128 records in 0.091498988 seconds. Throughput is 1398.9226 records/second. Loss is 2.085966. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7839643652561246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 31872/60000][Iteration 2594][Wall Clock 249.170359355s] Trained 128 records in 0.086244494 seconds. Throughput is 1484.1527 records/second. Loss is 2.1106174. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7831895352073476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32000/60000][Iteration 2595][Wall Clock 249.256435863s] Trained 128 records in 0.086076508 seconds. Throughput is 1487.0492 records/second. Loss is 2.0938187. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.782415136338342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32128/60000][Iteration 2596][Wall Clock 249.343965786s] Trained 128 records in 0.087529923 seconds. Throughput is 1462.357 records/second. Loss is 2.0911236. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7816411682892903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32256/60000][Iteration 2597][Wall Clock 249.43325369s] Trained 128 records in 0.089287904 seconds. Throughput is 1433.5648 records/second. Loss is 2.103399. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7808676307007786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32384/60000][Iteration 2598][Wall Clock 249.524207338s] Trained 128 records in 0.090953648 seconds. Throughput is 1407.3102 records/second. Loss is 2.1167321. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7800945232137893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32512/60000][Iteration 2599][Wall Clock 249.631444578s] Trained 128 records in 0.10723724 seconds. Throughput is 1193.6152 records/second. Loss is 2.1245222. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.779321845469706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32640/60000][Iteration 2600][Wall Clock 249.74176628s] Trained 128 records in 0.110321702 seconds. Throughput is 1160.2432 records/second. Loss is 2.100351. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.778549597110308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32768/60000][Iteration 2601][Wall Clock 249.848511949s] Trained 128 records in 0.106745669 seconds. Throughput is 1199.1119 records/second. Loss is 2.1183803. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.777777777777778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:25 INFO  DistriOptimizer$:408 - [Epoch 6 32896/60000][Iteration 2602][Wall Clock 249.956115803s] Trained 128 records in 0.107603854 seconds. Throughput is 1189.5485 records/second. Loss is 2.1100206. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7770063871146905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33024/60000][Iteration 2603][Wall Clock 250.064625752s] Trained 128 records in 0.108509949 seconds. Throughput is 1179.6154 records/second. Loss is 2.1094038. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.77623542476402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33152/60000][Iteration 2604][Wall Clock 250.172929684s] Trained 128 records in 0.108303932 seconds. Throughput is 1181.8591 records/second. Loss is 2.1037881. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7754648903691365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33280/60000][Iteration 2605][Wall Clock 250.282076828s] Trained 128 records in 0.109147144 seconds. Throughput is 1172.7288 records/second. Loss is 2.0931408. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.774694783573807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33408/60000][Iteration 2606][Wall Clock 250.367313426s] Trained 128 records in 0.085236598 seconds. Throughput is 1501.7023 records/second. Loss is 2.1421225. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7739251040221914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33536/60000][Iteration 2607][Wall Clock 250.45330374s] Trained 128 records in 0.085990314 seconds. Throughput is 1488.5397 records/second. Loss is 2.1257598. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7731558513588466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33664/60000][Iteration 2608][Wall Clock 250.538123483s] Trained 128 records in 0.084819743 seconds. Throughput is 1509.0826 records/second. Loss is 2.097695. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.772387025228722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33792/60000][Iteration 2609][Wall Clock 250.632288132s] Trained 128 records in 0.094164649 seconds. Throughput is 1359.3212 records/second. Loss is 2.1138344. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.771618625277162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 33920/60000][Iteration 2610][Wall Clock 250.715032017s] Trained 128 records in 0.082743885 seconds. Throughput is 1546.9421 records/second. Loss is 2.1051636. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.770850651149903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 34048/60000][Iteration 2611][Wall Clock 250.795630553s] Trained 128 records in 0.080598536 seconds. Throughput is 1588.1183 records/second. Loss is 2.105122. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.770083102493075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 34176/60000][Iteration 2612][Wall Clock 250.881185659s] Trained 128 records in 0.085555106 seconds. Throughput is 1496.1117 records/second. Loss is 2.1008966. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7693159789531985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:26 INFO  DistriOptimizer$:408 - [Epoch 6 34304/60000][Iteration 2613][Wall Clock 250.966760247s] Trained 128 records in 0.085574588 seconds. Throughput is 1495.7711 records/second. Loss is 2.1097443. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.768549280177187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 34432/60000][Iteration 2614][Wall Clock 251.052651123s] Trained 128 records in 0.085890876 seconds. Throughput is 1490.2631 records/second. Loss is 2.1067982. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.767783005812344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 34560/60000][Iteration 2615][Wall Clock 251.145888565s] Trained 128 records in 0.093237442 seconds. Throughput is 1372.839 records/second. Loss is 2.116136. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7670171555063645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 34688/60000][Iteration 2616][Wall Clock 251.233608611s] Trained 128 records in 0.087720046 seconds. Throughput is 1459.1876 records/second. Loss is 2.1316197. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7662517289073305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 34816/60000][Iteration 2617][Wall Clock 251.327466105s] Trained 128 records in 0.093857494 seconds. Throughput is 1363.7695 records/second. Loss is 2.084732. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.765486725663717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 34944/60000][Iteration 2618][Wall Clock 251.415771012s] Trained 128 records in 0.088304907 seconds. Throughput is 1449.5231 records/second. Loss is 2.0917234. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.764722145424385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 35072/60000][Iteration 2619][Wall Clock 251.499332837s] Trained 128 records in 0.083561825 seconds. Throughput is 1531.8 records/second. Loss is 2.1199095. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.763957987838585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 35200/60000][Iteration 2620][Wall Clock 251.587015562s] Trained 128 records in 0.087682725 seconds. Throughput is 1459.8087 records/second. Loss is 2.0902088. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7631942525559546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 35328/60000][Iteration 2621][Wall Clock 251.673742128s] Trained 128 records in 0.086726566 seconds. Throughput is 1475.903 records/second. Loss is 2.109139. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7624309392265195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 35456/60000][Iteration 2622][Wall Clock 251.760700412s] Trained 128 records in 0.086958284 seconds. Throughput is 1471.9702 records/second. Loss is 2.103841. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7616680475006904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 35584/60000][Iteration 2623][Wall Clock 251.845709861s] Trained 128 records in 0.085009449 seconds. Throughput is 1505.715 records/second. Loss is 2.0912962. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.760905577029266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:27 INFO  DistriOptimizer$:408 - [Epoch 6 35712/60000][Iteration 2624][Wall Clock 251.932881881s] Trained 128 records in 0.08717202 seconds. Throughput is 1468.3611 records/second. Loss is 2.0825882. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.760143527463428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 35840/60000][Iteration 2625][Wall Clock 252.019990186s] Trained 128 records in 0.087108305 seconds. Throughput is 1469.435 records/second. Loss is 2.142783. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.759381898454746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 35968/60000][Iteration 2626][Wall Clock 252.114326797s] Trained 128 records in 0.094336611 seconds. Throughput is 1356.8433 records/second. Loss is 2.1142888. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7586206896551725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36096/60000][Iteration 2627][Wall Clock 252.208448525s] Trained 128 records in 0.094121728 seconds. Throughput is 1359.941 records/second. Loss is 2.099067. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.757859900717044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36224/60000][Iteration 2628][Wall Clock 252.291469749s] Trained 128 records in 0.083021224 seconds. Throughput is 1541.7744 records/second. Loss is 2.0958345. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7570995312930797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36352/60000][Iteration 2629][Wall Clock 252.377594395s] Trained 128 records in 0.086124646 seconds. Throughput is 1486.218 records/second. Loss is 2.093787. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.756339581036384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36480/60000][Iteration 2630][Wall Clock 252.463235359s] Trained 128 records in 0.085640964 seconds. Throughput is 1494.6118 records/second. Loss is 2.1126568. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.755580049600441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36608/60000][Iteration 2631][Wall Clock 252.548793227s] Trained 128 records in 0.085557868 seconds. Throughput is 1496.0634 records/second. Loss is 2.093506. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.754820936639119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36736/60000][Iteration 2632][Wall Clock 252.63223421s] Trained 128 records in 0.083440983 seconds. Throughput is 1534.0184 records/second. Loss is 2.096567. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7540622418066645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36864/60000][Iteration 2633][Wall Clock 252.719419272s] Trained 128 records in 0.087185062 seconds. Throughput is 1468.1414 records/second. Loss is 2.129484. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.753303964757709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 36992/60000][Iteration 2634][Wall Clock 252.805309781s] Trained 128 records in 0.085890509 seconds. Throughput is 1490.2694 records/second. Loss is 2.1154459. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.752546105147261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:28 INFO  DistriOptimizer$:408 - [Epoch 6 37120/60000][Iteration 2635][Wall Clock 252.908682117s] Trained 128 records in 0.103372336 seconds. Throughput is 1238.2423 records/second. Loss is 2.1086535. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.75178866263071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 37248/60000][Iteration 2636][Wall Clock 252.984690685s] Trained 128 records in 0.076008568 seconds. Throughput is 1684.0208 records/second. Loss is 2.1017544. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.751031636863824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 37376/60000][Iteration 2637][Wall Clock 253.061958171s] Trained 128 records in 0.077267486 seconds. Throughput is 1656.583 records/second. Loss is 2.1130676. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.75027502750275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 37504/60000][Iteration 2638][Wall Clock 253.14212446s] Trained 128 records in 0.080166289 seconds. Throughput is 1596.6812 records/second. Loss is 2.1227918. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7495188342040145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 37632/60000][Iteration 2639][Wall Clock 253.226544329s] Trained 128 records in 0.084419869 seconds. Throughput is 1516.2307 records/second. Loss is 2.0830727. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.748763056624519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 37760/60000][Iteration 2640][Wall Clock 253.312935039s] Trained 128 records in 0.08639071 seconds. Throughput is 1481.6407 records/second. Loss is 2.1170795. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.748007694421544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 37888/60000][Iteration 2641][Wall Clock 253.401361207s] Trained 128 records in 0.088426168 seconds. Throughput is 1447.5354 records/second. Loss is 2.1225772. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.747252747252747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 38016/60000][Iteration 2642][Wall Clock 253.488354179s] Trained 128 records in 0.086992972 seconds. Throughput is 1471.3832 records/second. Loss is 2.1099868. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7464982147761604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 38144/60000][Iteration 2643][Wall Clock 253.768213244s] Trained 128 records in 0.279859065 seconds. Throughput is 457.37308 records/second. Loss is 2.1032655. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.745744096650192E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 38272/60000][Iteration 2644][Wall Clock 253.857511636s] Trained 128 records in 0.089298392 seconds. Throughput is 1433.3965 records/second. Loss is 2.0947902. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.744990392533626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:29 INFO  DistriOptimizer$:408 - [Epoch 6 38400/60000][Iteration 2645][Wall Clock 253.944416672s] Trained 128 records in 0.086905036 seconds. Throughput is 1472.8721 records/second. Loss is 2.0894623. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7442371020856203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 38528/60000][Iteration 2646][Wall Clock 254.030583905s] Trained 128 records in 0.086167233 seconds. Throughput is 1485.4835 records/second. Loss is 2.1065226. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7434842249657066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 38656/60000][Iteration 2647][Wall Clock 254.117431044s] Trained 128 records in 0.086847139 seconds. Throughput is 1473.8539 records/second. Loss is 2.1226096. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7427317608337906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 38784/60000][Iteration 2648][Wall Clock 254.208226197s] Trained 128 records in 0.090795153 seconds. Throughput is 1409.7668 records/second. Loss is 2.1007116. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7419797093501506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 38912/60000][Iteration 2649][Wall Clock 254.295896619s] Trained 128 records in 0.087670422 seconds. Throughput is 1460.0134 records/second. Loss is 2.1197948. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7412280701754384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39040/60000][Iteration 2650][Wall Clock 254.384211925s] Trained 128 records in 0.088315306 seconds. Throughput is 1449.3524 records/second. Loss is 2.1189365. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.740476842970677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39168/60000][Iteration 2651][Wall Clock 254.471642052s] Trained 128 records in 0.087430127 seconds. Throughput is 1464.0262 records/second. Loss is 2.113159. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7397260273972606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39296/60000][Iteration 2652][Wall Clock 254.561120576s] Trained 128 records in 0.089478524 seconds. Throughput is 1430.5109 records/second. Loss is 2.0911138. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.738975623116954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39424/60000][Iteration 2653][Wall Clock 254.648561841s] Trained 128 records in 0.087441265 seconds. Throughput is 1463.8397 records/second. Loss is 2.0783696. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.738225629791895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39552/60000][Iteration 2654][Wall Clock 254.73486745s] Trained 128 records in 0.086305609 seconds. Throughput is 1483.1017 records/second. Loss is 2.108529. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.737476047084588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39680/60000][Iteration 2655][Wall Clock 254.835046307s] Trained 128 records in 0.100178857 seconds. Throughput is 1277.7147 records/second. Loss is 2.1005256. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.736726874657909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:30 INFO  DistriOptimizer$:408 - [Epoch 6 39808/60000][Iteration 2656][Wall Clock 254.918733512s] Trained 128 records in 0.083687205 seconds. Throughput is 1529.505 records/second. Loss is 2.095915. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7359781121751026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 39936/60000][Iteration 2657][Wall Clock 255.005967083s] Trained 128 records in 0.087233571 seconds. Throughput is 1467.325 records/second. Loss is 2.1212833. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.735229759299781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40064/60000][Iteration 2658][Wall Clock 255.09338317s] Trained 128 records in 0.087416087 seconds. Throughput is 1464.2614 records/second. Loss is 2.089164. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7344818156959256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40192/60000][Iteration 2659][Wall Clock 255.183288857s] Trained 128 records in 0.089905687 seconds. Throughput is 1423.7141 records/second. Loss is 2.0985715. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.733734281027884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40320/60000][Iteration 2660][Wall Clock 255.279021554s] Trained 128 records in 0.095732697 seconds. Throughput is 1337.0563 records/second. Loss is 2.1206896. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7329871549603714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40448/60000][Iteration 2661][Wall Clock 255.37285368s] Trained 128 records in 0.093832126 seconds. Throughput is 1364.1383 records/second. Loss is 2.098668. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.73224043715847E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40576/60000][Iteration 2662][Wall Clock 255.460182063s] Trained 128 records in 0.087328383 seconds. Throughput is 1465.7319 records/second. Loss is 2.100686. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7314941272876266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40704/60000][Iteration 2663][Wall Clock 255.577953977s] Trained 128 records in 0.117771914 seconds. Throughput is 1086.8466 records/second. Loss is 2.092251. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.730748225013654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40832/60000][Iteration 2664][Wall Clock 255.690746595s] Trained 128 records in 0.112792618 seconds. Throughput is 1134.826 records/second. Loss is 2.0910451. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7300027300027296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 40960/60000][Iteration 2665][Wall Clock 255.797806207s] Trained 128 records in 0.107059612 seconds. Throughput is 1195.5956 records/second. Loss is 2.1083949. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.729257641921397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:31 INFO  DistriOptimizer$:408 - [Epoch 6 41088/60000][Iteration 2666][Wall Clock 255.899787157s] Trained 128 records in 0.10198095 seconds. Throughput is 1255.1364 records/second. Loss is 2.118224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7285129604365623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41216/60000][Iteration 2667][Wall Clock 256.011980807s] Trained 128 records in 0.11219365 seconds. Throughput is 1140.8845 records/second. Loss is 2.0974257. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.727768685215494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41344/60000][Iteration 2668][Wall Clock 256.134154279s] Trained 128 records in 0.122173472 seconds. Throughput is 1047.6906 records/second. Loss is 2.1152546. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.727024815925825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41472/60000][Iteration 2669][Wall Clock 256.246173197s] Trained 128 records in 0.112018918 seconds. Throughput is 1142.6641 records/second. Loss is 2.0579321. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.726281352235551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41600/60000][Iteration 2670][Wall Clock 256.337388744s] Trained 128 records in 0.091215547 seconds. Throughput is 1403.2697 records/second. Loss is 2.1167157. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.725538293813028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41728/60000][Iteration 2671][Wall Clock 256.447488242s] Trained 128 records in 0.110099498 seconds. Throughput is 1162.5848 records/second. Loss is 2.1137774. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7247956403269756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41856/60000][Iteration 2672][Wall Clock 256.541049119s] Trained 128 records in 0.093560877 seconds. Throughput is 1368.0933 records/second. Loss is 2.0915096. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7240533914464724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 41984/60000][Iteration 2673][Wall Clock 256.649925661s] Trained 128 records in 0.108876542 seconds. Throughput is 1175.6436 records/second. Loss is 2.1139815. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7233115468409583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 42112/60000][Iteration 2674][Wall Clock 256.741431485s] Trained 128 records in 0.091505824 seconds. Throughput is 1398.818 records/second. Loss is 2.1142843. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.722570106180234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 42240/60000][Iteration 2675][Wall Clock 256.838231855s] Trained 128 records in 0.09680037 seconds. Throughput is 1322.309 records/second. Loss is 2.0523818. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7218290691344586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:32 INFO  DistriOptimizer$:408 - [Epoch 6 42368/60000][Iteration 2676][Wall Clock 256.931549484s] Trained 128 records in 0.093317629 seconds. Throughput is 1371.6594 records/second. Loss is 2.132582. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7210884353741496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 42496/60000][Iteration 2677][Wall Clock 257.026245935s] Trained 128 records in 0.094696451 seconds. Throughput is 1351.6874 records/second. Loss is 2.0780747. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.720348204570185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 42624/60000][Iteration 2678][Wall Clock 257.118892069s] Trained 128 records in 0.092646134 seconds. Throughput is 1381.6011 records/second. Loss is 2.1094196. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.719608376393799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 42752/60000][Iteration 2679][Wall Clock 257.209388425s] Trained 128 records in 0.090496356 seconds. Throughput is 1414.4216 records/second. Loss is 2.097342. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7188689505165854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 42880/60000][Iteration 2680][Wall Clock 257.315215796s] Trained 128 records in 0.105827371 seconds. Throughput is 1209.517 records/second. Loss is 2.109947. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.718129926610492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 43008/60000][Iteration 2681][Wall Clock 257.405998507s] Trained 128 records in 0.090782711 seconds. Throughput is 1409.9601 records/second. Loss is 2.0836005. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.717391304347826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 43136/60000][Iteration 2682][Wall Clock 257.495572752s] Trained 128 records in 0.089574245 seconds. Throughput is 1428.9822 records/second. Loss is 2.068871. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7166530834012495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 43264/60000][Iteration 2683][Wall Clock 257.583617143s] Trained 128 records in 0.088044391 seconds. Throughput is 1453.8121 records/second. Loss is 2.0840237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.715915263443781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 43392/60000][Iteration 2684][Wall Clock 257.672120605s] Trained 128 records in 0.088503462 seconds. Throughput is 1446.2711 records/second. Loss is 2.08006. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7151778441487917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 43520/60000][Iteration 2685][Wall Clock 257.766550438s] Trained 128 records in 0.094429833 seconds. Throughput is 1355.5038 records/second. Loss is 2.1174624. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.714440825190011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:33 INFO  DistriOptimizer$:408 - [Epoch 6 43648/60000][Iteration 2686][Wall Clock 257.868745619s] Trained 128 records in 0.102195181 seconds. Throughput is 1252.5052 records/second. Loss is 2.0801318. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.71370420624152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 43776/60000][Iteration 2687][Wall Clock 257.95647116s] Trained 128 records in 0.087725541 seconds. Throughput is 1459.0962 records/second. Loss is 2.0951753. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7129679869777537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 43904/60000][Iteration 2688][Wall Clock 258.067035173s] Trained 128 records in 0.110564013 seconds. Throughput is 1157.7003 records/second. Loss is 2.063653. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7122321670735016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44032/60000][Iteration 2689][Wall Clock 258.174353223s] Trained 128 records in 0.10731805 seconds. Throughput is 1192.7164 records/second. Loss is 2.148199. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7114967462039046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44160/60000][Iteration 2690][Wall Clock 258.279955364s] Trained 128 records in 0.105602141 seconds. Throughput is 1212.0967 records/second. Loss is 2.0862525. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.710761724044457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44288/60000][Iteration 2691][Wall Clock 258.391680942s] Trained 128 records in 0.111725578 seconds. Throughput is 1145.6643 records/second. Loss is 2.1009462. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7100271002710027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44416/60000][Iteration 2692][Wall Clock 258.498470986s] Trained 128 records in 0.106790044 seconds. Throughput is 1198.6136 records/second. Loss is 2.0925074. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.70929287455974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44544/60000][Iteration 2693][Wall Clock 258.606562362s] Trained 128 records in 0.108091376 seconds. Throughput is 1184.1832 records/second. Loss is 2.097861. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7085590465872155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44672/60000][Iteration 2694][Wall Clock 258.724013808s] Trained 128 records in 0.117451446 seconds. Throughput is 1089.812 records/second. Loss is 2.1109226. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7078256160303275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:34 INFO  DistriOptimizer$:408 - [Epoch 6 44800/60000][Iteration 2695][Wall Clock 258.834385984s] Trained 128 records in 0.110372176 seconds. Throughput is 1159.7125 records/second. Loss is 2.0792224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.707092582566324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 44928/60000][Iteration 2696][Wall Clock 258.943935438s] Trained 128 records in 0.109549454 seconds. Throughput is 1168.422 records/second. Loss is 2.1087673. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7063599458728013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45056/60000][Iteration 2697][Wall Clock 259.046809813s] Trained 128 records in 0.102874375 seconds. Throughput is 1244.236 records/second. Loss is 2.0968478. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7056277056277056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45184/60000][Iteration 2698][Wall Clock 259.15678725s] Trained 128 records in 0.109977437 seconds. Throughput is 1163.8751 records/second. Loss is 2.118106. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.704895861509332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45312/60000][Iteration 2699][Wall Clock 259.259970875s] Trained 128 records in 0.103183625 seconds. Throughput is 1240.5068 records/second. Loss is 2.0860133. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.7041644131963225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45440/60000][Iteration 2700][Wall Clock 259.361977027s] Trained 128 records in 0.102006152 seconds. Throughput is 1254.8263 records/second. Loss is 2.1007452. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.703433360367667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45568/60000][Iteration 2701][Wall Clock 259.446920673s] Trained 128 records in 0.084943646 seconds. Throughput is 1506.8815 records/second. Loss is 2.0969589. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.702702702702703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45696/60000][Iteration 2702][Wall Clock 259.534107554s] Trained 128 records in 0.087186881 seconds. Throughput is 1468.1108 records/second. Loss is 2.1111426. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.701972439881113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45824/60000][Iteration 2703][Wall Clock 259.618670481s] Trained 128 records in 0.084562927 seconds. Throughput is 1513.6656 records/second. Loss is 2.0917838. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.701242571582928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 45952/60000][Iteration 2704][Wall Clock 259.702993509s] Trained 128 records in 0.084323028 seconds. Throughput is 1517.972 records/second. Loss is 2.0950272. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.700513097488523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 46080/60000][Iteration 2705][Wall Clock 259.785143373s] Trained 128 records in 0.082149864 seconds. Throughput is 1558.1279 records/second. Loss is 2.102859. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.699784017278618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:35 INFO  DistriOptimizer$:408 - [Epoch 6 46208/60000][Iteration 2706][Wall Clock 259.876387407s] Trained 128 records in 0.091244034 seconds. Throughput is 1402.8314 records/second. Loss is 2.1280682. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.699055330634278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 46336/60000][Iteration 2707][Wall Clock 259.961059498s] Trained 128 records in 0.084672091 seconds. Throughput is 1511.7141 records/second. Loss is 2.0814831. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.698327037236913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 46464/60000][Iteration 2708][Wall Clock 260.050923002s] Trained 128 records in 0.089863504 seconds. Throughput is 1424.3826 records/second. Loss is 2.0968244. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.697599136768276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 46592/60000][Iteration 2709][Wall Clock 260.137930453s] Trained 128 records in 0.087007451 seconds. Throughput is 1471.1384 records/second. Loss is 2.0892885. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6968716289104636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 46720/60000][Iteration 2710][Wall Clock 260.222225047s] Trained 128 records in 0.084294594 seconds. Throughput is 1518.4841 records/second. Loss is 2.0950146. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6961445133459155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 46848/60000][Iteration 2711][Wall Clock 260.318763012s] Trained 128 records in 0.096537965 seconds. Throughput is 1325.9033 records/second. Loss is 2.1093366. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6954177897574127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 46976/60000][Iteration 2712][Wall Clock 260.401089963s] Trained 128 records in 0.082326951 seconds. Throughput is 1554.7765 records/second. Loss is 2.1002502. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.694691457828079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 47104/60000][Iteration 2713][Wall Clock 260.491549155s] Trained 128 records in 0.090459192 seconds. Throughput is 1415.0027 records/second. Loss is 2.108517. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6939655172413793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 47232/60000][Iteration 2714][Wall Clock 260.577930914s] Trained 128 records in 0.086381759 seconds. Throughput is 1481.7944 records/second. Loss is 2.0572374. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6932399676811203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 47360/60000][Iteration 2715][Wall Clock 260.662009567s] Trained 128 records in 0.084078653 seconds. Throughput is 1522.384 records/second. Loss is 2.0902948. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6925148088314486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 47488/60000][Iteration 2716][Wall Clock 260.749582384s] Trained 128 records in 0.087572817 seconds. Throughput is 1461.6407 records/second. Loss is 2.1121383. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.691790040376851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:36 INFO  DistriOptimizer$:408 - [Epoch 6 47616/60000][Iteration 2717][Wall Clock 260.835793943s] Trained 128 records in 0.086211559 seconds. Throughput is 1484.7196 records/second. Loss is 2.0893428. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6910656620021526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 47744/60000][Iteration 2718][Wall Clock 260.922039751s] Trained 128 records in 0.086245808 seconds. Throughput is 1484.1301 records/second. Loss is 2.1133869. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.690341673392521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 47872/60000][Iteration 2719][Wall Clock 261.015378874s] Trained 128 records in 0.093339123 seconds. Throughput is 1371.3435 records/second. Loss is 2.0983183. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.689618074233459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48000/60000][Iteration 2720][Wall Clock 261.098247799s] Trained 128 records in 0.082868925 seconds. Throughput is 1544.6079 records/second. Loss is 2.0837038. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6888948642108095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48128/60000][Iteration 2721][Wall Clock 261.184675831s] Trained 128 records in 0.086428032 seconds. Throughput is 1481.001 records/second. Loss is 2.0893037. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6881720430107527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48256/60000][Iteration 2722][Wall Clock 261.271912964s] Trained 128 records in 0.087237133 seconds. Throughput is 1467.265 records/second. Loss is 2.0848546. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.687449610319806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48384/60000][Iteration 2723][Wall Clock 261.359684173s] Trained 128 records in 0.087771209 seconds. Throughput is 1458.337 records/second. Loss is 2.1046283. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6867275658248256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48512/60000][Iteration 2724][Wall Clock 261.44476645s] Trained 128 records in 0.085082277 seconds. Throughput is 1504.4261 records/second. Loss is 2.0973878. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6860059092130003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48640/60000][Iteration 2725][Wall Clock 261.53095937s] Trained 128 records in 0.08619292 seconds. Throughput is 1485.0408 records/second. Loss is 2.0918195. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.685284640171858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48768/60000][Iteration 2726][Wall Clock 261.618045269s] Trained 128 records in 0.087085899 seconds. Throughput is 1469.8131 records/second. Loss is 2.1252055. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6845637583892615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 48896/60000][Iteration 2727][Wall Clock 261.705768996s] Trained 128 records in 0.087723727 seconds. Throughput is 1459.1263 records/second. Loss is 2.074277. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6838432635534085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 49024/60000][Iteration 2728][Wall Clock 261.790393188s] Trained 128 records in 0.084624192 seconds. Throughput is 1512.5698 records/second. Loss is 2.0984375. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6831231553528306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:37 INFO  DistriOptimizer$:408 - [Epoch 6 49152/60000][Iteration 2729][Wall Clock 261.876903097s] Trained 128 records in 0.086509909 seconds. Throughput is 1479.5994 records/second. Loss is 2.0954745. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.682403433476395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 49280/60000][Iteration 2730][Wall Clock 261.968806917s] Trained 128 records in 0.09190382 seconds. Throughput is 1392.7604 records/second. Loss is 2.1031973. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.681684097613301E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 49408/60000][Iteration 2731][Wall Clock 262.076064929s] Trained 128 records in 0.107258012 seconds. Throughput is 1193.384 records/second. Loss is 2.0935912. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6809651474530834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 49536/60000][Iteration 2732][Wall Clock 262.185369756s] Trained 128 records in 0.109304827 seconds. Throughput is 1171.037 records/second. Loss is 2.093935. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.680246582685607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 49664/60000][Iteration 2733][Wall Clock 262.293483527s] Trained 128 records in 0.108113771 seconds. Throughput is 1183.938 records/second. Loss is 2.108877. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.679528403001072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 49792/60000][Iteration 2734][Wall Clock 262.400210377s] Trained 128 records in 0.10672685 seconds. Throughput is 1199.3234 records/second. Loss is 2.0928686. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.678810608090008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 49920/60000][Iteration 2735][Wall Clock 262.507879477s] Trained 128 records in 0.1076691 seconds. Throughput is 1188.8276 records/second. Loss is 2.0866468. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.678093197643278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 50048/60000][Iteration 2736][Wall Clock 262.623989525s] Trained 128 records in 0.116110048 seconds. Throughput is 1102.4025 records/second. Loss is 2.1147647. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.677376171352075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 50176/60000][Iteration 2737][Wall Clock 262.731952598s] Trained 128 records in 0.107963073 seconds. Throughput is 1185.5906 records/second. Loss is 2.0955572. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.676659528907923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:38 INFO  DistriOptimizer$:408 - [Epoch 6 50304/60000][Iteration 2738][Wall Clock 262.820596341s] Trained 128 records in 0.088643743 seconds. Throughput is 1443.9823 records/second. Loss is 2.089611. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.675943270002676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 50432/60000][Iteration 2739][Wall Clock 262.917547715s] Trained 128 records in 0.096951374 seconds. Throughput is 1320.2495 records/second. Loss is 2.1014056. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6752273943285177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 50560/60000][Iteration 2740][Wall Clock 263.032205801s] Trained 128 records in 0.114658086 seconds. Throughput is 1116.3625 records/second. Loss is 2.0781136. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6745119015779623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 50688/60000][Iteration 2741][Wall Clock 263.144294423s] Trained 128 records in 0.112088622 seconds. Throughput is 1141.9536 records/second. Loss is 2.1216128. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6737967914438503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 50816/60000][Iteration 2742][Wall Clock 263.275082368s] Trained 128 records in 0.130787945 seconds. Throughput is 978.68353 records/second. Loss is 2.1172361. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.673082063619353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 50944/60000][Iteration 2743][Wall Clock 263.360318356s] Trained 128 records in 0.085235988 seconds. Throughput is 1501.713 records/second. Loss is 2.1216245. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6723677177979693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 51072/60000][Iteration 2744][Wall Clock 263.450642608s] Trained 128 records in 0.090324252 seconds. Throughput is 1417.1166 records/second. Loss is 2.1217756. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.671653753673524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 51200/60000][Iteration 2745][Wall Clock 263.540577759s] Trained 128 records in 0.089935151 seconds. Throughput is 1423.2477 records/second. Loss is 2.0763807. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6709401709401707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 51328/60000][Iteration 2746][Wall Clock 263.627220452s] Trained 128 records in 0.086642693 seconds. Throughput is 1477.3318 records/second. Loss is 2.0859551. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.67022696929239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 51456/60000][Iteration 2747][Wall Clock 263.713615052s] Trained 128 records in 0.0863946 seconds. Throughput is 1481.5741 records/second. Loss is 2.1210947. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6695141484249865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 51584/60000][Iteration 2748][Wall Clock 263.798572032s] Trained 128 records in 0.08495698 seconds. Throughput is 1506.6449 records/second. Loss is 2.1122384. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.668801708033093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:39 INFO  DistriOptimizer$:408 - [Epoch 6 51712/60000][Iteration 2749][Wall Clock 263.884313568s] Trained 128 records in 0.085741536 seconds. Throughput is 1492.8588 records/second. Loss is 2.0862386. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6680896478121667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 51840/60000][Iteration 2750][Wall Clock 263.986462417s] Trained 128 records in 0.102148849 seconds. Throughput is 1253.0734 records/second. Loss is 2.109315. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6673779674579886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 51968/60000][Iteration 2751][Wall Clock 264.072832958s] Trained 128 records in 0.086370541 seconds. Throughput is 1481.9867 records/second. Loss is 2.094514. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.666666666666667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52096/60000][Iteration 2752][Wall Clock 264.181199905s] Trained 128 records in 0.108366947 seconds. Throughput is 1181.172 records/second. Loss is 2.0869603. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6659557451346307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52224/60000][Iteration 2753][Wall Clock 264.265998836s] Trained 128 records in 0.084798931 seconds. Throughput is 1509.453 records/second. Loss is 2.0798306. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6652452025586353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52352/60000][Iteration 2754][Wall Clock 264.351384315s] Trained 128 records in 0.085385479 seconds. Throughput is 1499.084 records/second. Loss is 2.0881774. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.664535038635758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52480/60000][Iteration 2755][Wall Clock 264.438957074s] Trained 128 records in 0.087572759 seconds. Throughput is 1461.6417 records/second. Loss is 2.0930562. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.663825253063399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52608/60000][Iteration 2756][Wall Clock 264.525265855s] Trained 128 records in 0.086308781 seconds. Throughput is 1483.0474 records/second. Loss is 2.082848. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6631158455392814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52736/60000][Iteration 2757][Wall Clock 264.609867615s] Trained 128 records in 0.08460176 seconds. Throughput is 1512.971 records/second. Loss is 2.0574207. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.662406815761448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52864/60000][Iteration 2758][Wall Clock 264.694524232s] Trained 128 records in 0.084656617 seconds. Throughput is 1511.9905 records/second. Loss is 2.0625465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6616981634282674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 52992/60000][Iteration 2759][Wall Clock 264.779237622s] Trained 128 records in 0.08471339 seconds. Throughput is 1510.9772 records/second. Loss is 2.092899. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6609898882384245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:40 INFO  DistriOptimizer$:408 - [Epoch 6 53120/60000][Iteration 2760][Wall Clock 264.86434475s] Trained 128 records in 0.085107128 seconds. Throughput is 1503.9869 records/second. Loss is 2.104751. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6602819898909286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 53248/60000][Iteration 2761][Wall Clock 264.952832879s] Trained 128 records in 0.088488129 seconds. Throughput is 1446.5217 records/second. Loss is 2.0928495. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6595744680851064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 53376/60000][Iteration 2762][Wall Clock 265.044080229s] Trained 128 records in 0.09124735 seconds. Throughput is 1402.7805 records/second. Loss is 2.0990787. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6588673225206064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 53504/60000][Iteration 2763][Wall Clock 265.131339387s] Trained 128 records in 0.087259158 seconds. Throughput is 1466.8948 records/second. Loss is 2.1108243. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.658160552897395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 53632/60000][Iteration 2764][Wall Clock 265.226698156s] Trained 128 records in 0.095358769 seconds. Throughput is 1342.2992 records/second. Loss is 2.098311. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.657454158915759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 53760/60000][Iteration 2765][Wall Clock 265.315136439s] Trained 128 records in 0.088438283 seconds. Throughput is 1447.337 records/second. Loss is 2.1035025. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6567481402763017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 53888/60000][Iteration 2766][Wall Clock 265.406659507s] Trained 128 records in 0.091523068 seconds. Throughput is 1398.5546 records/second. Loss is 2.099957. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.656042496679947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 54016/60000][Iteration 2767][Wall Clock 265.494663514s] Trained 128 records in 0.088004007 seconds. Throughput is 1454.4792 records/second. Loss is 2.1163812. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.655337227827934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 54144/60000][Iteration 2768][Wall Clock 265.578734831s] Trained 128 records in 0.084071317 seconds. Throughput is 1522.517 records/second. Loss is 2.096259. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.654632333421821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 54272/60000][Iteration 2769][Wall Clock 265.667332031s] Trained 128 records in 0.0885972 seconds. Throughput is 1444.7408 records/second. Loss is 2.0846357. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.653927813163482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 54400/60000][Iteration 2770][Wall Clock 265.756432152s] Trained 128 records in 0.089100121 seconds. Throughput is 1436.5862 records/second. Loss is 2.0965524. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.653223666755107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:41 INFO  DistriOptimizer$:408 - [Epoch 6 54528/60000][Iteration 2771][Wall Clock 265.84332077s] Trained 128 records in 0.086888618 seconds. Throughput is 1473.1504 records/second. Loss is 2.1070447. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6525198938992045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 54656/60000][Iteration 2772][Wall Clock 265.927432275s] Trained 128 records in 0.084111505 seconds. Throughput is 1521.7894 records/second. Loss is 2.0707264. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6518164942985947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 54784/60000][Iteration 2773][Wall Clock 266.011278697s] Trained 128 records in 0.083846422 seconds. Throughput is 1526.6007 records/second. Loss is 2.0499752. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6511134676564154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 54912/60000][Iteration 2774][Wall Clock 266.097336582s] Trained 128 records in 0.086057885 seconds. Throughput is 1487.371 records/second. Loss is 2.0723941. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6504108136761196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55040/60000][Iteration 2775][Wall Clock 266.185369368s] Trained 128 records in 0.088032786 seconds. Throughput is 1454.0037 records/second. Loss is 2.0822105. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6497085320614734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55168/60000][Iteration 2776][Wall Clock 266.271606263s] Trained 128 records in 0.086236895 seconds. Throughput is 1484.2836 records/second. Loss is 2.0946462. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6490066225165563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55296/60000][Iteration 2777][Wall Clock 266.356566855s] Trained 128 records in 0.084960592 seconds. Throughput is 1506.5808 records/second. Loss is 2.1017542. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6483050847457627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55424/60000][Iteration 2778][Wall Clock 266.44402775s] Trained 128 records in 0.087460895 seconds. Throughput is 1463.5111 records/second. Loss is 2.0951583. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6476039184537993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55552/60000][Iteration 2779][Wall Clock 266.531647685s] Trained 128 records in 0.087619935 seconds. Throughput is 1460.8547 records/second. Loss is 2.0998545. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6469031233456857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55680/60000][Iteration 2780][Wall Clock 266.616614317s] Trained 128 records in 0.084966632 seconds. Throughput is 1506.4738 records/second. Loss is 2.1212583. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.646202699126753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55808/60000][Iteration 2781][Wall Clock 266.701850599s] Trained 128 records in 0.085236282 seconds. Throughput is 1501.7079 records/second. Loss is 2.113738. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.645502645502645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 55936/60000][Iteration 2782][Wall Clock 266.785955445s] Trained 128 records in 0.084104846 seconds. Throughput is 1521.9099 records/second. Loss is 2.1166713. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6448029621793174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:42 INFO  DistriOptimizer$:408 - [Epoch 6 56064/60000][Iteration 2783][Wall Clock 266.86995223s] Trained 128 records in 0.083996785 seconds. Throughput is 1523.8678 records/second. Loss is 2.100394. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6441036488630354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56192/60000][Iteration 2784][Wall Clock 266.953880512s] Trained 128 records in 0.083928282 seconds. Throughput is 1525.1117 records/second. Loss is 2.0940995. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.643404705260376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56320/60000][Iteration 2785][Wall Clock 267.038391368s] Trained 128 records in 0.084510856 seconds. Throughput is 1514.5983 records/second. Loss is 2.0762413. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.642706131078224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56448/60000][Iteration 2786][Wall Clock 267.132882859s] Trained 128 records in 0.094491491 seconds. Throughput is 1354.6194 records/second. Loss is 2.1152523. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.642007926023778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56576/60000][Iteration 2787][Wall Clock 267.213798033s] Trained 128 records in 0.080915174 seconds. Throughput is 1581.9036 records/second. Loss is 2.0987282. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.641310089804543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56704/60000][Iteration 2788][Wall Clock 267.298687637s] Trained 128 records in 0.084889604 seconds. Throughput is 1507.8407 records/second. Loss is 2.0675912. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.640612622128334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56832/60000][Iteration 2789][Wall Clock 267.388559039s] Trained 128 records in 0.089871402 seconds. Throughput is 1424.2573 records/second. Loss is 2.0907986. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6399155227032733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 56960/60000][Iteration 2790][Wall Clock 267.473324543s] Trained 128 records in 0.084765504 seconds. Throughput is 1510.0483 records/second. Loss is 2.0902498. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6392187912377933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 57088/60000][Iteration 2791][Wall Clock 267.558511525s] Trained 128 records in 0.085186982 seconds. Throughput is 1502.577 records/second. Loss is 2.0690367. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.638522427440633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 57216/60000][Iteration 2792][Wall Clock 267.641518999s] Trained 128 records in 0.083007474 seconds. Throughput is 1542.0298 records/second. Loss is 2.0648365. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.637826431020839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 57344/60000][Iteration 2793][Wall Clock 267.726589174s] Trained 128 records in 0.085070175 seconds. Throughput is 1504.6401 records/second. Loss is 2.0907269. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6371308016877635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:43 INFO  DistriOptimizer$:408 - [Epoch 6 57472/60000][Iteration 2794][Wall Clock 267.821485727s] Trained 128 records in 0.094896553 seconds. Throughput is 1348.8372 records/second. Loss is 2.0876756. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6364355391510674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 57600/60000][Iteration 2795][Wall Clock 267.906965187s] Trained 128 records in 0.08547946 seconds. Throughput is 1497.4358 records/second. Loss is 2.082664. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.635740643120717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 57728/60000][Iteration 2796][Wall Clock 267.994532736s] Trained 128 records in 0.087567549 seconds. Throughput is 1461.7288 records/second. Loss is 2.0847785. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.635046113306983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 57856/60000][Iteration 2797][Wall Clock 268.077807897s] Trained 128 records in 0.083275161 seconds. Throughput is 1537.073 records/second. Loss is 2.0750759. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6343519494204424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 57984/60000][Iteration 2798][Wall Clock 268.162544917s] Trained 128 records in 0.08473702 seconds. Throughput is 1510.5559 records/second. Loss is 2.0835757. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.633658151171978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58112/60000][Iteration 2799][Wall Clock 268.247573399s] Trained 128 records in 0.085028482 seconds. Throughput is 1505.3779 records/second. Loss is 2.1193569. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.632964718272775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58240/60000][Iteration 2800][Wall Clock 268.341516724s] Trained 128 records in 0.093943325 seconds. Throughput is 1362.5236 records/second. Loss is 2.0786417. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6322716504343247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58368/60000][Iteration 2801][Wall Clock 268.424595374s] Trained 128 records in 0.08307865 seconds. Throughput is 1540.7086 records/second. Loss is 2.0884755. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.631578947368421E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58496/60000][Iteration 2802][Wall Clock 268.540648742s] Trained 128 records in 0.116053368 seconds. Throughput is 1102.9409 records/second. Loss is 2.0931127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6308866087871614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58624/60000][Iteration 2803][Wall Clock 268.625854982s] Trained 128 records in 0.08520624 seconds. Throughput is 1502.2374 records/second. Loss is 2.0946653. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.630194634402946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58752/60000][Iteration 2804][Wall Clock 268.720140273s] Trained 128 records in 0.094285291 seconds. Throughput is 1357.5818 records/second. Loss is 2.0861793. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6295030239284776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:44 INFO  DistriOptimizer$:408 - [Epoch 6 58880/60000][Iteration 2805][Wall Clock 268.826432586s] Trained 128 records in 0.106292313 seconds. Throughput is 1204.2263 records/second. Loss is 2.0989416. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.628811777076761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59008/60000][Iteration 2806][Wall Clock 268.913569109s] Trained 128 records in 0.087136523 seconds. Throughput is 1468.9592 records/second. Loss is 2.1045852. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6281208935611036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59136/60000][Iteration 2807][Wall Clock 269.000720835s] Trained 128 records in 0.087151726 seconds. Throughput is 1468.7029 records/second. Loss is 2.0924249. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.627430373095113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59264/60000][Iteration 2808][Wall Clock 269.085045662s] Trained 128 records in 0.084324827 seconds. Throughput is 1517.9396 records/second. Loss is 2.1150055. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.626740215392698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59392/60000][Iteration 2809][Wall Clock 269.171971888s] Trained 128 records in 0.086926226 seconds. Throughput is 1472.513 records/second. Loss is 2.07642. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.626050420168067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59520/60000][Iteration 2810][Wall Clock 269.256040853s] Trained 128 records in 0.084068965 seconds. Throughput is 1522.5596 records/second. Loss is 2.0563438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6253609871357313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59648/60000][Iteration 2811][Wall Clock 269.353926906s] Trained 128 records in 0.097886053 seconds. Throughput is 1307.6428 records/second. Loss is 2.1136153. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6246719160104987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59776/60000][Iteration 2812][Wall Clock 269.437191842s] Trained 128 records in 0.083264936 seconds. Throughput is 1537.2617 records/second. Loss is 2.1076431. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.623983206507478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 59904/60000][Iteration 2813][Wall Clock 269.522517287s] Trained 128 records in 0.085325445 seconds. Throughput is 1500.1387 records/second. Loss is 2.0765393. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6232948583420777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:408 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 269.6073251s] Trained 128 records in 0.084807813 seconds. Throughput is 1509.2949 records/second. Loss is 2.0985644. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6226068712300026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:45 INFO  DistriOptimizer$:452 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 269.6073251s] Epoch finished. Wall clock time is 270853.167421 ms
2019-10-14 23:15:45 INFO  DistriOptimizer$:111 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 269.6073251s] Validate model...
2019-10-14 23:15:46 INFO  DistriOptimizer$:178 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 269.6073251s] validate model throughput is 12390.706 records/second
2019-10-14 23:15:46 INFO  DistriOptimizer$:181 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 269.6073251s] Top1Accuracy is Accuracy(correct: 5276, count: 10000, accuracy: 0.5276)
2019-10-14 23:15:46 INFO  DistriOptimizer$:221 - [Wall Clock 270.853167421s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:15:46 INFO  DistriOptimizer$:226 - [Wall Clock 270.853167421s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:15:46 INFO  DistriOptimizer$:408 - [Epoch 7 128/60000][Iteration 2815][Wall Clock 270.949396641s] Trained 128 records in 0.09622922 seconds. Throughput is 1330.1573 records/second. Loss is 2.072693. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6219192448872575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:46 INFO  DistriOptimizer$:408 - [Epoch 7 256/60000][Iteration 2816][Wall Clock 271.035655328s] Trained 128 records in 0.086258687 seconds. Throughput is 1483.9086 records/second. Loss is 2.0771008. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.621231979030144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:46 INFO  DistriOptimizer$:408 - [Epoch 7 384/60000][Iteration 2817][Wall Clock 271.129403958s] Trained 128 records in 0.09374863 seconds. Throughput is 1365.3533 records/second. Loss is 2.0969434. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.620545073375262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:46 INFO  DistriOptimizer$:408 - [Epoch 7 512/60000][Iteration 2818][Wall Clock 271.20892491s] Trained 128 records in 0.079520952 seconds. Throughput is 1609.6385 records/second. Loss is 2.0726628. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.619858527639507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 640/60000][Iteration 2819][Wall Clock 271.293821014s] Trained 128 records in 0.084896104 seconds. Throughput is 1507.7252 records/second. Loss is 2.0735939. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6191723415400735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 768/60000][Iteration 2820][Wall Clock 271.376040289s] Trained 128 records in 0.082219275 seconds. Throughput is 1556.8126 records/second. Loss is 2.0725842. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.618486514794449E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 896/60000][Iteration 2821][Wall Clock 271.461256724s] Trained 128 records in 0.085216435 seconds. Throughput is 1502.0577 records/second. Loss is 2.1119235. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.617801047120419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1024/60000][Iteration 2822][Wall Clock 271.545115704s] Trained 128 records in 0.08385898 seconds. Throughput is 1526.372 records/second. Loss is 2.066246. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6171159382360636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1152/60000][Iteration 2823][Wall Clock 271.628751353s] Trained 128 records in 0.083635649 seconds. Throughput is 1530.4479 records/second. Loss is 2.0763497. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6164311878597594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1280/60000][Iteration 2824][Wall Clock 271.712670828s] Trained 128 records in 0.083919475 seconds. Throughput is 1525.2717 records/second. Loss is 2.0773127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6157467957101755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1408/60000][Iteration 2825][Wall Clock 271.793900286s] Trained 128 records in 0.081229458 seconds. Throughput is 1575.7831 records/second. Loss is 2.0961618. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6150627615062765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1536/60000][Iteration 2826][Wall Clock 271.876788868s] Trained 128 records in 0.082888582 seconds. Throughput is 1544.2417 records/second. Loss is 2.1157854. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.61437908496732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1664/60000][Iteration 2827][Wall Clock 271.961025165s] Trained 128 records in 0.084236297 seconds. Throughput is 1519.535 records/second. Loss is 2.0933013. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6136957658128593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1792/60000][Iteration 2828][Wall Clock 272.045019398s] Trained 128 records in 0.083994233 seconds. Throughput is 1523.9142 records/second. Loss is 2.118871. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6130128037627387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 1920/60000][Iteration 2829][Wall Clock 272.127584856s] Trained 128 records in 0.082565458 seconds. Throughput is 1550.2852 records/second. Loss is 2.0895412. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6123301985370953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:47 INFO  DistriOptimizer$:408 - [Epoch 7 2048/60000][Iteration 2830][Wall Clock 272.20908148s] Trained 128 records in 0.081496624 seconds. Throughput is 1570.6172 records/second. Loss is 2.1005194. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6116479498563595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2176/60000][Iteration 2831][Wall Clock 272.292869023s] Trained 128 records in 0.083787543 seconds. Throughput is 1527.6733 records/second. Loss is 2.092006. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.610966057441253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2304/60000][Iteration 2832][Wall Clock 272.37616213s] Trained 128 records in 0.083293107 seconds. Throughput is 1536.7417 records/second. Loss is 2.0803435. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6102845210127906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2432/60000][Iteration 2833][Wall Clock 272.461622951s] Trained 128 records in 0.085460821 seconds. Throughput is 1497.7623 records/second. Loss is 2.0887666. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.609603340292276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2560/60000][Iteration 2834][Wall Clock 272.549286971s] Trained 128 records in 0.08766402 seconds. Throughput is 1460.1201 records/second. Loss is 2.0918915. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6089225150013044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2688/60000][Iteration 2835][Wall Clock 272.639391777s] Trained 128 records in 0.090104806 seconds. Throughput is 1420.568 records/second. Loss is 2.0719192. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.608242044861763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2816/60000][Iteration 2836][Wall Clock 272.717941229s] Trained 128 records in 0.078549452 seconds. Throughput is 1629.5468 records/second. Loss is 2.103883. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.607561929595828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 2944/60000][Iteration 2837][Wall Clock 272.796712728s] Trained 128 records in 0.078771499 seconds. Throughput is 1624.9531 records/second. Loss is 2.0795596. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6068821689259646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 3072/60000][Iteration 2838][Wall Clock 272.882382756s] Trained 128 records in 0.085670028 seconds. Throughput is 1494.1047 records/second. Loss is 2.0918078. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6062027625749283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 3200/60000][Iteration 2839][Wall Clock 272.968561492s] Trained 128 records in 0.086178736 seconds. Throughput is 1485.2852 records/second. Loss is 2.0844257. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.605523710265763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 3328/60000][Iteration 2840][Wall Clock 273.05182557s] Trained 128 records in 0.083264078 seconds. Throughput is 1537.2776 records/second. Loss is 2.0916967. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6048450117218026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:48 INFO  DistriOptimizer$:408 - [Epoch 7 3456/60000][Iteration 2841][Wall Clock 273.136835594s] Trained 128 records in 0.085010024 seconds. Throughput is 1505.7048 records/second. Loss is 2.080852. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6041666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 3584/60000][Iteration 2842][Wall Clock 273.22704227s] Trained 128 records in 0.090206676 seconds. Throughput is 1418.9637 records/second. Loss is 2.10391. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.603488674824264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 3712/60000][Iteration 2843][Wall Clock 273.304582785s] Trained 128 records in 0.077540515 seconds. Throughput is 1650.7499 records/second. Loss is 2.096121. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.602811035918792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 3840/60000][Iteration 2844][Wall Clock 273.388928248s] Trained 128 records in 0.084345463 seconds. Throughput is 1517.5684 records/second. Loss is 2.113064. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6021337496747333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 3968/60000][Iteration 2845][Wall Clock 273.475439286s] Trained 128 records in 0.086511038 seconds. Throughput is 1479.58 records/second. Loss is 2.0617175. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.6014568158168577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4096/60000][Iteration 2846][Wall Clock 273.559848327s] Trained 128 records in 0.084409041 seconds. Throughput is 1516.4252 records/second. Loss is 2.06596. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.600780234070221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4224/60000][Iteration 2847][Wall Clock 273.644664969s] Trained 128 records in 0.084816642 seconds. Throughput is 1509.1378 records/second. Loss is 2.0531762. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.600104004160166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4352/60000][Iteration 2848][Wall Clock 273.728393569s] Trained 128 records in 0.0837286 seconds. Throughput is 1528.7489 records/second. Loss is 2.0995872. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5994281258123216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4480/60000][Iteration 2849][Wall Clock 273.812569805s] Trained 128 records in 0.084176236 seconds. Throughput is 1520.6193 records/second. Loss is 2.0870671. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.598752598752599E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4608/60000][Iteration 2850][Wall Clock 273.899931824s] Trained 128 records in 0.087362019 seconds. Throughput is 1465.1676 records/second. Loss is 2.0865724. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5980774227071964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4736/60000][Iteration 2851][Wall Clock 273.985424265s] Trained 128 records in 0.085492441 seconds. Throughput is 1497.2084 records/second. Loss is 2.0820727. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5974025974025974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4864/60000][Iteration 2852][Wall Clock 274.070349065s] Trained 128 records in 0.0849248 seconds. Throughput is 1507.2157 records/second. Loss is 2.106109. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5967281225655674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:49 INFO  DistriOptimizer$:408 - [Epoch 7 4992/60000][Iteration 2853][Wall Clock 274.153877032s] Trained 128 records in 0.083527967 seconds. Throughput is 1532.4209 records/second. Loss is 2.084871. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5960539979231567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5120/60000][Iteration 2854][Wall Clock 274.239530652s] Trained 128 records in 0.08565362 seconds. Throughput is 1494.391 records/second. Loss is 2.0858727. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.595380223202699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5248/60000][Iteration 2855][Wall Clock 274.323751056s] Trained 128 records in 0.084220404 seconds. Throughput is 1519.8218 records/second. Loss is 2.0931318. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.594706798131811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5376/60000][Iteration 2856][Wall Clock 274.409718282s] Trained 128 records in 0.085967226 seconds. Throughput is 1488.9395 records/second. Loss is 2.0998428. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5940337224383917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5504/60000][Iteration 2857][Wall Clock 274.501614641s] Trained 128 records in 0.091896359 seconds. Throughput is 1392.8734 records/second. Loss is 2.1071918. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5933609958506224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5632/60000][Iteration 2858][Wall Clock 274.585822896s] Trained 128 records in 0.084208255 seconds. Throughput is 1520.0409 records/second. Loss is 2.0888069. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5926886180969663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5760/60000][Iteration 2859][Wall Clock 274.670006323s] Trained 128 records in 0.084183427 seconds. Throughput is 1520.4894 records/second. Loss is 2.0530663. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.592016588906169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 5888/60000][Iteration 2860][Wall Clock 274.761388784s] Trained 128 records in 0.091382461 seconds. Throughput is 1400.7064 records/second. Loss is 2.090243. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.591344908007256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 6016/60000][Iteration 2861][Wall Clock 274.841470708s] Trained 128 records in 0.080081924 seconds. Throughput is 1598.3632 records/second. Loss is 2.0816011. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5906735751295336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 6144/60000][Iteration 2862][Wall Clock 274.92070338s] Trained 128 records in 0.079232672 seconds. Throughput is 1615.4952 records/second. Loss is 2.0754478. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.59000259000259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 6272/60000][Iteration 2863][Wall Clock 275.008167958s] Trained 128 records in 0.087464578 seconds. Throughput is 1463.4496 records/second. Loss is 2.1074557. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.589331952356292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 6400/60000][Iteration 2864][Wall Clock 275.096954808s] Trained 128 records in 0.08878685 seconds. Throughput is 1441.6549 records/second. Loss is 2.073995. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.588661661920787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:50 INFO  DistriOptimizer$:408 - [Epoch 7 6528/60000][Iteration 2865][Wall Clock 275.182701338s] Trained 128 records in 0.08574653 seconds. Throughput is 1492.7719 records/second. Loss is 2.0807111. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.587991718426501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 6656/60000][Iteration 2866][Wall Clock 275.269049579s] Trained 128 records in 0.086348241 seconds. Throughput is 1482.3695 records/second. Loss is 2.0900948. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.58732212160414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 6784/60000][Iteration 2867][Wall Clock 275.3634872s] Trained 128 records in 0.094437621 seconds. Throughput is 1355.3921 records/second. Loss is 2.1250503. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.586652871184687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 6912/60000][Iteration 2868][Wall Clock 275.447999358s] Trained 128 records in 0.084512158 seconds. Throughput is 1514.575 records/second. Loss is 2.0993748. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.585983966899405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7040/60000][Iteration 2869][Wall Clock 275.534503572s] Trained 128 records in 0.086504214 seconds. Throughput is 1479.6967 records/second. Loss is 2.0803266. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.585315408479835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7168/60000][Iteration 2870][Wall Clock 275.618345408s] Trained 128 records in 0.083841836 seconds. Throughput is 1526.6841 records/second. Loss is 2.066296. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.584647195657793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7296/60000][Iteration 2871][Wall Clock 275.702622713s] Trained 128 records in 0.084277305 seconds. Throughput is 1518.7957 records/second. Loss is 2.086399. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5839793281653745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7424/60000][Iteration 2872][Wall Clock 275.789598049s] Trained 128 records in 0.086975336 seconds. Throughput is 1471.6816 records/second. Loss is 2.0619006. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.583311805734952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7552/60000][Iteration 2873][Wall Clock 275.874046053s] Trained 128 records in 0.084448004 seconds. Throughput is 1515.7256 records/second. Loss is 2.0899897. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5826446280991736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7680/60000][Iteration 2874][Wall Clock 275.956480031s] Trained 128 records in 0.082433978 seconds. Throughput is 1552.7578 records/second. Loss is 2.097467. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.581977794990963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7808/60000][Iteration 2875][Wall Clock 276.042574109s] Trained 128 records in 0.086094078 seconds. Throughput is 1486.7456 records/second. Loss is 2.0871565. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.581311306143521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:51 INFO  DistriOptimizer$:408 - [Epoch 7 7936/60000][Iteration 2876][Wall Clock 276.126937452s] Trained 128 records in 0.084363343 seconds. Throughput is 1517.2467 records/second. Loss is 2.0813375. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5806451612903227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8064/60000][Iteration 2877][Wall Clock 276.212205955s] Trained 128 records in 0.085268503 seconds. Throughput is 1501.1404 records/second. Loss is 2.0945928. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.579979360165119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8192/60000][Iteration 2878][Wall Clock 276.295866235s] Trained 128 records in 0.08366028 seconds. Throughput is 1529.9972 records/second. Loss is 2.0704. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.579313902501934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8320/60000][Iteration 2879][Wall Clock 276.379883257s] Trained 128 records in 0.084017022 seconds. Throughput is 1523.5007 records/second. Loss is 2.089943. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5786487880350697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8448/60000][Iteration 2880][Wall Clock 276.464872868s] Trained 128 records in 0.084989611 seconds. Throughput is 1506.0665 records/second. Loss is 2.0629818. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.577984016499098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8576/60000][Iteration 2881][Wall Clock 276.548112328s] Trained 128 records in 0.08323946 seconds. Throughput is 1537.7323 records/second. Loss is 2.0565622. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.577319587628866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8704/60000][Iteration 2882][Wall Clock 276.630443826s] Trained 128 records in 0.082331498 seconds. Throughput is 1554.6904 records/second. Loss is 2.0943692. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.576655501159495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8832/60000][Iteration 2883][Wall Clock 276.716231617s] Trained 128 records in 0.085787791 seconds. Throughput is 1492.0538 records/second. Loss is 2.0701146. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5759917568263783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 8960/60000][Iteration 2884][Wall Clock 276.806443288s] Trained 128 records in 0.090211671 seconds. Throughput is 1418.8851 records/second. Loss is 2.096051. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.575328354365182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 9088/60000][Iteration 2885][Wall Clock 276.887857048s] Trained 128 records in 0.08141376 seconds. Throughput is 1572.2158 records/second. Loss is 2.0362363. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5746652935118434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 9216/60000][Iteration 2886][Wall Clock 276.971860325s] Trained 128 records in 0.084003277 seconds. Throughput is 1523.7501 records/second. Loss is 2.1084418. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.574002574002574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 9344/60000][Iteration 2887][Wall Clock 277.048814421s] Trained 128 records in 0.076954096 seconds. Throughput is 1663.3292 records/second. Loss is 2.0871985. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.573340195573855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:52 INFO  DistriOptimizer$:408 - [Epoch 7 9472/60000][Iteration 2888][Wall Clock 277.130289385s] Trained 128 records in 0.081474964 seconds. Throughput is 1571.0347 records/second. Loss is 2.0799232. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.572678157962439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 9600/60000][Iteration 2889][Wall Clock 277.215645091s] Trained 128 records in 0.085355706 seconds. Throughput is 1499.6068 records/second. Loss is 2.0728078. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.57201646090535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 9728/60000][Iteration 2890][Wall Clock 277.29832551s] Trained 128 records in 0.082680419 seconds. Throughput is 1548.1295 records/second. Loss is 2.063619. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5713551041398817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 9856/60000][Iteration 2891][Wall Clock 277.379130255s] Trained 128 records in 0.080804745 seconds. Throughput is 1584.0654 records/second. Loss is 2.074068. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.570694087403599E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 9984/60000][Iteration 2892][Wall Clock 277.469661883s] Trained 128 records in 0.090531628 seconds. Throughput is 1413.8706 records/second. Loss is 2.093914. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5700334104343357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10112/60000][Iteration 2893][Wall Clock 277.549983509s] Trained 128 records in 0.080321626 seconds. Throughput is 1593.5933 records/second. Loss is 2.0979385. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5693730729701953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10240/60000][Iteration 2894][Wall Clock 277.633768888s] Trained 128 records in 0.083785379 seconds. Throughput is 1527.7129 records/second. Loss is 2.0971723. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5687130747495504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10368/60000][Iteration 2895][Wall Clock 277.726598346s] Trained 128 records in 0.092829458 seconds. Throughput is 1378.8727 records/second. Loss is 2.0811477. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5680534155110427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10496/60000][Iteration 2896][Wall Clock 277.810161918s] Trained 128 records in 0.083563572 seconds. Throughput is 1531.768 records/second. Loss is 2.0925958. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5673940949935817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10624/60000][Iteration 2897][Wall Clock 277.892637632s] Trained 128 records in 0.082475714 seconds. Throughput is 1551.972 records/second. Loss is 2.1040695. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.566735112936345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10752/60000][Iteration 2898][Wall Clock 277.975992548s] Trained 128 records in 0.083354916 seconds. Throughput is 1535.6023 records/second. Loss is 2.0707502. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5660764690787786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 10880/60000][Iteration 2899][Wall Clock 278.059358297s] Trained 128 records in 0.083365749 seconds. Throughput is 1535.4028 records/second. Loss is 2.080945. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.565418163160595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:53 INFO  DistriOptimizer$:408 - [Epoch 7 11008/60000][Iteration 2900][Wall Clock 278.145342517s] Trained 128 records in 0.08598422 seconds. Throughput is 1488.6451 records/second. Loss is 2.0703566. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5647601949217746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11136/60000][Iteration 2901][Wall Clock 278.229074012s] Trained 128 records in 0.083731495 seconds. Throughput is 1528.696 records/second. Loss is 2.104111. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.564102564102564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11264/60000][Iteration 2902][Wall Clock 278.31529078s] Trained 128 records in 0.086216768 seconds. Throughput is 1484.63 records/second. Loss is 2.0511928. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.563445270443476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11392/60000][Iteration 2903][Wall Clock 278.400539633s] Trained 128 records in 0.085248853 seconds. Throughput is 1501.4866 records/second. Loss is 2.1128728. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5627883136852895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11520/60000][Iteration 2904][Wall Clock 278.485970681s] Trained 128 records in 0.085431048 seconds. Throughput is 1498.2843 records/second. Loss is 2.0684214. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5621316935690495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11648/60000][Iteration 2905][Wall Clock 278.57157568s] Trained 128 records in 0.085604999 seconds. Throughput is 1495.2399 records/second. Loss is 2.0767484. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5614754098360657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11776/60000][Iteration 2906][Wall Clock 278.661182919s] Trained 128 records in 0.089607239 seconds. Throughput is 1428.456 records/second. Loss is 2.0879393. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5608194622279127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 11904/60000][Iteration 2907][Wall Clock 278.747214489s] Trained 128 records in 0.08603157 seconds. Throughput is 1487.8259 records/second. Loss is 2.0872712. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.560163850486431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 12032/60000][Iteration 2908][Wall Clock 278.833487576s] Trained 128 records in 0.086273087 seconds. Throughput is 1483.6608 records/second. Loss is 2.0367398. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.559508574353724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 12160/60000][Iteration 2909][Wall Clock 278.925705343s] Trained 128 records in 0.092217767 seconds. Throughput is 1388.0189 records/second. Loss is 2.0423012. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5588536335721597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 12288/60000][Iteration 2910][Wall Clock 279.010314459s] Trained 128 records in 0.084609116 seconds. Throughput is 1512.8394 records/second. Loss is 2.0955367. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5581990278843696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 12416/60000][Iteration 2911][Wall Clock 279.094386896s] Trained 128 records in 0.084072437 seconds. Throughput is 1522.4967 records/second. Loss is 2.077746. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.557544757033248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:54 INFO  DistriOptimizer$:408 - [Epoch 7 12544/60000][Iteration 2912][Wall Clock 279.176121112s] Trained 128 records in 0.081734216 seconds. Throughput is 1566.0515 records/second. Loss is 2.0535438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5568908207619537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 12672/60000][Iteration 2913][Wall Clock 279.260833947s] Trained 128 records in 0.084712835 seconds. Throughput is 1510.9872 records/second. Loss is 2.0699637. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.556237218813906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 12800/60000][Iteration 2914][Wall Clock 279.345819316s] Trained 128 records in 0.084985369 seconds. Throughput is 1506.1416 records/second. Loss is 2.084039. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.555583950932788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 12928/60000][Iteration 2915][Wall Clock 279.428027743s] Trained 128 records in 0.082208427 seconds. Throughput is 1557.0181 records/second. Loss is 2.063683. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5549310168625444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13056/60000][Iteration 2916][Wall Clock 279.510890598s] Trained 128 records in 0.082862855 seconds. Throughput is 1544.7211 records/second. Loss is 2.0763862. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.554278416347382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13184/60000][Iteration 2917][Wall Clock 279.600383796s] Trained 128 records in 0.089493198 seconds. Throughput is 1430.2762 records/second. Loss is 2.036499. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.553626149131767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13312/60000][Iteration 2918][Wall Clock 279.685828611s] Trained 128 records in 0.085444815 seconds. Throughput is 1498.043 records/second. Loss is 2.0864236. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5529742149604285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13440/60000][Iteration 2919][Wall Clock 279.768600878s] Trained 128 records in 0.082772267 seconds. Throughput is 1546.4116 records/second. Loss is 2.1045702. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5523226135783564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13568/60000][Iteration 2920][Wall Clock 279.850976031s] Trained 128 records in 0.082375153 seconds. Throughput is 1553.8666 records/second. Loss is 2.0701008. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5516713447307985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13696/60000][Iteration 2921][Wall Clock 279.934410325s] Trained 128 records in 0.083434294 seconds. Throughput is 1534.1414 records/second. Loss is 2.0968647. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5510204081632655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13824/60000][Iteration 2922][Wall Clock 280.017644422s] Trained 128 records in 0.083234097 seconds. Throughput is 1537.8313 records/second. Loss is 2.0867124. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.550369803621525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:55 INFO  DistriOptimizer$:408 - [Epoch 7 13952/60000][Iteration 2923][Wall Clock 280.103011599s] Trained 128 records in 0.085367177 seconds. Throughput is 1499.4053 records/second. Loss is 2.0910964. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5497195308516065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14080/60000][Iteration 2924][Wall Clock 280.186063s] Trained 128 records in 0.083051401 seconds. Throughput is 1541.2142 records/second. Loss is 2.093067. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.549069589599796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14208/60000][Iteration 2925][Wall Clock 280.269538627s] Trained 128 records in 0.083475627 seconds. Throughput is 1533.3817 records/second. Loss is 2.111913. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5484199796126404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14336/60000][Iteration 2926][Wall Clock 280.36571824s] Trained 128 records in 0.096179613 seconds. Throughput is 1330.8434 records/second. Loss is 2.0718734. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5477707006369424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14464/60000][Iteration 2927][Wall Clock 280.44911958s] Trained 128 records in 0.08340134 seconds. Throughput is 1534.7476 records/second. Loss is 2.069931. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5471217524197657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14592/60000][Iteration 2928][Wall Clock 280.533427264s] Trained 128 records in 0.084307684 seconds. Throughput is 1518.2483 records/second. Loss is 2.0624588. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5464731347084286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14720/60000][Iteration 2929][Wall Clock 280.617928451s] Trained 128 records in 0.084501187 seconds. Throughput is 1514.7716 records/second. Loss is 2.0848713. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5458248472505095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14848/60000][Iteration 2930][Wall Clock 280.702438388s] Trained 128 records in 0.084509937 seconds. Throughput is 1514.6147 records/second. Loss is 2.0801532. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5451768897938407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 14976/60000][Iteration 2931][Wall Clock 280.787041109s] Trained 128 records in 0.084602721 seconds. Throughput is 1512.9537 records/second. Loss is 2.0835788. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.544529262086514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 15104/60000][Iteration 2932][Wall Clock 280.86981115s] Trained 128 records in 0.082770041 seconds. Throughput is 1546.4532 records/second. Loss is 2.091254. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.543881963876876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 15232/60000][Iteration 2933][Wall Clock 280.953375858s] Trained 128 records in 0.083564708 seconds. Throughput is 1531.7472 records/second. Loss is 2.0594757. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.54323499491353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 15360/60000][Iteration 2934][Wall Clock 281.043905497s] Trained 128 records in 0.090529639 seconds. Throughput is 1413.9016 records/second. Loss is 2.0964324. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.542588354945334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:56 INFO  DistriOptimizer$:408 - [Epoch 7 15488/60000][Iteration 2935][Wall Clock 281.12627816s] Trained 128 records in 0.082372663 seconds. Throughput is 1553.9136 records/second. Loss is 2.0774708. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.541942043721403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 15616/60000][Iteration 2936][Wall Clock 281.20867182s] Trained 128 records in 0.08239366 seconds. Throughput is 1553.5176 records/second. Loss is 2.0565736. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5412960609911054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 15744/60000][Iteration 2937][Wall Clock 281.290171906s] Trained 128 records in 0.081500086 seconds. Throughput is 1570.5505 records/second. Loss is 2.1079793. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5406504065040653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 15872/60000][Iteration 2938][Wall Clock 281.376895844s] Trained 128 records in 0.086723938 seconds. Throughput is 1475.9478 records/second. Loss is 2.0876737. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.54000508001016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16000/60000][Iteration 2939][Wall Clock 281.466136834s] Trained 128 records in 0.08924099 seconds. Throughput is 1434.3185 records/second. Loss is 2.0575645. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5393600812595224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16128/60000][Iteration 2940][Wall Clock 281.553161886s] Trained 128 records in 0.087025052 seconds. Throughput is 1470.8408 records/second. Loss is 2.083766. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.538715410002539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16256/60000][Iteration 2941][Wall Clock 281.639877858s] Trained 128 records in 0.086715972 seconds. Throughput is 1476.0833 records/second. Loss is 2.0803297. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.538071065989848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16384/60000][Iteration 2942][Wall Clock 281.738020693s] Trained 128 records in 0.098142835 seconds. Throughput is 1304.2216 records/second. Loss is 2.065999. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5374270489723417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16512/60000][Iteration 2943][Wall Clock 281.82641979s] Trained 128 records in 0.088399097 seconds. Throughput is 1447.9786 records/second. Loss is 2.0900385. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.536783358701167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16640/60000][Iteration 2944][Wall Clock 281.911740221s] Trained 128 records in 0.085320431 seconds. Throughput is 1500.2269 records/second. Loss is 2.0574763. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.53613999492772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16768/60000][Iteration 2945][Wall Clock 281.995960862s] Trained 128 records in 0.084220641 seconds. Throughput is 1519.8175 records/second. Loss is 2.0963528. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.535496957403651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:57 INFO  DistriOptimizer$:408 - [Epoch 7 16896/60000][Iteration 2946][Wall Clock 282.087797509s] Trained 128 records in 0.091836647 seconds. Throughput is 1393.7792 records/second. Loss is 2.0792358. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.534854245880862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17024/60000][Iteration 2947][Wall Clock 282.171836172s] Trained 128 records in 0.084038663 seconds. Throughput is 1523.1085 records/second. Loss is 2.0709095. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5342118601115053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17152/60000][Iteration 2948][Wall Clock 282.255891853s] Trained 128 records in 0.084055681 seconds. Throughput is 1522.8 records/second. Loss is 2.074435. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.533569799847986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17280/60000][Iteration 2949][Wall Clock 282.33962245s] Trained 128 records in 0.083730597 seconds. Throughput is 1528.7124 records/second. Loss is 2.099085. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5329280648429586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17408/60000][Iteration 2950][Wall Clock 282.425772298s] Trained 128 records in 0.086149848 seconds. Throughput is 1485.7832 records/second. Loss is 2.1206157. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5322866548493293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17536/60000][Iteration 2951][Wall Clock 282.510250476s] Trained 128 records in 0.084478178 seconds. Throughput is 1515.1842 records/second. Loss is 2.082612. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5316455696202533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17664/60000][Iteration 2952][Wall Clock 282.594191353s] Trained 128 records in 0.083940877 seconds. Throughput is 1524.8828 records/second. Loss is 2.0698776. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.531004808909137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17792/60000][Iteration 2953][Wall Clock 282.678478281s] Trained 128 records in 0.084286928 seconds. Throughput is 1518.6222 records/second. Loss is 2.0539045. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5303643724696357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 17920/60000][Iteration 2954][Wall Clock 282.761712501s] Trained 128 records in 0.08323422 seconds. Throughput is 1537.829 records/second. Loss is 2.0776458. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.529724260055654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 18048/60000][Iteration 2955][Wall Clock 282.844138404s] Trained 128 records in 0.082425903 seconds. Throughput is 1552.9099 records/second. Loss is 2.0805073. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5290844714213456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 18176/60000][Iteration 2956][Wall Clock 282.928346273s] Trained 128 records in 0.084207869 seconds. Throughput is 1520.048 records/second. Loss is 2.0627573. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5284450063211124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 18304/60000][Iteration 2957][Wall Clock 283.013123105s] Trained 128 records in 0.084776832 seconds. Throughput is 1509.8464 records/second. Loss is 2.0942218. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.527805864509606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:58 INFO  DistriOptimizer$:408 - [Epoch 7 18432/60000][Iteration 2958][Wall Clock 283.104950244s] Trained 128 records in 0.091827139 seconds. Throughput is 1393.9235 records/second. Loss is 2.0803983. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.527167045741724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 18560/60000][Iteration 2959][Wall Clock 283.197155042s] Trained 128 records in 0.092204798 seconds. Throughput is 1388.2141 records/second. Loss is 2.0808218. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5265285497726126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 18688/60000][Iteration 2960][Wall Clock 283.274569345s] Trained 128 records in 0.077414303 seconds. Throughput is 1653.4412 records/second. Loss is 2.0919776. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5258903763576663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 18816/60000][Iteration 2961][Wall Clock 283.355651155s] Trained 128 records in 0.08108181 seconds. Throughput is 1578.6525 records/second. Loss is 2.0648549. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.525252525252525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 18944/60000][Iteration 2962][Wall Clock 283.443583157s] Trained 128 records in 0.087932002 seconds. Throughput is 1455.6702 records/second. Loss is 2.0929875. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5246149962130775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19072/60000][Iteration 2963][Wall Clock 283.527109547s] Trained 128 records in 0.08352639 seconds. Throughput is 1532.4498 records/second. Loss is 2.0685332. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.523977788995457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19200/60000][Iteration 2964][Wall Clock 283.612682004s] Trained 128 records in 0.085572457 seconds. Throughput is 1495.8083 records/second. Loss is 2.0842376. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5233409033560434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19328/60000][Iteration 2965][Wall Clock 283.723445087s] Trained 128 records in 0.110763083 seconds. Throughput is 1155.6198 records/second. Loss is 2.0888565. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.522704339051463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19456/60000][Iteration 2966][Wall Clock 283.820307386s] Trained 128 records in 0.096862299 seconds. Throughput is 1321.4635 records/second. Loss is 2.0598. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5220680958385876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19584/60000][Iteration 2967][Wall Clock 283.903502711s] Trained 128 records in 0.083195325 seconds. Throughput is 1538.548 records/second. Loss is 2.0806983. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.521432173474533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19712/60000][Iteration 2968][Wall Clock 283.990721137s] Trained 128 records in 0.087218426 seconds. Throughput is 1467.5798 records/second. Loss is 2.090247. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5207965717166626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:15:59 INFO  DistriOptimizer$:408 - [Epoch 7 19840/60000][Iteration 2969][Wall Clock 284.07630808s] Trained 128 records in 0.085586943 seconds. Throughput is 1495.5552 records/second. Loss is 2.0458004. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5201612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 19968/60000][Iteration 2970][Wall Clock 284.160504702s] Trained 128 records in 0.084196622 seconds. Throughput is 1520.2511 records/second. Loss is 2.0793948. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.519526329050139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20096/60000][Iteration 2971][Wall Clock 284.244962108s] Trained 128 records in 0.084457406 seconds. Throughput is 1515.5569 records/second. Loss is 2.06532. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5188916876574307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20224/60000][Iteration 2972][Wall Clock 284.331924756s] Trained 128 records in 0.086962648 seconds. Throughput is 1471.8964 records/second. Loss is 2.0800867. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.518257365902795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20352/60000][Iteration 2973][Wall Clock 284.417850572s] Trained 128 records in 0.085925816 seconds. Throughput is 1489.6571 records/second. Loss is 2.0994399. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5176233635448137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20480/60000][Iteration 2974][Wall Clock 284.502314584s] Trained 128 records in 0.084464012 seconds. Throughput is 1515.4382 records/second. Loss is 2.0710936. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.516989680342311E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20608/60000][Iteration 2975][Wall Clock 284.589721246s] Trained 128 records in 0.087406662 seconds. Throughput is 1464.4192 records/second. Loss is 2.0808024. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.516356316054353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20736/60000][Iteration 2976][Wall Clock 284.677521788s] Trained 128 records in 0.087800542 seconds. Throughput is 1457.8499 records/second. Loss is 2.1098588. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5157232704402514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20864/60000][Iteration 2977][Wall Clock 284.76444924s] Trained 128 records in 0.086927452 seconds. Throughput is 1472.4923 records/second. Loss is 2.0768833. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5150905432595576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 20992/60000][Iteration 2978][Wall Clock 284.850052654s] Trained 128 records in 0.085603414 seconds. Throughput is 1495.2675 records/second. Loss is 2.1046102. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5144581342720644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 21120/60000][Iteration 2979][Wall Clock 284.936387976s] Trained 128 records in 0.086335322 seconds. Throughput is 1482.5913 records/second. Loss is 2.0690522. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5138260432378077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 21248/60000][Iteration 2980][Wall Clock 285.022531256s] Trained 128 records in 0.08614328 seconds. Throughput is 1485.8966 records/second. Loss is 2.0733638. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5131942699170643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:00 INFO  DistriOptimizer$:408 - [Epoch 7 21376/60000][Iteration 2981][Wall Clock 285.107234093s] Trained 128 records in 0.084702837 seconds. Throughput is 1511.1655 records/second. Loss is 2.0618114. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.512562814070352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 21504/60000][Iteration 2982][Wall Clock 285.193654519s] Trained 128 records in 0.086420426 seconds. Throughput is 1481.1313 records/second. Loss is 2.088848. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.511931675458428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 21632/60000][Iteration 2983][Wall Clock 285.277507199s] Trained 128 records in 0.08385268 seconds. Throughput is 1526.4867 records/second. Loss is 2.0854168. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.51130085384229E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 21760/60000][Iteration 2984][Wall Clock 285.366739212s] Trained 128 records in 0.089232013 seconds. Throughput is 1434.4628 records/second. Loss is 2.0805452. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5106703489831785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 21888/60000][Iteration 2985][Wall Clock 285.450413041s] Trained 128 records in 0.083673829 seconds. Throughput is 1529.7495 records/second. Loss is 2.04789. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5100401606425706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22016/60000][Iteration 2986][Wall Clock 285.536178418s] Trained 128 records in 0.085765377 seconds. Throughput is 1492.4437 records/second. Loss is 2.0631135. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5094102885821835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22144/60000][Iteration 2987][Wall Clock 285.617235067s] Trained 128 records in 0.081056649 seconds. Throughput is 1579.1426 records/second. Loss is 2.064237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.508780732563974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22272/60000][Iteration 2988][Wall Clock 285.700896488s] Trained 128 records in 0.083661421 seconds. Throughput is 1529.9764 records/second. Loss is 2.0527477. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5081514923501377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22400/60000][Iteration 2989][Wall Clock 285.786600773s] Trained 128 records in 0.085704285 seconds. Throughput is 1493.5077 records/second. Loss is 2.0743837. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5075225677031093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22528/60000][Iteration 2990][Wall Clock 285.871644926s] Trained 128 records in 0.085044153 seconds. Throughput is 1505.1006 records/second. Loss is 2.0907464. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5068939583855606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22656/60000][Iteration 2991][Wall Clock 285.956535375s] Trained 128 records in 0.084890449 seconds. Throughput is 1507.8257 records/second. Loss is 2.1061215. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.506265664160401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22784/60000][Iteration 2992][Wall Clock 286.041925077s] Trained 128 records in 0.085389702 seconds. Throughput is 1499.0098 records/second. Loss is 2.0508301. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5056376847907793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:01 INFO  DistriOptimizer$:408 - [Epoch 7 22912/60000][Iteration 2993][Wall Clock 286.123928572s] Trained 128 records in 0.082003495 seconds. Throughput is 1560.909 records/second. Loss is 2.0828693. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.50501002004008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23040/60000][Iteration 2994][Wall Clock 286.208099225s] Trained 128 records in 0.084170653 seconds. Throughput is 1520.72 records/second. Loss is 2.0757802. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.504382669671926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23168/60000][Iteration 2995][Wall Clock 286.294851133s] Trained 128 records in 0.086751908 seconds. Throughput is 1475.4719 records/second. Loss is 2.0651658. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.503755633450175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23296/60000][Iteration 2996][Wall Clock 286.381508929s] Trained 128 records in 0.086657796 seconds. Throughput is 1477.0743 records/second. Loss is 2.0711741. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5031289111389235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23424/60000][Iteration 2997][Wall Clock 286.468795534s] Trained 128 records in 0.087286605 seconds. Throughput is 1466.4335 records/second. Loss is 2.0776076. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5025025025025025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23552/60000][Iteration 2998][Wall Clock 286.555116472s] Trained 128 records in 0.086320938 seconds. Throughput is 1482.8384 records/second. Loss is 2.0849977. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.501876407305479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23680/60000][Iteration 2999][Wall Clock 286.640879818s] Trained 128 records in 0.085763346 seconds. Throughput is 1492.4791 records/second. Loss is 2.1077096. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.501250625312656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23808/60000][Iteration 3000][Wall Clock 286.727412651s] Trained 128 records in 0.086532833 seconds. Throughput is 1479.2074 records/second. Loss is 2.0692515. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.500625156289072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 23936/60000][Iteration 3001][Wall Clock 286.812142464s] Trained 128 records in 0.084729813 seconds. Throughput is 1510.6843 records/second. Loss is 2.0909271. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.5E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 24064/60000][Iteration 3002][Wall Clock 286.899762206s] Trained 128 records in 0.087619742 seconds. Throughput is 1460.8579 records/second. Loss is 2.0655832. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4993751562109475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 24192/60000][Iteration 3003][Wall Clock 286.985537142s] Trained 128 records in 0.085774936 seconds. Throughput is 1492.2775 records/second. Loss is 2.0679367. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4987506246876555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:02 INFO  DistriOptimizer$:408 - [Epoch 7 24320/60000][Iteration 3004][Wall Clock 287.068320275s] Trained 128 records in 0.082783133 seconds. Throughput is 1546.2087 records/second. Loss is 2.0665598. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.498126405196103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 24448/60000][Iteration 3005][Wall Clock 287.154340971s] Trained 128 records in 0.086020696 seconds. Throughput is 1488.014 records/second. Loss is 2.0764837. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.497502497502498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 24576/60000][Iteration 3006][Wall Clock 287.237825646s] Trained 128 records in 0.083484675 seconds. Throughput is 1533.2156 records/second. Loss is 2.0757308. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4968789013732833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 24704/60000][Iteration 3007][Wall Clock 287.325147857s] Trained 128 records in 0.087322211 seconds. Throughput is 1465.8354 records/second. Loss is 2.070884. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.496255616575137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 24832/60000][Iteration 3008][Wall Clock 287.410899113s] Trained 128 records in 0.085751256 seconds. Throughput is 1492.6895 records/second. Loss is 2.1041508. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.495632642874969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 24960/60000][Iteration 3009][Wall Clock 287.509786021s] Trained 128 records in 0.098886908 seconds. Throughput is 1294.408 records/second. Loss is 2.0939295. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.49500998003992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25088/60000][Iteration 3010][Wall Clock 287.59266866s] Trained 128 records in 0.082882639 seconds. Throughput is 1544.3524 records/second. Loss is 2.0746055. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4943876278373656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25216/60000][Iteration 3011][Wall Clock 287.678513567s] Trained 128 records in 0.085844907 seconds. Throughput is 1491.0612 records/second. Loss is 2.0901525. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.493765586034913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25344/60000][Iteration 3012][Wall Clock 287.765457522s] Trained 128 records in 0.086943955 seconds. Throughput is 1472.2128 records/second. Loss is 2.078011. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.493143854400399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25472/60000][Iteration 3013][Wall Clock 287.849564237s] Trained 128 records in 0.084106715 seconds. Throughput is 1521.8761 records/second. Loss is 2.0862012. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.492522432701894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25600/60000][Iteration 3014][Wall Clock 287.935640419s] Trained 128 records in 0.086076182 seconds. Throughput is 1487.0548 records/second. Loss is 2.113573. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4919013207077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25728/60000][Iteration 3015][Wall Clock 288.020192605s] Trained 128 records in 0.084552186 seconds. Throughput is 1513.858 records/second. Loss is 2.0499012. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4912805181863477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:03 INFO  DistriOptimizer$:408 - [Epoch 7 25856/60000][Iteration 3016][Wall Clock 288.105092484s] Trained 128 records in 0.084899879 seconds. Throughput is 1507.6582 records/second. Loss is 2.0799809. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4906600249066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 25984/60000][Iteration 3017][Wall Clock 288.199336302s] Trained 128 records in 0.094243818 seconds. Throughput is 1358.1793 records/second. Loss is 2.087341. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.49003984063745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26112/60000][Iteration 3018][Wall Clock 288.284829019s] Trained 128 records in 0.085492717 seconds. Throughput is 1497.2036 records/second. Loss is 2.0872664. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.489419965148121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26240/60000][Iteration 3019][Wall Clock 288.370990819s] Trained 128 records in 0.0861618 seconds. Throughput is 1485.5771 records/second. Loss is 2.061922. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.488800398208063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26368/60000][Iteration 3020][Wall Clock 288.454407985s] Trained 128 records in 0.083417166 seconds. Throughput is 1534.4564 records/second. Loss is 2.0942857. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.488181139586962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26496/60000][Iteration 3021][Wall Clock 288.539896894s] Trained 128 records in 0.085488909 seconds. Throughput is 1497.2703 records/second. Loss is 2.0499098. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.487562189054727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26624/60000][Iteration 3022][Wall Clock 288.626016425s] Trained 128 records in 0.086119531 seconds. Throughput is 1486.3063 records/second. Loss is 2.0819845. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.486943546381497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26752/60000][Iteration 3023][Wall Clock 288.710564111s] Trained 128 records in 0.084547686 seconds. Throughput is 1513.9386 records/second. Loss is 2.1011531. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.486325211337643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 26880/60000][Iteration 3024][Wall Clock 288.796118694s] Trained 128 records in 0.085554583 seconds. Throughput is 1496.1208 records/second. Loss is 2.0949972. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.485707183693761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 27008/60000][Iteration 3025][Wall Clock 288.87947503s] Trained 128 records in 0.083356336 seconds. Throughput is 1535.5762 records/second. Loss is 2.0548475. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.485089463220676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 27136/60000][Iteration 3026][Wall Clock 288.963775896s] Trained 128 records in 0.084300866 seconds. Throughput is 1518.3711 records/second. Loss is 2.046485. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.484472049689441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:04 INFO  DistriOptimizer$:408 - [Epoch 7 27264/60000][Iteration 3027][Wall Clock 289.046392709s] Trained 128 records in 0.082616813 seconds. Throughput is 1549.3214 records/second. Loss is 2.0822418. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4838549428713363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 27392/60000][Iteration 3028][Wall Clock 289.129604161s] Trained 128 records in 0.083211452 seconds. Throughput is 1538.2498 records/second. Loss is 2.0592284. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4832381425378696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 27520/60000][Iteration 3029][Wall Clock 289.21404261s] Trained 128 records in 0.084438449 seconds. Throughput is 1515.8971 records/second. Loss is 2.0481098. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4826216484607745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 27648/60000][Iteration 3030][Wall Clock 289.298331147s] Trained 128 records in 0.084288537 seconds. Throughput is 1518.5933 records/second. Loss is 2.0955842. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.482005460412013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 27776/60000][Iteration 3031][Wall Clock 289.382312104s] Trained 128 records in 0.083980957 seconds. Throughput is 1524.155 records/second. Loss is 2.0561466. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4813895781637717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 27904/60000][Iteration 3032][Wall Clock 289.465351848s] Trained 128 records in 0.083039744 seconds. Throughput is 1541.4305 records/second. Loss is 2.0707526. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4807740014884643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28032/60000][Iteration 3033][Wall Clock 289.551328082s] Trained 128 records in 0.085976234 seconds. Throughput is 1488.7834 records/second. Loss is 2.051803. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.48015873015873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28160/60000][Iteration 3034][Wall Clock 289.641556683s] Trained 128 records in 0.090228601 seconds. Throughput is 1418.6189 records/second. Loss is 2.0945063. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.479543763947434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28288/60000][Iteration 3035][Wall Clock 289.719005225s] Trained 128 records in 0.077448542 seconds. Throughput is 1652.7103 records/second. Loss is 2.0926867. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4789291026276647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28416/60000][Iteration 3036][Wall Clock 289.801039288s] Trained 128 records in 0.082034063 seconds. Throughput is 1560.3274 records/second. Loss is 2.071413. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4783147459727387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28544/60000][Iteration 3037][Wall Clock 289.883836438s] Trained 128 records in 0.08279715 seconds. Throughput is 1545.947 records/second. Loss is 2.0533438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.477700693756195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28672/60000][Iteration 3038][Wall Clock 289.969755552s] Trained 128 records in 0.085919114 seconds. Throughput is 1489.7733 records/second. Loss is 2.0540545. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.477086945751796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:05 INFO  DistriOptimizer$:408 - [Epoch 7 28800/60000][Iteration 3039][Wall Clock 290.055529906s] Trained 128 records in 0.085774354 seconds. Throughput is 1492.2875 records/second. Loss is 2.0631657. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4764735017335313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 28928/60000][Iteration 3040][Wall Clock 290.13795605s] Trained 128 records in 0.082426144 seconds. Throughput is 1552.9053 records/second. Loss is 2.0980728. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.475860361475613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29056/60000][Iteration 3041][Wall Clock 290.223472229s] Trained 128 records in 0.085516179 seconds. Throughput is 1496.7928 records/second. Loss is 2.0617507. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4752475247524753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29184/60000][Iteration 3042][Wall Clock 290.312242212s] Trained 128 records in 0.088769983 seconds. Throughput is 1441.929 records/second. Loss is 2.0646398. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4746349913387774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29312/60000][Iteration 3043][Wall Clock 290.398951758s] Trained 128 records in 0.086709546 seconds. Throughput is 1476.1927 records/second. Loss is 2.0488803. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4740227610094015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29440/60000][Iteration 3044][Wall Clock 290.48135576s] Trained 128 records in 0.082404002 seconds. Throughput is 1553.3226 records/second. Loss is 2.057282. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.473410833539451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29568/60000][Iteration 3045][Wall Clock 290.567064792s] Trained 128 records in 0.085709032 seconds. Throughput is 1493.4248 records/second. Loss is 2.0674336. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.472799208704253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29696/60000][Iteration 3046][Wall Clock 290.651679948s] Trained 128 records in 0.084615156 seconds. Throughput is 1512.7313 records/second. Loss is 2.0715215. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4721878862793575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29824/60000][Iteration 3047][Wall Clock 290.738188142s] Trained 128 records in 0.086508194 seconds. Throughput is 1479.6287 records/second. Loss is 2.0814085. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4715768660405336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 29952/60000][Iteration 3048][Wall Clock 290.823652737s] Trained 128 records in 0.085464595 seconds. Throughput is 1497.6962 records/second. Loss is 2.0566084. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.470966147763775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 30080/60000][Iteration 3049][Wall Clock 290.90818426s] Trained 128 records in 0.084531523 seconds. Throughput is 1514.228 records/second. Loss is 2.0996568. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4703557312252963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 30208/60000][Iteration 3050][Wall Clock 290.992464432s] Trained 128 records in 0.084280172 seconds. Throughput is 1518.744 records/second. Loss is 2.0853295. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4697456162015317E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:06 INFO  DistriOptimizer$:408 - [Epoch 7 30336/60000][Iteration 3051][Wall Clock 291.078264213s] Trained 128 records in 0.085799781 seconds. Throughput is 1491.8452 records/second. Loss is 2.0681078. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4691358024691353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 30464/60000][Iteration 3052][Wall Clock 291.162001496s] Trained 128 records in 0.083737283 seconds. Throughput is 1528.5903 records/second. Loss is 2.0568755. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4685262898049864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 30592/60000][Iteration 3053][Wall Clock 291.246321633s] Trained 128 records in 0.084320137 seconds. Throughput is 1518.0242 records/second. Loss is 2.0704186. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.46791707798618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 30720/60000][Iteration 3054][Wall Clock 291.329752289s] Trained 128 records in 0.083430656 seconds. Throughput is 1534.2083 records/second. Loss is 2.046748. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.467308166790032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 30848/60000][Iteration 3055][Wall Clock 291.41502494s] Trained 128 records in 0.085272651 seconds. Throughput is 1501.0675 records/second. Loss is 2.0602825. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4666995559940796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 30976/60000][Iteration 3056][Wall Clock 291.499586376s] Trained 128 records in 0.084561436 seconds. Throughput is 1513.6924 records/second. Loss is 2.0729017. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4660912453760794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31104/60000][Iteration 3057][Wall Clock 291.581745273s] Trained 128 records in 0.082158897 seconds. Throughput is 1557.9567 records/second. Loss is 2.0787227. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.465483234714004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31232/60000][Iteration 3058][Wall Clock 291.665249948s] Trained 128 records in 0.083504675 seconds. Throughput is 1532.8483 records/second. Loss is 2.086424. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4648755237860487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31360/60000][Iteration 3059][Wall Clock 291.748687554s] Trained 128 records in 0.083437606 seconds. Throughput is 1534.0804 records/second. Loss is 2.0909297. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.464268112370626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31488/60000][Iteration 3060][Wall Clock 291.838714293s] Trained 128 records in 0.090026739 seconds. Throughput is 1421.7998 records/second. Loss is 2.0636444. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.463661000246366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31616/60000][Iteration 3061][Wall Clock 291.925073379s] Trained 128 records in 0.086359086 seconds. Throughput is 1482.1833 records/second. Loss is 2.0617733. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.463054187192118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31744/60000][Iteration 3062][Wall Clock 292.000991542s] Trained 128 records in 0.075918163 seconds. Throughput is 1686.0261 records/second. Loss is 2.090808. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.462447672986949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:07 INFO  DistriOptimizer$:408 - [Epoch 7 31872/60000][Iteration 3063][Wall Clock 292.08302984s] Trained 128 records in 0.082038298 seconds. Throughput is 1560.247 records/second. Loss is 2.0665717. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4618414574101424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32000/60000][Iteration 3064][Wall Clock 292.168465143s] Trained 128 records in 0.085435303 seconds. Throughput is 1498.2097 records/second. Loss is 2.077323. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.461235540241201E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32128/60000][Iteration 3065][Wall Clock 292.253624925s] Trained 128 records in 0.085159782 seconds. Throughput is 1503.057 records/second. Loss is 2.0813372. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4606299212598425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32256/60000][Iteration 3066][Wall Clock 292.33731562s] Trained 128 records in 0.083690695 seconds. Throughput is 1529.4413 records/second. Loss is 2.0567853. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.460024600246003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32384/60000][Iteration 3067][Wall Clock 292.42938963s] Trained 128 records in 0.09207401 seconds. Throughput is 1390.186 records/second. Loss is 2.0637293. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4594195769798326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32512/60000][Iteration 3068][Wall Clock 292.509629558s] Trained 128 records in 0.080239928 seconds. Throughput is 1595.2158 records/second. Loss is 2.0625298. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4588148512417015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32640/60000][Iteration 3069][Wall Clock 292.590670686s] Trained 128 records in 0.081041128 seconds. Throughput is 1579.445 records/second. Loss is 2.0409648. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.458210422812193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32768/60000][Iteration 3070][Wall Clock 292.67396891s] Trained 128 records in 0.083298224 seconds. Throughput is 1536.6475 records/second. Loss is 2.0537598. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.457606291472106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 32896/60000][Iteration 3071][Wall Clock 292.757666676s] Trained 128 records in 0.083697766 seconds. Throughput is 1529.312 records/second. Loss is 2.0927489. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.457002457002457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 33024/60000][Iteration 3072][Wall Clock 292.839753797s] Trained 128 records in 0.082087121 seconds. Throughput is 1559.3188 records/second. Loss is 2.0720541. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.456398919184476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 33152/60000][Iteration 3073][Wall Clock 292.922810995s] Trained 128 records in 0.083057198 seconds. Throughput is 1541.1067 records/second. Loss is 2.0955827. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.455795677799607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 33280/60000][Iteration 3074][Wall Clock 293.008359387s] Trained 128 records in 0.085548392 seconds. Throughput is 1496.2291 records/second. Loss is 2.042766. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4551927326295114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:08 INFO  DistriOptimizer$:408 - [Epoch 7 33408/60000][Iteration 3075][Wall Clock 293.095161601s] Trained 128 records in 0.086802214 seconds. Throughput is 1474.6167 records/second. Loss is 2.0777225. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.454590083456063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 33536/60000][Iteration 3076][Wall Clock 293.179317807s] Trained 128 records in 0.084156206 seconds. Throughput is 1520.9811 records/second. Loss is 2.064885. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.45398773006135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 33664/60000][Iteration 3077][Wall Clock 293.26583219s] Trained 128 records in 0.086514383 seconds. Throughput is 1479.5227 records/second. Loss is 2.0835564. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.453385672227674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 33792/60000][Iteration 3078][Wall Clock 293.352123717s] Trained 128 records in 0.086291527 seconds. Throughput is 1483.3438 records/second. Loss is 2.06015. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.452783909737552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 33920/60000][Iteration 3079][Wall Clock 293.439092031s] Trained 128 records in 0.086968314 seconds. Throughput is 1471.8003 records/second. Loss is 2.0880632. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.452182442373713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34048/60000][Iteration 3080][Wall Clock 293.528504986s] Trained 128 records in 0.089412955 seconds. Throughput is 1431.5598 records/second. Loss is 2.0402944. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4515812699190976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34176/60000][Iteration 3081][Wall Clock 293.61389677s] Trained 128 records in 0.085391784 seconds. Throughput is 1498.9733 records/second. Loss is 2.092222. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4509803921568627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34304/60000][Iteration 3082][Wall Clock 293.697681792s] Trained 128 records in 0.083785022 seconds. Throughput is 1527.7194 records/second. Loss is 2.0544312. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4503798088703753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34432/60000][Iteration 3083][Wall Clock 293.781378478s] Trained 128 records in 0.083696686 seconds. Throughput is 1529.3318 records/second. Loss is 2.0590296. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.449779519843214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34560/60000][Iteration 3084][Wall Clock 293.864898674s] Trained 128 records in 0.083520196 seconds. Throughput is 1532.5635 records/second. Loss is 2.0706854. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.449179524859172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34688/60000][Iteration 3085][Wall Clock 293.951048148s] Trained 128 records in 0.086149474 seconds. Throughput is 1485.7897 records/second. Loss is 2.0575123. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.448579823702253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:09 INFO  DistriOptimizer$:408 - [Epoch 7 34816/60000][Iteration 3086][Wall Clock 294.034037487s] Trained 128 records in 0.082989339 seconds. Throughput is 1542.3667 records/second. Loss is 2.0641382. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.447980416156671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 34944/60000][Iteration 3087][Wall Clock 294.11504649s] Trained 128 records in 0.081009003 seconds. Throughput is 1580.0713 records/second. Loss is 2.0433488. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4473813020068524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35072/60000][Iteration 3088][Wall Clock 294.19559475s] Trained 128 records in 0.08054826 seconds. Throughput is 1589.1095 records/second. Loss is 2.0560966. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.446782481037436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35200/60000][Iteration 3089][Wall Clock 294.278885774s] Trained 128 records in 0.083291024 seconds. Throughput is 1536.7803 records/second. Loss is 2.069575. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.446183953033268E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35328/60000][Iteration 3090][Wall Clock 294.362925004s] Trained 128 records in 0.08403923 seconds. Throughput is 1523.0981 records/second. Loss is 2.074589. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.445585717779408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35456/60000][Iteration 3091][Wall Clock 294.447965099s] Trained 128 records in 0.085040095 seconds. Throughput is 1505.1724 records/second. Loss is 2.082339. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.444987775061125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35584/60000][Iteration 3092][Wall Clock 294.53709468s] Trained 128 records in 0.089129581 seconds. Throughput is 1436.1113 records/second. Loss is 2.0570898. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.444390124663896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35712/60000][Iteration 3093][Wall Clock 294.621175402s] Trained 128 records in 0.084080722 seconds. Throughput is 1522.3467 records/second. Loss is 2.069812. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4437927663734115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35840/60000][Iteration 3094][Wall Clock 294.706483861s] Trained 128 records in 0.085308459 seconds. Throughput is 1500.4373 records/second. Loss is 2.0581665. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.443195699975568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 35968/60000][Iteration 3095][Wall Clock 294.789512418s] Trained 128 records in 0.083028557 seconds. Throughput is 1541.6383 records/second. Loss is 2.0582004. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4425989252564734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 36096/60000][Iteration 3096][Wall Clock 294.873055933s] Trained 128 records in 0.083543515 seconds. Throughput is 1532.1356 records/second. Loss is 2.0692098. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4420024420024415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 36224/60000][Iteration 3097][Wall Clock 294.956508404s] Trained 128 records in 0.083452471 seconds. Throughput is 1533.8073 records/second. Loss is 2.0775385. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.44140625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:10 INFO  DistriOptimizer$:408 - [Epoch 7 36352/60000][Iteration 3098][Wall Clock 295.040834238s] Trained 128 records in 0.084325834 seconds. Throughput is 1517.9215 records/second. Loss is 2.055959. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4408103490358802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 36480/60000][Iteration 3099][Wall Clock 295.123411601s] Trained 128 records in 0.082577363 seconds. Throughput is 1550.0616 records/second. Loss is 2.0723486. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.440214738897023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 36608/60000][Iteration 3100][Wall Clock 295.205224234s] Trained 128 records in 0.081812633 seconds. Throughput is 1564.5505 records/second. Loss is 2.0664787. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4396194193705782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 36736/60000][Iteration 3101][Wall Clock 295.288010374s] Trained 128 records in 0.08278614 seconds. Throughput is 1546.1525 records/second. Loss is 2.0775552. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4390243902439027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 36864/60000][Iteration 3102][Wall Clock 295.370363672s] Trained 128 records in 0.082353298 seconds. Throughput is 1554.2789 records/second. Loss is 2.0627842. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.43842965130456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 36992/60000][Iteration 3103][Wall Clock 295.452485929s] Trained 128 records in 0.082122257 seconds. Throughput is 1558.6517 records/second. Loss is 2.0511348. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4378352023403217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37120/60000][Iteration 3104][Wall Clock 295.536738312s] Trained 128 records in 0.084252383 seconds. Throughput is 1519.2449 records/second. Loss is 2.0832815. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4372410431391668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37248/60000][Iteration 3105][Wall Clock 295.618170168s] Trained 128 records in 0.081431856 seconds. Throughput is 1571.8663 records/second. Loss is 2.064812. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4366471734892786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37376/60000][Iteration 3106][Wall Clock 295.701266966s] Trained 128 records in 0.083096798 seconds. Throughput is 1540.3723 records/second. Loss is 2.0947232. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4360535931790498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37504/60000][Iteration 3107][Wall Clock 295.782918963s] Trained 128 records in 0.081651997 seconds. Throughput is 1567.6284 records/second. Loss is 2.0586705. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4354603019970775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37632/60000][Iteration 3108][Wall Clock 295.864629366s] Trained 128 records in 0.081710403 seconds. Throughput is 1566.5079 records/second. Loss is 2.087473. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4348672997321646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37760/60000][Iteration 3109][Wall Clock 295.9483105s] Trained 128 records in 0.083681134 seconds. Throughput is 1529.616 records/second. Loss is 2.0738282. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4342745861733202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:11 INFO  DistriOptimizer$:408 - [Epoch 7 37888/60000][Iteration 3110][Wall Clock 296.046575116s] Trained 128 records in 0.098264616 seconds. Throughput is 1302.6051 records/second. Loss is 2.053608. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4336821611097592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38016/60000][Iteration 3111][Wall Clock 296.12771812s] Trained 128 records in 0.081143004 seconds. Throughput is 1577.4619 records/second. Loss is 2.080357. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4330900243309006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38144/60000][Iteration 3112][Wall Clock 296.202513315s] Trained 128 records in 0.074795195 seconds. Throughput is 1711.3398 records/second. Loss is 2.0692637. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.432498175626368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38272/60000][Iteration 3113][Wall Clock 296.289950052s] Trained 128 records in 0.087436737 seconds. Throughput is 1463.9155 records/second. Loss is 2.0933251. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4319066147859923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38400/60000][Iteration 3114][Wall Clock 296.375323467s] Trained 128 records in 0.085373415 seconds. Throughput is 1499.2958 records/second. Loss is 2.050051. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4313153415998057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38528/60000][Iteration 3115][Wall Clock 296.46020409s] Trained 128 records in 0.084880623 seconds. Throughput is 1508.0002 records/second. Loss is 2.0674117. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.430724355858046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38656/60000][Iteration 3116][Wall Clock 296.545492483s] Trained 128 records in 0.085288393 seconds. Throughput is 1500.7904 records/second. Loss is 2.0347216. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4301336573511544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38784/60000][Iteration 3117][Wall Clock 296.630244358s] Trained 128 records in 0.084751875 seconds. Throughput is 1510.2911 records/second. Loss is 2.0478702. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4295432458697766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 38912/60000][Iteration 3118][Wall Clock 296.721228682s] Trained 128 records in 0.090984324 seconds. Throughput is 1406.8358 records/second. Loss is 2.053558. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4289531212047608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 39040/60000][Iteration 3119][Wall Clock 296.800534177s] Trained 128 records in 0.079305495 seconds. Throughput is 1614.0118 records/second. Loss is 2.0347927. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4283632831471587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 39168/60000][Iteration 3120][Wall Clock 296.884646932s] Trained 128 records in 0.084112755 seconds. Throughput is 1521.7668 records/second. Loss is 2.058013. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4277737314882256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 39296/60000][Iteration 3121][Wall Clock 296.967476059s] Trained 128 records in 0.082829127 seconds. Throughput is 1545.3501 records/second. Loss is 2.097283. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4271844660194174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:12 INFO  DistriOptimizer$:408 - [Epoch 7 39424/60000][Iteration 3122][Wall Clock 297.051492913s] Trained 128 records in 0.084016854 seconds. Throughput is 1523.5039 records/second. Loss is 2.064673. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4265954865323948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 39552/60000][Iteration 3123][Wall Clock 297.134818825s] Trained 128 records in 0.083325912 seconds. Throughput is 1536.1367 records/second. Loss is 2.074668. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.42600679281902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 39680/60000][Iteration 3124][Wall Clock 297.218415883s] Trained 128 records in 0.083597058 seconds. Throughput is 1531.1544 records/second. Loss is 2.0730917. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4254183846713557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 39808/60000][Iteration 3125][Wall Clock 297.302001104s] Trained 128 records in 0.083585221 seconds. Throughput is 1531.3712 records/second. Loss is 2.060862. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.424830261881668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 39936/60000][Iteration 3126][Wall Clock 297.385009983s] Trained 128 records in 0.083008879 seconds. Throughput is 1542.0038 records/second. Loss is 2.0806913. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4242424242424242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40064/60000][Iteration 3127][Wall Clock 297.471225666s] Trained 128 records in 0.086215683 seconds. Throughput is 1484.6487 records/second. Loss is 2.0295126. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4236548715462922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40192/60000][Iteration 3128][Wall Clock 297.554675344s] Trained 128 records in 0.083449678 seconds. Throughput is 1533.8585 records/second. Loss is 2.071009. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4230676035861398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40320/60000][Iteration 3129][Wall Clock 297.638239306s] Trained 128 records in 0.083563962 seconds. Throughput is 1531.7607 records/second. Loss is 2.0556495. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4224806201550387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40448/60000][Iteration 3130][Wall Clock 297.721826675s] Trained 128 records in 0.083587369 seconds. Throughput is 1531.3318 records/second. Loss is 2.05332. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4218939210462584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40576/60000][Iteration 3131][Wall Clock 297.805059081s] Trained 128 records in 0.083232406 seconds. Throughput is 1537.8625 records/second. Loss is 2.0391214. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4213075060532688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40704/60000][Iteration 3132][Wall Clock 297.888106769s] Trained 128 records in 0.083047688 seconds. Throughput is 1541.2831 records/second. Loss is 2.0763052. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.420721374969741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40832/60000][Iteration 3133][Wall Clock 297.971318277s] Trained 128 records in 0.083211508 seconds. Throughput is 1538.2487 records/second. Loss is 2.0465052. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4201355275895454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:13 INFO  DistriOptimizer$:408 - [Epoch 7 40960/60000][Iteration 3134][Wall Clock 298.069836674s] Trained 128 records in 0.098518397 seconds. Throughput is 1299.2498 records/second. Loss is 2.0845015. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4195499637067505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41088/60000][Iteration 3135][Wall Clock 298.162832052s] Trained 128 records in 0.092995378 seconds. Throughput is 1376.4125 records/second. Loss is 2.029627. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4189646831156264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41216/60000][Iteration 3136][Wall Clock 298.240721904s] Trained 128 records in 0.077889852 seconds. Throughput is 1643.3463 records/second. Loss is 2.046214. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.418379685610641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41344/60000][Iteration 3137][Wall Clock 298.322447728s] Trained 128 records in 0.081725824 seconds. Throughput is 1566.2125 records/second. Loss is 2.0844772. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4177949709864604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41472/60000][Iteration 3138][Wall Clock 298.404551529s] Trained 128 records in 0.082103801 seconds. Throughput is 1559.0021 records/second. Loss is 2.0728626. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.41721053903795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41600/60000][Iteration 3139][Wall Clock 298.488100097s] Trained 128 records in 0.083548568 seconds. Throughput is 1532.043 records/second. Loss is 2.0713513. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.416626389560174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41728/60000][Iteration 3140][Wall Clock 298.572558391s] Trained 128 records in 0.084458294 seconds. Throughput is 1515.541 records/second. Loss is 2.0552506. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4160425223483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41856/60000][Iteration 3141][Wall Clock 298.657076115s] Trained 128 records in 0.084517724 seconds. Throughput is 1514.4752 records/second. Loss is 2.0675683. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4154589371980673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 41984/60000][Iteration 3142][Wall Clock 298.739896648s] Trained 128 records in 0.082820533 seconds. Throughput is 1545.5104 records/second. Loss is 2.0828838. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.414875633904854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 42112/60000][Iteration 3143][Wall Clock 298.823918964s] Trained 128 records in 0.084022316 seconds. Throughput is 1523.4049 records/second. Loss is 2.0722537. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.414292612264607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 42240/60000][Iteration 3144][Wall Clock 298.909560302s] Trained 128 records in 0.085641338 seconds. Throughput is 1494.6053 records/second. Loss is 2.1117947. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4137098720733763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:14 INFO  DistriOptimizer$:408 - [Epoch 7 42368/60000][Iteration 3145][Wall Clock 298.992794378s] Trained 128 records in 0.083234076 seconds. Throughput is 1537.8317 records/second. Loss is 2.043423. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4131274131274132E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 42496/60000][Iteration 3146][Wall Clock 299.076178195s] Trained 128 records in 0.083383817 seconds. Throughput is 1535.0701 records/second. Loss is 2.0466237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4125452352231607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 42624/60000][Iteration 3147][Wall Clock 299.158983607s] Trained 128 records in 0.082805412 seconds. Throughput is 1545.7927 records/second. Loss is 2.0625167. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.41196333815726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 42752/60000][Iteration 3148][Wall Clock 299.243699235s] Trained 128 records in 0.084715628 seconds. Throughput is 1510.9373 records/second. Loss is 2.0568929. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.411381721726549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 42880/60000][Iteration 3149][Wall Clock 299.329211785s] Trained 128 records in 0.08551255 seconds. Throughput is 1496.8563 records/second. Loss is 2.067242. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.410800385728062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43008/60000][Iteration 3150][Wall Clock 299.415218713s] Trained 128 records in 0.086006928 seconds. Throughput is 1488.2523 records/second. Loss is 2.0794075. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4102193299590263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43136/60000][Iteration 3151][Wall Clock 299.503158569s] Trained 128 records in 0.087939856 seconds. Throughput is 1455.5402 records/second. Loss is 2.0595975. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4096385542168674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43264/60000][Iteration 3152][Wall Clock 299.589656925s] Trained 128 records in 0.086498356 seconds. Throughput is 1479.7969 records/second. Loss is 2.056087. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4090580582992053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43392/60000][Iteration 3153][Wall Clock 299.676808345s] Trained 128 records in 0.08715142 seconds. Throughput is 1468.7081 records/second. Loss is 2.054959. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4084778420038535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43520/60000][Iteration 3154][Wall Clock 299.760544098s] Trained 128 records in 0.083735753 seconds. Throughput is 1528.6182 records/second. Loss is 2.0840333. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4078979051288222E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43648/60000][Iteration 3155][Wall Clock 299.844673974s] Trained 128 records in 0.084129876 seconds. Throughput is 1521.4572 records/second. Loss is 2.054757. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.407318247472316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43776/60000][Iteration 3156][Wall Clock 299.928922115s] Trained 128 records in 0.084248141 seconds. Throughput is 1519.3214 records/second. Loss is 2.048784. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4067388688327315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:15 INFO  DistriOptimizer$:408 - [Epoch 7 43904/60000][Iteration 3157][Wall Clock 300.011664974s] Trained 128 records in 0.082742859 seconds. Throughput is 1546.9612 records/second. Loss is 2.037849. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4061597690086618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44032/60000][Iteration 3158][Wall Clock 300.094858116s] Trained 128 records in 0.083193142 seconds. Throughput is 1538.5883 records/second. Loss is 2.080491. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4055809477988935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44160/60000][Iteration 3159][Wall Clock 300.183611118s] Trained 128 records in 0.088753002 seconds. Throughput is 1442.2047 records/second. Loss is 2.0801191. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4050024050024054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44288/60000][Iteration 3160][Wall Clock 300.273389633s] Trained 128 records in 0.089778515 seconds. Throughput is 1425.731 records/second. Loss is 2.05165. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4044241404183695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44416/60000][Iteration 3161][Wall Clock 300.351223799s] Trained 128 records in 0.077834166 seconds. Throughput is 1644.522 records/second. Loss is 2.0633614. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4038461538461537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44544/60000][Iteration 3162][Wall Clock 300.432584566s] Trained 128 records in 0.081360767 seconds. Throughput is 1573.2399 records/second. Loss is 2.0478358. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4032684450853164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44672/60000][Iteration 3163][Wall Clock 300.51596476s] Trained 128 records in 0.083380194 seconds. Throughput is 1535.1367 records/second. Loss is 2.0629673. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.402691013935608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44800/60000][Iteration 3164][Wall Clock 300.604442183s] Trained 128 records in 0.088477423 seconds. Throughput is 1446.6967 records/second. Loss is 2.0673072. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4021138601969732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 44928/60000][Iteration 3165][Wall Clock 300.686625202s] Trained 128 records in 0.082183019 seconds. Throughput is 1557.4994 records/second. Loss is 2.04343. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4015369836695487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 45056/60000][Iteration 3166][Wall Clock 300.77012765s] Trained 128 records in 0.083502448 seconds. Throughput is 1532.8892 records/second. Loss is 2.0821028. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4009603841536616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 45184/60000][Iteration 3167][Wall Clock 300.852554058s] Trained 128 records in 0.082426408 seconds. Throughput is 1552.9004 records/second. Loss is 2.0537465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.4003840614498319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 45312/60000][Iteration 3168][Wall Clock 300.943649555s] Trained 128 records in 0.091095497 seconds. Throughput is 1405.1188 records/second. Loss is 2.0635917. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3998080153587716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:16 INFO  DistriOptimizer$:408 - [Epoch 7 45440/60000][Iteration 3169][Wall Clock 301.017993811s] Trained 128 records in 0.074344256 seconds. Throughput is 1721.7201 records/second. Loss is 2.063753. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.399232245681382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 45568/60000][Iteration 3170][Wall Clock 301.101963499s] Trained 128 records in 0.083969688 seconds. Throughput is 1524.3596 records/second. Loss is 2.0534005. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3986567522187572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 45696/60000][Iteration 3171][Wall Clock 301.186017921s] Trained 128 records in 0.084054422 seconds. Throughput is 1522.8229 records/second. Loss is 2.0778708. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3980815347721823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 45824/60000][Iteration 3172][Wall Clock 301.27093495s] Trained 128 records in 0.084917029 seconds. Throughput is 1507.3536 records/second. Loss is 2.0776415. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.397506593143131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 45952/60000][Iteration 3173][Wall Clock 301.355636984s] Trained 128 records in 0.084702034 seconds. Throughput is 1511.1797 records/second. Loss is 2.0788927. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.396931927133269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46080/60000][Iteration 3174][Wall Clock 301.446781035s] Trained 128 records in 0.091144051 seconds. Throughput is 1404.3704 records/second. Loss is 2.0410552. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3963575365444525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46208/60000][Iteration 3175][Wall Clock 301.535786353s] Trained 128 records in 0.089005318 seconds. Throughput is 1438.1162 records/second. Loss is 2.0801973. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3957834211787258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46336/60000][Iteration 3176][Wall Clock 301.620878045s] Trained 128 records in 0.085091692 seconds. Throughput is 1504.2596 records/second. Loss is 2.0453687. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.395209580838323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46464/60000][Iteration 3177][Wall Clock 301.703125043s] Trained 128 records in 0.082246998 seconds. Throughput is 1556.2878 records/second. Loss is 2.048359. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3946360153256704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46592/60000][Iteration 3178][Wall Clock 301.78610496s] Trained 128 records in 0.082979917 seconds. Throughput is 1542.5419 records/second. Loss is 2.0917726. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3940627244433806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46720/60000][Iteration 3179][Wall Clock 301.871194767s] Trained 128 records in 0.085089807 seconds. Throughput is 1504.293 records/second. Loss is 2.0713015. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3934897079942556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46848/60000][Iteration 3180][Wall Clock 301.955600551s] Trained 128 records in 0.084405784 seconds. Throughput is 1516.4836 records/second. Loss is 2.0913858. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3929169657812874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:17 INFO  DistriOptimizer$:408 - [Epoch 7 46976/60000][Iteration 3181][Wall Clock 302.039330799s] Trained 128 records in 0.083730248 seconds. Throughput is 1528.7188 records/second. Loss is 2.0677373. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3923444976076558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47104/60000][Iteration 3182][Wall Clock 302.130305591s] Trained 128 records in 0.090974792 seconds. Throughput is 1406.9832 records/second. Loss is 2.0868485. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3917723032767282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47232/60000][Iteration 3183][Wall Clock 302.238622051s] Trained 128 records in 0.10831646 seconds. Throughput is 1181.7225 records/second. Loss is 2.0929544. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.391200382592061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47360/60000][Iteration 3184][Wall Clock 302.347765547s] Trained 128 records in 0.109143496 seconds. Throughput is 1172.7681 records/second. Loss is 2.0579085. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3906287353573993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47488/60000][Iteration 3185][Wall Clock 302.462145848s] Trained 128 records in 0.114380301 seconds. Throughput is 1119.0739 records/second. Loss is 2.0281382. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.390057361376673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47616/60000][Iteration 3186][Wall Clock 302.577933461s] Trained 128 records in 0.115787613 seconds. Throughput is 1105.4723 records/second. Loss is 2.0945413. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.389486260454002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47744/60000][Iteration 3187][Wall Clock 302.677885658s] Trained 128 records in 0.099952197 seconds. Throughput is 1280.6122 records/second. Loss is 2.0670922. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3889154323936934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 47872/60000][Iteration 3188][Wall Clock 302.790028817s] Trained 128 records in 0.112143159 seconds. Throughput is 1141.3982 records/second. Loss is 2.052891. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3883448770002386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 48000/60000][Iteration 3189][Wall Clock 302.89831252s] Trained 128 records in 0.108283703 seconds. Throughput is 1182.08 records/second. Loss is 2.0315442. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3877745940783187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:18 INFO  DistriOptimizer$:408 - [Epoch 7 48128/60000][Iteration 3190][Wall Clock 303.006641313s] Trained 128 records in 0.108328793 seconds. Throughput is 1181.588 records/second. Loss is 2.0329797. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3872045834328001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 48256/60000][Iteration 3191][Wall Clock 303.113704024s] Trained 128 records in 0.107062711 seconds. Throughput is 1195.5609 records/second. Loss is 2.0464284. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3866348448687354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 48384/60000][Iteration 3192][Wall Clock 303.21855917s] Trained 128 records in 0.104855146 seconds. Throughput is 1220.7317 records/second. Loss is 2.0966818. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3860653781913622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 48512/60000][Iteration 3193][Wall Clock 303.324601419s] Trained 128 records in 0.106042249 seconds. Throughput is 1207.066 records/second. Loss is 2.0487747. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3854961832061068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 48640/60000][Iteration 3194][Wall Clock 303.434832071s] Trained 128 records in 0.110230652 seconds. Throughput is 1161.2015 records/second. Loss is 2.0303679. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3849272597185788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 48768/60000][Iteration 3195][Wall Clock 303.542196114s] Trained 128 records in 0.107364043 seconds. Throughput is 1192.2054 records/second. Loss is 2.035368. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3843586075345734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 48896/60000][Iteration 3196][Wall Clock 303.649141215s] Trained 128 records in 0.106945101 seconds. Throughput is 1196.8759 records/second. Loss is 2.0515902. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3837902264600713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 49024/60000][Iteration 3197][Wall Clock 303.736617733s] Trained 128 records in 0.087476518 seconds. Throughput is 1463.2499 records/second. Loss is 2.0611365. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3832221163012395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 49152/60000][Iteration 3198][Wall Clock 303.822525069s] Trained 128 records in 0.085907336 seconds. Throughput is 1489.9775 records/second. Loss is 2.0451775. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.382654276864427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 49280/60000][Iteration 3199][Wall Clock 303.913102354s] Trained 128 records in 0.090577285 seconds. Throughput is 1413.1578 records/second. Loss is 2.0611696. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3820867079561695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:19 INFO  DistriOptimizer$:408 - [Epoch 7 49408/60000][Iteration 3200][Wall Clock 304.024182365s] Trained 128 records in 0.111080011 seconds. Throughput is 1152.3225 records/second. Loss is 2.0391848. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3815194093831867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 49536/60000][Iteration 3201][Wall Clock 304.106747111s] Trained 128 records in 0.082564746 seconds. Throughput is 1550.2985 records/second. Loss is 2.0591927. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.380952380952381E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 49664/60000][Iteration 3202][Wall Clock 304.18942444s] Trained 128 records in 0.082677329 seconds. Throughput is 1548.1875 records/second. Loss is 2.0346775. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.38038562247084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 49792/60000][Iteration 3203][Wall Clock 304.275921328s] Trained 128 records in 0.086496888 seconds. Throughput is 1479.822 records/second. Loss is 2.0384207. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3798191337458355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 49920/60000][Iteration 3204][Wall Clock 304.370852582s] Trained 128 records in 0.094931254 seconds. Throughput is 1348.3441 records/second. Loss is 2.0541031. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3792529145848207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50048/60000][Iteration 3205][Wall Clock 304.457699863s] Trained 128 records in 0.086847281 seconds. Throughput is 1473.8516 records/second. Loss is 2.0694118. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3786869647954325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50176/60000][Iteration 3206][Wall Clock 304.542699815s] Trained 128 records in 0.084999952 seconds. Throughput is 1505.8833 records/second. Loss is 2.0436037. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3781212841854935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50304/60000][Iteration 3207][Wall Clock 304.62519379s] Trained 128 records in 0.082493975 seconds. Throughput is 1551.6284 records/second. Loss is 2.039849. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3775558725630056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50432/60000][Iteration 3208][Wall Clock 304.71071974s] Trained 128 records in 0.08552595 seconds. Throughput is 1496.6217 records/second. Loss is 2.0559456. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3769907297361542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50560/60000][Iteration 3209][Wall Clock 304.796181038s] Trained 128 records in 0.085461298 seconds. Throughput is 1497.754 records/second. Loss is 2.0579484. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.376425855513308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50688/60000][Iteration 3210][Wall Clock 304.880338696s] Trained 128 records in 0.084157658 seconds. Throughput is 1520.9548 records/second. Loss is 2.0533864. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3758612497030176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:20 INFO  DistriOptimizer$:408 - [Epoch 7 50816/60000][Iteration 3211][Wall Clock 304.97121384s] Trained 128 records in 0.090875144 seconds. Throughput is 1408.526 records/second. Loss is 2.0472908. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3752969121140142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 50944/60000][Iteration 3212][Wall Clock 305.053018914s] Trained 128 records in 0.081805074 seconds. Throughput is 1564.6952 records/second. Loss is 2.0457344. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3747328425552123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51072/60000][Iteration 3213][Wall Clock 305.136949515s] Trained 128 records in 0.083930601 seconds. Throughput is 1525.0695 records/second. Loss is 2.051741. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3741690408357076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51200/60000][Iteration 3214][Wall Clock 305.223438392s] Trained 128 records in 0.086488877 seconds. Throughput is 1479.959 records/second. Loss is 2.0574932. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3736055067647758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51328/60000][Iteration 3215][Wall Clock 305.310616885s] Trained 128 records in 0.087178493 seconds. Throughput is 1468.2521 records/second. Loss is 2.0625577. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3730422401518745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51456/60000][Iteration 3216][Wall Clock 305.398333707s] Trained 128 records in 0.087716822 seconds. Throughput is 1459.2411 records/second. Loss is 2.0633955. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.372479240806643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51584/60000][Iteration 3217][Wall Clock 305.485222139s] Trained 128 records in 0.086888432 seconds. Throughput is 1473.1536 records/second. Loss is 2.0638385. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3719165085388995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51712/60000][Iteration 3218][Wall Clock 305.573245421s] Trained 128 records in 0.088023282 seconds. Throughput is 1454.1608 records/second. Loss is 2.0570076. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3713540431586434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51840/60000][Iteration 3219][Wall Clock 305.666593738s] Trained 128 records in 0.093348317 seconds. Throughput is 1371.2085 records/second. Loss is 2.0642464. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.370791844476055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 51968/60000][Iteration 3220][Wall Clock 305.751472907s] Trained 128 records in 0.084879169 seconds. Throughput is 1508.0261 records/second. Loss is 2.0915127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3702299123014937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 52096/60000][Iteration 3221][Wall Clock 305.838286955s] Trained 128 records in 0.086814048 seconds. Throughput is 1474.4158 records/second. Loss is 2.0539224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3696682464454974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 52224/60000][Iteration 3222][Wall Clock 305.922703271s] Trained 128 records in 0.084416316 seconds. Throughput is 1516.2946 records/second. Loss is 2.0704849. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3691068467187872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:21 INFO  DistriOptimizer$:408 - [Epoch 7 52352/60000][Iteration 3223][Wall Clock 306.007602446s] Trained 128 records in 0.084899175 seconds. Throughput is 1507.6708 records/second. Loss is 2.0535095. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.36854571293226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 52480/60000][Iteration 3224][Wall Clock 306.092955769s] Trained 128 records in 0.085353323 seconds. Throughput is 1499.6487 records/second. Loss is 2.0617292. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.367984844896993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 52608/60000][Iteration 3225][Wall Clock 306.176644061s] Trained 128 records in 0.083688292 seconds. Throughput is 1529.4852 records/second. Loss is 2.0151296. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3674242424242425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 52736/60000][Iteration 3226][Wall Clock 306.261533831s] Trained 128 records in 0.08488977 seconds. Throughput is 1507.8378 records/second. Loss is 2.085208. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.366863905325444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 52864/60000][Iteration 3227][Wall Clock 306.346523466s] Trained 128 records in 0.084989635 seconds. Throughput is 1506.0659 records/second. Loss is 2.070784. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.36630383341221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 52992/60000][Iteration 3228][Wall Clock 306.435070863s] Trained 128 records in 0.088547397 seconds. Throughput is 1445.5536 records/second. Loss is 2.0478477. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.365744026496333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53120/60000][Iteration 3229][Wall Clock 306.519507004s] Trained 128 records in 0.084436141 seconds. Throughput is 1515.9385 records/second. Loss is 2.0524428. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3651844843897827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53248/60000][Iteration 3230][Wall Clock 306.603663257s] Trained 128 records in 0.084156253 seconds. Throughput is 1520.9802 records/second. Loss is 2.0385497. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3646252069047056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53376/60000][Iteration 3231][Wall Clock 306.688333912s] Trained 128 records in 0.084670655 seconds. Throughput is 1511.7397 records/second. Loss is 2.0331008. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3640661938534278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53504/60000][Iteration 3232][Wall Clock 306.772249249s] Trained 128 records in 0.083915337 seconds. Throughput is 1525.3469 records/second. Loss is 2.071374. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.363507445048452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53632/60000][Iteration 3233][Wall Clock 306.857026509s] Trained 128 records in 0.08477726 seconds. Throughput is 1509.8389 records/second. Loss is 2.037904. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3629489603024575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53760/60000][Iteration 3234][Wall Clock 306.94034587s] Trained 128 records in 0.083319361 seconds. Throughput is 1536.2576 records/second. Loss is 2.0790143. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3623907394283012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:22 INFO  DistriOptimizer$:408 - [Epoch 7 53888/60000][Iteration 3235][Wall Clock 307.02466828s] Trained 128 records in 0.08432241 seconds. Throughput is 1517.9833 records/second. Loss is 2.0700269. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3618327822390176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54016/60000][Iteration 3236][Wall Clock 307.118260212s] Trained 128 records in 0.093591932 seconds. Throughput is 1367.6393 records/second. Loss is 2.0908432. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3612750885478162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54144/60000][Iteration 3237][Wall Clock 307.19274318s] Trained 128 records in 0.074482968 seconds. Throughput is 1718.5137 records/second. Loss is 2.0388. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3607176581680827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54272/60000][Iteration 3238][Wall Clock 307.294727172s] Trained 128 records in 0.101983992 seconds. Throughput is 1255.0989 records/second. Loss is 2.0937257. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.360160490913382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54400/60000][Iteration 3239][Wall Clock 307.367701256s] Trained 128 records in 0.072974084 seconds. Throughput is 1754.0474 records/second. Loss is 2.0569725. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.359603586597452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54528/60000][Iteration 3240][Wall Clock 307.452739076s] Trained 128 records in 0.08503782 seconds. Throughput is 1505.2126 records/second. Loss is 2.03961. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3590469450342062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54656/60000][Iteration 3241][Wall Clock 307.535324211s] Trained 128 records in 0.082585135 seconds. Throughput is 1549.9158 records/second. Loss is 2.0743318. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.358490566037736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54784/60000][Iteration 3242][Wall Clock 307.633063552s] Trained 128 records in 0.097739341 seconds. Throughput is 1309.6057 records/second. Loss is 2.0487022. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3579344494223064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 54912/60000][Iteration 3243][Wall Clock 307.725830688s] Trained 128 records in 0.092767136 seconds. Throughput is 1379.799 records/second. Loss is 2.0517411. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3573785950023574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 55040/60000][Iteration 3244][Wall Clock 307.816118675s] Trained 128 records in 0.090287987 seconds. Throughput is 1417.6859 records/second. Loss is 2.0541196. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.356823002592505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 55168/60000][Iteration 3245][Wall Clock 307.890229615s] Trained 128 records in 0.07411094 seconds. Throughput is 1727.1404 records/second. Loss is 2.0385728. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3562676720075403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:23 INFO  DistriOptimizer$:408 - [Epoch 7 55296/60000][Iteration 3246][Wall Clock 307.998208872s] Trained 128 records in 0.107979257 seconds. Throughput is 1185.4128 records/second. Loss is 2.0198824. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3557126030624264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 55424/60000][Iteration 3247][Wall Clock 308.104804956s] Trained 128 records in 0.106596084 seconds. Throughput is 1200.7946 records/second. Loss is 2.053994. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3551577955723032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 55552/60000][Iteration 3248][Wall Clock 308.212272905s] Trained 128 records in 0.107467949 seconds. Throughput is 1191.0527 records/second. Loss is 2.0839434. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.354603249352484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 55680/60000][Iteration 3249][Wall Clock 308.307601397s] Trained 128 records in 0.095328492 seconds. Throughput is 1342.7255 records/second. Loss is 2.0365813. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3540489642184556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 55808/60000][Iteration 3250][Wall Clock 308.417864178s] Trained 128 records in 0.110262781 seconds. Throughput is 1160.8632 records/second. Loss is 2.0170598. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3534949399858787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 55936/60000][Iteration 3251][Wall Clock 308.530049454s] Trained 128 records in 0.112185276 seconds. Throughput is 1140.9697 records/second. Loss is 2.0535133. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3529411764705883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 56064/60000][Iteration 3252][Wall Clock 308.61502732s] Trained 128 records in 0.084977866 seconds. Throughput is 1506.2747 records/second. Loss is 2.079956. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3523876734885912E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 56192/60000][Iteration 3253][Wall Clock 308.710453627s] Trained 128 records in 0.095426307 seconds. Throughput is 1341.3492 records/second. Loss is 2.0672648. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3518344308560675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 56320/60000][Iteration 3254][Wall Clock 308.795201677s] Trained 128 records in 0.08474805 seconds. Throughput is 1510.3593 records/second. Loss is 2.0544431. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.351281448389372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 56448/60000][Iteration 3255][Wall Clock 308.882378586s] Trained 128 records in 0.087176909 seconds. Throughput is 1468.2787 records/second. Loss is 2.003424. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.350728725905031E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:24 INFO  DistriOptimizer$:408 - [Epoch 7 56576/60000][Iteration 3256][Wall Clock 308.967972028s] Trained 128 records in 0.085593442 seconds. Throughput is 1495.4418 records/second. Loss is 2.0478935. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3501762632197415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 56704/60000][Iteration 3257][Wall Clock 309.051895966s] Trained 128 records in 0.083923938 seconds. Throughput is 1525.1907 records/second. Loss is 2.0673544. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3496240601503758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 56832/60000][Iteration 3258][Wall Clock 309.135769892s] Trained 128 records in 0.083873926 seconds. Throughput is 1526.1 records/second. Loss is 2.0673037. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.349072116513977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 56960/60000][Iteration 3259][Wall Clock 309.219733918s] Trained 128 records in 0.083964026 seconds. Throughput is 1524.4624 records/second. Loss is 2.0512369. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3485204321277596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57088/60000][Iteration 3260][Wall Clock 309.305695168s] Trained 128 records in 0.08596125 seconds. Throughput is 1489.043 records/second. Loss is 2.0817256. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.34796900680911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57216/60000][Iteration 3261][Wall Clock 309.395825001s] Trained 128 records in 0.090129833 seconds. Throughput is 1420.1736 records/second. Loss is 2.038435. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.347417840375587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57344/60000][Iteration 3262][Wall Clock 309.483081133s] Trained 128 records in 0.087256132 seconds. Throughput is 1466.9456 records/second. Loss is 2.0632777. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.346866932644919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57472/60000][Iteration 3263][Wall Clock 309.558124665s] Trained 128 records in 0.075043532 seconds. Throughput is 1705.6768 records/second. Loss is 2.0514886. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.346316283435007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57600/60000][Iteration 3264][Wall Clock 309.64189818s] Trained 128 records in 0.083773515 seconds. Throughput is 1527.9292 records/second. Loss is 2.036212. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3457658925639223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57728/60000][Iteration 3265][Wall Clock 309.729362899s] Trained 128 records in 0.087464719 seconds. Throughput is 1463.4473 records/second. Loss is 2.0488653. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3452157598499062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57856/60000][Iteration 3266][Wall Clock 309.815718994s] Trained 128 records in 0.086356095 seconds. Throughput is 1482.2346 records/second. Loss is 2.0860367. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3446658851113714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 57984/60000][Iteration 3267][Wall Clock 309.902508994s] Trained 128 records in 0.08679 seconds. Throughput is 1474.8242 records/second. Loss is 2.0609365. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3441162681669012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:25 INFO  DistriOptimizer$:408 - [Epoch 7 58112/60000][Iteration 3268][Wall Clock 309.987979723s] Trained 128 records in 0.085470729 seconds. Throughput is 1497.5887 records/second. Loss is 2.0580199. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3435669088352475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 58240/60000][Iteration 3269][Wall Clock 310.073671431s] Trained 128 records in 0.085691708 seconds. Throughput is 1493.7268 records/second. Loss is 2.02161. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3430178069353325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 58368/60000][Iteration 3270][Wall Clock 310.157170465s] Trained 128 records in 0.083499034 seconds. Throughput is 1532.9518 records/second. Loss is 2.076495. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3424689622862497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 58496/60000][Iteration 3271][Wall Clock 310.239617323s] Trained 128 records in 0.082446858 seconds. Throughput is 1552.5151 records/second. Loss is 2.081394. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3419203747072602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 58624/60000][Iteration 3272][Wall Clock 310.323416392s] Trained 128 records in 0.083799069 seconds. Throughput is 1527.4633 records/second. Loss is 2.045493. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3413720440177945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 58752/60000][Iteration 3273][Wall Clock 310.40773596s] Trained 128 records in 0.084319568 seconds. Throughput is 1518.0343 records/second. Loss is 2.0826764. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3408239700374532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 58880/60000][Iteration 3274][Wall Clock 310.491853406s] Trained 128 records in 0.084117446 seconds. Throughput is 1521.682 records/second. Loss is 2.0659032. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3402761525860054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 59008/60000][Iteration 3275][Wall Clock 310.574874218s] Trained 128 records in 0.083020812 seconds. Throughput is 1541.7821 records/second. Loss is 2.036094. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.339728591483388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 59136/60000][Iteration 3276][Wall Clock 310.65823573s] Trained 128 records in 0.083361512 seconds. Throughput is 1535.4807 records/second. Loss is 2.0333524. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3391812865497074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 59264/60000][Iteration 3277][Wall Clock 310.743729622s] Trained 128 records in 0.085493892 seconds. Throughput is 1497.183 records/second. Loss is 2.061434. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3386342376052386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 59392/60000][Iteration 3278][Wall Clock 310.830882613s] Trained 128 records in 0.087152991 seconds. Throughput is 1468.6818 records/second. Loss is 2.042851. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3380874444704232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 59520/60000][Iteration 3279][Wall Clock 310.915973977s] Trained 128 records in 0.085091364 seconds. Throughput is 1504.2654 records/second. Loss is 2.0710547. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3375409069658717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:26 INFO  DistriOptimizer$:408 - [Epoch 7 59648/60000][Iteration 3280][Wall Clock 311.000351175s] Trained 128 records in 0.084377198 seconds. Throughput is 1516.9974 records/second. Loss is 2.0675936. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3369946249123628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:27 INFO  DistriOptimizer$:408 - [Epoch 7 59776/60000][Iteration 3281][Wall Clock 311.083232862s] Trained 128 records in 0.082881687 seconds. Throughput is 1544.3701 records/second. Loss is 2.0675645. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.336448598130841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:27 INFO  DistriOptimizer$:408 - [Epoch 7 59904/60000][Iteration 3282][Wall Clock 311.166685128s] Trained 128 records in 0.083452266 seconds. Throughput is 1533.8109 records/second. Loss is 2.0545218. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3359028264424196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:27 INFO  DistriOptimizer$:408 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 311.250930388s] Trained 128 records in 0.08424526 seconds. Throughput is 1519.3734 records/second. Loss is 2.0465338. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3353573096683794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:27 INFO  DistriOptimizer$:452 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 311.250930388s] Epoch finished. Wall clock time is 312360.157334 ms
2019-10-14 23:16:27 INFO  DistriOptimizer$:111 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 311.250930388s] Validate model...
2019-10-14 23:16:28 INFO  DistriOptimizer$:178 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 311.250930388s] validate model throughput is 12399.158 records/second
2019-10-14 23:16:28 INFO  DistriOptimizer$:181 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 311.250930388s] Top1Accuracy is Accuracy(correct: 5496, count: 10000, accuracy: 0.5496)
2019-10-14 23:16:28 INFO  DistriOptimizer$:221 - [Wall Clock 312.360157334s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:16:28 INFO  DistriOptimizer$:226 - [Wall Clock 312.360157334s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 128/60000][Iteration 3284][Wall Clock 312.456090485s] Trained 128 records in 0.095933151 seconds. Throughput is 1334.2625 records/second. Loss is 2.023314. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.334812047630166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 256/60000][Iteration 3285][Wall Clock 312.539869372s] Trained 128 records in 0.083778887 seconds. Throughput is 1527.8312 records/second. Loss is 2.024786. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3342670401493927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 384/60000][Iteration 3286][Wall Clock 312.640172037s] Trained 128 records in 0.100302665 seconds. Throughput is 1276.1376 records/second. Loss is 2.0634837. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3337222870478412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 512/60000][Iteration 3287][Wall Clock 312.718129723s] Trained 128 records in 0.077957686 seconds. Throughput is 1641.9164 records/second. Loss is 2.0694191. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3331777881474572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 640/60000][Iteration 3288][Wall Clock 312.797554858s] Trained 128 records in 0.079425135 seconds. Throughput is 1611.5806 records/second. Loss is 2.0632272. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3326335432703523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 768/60000][Iteration 3289][Wall Clock 312.882375184s] Trained 128 records in 0.084820326 seconds. Throughput is 1509.0723 records/second. Loss is 2.037765. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.332089552238806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 896/60000][Iteration 3290][Wall Clock 312.966933712s] Trained 128 records in 0.084558528 seconds. Throughput is 1513.7444 records/second. Loss is 2.0428483. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3315458148752625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 1024/60000][Iteration 3291][Wall Clock 313.050089565s] Trained 128 records in 0.083155853 seconds. Throughput is 1539.2782 records/second. Loss is 2.0510275. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.331002331002331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 1152/60000][Iteration 3292][Wall Clock 313.135294961s] Trained 128 records in 0.085205396 seconds. Throughput is 1502.2522 records/second. Loss is 2.0714197. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.330459100442787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:28 INFO  DistriOptimizer$:408 - [Epoch 8 1280/60000][Iteration 3293][Wall Clock 313.220180993s] Trained 128 records in 0.084886032 seconds. Throughput is 1507.9042 records/second. Loss is 2.0441558. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3299161230195715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 1408/60000][Iteration 3294][Wall Clock 313.305217076s] Trained 128 records in 0.085036083 seconds. Throughput is 1505.2434 records/second. Loss is 2.0285807. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3293733985557886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 1536/60000][Iteration 3295][Wall Clock 313.388115224s] Trained 128 records in 0.082898148 seconds. Throughput is 1544.0635 records/second. Loss is 2.033261. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3288309268747087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 1664/60000][Iteration 3296][Wall Clock 313.473357698s] Trained 128 records in 0.085242474 seconds. Throughput is 1501.5989 records/second. Loss is 2.0626044. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3282887077997672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 1792/60000][Iteration 3297][Wall Clock 313.558175449s] Trained 128 records in 0.084817751 seconds. Throughput is 1509.118 records/second. Loss is 2.0540237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3277467411545624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 1920/60000][Iteration 3298][Wall Clock 313.641671873s] Trained 128 records in 0.083496424 seconds. Throughput is 1532.9999 records/second. Loss is 2.0602655. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3272050267628575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 2048/60000][Iteration 3299][Wall Clock 313.726690826s] Trained 128 records in 0.085018953 seconds. Throughput is 1505.5466 records/second. Loss is 2.0868108. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3266635644485808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 2176/60000][Iteration 3300][Wall Clock 313.809046937s] Trained 128 records in 0.082356111 seconds. Throughput is 1554.226 records/second. Loss is 2.0315216. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3261223540358225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 2304/60000][Iteration 3301][Wall Clock 313.891566942s] Trained 128 records in 0.082520005 seconds. Throughput is 1551.1389 records/second. Loss is 2.0340223. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3255813953488368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 2432/60000][Iteration 3302][Wall Clock 313.975091899s] Trained 128 records in 0.083524957 seconds. Throughput is 1532.4761 records/second. Loss is 2.066219. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3250406882120437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 2560/60000][Iteration 3303][Wall Clock 314.060001597s] Trained 128 records in 0.084909698 seconds. Throughput is 1507.4839 records/second. Loss is 2.0975418. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3245002324500234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:29 INFO  DistriOptimizer$:408 - [Epoch 8 2688/60000][Iteration 3304][Wall Clock 314.144538704s] Trained 128 records in 0.084537107 seconds. Throughput is 1514.128 records/second. Loss is 2.0472229. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3239600278875203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 2816/60000][Iteration 3305][Wall Clock 314.229784622s] Trained 128 records in 0.085245918 seconds. Throughput is 1501.5382 records/second. Loss is 2.0433042. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3234200743494423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 2944/60000][Iteration 3306][Wall Clock 314.315886282s] Trained 128 records in 0.08610166 seconds. Throughput is 1486.6147 records/second. Loss is 2.0566082. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3228803716608597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3072/60000][Iteration 3307][Wall Clock 314.403951645s] Trained 128 records in 0.088065363 seconds. Throughput is 1453.4658 records/second. Loss is 2.0505538. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3223409196470042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3200/60000][Iteration 3308][Wall Clock 314.491145034s] Trained 128 records in 0.087193389 seconds. Throughput is 1468.0011 records/second. Loss is 2.0514445. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3218017181332712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3328/60000][Iteration 3309][Wall Clock 314.577459921s] Trained 128 records in 0.086314887 seconds. Throughput is 1482.9424 records/second. Loss is 2.0591354. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3212627669452182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3456/60000][Iteration 3310][Wall Clock 314.665166899s] Trained 128 records in 0.087706978 seconds. Throughput is 1459.405 records/second. Loss is 2.0487752. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3207240659085633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3584/60000][Iteration 3311][Wall Clock 314.765715926s] Trained 128 records in 0.100549027 seconds. Throughput is 1273.0109 records/second. Loss is 2.0600219. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3201856148491877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3712/60000][Iteration 3312][Wall Clock 314.847024021s] Trained 128 records in 0.081308095 seconds. Throughput is 1574.2589 records/second. Loss is 2.0295641. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3196474135931338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3840/60000][Iteration 3313][Wall Clock 314.927503089s] Trained 128 records in 0.080479068 seconds. Throughput is 1590.4756 records/second. Loss is 2.0009468. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3191094619666046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 3968/60000][Iteration 3314][Wall Clock 315.011988332s] Trained 128 records in 0.084485243 seconds. Throughput is 1515.0575 records/second. Loss is 2.04945. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3185717597959654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 4096/60000][Iteration 3315][Wall Clock 315.098971602s] Trained 128 records in 0.08698327 seconds. Throughput is 1471.5474 records/second. Loss is 2.0438938. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.318034306907742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:30 INFO  DistriOptimizer$:408 - [Epoch 8 4224/60000][Iteration 3316][Wall Clock 315.189351031s] Trained 128 records in 0.090379429 seconds. Throughput is 1416.2515 records/second. Loss is 2.0462582. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3174971031286214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 4352/60000][Iteration 3317][Wall Clock 315.272341642s] Trained 128 records in 0.082990611 seconds. Throughput is 1542.3431 records/second. Loss is 2.0561125. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3169601482854493E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 4480/60000][Iteration 3318][Wall Clock 315.355213597s] Trained 128 records in 0.082871955 seconds. Throughput is 1544.5514 records/second. Loss is 2.0496268. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.316423442205235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 4608/60000][Iteration 3319][Wall Clock 315.443519061s] Trained 128 records in 0.088305464 seconds. Throughput is 1449.5139 records/second. Loss is 2.0361378. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3158869847151461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 4736/60000][Iteration 3320][Wall Clock 315.527445018s] Trained 128 records in 0.083925957 seconds. Throughput is 1525.1539 records/second. Loss is 2.0224757. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.31535077564251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 4864/60000][Iteration 3321][Wall Clock 315.611160657s] Trained 128 records in 0.083715639 seconds. Throughput is 1528.9855 records/second. Loss is 2.0720127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3148148148148146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 4992/60000][Iteration 3322][Wall Clock 315.695448481s] Trained 128 records in 0.084287824 seconds. Throughput is 1518.6061 records/second. Loss is 2.0439875. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3142791020597085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 5120/60000][Iteration 3323][Wall Clock 315.777602843s] Trained 128 records in 0.082154362 seconds. Throughput is 1558.0426 records/second. Loss is 2.0715854. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3137436372049977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 5248/60000][Iteration 3324][Wall Clock 315.860870104s] Trained 128 records in 0.083267261 seconds. Throughput is 1537.2188 records/second. Loss is 2.0570319. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3132084200786488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 5376/60000][Iteration 3325][Wall Clock 315.943213933s] Trained 128 records in 0.082343829 seconds. Throughput is 1554.4576 records/second. Loss is 2.0568585. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3126734505087883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 5504/60000][Iteration 3326][Wall Clock 316.027052958s] Trained 128 records in 0.083839025 seconds. Throughput is 1526.7354 records/second. Loss is 2.0588393. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3121387283236994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 5632/60000][Iteration 3327][Wall Clock 316.109268537s] Trained 128 records in 0.082215579 seconds. Throughput is 1556.8826 records/second. Loss is 2.042487. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.311604253351826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:31 INFO  DistriOptimizer$:408 - [Epoch 8 5760/60000][Iteration 3328][Wall Clock 316.192050601s] Trained 128 records in 0.082782064 seconds. Throughput is 1546.2286 records/second. Loss is 2.0741494. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3110700254217703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 5888/60000][Iteration 3329][Wall Clock 316.275042632s] Trained 128 records in 0.082992031 seconds. Throughput is 1542.3168 records/second. Loss is 2.0505202. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.310536044362292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6016/60000][Iteration 3330][Wall Clock 316.357641617s] Trained 128 records in 0.082598985 seconds. Throughput is 1549.6559 records/second. Loss is 2.0365615. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3100023100023096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6144/60000][Iteration 3331][Wall Clock 316.441027463s] Trained 128 records in 0.083385846 seconds. Throughput is 1535.0327 records/second. Loss is 2.0660212. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3094688221709007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6272/60000][Iteration 3332][Wall Clock 316.52519013s] Trained 128 records in 0.084162667 seconds. Throughput is 1520.8644 records/second. Loss is 2.0412257. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3089355806972989E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6400/60000][Iteration 3333][Wall Clock 316.608534524s] Trained 128 records in 0.083344394 seconds. Throughput is 1535.7961 records/second. Loss is 2.0529144. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3084025854108958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6528/60000][Iteration 3334][Wall Clock 316.693380575s] Trained 128 records in 0.084846051 seconds. Throughput is 1508.6147 records/second. Loss is 2.056901. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3078698361412415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6656/60000][Iteration 3335][Wall Clock 316.777018879s] Trained 128 records in 0.083638304 seconds. Throughput is 1530.3993 records/second. Loss is 2.0611305. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3073373327180436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6784/60000][Iteration 3336][Wall Clock 316.867900118s] Trained 128 records in 0.090881239 seconds. Throughput is 1408.4315 records/second. Loss is 2.0513427. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.306805074971165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 6912/60000][Iteration 3337][Wall Clock 316.948173092s] Trained 128 records in 0.080272974 seconds. Throughput is 1594.5591 records/second. Loss is 2.0874705. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3062730627306272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 7040/60000][Iteration 3338][Wall Clock 317.028996082s] Trained 128 records in 0.08082299 seconds. Throughput is 1583.7078 records/second. Loss is 2.0267358. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3057412958266084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 7168/60000][Iteration 3339][Wall Clock 317.111446218s] Trained 128 records in 0.082450136 seconds. Throughput is 1552.4535 records/second. Loss is 2.036823. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.305209774089442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:32 INFO  DistriOptimizer$:408 - [Epoch 8 7296/60000][Iteration 3340][Wall Clock 317.195103735s] Trained 128 records in 0.083657517 seconds. Throughput is 1530.0477 records/second. Loss is 2.0684779. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3046784973496196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 7424/60000][Iteration 3341][Wall Clock 317.279728573s] Trained 128 records in 0.084624838 seconds. Throughput is 1512.5583 records/second. Loss is 2.039859. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.304147465437788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 7552/60000][Iteration 3342][Wall Clock 317.363635703s] Trained 128 records in 0.08390713 seconds. Throughput is 1525.4961 records/second. Loss is 2.0112743. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.30361667818475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 7680/60000][Iteration 3343][Wall Clock 317.447933366s] Trained 128 records in 0.084297663 seconds. Throughput is 1518.4288 records/second. Loss is 2.0194893. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3030861354214645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 7808/60000][Iteration 3344][Wall Clock 317.539167265s] Trained 128 records in 0.091233899 seconds. Throughput is 1402.9872 records/second. Loss is 2.0558329. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.302555836979047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 7936/60000][Iteration 3345][Wall Clock 317.612169432s] Trained 128 records in 0.073002167 seconds. Throughput is 1753.3726 records/second. Loss is 2.0503986. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.3020257826887665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8064/60000][Iteration 3346][Wall Clock 317.691842067s] Trained 128 records in 0.079672635 seconds. Throughput is 1606.5742 records/second. Loss is 2.020456. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.301495972382048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8192/60000][Iteration 3347][Wall Clock 317.7759998s] Trained 128 records in 0.084157733 seconds. Throughput is 1520.9535 records/second. Loss is 2.0625355. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.300966405890474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8320/60000][Iteration 3348][Wall Clock 317.858525559s] Trained 128 records in 0.082525759 seconds. Throughput is 1551.0309 records/second. Loss is 2.0436907. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.300437083045779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8448/60000][Iteration 3349][Wall Clock 317.945085422s] Trained 128 records in 0.086559863 seconds. Throughput is 1478.7455 records/second. Loss is 2.0838227. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.299908003679853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8576/60000][Iteration 3350][Wall Clock 318.02946319s] Trained 128 records in 0.084377768 seconds. Throughput is 1516.9873 records/second. Loss is 2.062743. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2993791676247414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8704/60000][Iteration 3351][Wall Clock 318.112709552s] Trained 128 records in 0.083246362 seconds. Throughput is 1537.6046 records/second. Loss is 2.0599322. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2988505747126439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:33 INFO  DistriOptimizer$:408 - [Epoch 8 8832/60000][Iteration 3352][Wall Clock 318.195466476s] Trained 128 records in 0.082756924 seconds. Throughput is 1546.6984 records/second. Loss is 2.0461352. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2983222247759135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 8960/60000][Iteration 3353][Wall Clock 318.281983305s] Trained 128 records in 0.086516829 seconds. Throughput is 1479.481 records/second. Loss is 2.0464694. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2977941176470588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9088/60000][Iteration 3354][Wall Clock 318.366508062s] Trained 128 records in 0.084524757 seconds. Throughput is 1514.3492 records/second. Loss is 2.0606828. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2972662531587412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9216/60000][Iteration 3355][Wall Clock 318.449640104s] Trained 128 records in 0.083132042 seconds. Throughput is 1539.7191 records/second. Loss is 2.0472271. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2967386311437759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9344/60000][Iteration 3356][Wall Clock 318.532970833s] Trained 128 records in 0.083330729 seconds. Throughput is 1536.048 records/second. Loss is 2.0477784. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2962112514351318E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9472/60000][Iteration 3357][Wall Clock 318.617043269s] Trained 128 records in 0.084072436 seconds. Throughput is 1522.4967 records/second. Loss is 2.021118. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2956841138659323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9600/60000][Iteration 3358][Wall Clock 318.737433729s] Trained 128 records in 0.12039046 seconds. Throughput is 1063.2072 records/second. Loss is 2.0317438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2951572182694513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9728/60000][Iteration 3359][Wall Clock 318.822321926s] Trained 128 records in 0.084888197 seconds. Throughput is 1507.8657 records/second. Loss is 2.042778. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2946305644791186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9856/60000][Iteration 3360][Wall Clock 318.906739401s] Trained 128 records in 0.084417475 seconds. Throughput is 1516.2737 records/second. Loss is 2.056944. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.294104152328516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 9984/60000][Iteration 3361][Wall Clock 319.002858037s] Trained 128 records in 0.096118636 seconds. Throughput is 1331.6876 records/second. Loss is 2.0729284. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2935779816513765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 10112/60000][Iteration 3362][Wall Clock 319.081810984s] Trained 128 records in 0.078952947 seconds. Throughput is 1621.2188 records/second. Loss is 2.0538182. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2930520522815865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:34 INFO  DistriOptimizer$:408 - [Epoch 8 10240/60000][Iteration 3363][Wall Clock 319.158027209s] Trained 128 records in 0.076216225 seconds. Throughput is 1679.4324 records/second. Loss is 2.050811. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2925263640531865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 10368/60000][Iteration 3364][Wall Clock 319.24081742s] Trained 128 records in 0.082790211 seconds. Throughput is 1546.0765 records/second. Loss is 2.0374215. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.292000916800367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 10496/60000][Iteration 3365][Wall Clock 319.322719668s] Trained 128 records in 0.081902248 seconds. Throughput is 1562.8386 records/second. Loss is 2.0170658. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2914757103574703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 10624/60000][Iteration 3366][Wall Clock 319.407359779s] Trained 128 records in 0.084640111 seconds. Throughput is 1512.2854 records/second. Loss is 2.0525322. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.290950744558992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 10752/60000][Iteration 3367][Wall Clock 319.493346826s] Trained 128 records in 0.085987047 seconds. Throughput is 1488.5963 records/second. Loss is 2.034717. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2904260192395788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 10880/60000][Iteration 3368][Wall Clock 319.575845726s] Trained 128 records in 0.0824989 seconds. Throughput is 1551.5358 records/second. Loss is 2.0521173. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.289901534234028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11008/60000][Iteration 3369][Wall Clock 319.659423663s] Trained 128 records in 0.083577937 seconds. Throughput is 1531.5046 records/second. Loss is 2.0453057. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2893772893772894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11136/60000][Iteration 3370][Wall Clock 319.748447329s] Trained 128 records in 0.089023666 seconds. Throughput is 1437.82 records/second. Loss is 2.0514069. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2888532845044635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11264/60000][Iteration 3371][Wall Clock 319.831866084s] Trained 128 records in 0.083418755 seconds. Throughput is 1534.4271 records/second. Loss is 2.0525613. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.288329519450801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11392/60000][Iteration 3372][Wall Clock 319.915411173s] Trained 128 records in 0.083545089 seconds. Throughput is 1532.1068 records/second. Loss is 2.0283394. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2878059940517042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11520/60000][Iteration 3373][Wall Clock 319.997886264s] Trained 128 records in 0.082475091 seconds. Throughput is 1551.9838 records/second. Loss is 2.037281. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2872827081427266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11648/60000][Iteration 3374][Wall Clock 320.084284721s] Trained 128 records in 0.086398457 seconds. Throughput is 1481.5079 records/second. Loss is 2.037828. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.28675966155957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:35 INFO  DistriOptimizer$:408 - [Epoch 8 11776/60000][Iteration 3375][Wall Clock 320.167258491s] Trained 128 records in 0.08297377 seconds. Throughput is 1542.6561 records/second. Loss is 2.0330722. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2862368541380884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 11904/60000][Iteration 3376][Wall Clock 320.249642083s] Trained 128 records in 0.082383592 seconds. Throughput is 1553.7074 records/second. Loss is 2.0623689. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2857142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12032/60000][Iteration 3377][Wall Clock 320.33293672s] Trained 128 records in 0.083294637 seconds. Throughput is 1536.7136 records/second. Loss is 2.0863812. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2851919561243147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12160/60000][Iteration 3378][Wall Clock 320.416428861s] Trained 128 records in 0.083492141 seconds. Throughput is 1533.0785 records/second. Loss is 2.0259025. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2846698652044777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12288/60000][Iteration 3379][Wall Clock 320.499916707s] Trained 128 records in 0.083487846 seconds. Throughput is 1533.1573 records/second. Loss is 2.0457656. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2841480127912289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12416/60000][Iteration 3380][Wall Clock 320.583174375s] Trained 128 records in 0.083257668 seconds. Throughput is 1537.396 records/second. Loss is 2.0243459. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2836263987211696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12544/60000][Iteration 3381][Wall Clock 320.668268858s] Trained 128 records in 0.085094483 seconds. Throughput is 1504.2103 records/second. Loss is 2.0588465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2831050228310504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12672/60000][Iteration 3382][Wall Clock 320.755567006s] Trained 128 records in 0.087298148 seconds. Throughput is 1466.2396 records/second. Loss is 2.0656905. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2825838849577722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12800/60000][Iteration 3383][Wall Clock 320.842586385s] Trained 128 records in 0.087019379 seconds. Throughput is 1470.9368 records/second. Loss is 2.0404644. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2820629849383846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 12928/60000][Iteration 3384][Wall Clock 320.927168238s] Trained 128 records in 0.084581853 seconds. Throughput is 1513.327 records/second. Loss is 2.0467148. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2815423226100844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 13056/60000][Iteration 3385][Wall Clock 321.011942591s] Trained 128 records in 0.084774353 seconds. Throughput is 1509.8906 records/second. Loss is 2.038331. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.281021897810219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:36 INFO  DistriOptimizer$:408 - [Epoch 8 13184/60000][Iteration 3386][Wall Clock 321.110987104s] Trained 128 records in 0.099044513 seconds. Throughput is 1292.3481 records/second. Loss is 2.023195. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.280501710376283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 13312/60000][Iteration 3387][Wall Clock 321.198013831s] Trained 128 records in 0.087026727 seconds. Throughput is 1470.8125 records/second. Loss is 2.054466. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2799817601459188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 13440/60000][Iteration 3388][Wall Clock 321.275323199s] Trained 128 records in 0.077309368 seconds. Throughput is 1655.6854 records/second. Loss is 2.0726662. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.279462046956918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 13568/60000][Iteration 3389][Wall Clock 321.358899027s] Trained 128 records in 0.083575828 seconds. Throughput is 1531.5432 records/second. Loss is 2.0433607. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.27894257064722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 13696/60000][Iteration 3390][Wall Clock 321.443469949s] Trained 128 records in 0.084570922 seconds. Throughput is 1513.5226 records/second. Loss is 2.0475264. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.27842333105491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 13824/60000][Iteration 3391][Wall Clock 321.529846182s] Trained 128 records in 0.086376233 seconds. Throughput is 1481.889 records/second. Loss is 2.0424914. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.277904328018223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 13952/60000][Iteration 3392][Wall Clock 321.616037237s] Trained 128 records in 0.086191055 seconds. Throughput is 1485.0729 records/second. Loss is 2.0832293. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.277385561375541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 14080/60000][Iteration 3393][Wall Clock 321.699334697s] Trained 128 records in 0.08329746 seconds. Throughput is 1536.6615 records/second. Loss is 2.045918. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.276867030965392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 14208/60000][Iteration 3394][Wall Clock 321.782649725s] Trained 128 records in 0.083315028 seconds. Throughput is 1536.3374 records/second. Loss is 2.0566466. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2763487366264507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 14336/60000][Iteration 3395][Wall Clock 321.873516449s] Trained 128 records in 0.090866724 seconds. Throughput is 1408.6565 records/second. Loss is 2.0104709. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.275830678197542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 14464/60000][Iteration 3396][Wall Clock 321.956629186s] Trained 128 records in 0.083112737 seconds. Throughput is 1540.0768 records/second. Loss is 2.0386224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.275312855517634E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 14592/60000][Iteration 3397][Wall Clock 322.044724927s] Trained 128 records in 0.088095741 seconds. Throughput is 1452.9647 records/second. Loss is 2.061497. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2747952684258417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:37 INFO  DistriOptimizer$:408 - [Epoch 8 14720/60000][Iteration 3398][Wall Clock 322.130042638s] Trained 128 records in 0.085317711 seconds. Throughput is 1500.2747 records/second. Loss is 2.0170333. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2742779167614282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 14848/60000][Iteration 3399][Wall Clock 322.21547626s] Trained 128 records in 0.085433622 seconds. Throughput is 1498.2391 records/second. Loss is 2.062793. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.273760800363802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 14976/60000][Iteration 3400][Wall Clock 322.300377816s] Trained 128 records in 0.084901556 seconds. Throughput is 1507.6284 records/second. Loss is 2.0710075. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2732439190725165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15104/60000][Iteration 3401][Wall Clock 322.387608487s] Trained 128 records in 0.087230671 seconds. Throughput is 1467.3739 records/second. Loss is 2.0808363. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2727272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15232/60000][Iteration 3402][Wall Clock 322.477770444s] Trained 128 records in 0.090161957 seconds. Throughput is 1419.6675 records/second. Loss is 2.0714297. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2722108611679165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15360/60000][Iteration 3403][Wall Clock 322.562689911s] Trained 128 records in 0.084919467 seconds. Throughput is 1507.3104 records/second. Loss is 2.0121534. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2716946842344388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15488/60000][Iteration 3404][Wall Clock 322.647798148s] Trained 128 records in 0.085108237 seconds. Throughput is 1503.9673 records/second. Loss is 2.0169194. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2711787417669768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15616/60000][Iteration 3405][Wall Clock 322.73376748s] Trained 128 records in 0.085969332 seconds. Throughput is 1488.9031 records/second. Loss is 2.0358605. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.270663033605813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15744/60000][Iteration 3406][Wall Clock 322.820871704s] Trained 128 records in 0.087104224 seconds. Throughput is 1469.5039 records/second. Loss is 2.0582554. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2701475595913735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 15872/60000][Iteration 3407][Wall Clock 322.906083729s] Trained 128 records in 0.085212025 seconds. Throughput is 1502.1355 records/second. Loss is 2.0004318. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2696323195642304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 16000/60000][Iteration 3408][Wall Clock 322.993454559s] Trained 128 records in 0.08737083 seconds. Throughput is 1465.0199 records/second. Loss is 2.0727098. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.269117313365101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 16128/60000][Iteration 3409][Wall Clock 323.078414344s] Trained 128 records in 0.084959785 seconds. Throughput is 1506.5952 records/second. Loss is 2.065609. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.268602540834846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:38 INFO  DistriOptimizer$:408 - [Epoch 8 16256/60000][Iteration 3410][Wall Clock 323.162924409s] Trained 128 records in 0.084510065 seconds. Throughput is 1514.6124 records/second. Loss is 2.049457. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.26808800181447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 16384/60000][Iteration 3411][Wall Clock 323.246335899s] Trained 128 records in 0.08341149 seconds. Throughput is 1534.5607 records/second. Loss is 2.052041. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2675736961451246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 16512/60000][Iteration 3412][Wall Clock 323.32824653s] Trained 128 records in 0.081910631 seconds. Throughput is 1562.6787 records/second. Loss is 2.0408423. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2670596236681027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 16640/60000][Iteration 3413][Wall Clock 323.420023464s] Trained 128 records in 0.091776934 seconds. Throughput is 1394.6859 records/second. Loss is 2.0377374. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2665457842248413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 16768/60000][Iteration 3414][Wall Clock 323.504554927s] Trained 128 records in 0.084531463 seconds. Throughput is 1514.2291 records/second. Loss is 2.01643. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2660321776569228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 16896/60000][Iteration 3415][Wall Clock 323.591963819s] Trained 128 records in 0.087408892 seconds. Throughput is 1464.3818 records/second. Loss is 2.0489707. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2655188038060717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 17024/60000][Iteration 3416][Wall Clock 323.675437949s] Trained 128 records in 0.08347413 seconds. Throughput is 1533.4092 records/second. Loss is 2.0591307. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2650056625141563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 17152/60000][Iteration 3417][Wall Clock 323.760923968s] Trained 128 records in 0.085486019 seconds. Throughput is 1497.3209 records/second. Loss is 2.0689404. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2644927536231882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 17280/60000][Iteration 3418][Wall Clock 323.845730546s] Trained 128 records in 0.084806578 seconds. Throughput is 1509.3169 records/second. Loss is 2.0384798. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2639800769753228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 17408/60000][Iteration 3419][Wall Clock 323.92965408s] Trained 128 records in 0.083923534 seconds. Throughput is 1525.1979 records/second. Loss is 2.0298173. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2634676324128565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 17536/60000][Iteration 3420][Wall Clock 324.017336361s] Trained 128 records in 0.087682281 seconds. Throughput is 1459.816 records/second. Loss is 2.0386941. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2629554197782303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:39 INFO  DistriOptimizer$:408 - [Epoch 8 17664/60000][Iteration 3421][Wall Clock 324.09402842s] Trained 128 records in 0.076692059 seconds. Throughput is 1669.0125 records/second. Loss is 2.0358782. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2624434389140272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 17792/60000][Iteration 3422][Wall Clock 324.176124307s] Trained 128 records in 0.082095887 seconds. Throughput is 1559.1525 records/second. Loss is 2.0332224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2619316896629722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 17920/60000][Iteration 3423][Wall Clock 324.260918482s] Trained 128 records in 0.084794175 seconds. Throughput is 1509.5376 records/second. Loss is 2.062186. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2614201718679328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18048/60000][Iteration 3424][Wall Clock 324.345393253s] Trained 128 records in 0.084474771 seconds. Throughput is 1515.2452 records/second. Loss is 2.0591068. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2609088853719196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18176/60000][Iteration 3425][Wall Clock 324.431221805s] Trained 128 records in 0.085828552 seconds. Throughput is 1491.3452 records/second. Loss is 2.0357792. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2603978300180834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18304/60000][Iteration 3426][Wall Clock 324.519911686s] Trained 128 records in 0.088689881 seconds. Throughput is 1443.2312 records/second. Loss is 2.0477593. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2598870056497172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18432/60000][Iteration 3427][Wall Clock 324.604543083s] Trained 128 records in 0.084631397 seconds. Throughput is 1512.441 records/second. Loss is 2.053902. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2593764121102577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18560/60000][Iteration 3428][Wall Clock 324.689338629s] Trained 128 records in 0.084795546 seconds. Throughput is 1509.5132 records/second. Loss is 2.0352292. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.25886604924328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18688/60000][Iteration 3429][Wall Clock 324.772296058s] Trained 128 records in 0.082957429 seconds. Throughput is 1542.96 records/second. Loss is 2.0559556. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2583559168925024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18816/60000][Iteration 3430][Wall Clock 324.855927055s] Trained 128 records in 0.083630997 seconds. Throughput is 1530.5331 records/second. Loss is 2.0346518. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2578460149017836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 18944/60000][Iteration 3431][Wall Clock 324.940635007s] Trained 128 records in 0.084707952 seconds. Throughput is 1511.0742 records/second. Loss is 2.0463028. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2573363431151243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 19072/60000][Iteration 3432][Wall Clock 325.031290684s] Trained 128 records in 0.090655677 seconds. Throughput is 1411.9358 records/second. Loss is 2.0325162. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2568269013766644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:40 INFO  DistriOptimizer$:408 - [Epoch 8 19200/60000][Iteration 3433][Wall Clock 325.116342342s] Trained 128 records in 0.085051658 seconds. Throughput is 1504.9678 records/second. Loss is 2.035239. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2563176895306857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 19328/60000][Iteration 3434][Wall Clock 325.200654424s] Trained 128 records in 0.084312082 seconds. Throughput is 1518.1692 records/second. Loss is 2.0545971. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.255808707421611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 19456/60000][Iteration 3435][Wall Clock 325.283787595s] Trained 128 records in 0.083133171 seconds. Throughput is 1539.6984 records/second. Loss is 2.0656712. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.255299954894001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 19584/60000][Iteration 3436][Wall Clock 325.364386507s] Trained 128 records in 0.080598912 seconds. Throughput is 1588.1107 records/second. Loss is 2.0279622. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.254791431792559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 19712/60000][Iteration 3437][Wall Clock 325.449591061s] Trained 128 records in 0.085204554 seconds. Throughput is 1502.2671 records/second. Loss is 2.0621767. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2542831379621282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 19840/60000][Iteration 3438][Wall Clock 325.524286939s] Trained 128 records in 0.074695878 seconds. Throughput is 1713.6154 records/second. Loss is 2.035254. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2537750732476897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 19968/60000][Iteration 3439][Wall Clock 325.607417949s] Trained 128 records in 0.08313101 seconds. Throughput is 1539.7383 records/second. Loss is 2.0470798. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2532672374943666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 20096/60000][Iteration 3440][Wall Clock 325.689861973s] Trained 128 records in 0.082444024 seconds. Throughput is 1552.5685 records/second. Loss is 2.0698857. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2527596305474206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 20224/60000][Iteration 3441][Wall Clock 325.773128175s] Trained 128 records in 0.083266202 seconds. Throughput is 1537.2384 records/second. Loss is 2.0483336. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2522522522522526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 20352/60000][Iteration 3442][Wall Clock 325.855919062s] Trained 128 records in 0.082790887 seconds. Throughput is 1546.0638 records/second. Loss is 2.0237775. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.251745102454402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 20480/60000][Iteration 3443][Wall Clock 325.938054446s] Trained 128 records in 0.082135384 seconds. Throughput is 1558.4026 records/second. Loss is 2.0085514. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2512381809995497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 20608/60000][Iteration 3444][Wall Clock 326.02172904s] Trained 128 records in 0.083674594 seconds. Throughput is 1529.7355 records/second. Loss is 2.0737152. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2507314877335136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:41 INFO  DistriOptimizer$:408 - [Epoch 8 20736/60000][Iteration 3445][Wall Clock 326.104344368s] Trained 128 records in 0.082615328 seconds. Throughput is 1549.3492 records/second. Loss is 2.0488658. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2502250225022504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 20864/60000][Iteration 3446][Wall Clock 326.196891922s] Trained 128 records in 0.092547554 seconds. Throughput is 1383.0728 records/second. Loss is 2.0517654. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.249718785151856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 20992/60000][Iteration 3447][Wall Clock 326.278388851s] Trained 128 records in 0.081496929 seconds. Throughput is 1570.6113 records/second. Loss is 2.037176. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.249212775528565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21120/60000][Iteration 3448][Wall Clock 326.364066644s] Trained 128 records in 0.085677793 seconds. Throughput is 1493.9694 records/second. Loss is 2.0668893. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2487069934787497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21248/60000][Iteration 3449][Wall Clock 326.448485417s] Trained 128 records in 0.084418773 seconds. Throughput is 1516.2504 records/second. Loss is 2.0141723. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2482014388489207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21376/60000][Iteration 3450][Wall Clock 326.53337628s] Trained 128 records in 0.084890863 seconds. Throughput is 1507.8184 records/second. Loss is 2.056666. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2476961114857274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21504/60000][Iteration 3451][Wall Clock 326.619131935s] Trained 128 records in 0.085755655 seconds. Throughput is 1492.6129 records/second. Loss is 2.058308. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2471910112359551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21632/60000][Iteration 3452][Wall Clock 326.70677161s] Trained 128 records in 0.087639675 seconds. Throughput is 1460.5258 records/second. Loss is 2.030906. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2466861379465288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21760/60000][Iteration 3453][Wall Clock 326.793590354s] Trained 128 records in 0.086818744 seconds. Throughput is 1474.3359 records/second. Loss is 2.0384817. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2461814914645105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 21888/60000][Iteration 3454][Wall Clock 326.877399183s] Trained 128 records in 0.083808829 seconds. Throughput is 1527.2853 records/second. Loss is 2.016643. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2456770716370984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 22016/60000][Iteration 3455][Wall Clock 326.962846782s] Trained 128 records in 0.085447599 seconds. Throughput is 1497.994 records/second. Loss is 2.0036945. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2451728783116296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 22144/60000][Iteration 3456][Wall Clock 327.047686064s] Trained 128 records in 0.084839282 seconds. Throughput is 1508.735 records/second. Loss is 2.0352664. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.244668911335578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:42 INFO  DistriOptimizer$:408 - [Epoch 8 22272/60000][Iteration 3457][Wall Clock 327.132064006s] Trained 128 records in 0.084377942 seconds. Throughput is 1516.9841 records/second. Loss is 2.0484498. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2441651705565533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 22400/60000][Iteration 3458][Wall Clock 327.21659937s] Trained 128 records in 0.084535364 seconds. Throughput is 1514.1593 records/second. Loss is 2.033702. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.243661655822302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 22528/60000][Iteration 3459][Wall Clock 327.301371702s] Trained 128 records in 0.084772332 seconds. Throughput is 1509.9266 records/second. Loss is 2.0381207. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2431583669807088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 22656/60000][Iteration 3460][Wall Clock 327.383440393s] Trained 128 records in 0.082068691 seconds. Throughput is 1559.6691 records/second. Loss is 2.0149393. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2426553038797938E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 22784/60000][Iteration 3461][Wall Clock 327.465187348s] Trained 128 records in 0.081746955 seconds. Throughput is 1565.8075 records/second. Loss is 2.035991. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.242152466367713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 22912/60000][Iteration 3462][Wall Clock 327.540064182s] Trained 128 records in 0.074876834 seconds. Throughput is 1709.4739 records/second. Loss is 2.0120313. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2416498542927594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23040/60000][Iteration 3463][Wall Clock 327.622396018s] Trained 128 records in 0.082331836 seconds. Throughput is 1554.6841 records/second. Loss is 2.0314934. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2411474675033618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23168/60000][Iteration 3464][Wall Clock 327.705428042s] Trained 128 records in 0.083032024 seconds. Throughput is 1541.5739 records/second. Loss is 2.0201113. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2406453058480843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23296/60000][Iteration 3465][Wall Clock 327.789899917s] Trained 128 records in 0.084471875 seconds. Throughput is 1515.2972 records/second. Loss is 2.0178568. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.240143369175627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23424/60000][Iteration 3466][Wall Clock 327.872445033s] Trained 128 records in 0.082545116 seconds. Throughput is 1550.6671 records/second. Loss is 2.030586. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2396416573348266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23552/60000][Iteration 3467][Wall Clock 327.955467687s] Trained 128 records in 0.083022654 seconds. Throughput is 1541.7479 records/second. Loss is 2.066959. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.239140170174653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23680/60000][Iteration 3468][Wall Clock 328.038901784s] Trained 128 records in 0.083434097 seconds. Throughput is 1534.145 records/second. Loss is 2.0288851. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.238638907544213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:43 INFO  DistriOptimizer$:408 - [Epoch 8 23808/60000][Iteration 3469][Wall Clock 328.123532176s] Trained 128 records in 0.084630392 seconds. Throughput is 1512.459 records/second. Loss is 2.063717. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2381378692927484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 23936/60000][Iteration 3470][Wall Clock 328.206484488s] Trained 128 records in 0.082952312 seconds. Throughput is 1543.0552 records/second. Loss is 2.0281365. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2376370552696357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24064/60000][Iteration 3471][Wall Clock 328.29739834s] Trained 128 records in 0.090913852 seconds. Throughput is 1407.9263 records/second. Loss is 2.0329027. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2371364653243846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24192/60000][Iteration 3472][Wall Clock 328.377686586s] Trained 128 records in 0.080288246 seconds. Throughput is 1594.2557 records/second. Loss is 2.002508. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2366360993066427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24320/60000][Iteration 3473][Wall Clock 328.458498102s] Trained 128 records in 0.080811516 seconds. Throughput is 1583.9326 records/second. Loss is 2.088812. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.23613595706619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24448/60000][Iteration 3474][Wall Clock 328.542133096s] Trained 128 records in 0.083634994 seconds. Throughput is 1530.4598 records/second. Loss is 2.016294. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.23563603845294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24576/60000][Iteration 3475][Wall Clock 328.62578022s] Trained 128 records in 0.083647124 seconds. Throughput is 1530.2379 records/second. Loss is 2.0482936. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2351363433169424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24704/60000][Iteration 3476][Wall Clock 328.708121078s] Trained 128 records in 0.082340858 seconds. Throughput is 1554.5138 records/second. Loss is 2.0460532. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2346368715083802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24832/60000][Iteration 3477][Wall Clock 328.7940106s] Trained 128 records in 0.085889522 seconds. Throughput is 1490.2865 records/second. Loss is 2.0457902. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2341376228775692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 24960/60000][Iteration 3478][Wall Clock 328.880771624s] Trained 128 records in 0.086761024 seconds. Throughput is 1475.3168 records/second. Loss is 2.0474892. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2336385972749609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 25088/60000][Iteration 3479][Wall Clock 328.964189523s] Trained 128 records in 0.083417899 seconds. Throughput is 1534.4429 records/second. Loss is 2.079953. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.233139794551139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 25216/60000][Iteration 3480][Wall Clock 329.048607447s] Trained 128 records in 0.084417924 seconds. Throughput is 1516.2656 records/second. Loss is 2.0543942. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2326412145568208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:44 INFO  DistriOptimizer$:408 - [Epoch 8 25344/60000][Iteration 3481][Wall Clock 329.132255769s] Trained 128 records in 0.083648322 seconds. Throughput is 1530.216 records/second. Loss is 2.0404973. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.232142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 25472/60000][Iteration 3482][Wall Clock 329.218154911s] Trained 128 records in 0.085899142 seconds. Throughput is 1490.1196 records/second. Loss is 2.019022. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.231644722160232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 25600/60000][Iteration 3483][Wall Clock 329.304580542s] Trained 128 records in 0.086425631 seconds. Throughput is 1481.0421 records/second. Loss is 2.0304592. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2311468094600624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 25728/60000][Iteration 3484][Wall Clock 329.392619281s] Trained 128 records in 0.088038739 seconds. Throughput is 1453.9054 records/second. Loss is 2.013164. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.230649118893598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 25856/60000][Iteration 3485][Wall Clock 329.478706873s] Trained 128 records in 0.086087592 seconds. Throughput is 1486.8577 records/second. Loss is 1.9828191. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2301516503122213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 25984/60000][Iteration 3486][Wall Clock 329.567780505s] Trained 128 records in 0.089073632 seconds. Throughput is 1437.0133 records/second. Loss is 2.0106611. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2296544035674474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 26112/60000][Iteration 3487][Wall Clock 329.65552253s] Trained 128 records in 0.087742025 seconds. Throughput is 1458.822 records/second. Loss is 2.00405. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2291573785109225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 26240/60000][Iteration 3488][Wall Clock 329.744686507s] Trained 128 records in 0.089163977 seconds. Throughput is 1435.5574 records/second. Loss is 2.0216782. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2286605749944285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 26368/60000][Iteration 3489][Wall Clock 329.834223615s] Trained 128 records in 0.089537108 seconds. Throughput is 1429.575 records/second. Loss is 2.0637202. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2281639928698754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 26496/60000][Iteration 3490][Wall Clock 329.918460968s] Trained 128 records in 0.084237353 seconds. Throughput is 1519.516 records/second. Loss is 2.03436. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2276676319893073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 26624/60000][Iteration 3491][Wall Clock 330.001747536s] Trained 128 records in 0.083286568 seconds. Throughput is 1536.8624 records/second. Loss is 2.0256176. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2271714922048998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:45 INFO  DistriOptimizer$:408 - [Epoch 8 26752/60000][Iteration 3492][Wall Clock 330.086002358s] Trained 128 records in 0.084254822 seconds. Throughput is 1519.2008 records/second. Loss is 2.0528057. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2266755733689602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 26880/60000][Iteration 3493][Wall Clock 330.169273862s] Trained 128 records in 0.083271504 seconds. Throughput is 1537.1405 records/second. Loss is 2.0295756. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.226179875333927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27008/60000][Iteration 3494][Wall Clock 330.252737051s] Trained 128 records in 0.083463189 seconds. Throughput is 1533.6102 records/second. Loss is 2.0411048. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.22568439795237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27136/60000][Iteration 3495][Wall Clock 330.338979605s] Trained 128 records in 0.086242554 seconds. Throughput is 1484.186 records/second. Loss is 2.0283315. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2251891410769918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27264/60000][Iteration 3496][Wall Clock 330.422770131s] Trained 128 records in 0.083790526 seconds. Throughput is 1527.619 records/second. Loss is 2.0302894. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.224694104560623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27392/60000][Iteration 3497][Wall Clock 330.521270419s] Trained 128 records in 0.098500288 seconds. Throughput is 1299.4885 records/second. Loss is 2.0221918. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2241992882562276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27520/60000][Iteration 3498][Wall Clock 330.605928103s] Trained 128 records in 0.084657684 seconds. Throughput is 1511.9714 records/second. Loss is 2.0031412. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2237046920169003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27648/60000][Iteration 3499][Wall Clock 330.688766763s] Trained 128 records in 0.08283866 seconds. Throughput is 1545.1722 records/second. Loss is 2.0229816. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2232103156958648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27776/60000][Iteration 3500][Wall Clock 330.774525496s] Trained 128 records in 0.085758733 seconds. Throughput is 1492.5594 records/second. Loss is 2.0345075. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2227161591464767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 27904/60000][Iteration 3501][Wall Clock 330.858358606s] Trained 128 records in 0.08383311 seconds. Throughput is 1526.843 records/second. Loss is 2.0399399. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2222222222222223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 28032/60000][Iteration 3502][Wall Clock 330.940108898s] Trained 128 records in 0.081750292 seconds. Throughput is 1565.7437 records/second. Loss is 2.0495465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2217285047767166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 28160/60000][Iteration 3503][Wall Clock 331.025938853s] Trained 128 records in 0.085829955 seconds. Throughput is 1491.3208 records/second. Loss is 2.0211868. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2212350066637046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:46 INFO  DistriOptimizer$:408 - [Epoch 8 28288/60000][Iteration 3504][Wall Clock 331.110747659s] Trained 128 records in 0.084808806 seconds. Throughput is 1509.2772 records/second. Loss is 2.0297887. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2207417277370642E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 28416/60000][Iteration 3505][Wall Clock 331.19710229s] Trained 128 records in 0.086354631 seconds. Throughput is 1482.2599 records/second. Loss is 2.0693676. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2202486678507996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 28544/60000][Iteration 3506][Wall Clock 331.281169773s] Trained 128 records in 0.084067483 seconds. Throughput is 1522.5863 records/second. Loss is 2.035271. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2197558268590456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 28672/60000][Iteration 3507][Wall Clock 331.364928052s] Trained 128 records in 0.083758279 seconds. Throughput is 1528.2072 records/second. Loss is 2.0151386. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2192632046160674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 28800/60000][Iteration 3508][Wall Clock 331.448590108s] Trained 128 records in 0.083662056 seconds. Throughput is 1529.9648 records/second. Loss is 2.0478916. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2187708009762592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 28928/60000][Iteration 3509][Wall Clock 331.529753457s] Trained 128 records in 0.081163349 seconds. Throughput is 1577.0665 records/second. Loss is 2.043827. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2182786157941438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29056/60000][Iteration 3510][Wall Clock 331.611680768s] Trained 128 records in 0.081927311 seconds. Throughput is 1562.3605 records/second. Loss is 2.0453022. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2177866489243733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29184/60000][Iteration 3511][Wall Clock 331.695088828s] Trained 128 records in 0.08340806 seconds. Throughput is 1534.6239 records/second. Loss is 2.0386193. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2172949002217298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29312/60000][Iteration 3512][Wall Clock 331.77737143s] Trained 128 records in 0.082282602 seconds. Throughput is 1555.6144 records/second. Loss is 2.0179317. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2168033695411216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29440/60000][Iteration 3513][Wall Clock 331.852758711s] Trained 128 records in 0.075387281 seconds. Throughput is 1697.899 records/second. Loss is 2.0549135. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2163120567375886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29568/60000][Iteration 3514][Wall Clock 331.935835264s] Trained 128 records in 0.083076553 seconds. Throughput is 1540.7477 records/second. Loss is 2.0281014. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2158209616662973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29696/60000][Iteration 3515][Wall Clock 332.020055857s] Trained 128 records in 0.084220593 seconds. Throughput is 1519.8182 records/second. Loss is 2.0428143. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2153300841825432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:47 INFO  DistriOptimizer$:408 - [Epoch 8 29824/60000][Iteration 3516][Wall Clock 332.101945369s] Trained 128 records in 0.081889512 seconds. Throughput is 1563.0818 records/second. Loss is 2.0496683. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2148394241417496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 29952/60000][Iteration 3517][Wall Clock 332.185996262s] Trained 128 records in 0.084050893 seconds. Throughput is 1522.8868 records/second. Loss is 2.0275955. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2143489813994686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30080/60000][Iteration 3518][Wall Clock 332.270288862s] Trained 128 records in 0.0842926 seconds. Throughput is 1518.52 records/second. Loss is 2.0408435. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2138587558113794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30208/60000][Iteration 3519][Wall Clock 332.355596847s] Trained 128 records in 0.085307985 seconds. Throughput is 1500.4457 records/second. Loss is 2.0125303. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2133687472332888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30336/60000][Iteration 3520][Wall Clock 332.43999127s] Trained 128 records in 0.084394423 seconds. Throughput is 1516.6879 records/second. Loss is 2.0341263. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2128789555211329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30464/60000][Iteration 3521][Wall Clock 332.524771143s] Trained 128 records in 0.084779873 seconds. Throughput is 1509.7924 records/second. Loss is 2.073441. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2123893805309737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30592/60000][Iteration 3522][Wall Clock 332.608047273s] Trained 128 records in 0.08327613 seconds. Throughput is 1537.055 records/second. Loss is 2.013374. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2119000221190003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30720/60000][Iteration 3523][Wall Clock 332.698071451s] Trained 128 records in 0.090024178 seconds. Throughput is 1421.8402 records/second. Loss is 2.022463. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2114108801415302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30848/60000][Iteration 3524][Wall Clock 332.782025287s] Trained 128 records in 0.083953836 seconds. Throughput is 1524.6475 records/second. Loss is 2.0602028. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2109219544550078E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 30976/60000][Iteration 3525][Wall Clock 332.866793103s] Trained 128 records in 0.084767816 seconds. Throughput is 1510.007 records/second. Loss is 1.9944825. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2104332449160037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 31104/60000][Iteration 3526][Wall Clock 332.952122285s] Trained 128 records in 0.085329182 seconds. Throughput is 1500.073 records/second. Loss is 2.0213542. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2099447513812155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:48 INFO  DistriOptimizer$:408 - [Epoch 8 31232/60000][Iteration 3527][Wall Clock 333.035445965s] Trained 128 records in 0.08332368 seconds. Throughput is 1536.178 records/second. Loss is 2.036873. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.209456473707468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 31360/60000][Iteration 3528][Wall Clock 333.118848835s] Trained 128 records in 0.08340287 seconds. Throughput is 1534.7194 records/second. Loss is 2.0324838. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.208968411751712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 31488/60000][Iteration 3529][Wall Clock 333.204201137s] Trained 128 records in 0.085352302 seconds. Throughput is 1499.6666 records/second. Loss is 2.0093758. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2084805653710244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 31616/60000][Iteration 3530][Wall Clock 333.289025793s] Trained 128 records in 0.084824656 seconds. Throughput is 1508.9951 records/second. Loss is 2.0391638. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2079929344226098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 31744/60000][Iteration 3531][Wall Clock 333.373995529s] Trained 128 records in 0.084969736 seconds. Throughput is 1506.4187 records/second. Loss is 2.064843. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.207505518763797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 31872/60000][Iteration 3532][Wall Clock 333.461914138s] Trained 128 records in 0.087918609 seconds. Throughput is 1455.892 records/second. Loss is 2.0656626. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2070183182520414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32000/60000][Iteration 3533][Wall Clock 333.547270693s] Trained 128 records in 0.085356555 seconds. Throughput is 1499.5919 records/second. Loss is 2.0495017. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.206531332744925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32128/60000][Iteration 3534][Wall Clock 333.631441619s] Trained 128 records in 0.084170926 seconds. Throughput is 1520.7152 records/second. Loss is 2.0274284. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2060445621001546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32256/60000][Iteration 3535][Wall Clock 333.717217027s] Trained 128 records in 0.085775408 seconds. Throughput is 1492.2693 records/second. Loss is 2.0221944. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.205558006175562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32384/60000][Iteration 3536][Wall Clock 333.809285045s] Trained 128 records in 0.092068018 seconds. Throughput is 1390.2765 records/second. Loss is 2.0348566. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.205071664829107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32512/60000][Iteration 3537][Wall Clock 333.890496291s] Trained 128 records in 0.081211246 seconds. Throughput is 1576.1364 records/second. Loss is 2.0685263. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2045855379188714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32640/60000][Iteration 3538][Wall Clock 333.972084092s] Trained 128 records in 0.081587801 seconds. Throughput is 1568.862 records/second. Loss is 2.0400283. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2040996253030638E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:49 INFO  DistriOptimizer$:408 - [Epoch 8 32768/60000][Iteration 3539][Wall Clock 334.051397759s] Trained 128 records in 0.079313667 seconds. Throughput is 1613.8455 records/second. Loss is 2.0287104. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2036139268400174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 32896/60000][Iteration 3540][Wall Clock 334.136710014s] Trained 128 records in 0.085312255 seconds. Throughput is 1500.3706 records/second. Loss is 2.0403264. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2031284423881914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33024/60000][Iteration 3541][Wall Clock 334.221097307s] Trained 128 records in 0.084387293 seconds. Throughput is 1516.816 records/second. Loss is 2.0430934. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2026431718061675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33152/60000][Iteration 3542][Wall Clock 334.304186487s] Trained 128 records in 0.08308918 seconds. Throughput is 1540.5134 records/second. Loss is 2.050206. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2021581149526536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33280/60000][Iteration 3543][Wall Clock 334.388466267s] Trained 128 records in 0.08427978 seconds. Throughput is 1518.751 records/second. Loss is 2.0207667. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.201673271686482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33408/60000][Iteration 3544][Wall Clock 334.473311961s] Trained 128 records in 0.084845694 seconds. Throughput is 1508.6211 records/second. Loss is 2.0353312. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2011886418666079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33536/60000][Iteration 3545][Wall Clock 334.557112323s] Trained 128 records in 0.083800362 seconds. Throughput is 1527.4397 records/second. Loss is 2.0965736. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2007042253521125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33664/60000][Iteration 3546][Wall Clock 334.642218037s] Trained 128 records in 0.085105714 seconds. Throughput is 1504.0117 records/second. Loss is 2.0640013. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.2002200220022004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33792/60000][Iteration 3547][Wall Clock 334.729813969s] Trained 128 records in 0.087595932 seconds. Throughput is 1461.2551 records/second. Loss is 2.0030808. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1997360316761987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 33920/60000][Iteration 3548][Wall Clock 334.820475173s] Trained 128 records in 0.090661204 seconds. Throughput is 1411.8497 records/second. Loss is 2.023224. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1992522542335603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 34048/60000][Iteration 3549][Wall Clock 334.899110445s] Trained 128 records in 0.078635272 seconds. Throughput is 1627.7682 records/second. Loss is 2.0858922. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1987686895338611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 34176/60000][Iteration 3550][Wall Clock 334.976894694s] Trained 128 records in 0.077784249 seconds. Throughput is 1645.5774 records/second. Loss is 2.0573618. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1982853374367996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:50 INFO  DistriOptimizer$:408 - [Epoch 8 34304/60000][Iteration 3551][Wall Clock 335.06276187s] Trained 128 records in 0.085867176 seconds. Throughput is 1490.6744 records/second. Loss is 2.0236619. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1978021978021975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 34432/60000][Iteration 3552][Wall Clock 335.146402481s] Trained 128 records in 0.083640611 seconds. Throughput is 1530.357 records/second. Loss is 2.0274494. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1973192704900023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 34560/60000][Iteration 3553][Wall Clock 335.23191114s] Trained 128 records in 0.085508659 seconds. Throughput is 1496.9244 records/second. Loss is 2.042972. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1968365553602813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 34688/60000][Iteration 3554][Wall Clock 335.315923012s] Trained 128 records in 0.084011872 seconds. Throughput is 1523.5941 records/second. Loss is 2.0360155. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1963540522732265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 34816/60000][Iteration 3555][Wall Clock 335.400926641s] Trained 128 records in 0.085003629 seconds. Throughput is 1505.8181 records/second. Loss is 2.0297718. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1958717610891522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 34944/60000][Iteration 3556][Wall Clock 335.491556825s] Trained 128 records in 0.090630184 seconds. Throughput is 1412.333 records/second. Loss is 2.0122366. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1953896816684964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35072/60000][Iteration 3557][Wall Clock 335.576256441s] Trained 128 records in 0.084699616 seconds. Throughput is 1511.2229 records/second. Loss is 2.046299. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1949078138718174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35200/60000][Iteration 3558][Wall Clock 335.663316604s] Trained 128 records in 0.087060163 seconds. Throughput is 1470.2477 records/second. Loss is 2.0563004. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.194426157559798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35328/60000][Iteration 3559][Wall Clock 335.750790522s] Trained 128 records in 0.087473918 seconds. Throughput is 1463.2932 records/second. Loss is 2.0414414. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1939447125932427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35456/60000][Iteration 3560][Wall Clock 335.832446567s] Trained 128 records in 0.081656045 seconds. Throughput is 1567.5508 records/second. Loss is 2.029379. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1934634788330773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35584/60000][Iteration 3561][Wall Clock 335.925891616s] Trained 128 records in 0.093445049 seconds. Throughput is 1369.7891 records/second. Loss is 2.0491884. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1929824561403506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35712/60000][Iteration 3562][Wall Clock 336.007900222s] Trained 128 records in 0.082008606 seconds. Throughput is 1560.8118 records/second. Loss is 2.0121353. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1925016443762334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:51 INFO  DistriOptimizer$:408 - [Epoch 8 35840/60000][Iteration 3563][Wall Clock 336.096433801s] Trained 128 records in 0.088533579 seconds. Throughput is 1445.779 records/second. Loss is 2.0101976. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1920210434020165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 35968/60000][Iteration 3564][Wall Clock 336.176759627s] Trained 128 records in 0.080325826 seconds. Throughput is 1593.5099 records/second. Loss is 2.0391123. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1915406530791145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36096/60000][Iteration 3565][Wall Clock 336.261681496s] Trained 128 records in 0.084921869 seconds. Throughput is 1507.2678 records/second. Loss is 2.014761. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1910604732690623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36224/60000][Iteration 3566][Wall Clock 336.347481782s] Trained 128 records in 0.085800286 seconds. Throughput is 1491.8365 records/second. Loss is 2.0740912. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1905805038335163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36352/60000][Iteration 3567][Wall Clock 336.431673041s] Trained 128 records in 0.084191259 seconds. Throughput is 1520.3478 records/second. Loss is 2.0704765. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1901007446342529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36480/60000][Iteration 3568][Wall Clock 336.515979046s] Trained 128 records in 0.084306005 seconds. Throughput is 1518.2786 records/second. Loss is 2.0248036. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1896211955331726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36608/60000][Iteration 3569][Wall Clock 336.601735829s] Trained 128 records in 0.085756783 seconds. Throughput is 1492.5933 records/second. Loss is 1.9842373. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1891418563922945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36736/60000][Iteration 3570][Wall Clock 336.694488515s] Trained 128 records in 0.092752686 seconds. Throughput is 1380.0139 records/second. Loss is 2.0088544. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.188662727073758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36864/60000][Iteration 3571][Wall Clock 336.77827554s] Trained 128 records in 0.083787025 seconds. Throughput is 1527.6829 records/second. Loss is 2.0145786. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1881838074398248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 36992/60000][Iteration 3572][Wall Clock 336.863190179s] Trained 128 records in 0.084914639 seconds. Throughput is 1507.3961 records/second. Loss is 2.0301957. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.187705097352877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 37120/60000][Iteration 3573][Wall Clock 336.947139402s] Trained 128 records in 0.083949223 seconds. Throughput is 1524.7312 records/second. Loss is 2.0321655. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1872265966754156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:52 INFO  DistriOptimizer$:408 - [Epoch 8 37248/60000][Iteration 3574][Wall Clock 337.035163449s] Trained 128 records in 0.088024047 seconds. Throughput is 1454.1481 records/second. Loss is 2.039282. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1867483052700633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 37376/60000][Iteration 3575][Wall Clock 337.123027702s] Trained 128 records in 0.087864253 seconds. Throughput is 1456.7927 records/second. Loss is 2.069319. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1862702229995628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 37504/60000][Iteration 3576][Wall Clock 337.200710621s] Trained 128 records in 0.077682919 seconds. Throughput is 1647.7239 records/second. Loss is 2.047905. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.185792349726776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 37632/60000][Iteration 3577][Wall Clock 337.281113299s] Trained 128 records in 0.080402678 seconds. Throughput is 1591.9867 records/second. Loss is 2.0411277. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.185314685314685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 37760/60000][Iteration 3578][Wall Clock 337.364263148s] Trained 128 records in 0.083149849 seconds. Throughput is 1539.3894 records/second. Loss is 1.9895236. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.184837229626393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 37888/60000][Iteration 3579][Wall Clock 337.447685636s] Trained 128 records in 0.083422488 seconds. Throughput is 1534.3584 records/second. Loss is 2.0436544. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1843599825251202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38016/60000][Iteration 3580][Wall Clock 337.53111311s] Trained 128 records in 0.083427474 seconds. Throughput is 1534.2667 records/second. Loss is 1.9964591. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.183882943874208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38144/60000][Iteration 3581][Wall Clock 337.615072173s] Trained 128 records in 0.083959063 seconds. Throughput is 1524.5525 records/second. Loss is 2.0622492. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.183406113537118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38272/60000][Iteration 3582][Wall Clock 337.696450869s] Trained 128 records in 0.081378696 seconds. Throughput is 1572.8932 records/second. Loss is 1.9764489. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1829294913774288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38400/60000][Iteration 3583][Wall Clock 337.779440334s] Trained 128 records in 0.082989465 seconds. Throughput is 1542.3645 records/second. Loss is 2.0405636. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1824530772588386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38528/60000][Iteration 3584][Wall Clock 337.862752329s] Trained 128 records in 0.083311995 seconds. Throughput is 1536.3933 records/second. Loss is 2.0448785. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.181976871045167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38656/60000][Iteration 3585][Wall Clock 337.946398139s] Trained 128 records in 0.08364581 seconds. Throughput is 1530.2618 records/second. Loss is 2.0045424. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1815008726003494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:53 INFO  DistriOptimizer$:408 - [Epoch 8 38784/60000][Iteration 3586][Wall Clock 338.038498729s] Trained 128 records in 0.09210059 seconds. Throughput is 1389.7848 records/second. Loss is 2.0593631. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1810250817884405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 38912/60000][Iteration 3587][Wall Clock 338.114982223s] Trained 128 records in 0.076483494 seconds. Throughput is 1673.5637 records/second. Loss is 2.0280578. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1805494984736151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39040/60000][Iteration 3588][Wall Clock 338.199383682s] Trained 128 records in 0.084401459 seconds. Throughput is 1516.5615 records/second. Loss is 2.0657592. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1800741225201658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39168/60000][Iteration 3589][Wall Clock 338.286892336s] Trained 128 records in 0.087508654 seconds. Throughput is 1462.7124 records/second. Loss is 2.0378647. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1795989537925023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39296/60000][Iteration 3590][Wall Clock 338.374478059s] Trained 128 records in 0.087585723 seconds. Throughput is 1461.4254 records/second. Loss is 2.042463. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1791239921551534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39424/60000][Iteration 3591][Wall Clock 338.460462063s] Trained 128 records in 0.085984004 seconds. Throughput is 1488.6489 records/second. Loss is 2.043652. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.178649237472767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39552/60000][Iteration 3592][Wall Clock 338.546762939s] Trained 128 records in 0.086300876 seconds. Throughput is 1483.183 records/second. Loss is 2.0331988. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1781746896101068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39680/60000][Iteration 3593][Wall Clock 338.634144627s] Trained 128 records in 0.087381688 seconds. Throughput is 1464.8378 records/second. Loss is 2.0332758. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1777003484320555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39808/60000][Iteration 3594][Wall Clock 338.721792734s] Trained 128 records in 0.087648107 seconds. Throughput is 1460.3853 records/second. Loss is 2.0403247. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1772262138036142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 39936/60000][Iteration 3595][Wall Clock 338.807740848s] Trained 128 records in 0.085948114 seconds. Throughput is 1489.2705 records/second. Loss is 2.0440319. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1767522855899003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 40064/60000][Iteration 3596][Wall Clock 338.893006874s] Trained 128 records in 0.085266026 seconds. Throughput is 1501.1841 records/second. Loss is 2.0228338. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1762785636561478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 40192/60000][Iteration 3597][Wall Clock 338.97869531s] Trained 128 records in 0.085688436 seconds. Throughput is 1493.7838 records/second. Loss is 1.9687579. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.175805047867711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:54 INFO  DistriOptimizer$:408 - [Epoch 8 40320/60000][Iteration 3598][Wall Clock 339.062384727s] Trained 128 records in 0.083689417 seconds. Throughput is 1529.4646 records/second. Loss is 2.0225136. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.175331738090059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 40448/60000][Iteration 3599][Wall Clock 339.145770593s] Trained 128 records in 0.083385866 seconds. Throughput is 1535.0323 records/second. Loss is 2.0571332. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1748586341887777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 40576/60000][Iteration 3600][Wall Clock 339.234657059s] Trained 128 records in 0.088886466 seconds. Throughput is 1440.0392 records/second. Loss is 2.0051029. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1743857360295715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 40704/60000][Iteration 3601][Wall Clock 339.311284673s] Trained 128 records in 0.076627614 seconds. Throughput is 1670.4161 records/second. Loss is 2.0291936. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.173913043478261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 40832/60000][Iteration 3602][Wall Clock 339.396365211s] Trained 128 records in 0.085080538 seconds. Throughput is 1504.4568 records/second. Loss is 2.0710604. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1734405564007825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 40960/60000][Iteration 3603][Wall Clock 339.493230333s] Trained 128 records in 0.096865122 seconds. Throughput is 1321.425 records/second. Loss is 1.9971156. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1729682746631898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 41088/60000][Iteration 3604][Wall Clock 339.576878695s] Trained 128 records in 0.083648362 seconds. Throughput is 1530.2153 records/second. Loss is 1.9845203. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1724961981316534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 41216/60000][Iteration 3605][Wall Clock 339.660591141s] Trained 128 records in 0.083712446 seconds. Throughput is 1529.0438 records/second. Loss is 1.9992448. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1720243266724586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 41344/60000][Iteration 3606][Wall Clock 339.743212896s] Trained 128 records in 0.082621755 seconds. Throughput is 1549.2288 records/second. Loss is 2.0158532. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1715526601520085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 41472/60000][Iteration 3607][Wall Clock 339.829223488s] Trained 128 records in 0.086010592 seconds. Throughput is 1488.1888 records/second. Loss is 2.0429237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1710811984368216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 41600/60000][Iteration 3608][Wall Clock 339.91277894s] Trained 128 records in 0.083555452 seconds. Throughput is 1531.9167 records/second. Loss is 1.9948484. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1706099413935315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:55 INFO  DistriOptimizer$:408 - [Epoch 8 41728/60000][Iteration 3609][Wall Clock 339.99801445s] Trained 128 records in 0.08523551 seconds. Throughput is 1501.7216 records/second. Loss is 2.0330422. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1701388888888888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 41856/60000][Iteration 3610][Wall Clock 340.080722052s] Trained 128 records in 0.082707602 seconds. Throughput is 1547.6208 records/second. Loss is 2.0080962. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1696680407897592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 41984/60000][Iteration 3611][Wall Clock 340.174940341s] Trained 128 records in 0.094218289 seconds. Throughput is 1358.5472 records/second. Loss is 1.9931226. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.169197396963124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42112/60000][Iteration 3612][Wall Clock 340.255427564s] Trained 128 records in 0.080487223 seconds. Throughput is 1590.3146 records/second. Loss is 2.0255919. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1687269572760786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42240/60000][Iteration 3613][Wall Clock 340.338511723s] Trained 128 records in 0.083084159 seconds. Throughput is 1540.6066 records/second. Loss is 2.00472. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.168256721595837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42368/60000][Iteration 3614][Wall Clock 340.421637614s] Trained 128 records in 0.083125891 seconds. Throughput is 1539.8331 records/second. Loss is 2.05856. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.167786689789725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42496/60000][Iteration 3615][Wall Clock 340.508162393s] Trained 128 records in 0.086524779 seconds. Throughput is 1479.3451 records/second. Loss is 2.0309274. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1673168617251845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42624/60000][Iteration 3616][Wall Clock 340.596544965s] Trained 128 records in 0.088382572 seconds. Throughput is 1448.2493 records/second. Loss is 2.0144956. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1668472372697725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42752/60000][Iteration 3617][Wall Clock 340.682916913s] Trained 128 records in 0.086371948 seconds. Throughput is 1481.9626 records/second. Loss is 2.0437853. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1663778162911613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 42880/60000][Iteration 3618][Wall Clock 340.766847204s] Trained 128 records in 0.083930291 seconds. Throughput is 1525.0751 records/second. Loss is 2.0456924. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1659085986571366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 43008/60000][Iteration 3619][Wall Clock 340.855573036s] Trained 128 records in 0.088725832 seconds. Throughput is 1442.6464 records/second. Loss is 2.037657. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1654395842355997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 43136/60000][Iteration 3620][Wall Clock 340.942189687s] Trained 128 records in 0.086616651 seconds. Throughput is 1477.7759 records/second. Loss is 2.0222027. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.164970772894566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:56 INFO  DistriOptimizer$:408 - [Epoch 8 43264/60000][Iteration 3621][Wall Clock 341.027980567s] Trained 128 records in 0.08579088 seconds. Throughput is 1492.0001 records/second. Loss is 2.0131586. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1645021645021645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 43392/60000][Iteration 3622][Wall Clock 341.113375484s] Trained 128 records in 0.085394917 seconds. Throughput is 1498.9182 records/second. Loss is 2.0293849. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1640337589266391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 43520/60000][Iteration 3623][Wall Clock 341.200094263s] Trained 128 records in 0.086718779 seconds. Throughput is 1476.0356 records/second. Loss is 2.016241. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.163565556036348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 43648/60000][Iteration 3624][Wall Clock 341.283899593s] Trained 128 records in 0.08380533 seconds. Throughput is 1527.3491 records/second. Loss is 2.0389457. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.163097555699762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 43776/60000][Iteration 3625][Wall Clock 341.376731733s] Trained 128 records in 0.09283214 seconds. Throughput is 1378.8328 records/second. Loss is 2.039372. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.162629757785467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 43904/60000][Iteration 3626][Wall Clock 341.45521256s] Trained 128 records in 0.078480827 seconds. Throughput is 1630.9717 records/second. Loss is 2.0360446. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1621621621621621E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44032/60000][Iteration 3627][Wall Clock 341.535824283s] Trained 128 records in 0.080611723 seconds. Throughput is 1587.8584 records/second. Loss is 1.9752362. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.16169476869866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44160/60000][Iteration 3628][Wall Clock 341.619412844s] Trained 128 records in 0.083588561 seconds. Throughput is 1531.3099 records/second. Loss is 2.0292208. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1612275772638857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44288/60000][Iteration 3629][Wall Clock 341.704219804s] Trained 128 records in 0.08480696 seconds. Throughput is 1509.3102 records/second. Loss is 2.0081413. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.16076058772688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44416/60000][Iteration 3630][Wall Clock 341.786635915s] Trained 128 records in 0.082416111 seconds. Throughput is 1553.0944 records/second. Loss is 2.045627. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1602937999567944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44544/60000][Iteration 3631][Wall Clock 341.870456115s] Trained 128 records in 0.0838202 seconds. Throughput is 1527.0781 records/second. Loss is 2.0379827. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1598272138228941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44672/60000][Iteration 3632][Wall Clock 341.955444961s] Trained 128 records in 0.084988846 seconds. Throughput is 1506.08 records/second. Loss is 1.9997414. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1593608291945585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:57 INFO  DistriOptimizer$:408 - [Epoch 8 44800/60000][Iteration 3633][Wall Clock 342.052777693s] Trained 128 records in 0.097332732 seconds. Throughput is 1315.0767 records/second. Loss is 2.0430534. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1588946459412782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 44928/60000][Iteration 3634][Wall Clock 342.1381276s] Trained 128 records in 0.085349907 seconds. Throughput is 1499.7086 records/second. Loss is 1.9959104. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.158428663932657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45056/60000][Iteration 3635][Wall Clock 342.221867656s] Trained 128 records in 0.083740056 seconds. Throughput is 1528.5397 records/second. Loss is 2.055915. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1579628830384117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45184/60000][Iteration 3636][Wall Clock 342.321435888s] Trained 128 records in 0.099568232 seconds. Throughput is 1285.5505 records/second. Loss is 2.011765. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.157497303128371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45312/60000][Iteration 3637][Wall Clock 342.399227448s] Trained 128 records in 0.07779156 seconds. Throughput is 1645.4227 records/second. Loss is 2.0049448. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1570319240724764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45440/60000][Iteration 3638][Wall Clock 342.476887897s] Trained 128 records in 0.077660449 seconds. Throughput is 1648.2006 records/second. Loss is 2.0352237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1565667457407804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45568/60000][Iteration 3639][Wall Clock 342.559260762s] Trained 128 records in 0.082372865 seconds. Throughput is 1553.9098 records/second. Loss is 2.040278. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1561017680034498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45696/60000][Iteration 3640][Wall Clock 342.646957884s] Trained 128 records in 0.087697122 seconds. Throughput is 1459.5691 records/second. Loss is 1.9929364. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.155636990730761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45824/60000][Iteration 3641][Wall Clock 342.730395688s] Trained 128 records in 0.083437804 seconds. Throughput is 1534.0769 records/second. Loss is 1.990019. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1551724137931031E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 45952/60000][Iteration 3642][Wall Clock 342.813399943s] Trained 128 records in 0.083004255 seconds. Throughput is 1542.0896 records/second. Loss is 2.05028. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1547080370609782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 46080/60000][Iteration 3643][Wall Clock 342.896048109s] Trained 128 records in 0.082648166 seconds. Throughput is 1548.7338 records/second. Loss is 2.058006. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.154243860404998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 46208/60000][Iteration 3644][Wall Clock 342.978125801s] Trained 128 records in 0.082077692 seconds. Throughput is 1559.498 records/second. Loss is 2.0712812. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1537798836958861E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:58 INFO  DistriOptimizer$:408 - [Epoch 8 46336/60000][Iteration 3645][Wall Clock 343.062945431s] Trained 128 records in 0.08481963 seconds. Throughput is 1509.0846 records/second. Loss is 2.0153055. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.153316106804479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 46464/60000][Iteration 3646][Wall Clock 343.147838141s] Trained 128 records in 0.08489271 seconds. Throughput is 1507.7855 records/second. Loss is 2.0321598. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1528525296017224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 46592/60000][Iteration 3647][Wall Clock 343.232587161s] Trained 128 records in 0.08474902 seconds. Throughput is 1510.3419 records/second. Loss is 2.0319657. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1523891519586742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 46720/60000][Iteration 3648][Wall Clock 343.317051691s] Trained 128 records in 0.08446453 seconds. Throughput is 1515.4291 records/second. Loss is 2.0439026. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.151925973746503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 46848/60000][Iteration 3649][Wall Clock 343.399894653s] Trained 128 records in 0.082842962 seconds. Throughput is 1545.092 records/second. Loss is 2.0494955. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.151462994836489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 46976/60000][Iteration 3650][Wall Clock 343.482244454s] Trained 128 records in 0.082349801 seconds. Throughput is 1554.345 records/second. Loss is 2.0312078. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1510002151000216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 47104/60000][Iteration 3651][Wall Clock 343.575747604s] Trained 128 records in 0.09350315 seconds. Throughput is 1368.9379 records/second. Loss is 2.024666. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1505376344086021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 47232/60000][Iteration 3652][Wall Clock 343.659354285s] Trained 128 records in 0.083606681 seconds. Throughput is 1530.9781 records/second. Loss is 2.0184345. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1500752526338424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 47360/60000][Iteration 3653][Wall Clock 343.745107572s] Trained 128 records in 0.085753287 seconds. Throughput is 1492.6542 records/second. Loss is 2.0028617. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1496130696474635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 47488/60000][Iteration 3654][Wall Clock 343.82767887s] Trained 128 records in 0.082571298 seconds. Throughput is 1550.1754 records/second. Loss is 2.0526304. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.149151085321298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 47616/60000][Iteration 3655][Wall Clock 343.911761521s] Trained 128 records in 0.084082651 seconds. Throughput is 1522.3118 records/second. Loss is 2.054999. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1486892995272884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:16:59 INFO  DistriOptimizer$:408 - [Epoch 8 47744/60000][Iteration 3656][Wall Clock 344.001974942s] Trained 128 records in 0.090213421 seconds. Throughput is 1418.8577 records/second. Loss is 2.0402484. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1482277121374866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 47872/60000][Iteration 3657][Wall Clock 344.084476435s] Trained 128 records in 0.082501493 seconds. Throughput is 1551.487 records/second. Loss is 2.0396237. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1477663230240547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48000/60000][Iteration 3658][Wall Clock 344.166837057s] Trained 128 records in 0.082360622 seconds. Throughput is 1554.1407 records/second. Loss is 2.0217943. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1473051320592657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48128/60000][Iteration 3659][Wall Clock 344.251028046s] Trained 128 records in 0.084190989 seconds. Throughput is 1520.3528 records/second. Loss is 2.0011723. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1468441391155006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48256/60000][Iteration 3660][Wall Clock 344.336121757s] Trained 128 records in 0.085093711 seconds. Throughput is 1504.2239 records/second. Loss is 2.0136409. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1463833440652497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48384/60000][Iteration 3661][Wall Clock 344.419864862s] Trained 128 records in 0.083743105 seconds. Throughput is 1528.4841 records/second. Loss is 2.053675. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1459227467811158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48512/60000][Iteration 3662][Wall Clock 344.511578046s] Trained 128 records in 0.091713184 seconds. Throughput is 1395.6554 records/second. Loss is 2.0461147. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.145462347135808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48640/60000][Iteration 3663][Wall Clock 344.595409406s] Trained 128 records in 0.08383136 seconds. Throughput is 1526.8749 records/second. Loss is 2.058946. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.145002145002145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48768/60000][Iteration 3664][Wall Clock 344.67953902s] Trained 128 records in 0.084129614 seconds. Throughput is 1521.4618 records/second. Loss is 2.0172868. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1445421402530558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 48896/60000][Iteration 3665][Wall Clock 344.76439831s] Trained 128 records in 0.08485929 seconds. Throughput is 1508.3794 records/second. Loss is 2.059633. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1440823327615783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 49024/60000][Iteration 3666][Wall Clock 344.847788332s] Trained 128 records in 0.083390022 seconds. Throughput is 1534.9558 records/second. Loss is 1.9958029. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1436227224008576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 49152/60000][Iteration 3667][Wall Clock 344.931609947s] Trained 128 records in 0.083821615 seconds. Throughput is 1527.0524 records/second. Loss is 2.0100288. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.143163309044149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:00 INFO  DistriOptimizer$:408 - [Epoch 8 49280/60000][Iteration 3668][Wall Clock 345.015536278s] Trained 128 records in 0.083926331 seconds. Throughput is 1525.1472 records/second. Loss is 2.0240467. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.142704092564817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 49408/60000][Iteration 3669][Wall Clock 345.100047008s] Trained 128 records in 0.08451073 seconds. Throughput is 1514.6006 records/second. Loss is 2.0195916. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1422450728363323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 49536/60000][Iteration 3670][Wall Clock 345.181234443s] Trained 128 records in 0.081187435 seconds. Throughput is 1576.5986 records/second. Loss is 2.0297973. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1417862497322766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 49664/60000][Iteration 3671][Wall Clock 345.265779399s] Trained 128 records in 0.084544956 seconds. Throughput is 1513.9874 records/second. Loss is 2.0274282. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1413276231263385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 49792/60000][Iteration 3672][Wall Clock 345.353562628s] Trained 128 records in 0.087783229 seconds. Throughput is 1458.1372 records/second. Loss is 2.0226796. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1408691928923143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 49920/60000][Iteration 3673][Wall Clock 345.436424293s] Trained 128 records in 0.082861665 seconds. Throughput is 1544.7433 records/second. Loss is 2.0426974. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1404109589041095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50048/60000][Iteration 3674][Wall Clock 345.521520692s] Trained 128 records in 0.085096399 seconds. Throughput is 1504.1765 records/second. Loss is 2.0090249. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1399529210357372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50176/60000][Iteration 3675][Wall Clock 345.603445493s] Trained 128 records in 0.081924801 seconds. Throughput is 1562.4083 records/second. Loss is 2.0368114. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1394950791613182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50304/60000][Iteration 3676][Wall Clock 345.68510105s] Trained 128 records in 0.081655557 seconds. Throughput is 1567.5602 records/second. Loss is 2.029439. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1390374331550798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50432/60000][Iteration 3677][Wall Clock 345.773992545s] Trained 128 records in 0.088891495 seconds. Throughput is 1439.9579 records/second. Loss is 2.0416968. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.13857998289136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50560/60000][Iteration 3678][Wall Clock 345.84818637s] Trained 128 records in 0.074193825 seconds. Throughput is 1725.2109 records/second. Loss is 2.0584874. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1381227282446015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50688/60000][Iteration 3679][Wall Clock 345.928143918s] Trained 128 records in 0.079957548 seconds. Throughput is 1600.8496 records/second. Loss is 2.0607438. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1376656690893546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:01 INFO  DistriOptimizer$:408 - [Epoch 8 50816/60000][Iteration 3680][Wall Clock 346.01438817s] Trained 128 records in 0.086244252 seconds. Throughput is 1484.1569 records/second. Loss is 2.0158834. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1372088053002778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 50944/60000][Iteration 3681][Wall Clock 346.101157295s] Trained 128 records in 0.086769125 seconds. Throughput is 1475.1791 records/second. Loss is 2.016819. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.136752136752137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51072/60000][Iteration 3682][Wall Clock 346.188063951s] Trained 128 records in 0.086906656 seconds. Throughput is 1472.8446 records/second. Loss is 2.0197203. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1362956633198035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51200/60000][Iteration 3683][Wall Clock 346.277307218s] Trained 128 records in 0.089243267 seconds. Throughput is 1434.2819 records/second. Loss is 2.0572708. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.135839384878257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51328/60000][Iteration 3684][Wall Clock 346.361976871s] Trained 128 records in 0.084669653 seconds. Throughput is 1511.7578 records/second. Loss is 2.0530796. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.135383301302584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51456/60000][Iteration 3685][Wall Clock 346.448490227s] Trained 128 records in 0.086513356 seconds. Throughput is 1479.5404 records/second. Loss is 2.0078955. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.134927412467976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51584/60000][Iteration 3686][Wall Clock 346.534932573s] Trained 128 records in 0.086442346 seconds. Throughput is 1480.7557 records/second. Loss is 2.0165064. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.134471718249733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51712/60000][Iteration 3687][Wall Clock 346.615204274s] Trained 128 records in 0.080271701 seconds. Throughput is 1594.5845 records/second. Loss is 2.0490053. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.134016218523261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51840/60000][Iteration 3688][Wall Clock 346.695110796s] Trained 128 records in 0.079906522 seconds. Throughput is 1601.8717 records/second. Loss is 2.0454423. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1335609131640707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 51968/60000][Iteration 3689][Wall Clock 346.783111405s] Trained 128 records in 0.088000609 seconds. Throughput is 1454.5354 records/second. Loss is 2.0176291. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1331058020477813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 52096/60000][Iteration 3690][Wall Clock 346.867000027s] Trained 128 records in 0.083888622 seconds. Throughput is 1525.8328 records/second. Loss is 2.0087187. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1326508850501172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 52224/60000][Iteration 3691][Wall Clock 346.950628306s] Trained 128 records in 0.083628279 seconds. Throughput is 1530.5826 records/second. Loss is 2.051014. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1321961620469085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:02 INFO  DistriOptimizer$:408 - [Epoch 8 52352/60000][Iteration 3692][Wall Clock 347.034536103s] Trained 128 records in 0.083907797 seconds. Throughput is 1525.484 records/second. Loss is 2.042463. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1317416329140904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 52480/60000][Iteration 3693][Wall Clock 347.122037632s] Trained 128 records in 0.087501529 seconds. Throughput is 1462.8317 records/second. Loss is 1.989856. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1312872975277067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 52608/60000][Iteration 3694][Wall Clock 347.233225233s] Trained 128 records in 0.111187601 seconds. Throughput is 1151.2075 records/second. Loss is 2.0102522. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1308331557639038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 52736/60000][Iteration 3695][Wall Clock 347.34501678s] Trained 128 records in 0.111791547 seconds. Throughput is 1144.9882 records/second. Loss is 2.009632. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.130379207498935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 52864/60000][Iteration 3696][Wall Clock 347.433489317s] Trained 128 records in 0.088472537 seconds. Throughput is 1446.7766 records/second. Loss is 2.0400686. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1299254526091586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 52992/60000][Iteration 3697][Wall Clock 347.549546351s] Trained 128 records in 0.116057034 seconds. Throughput is 1102.906 records/second. Loss is 2.0327435. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1294718909710395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 53120/60000][Iteration 3698][Wall Clock 347.657647497s] Trained 128 records in 0.108101146 seconds. Throughput is 1184.0763 records/second. Loss is 2.0019426. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1290185224611454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 53248/60000][Iteration 3699][Wall Clock 347.763422391s] Trained 128 records in 0.105774894 seconds. Throughput is 1210.1171 records/second. Loss is 1.9574873. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1285653469561513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 53376/60000][Iteration 3700][Wall Clock 347.868083532s] Trained 128 records in 0.104661141 seconds. Throughput is 1222.9945 records/second. Loss is 2.0088127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1281123643328368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:03 INFO  DistriOptimizer$:408 - [Epoch 8 53504/60000][Iteration 3701][Wall Clock 347.974799593s] Trained 128 records in 0.106716061 seconds. Throughput is 1199.4446 records/second. Loss is 2.0141997. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.127659574468085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 53632/60000][Iteration 3702][Wall Clock 348.081087643s] Trained 128 records in 0.10628805 seconds. Throughput is 1204.2745 records/second. Loss is 2.014808. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1272069772388852E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 53760/60000][Iteration 3703][Wall Clock 348.200574048s] Trained 128 records in 0.119486405 seconds. Throughput is 1071.2516 records/second. Loss is 2.0627623. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.126754572522331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 53888/60000][Iteration 3704][Wall Clock 348.304213647s] Trained 128 records in 0.103639599 seconds. Throughput is 1235.0491 records/second. Loss is 2.0224278. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1263023601956197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54016/60000][Iteration 3705][Wall Clock 348.421140516s] Trained 128 records in 0.116926869 seconds. Throughput is 1094.7013 records/second. Loss is 2.006625. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.125850340136054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54144/60000][Iteration 3706][Wall Clock 348.506942892s] Trained 128 records in 0.085802376 seconds. Throughput is 1491.8002 records/second. Loss is 2.0394204. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1253985122210415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54272/60000][Iteration 3707][Wall Clock 348.592304079s] Trained 128 records in 0.085361187 seconds. Throughput is 1499.5105 records/second. Loss is 2.007295. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.124946876328092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54400/60000][Iteration 3708][Wall Clock 348.677817947s] Trained 128 records in 0.085513868 seconds. Throughput is 1496.8333 records/second. Loss is 2.0458496. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.12449543233482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54528/60000][Iteration 3709][Wall Clock 348.761751601s] Trained 128 records in 0.083933654 seconds. Throughput is 1525.014 records/second. Loss is 2.0006804. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1240441801189465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54656/60000][Iteration 3710][Wall Clock 348.849904513s] Trained 128 records in 0.088152912 seconds. Throughput is 1452.0223 records/second. Loss is 2.0402117. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.123593119558293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:04 INFO  DistriOptimizer$:408 - [Epoch 8 54784/60000][Iteration 3711][Wall Clock 348.932610025s] Trained 128 records in 0.082705512 seconds. Throughput is 1547.6598 records/second. Loss is 2.0181065. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1231422505307856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 54912/60000][Iteration 3712][Wall Clock 349.035029053s] Trained 128 records in 0.102419028 seconds. Throughput is 1249.7678 records/second. Loss is 2.0136404. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1226915729144553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55040/60000][Iteration 3713][Wall Clock 349.115955664s] Trained 128 records in 0.080926611 seconds. Throughput is 1581.6799 records/second. Loss is 2.0169203. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1222410865874366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55168/60000][Iteration 3714][Wall Clock 349.20059757s] Trained 128 records in 0.084641906 seconds. Throughput is 1512.2533 records/second. Loss is 2.0512002. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.121790791427965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55296/60000][Iteration 3715][Wall Clock 349.285512125s] Trained 128 records in 0.084914555 seconds. Throughput is 1507.3976 records/second. Loss is 2.0129771. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1213406873143826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55424/60000][Iteration 3716][Wall Clock 349.368576061s] Trained 128 records in 0.083063936 seconds. Throughput is 1540.9816 records/second. Loss is 2.0095007. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1208907741251327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55552/60000][Iteration 3717][Wall Clock 349.452322344s] Trained 128 records in 0.083746283 seconds. Throughput is 1528.426 records/second. Loss is 2.0136716. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1204410517387616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55680/60000][Iteration 3718][Wall Clock 349.53549204s] Trained 128 records in 0.083169696 seconds. Throughput is 1539.0221 records/second. Loss is 2.025858. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1199915200339196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55808/60000][Iteration 3719][Wall Clock 349.6187161s] Trained 128 records in 0.08322406 seconds. Throughput is 1538.0168 records/second. Loss is 2.0334916. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.11954217888936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 55936/60000][Iteration 3720][Wall Clock 349.700588367s] Trained 128 records in 0.081872267 seconds. Throughput is 1563.4109 records/second. Loss is 1.9857875. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1190930281839377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 56064/60000][Iteration 3721][Wall Clock 349.788340516s] Trained 128 records in 0.087752149 seconds. Throughput is 1458.6537 records/second. Loss is 1.9922246. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1186440677966098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 56192/60000][Iteration 3722][Wall Clock 349.871084928s] Trained 128 records in 0.082744412 seconds. Throughput is 1546.9323 records/second. Loss is 2.0210266. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1181952976064393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:05 INFO  DistriOptimizer$:408 - [Epoch 8 56320/60000][Iteration 3723][Wall Clock 349.954966333s] Trained 128 records in 0.083881405 seconds. Throughput is 1525.9639 records/second. Loss is 1.9990213. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.117746717492588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 56448/60000][Iteration 3724][Wall Clock 350.038364812s] Trained 128 records in 0.083398479 seconds. Throughput is 1534.8002 records/second. Loss is 1.9720545. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1172983273343214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 56576/60000][Iteration 3725][Wall Clock 350.121517877s] Trained 128 records in 0.083153065 seconds. Throughput is 1539.33 records/second. Loss is 1.9867877. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1168501270110075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 56704/60000][Iteration 3726][Wall Clock 350.204766985s] Trained 128 records in 0.083249108 seconds. Throughput is 1537.5541 records/second. Loss is 2.0494545. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1164021164021165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 56832/60000][Iteration 3727][Wall Clock 350.289502805s] Trained 128 records in 0.08473582 seconds. Throughput is 1510.5773 records/second. Loss is 2.0113497. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1159542953872197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 56960/60000][Iteration 3728][Wall Clock 350.3754644s] Trained 128 records in 0.085961595 seconds. Throughput is 1489.0371 records/second. Loss is 1.980854. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.115506663845991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57088/60000][Iteration 3729][Wall Clock 350.473121426s] Trained 128 records in 0.097657026 seconds. Throughput is 1310.7096 records/second. Loss is 2.0040233. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1150592216582066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57216/60000][Iteration 3730][Wall Clock 350.555387871s] Trained 128 records in 0.082266445 seconds. Throughput is 1555.9199 records/second. Loss is 2.024421. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1146119687037428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57344/60000][Iteration 3731][Wall Clock 350.63651901s] Trained 128 records in 0.081131139 seconds. Throughput is 1577.6926 records/second. Loss is 2.0333388. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1141649048625792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57472/60000][Iteration 3732][Wall Clock 350.724883743s] Trained 128 records in 0.088364733 seconds. Throughput is 1448.5416 records/second. Loss is 2.0146813. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1137180300147962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57600/60000][Iteration 3733][Wall Clock 350.806076283s] Trained 128 records in 0.08119254 seconds. Throughput is 1576.4995 records/second. Loss is 2.01686. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1132713440405747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57728/60000][Iteration 3734][Wall Clock 350.896186366s] Trained 128 records in 0.090110083 seconds. Throughput is 1420.4847 records/second. Loss is 2.029968. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1128248468201983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:06 INFO  DistriOptimizer$:408 - [Epoch 8 57856/60000][Iteration 3735][Wall Clock 350.982423894s] Trained 128 records in 0.086237528 seconds. Throughput is 1484.2726 records/second. Loss is 2.0069532. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1123785382340515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 57984/60000][Iteration 3736][Wall Clock 351.063684192s] Trained 128 records in 0.081260298 seconds. Throughput is 1575.1849 records/second. Loss is 2.0013576. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.111932418162619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58112/60000][Iteration 3737][Wall Clock 351.151529519s] Trained 128 records in 0.087845327 seconds. Throughput is 1457.1066 records/second. Loss is 2.0110888. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1114864864864863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58240/60000][Iteration 3738][Wall Clock 351.23668036s] Trained 128 records in 0.085150841 seconds. Throughput is 1503.2148 records/second. Loss is 2.0269942. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1110407430863416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58368/60000][Iteration 3739][Wall Clock 351.318309659s] Trained 128 records in 0.081629299 seconds. Throughput is 1568.0645 records/second. Loss is 2.0175092. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.110595187842972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58496/60000][Iteration 3740][Wall Clock 351.401195417s] Trained 128 records in 0.082885758 seconds. Throughput is 1544.2943 records/second. Loss is 2.0354311. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1101498206372655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58624/60000][Iteration 3741][Wall Clock 351.484009915s] Trained 128 records in 0.082814498 seconds. Throughput is 1545.623 records/second. Loss is 2.0290742. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.109704641350211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58752/60000][Iteration 3742][Wall Clock 351.56552958s] Trained 128 records in 0.081519665 seconds. Throughput is 1570.1733 records/second. Loss is 2.0368395. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1092596498628984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 58880/60000][Iteration 3743][Wall Clock 351.64700557s] Trained 128 records in 0.08147599 seconds. Throughput is 1571.015 records/second. Loss is 2.000782. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1088148460565162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 59008/60000][Iteration 3744][Wall Clock 351.729167327s] Trained 128 records in 0.082161757 seconds. Throughput is 1557.9025 records/second. Loss is 1.9956285. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.108370229812355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 59136/60000][Iteration 3745][Wall Clock 351.811352056s] Trained 128 records in 0.082184729 seconds. Throughput is 1557.4669 records/second. Loss is 2.036629. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1079258010118045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 59264/60000][Iteration 3746][Wall Clock 351.892904929s] Trained 128 records in 0.081552873 seconds. Throughput is 1569.5339 records/second. Loss is 2.0241244. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1074815595363542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:07 INFO  DistriOptimizer$:408 - [Epoch 8 59392/60000][Iteration 3747][Wall Clock 351.975954534s] Trained 128 records in 0.083049605 seconds. Throughput is 1541.2476 records/second. Loss is 2.0130782. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1070375052675936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:08 INFO  DistriOptimizer$:408 - [Epoch 8 59520/60000][Iteration 3748][Wall Clock 352.058239174s] Trained 128 records in 0.08228464 seconds. Throughput is 1555.5759 records/second. Loss is 1.9511157. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.106593638087213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:08 INFO  DistriOptimizer$:408 - [Epoch 8 59648/60000][Iteration 3749][Wall Clock 352.140869486s] Trained 128 records in 0.082630312 seconds. Throughput is 1549.0684 records/second. Loss is 2.047062. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1061499578770007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:08 INFO  DistriOptimizer$:408 - [Epoch 8 59776/60000][Iteration 3750][Wall Clock 352.224762396s] Trained 128 records in 0.08389291 seconds. Throughput is 1525.7546 records/second. Loss is 2.0490282. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1057064645188457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:08 INFO  DistriOptimizer$:408 - [Epoch 8 59904/60000][Iteration 3751][Wall Clock 352.307642749s] Trained 128 records in 0.082880353 seconds. Throughput is 1544.3949 records/second. Loss is 2.024973. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.105263157894737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:08 INFO  DistriOptimizer$:408 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.39137041s] Trained 128 records in 0.083727661 seconds. Throughput is 1528.766 records/second. Loss is 2.0332768. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.104820037886761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:08 INFO  DistriOptimizer$:452 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.39137041s] Epoch finished. Wall clock time is 353497.083357 ms
2019-10-14 23:17:08 INFO  DistriOptimizer$:111 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.39137041s] Validate model...
2019-10-14 23:17:09 INFO  DistriOptimizer$:178 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.39137041s] validate model throughput is 12456.577 records/second
2019-10-14 23:17:09 INFO  DistriOptimizer$:181 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.39137041s] Top1Accuracy is Accuracy(correct: 5699, count: 10000, accuracy: 0.5699)
2019-10-14 23:17:09 INFO  DistriOptimizer$:221 - [Wall Clock 353.497083357s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:17:09 INFO  DistriOptimizer$:226 - [Wall Clock 353.497083357s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 128/60000][Iteration 3753][Wall Clock 353.591618251s] Trained 128 records in 0.094534894 seconds. Throughput is 1353.9973 records/second. Loss is 2.0298886. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.104377104377104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 256/60000][Iteration 3754][Wall Clock 353.685097155s] Trained 128 records in 0.093478904 seconds. Throughput is 1369.293 records/second. Loss is 1.98453. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1039343572480537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 384/60000][Iteration 3755][Wall Clock 353.760267328s] Trained 128 records in 0.075170173 seconds. Throughput is 1702.803 records/second. Loss is 2.0067267. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1034917963819945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 512/60000][Iteration 3756][Wall Clock 353.860778984s] Trained 128 records in 0.100511656 seconds. Throughput is 1273.4841 records/second. Loss is 1.9768618. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1030494216614092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 640/60000][Iteration 3757][Wall Clock 353.945985062s] Trained 128 records in 0.085206078 seconds. Throughput is 1502.2402 records/second. Loss is 2.0219107. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1026072329688813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 768/60000][Iteration 3758][Wall Clock 354.03343446s] Trained 128 records in 0.087449398 seconds. Throughput is 1463.7036 records/second. Loss is 2.006165. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1021652301870928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 896/60000][Iteration 3759][Wall Clock 354.115838279s] Trained 128 records in 0.082403819 seconds. Throughput is 1553.3262 records/second. Loss is 2.0106564. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.101723413198823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:09 INFO  DistriOptimizer$:408 - [Epoch 9 1024/60000][Iteration 3760][Wall Clock 354.206918338s] Trained 128 records in 0.091080059 seconds. Throughput is 1405.3569 records/second. Loss is 2.0153422. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.101281781886951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1152/60000][Iteration 3761][Wall Clock 354.291648415s] Trained 128 records in 0.084730077 seconds. Throughput is 1510.6797 records/second. Loss is 2.0179703. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.100840336134454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1280/60000][Iteration 3762][Wall Clock 354.380867691s] Trained 128 records in 0.089219276 seconds. Throughput is 1434.6675 records/second. Loss is 1.9994972. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.1003990758244065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1408/60000][Iteration 3763][Wall Clock 354.461357442s] Trained 128 records in 0.080489751 seconds. Throughput is 1590.2645 records/second. Loss is 2.0159671. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.099958000839983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1536/60000][Iteration 3764][Wall Clock 354.546135656s] Trained 128 records in 0.084778214 seconds. Throughput is 1509.8219 records/second. Loss is 2.0249815. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0995171110644553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1664/60000][Iteration 3765][Wall Clock 354.632374005s] Trained 128 records in 0.086238349 seconds. Throughput is 1484.2585 records/second. Loss is 1.9933596. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0990764063811922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1792/60000][Iteration 3766][Wall Clock 354.718887694s] Trained 128 records in 0.086513689 seconds. Throughput is 1479.5347 records/second. Loss is 2.0029485. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.098635886673662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 1920/60000][Iteration 3767][Wall Clock 354.805899745s] Trained 128 records in 0.087012051 seconds. Throughput is 1471.0605 records/second. Loss is 2.0011542. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.09819555182543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 2048/60000][Iteration 3768][Wall Clock 354.891028542s] Trained 128 records in 0.085128797 seconds. Throughput is 1503.604 records/second. Loss is 2.0150387. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0977554017201597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 2176/60000][Iteration 3769][Wall Clock 354.974549412s] Trained 128 records in 0.08352087 seconds. Throughput is 1532.5511 records/second. Loss is 1.9991899. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0973154362416104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 2304/60000][Iteration 3770][Wall Clock 355.057854423s] Trained 128 records in 0.083305011 seconds. Throughput is 1536.5222 records/second. Loss is 2.045429. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0968756552736424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:10 INFO  DistriOptimizer$:408 - [Epoch 9 2432/60000][Iteration 3771][Wall Clock 355.143600218s] Trained 128 records in 0.085745795 seconds. Throughput is 1492.7845 records/second. Loss is 2.0233212. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0964360587002098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 2560/60000][Iteration 3772][Wall Clock 355.226984276s] Trained 128 records in 0.083384058 seconds. Throughput is 1535.0656 records/second. Loss is 2.0056129. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0959966464053657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 2688/60000][Iteration 3773][Wall Clock 355.311030203s] Trained 128 records in 0.084045927 seconds. Throughput is 1522.9769 records/second. Loss is 2.0174086. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0955574182732607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 2816/60000][Iteration 3774][Wall Clock 355.394587122s] Trained 128 records in 0.083556919 seconds. Throughput is 1531.8899 records/second. Loss is 2.0461938. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0951183741881418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 2944/60000][Iteration 3775][Wall Clock 355.478136777s] Trained 128 records in 0.083549655 seconds. Throughput is 1532.0231 records/second. Loss is 2.0257955. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0946795140343527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3072/60000][Iteration 3776][Wall Clock 355.561724096s] Trained 128 records in 0.083587319 seconds. Throughput is 1531.3328 records/second. Loss is 1.99749. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.094240837696335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3200/60000][Iteration 3777][Wall Clock 355.645740772s] Trained 128 records in 0.084016676 seconds. Throughput is 1523.5071 records/second. Loss is 2.0417802. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0938023450586265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3328/60000][Iteration 3778][Wall Clock 355.730295747s] Trained 128 records in 0.084554975 seconds. Throughput is 1513.808 records/second. Loss is 2.0496929. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0933640360058613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3456/60000][Iteration 3779][Wall Clock 355.821473445s] Trained 128 records in 0.091177698 seconds. Throughput is 1403.8522 records/second. Loss is 2.0194042. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0929259104227708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3584/60000][Iteration 3780][Wall Clock 355.899277793s] Trained 128 records in 0.077804348 seconds. Throughput is 1645.1522 records/second. Loss is 2.0289445. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.092487968194183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3712/60000][Iteration 3781][Wall Clock 355.975893154s] Trained 128 records in 0.076615361 seconds. Throughput is 1670.6832 records/second. Loss is 1.9967316. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0920502092050208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3840/60000][Iteration 3782][Wall Clock 356.061573722s] Trained 128 records in 0.085680568 seconds. Throughput is 1493.921 records/second. Loss is 2.0450048. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0916126333403052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:11 INFO  DistriOptimizer$:408 - [Epoch 9 3968/60000][Iteration 3783][Wall Clock 356.146448935s] Trained 128 records in 0.084875213 seconds. Throughput is 1508.0964 records/second. Loss is 2.0135243. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0911752404851526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4096/60000][Iteration 3784][Wall Clock 356.230662263s] Trained 128 records in 0.084213328 seconds. Throughput is 1519.9493 records/second. Loss is 1.9800324. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0907380305247754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4224/60000][Iteration 3785][Wall Clock 356.314830289s] Trained 128 records in 0.084168026 seconds. Throughput is 1520.7676 records/second. Loss is 2.0185416. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0903010033444813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4352/60000][Iteration 3786][Wall Clock 356.39965496s] Trained 128 records in 0.084824671 seconds. Throughput is 1508.9949 records/second. Loss is 2.0401058. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.089864158829676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4480/60000][Iteration 3787][Wall Clock 356.489325545s] Trained 128 records in 0.089670585 seconds. Throughput is 1427.4469 records/second. Loss is 2.0546472. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.089427496865859E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4608/60000][Iteration 3788][Wall Clock 356.570114725s] Trained 128 records in 0.08078918 seconds. Throughput is 1584.3706 records/second. Loss is 2.0073183. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0889910173386257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4736/60000][Iteration 3789][Wall Clock 356.651995593s] Trained 128 records in 0.081880868 seconds. Throughput is 1563.2467 records/second. Loss is 2.0233078. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0885547201336674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4864/60000][Iteration 3790][Wall Clock 356.738696415s] Trained 128 records in 0.086700822 seconds. Throughput is 1476.3413 records/second. Loss is 2.0059943. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.088118605136772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 4992/60000][Iteration 3791][Wall Clock 356.825149158s] Trained 128 records in 0.086452743 seconds. Throughput is 1480.5776 records/second. Loss is 2.0337987. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0876826722338206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 5120/60000][Iteration 3792][Wall Clock 356.910797701s] Trained 128 records in 0.085648543 seconds. Throughput is 1494.4796 records/second. Loss is 2.0271173. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.087246921310791E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 5248/60000][Iteration 3793][Wall Clock 356.993886049s] Trained 128 records in 0.083088348 seconds. Throughput is 1540.5289 records/second. Loss is 2.0447824. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0868113522537563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 5376/60000][Iteration 3794][Wall Clock 357.07858319s] Trained 128 records in 0.084697141 seconds. Throughput is 1511.2671 records/second. Loss is 2.0390995. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0863759649488838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:12 INFO  DistriOptimizer$:408 - [Epoch 9 5504/60000][Iteration 3795][Wall Clock 357.163267915s] Trained 128 records in 0.084684725 seconds. Throughput is 1511.4886 records/second. Loss is 2.0022855. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0859407592824363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 5632/60000][Iteration 3796][Wall Clock 357.247648675s] Trained 128 records in 0.08438076 seconds. Throughput is 1516.9335 records/second. Loss is 1.9858222. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0855057351407716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 5760/60000][Iteration 3797][Wall Clock 357.332618636s] Trained 128 records in 0.084969961 seconds. Throughput is 1506.4148 records/second. Loss is 2.040453. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.085070892410342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 5888/60000][Iteration 3798][Wall Clock 357.416393919s] Trained 128 records in 0.083775283 seconds. Throughput is 1527.897 records/second. Loss is 1.9816808. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.084636230977694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6016/60000][Iteration 3799][Wall Clock 357.499031143s] Trained 128 records in 0.082637224 seconds. Throughput is 1548.9388 records/second. Loss is 2.0061245. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0842017507294707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6144/60000][Iteration 3800][Wall Clock 357.583464733s] Trained 128 records in 0.08443359 seconds. Throughput is 1515.9843 records/second. Loss is 1.9601394. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.083767451552407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6272/60000][Iteration 3801][Wall Clock 357.669129438s] Trained 128 records in 0.085664705 seconds. Throughput is 1494.1976 records/second. Loss is 2.0514963. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0833333333333332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6400/60000][Iteration 3802][Wall Clock 357.753166592s] Trained 128 records in 0.084037154 seconds. Throughput is 1523.1359 records/second. Loss is 2.0067825. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0828993959591752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6528/60000][Iteration 3803][Wall Clock 357.837108806s] Trained 128 records in 0.083942214 seconds. Throughput is 1524.8585 records/second. Loss is 2.011002. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0824656393169514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6656/60000][Iteration 3804][Wall Clock 357.91903362s] Trained 128 records in 0.081924814 seconds. Throughput is 1562.4082 records/second. Loss is 1.9895351. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0820320632937748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6784/60000][Iteration 3805][Wall Clock 358.01099424s] Trained 128 records in 0.09196062 seconds. Throughput is 1391.9001 records/second. Loss is 2.020429. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0815986677768527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 6912/60000][Iteration 3806][Wall Clock 358.091904427s] Trained 128 records in 0.080910187 seconds. Throughput is 1582.0011 records/second. Loss is 2.0026357. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.081165452653486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:13 INFO  DistriOptimizer$:408 - [Epoch 9 7040/60000][Iteration 3807][Wall Clock 358.169586891s] Trained 128 records in 0.077682464 seconds. Throughput is 1647.7335 records/second. Loss is 1.9746919. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0807324178110696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7168/60000][Iteration 3808][Wall Clock 358.254098975s] Trained 128 records in 0.084512084 seconds. Throughput is 1514.5763 records/second. Loss is 2.0008912. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0802995631370917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7296/60000][Iteration 3809][Wall Clock 358.337671048s] Trained 128 records in 0.083572073 seconds. Throughput is 1531.612 records/second. Loss is 2.031475. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0798668885191348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7424/60000][Iteration 3810][Wall Clock 358.42138388s] Trained 128 records in 0.083712832 seconds. Throughput is 1529.0369 records/second. Loss is 2.037497. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.079434393844874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7552/60000][Iteration 3811][Wall Clock 358.504389929s] Trained 128 records in 0.083006049 seconds. Throughput is 1542.0563 records/second. Loss is 1.9590323. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0790020790020788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7680/60000][Iteration 3812][Wall Clock 358.586994528s] Trained 128 records in 0.082604599 seconds. Throughput is 1549.5504 records/second. Loss is 2.0206156. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0785699438786117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7808/60000][Iteration 3813][Wall Clock 358.679272356s] Trained 128 records in 0.092277828 seconds. Throughput is 1387.1155 records/second. Loss is 2.0347033. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0781379883624273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 7936/60000][Iteration 3814][Wall Clock 358.75794276s] Trained 128 records in 0.078670404 seconds. Throughput is 1627.0414 records/second. Loss is 2.0200987. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0777062123415746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 8064/60000][Iteration 3815][Wall Clock 358.837315889s] Trained 128 records in 0.079373129 seconds. Throughput is 1612.6365 records/second. Loss is 2.0331223. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.077274615704196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 8192/60000][Iteration 3816][Wall Clock 358.919485652s] Trained 128 records in 0.082169763 seconds. Throughput is 1557.7506 records/second. Loss is 1.9790983. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0768431983385257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 8320/60000][Iteration 3817][Wall Clock 359.003018076s] Trained 128 records in 0.083532424 seconds. Throughput is 1532.3391 records/second. Loss is 2.0132833. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0764119601328901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 8448/60000][Iteration 3818][Wall Clock 359.086383488s] Trained 128 records in 0.083365412 seconds. Throughput is 1535.4089 records/second. Loss is 2.0093856. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.075980900975711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:14 INFO  DistriOptimizer$:408 - [Epoch 9 8576/60000][Iteration 3819][Wall Clock 359.169719854s] Trained 128 records in 0.083336366 seconds. Throughput is 1535.9441 records/second. Loss is 2.001541. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0755500207555005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 8704/60000][Iteration 3820][Wall Clock 359.254063032s] Trained 128 records in 0.084343178 seconds. Throughput is 1517.6094 records/second. Loss is 2.0367563. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0751193193608634E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 8832/60000][Iteration 3821][Wall Clock 359.338554028s] Trained 128 records in 0.084490996 seconds. Throughput is 1514.9542 records/second. Loss is 2.0125794. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.074688796680498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 8960/60000][Iteration 3822][Wall Clock 359.432481037s] Trained 128 records in 0.093927009 seconds. Throughput is 1362.7603 records/second. Loss is 2.0152855. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0742584526031946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9088/60000][Iteration 3823][Wall Clock 359.516398022s] Trained 128 records in 0.083916985 seconds. Throughput is 1525.317 records/second. Loss is 2.0389085. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.073828287017835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9216/60000][Iteration 3824][Wall Clock 359.608621323s] Trained 128 records in 0.092223301 seconds. Throughput is 1387.9355 records/second. Loss is 2.0088441. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.073398299813394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9344/60000][Iteration 3825][Wall Clock 359.700473557s] Trained 128 records in 0.091852234 seconds. Throughput is 1393.5426 records/second. Loss is 2.006465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0729684908789387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9472/60000][Iteration 3826][Wall Clock 359.786568014s] Trained 128 records in 0.086094457 seconds. Throughput is 1486.7393 records/second. Loss is 1.9932909. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.072538860103627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9600/60000][Iteration 3827][Wall Clock 359.869106543s] Trained 128 records in 0.082538529 seconds. Throughput is 1550.7909 records/second. Loss is 1.9827589. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0721094073767094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9728/60000][Iteration 3828][Wall Clock 359.953096611s] Trained 128 records in 0.083990068 seconds. Throughput is 1523.9897 records/second. Loss is 2.034923. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0716801325875285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9856/60000][Iteration 3829][Wall Clock 360.03982174s] Trained 128 records in 0.086725129 seconds. Throughput is 1475.9275 records/second. Loss is 2.0058663. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0712510356255177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:15 INFO  DistriOptimizer$:408 - [Epoch 9 9984/60000][Iteration 3830][Wall Clock 360.123799379s] Trained 128 records in 0.083977639 seconds. Throughput is 1524.2152 records/second. Loss is 2.0049958. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0708221163802027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10112/60000][Iteration 3831][Wall Clock 360.214496256s] Trained 128 records in 0.090696877 seconds. Throughput is 1411.2944 records/second. Loss is 1.9757016. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0703933747412008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10240/60000][Iteration 3832][Wall Clock 360.296897198s] Trained 128 records in 0.082400942 seconds. Throughput is 1553.3804 records/second. Loss is 2.0112362. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.06996481059822E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10368/60000][Iteration 3833][Wall Clock 360.375768652s] Trained 128 records in 0.078871454 seconds. Throughput is 1622.8939 records/second. Loss is 2.0115829. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0695364238410593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10496/60000][Iteration 3834][Wall Clock 360.463851414s] Trained 128 records in 0.088082762 seconds. Throughput is 1453.1788 records/second. Loss is 2.0009909. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.069108214359611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10624/60000][Iteration 3835][Wall Clock 360.549423757s] Trained 128 records in 0.085572343 seconds. Throughput is 1495.8104 records/second. Loss is 1.9944901. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0686801820438562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10752/60000][Iteration 3836][Wall Clock 360.636342528s] Trained 128 records in 0.086918771 seconds. Throughput is 1472.6393 records/second. Loss is 2.0092654. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0682523267838676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 10880/60000][Iteration 3837][Wall Clock 360.719423755s] Trained 128 records in 0.083081227 seconds. Throughput is 1540.6609 records/second. Loss is 2.0067987. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0678246484698098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 11008/60000][Iteration 3838][Wall Clock 360.803706s] Trained 128 records in 0.084282245 seconds. Throughput is 1518.7067 records/second. Loss is 1.9953628. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0673971469919373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 11136/60000][Iteration 3839][Wall Clock 360.891188186s] Trained 128 records in 0.087482186 seconds. Throughput is 1463.155 records/second. Loss is 2.0176454. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0669698222405952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 11264/60000][Iteration 3840][Wall Clock 360.975859489s] Trained 128 records in 0.084671303 seconds. Throughput is 1511.7283 records/second. Loss is 2.0052547. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.06654267410622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 11392/60000][Iteration 3841][Wall Clock 361.059196368s] Trained 128 records in 0.083336879 seconds. Throughput is 1535.9346 records/second. Loss is 2.0050068. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.066115702479339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:16 INFO  DistriOptimizer$:408 - [Epoch 9 11520/60000][Iteration 3842][Wall Clock 361.144552909s] Trained 128 records in 0.085356541 seconds. Throughput is 1499.5922 records/second. Loss is 2.0085013. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.065688907250568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 11648/60000][Iteration 3843][Wall Clock 361.226405436s] Trained 128 records in 0.081852527 seconds. Throughput is 1563.7881 records/second. Loss is 1.9658774. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0652622883106153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 11776/60000][Iteration 3844][Wall Clock 361.308997138s] Trained 128 records in 0.082591702 seconds. Throughput is 1549.7925 records/second. Loss is 2.0207508. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0648358455502787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 11904/60000][Iteration 3845][Wall Clock 361.391219869s] Trained 128 records in 0.082222731 seconds. Throughput is 1556.7472 records/second. Loss is 1.9772972. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.064409578860446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12032/60000][Iteration 3846][Wall Clock 361.473306507s] Trained 128 records in 0.082086638 seconds. Throughput is 1559.3281 records/second. Loss is 2.0321715. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0639834881320946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12160/60000][Iteration 3847][Wall Clock 361.556866213s] Trained 128 records in 0.083559706 seconds. Throughput is 1531.8387 records/second. Loss is 1.9961189. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.063557573256294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12288/60000][Iteration 3848][Wall Clock 361.641488137s] Trained 128 records in 0.084621924 seconds. Throughput is 1512.6105 records/second. Loss is 2.0166543. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.063131834124201E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12416/60000][Iteration 3849][Wall Clock 361.726296676s] Trained 128 records in 0.084808539 seconds. Throughput is 1509.282 records/second. Loss is 2.0258377. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0627062706270627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12544/60000][Iteration 3850][Wall Clock 361.810352671s] Trained 128 records in 0.084055995 seconds. Throughput is 1522.7944 records/second. Loss is 2.0113528. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0622808826562179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12672/60000][Iteration 3851][Wall Clock 361.893899851s] Trained 128 records in 0.08354718 seconds. Throughput is 1532.0685 records/second. Loss is 2.0041564. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.061855670103093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12800/60000][Iteration 3852][Wall Clock 361.978912694s] Trained 128 records in 0.085012843 seconds. Throughput is 1505.6548 records/second. Loss is 2.0444996. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0614306328592044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 12928/60000][Iteration 3853][Wall Clock 362.063986007s] Trained 128 records in 0.085073313 seconds. Throughput is 1504.5846 records/second. Loss is 1.9982953. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0610057708161583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:17 INFO  DistriOptimizer$:408 - [Epoch 9 13056/60000][Iteration 3854][Wall Clock 362.150780293s] Trained 128 records in 0.086794286 seconds. Throughput is 1474.7515 records/second. Loss is 1.9577135. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0605810838656503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13184/60000][Iteration 3855][Wall Clock 362.247656929s] Trained 128 records in 0.096876636 seconds. Throughput is 1321.2681 records/second. Loss is 2.0428464. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0601565718994644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13312/60000][Iteration 3856][Wall Clock 362.342581203s] Trained 128 records in 0.094924274 seconds. Throughput is 1348.4434 records/second. Loss is 2.0148642. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0597322348094745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13440/60000][Iteration 3857][Wall Clock 362.423325258s] Trained 128 records in 0.080744055 seconds. Throughput is 1585.256 records/second. Loss is 1.9937583. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0593080724876442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13568/60000][Iteration 3858][Wall Clock 362.505040127s] Trained 128 records in 0.081714869 seconds. Throughput is 1566.4224 records/second. Loss is 1.982221. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0588840848260242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13696/60000][Iteration 3859][Wall Clock 362.591265092s] Trained 128 records in 0.086224965 seconds. Throughput is 1484.4889 records/second. Loss is 2.0006957. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0584602717167556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13824/60000][Iteration 3860][Wall Clock 362.678566741s] Trained 128 records in 0.087301649 seconds. Throughput is 1466.1808 records/second. Loss is 1.982046. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0580366330520683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 13952/60000][Iteration 3861][Wall Clock 362.767536374s] Trained 128 records in 0.088969633 seconds. Throughput is 1438.6931 records/second. Loss is 2.035249. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.05761316872428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 14080/60000][Iteration 3862][Wall Clock 362.852519603s] Trained 128 records in 0.084983229 seconds. Throughput is 1506.1796 records/second. Loss is 2.0285974. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0571898786257969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 14208/60000][Iteration 3863][Wall Clock 362.937856117s] Trained 128 records in 0.085336514 seconds. Throughput is 1499.9441 records/second. Loss is 1.989294. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0567667626491157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 14336/60000][Iteration 3864][Wall Clock 363.034313044s] Trained 128 records in 0.096456927 seconds. Throughput is 1327.0171 records/second. Loss is 2.0073576. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.056343820686819E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:18 INFO  DistriOptimizer$:408 - [Epoch 9 14464/60000][Iteration 3865][Wall Clock 363.12847088s] Trained 128 records in 0.094157836 seconds. Throughput is 1359.4196 records/second. Loss is 2.0097678. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.055921052631579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 14592/60000][Iteration 3866][Wall Clock 363.21083238s] Trained 128 records in 0.0823615 seconds. Throughput is 1554.1243 records/second. Loss is 1.9768709. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0554984583761563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 14720/60000][Iteration 3867][Wall Clock 363.29511929s] Trained 128 records in 0.08428691 seconds. Throughput is 1518.6224 records/second. Loss is 2.020093. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0550760378133993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 14848/60000][Iteration 3868][Wall Clock 363.382193521s] Trained 128 records in 0.087074231 seconds. Throughput is 1470.0101 records/second. Loss is 2.039995. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.054653790836244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 14976/60000][Iteration 3869][Wall Clock 363.46688359s] Trained 128 records in 0.084690069 seconds. Throughput is 1511.3932 records/second. Loss is 2.0183072. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0542317173377156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15104/60000][Iteration 3870][Wall Clock 363.54992248s] Trained 128 records in 0.08303889 seconds. Throughput is 1541.4464 records/second. Loss is 2.027452. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0538098172109265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15232/60000][Iteration 3871][Wall Clock 363.636000068s] Trained 128 records in 0.086077588 seconds. Throughput is 1487.0305 records/second. Loss is 1.9777272. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.053388090349076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15360/60000][Iteration 3872][Wall Clock 363.721056688s] Trained 128 records in 0.08505662 seconds. Throughput is 1504.88 records/second. Loss is 1.9894238. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0529665366454526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15488/60000][Iteration 3873][Wall Clock 363.804756669s] Trained 128 records in 0.083699981 seconds. Throughput is 1529.2716 records/second. Loss is 2.0312676. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.052545155993432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15616/60000][Iteration 3874][Wall Clock 363.890848678s] Trained 128 records in 0.086092009 seconds. Throughput is 1486.7814 records/second. Loss is 1.9654906. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0521239482864764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15744/60000][Iteration 3875][Wall Clock 363.974704803s] Trained 128 records in 0.083856125 seconds. Throughput is 1526.424 records/second. Loss is 2.0282042. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0517029134181367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 15872/60000][Iteration 3876][Wall Clock 364.057799576s] Trained 128 records in 0.083094773 seconds. Throughput is 1540.4097 records/second. Loss is 1.9950495. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0512820512820514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:19 INFO  DistriOptimizer$:408 - [Epoch 9 16000/60000][Iteration 3877][Wall Clock 364.143277166s] Trained 128 records in 0.08547759 seconds. Throughput is 1497.4685 records/second. Loss is 2.0067415. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0508613617719446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16128/60000][Iteration 3878][Wall Clock 364.224977565s] Trained 128 records in 0.081700399 seconds. Throughput is 1566.6998 records/second. Loss is 2.020238. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0504408447816278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16256/60000][Iteration 3879][Wall Clock 364.306238781s] Trained 128 records in 0.081261216 seconds. Throughput is 1575.1671 records/second. Loss is 2.0383666. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.050020500205002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16384/60000][Iteration 3880][Wall Clock 364.388873788s] Trained 128 records in 0.082635007 seconds. Throughput is 1548.9803 records/second. Loss is 2.012956. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0496003279360528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16512/60000][Iteration 3881][Wall Clock 364.486799296s] Trained 128 records in 0.097925508 seconds. Throughput is 1307.1161 records/second. Loss is 2.0255587. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0491803278688525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16640/60000][Iteration 3882][Wall Clock 364.579458927s] Trained 128 records in 0.092659631 seconds. Throughput is 1381.3999 records/second. Loss is 1.9762535. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.048760499897562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16768/60000][Iteration 3883][Wall Clock 364.656704241s] Trained 128 records in 0.077245314 seconds. Throughput is 1657.0583 records/second. Loss is 2.0077853. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.048340843916428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 16896/60000][Iteration 3884][Wall Clock 364.734428435s] Trained 128 records in 0.077724194 seconds. Throughput is 1646.8488 records/second. Loss is 2.0390193. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.047921359819783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 17024/60000][Iteration 3885][Wall Clock 364.824946248s] Trained 128 records in 0.090517813 seconds. Throughput is 1414.0863 records/second. Loss is 2.0269957. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0475020475020474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 17152/60000][Iteration 3886][Wall Clock 364.908660809s] Trained 128 records in 0.083714561 seconds. Throughput is 1529.0052 records/second. Loss is 2.0262263. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.047082906857728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 17280/60000][Iteration 3887][Wall Clock 364.993024212s] Trained 128 records in 0.084363403 seconds. Throughput is 1517.2456 records/second. Loss is 1.9950856. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0466639377814163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 17408/60000][Iteration 3888][Wall Clock 365.078772461s] Trained 128 records in 0.085748249 seconds. Throughput is 1492.7418 records/second. Loss is 2.0303118. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0462451401677918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:20 INFO  DistriOptimizer$:408 - [Epoch 9 17536/60000][Iteration 3889][Wall Clock 365.161954678s] Trained 128 records in 0.083182217 seconds. Throughput is 1538.7904 records/second. Loss is 1.9886452. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0458265139116204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 17664/60000][Iteration 3890][Wall Clock 365.252486654s] Trained 128 records in 0.090531976 seconds. Throughput is 1413.8651 records/second. Loss is 2.0239046. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.045408058907752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 17792/60000][Iteration 3891][Wall Clock 365.334446407s] Trained 128 records in 0.081959753 seconds. Throughput is 1561.7421 records/second. Loss is 2.0309076. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0449897750511245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 17920/60000][Iteration 3892][Wall Clock 365.419935378s] Trained 128 records in 0.085488971 seconds. Throughput is 1497.2692 records/second. Loss is 2.008772. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0445716622367614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18048/60000][Iteration 3893][Wall Clock 365.504674609s] Trained 128 records in 0.084739231 seconds. Throughput is 1510.5165 records/second. Loss is 2.001169. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0441537203597714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18176/60000][Iteration 3894][Wall Clock 365.589675626s] Trained 128 records in 0.085001017 seconds. Throughput is 1505.8644 records/second. Loss is 2.013521. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0437359493153483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18304/60000][Iteration 3895][Wall Clock 365.67482202s] Trained 128 records in 0.085146394 seconds. Throughput is 1503.2932 records/second. Loss is 2.0368285. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.043318348998774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18432/60000][Iteration 3896][Wall Clock 365.760238256s] Trained 128 records in 0.085416236 seconds. Throughput is 1498.5442 records/second. Loss is 2.0204632. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.042900919305414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18560/60000][Iteration 3897][Wall Clock 365.845212908s] Trained 128 records in 0.084974652 seconds. Throughput is 1506.3315 records/second. Loss is 1.995557. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.042483660130719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18688/60000][Iteration 3898][Wall Clock 365.927288401s] Trained 128 records in 0.082075493 seconds. Throughput is 1559.5398 records/second. Loss is 2.0363867. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0420665713702266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18816/60000][Iteration 3899][Wall Clock 366.010778631s] Trained 128 records in 0.08349023 seconds. Throughput is 1533.1135 records/second. Loss is 1.9943554. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.041649652919559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:21 INFO  DistriOptimizer$:408 - [Epoch 9 18944/60000][Iteration 3900][Wall Clock 366.095914807s] Trained 128 records in 0.085136176 seconds. Throughput is 1503.4738 records/second. Loss is 1.9975507. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0412329046744235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19072/60000][Iteration 3901][Wall Clock 366.181767468s] Trained 128 records in 0.085852661 seconds. Throughput is 1490.9264 records/second. Loss is 2.0066793. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.040816326530612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19200/60000][Iteration 3902][Wall Clock 366.26456232s] Trained 128 records in 0.082794852 seconds. Throughput is 1545.9899 records/second. Loss is 1.9974487. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0403999183840033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19328/60000][Iteration 3903][Wall Clock 366.346537181s] Trained 128 records in 0.081974861 seconds. Throughput is 1561.4542 records/second. Loss is 2.008815. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.039983680130559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19456/60000][Iteration 3904][Wall Clock 366.429670202s] Trained 128 records in 0.083133021 seconds. Throughput is 1539.701 records/second. Loss is 1.969775. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0395676116663266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19584/60000][Iteration 3905][Wall Clock 366.515627408s] Trained 128 records in 0.085957206 seconds. Throughput is 1489.113 records/second. Loss is 2.004065. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.039151712887439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19712/60000][Iteration 3906][Wall Clock 366.600059179s] Trained 128 records in 0.084431771 seconds. Throughput is 1516.0171 records/second. Loss is 1.9941536. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0387359836901122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19840/60000][Iteration 3907][Wall Clock 366.691690664s] Trained 128 records in 0.091631485 seconds. Throughput is 1396.8998 records/second. Loss is 2.0020156. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.038320423970648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 19968/60000][Iteration 3908][Wall Clock 366.771516519s] Trained 128 records in 0.079825855 seconds. Throughput is 1603.4905 records/second. Loss is 2.005842. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.037905033625433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 20096/60000][Iteration 3909][Wall Clock 366.8505942s] Trained 128 records in 0.079077681 seconds. Throughput is 1618.6615 records/second. Loss is 2.0175834. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0374898125509374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 20224/60000][Iteration 3910][Wall Clock 366.939645495s] Trained 128 records in 0.089051295 seconds. Throughput is 1437.3739 records/second. Loss is 1.9948784. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0370747606437154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 20352/60000][Iteration 3911][Wall Clock 367.027217603s] Trained 128 records in 0.087572108 seconds. Throughput is 1461.6527 records/second. Loss is 2.0605874. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0366598778004074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:22 INFO  DistriOptimizer$:408 - [Epoch 9 20480/60000][Iteration 3912][Wall Clock 367.109963069s] Trained 128 records in 0.082745466 seconds. Throughput is 1546.9126 records/second. Loss is 1.9918063. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.036245163917736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 20608/60000][Iteration 3913][Wall Clock 367.190647297s] Trained 128 records in 0.080684228 seconds. Throughput is 1586.4314 records/second. Loss is 2.0260448. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0358306188925082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 20736/60000][Iteration 3914][Wall Clock 367.274031442s] Trained 128 records in 0.083384145 seconds. Throughput is 1535.0641 records/second. Loss is 1.9912475. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.035416242621616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 20864/60000][Iteration 3915][Wall Clock 367.370156214s] Trained 128 records in 0.096124772 seconds. Throughput is 1331.6025 records/second. Loss is 2.0062168. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0350020350020352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 20992/60000][Iteration 3916][Wall Clock 367.447892821s] Trained 128 records in 0.077736607 seconds. Throughput is 1646.5858 records/second. Loss is 2.002843. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.034587995930824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21120/60000][Iteration 3917][Wall Clock 367.528937896s] Trained 128 records in 0.081045075 seconds. Throughput is 1579.368 records/second. Loss is 2.040689. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.034174125305126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21248/60000][Iteration 3918][Wall Clock 367.613811968s] Trained 128 records in 0.084874072 seconds. Throughput is 1508.1167 records/second. Loss is 2.0210888. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.033760423022168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21376/60000][Iteration 3919][Wall Clock 367.6978418s] Trained 128 records in 0.084029832 seconds. Throughput is 1523.2686 records/second. Loss is 2.0271087. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0333468889792598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21504/60000][Iteration 3920][Wall Clock 367.780632608s] Trained 128 records in 0.082790808 seconds. Throughput is 1546.0654 records/second. Loss is 2.0008569. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0329335230737954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21632/60000][Iteration 3921][Wall Clock 367.86505861s] Trained 128 records in 0.084426002 seconds. Throughput is 1516.1206 records/second. Loss is 2.0041652. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.032520325203252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21760/60000][Iteration 3922][Wall Clock 367.948620338s] Trained 128 records in 0.083561728 seconds. Throughput is 1531.8018 records/second. Loss is 2.006597. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.03210729526519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 21888/60000][Iteration 3923][Wall Clock 368.033663491s] Trained 128 records in 0.085043153 seconds. Throughput is 1505.1182 records/second. Loss is 2.055989. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.031694433157253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:23 INFO  DistriOptimizer$:408 - [Epoch 9 22016/60000][Iteration 3924][Wall Clock 368.114829256s] Trained 128 records in 0.081165765 seconds. Throughput is 1577.0195 records/second. Loss is 1.9990089. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0312817387771684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22144/60000][Iteration 3925][Wall Clock 368.199312357s] Trained 128 records in 0.084483101 seconds. Throughput is 1515.0958 records/second. Loss is 2.0050333. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.030869212022746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22272/60000][Iteration 3926][Wall Clock 368.284045946s] Trained 128 records in 0.084733589 seconds. Throughput is 1510.617 records/second. Loss is 1.9964547. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0304568527918778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22400/60000][Iteration 3927][Wall Clock 368.372098473s] Trained 128 records in 0.088052527 seconds. Throughput is 1453.6777 records/second. Loss is 2.0174532. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0300446609825416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22528/60000][Iteration 3928][Wall Clock 368.458932419s] Trained 128 records in 0.086833946 seconds. Throughput is 1474.0779 records/second. Loss is 2.0278053. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.029632636492795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22656/60000][Iteration 3929][Wall Clock 368.548273249s] Trained 128 records in 0.08934083 seconds. Throughput is 1432.7156 records/second. Loss is 2.0200758. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0292207792207794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22784/60000][Iteration 3930][Wall Clock 368.635106261s] Trained 128 records in 0.086833012 seconds. Throughput is 1474.0938 records/second. Loss is 2.0114603. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.028809089064719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 22912/60000][Iteration 3931][Wall Clock 368.720708285s] Trained 128 records in 0.085602024 seconds. Throughput is 1495.2917 records/second. Loss is 2.027943. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.028397565922921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 23040/60000][Iteration 3932][Wall Clock 368.808040376s] Trained 128 records in 0.087332091 seconds. Throughput is 1465.6697 records/second. Loss is 2.0390642. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0279862096937742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 23168/60000][Iteration 3933][Wall Clock 368.903388797s] Trained 128 records in 0.095348421 seconds. Throughput is 1342.445 records/second. Loss is 1.9782684. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.02757502027575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 23296/60000][Iteration 3934][Wall Clock 368.988636278s] Trained 128 records in 0.085247481 seconds. Throughput is 1501.5106 records/second. Loss is 1.9984089. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0271639975674033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:24 INFO  DistriOptimizer$:408 - [Epoch 9 23424/60000][Iteration 3935][Wall Clock 369.067376227s] Trained 128 records in 0.078739949 seconds. Throughput is 1625.6044 records/second. Loss is 2.0098348. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0267531414673692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 23552/60000][Iteration 3936][Wall Clock 369.158769429s] Trained 128 records in 0.091393202 seconds. Throughput is 1400.5417 records/second. Loss is 1.988548. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0263424518743666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 23680/60000][Iteration 3937][Wall Clock 369.244217675s] Trained 128 records in 0.085448246 seconds. Throughput is 1497.9828 records/second. Loss is 1.952278. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0259319286871963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 23808/60000][Iteration 3938][Wall Clock 369.326917133s] Trained 128 records in 0.082699458 seconds. Throughput is 1547.7732 records/second. Loss is 1.9918828. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0255215718047395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 23936/60000][Iteration 3939][Wall Clock 369.41133774s] Trained 128 records in 0.084420607 seconds. Throughput is 1516.2175 records/second. Loss is 2.0333672. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0251113811259617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24064/60000][Iteration 3940][Wall Clock 369.495246911s] Trained 128 records in 0.083909171 seconds. Throughput is 1525.459 records/second. Loss is 1.9718994. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0247013565499088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24192/60000][Iteration 3941][Wall Clock 369.588797446s] Trained 128 records in 0.093550535 seconds. Throughput is 1368.2445 records/second. Loss is 2.0235271. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0242914979757087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24320/60000][Iteration 3942][Wall Clock 369.671232163s] Trained 128 records in 0.082434717 seconds. Throughput is 1552.7439 records/second. Loss is 1.9989659. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0238818053025702E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24448/60000][Iteration 3943][Wall Clock 369.754139634s] Trained 128 records in 0.082907471 seconds. Throughput is 1543.8899 records/second. Loss is 2.0238554. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0234722784297855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24576/60000][Iteration 3944][Wall Clock 369.836421279s] Trained 128 records in 0.082281645 seconds. Throughput is 1555.6326 records/second. Loss is 2.018816. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.023062917256727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24704/60000][Iteration 3945][Wall Clock 369.922133891s] Trained 128 records in 0.085712612 seconds. Throughput is 1493.3625 records/second. Loss is 1.9870956. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.022653721682848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24832/60000][Iteration 3946][Wall Clock 370.005204359s] Trained 128 records in 0.083070468 seconds. Throughput is 1540.8605 records/second. Loss is 1.9891611. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0222446916076846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:25 INFO  DistriOptimizer$:408 - [Epoch 9 24960/60000][Iteration 3947][Wall Clock 370.087624657s] Trained 128 records in 0.082420298 seconds. Throughput is 1553.0155 records/second. Loss is 2.005569. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0218358269308534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25088/60000][Iteration 3948][Wall Clock 370.171619362s] Trained 128 records in 0.083994705 seconds. Throughput is 1523.9056 records/second. Loss is 2.013227. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.021427127552052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25216/60000][Iteration 3949][Wall Clock 370.255842057s] Trained 128 records in 0.084222695 seconds. Throughput is 1519.7804 records/second. Loss is 1.9718623. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.021018593371059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25344/60000][Iteration 3950][Wall Clock 370.343494779s] Trained 128 records in 0.087652722 seconds. Throughput is 1460.3083 records/second. Loss is 2.0087352. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.020610224287735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25472/60000][Iteration 3951][Wall Clock 370.427440089s] Trained 128 records in 0.08394531 seconds. Throughput is 1524.8022 records/second. Loss is 2.026785. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0202020202020202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25600/60000][Iteration 3952][Wall Clock 370.513501772s] Trained 128 records in 0.086061683 seconds. Throughput is 1487.3053 records/second. Loss is 2.0219147. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0197939810139365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25728/60000][Iteration 3953][Wall Clock 370.628781042s] Trained 128 records in 0.11527927 seconds. Throughput is 1110.347 records/second. Loss is 2.0244622. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0193861066235866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25856/60000][Iteration 3954][Wall Clock 370.712065972s] Trained 128 records in 0.08328493 seconds. Throughput is 1536.8927 records/second. Loss is 2.0109935. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.018978396931153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 25984/60000][Iteration 3955][Wall Clock 370.796813401s] Trained 128 records in 0.084747429 seconds. Throughput is 1510.3704 records/second. Loss is 1.9988267. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0185708518368994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 26112/60000][Iteration 3956][Wall Clock 370.88385242s] Trained 128 records in 0.087039019 seconds. Throughput is 1470.6049 records/second. Loss is 1.9815623. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0181634712411706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 26240/60000][Iteration 3957][Wall Clock 370.971678391s] Trained 128 records in 0.087825971 seconds. Throughput is 1457.4277 records/second. Loss is 2.0349638. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0177562550443908E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:26 INFO  DistriOptimizer$:408 - [Epoch 9 26368/60000][Iteration 3958][Wall Clock 371.068245222s] Trained 128 records in 0.096566831 seconds. Throughput is 1325.5068 records/second. Loss is 2.0244226. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0173492031470646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 26496/60000][Iteration 3959][Wall Clock 371.145062548s] Trained 128 records in 0.076817326 seconds. Throughput is 1666.2908 records/second. Loss is 1.963641. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.016942315449778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 26624/60000][Iteration 3960][Wall Clock 371.232525297s] Trained 128 records in 0.087462749 seconds. Throughput is 1463.4802 records/second. Loss is 2.0209568. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0165355918531965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 26752/60000][Iteration 3961][Wall Clock 371.32245856s] Trained 128 records in 0.089933263 seconds. Throughput is 1423.2776 records/second. Loss is 2.0046616. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0161290322580645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 26880/60000][Iteration 3962][Wall Clock 371.410507357s] Trained 128 records in 0.088048797 seconds. Throughput is 1453.7394 records/second. Loss is 2.0005035. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0157226365652087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27008/60000][Iteration 3963][Wall Clock 371.49558618s] Trained 128 records in 0.085078823 seconds. Throughput is 1504.4872 records/second. Loss is 1.9953415. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0153164046755341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27136/60000][Iteration 3964][Wall Clock 371.582112889s] Trained 128 records in 0.086526709 seconds. Throughput is 1479.312 records/second. Loss is 2.0031884. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0149103364900262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27264/60000][Iteration 3965][Wall Clock 371.668524164s] Trained 128 records in 0.086411275 seconds. Throughput is 1481.2882 records/second. Loss is 1.9775999. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.01450443190975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27392/60000][Iteration 3966][Wall Clock 371.761867776s] Trained 128 records in 0.093343612 seconds. Throughput is 1371.2775 records/second. Loss is 2.0248306. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.014098690835851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27520/60000][Iteration 3967][Wall Clock 371.845195468s] Trained 128 records in 0.083327692 seconds. Throughput is 1536.104 records/second. Loss is 2.0088465. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.013693113169553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27648/60000][Iteration 3968][Wall Clock 371.925195108s] Trained 128 records in 0.07999964 seconds. Throughput is 1600.0072 records/second. Loss is 1.9895275. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.01328769881216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27776/60000][Iteration 3969][Wall Clock 372.008217175s] Trained 128 records in 0.083022067 seconds. Throughput is 1541.7588 records/second. Loss is 1.9801967. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0128824476650564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:27 INFO  DistriOptimizer$:408 - [Epoch 9 27904/60000][Iteration 3970][Wall Clock 372.09164249s] Trained 128 records in 0.083425315 seconds. Throughput is 1534.3065 records/second. Loss is 2.0205426. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0124773596297044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28032/60000][Iteration 3971][Wall Clock 372.176264282s] Trained 128 records in 0.084621792 seconds. Throughput is 1512.6127 records/second. Loss is 1.9765754. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0120724346076456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28160/60000][Iteration 3972][Wall Clock 372.260167675s] Trained 128 records in 0.083903393 seconds. Throughput is 1525.564 records/second. Loss is 1.9956414. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.011667672500503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28288/60000][Iteration 3973][Wall Clock 372.3454737s] Trained 128 records in 0.085306025 seconds. Throughput is 1500.4802 records/second. Loss is 1.9987204. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.011263073209976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28416/60000][Iteration 3974][Wall Clock 372.437456533s] Trained 128 records in 0.091982833 seconds. Throughput is 1391.564 records/second. Loss is 1.991332. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0108586366378444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28544/60000][Iteration 3975][Wall Clock 372.523222589s] Trained 128 records in 0.085766056 seconds. Throughput is 1492.432 records/second. Loss is 1.9994886. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.010454362685967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28672/60000][Iteration 3976][Wall Clock 372.608922807s] Trained 128 records in 0.085700218 seconds. Throughput is 1493.5784 records/second. Loss is 2.0001957. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0100502512562817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28800/60000][Iteration 3977][Wall Clock 372.69352647s] Trained 128 records in 0.084603663 seconds. Throughput is 1512.9369 records/second. Loss is 2.0156038. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0096463022508038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 28928/60000][Iteration 3978][Wall Clock 372.778804232s] Trained 128 records in 0.085277762 seconds. Throughput is 1500.9775 records/second. Loss is 2.0142317. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0092425155716293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 29056/60000][Iteration 3979][Wall Clock 372.862597367s] Trained 128 records in 0.083793135 seconds. Throughput is 1527.5714 records/second. Loss is 1.9691436. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0088388911209323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 29184/60000][Iteration 3980][Wall Clock 372.947065112s] Trained 128 records in 0.084467745 seconds. Throughput is 1515.3713 records/second. Loss is 1.9947706. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.008435428800964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 29312/60000][Iteration 3981][Wall Clock 373.033423135s] Trained 128 records in 0.086358023 seconds. Throughput is 1482.2015 records/second. Loss is 2.0167398. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.008032128514056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:28 INFO  DistriOptimizer$:408 - [Epoch 9 29440/60000][Iteration 3982][Wall Clock 373.116754663s] Trained 128 records in 0.083331528 seconds. Throughput is 1536.0333 records/second. Loss is 1.9936184. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.007628990162618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 29568/60000][Iteration 3983][Wall Clock 373.199953405s] Trained 128 records in 0.083198742 seconds. Throughput is 1538.4849 records/second. Loss is 2.0199692. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.007226013649137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 29696/60000][Iteration 3984][Wall Clock 373.289229932s] Trained 128 records in 0.089276527 seconds. Throughput is 1433.7474 records/second. Loss is 2.0136416. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0068231988761787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 29824/60000][Iteration 3985][Wall Clock 373.381120582s] Trained 128 records in 0.09189065 seconds. Throughput is 1392.9601 records/second. Loss is 1.989633. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0064205457463884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 29952/60000][Iteration 3986][Wall Clock 373.462447483s] Trained 128 records in 0.081326901 seconds. Throughput is 1573.8949 records/second. Loss is 1.9889127. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0060180541624876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30080/60000][Iteration 3987][Wall Clock 373.546569821s] Trained 128 records in 0.084122338 seconds. Throughput is 1521.5935 records/second. Loss is 1.997885. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0056157240272763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30208/60000][Iteration 3988][Wall Clock 373.628784797s] Trained 128 records in 0.082214976 seconds. Throughput is 1556.894 records/second. Loss is 1.9823093. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0052135552436334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30336/60000][Iteration 3989][Wall Clock 373.710855726s] Trained 128 records in 0.082070929 seconds. Throughput is 1559.6265 records/second. Loss is 1.9650185. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.004811547714515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30464/60000][Iteration 3990][Wall Clock 373.7951556s] Trained 128 records in 0.084299874 seconds. Throughput is 1518.3889 records/second. Loss is 2.023203. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0044097013429546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30592/60000][Iteration 3991][Wall Clock 373.877910855s] Trained 128 records in 0.082755255 seconds. Throughput is 1546.7296 records/second. Loss is 2.0506883. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.004008016032064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30720/60000][Iteration 3992][Wall Clock 373.959338668s] Trained 128 records in 0.081427813 seconds. Throughput is 1571.9445 records/second. Loss is 2.037537. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0036064916850334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:29 INFO  DistriOptimizer$:408 - [Epoch 9 30848/60000][Iteration 3993][Wall Clock 374.04407213s] Trained 128 records in 0.084733462 seconds. Throughput is 1510.6193 records/second. Loss is 1.9789029. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0032051282051281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 30976/60000][Iteration 3994][Wall Clock 374.128719854s] Trained 128 records in 0.084647724 seconds. Throughput is 1512.1494 records/second. Loss is 2.007071. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0028039254956937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31104/60000][Iteration 3995][Wall Clock 374.213524235s] Trained 128 records in 0.084804381 seconds. Throughput is 1509.3561 records/second. Loss is 2.0028434. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0024028834601524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31232/60000][Iteration 3996][Wall Clock 374.298827597s] Trained 128 records in 0.085303362 seconds. Throughput is 1500.5271 records/second. Loss is 1.9771829. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.002002002002002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31360/60000][Iteration 3997][Wall Clock 374.383453674s] Trained 128 records in 0.084626077 seconds. Throughput is 1512.5361 records/second. Loss is 1.9975302. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0016012810248197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31488/60000][Iteration 3998][Wall Clock 374.468697699s] Trained 128 records in 0.085244025 seconds. Throughput is 1501.5715 records/second. Loss is 1.9918293. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0012007204322593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31616/60000][Iteration 3999][Wall Clock 374.557128508s] Trained 128 records in 0.088430809 seconds. Throughput is 1447.4594 records/second. Loss is 1.9915147. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.000800320128051E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31744/60000][Iteration 4000][Wall Clock 374.644914574s] Trained 128 records in 0.087786066 seconds. Throughput is 1458.0902 records/second. Loss is 1.9543939. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.000400080016003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 31872/60000][Iteration 4001][Wall Clock 374.732420941s] Trained 128 records in 0.087506367 seconds. Throughput is 1462.7507 records/second. Loss is 1.9874488. Sequentialdaab25a8's hyper parameters: Current learning rate is 2.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 32000/60000][Iteration 4002][Wall Clock 374.817072821s] Trained 128 records in 0.08465188 seconds. Throughput is 1512.0751 records/second. Loss is 2.0098433. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.999600079984003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 32128/60000][Iteration 4003][Wall Clock 374.899915733s] Trained 128 records in 0.082842912 seconds. Throughput is 1545.093 records/second. Loss is 1.974753. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9992003198720512E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 32256/60000][Iteration 4004][Wall Clock 374.984117801s] Trained 128 records in 0.084202068 seconds. Throughput is 1520.1527 records/second. Loss is 2.005307. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.998800719568259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:30 INFO  DistriOptimizer$:408 - [Epoch 9 32384/60000][Iteration 4005][Wall Clock 375.068035253s] Trained 128 records in 0.083917452 seconds. Throughput is 1525.3085 records/second. Loss is 2.0118914. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9984012789768185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 32512/60000][Iteration 4006][Wall Clock 375.151038686s] Trained 128 records in 0.083003433 seconds. Throughput is 1542.1049 records/second. Loss is 2.0084245. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.998001998001998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 32640/60000][Iteration 4007][Wall Clock 375.232945959s] Trained 128 records in 0.081907273 seconds. Throughput is 1562.7428 records/second. Loss is 2.02426. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9976028765481422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 32768/60000][Iteration 4008][Wall Clock 375.315498052s] Trained 128 records in 0.082552093 seconds. Throughput is 1550.5361 records/second. Loss is 1.9724327. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9972039145196727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 32896/60000][Iteration 4009][Wall Clock 375.406020427s] Trained 128 records in 0.090522375 seconds. Throughput is 1414.015 records/second. Loss is 2.0418832. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9968051118210862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33024/60000][Iteration 4010][Wall Clock 375.493018998s] Trained 128 records in 0.086998571 seconds. Throughput is 1471.2885 records/second. Loss is 2.0271966. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9964064683569574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33152/60000][Iteration 4011][Wall Clock 375.572318756s] Trained 128 records in 0.079299758 seconds. Throughput is 1614.1285 records/second. Loss is 2.050033. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9960079840319363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33280/60000][Iteration 4012][Wall Clock 375.651142104s] Trained 128 records in 0.078823348 seconds. Throughput is 1623.8843 records/second. Loss is 1.9893191. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9956096587507485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33408/60000][Iteration 4013][Wall Clock 375.736170871s] Trained 128 records in 0.085028767 seconds. Throughput is 1505.3729 records/second. Loss is 2.0084898. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9952114924181962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33536/60000][Iteration 4014][Wall Clock 375.820358954s] Trained 128 records in 0.084188083 seconds. Throughput is 1520.4053 records/second. Loss is 2.0068352. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9948134849391582E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33664/60000][Iteration 4015][Wall Clock 375.904039893s] Trained 128 records in 0.083680939 seconds. Throughput is 1529.6195 records/second. Loss is 2.0136902. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9944156362185878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33792/60000][Iteration 4016][Wall Clock 375.986472163s] Trained 128 records in 0.08243227 seconds. Throughput is 1552.7899 records/second. Loss is 1.9752176. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9940179461615156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:31 INFO  DistriOptimizer$:408 - [Epoch 9 33920/60000][Iteration 4017][Wall Clock 376.081842777s] Trained 128 records in 0.095370614 seconds. Throughput is 1342.1324 records/second. Loss is 2.0400972. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9936204146730463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34048/60000][Iteration 4018][Wall Clock 376.163884285s] Trained 128 records in 0.082041508 seconds. Throughput is 1560.1858 records/second. Loss is 1.9961326. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9932230416583614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34176/60000][Iteration 4019][Wall Clock 376.241689364s] Trained 128 records in 0.077805079 seconds. Throughput is 1645.1368 records/second. Loss is 1.9853278. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9928258270227183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34304/60000][Iteration 4020][Wall Clock 376.325282589s] Trained 128 records in 0.083593225 seconds. Throughput is 1531.2245 records/second. Loss is 2.0334496. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9924287706714485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34432/60000][Iteration 4021][Wall Clock 376.409945642s] Trained 128 records in 0.084663053 seconds. Throughput is 1511.8755 records/second. Loss is 2.0074832. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.99203187250996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34560/60000][Iteration 4022][Wall Clock 376.492858692s] Trained 128 records in 0.08291305 seconds. Throughput is 1543.786 records/second. Loss is 1.948155. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9916351324437363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34688/60000][Iteration 4023][Wall Clock 376.575838992s] Trained 128 records in 0.0829803 seconds. Throughput is 1542.5348 records/second. Loss is 2.01541. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9912385503783353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34816/60000][Iteration 4024][Wall Clock 376.658179486s] Trained 128 records in 0.082340494 seconds. Throughput is 1554.5206 records/second. Loss is 2.035644. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.990842126219391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 34944/60000][Iteration 4025][Wall Clock 376.741471591s] Trained 128 records in 0.083292105 seconds. Throughput is 1536.7603 records/second. Loss is 2.0062754. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9904458598726116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 35072/60000][Iteration 4026][Wall Clock 376.828683795s] Trained 128 records in 0.087212204 seconds. Throughput is 1467.6844 records/second. Loss is 1.9590558. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.990049751243781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 35200/60000][Iteration 4027][Wall Clock 376.912328442s] Trained 128 records in 0.083644647 seconds. Throughput is 1530.2833 records/second. Loss is 1.962164. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9896538002387587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 35328/60000][Iteration 4028][Wall Clock 376.995941034s] Trained 128 records in 0.083612592 seconds. Throughput is 1530.8699 records/second. Loss is 1.9779226. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9892580067634773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:32 INFO  DistriOptimizer$:408 - [Epoch 9 35456/60000][Iteration 4029][Wall Clock 377.080804907s] Trained 128 records in 0.084863873 seconds. Throughput is 1508.298 records/second. Loss is 2.0244598. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9888623707239457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 35584/60000][Iteration 4030][Wall Clock 377.165781058s] Trained 128 records in 0.084976151 seconds. Throughput is 1506.3049 records/second. Loss is 1.9905231. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.988466892026248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 35712/60000][Iteration 4031][Wall Clock 377.250088159s] Trained 128 records in 0.084307101 seconds. Throughput is 1518.2588 records/second. Loss is 1.9736702. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9880715705765408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 35840/60000][Iteration 4032][Wall Clock 377.336246609s] Trained 128 records in 0.08615845 seconds. Throughput is 1485.635 records/second. Loss is 2.025297. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9876764062810577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 35968/60000][Iteration 4033][Wall Clock 377.420771092s] Trained 128 records in 0.084524483 seconds. Throughput is 1514.3541 records/second. Loss is 2.0016427. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.987281399046105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36096/60000][Iteration 4034][Wall Clock 377.514897068s] Trained 128 records in 0.094125976 seconds. Throughput is 1359.8796 records/second. Loss is 1.9573039. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9868865487780648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36224/60000][Iteration 4035][Wall Clock 377.599639715s] Trained 128 records in 0.084742647 seconds. Throughput is 1510.4554 records/second. Loss is 2.0041707. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.986491855383393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36352/60000][Iteration 4036][Wall Clock 377.682280747s] Trained 128 records in 0.082641032 seconds. Throughput is 1548.8673 records/second. Loss is 2.022975. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9860973187686197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36480/60000][Iteration 4037][Wall Clock 377.757077298s] Trained 128 records in 0.074796551 seconds. Throughput is 1711.3088 records/second. Loss is 1.9947872. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9857029388403494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36608/60000][Iteration 4038][Wall Clock 377.837178256s] Trained 128 records in 0.080100958 seconds. Throughput is 1597.9833 records/second. Loss is 2.039577. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9853087155052612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36736/60000][Iteration 4039][Wall Clock 377.920753848s] Trained 128 records in 0.083575592 seconds. Throughput is 1531.5476 records/second. Loss is 1.9576776. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.984914648670107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36864/60000][Iteration 4040][Wall Clock 378.004696523s] Trained 128 records in 0.083942675 seconds. Throughput is 1524.8502 records/second. Loss is 1.9919068. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9845207382417147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:33 INFO  DistriOptimizer$:408 - [Epoch 9 36992/60000][Iteration 4041][Wall Clock 378.089035193s] Trained 128 records in 0.08433867 seconds. Throughput is 1517.6904 records/second. Loss is 1.998919. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.984126984126984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37120/60000][Iteration 4042][Wall Clock 378.173908408s] Trained 128 records in 0.084873215 seconds. Throughput is 1508.1318 records/second. Loss is 1.9948813. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9837333862328903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37248/60000][Iteration 4043][Wall Clock 378.26595688s] Trained 128 records in 0.092048472 seconds. Throughput is 1390.5717 records/second. Loss is 1.9937708. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9833399444664816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37376/60000][Iteration 4044][Wall Clock 378.355017915s] Trained 128 records in 0.089061035 seconds. Throughput is 1437.2166 records/second. Loss is 1.9645503. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.98294665873488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37504/60000][Iteration 4045][Wall Clock 378.438079875s] Trained 128 records in 0.08306196 seconds. Throughput is 1541.0182 records/second. Loss is 2.0094607. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9825535289452813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37632/60000][Iteration 4046][Wall Clock 378.522661632s] Trained 128 records in 0.084581757 seconds. Throughput is 1513.3287 records/second. Loss is 1.9799513. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9821605550049556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37760/60000][Iteration 4047][Wall Clock 378.607891289s] Trained 128 records in 0.085229657 seconds. Throughput is 1501.8246 records/second. Loss is 2.0290687. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9817677368212444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 37888/60000][Iteration 4048][Wall Clock 378.692686899s] Trained 128 records in 0.08479561 seconds. Throughput is 1509.5121 records/second. Loss is 1.9866283. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9813750743015655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 38016/60000][Iteration 4049][Wall Clock 378.777616426s] Trained 128 records in 0.084929527 seconds. Throughput is 1507.132 records/second. Loss is 1.9870561. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9809825673534074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 38144/60000][Iteration 4050][Wall Clock 378.860657005s] Trained 128 records in 0.083040579 seconds. Throughput is 1541.415 records/second. Loss is 1.9990737. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9805902158843335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 38272/60000][Iteration 4051][Wall Clock 378.943849931s] Trained 128 records in 0.083192926 seconds. Throughput is 1538.5923 records/second. Loss is 1.9648373. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9801980198019803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:34 INFO  DistriOptimizer$:408 - [Epoch 9 38400/60000][Iteration 4052][Wall Clock 379.02729417s] Trained 128 records in 0.083444239 seconds. Throughput is 1533.9585 records/second. Loss is 1.9918137. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9798059790140566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 38528/60000][Iteration 4053][Wall Clock 379.163988275s] Trained 128 records in 0.136694105 seconds. Throughput is 936.3974 records/second. Loss is 1.9969969. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.979414093428345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 38656/60000][Iteration 4054][Wall Clock 379.274924s] Trained 128 records in 0.110935725 seconds. Throughput is 1153.8213 records/second. Loss is 2.004642. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9790223629527015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 38784/60000][Iteration 4055][Wall Clock 379.358014133s] Trained 128 records in 0.083090133 seconds. Throughput is 1540.4957 records/second. Loss is 2.0347056. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9786307874950534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 38912/60000][Iteration 4056][Wall Clock 379.441102025s] Trained 128 records in 0.083087892 seconds. Throughput is 1540.5374 records/second. Loss is 1.9933225. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9782393669634028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39040/60000][Iteration 4057][Wall Clock 379.524449971s] Trained 128 records in 0.083347946 seconds. Throughput is 1535.7307 records/second. Loss is 2.0196826. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9778481012658228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39168/60000][Iteration 4058][Wall Clock 379.608729553s] Trained 128 records in 0.084279582 seconds. Throughput is 1518.7545 records/second. Loss is 1.9532692. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9774569903104606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39296/60000][Iteration 4059][Wall Clock 379.698290675s] Trained 128 records in 0.089561122 seconds. Throughput is 1429.1917 records/second. Loss is 1.9781246. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9770660340055358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39424/60000][Iteration 4060][Wall Clock 379.783056768s] Trained 128 records in 0.084766093 seconds. Throughput is 1510.0378 records/second. Loss is 2.009792. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9766752322593396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39552/60000][Iteration 4061][Wall Clock 379.865569383s] Trained 128 records in 0.082512615 seconds. Throughput is 1551.278 records/second. Loss is 1.9836308. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.976284584980237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39680/60000][Iteration 4062][Wall Clock 379.944767924s] Trained 128 records in 0.079198541 seconds. Throughput is 1616.1914 records/second. Loss is 2.0031009. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9758940920766647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:35 INFO  DistriOptimizer$:408 - [Epoch 9 39808/60000][Iteration 4063][Wall Clock 380.032882795s] Trained 128 records in 0.088114871 seconds. Throughput is 1452.6492 records/second. Loss is 1.9222937. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9755037534571315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 39936/60000][Iteration 4064][Wall Clock 380.11608796s] Trained 128 records in 0.083205165 seconds. Throughput is 1538.3661 records/second. Loss is 1.9639344. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9751135690302193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40064/60000][Iteration 4065][Wall Clock 380.200200286s] Trained 128 records in 0.084112326 seconds. Throughput is 1521.7747 records/second. Loss is 1.9994633. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9747235387045813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40192/60000][Iteration 4066][Wall Clock 380.287281903s] Trained 128 records in 0.087081617 seconds. Throughput is 1469.8854 records/second. Loss is 2.0108824. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9743336623889436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40320/60000][Iteration 4067][Wall Clock 380.373044739s] Trained 128 records in 0.085762836 seconds. Throughput is 1492.4879 records/second. Loss is 1.9624871. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9739439399921044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40448/60000][Iteration 4068][Wall Clock 380.470251392s] Trained 128 records in 0.097206653 seconds. Throughput is 1316.7823 records/second. Loss is 2.0331464. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9735543714229328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40576/60000][Iteration 4069][Wall Clock 380.549179545s] Trained 128 records in 0.078928153 seconds. Throughput is 1621.7281 records/second. Loss is 1.9798251. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9731649565903707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40704/60000][Iteration 4070][Wall Clock 380.63522913s] Trained 128 records in 0.086049585 seconds. Throughput is 1487.5144 records/second. Loss is 2.023853. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9727756954034326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40832/60000][Iteration 4071][Wall Clock 380.722711163s] Trained 128 records in 0.087482033 seconds. Throughput is 1463.1576 records/second. Loss is 2.0244062. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.972386587771203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 40960/60000][Iteration 4072][Wall Clock 380.807295868s] Trained 128 records in 0.084584705 seconds. Throughput is 1513.276 records/second. Loss is 2.0076. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9719976336028398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 41088/60000][Iteration 4073][Wall Clock 380.894272176s] Trained 128 records in 0.086976308 seconds. Throughput is 1471.6652 records/second. Loss is 1.9920949. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.971608832807571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 41216/60000][Iteration 4074][Wall Clock 380.979042398s] Trained 128 records in 0.084770222 seconds. Throughput is 1509.9641 records/second. Loss is 1.983358. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9712201852946972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:36 INFO  DistriOptimizer$:408 - [Epoch 9 41344/60000][Iteration 4075][Wall Clock 381.0651654s] Trained 128 records in 0.086123002 seconds. Throughput is 1486.2463 records/second. Loss is 1.9648743. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.970831690973591E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 41472/60000][Iteration 4076][Wall Clock 381.149103859s] Trained 128 records in 0.083938459 seconds. Throughput is 1524.9268 records/second. Loss is 2.0358722. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9704433497536944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 41600/60000][Iteration 4077][Wall Clock 381.236746587s] Trained 128 records in 0.087642728 seconds. Throughput is 1460.4749 records/second. Loss is 1.969535. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.970055161544523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 41728/60000][Iteration 4078][Wall Clock 381.321076533s] Trained 128 records in 0.084329946 seconds. Throughput is 1517.8475 records/second. Loss is 2.0108414. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9696671262556627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 41856/60000][Iteration 4079][Wall Clock 381.405396846s] Trained 128 records in 0.084320313 seconds. Throughput is 1518.0209 records/second. Loss is 2.0259469. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9692792437967703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 41984/60000][Iteration 4080][Wall Clock 381.488665928s] Trained 128 records in 0.083269082 seconds. Throughput is 1537.1852 records/second. Loss is 1.9935728. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9688915140775746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42112/60000][Iteration 4081][Wall Clock 381.571344745s] Trained 128 records in 0.082678817 seconds. Throughput is 1548.1595 records/second. Loss is 1.9768515. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.968503937007874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42240/60000][Iteration 4082][Wall Clock 381.653478156s] Trained 128 records in 0.082133411 seconds. Throughput is 1558.4401 records/second. Loss is 1.9574208. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9681165124975396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42368/60000][Iteration 4083][Wall Clock 381.737221958s] Trained 128 records in 0.083743802 seconds. Throughput is 1528.4713 records/second. Loss is 2.0492573. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9677292404565134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42496/60000][Iteration 4084][Wall Clock 381.831672942s] Trained 128 records in 0.094450984 seconds. Throughput is 1355.2003 records/second. Loss is 2.016476. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.967342120794806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42624/60000][Iteration 4085][Wall Clock 381.908033702s] Trained 128 records in 0.07636076 seconds. Throughput is 1676.2535 records/second. Loss is 2.0331829. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9669551534225017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42752/60000][Iteration 4086][Wall Clock 381.982809758s] Trained 128 records in 0.074776056 seconds. Throughput is 1711.778 records/second. Loss is 1.9850587. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9665683382497542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:37 INFO  DistriOptimizer$:408 - [Epoch 9 42880/60000][Iteration 4087][Wall Clock 382.064606206s] Trained 128 records in 0.081796448 seconds. Throughput is 1564.8602 records/second. Loss is 2.0407655. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9661816751867872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43008/60000][Iteration 4088][Wall Clock 382.150242252s] Trained 128 records in 0.085636046 seconds. Throughput is 1494.6976 records/second. Loss is 1.9803278. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9657951641438963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43136/60000][Iteration 4089][Wall Clock 382.234321852s] Trained 128 records in 0.0840796 seconds. Throughput is 1522.367 records/second. Loss is 1.9963316. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9654088050314466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43264/60000][Iteration 4090][Wall Clock 382.320819969s] Trained 128 records in 0.086498117 seconds. Throughput is 1479.801 records/second. Loss is 1.9758201. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.965022597759874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43392/60000][Iteration 4091][Wall Clock 382.407475906s] Trained 128 records in 0.086655937 seconds. Throughput is 1477.106 records/second. Loss is 1.9765836. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9646365422396858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43520/60000][Iteration 4092][Wall Clock 382.493040145s] Trained 128 records in 0.085564239 seconds. Throughput is 1495.952 records/second. Loss is 2.02751. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9642506383814575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43648/60000][Iteration 4093][Wall Clock 382.580616472s] Trained 128 records in 0.087576327 seconds. Throughput is 1461.5822 records/second. Loss is 1.9959667. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9638648860958365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43776/60000][Iteration 4094][Wall Clock 382.672548125s] Trained 128 records in 0.091931653 seconds. Throughput is 1392.3386 records/second. Loss is 1.995427. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9634792852935403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 43904/60000][Iteration 4095][Wall Clock 382.7557145s] Trained 128 records in 0.083166375 seconds. Throughput is 1539.0835 records/second. Loss is 2.0299308. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9630938358853554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 44032/60000][Iteration 4096][Wall Clock 382.841361382s] Trained 128 records in 0.085646882 seconds. Throughput is 1494.5085 records/second. Loss is 1.9914944. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9627085377821394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 44160/60000][Iteration 4097][Wall Clock 382.925158726s] Trained 128 records in 0.083797344 seconds. Throughput is 1527.4948 records/second. Loss is 1.9883182. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9623233908948196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:38 INFO  DistriOptimizer$:408 - [Epoch 9 44288/60000][Iteration 4098][Wall Clock 383.008605271s] Trained 128 records in 0.083446545 seconds. Throughput is 1533.916 records/second. Loss is 2.029673. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9619383951343926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 44416/60000][Iteration 4099][Wall Clock 383.090766066s] Trained 128 records in 0.082160795 seconds. Throughput is 1557.9207 records/second. Loss is 1.9762851. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9615535504119262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 44544/60000][Iteration 4100][Wall Clock 383.17519855s] Trained 128 records in 0.084432484 seconds. Throughput is 1516.0043 records/second. Loss is 2.0074086. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9611688566385565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 44672/60000][Iteration 4101][Wall Clock 383.261490832s] Trained 128 records in 0.086292282 seconds. Throughput is 1483.3308 records/second. Loss is 1.9811478. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9607843137254904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 44800/60000][Iteration 4102][Wall Clock 383.348056004s] Trained 128 records in 0.086565172 seconds. Throughput is 1478.6547 records/second. Loss is 1.9714845. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9603999215840032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 44928/60000][Iteration 4103][Wall Clock 383.433290158s] Trained 128 records in 0.085234154 seconds. Throughput is 1501.7455 records/second. Loss is 1.9979614. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.960015680125441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45056/60000][Iteration 4104][Wall Clock 383.517580158s] Trained 128 records in 0.08429 seconds. Throughput is 1518.5669 records/second. Loss is 1.9860674. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.959631589261219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45184/60000][Iteration 4105][Wall Clock 383.602435517s] Trained 128 records in 0.084855359 seconds. Throughput is 1508.4493 records/second. Loss is 1.9953979. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9592476489028212E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45312/60000][Iteration 4106][Wall Clock 383.68795092s] Trained 128 records in 0.085515403 seconds. Throughput is 1496.8064 records/second. Loss is 2.0099204. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.958863858961802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45440/60000][Iteration 4107][Wall Clock 383.776567547s] Trained 128 records in 0.088616627 seconds. Throughput is 1444.4242 records/second. Loss is 1.9887297. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9584802193497848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45568/60000][Iteration 4108][Wall Clock 383.861846985s] Trained 128 records in 0.085279438 seconds. Throughput is 1500.948 records/second. Loss is 1.9824289. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9580967299784609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45696/60000][Iteration 4109][Wall Clock 383.946270764s] Trained 128 records in 0.084423779 seconds. Throughput is 1516.1605 records/second. Loss is 1.9815084. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.957713390759593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:39 INFO  DistriOptimizer$:408 - [Epoch 9 45824/60000][Iteration 4110][Wall Clock 384.03778126s] Trained 128 records in 0.091510496 seconds. Throughput is 1398.7466 records/second. Loss is 2.0421896. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9573302016050108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 45952/60000][Iteration 4111][Wall Clock 384.118540808s] Trained 128 records in 0.080759548 seconds. Throughput is 1584.9519 records/second. Loss is 1.9831159. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9569471624266143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46080/60000][Iteration 4112][Wall Clock 384.19622853s] Trained 128 records in 0.077687722 seconds. Throughput is 1647.622 records/second. Loss is 2.0397372. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9565642731363727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46208/60000][Iteration 4113][Wall Clock 384.277269763s] Trained 128 records in 0.081041233 seconds. Throughput is 1579.4429 records/second. Loss is 1.9937567. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9561815336463224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46336/60000][Iteration 4114][Wall Clock 384.3615664s] Trained 128 records in 0.084296637 seconds. Throughput is 1518.4473 records/second. Loss is 1.992996. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.95579894386857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46464/60000][Iteration 4115][Wall Clock 384.444456075s] Trained 128 records in 0.082889675 seconds. Throughput is 1544.2213 records/second. Loss is 1.9801462. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9554165037152915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46592/60000][Iteration 4116][Wall Clock 384.528382768s] Trained 128 records in 0.083926693 seconds. Throughput is 1525.1405 records/second. Loss is 2.0094578. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9550342130987292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46720/60000][Iteration 4117][Wall Clock 384.611370118s] Trained 128 records in 0.08298735 seconds. Throughput is 1542.4037 records/second. Loss is 1.9790318. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9546520719311965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46848/60000][Iteration 4118][Wall Clock 384.695819301s] Trained 128 records in 0.084449183 seconds. Throughput is 1515.7045 records/second. Loss is 2.0169785. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9542700801250732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 46976/60000][Iteration 4119][Wall Clock 384.785178002s] Trained 128 records in 0.089358701 seconds. Throughput is 1432.4291 records/second. Loss is 1.9552561. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9538882375928096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 47104/60000][Iteration 4120][Wall Clock 384.865045036s] Trained 128 records in 0.079867034 seconds. Throughput is 1602.6637 records/second. Loss is 1.9899725. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9535065442469234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 47232/60000][Iteration 4121][Wall Clock 384.948112836s] Trained 128 records in 0.0830678 seconds. Throughput is 1540.91 records/second. Loss is 1.98168. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.953125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:40 INFO  DistriOptimizer$:408 - [Epoch 9 47360/60000][Iteration 4122][Wall Clock 385.03279917s] Trained 128 records in 0.084686334 seconds. Throughput is 1511.46 records/second. Loss is 1.9771423. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9527436047646942E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 47488/60000][Iteration 4123][Wall Clock 385.115611592s] Trained 128 records in 0.082812422 seconds. Throughput is 1545.6619 records/second. Loss is 1.9598206. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.952362358453729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 47616/60000][Iteration 4124][Wall Clock 385.198424578s] Trained 128 records in 0.082812986 seconds. Throughput is 1545.6512 records/second. Loss is 1.9844424. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9519812609798944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 47744/60000][Iteration 4125][Wall Clock 385.280825329s] Trained 128 records in 0.082400751 seconds. Throughput is 1553.3838 records/second. Loss is 1.9299695. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9516003122560502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 47872/60000][Iteration 4126][Wall Clock 385.363455996s] Trained 128 records in 0.082630667 seconds. Throughput is 1549.0618 records/second. Loss is 1.9759834. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.951219512195122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48000/60000][Iteration 4127][Wall Clock 385.44876589s] Trained 128 records in 0.085309894 seconds. Throughput is 1500.4121 records/second. Loss is 1.9933343. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9508388607101054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48128/60000][Iteration 4128][Wall Clock 385.53012389s] Trained 128 records in 0.081358 seconds. Throughput is 1573.2933 records/second. Loss is 1.9928411. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.950458357714063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48256/60000][Iteration 4129][Wall Clock 385.611980981s] Trained 128 records in 0.081857091 seconds. Throughput is 1563.7008 records/second. Loss is 1.9705758. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.950078003120125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48384/60000][Iteration 4130][Wall Clock 385.69645335s] Trained 128 records in 0.084472369 seconds. Throughput is 1515.2885 records/second. Loss is 1.9754438. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9496977968414895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48512/60000][Iteration 4131][Wall Clock 385.78147061s] Trained 128 records in 0.08501726 seconds. Throughput is 1505.5767 records/second. Loss is 1.9927604. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.949317738791423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48640/60000][Iteration 4132][Wall Clock 385.865492181s] Trained 128 records in 0.084021571 seconds. Throughput is 1523.4183 records/second. Loss is 1.9782835. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9489378288832586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48768/60000][Iteration 4133][Wall Clock 385.952159722s] Trained 128 records in 0.086667541 seconds. Throughput is 1476.9082 records/second. Loss is 1.9996128. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9485580670303975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:41 INFO  DistriOptimizer$:408 - [Epoch 9 48896/60000][Iteration 4134][Wall Clock 386.03644052s] Trained 128 records in 0.084280798 seconds. Throughput is 1518.7327 records/second. Loss is 1.9964398. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9481784531463084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49024/60000][Iteration 4135][Wall Clock 386.138091606s] Trained 128 records in 0.101651086 seconds. Throughput is 1259.2094 records/second. Loss is 1.9763567. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9477989871445267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49152/60000][Iteration 4136][Wall Clock 386.220585753s] Trained 128 records in 0.082494147 seconds. Throughput is 1551.6252 records/second. Loss is 1.9563655. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9474196689386563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49280/60000][Iteration 4137][Wall Clock 386.30321704s] Trained 128 records in 0.082631287 seconds. Throughput is 1549.05 records/second. Loss is 1.9728017. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9470404984423675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49408/60000][Iteration 4138][Wall Clock 386.382129164s] Trained 128 records in 0.078912124 seconds. Throughput is 1622.0575 records/second. Loss is 1.9699786. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9466614755693983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49536/60000][Iteration 4139][Wall Clock 386.466788525s] Trained 128 records in 0.084659361 seconds. Throughput is 1511.9415 records/second. Loss is 1.9886446. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.946282600233554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49664/60000][Iteration 4140][Wall Clock 386.552688953s] Trained 128 records in 0.085900428 seconds. Throughput is 1490.0974 records/second. Loss is 2.0024219. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.945903872348706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49792/60000][Iteration 4141][Wall Clock 386.638480815s] Trained 128 records in 0.085791862 seconds. Throughput is 1491.983 records/second. Loss is 2.008134. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.945525291828794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 49920/60000][Iteration 4142][Wall Clock 386.722831671s] Trained 128 records in 0.084350856 seconds. Throughput is 1517.4713 records/second. Loss is 2.021055. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9451468585878235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 50048/60000][Iteration 4143][Wall Clock 386.80670895s] Trained 128 records in 0.083877279 seconds. Throughput is 1526.039 records/second. Loss is 1.9780442. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9447685725398678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 50176/60000][Iteration 4144][Wall Clock 386.890186554s] Trained 128 records in 0.083477604 seconds. Throughput is 1533.3455 records/second. Loss is 1.9835252. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9443904335990667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:42 INFO  DistriOptimizer$:408 - [Epoch 9 50304/60000][Iteration 4145][Wall Clock 386.983021225s] Trained 128 records in 0.092834671 seconds. Throughput is 1378.7952 records/second. Loss is 1.9912746. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9440124416796267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 50432/60000][Iteration 4146][Wall Clock 387.059842613s] Trained 128 records in 0.076821388 seconds. Throughput is 1666.2026 records/second. Loss is 1.9804897. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.943634596695821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 50560/60000][Iteration 4147][Wall Clock 387.140608512s] Trained 128 records in 0.080765899 seconds. Throughput is 1584.8274 records/second. Loss is 1.9821085. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.94325689856199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 50688/60000][Iteration 4148][Wall Clock 387.225248344s] Trained 128 records in 0.084639832 seconds. Throughput is 1512.2903 records/second. Loss is 2.034868. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9428793471925392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 50816/60000][Iteration 4149][Wall Clock 387.309231842s] Trained 128 records in 0.083983498 seconds. Throughput is 1524.109 records/second. Loss is 1.9843361. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9425019425019428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 50944/60000][Iteration 4150][Wall Clock 387.393679857s] Trained 128 records in 0.084448015 seconds. Throughput is 1515.7253 records/second. Loss is 1.9985557. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.942124684404739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51072/60000][Iteration 4151][Wall Clock 387.479445007s] Trained 128 records in 0.08576515 seconds. Throughput is 1492.4476 records/second. Loss is 1.9766508. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9417475728155338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51200/60000][Iteration 4152][Wall Clock 387.561960933s] Trained 128 records in 0.082515926 seconds. Throughput is 1551.2157 records/second. Loss is 1.9916936. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9413706076490004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51328/60000][Iteration 4153][Wall Clock 387.644935341s] Trained 128 records in 0.082974408 seconds. Throughput is 1542.6443 records/second. Loss is 1.9879373. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9409937888198756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51456/60000][Iteration 4154][Wall Clock 387.73181262s] Trained 128 records in 0.086877279 seconds. Throughput is 1473.3427 records/second. Loss is 1.976674. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.940617116242965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51584/60000][Iteration 4155][Wall Clock 387.816064498s] Trained 128 records in 0.084251878 seconds. Throughput is 1519.2539 records/second. Loss is 1.9755412. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9402405898331394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51712/60000][Iteration 4156][Wall Clock 387.898645534s] Trained 128 records in 0.082581036 seconds. Throughput is 1549.9927 records/second. Loss is 1.9658102. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9398642095053346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:43 INFO  DistriOptimizer$:408 - [Epoch 9 51840/60000][Iteration 4157][Wall Clock 387.980900554s] Trained 128 records in 0.08225502 seconds. Throughput is 1556.136 records/second. Loss is 1.9900807. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9394879751745542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 51968/60000][Iteration 4158][Wall Clock 388.061881616s] Trained 128 records in 0.080981062 seconds. Throughput is 1580.6165 records/second. Loss is 1.9397106. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9391118867558658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52096/60000][Iteration 4159][Wall Clock 388.144379972s] Trained 128 records in 0.082498356 seconds. Throughput is 1551.546 records/second. Loss is 1.985581. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9387359441644047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52224/60000][Iteration 4160][Wall Clock 388.234873029s] Trained 128 records in 0.090493057 seconds. Throughput is 1414.4731 records/second. Loss is 2.0097435. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9383601473153714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52352/60000][Iteration 4161][Wall Clock 388.30937835s] Trained 128 records in 0.074505321 seconds. Throughput is 1717.998 records/second. Loss is 1.9667484. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.937984496124031E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52480/60000][Iteration 4162][Wall Clock 388.391006561s] Trained 128 records in 0.081628211 seconds. Throughput is 1568.0853 records/second. Loss is 2.0103781. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9376089905057158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52608/60000][Iteration 4163][Wall Clock 388.474106969s] Trained 128 records in 0.083100408 seconds. Throughput is 1540.3053 records/second. Loss is 1.9988295. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9372336303758234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52736/60000][Iteration 4164][Wall Clock 388.557619879s] Trained 128 records in 0.08351291 seconds. Throughput is 1532.6971 records/second. Loss is 1.9762671. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.936858415649816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52864/60000][Iteration 4165][Wall Clock 388.642208326s] Trained 128 records in 0.084588447 seconds. Throughput is 1513.209 records/second. Loss is 2.0190485. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9364833462432224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 52992/60000][Iteration 4166][Wall Clock 388.727841098s] Trained 128 records in 0.085632772 seconds. Throughput is 1494.7549 records/second. Loss is 2.0293255. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.936108422071636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 53120/60000][Iteration 4167][Wall Clock 388.813514081s] Trained 128 records in 0.085672983 seconds. Throughput is 1494.0532 records/second. Loss is 1.9409966. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9357336430507162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 53248/60000][Iteration 4168][Wall Clock 388.899019014s] Trained 128 records in 0.085504933 seconds. Throughput is 1496.9896 records/second. Loss is 1.9950793. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9353590090961874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:44 INFO  DistriOptimizer$:408 - [Epoch 9 53376/60000][Iteration 4169][Wall Clock 388.983888502s] Trained 128 records in 0.084869488 seconds. Throughput is 1508.1981 records/second. Loss is 1.9925803. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.934984520123839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 53504/60000][Iteration 4170][Wall Clock 389.067244108s] Trained 128 records in 0.083355606 seconds. Throughput is 1535.5896 records/second. Loss is 2.0055575. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.934610176049526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 53632/60000][Iteration 4171][Wall Clock 389.150982269s] Trained 128 records in 0.083738161 seconds. Throughput is 1528.5742 records/second. Loss is 2.0034502. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9342359767891682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 53760/60000][Iteration 4172][Wall Clock 389.232610726s] Trained 128 records in 0.081628457 seconds. Throughput is 1568.0806 records/second. Loss is 1.9965998. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9338619222587506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 53888/60000][Iteration 4173][Wall Clock 389.316125269s] Trained 128 records in 0.083514543 seconds. Throughput is 1532.6672 records/second. Loss is 1.9344877. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9334880123743234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54016/60000][Iteration 4174][Wall Clock 389.401958902s] Trained 128 records in 0.085833633 seconds. Throughput is 1491.257 records/second. Loss is 1.9851073. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.933114247052001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54144/60000][Iteration 4175][Wall Clock 389.487570061s] Trained 128 records in 0.085611159 seconds. Throughput is 1495.1322 records/second. Loss is 1.9922967. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9327406262079628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54272/60000][Iteration 4176][Wall Clock 389.570952956s] Trained 128 records in 0.083382895 seconds. Throughput is 1535.087 records/second. Loss is 2.0122705. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9323671497584543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54400/60000][Iteration 4177][Wall Clock 389.655486642s] Trained 128 records in 0.084533686 seconds. Throughput is 1514.1893 records/second. Loss is 1.990794. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9319938176197836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54528/60000][Iteration 4178][Wall Clock 389.739683952s] Trained 128 records in 0.08419731 seconds. Throughput is 1520.2385 records/second. Loss is 1.9997213. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9316206297083252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54656/60000][Iteration 4179][Wall Clock 389.825639304s] Trained 128 records in 0.085955352 seconds. Throughput is 1489.1453 records/second. Loss is 1.9709998. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9312475859405175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54784/60000][Iteration 4180][Wall Clock 389.907806132s] Trained 128 records in 0.082166828 seconds. Throughput is 1557.8063 records/second. Loss is 1.9469209. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9308746862328635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:45 INFO  DistriOptimizer$:408 - [Epoch 9 54912/60000][Iteration 4181][Wall Clock 389.990347682s] Trained 128 records in 0.08254155 seconds. Throughput is 1550.7341 records/second. Loss is 1.9902394. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9305019305019308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55040/60000][Iteration 4182][Wall Clock 390.074501971s] Trained 128 records in 0.084154289 seconds. Throughput is 1521.0159 records/second. Loss is 1.955242. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9301293186643506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55168/60000][Iteration 4183][Wall Clock 390.158298922s] Trained 128 records in 0.083796951 seconds. Throughput is 1527.502 records/second. Loss is 1.957124. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9297568506368196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55296/60000][Iteration 4184][Wall Clock 390.242735752s] Trained 128 records in 0.08443683 seconds. Throughput is 1515.9263 records/second. Loss is 1.9884686. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9293845263360988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55424/60000][Iteration 4185][Wall Clock 390.340670191s] Trained 128 records in 0.097934439 seconds. Throughput is 1306.9968 records/second. Loss is 1.9204562. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9290123456790122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55552/60000][Iteration 4186][Wall Clock 390.420546521s] Trained 128 records in 0.07987633 seconds. Throughput is 1602.4772 records/second. Loss is 2.018968. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9286403085824492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55680/60000][Iteration 4187][Wall Clock 390.50383816s] Trained 128 records in 0.083291639 seconds. Throughput is 1536.7688 records/second. Loss is 1.9658551. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.928268414963363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55808/60000][Iteration 4188][Wall Clock 390.585039012s] Trained 128 records in 0.081200852 seconds. Throughput is 1576.3381 records/second. Loss is 1.9994366. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.92789666473877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 55936/60000][Iteration 4189][Wall Clock 390.667715016s] Trained 128 records in 0.082676004 seconds. Throughput is 1548.2123 records/second. Loss is 1.9491274. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.927525057825752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 56064/60000][Iteration 4190][Wall Clock 390.751666922s] Trained 128 records in 0.083951906 seconds. Throughput is 1524.6825 records/second. Loss is 1.9492663. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.927153594141453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 56192/60000][Iteration 4191][Wall Clock 390.834476423s] Trained 128 records in 0.082809501 seconds. Throughput is 1545.7163 records/second. Loss is 1.9499893. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9267822736030826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 56320/60000][Iteration 4192][Wall Clock 390.917345138s] Trained 128 records in 0.082868715 seconds. Throughput is 1544.6118 records/second. Loss is 1.9756291. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9264110961279138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:46 INFO  DistriOptimizer$:408 - [Epoch 9 56448/60000][Iteration 4193][Wall Clock 391.002308365s] Trained 128 records in 0.084963227 seconds. Throughput is 1506.5342 records/second. Loss is 1.9718641. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.926040061633282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 56576/60000][Iteration 4194][Wall Clock 391.085127945s] Trained 128 records in 0.08281958 seconds. Throughput is 1545.5282 records/second. Loss is 1.9906083. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9256691700365877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 56704/60000][Iteration 4195][Wall Clock 391.16794768s] Trained 128 records in 0.082819735 seconds. Throughput is 1545.5253 records/second. Loss is 2.0207465. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9252984212552945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 56832/60000][Iteration 4196][Wall Clock 391.25664171s] Trained 128 records in 0.08869403 seconds. Throughput is 1443.1637 records/second. Loss is 1.9714469. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9249278152069297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 56960/60000][Iteration 4197][Wall Clock 391.336533956s] Trained 128 records in 0.079892246 seconds. Throughput is 1602.158 records/second. Loss is 2.0088475. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.924557351809084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57088/60000][Iteration 4198][Wall Clock 391.412880375s] Trained 128 records in 0.076346419 seconds. Throughput is 1676.5685 records/second. Loss is 2.0095844. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9241870309794111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57216/60000][Iteration 4199][Wall Clock 391.495359038s] Trained 128 records in 0.082478663 seconds. Throughput is 1551.9165 records/second. Loss is 1.9759914. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.923816852635629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57344/60000][Iteration 4200][Wall Clock 391.579546278s] Trained 128 records in 0.08418724 seconds. Throughput is 1520.4204 records/second. Loss is 2.0045621. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9234468166955186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57472/60000][Iteration 4201][Wall Clock 391.661771183s] Trained 128 records in 0.082224905 seconds. Throughput is 1556.7059 records/second. Loss is 2.0049593. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.923076923076923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57600/60000][Iteration 4202][Wall Clock 391.745291661s] Trained 128 records in 0.083520478 seconds. Throughput is 1532.5582 records/second. Loss is 2.0139198. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9227071716977504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57728/60000][Iteration 4203][Wall Clock 391.829603921s] Trained 128 records in 0.08431226 seconds. Throughput is 1518.1659 records/second. Loss is 1.9597274. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9223375624759708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57856/60000][Iteration 4204][Wall Clock 391.916046375s] Trained 128 records in 0.086442454 seconds. Throughput is 1480.7539 records/second. Loss is 1.9483312. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9219680953296174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:47 INFO  DistriOptimizer$:408 - [Epoch 9 57984/60000][Iteration 4205][Wall Clock 391.999689489s] Trained 128 records in 0.083643114 seconds. Throughput is 1530.3113 records/second. Loss is 1.9755304. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.921598770176787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58112/60000][Iteration 4206][Wall Clock 392.082587815s] Trained 128 records in 0.082898326 seconds. Throughput is 1544.0602 records/second. Loss is 1.9713598. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9212295869356388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58240/60000][Iteration 4207][Wall Clock 392.165717056s] Trained 128 records in 0.083129241 seconds. Throughput is 1539.771 records/second. Loss is 1.9898143. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9208605455243947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58368/60000][Iteration 4208][Wall Clock 392.287272839s] Trained 128 records in 0.121555783 seconds. Throughput is 1053.0145 records/second. Loss is 1.9709501. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9204916458613407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58496/60000][Iteration 4209][Wall Clock 392.394839168s] Trained 128 records in 0.107566329 seconds. Throughput is 1189.9635 records/second. Loss is 1.9902344. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9201228878648233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58624/60000][Iteration 4210][Wall Clock 392.504359658s] Trained 128 records in 0.10952049 seconds. Throughput is 1168.7311 records/second. Loss is 1.9711113. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.919754271453254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58752/60000][Iteration 4211][Wall Clock 392.611256739s] Trained 128 records in 0.106897081 seconds. Throughput is 1197.4135 records/second. Loss is 1.990324. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9193857965451057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 58880/60000][Iteration 4212][Wall Clock 392.719804658s] Trained 128 records in 0.108547919 seconds. Throughput is 1179.2028 records/second. Loss is 2.016567. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9190174630589137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 59008/60000][Iteration 4213][Wall Clock 392.824498142s] Trained 128 records in 0.104693484 seconds. Throughput is 1222.6167 records/second. Loss is 1.964613. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9186492709132773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:48 INFO  DistriOptimizer$:408 - [Epoch 9 59136/60000][Iteration 4214][Wall Clock 392.93167667s] Trained 128 records in 0.107178528 seconds. Throughput is 1194.269 records/second. Loss is 1.9619201. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.918281220026856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 59264/60000][Iteration 4215][Wall Clock 393.016155837s] Trained 128 records in 0.084479167 seconds. Throughput is 1515.1664 records/second. Loss is 1.9622383. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9179133103183735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 59392/60000][Iteration 4216][Wall Clock 393.101157006s] Trained 128 records in 0.085001169 seconds. Throughput is 1505.8616 records/second. Loss is 1.9513711. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9175455417066157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 59520/60000][Iteration 4217][Wall Clock 393.184958603s] Trained 128 records in 0.083801597 seconds. Throughput is 1527.4172 records/second. Loss is 1.947525. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9171779141104295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 59648/60000][Iteration 4218][Wall Clock 393.268553779s] Trained 128 records in 0.083595176 seconds. Throughput is 1531.1887 records/second. Loss is 2.0007055. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9168104274487253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 59776/60000][Iteration 4219][Wall Clock 393.35498871s] Trained 128 records in 0.086434931 seconds. Throughput is 1480.8828 records/second. Loss is 1.9994822. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9164430816404754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 59904/60000][Iteration 4220][Wall Clock 393.440309995s] Trained 128 records in 0.085321285 seconds. Throughput is 1500.2118 records/second. Loss is 2.0198445. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9160758766047133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:408 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.523743063s] Trained 128 records in 0.083433068 seconds. Throughput is 1534.1638 records/second. Loss is 1.99714. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9157088122605365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:49 INFO  DistriOptimizer$:452 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.523743063s] Epoch finished. Wall clock time is 394632.822276 ms
2019-10-14 23:17:49 INFO  DistriOptimizer$:111 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.523743063s] Validate model...
2019-10-14 23:17:50 INFO  DistriOptimizer$:178 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.523743063s] validate model throughput is 12349.563 records/second
2019-10-14 23:17:50 INFO  DistriOptimizer$:181 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.523743063s] Top1Accuracy is Accuracy(correct: 5830, count: 10000, accuracy: 0.583)
2019-10-14 23:17:50 INFO  DistriOptimizer$:221 - [Wall Clock 394.632822276s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:17:50 INFO  DistriOptimizer$:226 - [Wall Clock 394.632822276s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
2019-10-14 23:17:50 INFO  DistriOptimizer$:408 - [Epoch 10 128/60000][Iteration 4222][Wall Clock 394.717657578s] Trained 128 records in 0.084835302 seconds. Throughput is 1508.8059 records/second. Loss is 2.0175998. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.915341888527102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:50 INFO  DistriOptimizer$:408 - [Epoch 10 256/60000][Iteration 4223][Wall Clock 394.799961121s] Trained 128 records in 0.082303543 seconds. Throughput is 1555.2185 records/second. Loss is 1.9938506. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9149751053236308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:50 INFO  DistriOptimizer$:408 - [Epoch 10 384/60000][Iteration 4224][Wall Clock 394.888288479s] Trained 128 records in 0.088327358 seconds. Throughput is 1449.1547 records/second. Loss is 1.9669975. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9146084625694046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:50 INFO  DistriOptimizer$:408 - [Epoch 10 512/60000][Iteration 4225][Wall Clock 394.994314686s] Trained 128 records in 0.106026207 seconds. Throughput is 1207.2487 records/second. Loss is 1.9925942. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9142419601837673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:50 INFO  DistriOptimizer$:408 - [Epoch 10 640/60000][Iteration 4226][Wall Clock 395.078568046s] Trained 128 records in 0.08425336 seconds. Throughput is 1519.2272 records/second. Loss is 1.9758078. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9138755980861245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:50 INFO  DistriOptimizer$:408 - [Epoch 10 768/60000][Iteration 4227][Wall Clock 395.164369789s] Trained 128 records in 0.085801743 seconds. Throughput is 1491.8112 records/second. Loss is 1.9799237. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9135093761959434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 896/60000][Iteration 4228][Wall Clock 395.249132034s] Trained 128 records in 0.084762245 seconds. Throughput is 1510.1063 records/second. Loss is 1.9780537. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.913143294432753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1024/60000][Iteration 4229][Wall Clock 395.333558968s] Trained 128 records in 0.084426934 seconds. Throughput is 1516.1039 records/second. Loss is 1.9953393. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.912777352716144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1152/60000][Iteration 4230][Wall Clock 395.42136483s] Trained 128 records in 0.087805862 seconds. Throughput is 1457.7615 records/second. Loss is 2.009325. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9124115509657678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1280/60000][Iteration 4231][Wall Clock 395.510159373s] Trained 128 records in 0.088794543 seconds. Throughput is 1441.53 records/second. Loss is 1.9417999. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9120458891013384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1408/60000][Iteration 4232][Wall Clock 395.595145909s] Trained 128 records in 0.084986536 seconds. Throughput is 1506.1208 records/second. Loss is 2.0265105. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9116803670426305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1536/60000][Iteration 4233][Wall Clock 395.679673057s] Trained 128 records in 0.084527148 seconds. Throughput is 1514.3064 records/second. Loss is 1.9377668. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9113149847094801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1664/60000][Iteration 4234][Wall Clock 395.765406426s] Trained 128 records in 0.085733369 seconds. Throughput is 1493.001 records/second. Loss is 1.9757123. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.910949742021785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1792/60000][Iteration 4235][Wall Clock 395.841034079s] Trained 128 records in 0.075627653 seconds. Throughput is 1692.5026 records/second. Loss is 2.0192857. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9105846388995032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 1920/60000][Iteration 4236][Wall Clock 395.92241748s] Trained 128 records in 0.081383401 seconds. Throughput is 1572.8024 records/second. Loss is 1.982794. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9102196752626553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 2048/60000][Iteration 4237][Wall Clock 396.004220729s] Trained 128 records in 0.081803249 seconds. Throughput is 1564.7301 records/second. Loss is 2.0020177. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9098548510313219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 2176/60000][Iteration 4238][Wall Clock 396.088034577s] Trained 128 records in 0.083813848 seconds. Throughput is 1527.194 records/second. Loss is 1.9717561. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9094901661256445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:51 INFO  DistriOptimizer$:408 - [Epoch 10 2304/60000][Iteration 4239][Wall Clock 396.173056855s] Trained 128 records in 0.085022278 seconds. Throughput is 1505.4878 records/second. Loss is 1.987902. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9091256204658265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 2432/60000][Iteration 4240][Wall Clock 396.257266991s] Trained 128 records in 0.084210136 seconds. Throughput is 1520.0071 records/second. Loss is 1.9806648. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9087612139721323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 2560/60000][Iteration 4241][Wall Clock 396.340951765s] Trained 128 records in 0.083684774 seconds. Throughput is 1529.5494 records/second. Loss is 1.9460652. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9083969465648855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 2688/60000][Iteration 4242][Wall Clock 396.426114241s] Trained 128 records in 0.085162476 seconds. Throughput is 1503.0094 records/second. Loss is 1.9614265. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9080328181644726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 2816/60000][Iteration 4243][Wall Clock 396.509965059s] Trained 128 records in 0.083850818 seconds. Throughput is 1526.5206 records/second. Loss is 1.956439. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9076688286913393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 2944/60000][Iteration 4244][Wall Clock 396.594563386s] Trained 128 records in 0.084598327 seconds. Throughput is 1513.0323 records/second. Loss is 1.9912802. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9073049780659926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3072/60000][Iteration 4245][Wall Clock 396.678701481s] Trained 128 records in 0.084138095 seconds. Throughput is 1521.3085 records/second. Loss is 2.0213137. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9069412662090009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3200/60000][Iteration 4246][Wall Clock 396.764761771s] Trained 128 records in 0.08606029 seconds. Throughput is 1487.3293 records/second. Loss is 1.9878877. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9065776930409913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3328/60000][Iteration 4247][Wall Clock 396.856213131s] Trained 128 records in 0.09145136 seconds. Throughput is 1399.6511 records/second. Loss is 1.9872216. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9062142584826535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3456/60000][Iteration 4248][Wall Clock 396.940861499s] Trained 128 records in 0.084648368 seconds. Throughput is 1512.1378 records/second. Loss is 1.9785618. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9058509624547362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3584/60000][Iteration 4249][Wall Clock 397.031882392s] Trained 128 records in 0.091020893 seconds. Throughput is 1406.2706 records/second. Loss is 1.9435638. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9054878048780488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3712/60000][Iteration 4250][Wall Clock 397.119002534s] Trained 128 records in 0.087120142 seconds. Throughput is 1469.2354 records/second. Loss is 1.9662344. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9051247856734617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:52 INFO  DistriOptimizer$:408 - [Epoch 10 3840/60000][Iteration 4251][Wall Clock 397.203890325s] Trained 128 records in 0.084887791 seconds. Throughput is 1507.8729 records/second. Loss is 1.9747328. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9047619047619048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 3968/60000][Iteration 4252][Wall Clock 397.285846012s] Trained 128 records in 0.081955687 seconds. Throughput is 1561.8196 records/second. Loss is 2.0035682. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9043991620643687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4096/60000][Iteration 4253][Wall Clock 397.369216831s] Trained 128 records in 0.083370819 seconds. Throughput is 1535.3093 records/second. Loss is 1.9661859. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.904036557501904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4224/60000][Iteration 4254][Wall Clock 397.454146332s] Trained 128 records in 0.084929501 seconds. Throughput is 1507.1323 records/second. Loss is 1.9656162. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9036740909956216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4352/60000][Iteration 4255][Wall Clock 397.537269633s] Trained 128 records in 0.083123301 seconds. Throughput is 1539.8811 records/second. Loss is 1.9751346. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.903311762466692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4480/60000][Iteration 4256][Wall Clock 397.621145s] Trained 128 records in 0.083875367 seconds. Throughput is 1526.0739 records/second. Loss is 1.9809194. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9029495718363463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4608/60000][Iteration 4257][Wall Clock 397.706252802s] Trained 128 records in 0.085107802 seconds. Throughput is 1503.9749 records/second. Loss is 1.9440768. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.902587519025875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4736/60000][Iteration 4258][Wall Clock 397.797007419s] Trained 128 records in 0.090754617 seconds. Throughput is 1410.3966 records/second. Loss is 1.9512899. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9022256039566293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4864/60000][Iteration 4259][Wall Clock 397.887356913s] Trained 128 records in 0.090349494 seconds. Throughput is 1416.7207 records/second. Loss is 1.9602282. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.901863826550019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 4992/60000][Iteration 4260][Wall Clock 397.974298656s] Trained 128 records in 0.086941743 seconds. Throughput is 1472.2502 records/second. Loss is 1.9895515. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9015021867275147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 5120/60000][Iteration 4261][Wall Clock 398.060053958s] Trained 128 records in 0.085755302 seconds. Throughput is 1492.619 records/second. Loss is 1.9752346. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9011406844106465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:53 INFO  DistriOptimizer$:408 - [Epoch 10 5248/60000][Iteration 4262][Wall Clock 398.142746046s] Trained 128 records in 0.082692088 seconds. Throughput is 1547.9111 records/second. Loss is 1.9798703. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9007793195210037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 5376/60000][Iteration 4263][Wall Clock 398.227765537s] Trained 128 records in 0.085019491 seconds. Throughput is 1505.5371 records/second. Loss is 1.9536619. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9004180919802356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 5504/60000][Iteration 4264][Wall Clock 398.312653464s] Trained 128 records in 0.084887927 seconds. Throughput is 1507.8705 records/second. Loss is 1.9678892. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.9000570017100514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 5632/60000][Iteration 4265][Wall Clock 398.399402365s] Trained 128 records in 0.086748901 seconds. Throughput is 1475.5231 records/second. Loss is 1.9419023. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8996960486322188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 5760/60000][Iteration 4266][Wall Clock 398.488795123s] Trained 128 records in 0.089392758 seconds. Throughput is 1431.8833 records/second. Loss is 1.9708774. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8993352326685662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 5888/60000][Iteration 4267][Wall Clock 398.573967406s] Trained 128 records in 0.085172283 seconds. Throughput is 1502.8363 records/second. Loss is 2.0019188. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8989745537409798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6016/60000][Iteration 4268][Wall Clock 398.660031224s] Trained 128 records in 0.086063818 seconds. Throughput is 1487.2684 records/second. Loss is 2.0011237. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8986140117714068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6144/60000][Iteration 4269][Wall Clock 398.746032459s] Trained 128 records in 0.086001235 seconds. Throughput is 1488.3507 records/second. Loss is 2.0021322. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8982536066818528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6272/60000][Iteration 4270][Wall Clock 398.834968306s] Trained 128 records in 0.088935847 seconds. Throughput is 1439.2397 records/second. Loss is 1.9530851. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.897893338394382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6400/60000][Iteration 4271][Wall Clock 398.918952562s] Trained 128 records in 0.083984256 seconds. Throughput is 1524.0952 records/second. Loss is 1.9972774. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8975332068311195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6528/60000][Iteration 4272][Wall Clock 399.01080297s] Trained 128 records in 0.091850408 seconds. Throughput is 1393.5703 records/second. Loss is 2.013902. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8971732119142478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6656/60000][Iteration 4273][Wall Clock 399.091017989s] Trained 128 records in 0.080215019 seconds. Throughput is 1595.711 records/second. Loss is 2.0008426. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8968133535660092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:54 INFO  DistriOptimizer$:408 - [Epoch 10 6784/60000][Iteration 4274][Wall Clock 399.173918412s] Trained 128 records in 0.082900423 seconds. Throughput is 1544.0211 records/second. Loss is 1.9685456. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.896453631708705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 6912/60000][Iteration 4275][Wall Clock 399.253659116s] Trained 128 records in 0.079740704 seconds. Throughput is 1605.2028 records/second. Loss is 1.9878728. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8960940462646946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7040/60000][Iteration 4276][Wall Clock 399.339291522s] Trained 128 records in 0.085632406 seconds. Throughput is 1494.7612 records/second. Loss is 1.973417. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.895734597156398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7168/60000][Iteration 4277][Wall Clock 399.425447045s] Trained 128 records in 0.086155523 seconds. Throughput is 1485.6853 records/second. Loss is 1.9719175. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8953752843062926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7296/60000][Iteration 4278][Wall Clock 399.510016095s] Trained 128 records in 0.08456905 seconds. Throughput is 1513.556 records/second. Loss is 1.9771473. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8950161076369148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7424/60000][Iteration 4279][Wall Clock 399.616463169s] Trained 128 records in 0.106447074 seconds. Throughput is 1202.4756 records/second. Loss is 1.9720553. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8946570670708602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7552/60000][Iteration 4280][Wall Clock 399.732193696s] Trained 128 records in 0.115730527 seconds. Throughput is 1106.0176 records/second. Loss is 1.9803379. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8942981625307825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7680/60000][Iteration 4281][Wall Clock 399.838293564s] Trained 128 records in 0.106099868 seconds. Throughput is 1206.4105 records/second. Loss is 1.9332445. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.893939393939394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7808/60000][Iteration 4282][Wall Clock 399.942427618s] Trained 128 records in 0.104134054 seconds. Throughput is 1229.1848 records/second. Loss is 1.9536802. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8935807612194662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 7936/60000][Iteration 4283][Wall Clock 400.046649485s] Trained 128 records in 0.104221867 seconds. Throughput is 1228.1492 records/second. Loss is 1.979227. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.893222264293828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:55 INFO  DistriOptimizer$:408 - [Epoch 10 8064/60000][Iteration 4284][Wall Clock 400.14852598s] Trained 128 records in 0.101876495 seconds. Throughput is 1256.4232 records/second. Loss is 1.9595287. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.892863903085368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8192/60000][Iteration 4285][Wall Clock 400.25104727s] Trained 128 records in 0.10252129 seconds. Throughput is 1248.5211 records/second. Loss is 1.9676471. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8925056775170325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8320/60000][Iteration 4286][Wall Clock 400.359279747s] Trained 128 records in 0.108232477 seconds. Throughput is 1182.6395 records/second. Loss is 1.9448578. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.892147587511826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8448/60000][Iteration 4287][Wall Clock 400.456085379s] Trained 128 records in 0.096805632 seconds. Throughput is 1322.237 records/second. Loss is 1.9893547. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.891789632992811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8576/60000][Iteration 4288][Wall Clock 400.539583699s] Trained 128 records in 0.08349832 seconds. Throughput is 1532.965 records/second. Loss is 1.9688784. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8914318138831096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8704/60000][Iteration 4289][Wall Clock 400.624961271s] Trained 128 records in 0.085377572 seconds. Throughput is 1499.2228 records/second. Loss is 2.0053043. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8910741301059002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8832/60000][Iteration 4290][Wall Clock 400.70916474s] Trained 128 records in 0.084203469 seconds. Throughput is 1520.1274 records/second. Loss is 1.9972199. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8907165815844207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 8960/60000][Iteration 4291][Wall Clock 400.792780531s] Trained 128 records in 0.083615791 seconds. Throughput is 1530.8114 records/second. Loss is 1.9890755. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.890359168241966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 9088/60000][Iteration 4292][Wall Clock 400.87995637s] Trained 128 records in 0.087175839 seconds. Throughput is 1468.2968 records/second. Loss is 1.9854714. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.89000189000189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 9216/60000][Iteration 4293][Wall Clock 400.965145501s] Trained 128 records in 0.085189131 seconds. Throughput is 1502.5391 records/second. Loss is 1.9761617. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.889644746787604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 9344/60000][Iteration 4294][Wall Clock 401.049763206s] Trained 128 records in 0.084617705 seconds. Throughput is 1512.6858 records/second. Loss is 1.9304106. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.889287738522577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:56 INFO  DistriOptimizer$:408 - [Epoch 10 9472/60000][Iteration 4295][Wall Clock 401.133836332s] Trained 128 records in 0.084073126 seconds. Throughput is 1522.4841 records/second. Loss is 1.9581738. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8889308651303362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 9600/60000][Iteration 4296][Wall Clock 401.217335576s] Trained 128 records in 0.083499244 seconds. Throughput is 1532.948 records/second. Loss is 1.9858335. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8885741265344666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 9728/60000][Iteration 4297][Wall Clock 401.301299854s] Trained 128 records in 0.083964278 seconds. Throughput is 1524.4578 records/second. Loss is 1.9448209. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8882175226586103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 9856/60000][Iteration 4298][Wall Clock 401.392805375s] Trained 128 records in 0.091505521 seconds. Throughput is 1398.8228 records/second. Loss is 1.9789231. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.887861053426468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 9984/60000][Iteration 4299][Wall Clock 401.469302882s] Trained 128 records in 0.076497507 seconds. Throughput is 1673.2571 records/second. Loss is 1.9405617. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8875047187617969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10112/60000][Iteration 4300][Wall Clock 401.554058609s] Trained 128 records in 0.084755727 seconds. Throughput is 1510.2224 records/second. Loss is 1.984909. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.887148518588413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10240/60000][Iteration 4301][Wall Clock 401.639076375s] Trained 128 records in 0.085017766 seconds. Throughput is 1505.5677 records/second. Loss is 1.9538317. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8867924528301889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10368/60000][Iteration 4302][Wall Clock 401.722768651s] Trained 128 records in 0.083692276 seconds. Throughput is 1529.4124 records/second. Loss is 1.9336778. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8864365214110544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10496/60000][Iteration 4303][Wall Clock 401.809688713s] Trained 128 records in 0.086920062 seconds. Throughput is 1472.6174 records/second. Loss is 1.9498154. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.886080724254998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10624/60000][Iteration 4304][Wall Clock 401.892776096s] Trained 128 records in 0.083087383 seconds. Throughput is 1540.5468 records/second. Loss is 1.9724071. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8857250612860644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10752/60000][Iteration 4305][Wall Clock 401.976709209s] Trained 128 records in 0.083933113 seconds. Throughput is 1525.0238 records/second. Loss is 2.021062. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.885369532428356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 10880/60000][Iteration 4306][Wall Clock 402.059548473s] Trained 128 records in 0.082839264 seconds. Throughput is 1545.161 records/second. Loss is 2.0147593. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8850141376060322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:57 INFO  DistriOptimizer$:408 - [Epoch 10 11008/60000][Iteration 4307][Wall Clock 402.143610091s] Trained 128 records in 0.084061618 seconds. Throughput is 1522.6926 records/second. Loss is 1.9822114. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8846588767433095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11136/60000][Iteration 4308][Wall Clock 402.235556694s] Trained 128 records in 0.091946603 seconds. Throughput is 1392.1123 records/second. Loss is 2.0044155. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.884303749764462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11264/60000][Iteration 4309][Wall Clock 402.316591677s] Trained 128 records in 0.081034983 seconds. Throughput is 1579.5648 records/second. Loss is 1.9862226. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8839487565938207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11392/60000][Iteration 4310][Wall Clock 402.401956055s] Trained 128 records in 0.085364378 seconds. Throughput is 1499.4545 records/second. Loss is 2.0159266. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8835938971557733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11520/60000][Iteration 4311][Wall Clock 402.487567455s] Trained 128 records in 0.0856114 seconds. Throughput is 1495.1279 records/second. Loss is 2.0058448. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8832391713747646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11648/60000][Iteration 4312][Wall Clock 402.571506797s] Trained 128 records in 0.083939342 seconds. Throughput is 1524.9106 records/second. Loss is 1.9429636. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8828845791752966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11776/60000][Iteration 4313][Wall Clock 402.654815191s] Trained 128 records in 0.083308394 seconds. Throughput is 1536.4598 records/second. Loss is 1.9483634. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8825301204819275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 11904/60000][Iteration 4314][Wall Clock 402.737744108s] Trained 128 records in 0.082928917 seconds. Throughput is 1543.4905 records/second. Loss is 1.9768885. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8821757952192737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 12032/60000][Iteration 4315][Wall Clock 402.822264492s] Trained 128 records in 0.084520384 seconds. Throughput is 1514.4276 records/second. Loss is 1.9722224. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.881821603312006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 12160/60000][Iteration 4316][Wall Clock 402.905019182s] Trained 128 records in 0.08275469 seconds. Throughput is 1546.7402 records/second. Loss is 2.0023508. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8814675446848542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 12288/60000][Iteration 4317][Wall Clock 402.988779777s] Trained 128 records in 0.083760595 seconds. Throughput is 1528.1648 records/second. Loss is 1.9708762. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8811136192626037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 12416/60000][Iteration 4318][Wall Clock 403.07190682s] Trained 128 records in 0.083127043 seconds. Throughput is 1539.8118 records/second. Loss is 1.9722787. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.880759826970096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:58 INFO  DistriOptimizer$:408 - [Epoch 10 12544/60000][Iteration 4319][Wall Clock 403.155185178s] Trained 128 records in 0.083278358 seconds. Throughput is 1537.0139 records/second. Loss is 1.9595287. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.88040616773223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 12672/60000][Iteration 4320][Wall Clock 403.239388052s] Trained 128 records in 0.084202874 seconds. Throughput is 1520.1382 records/second. Loss is 1.9948602. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8800526414739614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 12800/60000][Iteration 4321][Wall Clock 403.322553336s] Trained 128 records in 0.083165284 seconds. Throughput is 1539.1038 records/second. Loss is 1.9460831. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8796992481203006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 12928/60000][Iteration 4322][Wall Clock 403.407694825s] Trained 128 records in 0.085141489 seconds. Throughput is 1503.3799 records/second. Loss is 1.9870707. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8793459875963167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13056/60000][Iteration 4323][Wall Clock 403.490171149s] Trained 128 records in 0.082476324 seconds. Throughput is 1551.9606 records/second. Loss is 1.9605554. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8789928598271326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13184/60000][Iteration 4324][Wall Clock 403.579895856s] Trained 128 records in 0.089724707 seconds. Throughput is 1426.5859 records/second. Loss is 1.976264. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8786398647379295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13312/60000][Iteration 4325][Wall Clock 403.655635822s] Trained 128 records in 0.075739966 seconds. Throughput is 1689.9929 records/second. Loss is 1.9614737. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8782870022539445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13440/60000][Iteration 4326][Wall Clock 403.736532296s] Trained 128 records in 0.080896474 seconds. Throughput is 1582.2692 records/second. Loss is 2.025145. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8779342723004695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13568/60000][Iteration 4327][Wall Clock 403.818592443s] Trained 128 records in 0.082060147 seconds. Throughput is 1559.8315 records/second. Loss is 1.9407706. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.877581674802854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13696/60000][Iteration 4328][Wall Clock 403.918588079s] Trained 128 records in 0.099995636 seconds. Throughput is 1280.0559 records/second. Loss is 1.9767246. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8772292096865028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13824/60000][Iteration 4329][Wall Clock 404.002872124s] Trained 128 records in 0.084284045 seconds. Throughput is 1518.6742 records/second. Loss is 2.000116. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8768768768768769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:17:59 INFO  DistriOptimizer$:408 - [Epoch 10 13952/60000][Iteration 4330][Wall Clock 404.091637731s] Trained 128 records in 0.088765607 seconds. Throughput is 1442.0 records/second. Loss is 2.01252. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8765246762994934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14080/60000][Iteration 4331][Wall Clock 404.17597131s] Trained 128 records in 0.084333579 seconds. Throughput is 1517.7822 records/second. Loss is 1.979926. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.876172607879925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14208/60000][Iteration 4332][Wall Clock 404.259638086s] Trained 128 records in 0.083666776 seconds. Throughput is 1529.8784 records/second. Loss is 1.9716537. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8758206715438003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14336/60000][Iteration 4333][Wall Clock 404.350014073s] Trained 128 records in 0.090375987 seconds. Throughput is 1416.3054 records/second. Loss is 1.93738. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8754688672168043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14464/60000][Iteration 4334][Wall Clock 404.447388684s] Trained 128 records in 0.097374611 seconds. Throughput is 1314.511 records/second. Loss is 1.9788376. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8751171948246765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14592/60000][Iteration 4335][Wall Clock 404.561660499s] Trained 128 records in 0.114271815 seconds. Throughput is 1120.1362 records/second. Loss is 1.9646195. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8747656542932132E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14720/60000][Iteration 4336][Wall Clock 404.652670371s] Trained 128 records in 0.091009872 seconds. Throughput is 1406.4409 records/second. Loss is 1.9884274. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8744142455482662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14848/60000][Iteration 4337][Wall Clock 404.740582528s] Trained 128 records in 0.087912157 seconds. Throughput is 1455.9989 records/second. Loss is 1.9510869. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.874062968515742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 14976/60000][Iteration 4338][Wall Clock 404.827355213s] Trained 128 records in 0.086772685 seconds. Throughput is 1475.1185 records/second. Loss is 1.9875203. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.873711823121604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 15104/60000][Iteration 4339][Wall Clock 404.912260587s] Trained 128 records in 0.084905374 seconds. Throughput is 1507.5607 records/second. Loss is 1.9794259. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8733608092918696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 15232/60000][Iteration 4340][Wall Clock 404.993984231s] Trained 128 records in 0.081723644 seconds. Throughput is 1566.2542 records/second. Loss is 1.9466541. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8730099269526128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:00 INFO  DistriOptimizer$:408 - [Epoch 10 15360/60000][Iteration 4341][Wall Clock 405.079254801s] Trained 128 records in 0.08527057 seconds. Throughput is 1501.1041 records/second. Loss is 1.986876. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8726591760299626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 15488/60000][Iteration 4342][Wall Clock 405.164976868s] Trained 128 records in 0.085722067 seconds. Throughput is 1493.1978 records/second. Loss is 1.9959335. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8723085564501028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 15616/60000][Iteration 4343][Wall Clock 405.251407046s] Trained 128 records in 0.086430178 seconds. Throughput is 1480.9642 records/second. Loss is 1.9987203. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8719580681392735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 15744/60000][Iteration 4344][Wall Clock 405.337620711s] Trained 128 records in 0.086213665 seconds. Throughput is 1484.6835 records/second. Loss is 1.9624009. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8716077110237696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 15872/60000][Iteration 4345][Wall Clock 405.42161584s] Trained 128 records in 0.083995129 seconds. Throughput is 1523.898 records/second. Loss is 1.9699723. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.87125748502994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16000/60000][Iteration 4346][Wall Clock 405.504410606s] Trained 128 records in 0.082794766 seconds. Throughput is 1545.9915 records/second. Loss is 1.9730496. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.870907390084191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16128/60000][Iteration 4347][Wall Clock 405.58726837s] Trained 128 records in 0.082857764 seconds. Throughput is 1544.816 records/second. Loss is 1.95147. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8705574261129816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16256/60000][Iteration 4348][Wall Clock 405.668578631s] Trained 128 records in 0.081310261 seconds. Throughput is 1574.2172 records/second. Loss is 1.9806767. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8702075930428276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16384/60000][Iteration 4349][Wall Clock 405.750512789s] Trained 128 records in 0.081934158 seconds. Throughput is 1562.23 records/second. Loss is 1.9491087. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8698578908002991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16512/60000][Iteration 4350][Wall Clock 405.843314979s] Trained 128 records in 0.09280219 seconds. Throughput is 1379.2778 records/second. Loss is 1.9344949. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.869508319312021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16640/60000][Iteration 4351][Wall Clock 405.91972413s] Trained 128 records in 0.076409151 seconds. Throughput is 1675.192 records/second. Loss is 1.9837683. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8691588785046728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16768/60000][Iteration 4352][Wall Clock 406.006421142s] Trained 128 records in 0.086697012 seconds. Throughput is 1476.4061 records/second. Loss is 1.9740233. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8688095683049897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:01 INFO  DistriOptimizer$:408 - [Epoch 10 16896/60000][Iteration 4353][Wall Clock 406.089425495s] Trained 128 records in 0.083004353 seconds. Throughput is 1542.0878 records/second. Loss is 1.9823629. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.868460388639761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17024/60000][Iteration 4354][Wall Clock 406.179464965s] Trained 128 records in 0.09003947 seconds. Throughput is 1421.5988 records/second. Loss is 2.0144424. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8681113394358306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17152/60000][Iteration 4355][Wall Clock 406.26366164s] Trained 128 records in 0.084196675 seconds. Throughput is 1520.2501 records/second. Loss is 1.9869461. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8677624206200972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17280/60000][Iteration 4356][Wall Clock 406.346934856s] Trained 128 records in 0.083273216 seconds. Throughput is 1537.1089 records/second. Loss is 1.963983. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8674136321195143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17408/60000][Iteration 4357][Wall Clock 406.430233171s] Trained 128 records in 0.083298315 seconds. Throughput is 1536.6456 records/second. Loss is 2.0234866. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8670649738610905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17536/60000][Iteration 4358][Wall Clock 406.514678248s] Trained 128 records in 0.084445077 seconds. Throughput is 1515.7782 records/second. Loss is 1.9341211. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8667164457718873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17664/60000][Iteration 4359][Wall Clock 406.604572831s] Trained 128 records in 0.089894583 seconds. Throughput is 1423.89 records/second. Loss is 1.9978697. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8663680477790223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17792/60000][Iteration 4360][Wall Clock 406.687774974s] Trained 128 records in 0.083202143 seconds. Throughput is 1538.4219 records/second. Loss is 1.9932036. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.866019779809666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 17920/60000][Iteration 4361][Wall Clock 406.774301687s] Trained 128 records in 0.086526713 seconds. Throughput is 1479.3119 records/second. Loss is 1.9736875. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8656716417910448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 18048/60000][Iteration 4362][Wall Clock 406.860803155s] Trained 128 records in 0.086501468 seconds. Throughput is 1479.7437 records/second. Loss is 1.9102275. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8653236336504386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 18176/60000][Iteration 4363][Wall Clock 406.945514609s] Trained 128 records in 0.084711454 seconds. Throughput is 1511.0117 records/second. Loss is 1.9603646. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.864975755315181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 18304/60000][Iteration 4364][Wall Clock 407.029864779s] Trained 128 records in 0.08435017 seconds. Throughput is 1517.4836 records/second. Loss is 1.9976912. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8646280067126608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:02 INFO  DistriOptimizer$:408 - [Epoch 10 18432/60000][Iteration 4365][Wall Clock 407.115713452s] Trained 128 records in 0.085848673 seconds. Throughput is 1490.9956 records/second. Loss is 1.9891993. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8642803877703208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 18560/60000][Iteration 4366][Wall Clock 407.20244121s] Trained 128 records in 0.086727758 seconds. Throughput is 1475.8827 records/second. Loss is 2.0137196. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.863932898415657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 18688/60000][Iteration 4367][Wall Clock 407.28848402s] Trained 128 records in 0.08604281 seconds. Throughput is 1487.6316 records/second. Loss is 1.947146. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8635855385762209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 18816/60000][Iteration 4368][Wall Clock 407.374077366s] Trained 128 records in 0.085593346 seconds. Throughput is 1495.4434 records/second. Loss is 2.0266669. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.863238308179616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 18944/60000][Iteration 4369][Wall Clock 407.458532943s] Trained 128 records in 0.084455577 seconds. Throughput is 1515.5896 records/second. Loss is 1.9596356. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8628912071535022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19072/60000][Iteration 4370][Wall Clock 407.545056149s] Trained 128 records in 0.086523206 seconds. Throughput is 1479.372 records/second. Loss is 1.9984348. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8625442354255913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19200/60000][Iteration 4371][Wall Clock 407.629813439s] Trained 128 records in 0.08475729 seconds. Throughput is 1510.1946 records/second. Loss is 2.0036795. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8621973929236498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19328/60000][Iteration 4372][Wall Clock 407.713201687s] Trained 128 records in 0.083388248 seconds. Throughput is 1534.9885 records/second. Loss is 1.9790348. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.861850679575498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19456/60000][Iteration 4373][Wall Clock 407.797516009s] Trained 128 records in 0.084314322 seconds. Throughput is 1518.1288 records/second. Loss is 1.9907221. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8615040953090097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19584/60000][Iteration 4374][Wall Clock 407.881304066s] Trained 128 records in 0.083788057 seconds. Throughput is 1527.664 records/second. Loss is 1.9572697. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8611576400521124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19712/60000][Iteration 4375][Wall Clock 407.964099734s] Trained 128 records in 0.082795668 seconds. Throughput is 1545.9746 records/second. Loss is 1.9515967. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8608113137327876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19840/60000][Iteration 4376][Wall Clock 408.057616421s] Trained 128 records in 0.093516687 seconds. Throughput is 1368.7397 records/second. Loss is 1.9845169. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.86046511627907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:03 INFO  DistriOptimizer$:408 - [Epoch 10 19968/60000][Iteration 4377][Wall Clock 408.139368159s] Trained 128 records in 0.081751738 seconds. Throughput is 1565.716 records/second. Loss is 1.9483924. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8601190476190475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20096/60000][Iteration 4378][Wall Clock 408.220502037s] Trained 128 records in 0.081133878 seconds. Throughput is 1577.6393 records/second. Loss is 1.9767679. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.859773107680863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20224/60000][Iteration 4379][Wall Clock 408.301901501s] Trained 128 records in 0.081399464 seconds. Throughput is 1572.492 records/second. Loss is 1.9591032. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.859427296392711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20352/60000][Iteration 4380][Wall Clock 408.386655469s] Trained 128 records in 0.084753968 seconds. Throughput is 1510.2538 records/second. Loss is 1.9639701. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8590816136828406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20480/60000][Iteration 4381][Wall Clock 408.470087272s] Trained 128 records in 0.083431803 seconds. Throughput is 1534.1871 records/second. Loss is 1.9586786. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.858736059479554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20608/60000][Iteration 4382][Wall Clock 408.555757792s] Trained 128 records in 0.08567052 seconds. Throughput is 1494.0962 records/second. Loss is 1.9531007. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8583906337112061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20736/60000][Iteration 4383][Wall Clock 408.645837671s] Trained 128 records in 0.090079879 seconds. Throughput is 1420.961 records/second. Loss is 1.9647183. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.858045336306206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20864/60000][Iteration 4384][Wall Clock 408.738802255s] Trained 128 records in 0.092964584 seconds. Throughput is 1376.8684 records/second. Loss is 1.9808505. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.857700167193015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 20992/60000][Iteration 4385][Wall Clock 408.82254411s] Trained 128 records in 0.083741855 seconds. Throughput is 1528.5068 records/second. Loss is 1.9334974. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8573551263001485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 21120/60000][Iteration 4386][Wall Clock 408.906354527s] Trained 128 records in 0.083810417 seconds. Throughput is 1527.2565 records/second. Loss is 2.019455. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8570102135561747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 21248/60000][Iteration 4387][Wall Clock 408.993405259s] Trained 128 records in 0.087050732 seconds. Throughput is 1470.407 records/second. Loss is 1.9501728. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.856665428889714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:04 INFO  DistriOptimizer$:408 - [Epoch 10 21376/60000][Iteration 4388][Wall Clock 409.080236203s] Trained 128 records in 0.086830944 seconds. Throughput is 1474.1289 records/second. Loss is 1.9631917. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.856320772229441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 21504/60000][Iteration 4389][Wall Clock 409.166007238s] Trained 128 records in 0.085771035 seconds. Throughput is 1492.3453 records/second. Loss is 2.0087612. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8559762435040833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 21632/60000][Iteration 4390][Wall Clock 409.251168557s] Trained 128 records in 0.085161319 seconds. Throughput is 1503.0298 records/second. Loss is 2.0276766. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8556318426424197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 21760/60000][Iteration 4391][Wall Clock 409.335631572s] Trained 128 records in 0.084463015 seconds. Throughput is 1515.4562 records/second. Loss is 1.9525532. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.855287569573284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 21888/60000][Iteration 4392][Wall Clock 409.421382393s] Trained 128 records in 0.085750821 seconds. Throughput is 1492.6971 records/second. Loss is 1.9587114. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8549434242255613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22016/60000][Iteration 4393][Wall Clock 409.505683735s] Trained 128 records in 0.084301342 seconds. Throughput is 1518.3625 records/second. Loss is 1.9809654. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8545994065281897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22144/60000][Iteration 4394][Wall Clock 409.589634358s] Trained 128 records in 0.083950623 seconds. Throughput is 1524.7058 records/second. Loss is 1.9702829. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8542555164101615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22272/60000][Iteration 4395][Wall Clock 409.680067548s] Trained 128 records in 0.09043319 seconds. Throughput is 1415.4095 records/second. Loss is 1.9317079. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.853911753800519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22400/60000][Iteration 4396][Wall Clock 409.762116125s] Trained 128 records in 0.082048577 seconds. Throughput is 1560.0514 records/second. Loss is 1.9579688. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8535681186283596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22528/60000][Iteration 4397][Wall Clock 409.845290751s] Trained 128 records in 0.083174626 seconds. Throughput is 1538.9309 records/second. Loss is 1.9744712. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.853224610822832E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22656/60000][Iteration 4398][Wall Clock 409.931359224s] Trained 128 records in 0.086068473 seconds. Throughput is 1487.188 records/second. Loss is 1.9521364. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8528812303131369E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22784/60000][Iteration 4399][Wall Clock 410.013509836s] Trained 128 records in 0.082150612 seconds. Throughput is 1558.1139 records/second. Loss is 1.9770305. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8525379770285293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:05 INFO  DistriOptimizer$:408 - [Epoch 10 22912/60000][Iteration 4400][Wall Clock 410.097607791s] Trained 128 records in 0.084097955 seconds. Throughput is 1522.0347 records/second. Loss is 1.9767976. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8521948508983145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23040/60000][Iteration 4401][Wall Clock 410.182455475s] Trained 128 records in 0.084847684 seconds. Throughput is 1508.5857 records/second. Loss is 1.9933894. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8518518518518518E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23168/60000][Iteration 4402][Wall Clock 410.275447985s] Trained 128 records in 0.09299251 seconds. Throughput is 1376.455 records/second. Loss is 1.9979254. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8515089798185522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23296/60000][Iteration 4403][Wall Clock 410.352616699s] Trained 128 records in 0.077168714 seconds. Throughput is 1658.7034 records/second. Loss is 1.9732492. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8511662347278786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23424/60000][Iteration 4404][Wall Clock 410.433411545s] Trained 128 records in 0.080794846 seconds. Throughput is 1584.2594 records/second. Loss is 1.9917. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8508236165093466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23552/60000][Iteration 4405][Wall Clock 410.517691842s] Trained 128 records in 0.084280297 seconds. Throughput is 1518.7417 records/second. Loss is 1.9861907. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8504811250925242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23680/60000][Iteration 4406][Wall Clock 410.60400829s] Trained 128 records in 0.086316448 seconds. Throughput is 1482.9154 records/second. Loss is 1.9738892. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8501387604070305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23808/60000][Iteration 4407][Wall Clock 410.691746569s] Trained 128 records in 0.087738279 seconds. Throughput is 1458.8844 records/second. Loss is 2.0182943. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.849796522382538E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 23936/60000][Iteration 4408][Wall Clock 410.779902849s] Trained 128 records in 0.08815628 seconds. Throughput is 1451.9668 records/second. Loss is 1.998516. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.84945441094877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 24064/60000][Iteration 4409][Wall Clock 410.865736348s] Trained 128 records in 0.085833499 seconds. Throughput is 1491.2593 records/second. Loss is 2.0122368. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.849112426035503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 24192/60000][Iteration 4410][Wall Clock 410.955760638s] Trained 128 records in 0.09002429 seconds. Throughput is 1421.8385 records/second. Loss is 1.9292806. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8487705675725643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 24320/60000][Iteration 4411][Wall Clock 411.042332121s] Trained 128 records in 0.086571483 seconds. Throughput is 1478.5469 records/second. Loss is 1.9505033. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8484288354898336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:06 INFO  DistriOptimizer$:408 - [Epoch 10 24448/60000][Iteration 4412][Wall Clock 411.125628569s] Trained 128 records in 0.083296448 seconds. Throughput is 1536.6802 records/second. Loss is 2.00962. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8480872297172425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 24576/60000][Iteration 4413][Wall Clock 411.212311908s] Trained 128 records in 0.086683339 seconds. Throughput is 1476.639 records/second. Loss is 1.9719464. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8477457501847746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 24704/60000][Iteration 4414][Wall Clock 411.297302549s] Trained 128 records in 0.084990641 seconds. Throughput is 1506.0481 records/second. Loss is 1.9652804. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8474043968224645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 24832/60000][Iteration 4415][Wall Clock 411.382211804s] Trained 128 records in 0.084909255 seconds. Throughput is 1507.4918 records/second. Loss is 1.9660515. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8470631695603992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 24960/60000][Iteration 4416][Wall Clock 411.467025942s] Trained 128 records in 0.084814138 seconds. Throughput is 1509.1824 records/second. Loss is 1.9995085. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8467220683287167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25088/60000][Iteration 4417][Wall Clock 411.550117726s] Trained 128 records in 0.083091784 seconds. Throughput is 1540.4652 records/second. Loss is 1.9707156. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.846381093057607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25216/60000][Iteration 4418][Wall Clock 411.633859469s] Trained 128 records in 0.083741743 seconds. Throughput is 1528.5089 records/second. Loss is 1.9674203. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8460402436773122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25344/60000][Iteration 4419][Wall Clock 411.718268951s] Trained 128 records in 0.084409482 seconds. Throughput is 1516.4174 records/second. Loss is 1.9673287. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8456995201181247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25472/60000][Iteration 4420][Wall Clock 411.802050989s] Trained 128 records in 0.083782038 seconds. Throughput is 1527.7737 records/second. Loss is 1.9897574. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8453589223103894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25600/60000][Iteration 4421][Wall Clock 411.885731465s] Trained 128 records in 0.083680476 seconds. Throughput is 1529.628 records/second. Loss is 1.9741644. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8450184501845018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25728/60000][Iteration 4422][Wall Clock 411.969736414s] Trained 128 records in 0.084004949 seconds. Throughput is 1523.7198 records/second. Loss is 1.9158976. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8446781036709093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:07 INFO  DistriOptimizer$:408 - [Epoch 10 25856/60000][Iteration 4423][Wall Clock 412.053645737s] Trained 128 records in 0.083909323 seconds. Throughput is 1525.4562 records/second. Loss is 1.9155874. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8443378827001107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 25984/60000][Iteration 4424][Wall Clock 412.136542018s] Trained 128 records in 0.082896281 seconds. Throughput is 1544.0983 records/second. Loss is 1.9763778. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8439977872026554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26112/60000][Iteration 4425][Wall Clock 412.219603139s] Trained 128 records in 0.083061121 seconds. Throughput is 1541.0338 records/second. Loss is 1.9921402. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8436578171091445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26240/60000][Iteration 4426][Wall Clock 412.302273681s] Trained 128 records in 0.082670542 seconds. Throughput is 1548.3146 records/second. Loss is 1.9783183. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8433179723502304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26368/60000][Iteration 4427][Wall Clock 412.385290254s] Trained 128 records in 0.083016573 seconds. Throughput is 1541.8607 records/second. Loss is 1.9324327. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8429782528566163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26496/60000][Iteration 4428][Wall Clock 412.477471356s] Trained 128 records in 0.092181102 seconds. Throughput is 1388.5709 records/second. Loss is 2.0473254. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8426386585590563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26624/60000][Iteration 4429][Wall Clock 412.555792867s] Trained 128 records in 0.078321511 seconds. Throughput is 1634.2893 records/second. Loss is 1.9482037. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8422991893883567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26752/60000][Iteration 4430][Wall Clock 412.632687311s] Trained 128 records in 0.076894444 seconds. Throughput is 1664.6195 records/second. Loss is 1.9794518. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.841959845275373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 26880/60000][Iteration 4431][Wall Clock 412.712838065s] Trained 128 records in 0.080150754 seconds. Throughput is 1596.9906 records/second. Loss is 1.9472657. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.841620626151013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 27008/60000][Iteration 4432][Wall Clock 412.797497798s] Trained 128 records in 0.084659733 seconds. Throughput is 1511.9348 records/second. Loss is 1.9312327. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8412815319462347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 27136/60000][Iteration 4433][Wall Clock 412.883467404s] Trained 128 records in 0.085969606 seconds. Throughput is 1488.8983 records/second. Loss is 1.9858267. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.840942562592047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 27264/60000][Iteration 4434][Wall Clock 412.970512939s] Trained 128 records in 0.087045535 seconds. Throughput is 1470.4948 records/second. Loss is 1.9422601. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8406037180195104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:08 INFO  DistriOptimizer$:408 - [Epoch 10 27392/60000][Iteration 4435][Wall Clock 413.054776277s] Trained 128 records in 0.084263338 seconds. Throughput is 1519.0474 records/second. Loss is 1.9826487. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.840264998159735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 27520/60000][Iteration 4436][Wall Clock 413.143863894s] Trained 128 records in 0.089087617 seconds. Throughput is 1436.7877 records/second. Loss is 1.9590914. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.839926402943882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 27648/60000][Iteration 4437][Wall Clock 413.223308358s] Trained 128 records in 0.079444464 seconds. Throughput is 1611.1885 records/second. Loss is 1.9195257. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.839587932303164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 27776/60000][Iteration 4438][Wall Clock 413.337131693s] Trained 128 records in 0.113823335 seconds. Throughput is 1124.5498 records/second. Loss is 1.9826194. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.839249586168843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 27904/60000][Iteration 4439][Wall Clock 413.422297967s] Trained 128 records in 0.085166274 seconds. Throughput is 1502.9424 records/second. Loss is 2.0146608. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8389113644722325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28032/60000][Iteration 4440][Wall Clock 413.507836225s] Trained 128 records in 0.085538258 seconds. Throughput is 1496.4064 records/second. Loss is 1.9515235. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8385732671446958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28160/60000][Iteration 4441][Wall Clock 413.592846738s] Trained 128 records in 0.085010513 seconds. Throughput is 1505.6962 records/second. Loss is 1.9374745. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.838235294117647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28288/60000][Iteration 4442][Wall Clock 413.67722853s] Trained 128 records in 0.084381792 seconds. Throughput is 1516.915 records/second. Loss is 2.020937. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8378974453225511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28416/60000][Iteration 4443][Wall Clock 413.761043106s] Trained 128 records in 0.083814576 seconds. Throughput is 1527.1807 records/second. Loss is 1.944117. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8375597206909223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28544/60000][Iteration 4444][Wall Clock 413.845486971s] Trained 128 records in 0.084443865 seconds. Throughput is 1515.7998 records/second. Loss is 1.9766253. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8372221201543265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28672/60000][Iteration 4445][Wall Clock 413.930280857s] Trained 128 records in 0.084793886 seconds. Throughput is 1509.5427 records/second. Loss is 1.9906521. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8368846436443793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28800/60000][Iteration 4446][Wall Clock 414.014269334s] Trained 128 records in 0.083988477 seconds. Throughput is 1524.0186 records/second. Loss is 2.0109649. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8365472910927456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:09 INFO  DistriOptimizer$:408 - [Epoch 10 28928/60000][Iteration 4447][Wall Clock 414.098877873s] Trained 128 records in 0.084608539 seconds. Throughput is 1512.8496 records/second. Loss is 2.0155005. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8362100624311423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29056/60000][Iteration 4448][Wall Clock 414.180574483s] Trained 128 records in 0.08169661 seconds. Throughput is 1566.7726 records/second. Loss is 1.9518739. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8358729575913347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29184/60000][Iteration 4449][Wall Clock 414.263532826s] Trained 128 records in 0.082958343 seconds. Throughput is 1542.9431 records/second. Loss is 1.9707932. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8355359765051394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29312/60000][Iteration 4450][Wall Clock 414.34695279s] Trained 128 records in 0.083419964 seconds. Throughput is 1534.4049 records/second. Loss is 1.969254. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.835199119104423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29440/60000][Iteration 4451][Wall Clock 414.430088233s] Trained 128 records in 0.083135443 seconds. Throughput is 1539.6562 records/second. Loss is 1.9446274. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.834862385321101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29568/60000][Iteration 4452][Wall Clock 414.513347394s] Trained 128 records in 0.083259161 seconds. Throughput is 1537.3684 records/second. Loss is 1.9748164. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.83452577508714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29696/60000][Iteration 4453][Wall Clock 414.608980179s] Trained 128 records in 0.095632785 seconds. Throughput is 1338.4531 records/second. Loss is 1.913497. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8341892883345562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29824/60000][Iteration 4454][Wall Clock 414.687967009s] Trained 128 records in 0.07898683 seconds. Throughput is 1620.5233 records/second. Loss is 1.9627993. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8338529249954154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 29952/60000][Iteration 4455][Wall Clock 414.770378832s] Trained 128 records in 0.082411823 seconds. Throughput is 1553.1752 records/second. Loss is 1.9103414. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8335166850018335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 30080/60000][Iteration 4456][Wall Clock 414.851121219s] Trained 128 records in 0.080742387 seconds. Throughput is 1585.2887 records/second. Loss is 1.9317247. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8331805682859762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 30208/60000][Iteration 4457][Wall Clock 414.934520229s] Trained 128 records in 0.08339901 seconds. Throughput is 1534.7904 records/second. Loss is 1.952762. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8328445747800586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 30336/60000][Iteration 4458][Wall Clock 415.019723392s] Trained 128 records in 0.085203163 seconds. Throughput is 1502.2916 records/second. Loss is 1.9914559. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.832508704416346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:10 INFO  DistriOptimizer$:408 - [Epoch 10 30464/60000][Iteration 4459][Wall Clock 415.105161649s] Trained 128 records in 0.085438257 seconds. Throughput is 1498.1578 records/second. Loss is 1.9499067. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8321729571271528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 30592/60000][Iteration 4460][Wall Clock 415.190339144s] Trained 128 records in 0.085177495 seconds. Throughput is 1502.7444 records/second. Loss is 1.9549398. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8318373328448433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 30720/60000][Iteration 4461][Wall Clock 415.276216119s] Trained 128 records in 0.085876975 seconds. Throughput is 1490.5044 records/second. Loss is 1.9640697. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8315018315018315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 30848/60000][Iteration 4462][Wall Clock 415.356665427s] Trained 128 records in 0.080449308 seconds. Throughput is 1591.0641 records/second. Loss is 1.9384935. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8311664530305805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 30976/60000][Iteration 4463][Wall Clock 415.437193022s] Trained 128 records in 0.080527595 seconds. Throughput is 1589.5172 records/second. Loss is 1.9410379. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8308311973636032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31104/60000][Iteration 4464][Wall Clock 415.5258013s] Trained 128 records in 0.088608278 seconds. Throughput is 1444.5603 records/second. Loss is 1.9528325. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8304960644334616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31232/60000][Iteration 4465][Wall Clock 415.609682898s] Trained 128 records in 0.083881598 seconds. Throughput is 1525.9603 records/second. Loss is 1.9498937. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.830161054172767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31360/60000][Iteration 4466][Wall Clock 415.692713988s] Trained 128 records in 0.08303109 seconds. Throughput is 1541.5913 records/second. Loss is 1.9457976. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8298261665141812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31488/60000][Iteration 4467][Wall Clock 415.77546515s] Trained 128 records in 0.082751162 seconds. Throughput is 1546.806 records/second. Loss is 1.9249544. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8294914013904133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31616/60000][Iteration 4468][Wall Clock 415.85882956s] Trained 128 records in 0.08336441 seconds. Throughput is 1535.4274 records/second. Loss is 1.9399507. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8291567587342233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31744/60000][Iteration 4469][Wall Clock 415.94486184s] Trained 128 records in 0.08603228 seconds. Throughput is 1487.8137 records/second. Loss is 1.9797598. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.82882223847842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:11 INFO  DistriOptimizer$:408 - [Epoch 10 31872/60000][Iteration 4470][Wall Clock 416.035446396s] Trained 128 records in 0.090584556 seconds. Throughput is 1413.0444 records/second. Loss is 1.9293483. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8284878405558602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32000/60000][Iteration 4471][Wall Clock 416.118545411s] Trained 128 records in 0.083099015 seconds. Throughput is 1540.3312 records/second. Loss is 1.977137. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8281535648994517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32128/60000][Iteration 4472][Wall Clock 416.202224343s] Trained 128 records in 0.083678932 seconds. Throughput is 1529.6562 records/second. Loss is 1.9949522. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8278194114421494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32256/60000][Iteration 4473][Wall Clock 416.289482228s] Trained 128 records in 0.087257885 seconds. Throughput is 1466.9161 records/second. Loss is 1.9910101. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.827485380116959E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32384/60000][Iteration 4474][Wall Clock 416.374688341s] Trained 128 records in 0.085206113 seconds. Throughput is 1502.2396 records/second. Loss is 1.9596385. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.827151470856934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32512/60000][Iteration 4475][Wall Clock 416.45970243s] Trained 128 records in 0.085014089 seconds. Throughput is 1505.6328 records/second. Loss is 1.987755. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8268176835951772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32640/60000][Iteration 4476][Wall Clock 416.545951775s] Trained 128 records in 0.086249345 seconds. Throughput is 1484.0692 records/second. Loss is 1.9629896. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.82648401826484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32768/60000][Iteration 4477][Wall Clock 416.63050098s] Trained 128 records in 0.084549205 seconds. Throughput is 1513.9114 records/second. Loss is 1.9184991. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8261504747991235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 32896/60000][Iteration 4478][Wall Clock 416.717733398s] Trained 128 records in 0.087232418 seconds. Throughput is 1467.3444 records/second. Loss is 1.9644338. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.825817053131276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 33024/60000][Iteration 4479][Wall Clock 416.80493724s] Trained 128 records in 0.087203842 seconds. Throughput is 1467.8252 records/second. Loss is 1.9612161. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8254837531945966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 33152/60000][Iteration 4480][Wall Clock 416.884570059s] Trained 128 records in 0.079632819 seconds. Throughput is 1607.3774 records/second. Loss is 1.9833215. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.825150574922431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 33280/60000][Iteration 4481][Wall Clock 416.962561025s] Trained 128 records in 0.077990966 seconds. Throughput is 1641.2158 records/second. Loss is 1.9528223. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.824817518248175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:12 INFO  DistriOptimizer$:408 - [Epoch 10 33408/60000][Iteration 4482][Wall Clock 417.051668634s] Trained 128 records in 0.089107609 seconds. Throughput is 1436.4655 records/second. Loss is 1.9402814. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.824484583105273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 33536/60000][Iteration 4483][Wall Clock 417.13691671s] Trained 128 records in 0.085248076 seconds. Throughput is 1501.5001 records/second. Loss is 1.9517479. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8241517694272163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 33664/60000][Iteration 4484][Wall Clock 417.222732773s] Trained 128 records in 0.085816063 seconds. Throughput is 1491.5623 records/second. Loss is 1.984251. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8238190771475472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 33792/60000][Iteration 4485][Wall Clock 417.308483592s] Trained 128 records in 0.085750819 seconds. Throughput is 1492.6971 records/second. Loss is 1.9609971. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8234865061998541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 33920/60000][Iteration 4486][Wall Clock 417.391782572s] Trained 128 records in 0.08329898 seconds. Throughput is 1536.6334 records/second. Loss is 1.9619436. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8231540565177758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34048/60000][Iteration 4487][Wall Clock 417.482515097s] Trained 128 records in 0.090732525 seconds. Throughput is 1410.74 records/second. Loss is 1.9324303. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8228217280349984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34176/60000][Iteration 4488][Wall Clock 417.566381486s] Trained 128 records in 0.083866389 seconds. Throughput is 1526.2372 records/second. Loss is 2.03133. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8224895206852561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34304/60000][Iteration 4489][Wall Clock 417.646988193s] Trained 128 records in 0.080606707 seconds. Throughput is 1587.9572 records/second. Loss is 1.9676384. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8221574344023323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34432/60000][Iteration 4490][Wall Clock 417.729605572s] Trained 128 records in 0.082617379 seconds. Throughput is 1549.3108 records/second. Loss is 1.9287648. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8218254691200583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34560/60000][Iteration 4491][Wall Clock 417.81280484s] Trained 128 records in 0.083199268 seconds. Throughput is 1538.475 records/second. Loss is 2.0011532. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8214936247723133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34688/60000][Iteration 4492][Wall Clock 417.901549607s] Trained 128 records in 0.088744767 seconds. Throughput is 1442.3386 records/second. Loss is 1.9831522. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.821161901293025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34816/60000][Iteration 4493][Wall Clock 417.983378128s] Trained 128 records in 0.081828521 seconds. Throughput is 1564.2468 records/second. Loss is 1.976653. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.820830298616169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:13 INFO  DistriOptimizer$:408 - [Epoch 10 34944/60000][Iteration 4494][Wall Clock 418.067057376s] Trained 128 records in 0.083679248 seconds. Throughput is 1529.6504 records/second. Loss is 2.0121863. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.820498816675769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35072/60000][Iteration 4495][Wall Clock 418.149231869s] Trained 128 records in 0.082174493 seconds. Throughput is 1557.6609 records/second. Loss is 1.9554044. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8201674554058975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35200/60000][Iteration 4496][Wall Clock 418.232819298s] Trained 128 records in 0.083587429 seconds. Throughput is 1531.3307 records/second. Loss is 1.9389591. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8198362147406734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35328/60000][Iteration 4497][Wall Clock 418.316783686s] Trained 128 records in 0.083964388 seconds. Throughput is 1524.4559 records/second. Loss is 1.9863111. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8195050946142647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35456/60000][Iteration 4498][Wall Clock 418.400317706s] Trained 128 records in 0.08353402 seconds. Throughput is 1532.3099 records/second. Loss is 1.969243. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8191740949608878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35584/60000][Iteration 4499][Wall Clock 418.485230815s] Trained 128 records in 0.084913109 seconds. Throughput is 1507.4232 records/second. Loss is 1.9451483. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8188432157148054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35712/60000][Iteration 4500][Wall Clock 418.569795662s] Trained 128 records in 0.084564847 seconds. Throughput is 1513.6312 records/second. Loss is 1.9257318. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8185124568103294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35840/60000][Iteration 4501][Wall Clock 418.653070874s] Trained 128 records in 0.083275212 seconds. Throughput is 1537.072 records/second. Loss is 1.9692832. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8181818181818183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 35968/60000][Iteration 4502][Wall Clock 418.736725725s] Trained 128 records in 0.083654851 seconds. Throughput is 1530.0966 records/second. Loss is 1.9728713. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8178512997636792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 36096/60000][Iteration 4503][Wall Clock 418.821161788s] Trained 128 records in 0.084436063 seconds. Throughput is 1515.9398 records/second. Loss is 1.9329838. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8175209014903673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 36224/60000][Iteration 4504][Wall Clock 418.904551048s] Trained 128 records in 0.08338926 seconds. Throughput is 1534.9698 records/second. Loss is 1.9862965. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8171906232963838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 36352/60000][Iteration 4505][Wall Clock 418.997426989s] Trained 128 records in 0.092875941 seconds. Throughput is 1378.1825 records/second. Loss is 1.986481. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.816860465116279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:14 INFO  DistriOptimizer$:408 - [Epoch 10 36480/60000][Iteration 4506][Wall Clock 419.070727758s] Trained 128 records in 0.073300769 seconds. Throughput is 1746.2299 records/second. Loss is 1.9780061. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8165304268846503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 36608/60000][Iteration 4507][Wall Clock 419.150046958s] Trained 128 records in 0.0793192 seconds. Throughput is 1613.7328 records/second. Loss is 1.9842008. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8162005085361425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 36736/60000][Iteration 4508][Wall Clock 419.233236419s] Trained 128 records in 0.083189461 seconds. Throughput is 1538.6565 records/second. Loss is 1.9724026. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8158707100054478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 36864/60000][Iteration 4509][Wall Clock 419.316324418s] Trained 128 records in 0.083087999 seconds. Throughput is 1540.5354 records/second. Loss is 1.9289954. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8155410312273057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 36992/60000][Iteration 4510][Wall Clock 419.399642131s] Trained 128 records in 0.083317713 seconds. Throughput is 1536.288 records/second. Loss is 1.952861. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.815211472136504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37120/60000][Iteration 4511][Wall Clock 419.484969966s] Trained 128 records in 0.085327835 seconds. Throughput is 1500.0967 records/second. Loss is 2.002634. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8148820326678767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37248/60000][Iteration 4512][Wall Clock 419.569875272s] Trained 128 records in 0.084905306 seconds. Throughput is 1507.5619 records/second. Loss is 1.897096. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8145527127563056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37376/60000][Iteration 4513][Wall Clock 419.657008265s] Trained 128 records in 0.087132993 seconds. Throughput is 1469.0188 records/second. Loss is 1.9444718. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.81422351233672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37504/60000][Iteration 4514][Wall Clock 419.748077676s] Trained 128 records in 0.091069411 seconds. Throughput is 1405.5214 records/second. Loss is 1.9613981. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8138944313440957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37632/60000][Iteration 4515][Wall Clock 419.832216086s] Trained 128 records in 0.08413841 seconds. Throughput is 1521.3029 records/second. Loss is 1.9948442. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8135654697134566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37760/60000][Iteration 4516][Wall Clock 419.914521573s] Trained 128 records in 0.082305487 seconds. Throughput is 1555.1819 records/second. Loss is 1.9720309. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8132366273798732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 37888/60000][Iteration 4517][Wall Clock 419.99757708s] Trained 128 records in 0.083055507 seconds. Throughput is 1541.1381 records/second. Loss is 1.9580005. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8129079042784627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:15 INFO  DistriOptimizer$:408 - [Epoch 10 38016/60000][Iteration 4518][Wall Clock 420.078323425s] Trained 128 records in 0.080746345 seconds. Throughput is 1585.211 records/second. Loss is 1.9409654. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.81257930034439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38144/60000][Iteration 4519][Wall Clock 420.16040883s] Trained 128 records in 0.082085405 seconds. Throughput is 1559.3514 records/second. Loss is 1.9522445. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8122508155128672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38272/60000][Iteration 4520][Wall Clock 420.247891064s] Trained 128 records in 0.087482234 seconds. Throughput is 1463.1542 records/second. Loss is 1.9611396. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.811922449719152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38400/60000][Iteration 4521][Wall Clock 420.330849652s] Trained 128 records in 0.082958588 seconds. Throughput is 1542.9385 records/second. Loss is 1.9534041. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8115942028985505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38528/60000][Iteration 4522][Wall Clock 420.414633397s] Trained 128 records in 0.083783745 seconds. Throughput is 1527.7427 records/second. Loss is 1.9845009. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8112660749864155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38656/60000][Iteration 4523][Wall Clock 420.495321433s] Trained 128 records in 0.080688036 seconds. Throughput is 1586.3566 records/second. Loss is 1.9849201. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8109380659181456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38784/60000][Iteration 4524][Wall Clock 420.578237638s] Trained 128 records in 0.082916205 seconds. Throughput is 1543.7272 records/second. Loss is 1.9555587. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8106101756291872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 38912/60000][Iteration 4525][Wall Clock 420.660032231s] Trained 128 records in 0.081794593 seconds. Throughput is 1564.8956 records/second. Loss is 2.0262353. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8102824040550327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 39040/60000][Iteration 4526][Wall Clock 420.744538998s] Trained 128 records in 0.084506767 seconds. Throughput is 1514.6716 records/second. Loss is 1.9712433. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8099547511312217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 39168/60000][Iteration 4527][Wall Clock 420.829031647s] Trained 128 records in 0.084492649 seconds. Throughput is 1514.9247 records/second. Loss is 1.985735. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8096272167933406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 39296/60000][Iteration 4528][Wall Clock 420.913842589s] Trained 128 records in 0.084810942 seconds. Throughput is 1509.2393 records/second. Loss is 1.9304953. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.809299800977022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:16 INFO  DistriOptimizer$:408 - [Epoch 10 39424/60000][Iteration 4529][Wall Clock 420.997388202s] Trained 128 records in 0.083545613 seconds. Throughput is 1532.0973 records/second. Loss is 1.952563. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.808972503617945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 39552/60000][Iteration 4530][Wall Clock 421.088377235s] Trained 128 records in 0.090989033 seconds. Throughput is 1406.763 records/second. Loss is 1.9776511. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8086453246518358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 39680/60000][Iteration 4531][Wall Clock 421.170785764s] Trained 128 records in 0.082408529 seconds. Throughput is 1553.2372 records/second. Loss is 1.954887. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8083182640144665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 39808/60000][Iteration 4532][Wall Clock 421.245748142s] Trained 128 records in 0.074962378 seconds. Throughput is 1707.5232 records/second. Loss is 1.9526135. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.807991321641656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 39936/60000][Iteration 4533][Wall Clock 421.323616889s] Trained 128 records in 0.077868747 seconds. Throughput is 1643.7917 records/second. Loss is 2.0238674. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8076644974692697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40064/60000][Iteration 4534][Wall Clock 421.406369649s] Trained 128 records in 0.08275276 seconds. Throughput is 1546.7762 records/second. Loss is 1.9388342. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.807337791433219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40192/60000][Iteration 4535][Wall Clock 421.490272402s] Trained 128 records in 0.083902753 seconds. Throughput is 1525.5757 records/second. Loss is 1.9360648. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8070112034694616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40320/60000][Iteration 4536][Wall Clock 421.573873176s] Trained 128 records in 0.083600774 seconds. Throughput is 1531.0863 records/second. Loss is 1.9709206. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.806684733514002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40448/60000][Iteration 4537][Wall Clock 421.656662942s] Trained 128 records in 0.082789766 seconds. Throughput is 1546.0848 records/second. Loss is 1.9962251. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.80635838150289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40576/60000][Iteration 4538][Wall Clock 421.751354366s] Trained 128 records in 0.094691424 seconds. Throughput is 1351.7592 records/second. Loss is 1.9554223. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8060321473722233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40704/60000][Iteration 4539][Wall Clock 421.835045547s] Trained 128 records in 0.083691181 seconds. Throughput is 1529.4324 records/second. Loss is 1.9782691. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8057060310581438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40832/60000][Iteration 4540][Wall Clock 421.916393375s] Trained 128 records in 0.081347828 seconds. Throughput is 1573.49 records/second. Loss is 1.9638869. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8053800324968408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:17 INFO  DistriOptimizer$:408 - [Epoch 10 40960/60000][Iteration 4541][Wall Clock 421.999247293s] Trained 128 records in 0.082853918 seconds. Throughput is 1544.8877 records/second. Loss is 1.9796948. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8050541516245486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41088/60000][Iteration 4542][Wall Clock 422.081735233s] Trained 128 records in 0.08248794 seconds. Throughput is 1551.742 records/second. Loss is 1.961562. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8047283883775492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41216/60000][Iteration 4543][Wall Clock 422.163532707s] Trained 128 records in 0.081797474 seconds. Throughput is 1564.8406 records/second. Loss is 1.968172. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.804402742692169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41344/60000][Iteration 4544][Wall Clock 422.249564007s] Trained 128 records in 0.0860313 seconds. Throughput is 1487.8306 records/second. Loss is 1.9414985. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8040772145047808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41472/60000][Iteration 4545][Wall Clock 422.335751701s] Trained 128 records in 0.086187694 seconds. Throughput is 1485.1309 records/second. Loss is 1.9500145. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8037518037518038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41600/60000][Iteration 4546][Wall Clock 422.422097744s] Trained 128 records in 0.086346043 seconds. Throughput is 1482.4072 records/second. Loss is 2.004794. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8034265103697024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41728/60000][Iteration 4547][Wall Clock 422.506102384s] Trained 128 records in 0.08400464 seconds. Throughput is 1523.7253 records/second. Loss is 1.9944241. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8031013342949875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41856/60000][Iteration 4548][Wall Clock 422.591732536s] Trained 128 records in 0.085630152 seconds. Throughput is 1494.8007 records/second. Loss is 1.9979832. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.802776275464215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 41984/60000][Iteration 4549][Wall Clock 422.676682887s] Trained 128 records in 0.084950351 seconds. Throughput is 1506.7625 records/second. Loss is 1.9829974. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.802451333813987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 42112/60000][Iteration 4550][Wall Clock 422.761207608s] Trained 128 records in 0.084524721 seconds. Throughput is 1514.3499 records/second. Loss is 1.9881015. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8021265092809513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 42240/60000][Iteration 4551][Wall Clock 422.846562459s] Trained 128 records in 0.085354851 seconds. Throughput is 1499.6218 records/second. Loss is 1.9406381. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8018018018018018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 42368/60000][Iteration 4552][Wall Clock 422.931707757s] Trained 128 records in 0.085145298 seconds. Throughput is 1503.3126 records/second. Loss is 1.9708678. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.801477211313277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:18 INFO  DistriOptimizer$:408 - [Epoch 10 42496/60000][Iteration 4553][Wall Clock 423.01743458s] Trained 128 records in 0.085726823 seconds. Throughput is 1493.115 records/second. Loss is 2.020867. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8011527377521613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 42624/60000][Iteration 4554][Wall Clock 423.100534756s] Trained 128 records in 0.083100176 seconds. Throughput is 1540.3096 records/second. Loss is 1.9411147. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8008283810552856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 42752/60000][Iteration 4555][Wall Clock 423.182642245s] Trained 128 records in 0.082107489 seconds. Throughput is 1558.932 records/second. Loss is 1.9747365. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8005041411595245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 42880/60000][Iteration 4556][Wall Clock 423.275103337s] Trained 128 records in 0.092461092 seconds. Throughput is 1384.3661 records/second. Loss is 1.9763663. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.8001800180018004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43008/60000][Iteration 4557][Wall Clock 423.359293718s] Trained 128 records in 0.084190381 seconds. Throughput is 1520.3636 records/second. Loss is 1.9528654. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7998560115190784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43136/60000][Iteration 4558][Wall Clock 423.436024303s] Trained 128 records in 0.076730585 seconds. Throughput is 1668.1744 records/second. Loss is 1.9604961. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7995321216483713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43264/60000][Iteration 4559][Wall Clock 423.517306179s] Trained 128 records in 0.081281876 seconds. Throughput is 1574.7667 records/second. Loss is 1.9616739. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7992083483267364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43392/60000][Iteration 4560][Wall Clock 423.599423214s] Trained 128 records in 0.082117035 seconds. Throughput is 1558.7509 records/second. Loss is 1.9869167. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7988846914912754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43520/60000][Iteration 4561][Wall Clock 423.683166495s] Trained 128 records in 0.083743281 seconds. Throughput is 1528.4808 records/second. Loss is 1.948907. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7985611510791365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43648/60000][Iteration 4562][Wall Clock 423.766906321s] Trained 128 records in 0.083739826 seconds. Throughput is 1528.544 records/second. Loss is 1.9828192. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.798237727027513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43776/60000][Iteration 4563][Wall Clock 423.851331343s] Trained 128 records in 0.084425022 seconds. Throughput is 1516.1382 records/second. Loss is 1.9867159. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7979144192736425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 43904/60000][Iteration 4564][Wall Clock 423.94371889s] Trained 128 records in 0.092387547 seconds. Throughput is 1385.468 records/second. Loss is 1.9772685. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7975912277548087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:19 INFO  DistriOptimizer$:408 - [Epoch 10 44032/60000][Iteration 4565][Wall Clock 424.02904972s] Trained 128 records in 0.08533083 seconds. Throughput is 1500.0441 records/second. Loss is 1.9301137. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7972681524083394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44160/60000][Iteration 4566][Wall Clock 424.113331741s] Trained 128 records in 0.084282021 seconds. Throughput is 1518.7107 records/second. Loss is 1.9617217. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7969451931716083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44288/60000][Iteration 4567][Wall Clock 424.195207891s] Trained 128 records in 0.08187615 seconds. Throughput is 1563.3368 records/second. Loss is 1.9165453. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7966223499820338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44416/60000][Iteration 4568][Wall Clock 424.279662247s] Trained 128 records in 0.084454356 seconds. Throughput is 1515.6116 records/second. Loss is 1.9269786. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7962996227770793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44544/60000][Iteration 4569][Wall Clock 424.366093977s] Trained 128 records in 0.08643173 seconds. Throughput is 1480.9376 records/second. Loss is 1.9331238. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7959770114942528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44672/60000][Iteration 4570][Wall Clock 424.448760573s] Trained 128 records in 0.082666596 seconds. Throughput is 1548.3884 records/second. Loss is 1.9402113. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.795654516071108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44800/60000][Iteration 4571][Wall Clock 424.533302036s] Trained 128 records in 0.084541463 seconds. Throughput is 1514.0499 records/second. Loss is 1.9555119. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7953321364452422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 44928/60000][Iteration 4572][Wall Clock 424.616618027s] Trained 128 records in 0.083315991 seconds. Throughput is 1536.3197 records/second. Loss is 1.9591767. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.795009872554299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 45056/60000][Iteration 4573][Wall Clock 424.701898934s] Trained 128 records in 0.085280907 seconds. Throughput is 1500.9221 records/second. Loss is 1.9770917. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7946877243359656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 45184/60000][Iteration 4574][Wall Clock 424.785581823s] Trained 128 records in 0.083682889 seconds. Throughput is 1529.584 records/second. Loss is 2.0276117. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.794365691727974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 45312/60000][Iteration 4575][Wall Clock 424.869736529s] Trained 128 records in 0.084154706 seconds. Throughput is 1521.0083 records/second. Loss is 1.9326597. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.794043774668102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 45440/60000][Iteration 4576][Wall Clock 424.954196397s] Trained 128 records in 0.084459868 seconds. Throughput is 1515.5126 records/second. Loss is 1.951634. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7937219730941703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:20 INFO  DistriOptimizer$:408 - [Epoch 10 45568/60000][Iteration 4577][Wall Clock 425.036604753s] Trained 128 records in 0.082408356 seconds. Throughput is 1553.2406 records/second. Loss is 1.9768327. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7934002869440457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 45696/60000][Iteration 4578][Wall Clock 425.119488395s] Trained 128 records in 0.082883642 seconds. Throughput is 1544.3337 records/second. Loss is 1.9476408. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7930787161556393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 45824/60000][Iteration 4579][Wall Clock 425.201567434s] Trained 128 records in 0.082079039 seconds. Throughput is 1559.4724 records/second. Loss is 1.957675. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7927572606669056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 45952/60000][Iteration 4580][Wall Clock 425.285300092s] Trained 128 records in 0.083732658 seconds. Throughput is 1528.6748 records/second. Loss is 1.9769287. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7924359204158453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46080/60000][Iteration 4581][Wall Clock 425.37957078s] Trained 128 records in 0.094270688 seconds. Throughput is 1357.7921 records/second. Loss is 1.9787341. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7921146953405018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46208/60000][Iteration 4582][Wall Clock 425.465118518s] Trained 128 records in 0.085547738 seconds. Throughput is 1496.2406 records/second. Loss is 1.9481792. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7917935853789643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46336/60000][Iteration 4583][Wall Clock 425.546929381s] Trained 128 records in 0.081810863 seconds. Throughput is 1564.5845 records/second. Loss is 1.988237. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.791472590469366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46464/60000][Iteration 4584][Wall Clock 425.626144809s] Trained 128 records in 0.079215428 seconds. Throughput is 1615.8468 records/second. Loss is 1.9422836. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7911517105498835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46592/60000][Iteration 4585][Wall Clock 425.712391507s] Trained 128 records in 0.086246698 seconds. Throughput is 1484.1147 records/second. Loss is 1.9395449. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7908309455587392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46720/60000][Iteration 4586][Wall Clock 425.794983648s] Trained 128 records in 0.082592141 seconds. Throughput is 1549.7842 records/second. Loss is 1.9680429. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7905102954341988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46848/60000][Iteration 4587][Wall Clock 425.878204825s] Trained 128 records in 0.083221177 seconds. Throughput is 1538.0701 records/second. Loss is 2.002151. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.790189760114572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 46976/60000][Iteration 4588][Wall Clock 425.962212987s] Trained 128 records in 0.084008162 seconds. Throughput is 1523.6614 records/second. Loss is 1.9902686. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7898693395382138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:21 INFO  DistriOptimizer$:408 - [Epoch 10 47104/60000][Iteration 4589][Wall Clock 426.049599999s] Trained 128 records in 0.087387012 seconds. Throughput is 1464.7485 records/second. Loss is 1.9440777. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7895490336435218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 47232/60000][Iteration 4590][Wall Clock 426.12998856s] Trained 128 records in 0.080388561 seconds. Throughput is 1592.2664 records/second. Loss is 2.0071292. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.789228842368939E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 47360/60000][Iteration 4591][Wall Clock 426.212989342s] Trained 128 records in 0.083000782 seconds. Throughput is 1542.1542 records/second. Loss is 1.9796612. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7889087656529517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 47488/60000][Iteration 4592][Wall Clock 426.295967962s] Trained 128 records in 0.08297862 seconds. Throughput is 1542.566 records/second. Loss is 1.9114044. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7885888034340904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 47616/60000][Iteration 4593][Wall Clock 426.378238149s] Trained 128 records in 0.082270187 seconds. Throughput is 1555.8491 records/second. Loss is 2.0228987. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.78826895565093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 47744/60000][Iteration 4594][Wall Clock 426.461813884s] Trained 128 records in 0.083575735 seconds. Throughput is 1531.545 records/second. Loss is 1.9787054. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7879492222420883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 47872/60000][Iteration 4595][Wall Clock 426.54691769s] Trained 128 records in 0.085103806 seconds. Throughput is 1504.0457 records/second. Loss is 2.0209093. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.787629603146228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 48000/60000][Iteration 4596][Wall Clock 426.630817267s] Trained 128 records in 0.083899577 seconds. Throughput is 1525.6334 records/second. Loss is 1.939165. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7873100983020556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 48128/60000][Iteration 4597][Wall Clock 426.713585507s] Trained 128 records in 0.08276824 seconds. Throughput is 1546.4869 records/second. Loss is 1.936495. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7869907076483203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 48256/60000][Iteration 4598][Wall Clock 426.795843376s] Trained 128 records in 0.082257869 seconds. Throughput is 1556.0822 records/second. Loss is 1.9376633. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7866714311238162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 48384/60000][Iteration 4599][Wall Clock 426.879485409s] Trained 128 records in 0.083642033 seconds. Throughput is 1530.331 records/second. Loss is 1.9019032. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7863522686673814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:22 INFO  DistriOptimizer$:408 - [Epoch 10 48512/60000][Iteration 4600][Wall Clock 426.962852675s] Trained 128 records in 0.083367266 seconds. Throughput is 1535.3748 records/second. Loss is 1.9348118. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.786033220217896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 48640/60000][Iteration 4601][Wall Clock 427.04697966s] Trained 128 records in 0.084126985 seconds. Throughput is 1521.5094 records/second. Loss is 1.9315279. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7857142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 48768/60000][Iteration 4602][Wall Clock 427.131123907s] Trained 128 records in 0.084144247 seconds. Throughput is 1521.1973 records/second. Loss is 1.9784597. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7853954650955188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 48896/60000][Iteration 4603][Wall Clock 427.213322409s] Trained 128 records in 0.082198502 seconds. Throughput is 1557.206 records/second. Loss is 1.9484468. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7850767583006067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49024/60000][Iteration 4604][Wall Clock 427.297591707s] Trained 128 records in 0.084269298 seconds. Throughput is 1518.9398 records/second. Loss is 1.9793446. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7847581652686063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49152/60000][Iteration 4605][Wall Clock 427.38086344s] Trained 128 records in 0.083271733 seconds. Throughput is 1537.1362 records/second. Loss is 1.9686. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7844396859386153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49280/60000][Iteration 4606][Wall Clock 427.46398592s] Trained 128 records in 0.08312248 seconds. Throughput is 1539.8964 records/second. Loss is 1.9169178. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.784121320249777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49408/60000][Iteration 4607][Wall Clock 427.557649097s] Trained 128 records in 0.093663177 seconds. Throughput is 1366.5989 records/second. Loss is 1.9488332. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7838030681412772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49536/60000][Iteration 4608][Wall Clock 427.646333458s] Trained 128 records in 0.088684361 seconds. Throughput is 1443.321 records/second. Loss is 1.9032938. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7834849295523451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49664/60000][Iteration 4609][Wall Clock 427.721690018s] Trained 128 records in 0.07535656 seconds. Throughput is 1698.5914 records/second. Loss is 1.9032823. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7831669044222537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49792/60000][Iteration 4610][Wall Clock 427.800353134s] Trained 128 records in 0.078663116 seconds. Throughput is 1627.192 records/second. Loss is 1.9635237. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7828489926903192E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 49920/60000][Iteration 4611][Wall Clock 427.883178449s] Trained 128 records in 0.082825315 seconds. Throughput is 1545.4211 records/second. Loss is 1.976946. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7825311942959E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:23 INFO  DistriOptimizer$:408 - [Epoch 10 50048/60000][Iteration 4612][Wall Clock 427.964738932s] Trained 128 records in 0.081560483 seconds. Throughput is 1569.3875 records/second. Loss is 1.9503163. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7822135091783998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50176/60000][Iteration 4613][Wall Clock 428.049674184s] Trained 128 records in 0.084935252 seconds. Throughput is 1507.0303 records/second. Loss is 1.9510435. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.781895937277263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50304/60000][Iteration 4614][Wall Clock 428.133484242s] Trained 128 records in 0.083810058 seconds. Throughput is 1527.263 records/second. Loss is 1.9406114. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7815784785319794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50432/60000][Iteration 4615][Wall Clock 428.217839238s] Trained 128 records in 0.084354996 seconds. Throughput is 1517.3967 records/second. Loss is 1.9552722. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7812611328820805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50560/60000][Iteration 4616][Wall Clock 428.306686952s] Trained 128 records in 0.088847714 seconds. Throughput is 1440.6674 records/second. Loss is 1.9843016. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7809439002671417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50688/60000][Iteration 4617][Wall Clock 428.391440884s] Trained 128 records in 0.084753932 seconds. Throughput is 1510.2544 records/second. Loss is 1.978458. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7806267806267807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50816/60000][Iteration 4618][Wall Clock 428.477043439s] Trained 128 records in 0.085602555 seconds. Throughput is 1495.2825 records/second. Loss is 1.940925. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7803097739006588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 50944/60000][Iteration 4619][Wall Clock 428.560763246s] Trained 128 records in 0.083719807 seconds. Throughput is 1528.9094 records/second. Loss is 1.9139056. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7799928800284797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 51072/60000][Iteration 4620][Wall Clock 428.645771322s] Trained 128 records in 0.085008076 seconds. Throughput is 1505.7393 records/second. Loss is 1.9933407. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7796760989499913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 51200/60000][Iteration 4621][Wall Clock 428.729639256s] Trained 128 records in 0.083867934 seconds. Throughput is 1526.209 records/second. Loss is 1.9483492. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7793594306049823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 51328/60000][Iteration 4622][Wall Clock 428.814488498s] Trained 128 records in 0.084849242 seconds. Throughput is 1508.558 records/second. Loss is 1.9527748. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.779042874933286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 51456/60000][Iteration 4623][Wall Clock 428.899048807s] Trained 128 records in 0.084560309 seconds. Throughput is 1513.7125 records/second. Loss is 1.9245621. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7787264318747779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:24 INFO  DistriOptimizer$:408 - [Epoch 10 51584/60000][Iteration 4624][Wall Clock 428.982481611s] Trained 128 records in 0.083432804 seconds. Throughput is 1534.1688 records/second. Loss is 1.9149191. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7784101013693757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 51712/60000][Iteration 4625][Wall Clock 429.06662873s] Trained 128 records in 0.084147119 seconds. Throughput is 1521.1454 records/second. Loss is 1.9605129. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7780938833570413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 51840/60000][Iteration 4626][Wall Clock 429.149877418s] Trained 128 records in 0.083248688 seconds. Throughput is 1537.5618 records/second. Loss is 1.9553947. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7777777777777779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 51968/60000][Iteration 4627][Wall Clock 429.233100569s] Trained 128 records in 0.083223151 seconds. Throughput is 1538.0336 records/second. Loss is 1.9514761. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7774617845716317E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52096/60000][Iteration 4628][Wall Clock 429.316650334s] Trained 128 records in 0.083549765 seconds. Throughput is 1532.021 records/second. Loss is 1.9405683. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7771459036786921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52224/60000][Iteration 4629][Wall Clock 429.399680342s] Trained 128 records in 0.083030008 seconds. Throughput is 1541.6113 records/second. Loss is 1.9338005. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7768301350390902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52352/60000][Iteration 4630][Wall Clock 429.482541564s] Trained 128 records in 0.082861222 seconds. Throughput is 1544.7516 records/second. Loss is 2.0449016. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7765144785930004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52480/60000][Iteration 4631][Wall Clock 429.564715581s] Trained 128 records in 0.082174017 seconds. Throughput is 1557.6699 records/second. Loss is 2.001672. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7761989342806396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52608/60000][Iteration 4632][Wall Clock 429.661994079s] Trained 128 records in 0.097278498 seconds. Throughput is 1315.8098 records/second. Loss is 1.957464. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.775883502042266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52736/60000][Iteration 4633][Wall Clock 429.739568722s] Trained 128 records in 0.077574643 seconds. Throughput is 1650.0238 records/second. Loss is 1.9796631. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.775568181818182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52864/60000][Iteration 4634][Wall Clock 429.819461824s] Trained 128 records in 0.079893102 seconds. Throughput is 1602.1407 records/second. Loss is 1.9160415. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7752529735487308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 52992/60000][Iteration 4635][Wall Clock 429.900622134s] Trained 128 records in 0.08116031 seconds. Throughput is 1577.1256 records/second. Loss is 1.9373226. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.774937877174299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:25 INFO  DistriOptimizer$:408 - [Epoch 10 53120/60000][Iteration 4636][Wall Clock 429.979072924s] Trained 128 records in 0.07845079 seconds. Throughput is 1631.5961 records/second. Loss is 1.970986. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.774622892635315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 53248/60000][Iteration 4637][Wall Clock 430.061004039s] Trained 128 records in 0.081931115 seconds. Throughput is 1562.2881 records/second. Loss is 1.9800768. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.77430801987225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 53376/60000][Iteration 4638][Wall Clock 430.144322244s] Trained 128 records in 0.083318205 seconds. Throughput is 1536.2789 records/second. Loss is 1.9819026. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7739932588256165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 53504/60000][Iteration 4639][Wall Clock 430.226689455s] Trained 128 records in 0.082367211 seconds. Throughput is 1554.0165 records/second. Loss is 1.9819667. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7736786094359704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 53632/60000][Iteration 4640][Wall Clock 430.314037412s] Trained 128 records in 0.087347957 seconds. Throughput is 1465.4036 records/second. Loss is 1.9567689. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7733640716439085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 53760/60000][Iteration 4641][Wall Clock 430.391043967s] Trained 128 records in 0.077006555 seconds. Throughput is 1662.1962 records/second. Loss is 1.9096754. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.773049645390071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 53888/60000][Iteration 4642][Wall Clock 430.471292543s] Trained 128 records in 0.080248576 seconds. Throughput is 1595.0438 records/second. Loss is 1.9435952. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.772735330615139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 54016/60000][Iteration 4643][Wall Clock 430.553633258s] Trained 128 records in 0.082340715 seconds. Throughput is 1554.5165 records/second. Loss is 1.926702. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.772421127259837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 54144/60000][Iteration 4644][Wall Clock 430.638132997s] Trained 128 records in 0.084499739 seconds. Throughput is 1514.7976 records/second. Loss is 1.9297005. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7721070352649302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 54272/60000][Iteration 4645][Wall Clock 430.721866842s] Trained 128 records in 0.083733845 seconds. Throughput is 1528.6532 records/second. Loss is 2.019832. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7717930545712261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 54400/60000][Iteration 4646][Wall Clock 430.809755211s] Trained 128 records in 0.087888369 seconds. Throughput is 1456.393 records/second. Loss is 1.896867. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7714791851195747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 54528/60000][Iteration 4647][Wall Clock 430.894529755s] Trained 128 records in 0.084774544 seconds. Throughput is 1509.8872 records/second. Loss is 1.9440744. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7711654268508679E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:26 INFO  DistriOptimizer$:408 - [Epoch 10 54656/60000][Iteration 4648][Wall Clock 430.980212364s] Trained 128 records in 0.085682609 seconds. Throughput is 1493.8854 records/second. Loss is 1.9477875. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7708517797060386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 54784/60000][Iteration 4649][Wall Clock 431.065484092s] Trained 128 records in 0.085271728 seconds. Throughput is 1501.0836 records/second. Loss is 1.9308188. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7705382436260624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 54912/60000][Iteration 4650][Wall Clock 431.150359356s] Trained 128 records in 0.084875264 seconds. Throughput is 1508.0955 records/second. Loss is 1.9050367. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7702248185519562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55040/60000][Iteration 4651][Wall Clock 431.235229944s] Trained 128 records in 0.084870588 seconds. Throughput is 1508.1786 records/second. Loss is 1.9660499. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7699115044247788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55168/60000][Iteration 4652][Wall Clock 431.321014613s] Trained 128 records in 0.085784669 seconds. Throughput is 1492.1082 records/second. Loss is 1.9674826. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.769598301185631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55296/60000][Iteration 4653][Wall Clock 431.406984637s] Trained 128 records in 0.085970024 seconds. Throughput is 1488.8911 records/second. Loss is 1.952262. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7692852087756547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55424/60000][Iteration 4654][Wall Clock 431.494345862s] Trained 128 records in 0.087361225 seconds. Throughput is 1465.1809 records/second. Loss is 1.9928352. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.768972227136034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55552/60000][Iteration 4655][Wall Clock 431.582767516s] Trained 128 records in 0.088421654 seconds. Throughput is 1447.6091 records/second. Loss is 1.9298133. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7686593562079943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55680/60000][Iteration 4656][Wall Clock 431.667089594s] Trained 128 records in 0.084322078 seconds. Throughput is 1517.9891 records/second. Loss is 1.9753983. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7683465959328028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55808/60000][Iteration 4657][Wall Clock 431.759269265s] Trained 128 records in 0.092179671 seconds. Throughput is 1388.5925 records/second. Loss is 1.9515395. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.768033946251768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 55936/60000][Iteration 4658][Wall Clock 431.844369031s] Trained 128 records in 0.085099766 seconds. Throughput is 1504.117 records/second. Loss is 1.9727198. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7677214071062401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 56064/60000][Iteration 4659][Wall Clock 431.925272257s] Trained 128 records in 0.080903226 seconds. Throughput is 1582.1372 records/second. Loss is 1.8942574. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7674089784376103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:27 INFO  DistriOptimizer$:408 - [Epoch 10 56192/60000][Iteration 4660][Wall Clock 432.006986061s] Trained 128 records in 0.081713804 seconds. Throughput is 1566.4429 records/second. Loss is 1.9773473. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7670966601873123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 56320/60000][Iteration 4661][Wall Clock 432.123424919s] Trained 128 records in 0.116438858 seconds. Throughput is 1099.2894 records/second. Loss is 2.0021214. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7667844522968197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 56448/60000][Iteration 4662][Wall Clock 432.230734487s] Trained 128 records in 0.107309568 seconds. Throughput is 1192.8107 records/second. Loss is 1.9394641. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7664723547076487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 56576/60000][Iteration 4663][Wall Clock 432.347848144s] Trained 128 records in 0.117113657 seconds. Throughput is 1092.9553 records/second. Loss is 1.9438038. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7661603673613564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 56704/60000][Iteration 4664][Wall Clock 432.430478611s] Trained 128 records in 0.082630467 seconds. Throughput is 1549.0653 records/second. Loss is 1.9399376. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.765848490199541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 56832/60000][Iteration 4665][Wall Clock 432.516177323s] Trained 128 records in 0.085698712 seconds. Throughput is 1493.6047 records/second. Loss is 1.9663666. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.765536723163842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 56960/60000][Iteration 4666][Wall Clock 432.605196844s] Trained 128 records in 0.089019521 seconds. Throughput is 1437.8868 records/second. Loss is 1.9496255. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.76522506619594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 57088/60000][Iteration 4667][Wall Clock 432.684879999s] Trained 128 records in 0.079683155 seconds. Throughput is 1606.362 records/second. Loss is 1.9550396. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7649135192375574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 57216/60000][Iteration 4668][Wall Clock 432.768790054s] Trained 128 records in 0.083910055 seconds. Throughput is 1525.4429 records/second. Loss is 1.9494677. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.764602082230457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 57344/60000][Iteration 4669][Wall Clock 432.852921087s] Trained 128 records in 0.084131033 seconds. Throughput is 1521.4363 records/second. Loss is 1.9972248. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7642907551164433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:28 INFO  DistriOptimizer$:408 - [Epoch 10 57472/60000][Iteration 4670][Wall Clock 432.936149137s] Trained 128 records in 0.08322805 seconds. Throughput is 1537.943 records/second. Loss is 1.8965427. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7639795378373608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 57600/60000][Iteration 4671][Wall Clock 433.020316137s] Trained 128 records in 0.084167 seconds. Throughput is 1520.786 records/second. Loss is 1.9646851. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.763668430335097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 57728/60000][Iteration 4672][Wall Clock 433.104538607s] Trained 128 records in 0.08422247 seconds. Throughput is 1519.7844 records/second. Loss is 1.9193845. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7633574325515782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 57856/60000][Iteration 4673][Wall Clock 433.186693727s] Trained 128 records in 0.08215512 seconds. Throughput is 1558.0282 records/second. Loss is 1.990721. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7630465444287732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 57984/60000][Iteration 4674][Wall Clock 433.271279177s] Trained 128 records in 0.08458545 seconds. Throughput is 1513.2626 records/second. Loss is 1.9179075. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7627357659086903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58112/60000][Iteration 4675][Wall Clock 433.355151534s] Trained 128 records in 0.083872357 seconds. Throughput is 1526.1285 records/second. Loss is 1.9717562. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7624250969333803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58240/60000][Iteration 4676][Wall Clock 433.438794383s] Trained 128 records in 0.083642849 seconds. Throughput is 1530.3162 records/second. Loss is 1.9313667. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.762114537444934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58368/60000][Iteration 4677][Wall Clock 433.541355422s] Trained 128 records in 0.102561039 seconds. Throughput is 1248.0372 records/second. Loss is 1.9815016. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7618040873854828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58496/60000][Iteration 4678][Wall Clock 433.624098134s] Trained 128 records in 0.082742712 seconds. Throughput is 1546.964 records/second. Loss is 1.9519203. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.761493746697199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58624/60000][Iteration 4679][Wall Clock 433.706992049s] Trained 128 records in 0.082893915 seconds. Throughput is 1544.1423 records/second. Loss is 1.9406447. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7611835153222966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58752/60000][Iteration 4680][Wall Clock 433.789387637s] Trained 128 records in 0.082395588 seconds. Throughput is 1553.4812 records/second. Loss is 1.9271307. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7608733932030288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 58880/60000][Iteration 4681][Wall Clock 433.874067021s] Trained 128 records in 0.084679384 seconds. Throughput is 1511.5839 records/second. Loss is 1.9758189. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7605633802816902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:29 INFO  DistriOptimizer$:408 - [Epoch 10 59008/60000][Iteration 4682][Wall Clock 433.970356256s] Trained 128 records in 0.096289235 seconds. Throughput is 1329.3282 records/second. Loss is 1.9607918. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.760253476500616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59136/60000][Iteration 4683][Wall Clock 434.052328047s] Trained 128 records in 0.081971791 seconds. Throughput is 1561.5127 records/second. Loss is 1.9441249. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7599436818021823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59264/60000][Iteration 4684][Wall Clock 434.131296376s] Trained 128 records in 0.078968329 seconds. Throughput is 1620.903 records/second. Loss is 1.9686654. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7596339961288053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59392/60000][Iteration 4685][Wall Clock 434.210777869s] Trained 128 records in 0.079481493 seconds. Throughput is 1610.4379 records/second. Loss is 1.9459798. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7593244194229416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59520/60000][Iteration 4686][Wall Clock 434.295695225s] Trained 128 records in 0.084917356 seconds. Throughput is 1507.3479 records/second. Loss is 1.9200896. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7590149516270886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59648/60000][Iteration 4687][Wall Clock 434.379304634s] Trained 128 records in 0.083609409 seconds. Throughput is 1530.9282 records/second. Loss is 1.9518572. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7587055926837847E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59776/60000][Iteration 4688][Wall Clock 434.463315575s] Trained 128 records in 0.084010941 seconds. Throughput is 1523.6111 records/second. Loss is 1.9875511. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7583963425356076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 59904/60000][Iteration 4689][Wall Clock 434.550565585s] Trained 128 records in 0.08725001 seconds. Throughput is 1467.0486 records/second. Loss is 1.8992127. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7580872011251758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:408 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 434.637667057s] Trained 128 records in 0.087101472 seconds. Throughput is 1469.5503 records/second. Loss is 1.9718735. Sequentialdaab25a8's hyper parameters: Current learning rate is 1.7577781683951485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-14 23:18:30 INFO  DistriOptimizer$:452 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 434.637667057s] Epoch finished. Wall clock time is 435753.439696 ms
2019-10-14 23:18:30 INFO  DistriOptimizer$:111 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 434.637667057s] Validate model...
2019-10-14 23:18:31 INFO  DistriOptimizer$:178 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 434.637667057s] validate model throughput is 12483.232 records/second
2019-10-14 23:18:31 INFO  DistriOptimizer$:181 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 434.637667057s] Top1Accuracy is Accuracy(correct: 5964, count: 10000, accuracy: 0.5964)
2019-10-14 23:18:31 INFO  DistriOptimizer$:221 - [Wall Clock 435.753439696s] Save model to /tmp/lenet5/20191014_231114
2019-10-14 23:18:31 INFO  DistriOptimizer$:226 - [Wall Clock 435.753439696s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@5dc881de to /tmp/lenet5/20191014_231114
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.596899986267, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.936800003052, total_num: 10000, method: Top5Accuracy
Evaluated result: 1.9449338913, total_num: 157, method: Loss
