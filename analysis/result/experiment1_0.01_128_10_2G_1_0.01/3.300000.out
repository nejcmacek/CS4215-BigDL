2019-10-15 08:17:51 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-15 08:17:52 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-15 08:17:52 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-15 08:17:52 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-15 08:17:52 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-15 08:17:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-15 08:17:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-15 08:17:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-15 08:17:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39691.
2019-10-15 08:17:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-15 08:17:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-15 08:17:53 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-15 08:17:53 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-15 08:17:53 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-1ba38133-9dda-48e1-8630-6846f8532fa4
2019-10-15 08:17:53 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-15 08:17:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-15 08:17:53 INFO  log:192 - Logging initialized @3227ms
2019-10-15 08:17:53 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-15 08:17:53 INFO  Server:414 - Started @3349ms
2019-10-15 08:17:53 INFO  AbstractConnector:278 - Started ServerConnector@5162b7c6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-15 08:17:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4468b3b7{/jobs,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39daa813{/jobs/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31f4ca9f{/jobs/job,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@773125d1{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1bc78114{/stages,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c7010c1{/stages/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d221d99{/stages/stage,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7851ae50{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45a2ba16{/stages/pool,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@bfd8141{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2588750c{/storage,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@505e7cc3{/storage/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c1ed4{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67ec7013{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1aa59f7{/environment,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22319565{/environment/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@42dbb549{/executors,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@463329e9{/executors/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1585a539{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b319051{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@245f0b83{/static,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1cf77206{/,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45f38e32{/api,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75305298{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3132b77e{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-15 08:17:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4040
2019-10-15 08:17:53 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:39691/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571127473839
2019-10-15 08:17:53 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:39691/files/lenet5.py with timestamp 1571127473892
2019-10-15 08:17:53 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-5ba7e4ef-1547-4c9d-9997-69600089e674/userFiles-2118db4e-3656-4742-beeb-952002ec1968/lenet5.py
2019-10-15 08:17:53 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:39691/files/bigdl-0.8.0-python-api.zip with timestamp 1571127473910
2019-10-15 08:17:53 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-5ba7e4ef-1547-4c9d-9997-69600089e674/userFiles-2118db4e-3656-4742-beeb-952002ec1968/bigdl-0.8.0-python-api.zip
2019-10-15 08:17:54 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-15 08:17:54 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 79 ms (0 ms spent in bootstraps)
2019-10-15 08:17:54 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191015081754-0124
2019-10-15 08:17:54 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191015081754-0124/0 on worker-20191014155229-10.164.0.3-45141 (10.164.0.3:45141) with 1 core(s)
2019-10-15 08:17:54 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191015081754-0124/0 on hostPort 10.164.0.3:45141 with 1 core(s), 2.0 GB RAM
2019-10-15 08:17:54 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45739.
2019-10-15 08:17:54 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:45739
2019-10-15 08:17:54 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-15 08:17:54 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191015081754-0124/0 is now RUNNING
2019-10-15 08:17:54 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 45739, None)
2019-10-15 08:17:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:45739 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 45739, None)
2019-10-15 08:17:54 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 45739, None)
2019-10-15 08:17:54 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 45739, None)
2019-10-15 08:17:54 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20cf00df{/metrics/json,null,AVAILABLE,@Spark}
2019-10-15 08:17:56 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.3:60374) with ID 0
2019-10-15 08:17:56 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-15 08:17:57 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.3:43919 with 1007.8 MB RAM, BlockManagerId(0, 10.164.0.3, 43919, None)
2019-10-15 08:17:57 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-15 08:17:57 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-15 08:17:57 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 18
2019-10-15 08:17:57 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.01
('Extracting', '/tmp/mnist/train-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-15 08:17:59 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-15 08:18:16 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-15 08:18:17 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-15 08:18:17 INFO  DistriOptimizer$:154 - Count dataset
2019-10-15 08:18:17 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.668078635s
2019-10-15 08:18:18 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-15 08:18:18 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-15 08:18:18 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.050642183s
2019-10-15 08:18:18 INFO  DistriOptimizer$:408 - [Epoch 1 128/60000][Iteration 1][Wall Clock 0.775715137s] Trained 128 records in 0.775715137 seconds. Throughput is 165.00903 records/second. Loss is 2.3092444. Sequential266afc8b's hyper parameters: Current learning rate is 0.01. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:19 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 2][Wall Clock 1.088254552s] Trained 128 records in 0.312539415 seconds. Throughput is 409.54834 records/second. Loss is 2.285551. Sequential266afc8b's hyper parameters: Current learning rate is 0.009900990099009901. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:19 INFO  DistriOptimizer$:408 - [Epoch 1 384/60000][Iteration 3][Wall Clock 1.339149332s] Trained 128 records in 0.25089478 seconds. Throughput is 510.174 records/second. Loss is 2.3051586. Sequential266afc8b's hyper parameters: Current learning rate is 0.00980392156862745. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:19 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 4][Wall Clock 1.589902394s] Trained 128 records in 0.250753062 seconds. Throughput is 510.46234 records/second. Loss is 2.2938938. Sequential266afc8b's hyper parameters: Current learning rate is 0.009708737864077669. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:19 INFO  DistriOptimizer$:408 - [Epoch 1 640/60000][Iteration 5][Wall Clock 1.822276732s] Trained 128 records in 0.232374338 seconds. Throughput is 550.8353 records/second. Loss is 2.3081198. Sequential266afc8b's hyper parameters: Current learning rate is 0.009615384615384616. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:20 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 6][Wall Clock 2.062629497s] Trained 128 records in 0.240352765 seconds. Throughput is 532.55054 records/second. Loss is 2.3063128. Sequential266afc8b's hyper parameters: Current learning rate is 0.009523809523809523. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:20 INFO  DistriOptimizer$:408 - [Epoch 1 896/60000][Iteration 7][Wall Clock 2.281761418s] Trained 128 records in 0.219131921 seconds. Throughput is 584.12305 records/second. Loss is 2.3003721. Sequential266afc8b's hyper parameters: Current learning rate is 0.009433962264150943. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:20 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 8][Wall Clock 2.477309408s] Trained 128 records in 0.19554799 seconds. Throughput is 654.5708 records/second. Loss is 2.3141267. Sequential266afc8b's hyper parameters: Current learning rate is 0.009345794392523364. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:20 INFO  DistriOptimizer$:408 - [Epoch 1 1152/60000][Iteration 9][Wall Clock 2.736465453s] Trained 128 records in 0.259156045 seconds. Throughput is 493.91092 records/second. Loss is 2.2952034. Sequential266afc8b's hyper parameters: Current learning rate is 0.009259259259259259. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:21 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 10][Wall Clock 2.9337109s] Trained 128 records in 0.197245447 seconds. Throughput is 648.9377 records/second. Loss is 2.3183658. Sequential266afc8b's hyper parameters: Current learning rate is 0.009174311926605503. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:21 INFO  DistriOptimizer$:408 - [Epoch 1 1408/60000][Iteration 11][Wall Clock 3.11387183s] Trained 128 records in 0.18016093 seconds. Throughput is 710.47595 records/second. Loss is 2.3107226. Sequential266afc8b's hyper parameters: Current learning rate is 0.00909090909090909. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:21 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 12][Wall Clock 3.280507967s] Trained 128 records in 0.166636137 seconds. Throughput is 768.1407 records/second. Loss is 2.2942579. Sequential266afc8b's hyper parameters: Current learning rate is 0.009009009009009009. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:21 INFO  DistriOptimizer$:408 - [Epoch 1 1664/60000][Iteration 13][Wall Clock 3.46557891s] Trained 128 records in 0.185070943 seconds. Throughput is 691.62665 records/second. Loss is 2.2921228. Sequential266afc8b's hyper parameters: Current learning rate is 0.008928571428571428. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:21 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 14][Wall Clock 3.626409322s] Trained 128 records in 0.160830412 seconds. Throughput is 795.8694 records/second. Loss is 2.306571. Sequential266afc8b's hyper parameters: Current learning rate is 0.008849557522123895. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:21 INFO  DistriOptimizer$:408 - [Epoch 1 1920/60000][Iteration 15][Wall Clock 3.823699817s] Trained 128 records in 0.197290495 seconds. Throughput is 648.7895 records/second. Loss is 2.2865229. Sequential266afc8b's hyper parameters: Current learning rate is 0.008771929824561403. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:22 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 16][Wall Clock 3.986176611s] Trained 128 records in 0.162476794 seconds. Throughput is 787.8048 records/second. Loss is 2.2957137. Sequential266afc8b's hyper parameters: Current learning rate is 0.008695652173913044. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:22 INFO  DistriOptimizer$:408 - [Epoch 1 2176/60000][Iteration 17][Wall Clock 4.139737027s] Trained 128 records in 0.153560416 seconds. Throughput is 833.54816 records/second. Loss is 2.2979858. Sequential266afc8b's hyper parameters: Current learning rate is 0.008620689655172415. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:22 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 18][Wall Clock 4.292204546s] Trained 128 records in 0.152467519 seconds. Throughput is 839.5231 records/second. Loss is 2.2823951. Sequential266afc8b's hyper parameters: Current learning rate is 0.008547008547008548. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:22 INFO  DistriOptimizer$:408 - [Epoch 1 2432/60000][Iteration 19][Wall Clock 4.438158435s] Trained 128 records in 0.145953889 seconds. Throughput is 876.98926 records/second. Loss is 2.304967. Sequential266afc8b's hyper parameters: Current learning rate is 0.00847457627118644. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:22 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 20][Wall Clock 4.596609935s] Trained 128 records in 0.1584515 seconds. Throughput is 807.8182 records/second. Loss is 2.299305. Sequential266afc8b's hyper parameters: Current learning rate is 0.008403361344537816. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:22 INFO  DistriOptimizer$:408 - [Epoch 1 2688/60000][Iteration 21][Wall Clock 4.807059301s] Trained 128 records in 0.210449366 seconds. Throughput is 608.2223 records/second. Loss is 2.2948065. Sequential266afc8b's hyper parameters: Current learning rate is 0.008333333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:23 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 22][Wall Clock 4.983411357s] Trained 128 records in 0.176352056 seconds. Throughput is 725.82086 records/second. Loss is 2.275761. Sequential266afc8b's hyper parameters: Current learning rate is 0.008264462809917356. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:23 INFO  DistriOptimizer$:408 - [Epoch 1 2944/60000][Iteration 23][Wall Clock 5.336824976s] Trained 128 records in 0.353413619 seconds. Throughput is 362.18185 records/second. Loss is 2.2710643. Sequential266afc8b's hyper parameters: Current learning rate is 0.00819672131147541. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:23 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 24][Wall Clock 5.489637075s] Trained 128 records in 0.152812099 seconds. Throughput is 837.63007 records/second. Loss is 2.2880683. Sequential266afc8b's hyper parameters: Current learning rate is 0.008130081300813009. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:23 INFO  DistriOptimizer$:408 - [Epoch 1 3200/60000][Iteration 25][Wall Clock 5.638734168s] Trained 128 records in 0.149097093 seconds. Throughput is 858.5009 records/second. Loss is 2.2863622. Sequential266afc8b's hyper parameters: Current learning rate is 0.008064516129032258. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:23 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 26][Wall Clock 5.788916801s] Trained 128 records in 0.150182633 seconds. Throughput is 852.2956 records/second. Loss is 2.2850113. Sequential266afc8b's hyper parameters: Current learning rate is 0.008. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:24 INFO  DistriOptimizer$:408 - [Epoch 1 3456/60000][Iteration 27][Wall Clock 6.158908346s] Trained 128 records in 0.369991545 seconds. Throughput is 345.95386 records/second. Loss is 2.2736256. Sequential266afc8b's hyper parameters: Current learning rate is 0.007936507936507936. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:24 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 28][Wall Clock 6.301540392s] Trained 128 records in 0.142632046 seconds. Throughput is 897.414 records/second. Loss is 2.3041654. Sequential266afc8b's hyper parameters: Current learning rate is 0.007874015748031496. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:24 INFO  DistriOptimizer$:408 - [Epoch 1 3712/60000][Iteration 29][Wall Clock 6.445366987s] Trained 128 records in 0.143826595 seconds. Throughput is 889.96063 records/second. Loss is 2.2927842. Sequential266afc8b's hyper parameters: Current learning rate is 0.0078125. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:24 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 30][Wall Clock 6.617654978s] Trained 128 records in 0.172287991 seconds. Throughput is 742.94214 records/second. Loss is 2.2755582. Sequential266afc8b's hyper parameters: Current learning rate is 0.007751937984496124. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:24 INFO  DistriOptimizer$:408 - [Epoch 1 3968/60000][Iteration 31][Wall Clock 6.77236153s] Trained 128 records in 0.154706552 seconds. Throughput is 827.37286 records/second. Loss is 2.2617378. Sequential266afc8b's hyper parameters: Current learning rate is 0.007692307692307692. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 32][Wall Clock 6.915399727s] Trained 128 records in 0.143038197 seconds. Throughput is 894.86584 records/second. Loss is 2.2733853. Sequential266afc8b's hyper parameters: Current learning rate is 0.007633587786259542. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4224/60000][Iteration 33][Wall Clock 7.06465538s] Trained 128 records in 0.149255653 seconds. Throughput is 857.589 records/second. Loss is 2.278443. Sequential266afc8b's hyper parameters: Current learning rate is 0.007575757575757576. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 34][Wall Clock 7.212896517s] Trained 128 records in 0.148241137 seconds. Throughput is 863.45807 records/second. Loss is 2.2835238. Sequential266afc8b's hyper parameters: Current learning rate is 0.007518796992481203. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4480/60000][Iteration 35][Wall Clock 7.355967212s] Trained 128 records in 0.143070695 seconds. Throughput is 894.6626 records/second. Loss is 2.263294. Sequential266afc8b's hyper parameters: Current learning rate is 0.007462686567164179. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 36][Wall Clock 7.506848929s] Trained 128 records in 0.150881717 seconds. Throughput is 848.3466 records/second. Loss is 2.2725203. Sequential266afc8b's hyper parameters: Current learning rate is 0.007407407407407407. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4736/60000][Iteration 37][Wall Clock 7.63460799s] Trained 128 records in 0.127759061 seconds. Throughput is 1001.8859 records/second. Loss is 2.2525544. Sequential266afc8b's hyper parameters: Current learning rate is 0.007352941176470589. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:25 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 38][Wall Clock 7.794245757s] Trained 128 records in 0.159637767 seconds. Throughput is 801.8153 records/second. Loss is 2.269045. Sequential266afc8b's hyper parameters: Current learning rate is 0.0072992700729927005. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 4992/60000][Iteration 39][Wall Clock 7.957349798s] Trained 128 records in 0.163104041 seconds. Throughput is 784.77515 records/second. Loss is 2.2807524. Sequential266afc8b's hyper parameters: Current learning rate is 0.007246376811594204. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 40][Wall Clock 8.083540715s] Trained 128 records in 0.126190917 seconds. Throughput is 1014.33606 records/second. Loss is 2.2664466. Sequential266afc8b's hyper parameters: Current learning rate is 0.007194244604316546. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 5248/60000][Iteration 41][Wall Clock 8.234564331s] Trained 128 records in 0.151023616 seconds. Throughput is 847.54956 records/second. Loss is 2.2621899. Sequential266afc8b's hyper parameters: Current learning rate is 0.0071428571428571435. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 42][Wall Clock 8.381723534s] Trained 128 records in 0.147159203 seconds. Throughput is 869.8063 records/second. Loss is 2.2510526. Sequential266afc8b's hyper parameters: Current learning rate is 0.0070921985815602835. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 5504/60000][Iteration 43][Wall Clock 8.526106402s] Trained 128 records in 0.144382868 seconds. Throughput is 886.5318 records/second. Loss is 2.2733476. Sequential266afc8b's hyper parameters: Current learning rate is 0.007042253521126761. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 44][Wall Clock 8.668188412s] Trained 128 records in 0.14208201 seconds. Throughput is 900.8882 records/second. Loss is 2.2762623. Sequential266afc8b's hyper parameters: Current learning rate is 0.006993006993006994. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:26 INFO  DistriOptimizer$:408 - [Epoch 1 5760/60000][Iteration 45][Wall Clock 8.839657711s] Trained 128 records in 0.171469299 seconds. Throughput is 746.4893 records/second. Loss is 2.2605162. Sequential266afc8b's hyper parameters: Current learning rate is 0.006944444444444445. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:27 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 46][Wall Clock 8.982985911s] Trained 128 records in 0.1433282 seconds. Throughput is 893.05524 records/second. Loss is 2.268188. Sequential266afc8b's hyper parameters: Current learning rate is 0.006896551724137932. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:27 INFO  DistriOptimizer$:408 - [Epoch 1 6016/60000][Iteration 47][Wall Clock 9.130634824s] Trained 128 records in 0.147648913 seconds. Throughput is 866.9214 records/second. Loss is 2.2494059. Sequential266afc8b's hyper parameters: Current learning rate is 0.006849315068493151. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:27 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 48][Wall Clock 9.276365267s] Trained 128 records in 0.145730443 seconds. Throughput is 878.33405 records/second. Loss is 2.2581732. Sequential266afc8b's hyper parameters: Current learning rate is 0.006802721088435375. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:27 INFO  DistriOptimizer$:408 - [Epoch 1 6272/60000][Iteration 49][Wall Clock 9.416710481s] Trained 128 records in 0.140345214 seconds. Throughput is 912.0368 records/second. Loss is 2.2639925. Sequential266afc8b's hyper parameters: Current learning rate is 0.006756756756756757. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:27 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 50][Wall Clock 9.553074715s] Trained 128 records in 0.136364234 seconds. Throughput is 938.66254 records/second. Loss is 2.2692378. Sequential266afc8b's hyper parameters: Current learning rate is 0.006711409395973154. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:27 INFO  DistriOptimizer$:408 - [Epoch 1 6528/60000][Iteration 51][Wall Clock 9.694595078s] Trained 128 records in 0.141520363 seconds. Throughput is 904.46344 records/second. Loss is 2.2568686. Sequential266afc8b's hyper parameters: Current learning rate is 0.006666666666666667. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 52][Wall Clock 9.865005349s] Trained 128 records in 0.170410271 seconds. Throughput is 751.1284 records/second. Loss is 2.2500343. Sequential266afc8b's hyper parameters: Current learning rate is 0.006622516556291391. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 6784/60000][Iteration 53][Wall Clock 10.018881336s] Trained 128 records in 0.153875987 seconds. Throughput is 831.8387 records/second. Loss is 2.26193. Sequential266afc8b's hyper parameters: Current learning rate is 0.006578947368421052. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 54][Wall Clock 10.142526262s] Trained 128 records in 0.123644926 seconds. Throughput is 1035.2224 records/second. Loss is 2.254597. Sequential266afc8b's hyper parameters: Current learning rate is 0.006535947712418301. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 7040/60000][Iteration 55][Wall Clock 10.266006401s] Trained 128 records in 0.123480139 seconds. Throughput is 1036.6039 records/second. Loss is 2.2485502. Sequential266afc8b's hyper parameters: Current learning rate is 0.006493506493506493. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 56][Wall Clock 10.403858348s] Trained 128 records in 0.137851947 seconds. Throughput is 928.53235 records/second. Loss is 2.2538705. Sequential266afc8b's hyper parameters: Current learning rate is 0.0064516129032258064. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 7296/60000][Iteration 57][Wall Clock 10.529247681s] Trained 128 records in 0.125389333 seconds. Throughput is 1020.82043 records/second. Loss is 2.2385404. Sequential266afc8b's hyper parameters: Current learning rate is 0.00641025641025641. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 58][Wall Clock 10.669847017s] Trained 128 records in 0.140599336 seconds. Throughput is 910.38837 records/second. Loss is 2.2507136. Sequential266afc8b's hyper parameters: Current learning rate is 0.006369426751592356. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:28 INFO  DistriOptimizer$:408 - [Epoch 1 7552/60000][Iteration 59][Wall Clock 10.810787424s] Trained 128 records in 0.140940407 seconds. Throughput is 908.18524 records/second. Loss is 2.26261. Sequential266afc8b's hyper parameters: Current learning rate is 0.006329113924050633. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 60][Wall Clock 10.959876602s] Trained 128 records in 0.149089178 seconds. Throughput is 858.5466 records/second. Loss is 2.2614105. Sequential266afc8b's hyper parameters: Current learning rate is 0.006289308176100629. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 7808/60000][Iteration 61][Wall Clock 11.074732798s] Trained 128 records in 0.114856196 seconds. Throughput is 1114.437 records/second. Loss is 2.2539349. Sequential266afc8b's hyper parameters: Current learning rate is 0.0062499999999999995. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 62][Wall Clock 11.197011637s] Trained 128 records in 0.122278839 seconds. Throughput is 1046.7878 records/second. Loss is 2.2445061. Sequential266afc8b's hyper parameters: Current learning rate is 0.006211180124223603. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 8064/60000][Iteration 63][Wall Clock 11.316397211s] Trained 128 records in 0.119385574 seconds. Throughput is 1072.1564 records/second. Loss is 2.2391489. Sequential266afc8b's hyper parameters: Current learning rate is 0.006172839506172839. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 64][Wall Clock 11.460912871s] Trained 128 records in 0.14451566 seconds. Throughput is 885.71716 records/second. Loss is 2.265299. Sequential266afc8b's hyper parameters: Current learning rate is 0.006134969325153374. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 8320/60000][Iteration 65][Wall Clock 11.577433839s] Trained 128 records in 0.116520968 seconds. Throughput is 1098.5146 records/second. Loss is 2.2457187. Sequential266afc8b's hyper parameters: Current learning rate is 0.0060975609756097554. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 66][Wall Clock 11.693001709s] Trained 128 records in 0.11556787 seconds. Throughput is 1107.5742 records/second. Loss is 2.2411282. Sequential266afc8b's hyper parameters: Current learning rate is 0.0060606060606060615. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:29 INFO  DistriOptimizer$:408 - [Epoch 1 8576/60000][Iteration 67][Wall Clock 11.806410812s] Trained 128 records in 0.113409103 seconds. Throughput is 1128.6572 records/second. Loss is 2.2460077. Sequential266afc8b's hyper parameters: Current learning rate is 0.006024096385542168. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 68][Wall Clock 11.918990959s] Trained 128 records in 0.112580147 seconds. Throughput is 1136.9678 records/second. Loss is 2.2415895. Sequential266afc8b's hyper parameters: Current learning rate is 0.005988023952095809. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 8832/60000][Iteration 69][Wall Clock 12.030913275s] Trained 128 records in 0.111922316 seconds. Throughput is 1143.6504 records/second. Loss is 2.2591572. Sequential266afc8b's hyper parameters: Current learning rate is 0.005952380952380952. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 70][Wall Clock 12.165369935s] Trained 128 records in 0.13445666 seconds. Throughput is 951.9796 records/second. Loss is 2.2381227. Sequential266afc8b's hyper parameters: Current learning rate is 0.00591715976331361. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 9088/60000][Iteration 71][Wall Clock 12.318161756s] Trained 128 records in 0.152791821 seconds. Throughput is 837.74115 records/second. Loss is 2.228218. Sequential266afc8b's hyper parameters: Current learning rate is 0.0058823529411764705. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 72][Wall Clock 12.432256475s] Trained 128 records in 0.114094719 seconds. Throughput is 1121.8749 records/second. Loss is 2.2424295. Sequential266afc8b's hyper parameters: Current learning rate is 0.0058479532163742695. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 9344/60000][Iteration 73][Wall Clock 12.54579403s] Trained 128 records in 0.113537555 seconds. Throughput is 1127.3802 records/second. Loss is 2.2205904. Sequential266afc8b's hyper parameters: Current learning rate is 0.005813953488372093. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 74][Wall Clock 12.683840221s] Trained 128 records in 0.138046191 seconds. Throughput is 927.2259 records/second. Loss is 2.2289078. Sequential266afc8b's hyper parameters: Current learning rate is 0.005780346820809249. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:30 INFO  DistriOptimizer$:408 - [Epoch 1 9600/60000][Iteration 75][Wall Clock 12.797053236s] Trained 128 records in 0.113213015 seconds. Throughput is 1130.612 records/second. Loss is 2.2388864. Sequential266afc8b's hyper parameters: Current learning rate is 0.005747126436781609. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 76][Wall Clock 12.912157739s] Trained 128 records in 0.115104503 seconds. Throughput is 1112.033 records/second. Loss is 2.2444627. Sequential266afc8b's hyper parameters: Current learning rate is 0.005714285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 9856/60000][Iteration 77][Wall Clock 13.022351498s] Trained 128 records in 0.110193759 seconds. Throughput is 1161.5903 records/second. Loss is 2.2424455. Sequential266afc8b's hyper parameters: Current learning rate is 0.005681818181818182. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 78][Wall Clock 13.18833986s] Trained 128 records in 0.165988362 seconds. Throughput is 771.1384 records/second. Loss is 2.23654. Sequential266afc8b's hyper parameters: Current learning rate is 0.005649717514124294. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 10112/60000][Iteration 79][Wall Clock 13.309065573s] Trained 128 records in 0.120725713 seconds. Throughput is 1060.2546 records/second. Loss is 2.2403238. Sequential266afc8b's hyper parameters: Current learning rate is 0.0056179775280898875. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 80][Wall Clock 13.427733026s] Trained 128 records in 0.118667453 seconds. Throughput is 1078.6445 records/second. Loss is 2.2371993. Sequential266afc8b's hyper parameters: Current learning rate is 0.00558659217877095. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 10368/60000][Iteration 81][Wall Clock 13.539140264s] Trained 128 records in 0.111407238 seconds. Throughput is 1148.938 records/second. Loss is 2.2147815. Sequential266afc8b's hyper parameters: Current learning rate is 0.005555555555555556. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 82][Wall Clock 13.652242431s] Trained 128 records in 0.113102167 seconds. Throughput is 1131.7201 records/second. Loss is 2.2391732. Sequential266afc8b's hyper parameters: Current learning rate is 0.0055248618784530384. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:31 INFO  DistriOptimizer$:408 - [Epoch 1 10624/60000][Iteration 83][Wall Clock 13.770126188s] Trained 128 records in 0.117883757 seconds. Throughput is 1085.8154 records/second. Loss is 2.2362936. Sequential266afc8b's hyper parameters: Current learning rate is 0.005494505494505494. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 84][Wall Clock 13.893471508s] Trained 128 records in 0.12334532 seconds. Throughput is 1037.7369 records/second. Loss is 2.2394435. Sequential266afc8b's hyper parameters: Current learning rate is 0.00546448087431694. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 10880/60000][Iteration 85][Wall Clock 14.047320871s] Trained 128 records in 0.153849363 seconds. Throughput is 831.98267 records/second. Loss is 2.2307832. Sequential266afc8b's hyper parameters: Current learning rate is 0.005434782608695653. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 86][Wall Clock 14.162310472s] Trained 128 records in 0.114989601 seconds. Throughput is 1113.1442 records/second. Loss is 2.2311194. Sequential266afc8b's hyper parameters: Current learning rate is 0.005405405405405405. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 11136/60000][Iteration 87][Wall Clock 14.278631811s] Trained 128 records in 0.116321339 seconds. Throughput is 1100.4 records/second. Loss is 2.2106164. Sequential266afc8b's hyper parameters: Current learning rate is 0.005376344086021506. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 88][Wall Clock 14.385229192s] Trained 128 records in 0.106597381 seconds. Throughput is 1200.78 records/second. Loss is 2.227483. Sequential266afc8b's hyper parameters: Current learning rate is 0.0053475935828877. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 11392/60000][Iteration 89][Wall Clock 14.500847013s] Trained 128 records in 0.115617821 seconds. Throughput is 1107.0958 records/second. Loss is 2.2221582. Sequential266afc8b's hyper parameters: Current learning rate is 0.0053191489361702135. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 90][Wall Clock 14.612227933s] Trained 128 records in 0.11138092 seconds. Throughput is 1149.2094 records/second. Loss is 2.2118378. Sequential266afc8b's hyper parameters: Current learning rate is 0.005291005291005291. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:32 INFO  DistriOptimizer$:408 - [Epoch 1 11648/60000][Iteration 91][Wall Clock 14.745558546s] Trained 128 records in 0.133330613 seconds. Throughput is 960.0196 records/second. Loss is 2.2167995. Sequential266afc8b's hyper parameters: Current learning rate is 0.005263157894736843. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 92][Wall Clock 14.856103602s] Trained 128 records in 0.110545056 seconds. Throughput is 1157.8989 records/second. Loss is 2.2343805. Sequential266afc8b's hyper parameters: Current learning rate is 0.005235602094240837. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 11904/60000][Iteration 93][Wall Clock 14.981646959s] Trained 128 records in 0.125543357 seconds. Throughput is 1019.5681 records/second. Loss is 2.2294273. Sequential266afc8b's hyper parameters: Current learning rate is 0.005208333333333334. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 94][Wall Clock 15.104409161s] Trained 128 records in 0.122762202 seconds. Throughput is 1042.6663 records/second. Loss is 2.230443. Sequential266afc8b's hyper parameters: Current learning rate is 0.005181347150259067. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12160/60000][Iteration 95][Wall Clock 15.210722364s] Trained 128 records in 0.106313203 seconds. Throughput is 1203.9896 records/second. Loss is 2.2225287. Sequential266afc8b's hyper parameters: Current learning rate is 0.005154639175257732. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 96][Wall Clock 15.318119459s] Trained 128 records in 0.107397095 seconds. Throughput is 1191.8386 records/second. Loss is 2.196458. Sequential266afc8b's hyper parameters: Current learning rate is 0.005128205128205128. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12416/60000][Iteration 97][Wall Clock 15.4360531s] Trained 128 records in 0.117933641 seconds. Throughput is 1085.3562 records/second. Loss is 2.2336369. Sequential266afc8b's hyper parameters: Current learning rate is 0.005102040816326531. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 98][Wall Clock 15.544168199s] Trained 128 records in 0.108115099 seconds. Throughput is 1183.9235 records/second. Loss is 2.2325144. Sequential266afc8b's hyper parameters: Current learning rate is 0.005076142131979696. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12672/60000][Iteration 99][Wall Clock 15.661797249s] Trained 128 records in 0.11762905 seconds. Throughput is 1088.1665 records/second. Loss is 2.22025. Sequential266afc8b's hyper parameters: Current learning rate is 0.005050505050505051. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:33 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 100][Wall Clock 15.764268209s] Trained 128 records in 0.10247096 seconds. Throughput is 1249.1344 records/second. Loss is 2.2330456. Sequential266afc8b's hyper parameters: Current learning rate is 0.005025125628140704. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 12928/60000][Iteration 101][Wall Clock 15.883869374s] Trained 128 records in 0.119601165 seconds. Throughput is 1070.2236 records/second. Loss is 2.2072709. Sequential266afc8b's hyper parameters: Current learning rate is 0.005. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 102][Wall Clock 15.999114249s] Trained 128 records in 0.115244875 seconds. Throughput is 1110.6785 records/second. Loss is 2.2003155. Sequential266afc8b's hyper parameters: Current learning rate is 0.0049751243781094535. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13184/60000][Iteration 103][Wall Clock 16.108486777s] Trained 128 records in 0.109372528 seconds. Throughput is 1170.3121 records/second. Loss is 2.2064197. Sequential266afc8b's hyper parameters: Current learning rate is 0.0049504950495049506. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 104][Wall Clock 16.223156708s] Trained 128 records in 0.114669931 seconds. Throughput is 1116.2473 records/second. Loss is 2.2320392. Sequential266afc8b's hyper parameters: Current learning rate is 0.004926108374384236. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13440/60000][Iteration 105][Wall Clock 16.334912431s] Trained 128 records in 0.111755723 seconds. Throughput is 1145.3552 records/second. Loss is 2.1986396. Sequential266afc8b's hyper parameters: Current learning rate is 0.004901960784313725. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 106][Wall Clock 16.436327644s] Trained 128 records in 0.101415213 seconds. Throughput is 1262.1381 records/second. Loss is 2.2231212. Sequential266afc8b's hyper parameters: Current learning rate is 0.004878048780487806. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13696/60000][Iteration 107][Wall Clock 16.543166775s] Trained 128 records in 0.106839131 seconds. Throughput is 1198.063 records/second. Loss is 2.2273262. Sequential266afc8b's hyper parameters: Current learning rate is 0.0048543689320388345. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 108][Wall Clock 16.671916699s] Trained 128 records in 0.128749924 seconds. Throughput is 994.17535 records/second. Loss is 2.2067554. Sequential266afc8b's hyper parameters: Current learning rate is 0.004830917874396135. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:34 INFO  DistriOptimizer$:408 - [Epoch 1 13952/60000][Iteration 109][Wall Clock 16.802147575s] Trained 128 records in 0.130230876 seconds. Throughput is 982.8699 records/second. Loss is 2.2372093. Sequential266afc8b's hyper parameters: Current learning rate is 0.004807692307692308. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 110][Wall Clock 16.940573559s] Trained 128 records in 0.138425984 seconds. Throughput is 924.6818 records/second. Loss is 2.2244122. Sequential266afc8b's hyper parameters: Current learning rate is 0.004784688995215312. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14208/60000][Iteration 111][Wall Clock 17.075775717s] Trained 128 records in 0.135202158 seconds. Throughput is 946.73047 records/second. Loss is 2.1709645. Sequential266afc8b's hyper parameters: Current learning rate is 0.0047619047619047615. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 112][Wall Clock 17.188201392s] Trained 128 records in 0.112425675 seconds. Throughput is 1138.5299 records/second. Loss is 2.2086732. Sequential266afc8b's hyper parameters: Current learning rate is 0.004739336492890995. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14464/60000][Iteration 113][Wall Clock 17.300107941s] Trained 128 records in 0.111906549 seconds. Throughput is 1143.8115 records/second. Loss is 2.2010894. Sequential266afc8b's hyper parameters: Current learning rate is 0.0047169811320754715. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 114][Wall Clock 17.422917949s] Trained 128 records in 0.122810008 seconds. Throughput is 1042.2604 records/second. Loss is 2.1800478. Sequential266afc8b's hyper parameters: Current learning rate is 0.004694835680751174. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14720/60000][Iteration 115][Wall Clock 17.533920484s] Trained 128 records in 0.111002535 seconds. Throughput is 1153.1268 records/second. Loss is 2.1985598. Sequential266afc8b's hyper parameters: Current learning rate is 0.004672897196261682. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 116][Wall Clock 17.657962268s] Trained 128 records in 0.124041784 seconds. Throughput is 1031.9104 records/second. Loss is 2.1957362. Sequential266afc8b's hyper parameters: Current learning rate is 0.0046511627906976735. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:35 INFO  DistriOptimizer$:408 - [Epoch 1 14976/60000][Iteration 117][Wall Clock 17.774192276s] Trained 128 records in 0.116230008 seconds. Throughput is 1101.2646 records/second. Loss is 2.187467. Sequential266afc8b's hyper parameters: Current learning rate is 0.004629629629629629. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 118][Wall Clock 17.88340315s] Trained 128 records in 0.109210874 seconds. Throughput is 1172.0444 records/second. Loss is 2.2012844. Sequential266afc8b's hyper parameters: Current learning rate is 0.004608294930875576. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15232/60000][Iteration 119][Wall Clock 18.015133558s] Trained 128 records in 0.131730408 seconds. Throughput is 971.6815 records/second. Loss is 2.195752. Sequential266afc8b's hyper parameters: Current learning rate is 0.004587155963302753. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 120][Wall Clock 18.129427904s] Trained 128 records in 0.114294346 seconds. Throughput is 1119.9154 records/second. Loss is 2.2162085. Sequential266afc8b's hyper parameters: Current learning rate is 0.004566210045662101. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15488/60000][Iteration 121][Wall Clock 18.251002858s] Trained 128 records in 0.121574954 seconds. Throughput is 1052.8484 records/second. Loss is 2.187146. Sequential266afc8b's hyper parameters: Current learning rate is 0.004545454545454545. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 122][Wall Clock 18.365515669s] Trained 128 records in 0.114512811 seconds. Throughput is 1117.7789 records/second. Loss is 2.2044175. Sequential266afc8b's hyper parameters: Current learning rate is 0.004524886877828055. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15744/60000][Iteration 123][Wall Clock 18.488878117s] Trained 128 records in 0.123362448 seconds. Throughput is 1037.5929 records/second. Loss is 2.1980927. Sequential266afc8b's hyper parameters: Current learning rate is 0.004504504504504505. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 124][Wall Clock 18.63890919s] Trained 128 records in 0.150031073 seconds. Throughput is 853.1566 records/second. Loss is 2.2043362. Sequential266afc8b's hyper parameters: Current learning rate is 0.004484304932735426. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:36 INFO  DistriOptimizer$:408 - [Epoch 1 16000/60000][Iteration 125][Wall Clock 18.753351363s] Trained 128 records in 0.114442173 seconds. Throughput is 1118.4689 records/second. Loss is 2.1839018. Sequential266afc8b's hyper parameters: Current learning rate is 0.004464285714285714. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 126][Wall Clock 18.871223233s] Trained 128 records in 0.11787187 seconds. Throughput is 1085.9249 records/second. Loss is 2.1938984. Sequential266afc8b's hyper parameters: Current learning rate is 0.0044444444444444444. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16256/60000][Iteration 127][Wall Clock 18.984464687s] Trained 128 records in 0.113241454 seconds. Throughput is 1130.3281 records/second. Loss is 2.190049. Sequential266afc8b's hyper parameters: Current learning rate is 0.004424778761061948. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 128][Wall Clock 19.135117763s] Trained 128 records in 0.150653076 seconds. Throughput is 849.63416 records/second. Loss is 2.1934638. Sequential266afc8b's hyper parameters: Current learning rate is 0.004405286343612335. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16512/60000][Iteration 129][Wall Clock 19.265050633s] Trained 128 records in 0.12993287 seconds. Throughput is 985.12415 records/second. Loss is 2.1958182. Sequential266afc8b's hyper parameters: Current learning rate is 0.0043859649122807015. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 130][Wall Clock 19.364867878s] Trained 128 records in 0.099817245 seconds. Throughput is 1282.3435 records/second. Loss is 2.2012434. Sequential266afc8b's hyper parameters: Current learning rate is 0.004366812227074236. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16768/60000][Iteration 131][Wall Clock 19.472206092s] Trained 128 records in 0.107338214 seconds. Throughput is 1192.4924 records/second. Loss is 2.1976907. Sequential266afc8b's hyper parameters: Current learning rate is 0.004347826086956522. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 132][Wall Clock 19.597953594s] Trained 128 records in 0.125747502 seconds. Throughput is 1017.91284 records/second. Loss is 2.203754. Sequential266afc8b's hyper parameters: Current learning rate is 0.004329004329004329. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:37 INFO  DistriOptimizer$:408 - [Epoch 1 17024/60000][Iteration 133][Wall Clock 19.72203841s] Trained 128 records in 0.124084816 seconds. Throughput is 1031.5525 records/second. Loss is 2.1972394. Sequential266afc8b's hyper parameters: Current learning rate is 0.004310344827586207. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 134][Wall Clock 19.8541753s] Trained 128 records in 0.13213689 seconds. Throughput is 968.6923 records/second. Loss is 2.1878877. Sequential266afc8b's hyper parameters: Current learning rate is 0.004291845493562232. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17280/60000][Iteration 135][Wall Clock 19.960944155s] Trained 128 records in 0.106768855 seconds. Throughput is 1198.8514 records/second. Loss is 2.1879964. Sequential266afc8b's hyper parameters: Current learning rate is 0.004273504273504274. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 136][Wall Clock 20.061870282s] Trained 128 records in 0.100926127 seconds. Throughput is 1268.2544 records/second. Loss is 2.1995127. Sequential266afc8b's hyper parameters: Current learning rate is 0.00425531914893617. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17536/60000][Iteration 137][Wall Clock 20.164997696s] Trained 128 records in 0.103127414 seconds. Throughput is 1241.1831 records/second. Loss is 2.1777496. Sequential266afc8b's hyper parameters: Current learning rate is 0.0042372881355932195. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 138][Wall Clock 20.279694161s] Trained 128 records in 0.114696465 seconds. Throughput is 1115.989 records/second. Loss is 2.1841764. Sequential266afc8b's hyper parameters: Current learning rate is 0.004219409282700422. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17792/60000][Iteration 139][Wall Clock 20.390258973s] Trained 128 records in 0.110564812 seconds. Throughput is 1157.692 records/second. Loss is 2.1867418. Sequential266afc8b's hyper parameters: Current learning rate is 0.004201680672268908. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 140][Wall Clock 20.511089771s] Trained 128 records in 0.120830798 seconds. Throughput is 1059.3326 records/second. Loss is 2.1784618. Sequential266afc8b's hyper parameters: Current learning rate is 0.0041841004184100415. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 18048/60000][Iteration 141][Wall Clock 20.625790624s] Trained 128 records in 0.114700853 seconds. Throughput is 1115.9464 records/second. Loss is 2.1813064. Sequential266afc8b's hyper parameters: Current learning rate is 0.004166666666666666. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:38 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 142][Wall Clock 20.733667628s] Trained 128 records in 0.107877004 seconds. Throughput is 1186.5365 records/second. Loss is 2.1813755. Sequential266afc8b's hyper parameters: Current learning rate is 0.004149377593360996. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 18304/60000][Iteration 143][Wall Clock 20.832499052s] Trained 128 records in 0.098831424 seconds. Throughput is 1295.1346 records/second. Loss is 2.1805198. Sequential266afc8b's hyper parameters: Current learning rate is 0.004132231404958678. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 144][Wall Clock 20.932102394s] Trained 128 records in 0.099603342 seconds. Throughput is 1285.0974 records/second. Loss is 2.1715953. Sequential266afc8b's hyper parameters: Current learning rate is 0.00411522633744856. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 18560/60000][Iteration 145][Wall Clock 21.030541223s] Trained 128 records in 0.098438829 seconds. Throughput is 1300.2999 records/second. Loss is 2.1838853. Sequential266afc8b's hyper parameters: Current learning rate is 0.004098360655737705. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 146][Wall Clock 21.136964146s] Trained 128 records in 0.106422923 seconds. Throughput is 1202.7484 records/second. Loss is 2.1707473. Sequential266afc8b's hyper parameters: Current learning rate is 0.004081632653061224. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 18816/60000][Iteration 147][Wall Clock 21.241279765s] Trained 128 records in 0.104315619 seconds. Throughput is 1227.0454 records/second. Loss is 2.156739. Sequential266afc8b's hyper parameters: Current learning rate is 0.0040650406504065045. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 148][Wall Clock 21.345036976s] Trained 128 records in 0.103757211 seconds. Throughput is 1233.6492 records/second. Loss is 2.1952348. Sequential266afc8b's hyper parameters: Current learning rate is 0.004048582995951418. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 19072/60000][Iteration 149][Wall Clock 21.457417764s] Trained 128 records in 0.112380788 seconds. Throughput is 1138.9847 records/second. Loss is 2.168823. Sequential266afc8b's hyper parameters: Current learning rate is 0.004032258064516129. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 150][Wall Clock 21.560401128s] Trained 128 records in 0.102983364 seconds. Throughput is 1242.9192 records/second. Loss is 2.160296. Sequential266afc8b's hyper parameters: Current learning rate is 0.004016064257028112. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 19328/60000][Iteration 151][Wall Clock 21.664078062s] Trained 128 records in 0.103676934 seconds. Throughput is 1234.6044 records/second. Loss is 2.1913538. Sequential266afc8b's hyper parameters: Current learning rate is 0.004. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:39 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 152][Wall Clock 21.769194339s] Trained 128 records in 0.105116277 seconds. Throughput is 1217.6991 records/second. Loss is 2.1930985. Sequential266afc8b's hyper parameters: Current learning rate is 0.003984063745019921. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 19584/60000][Iteration 153][Wall Clock 21.875844807s] Trained 128 records in 0.106650468 seconds. Throughput is 1200.1823 records/second. Loss is 2.1722522. Sequential266afc8b's hyper parameters: Current learning rate is 0.003968253968253968. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 154][Wall Clock 21.98207565s] Trained 128 records in 0.106230843 seconds. Throughput is 1204.9232 records/second. Loss is 2.1849854. Sequential266afc8b's hyper parameters: Current learning rate is 0.003952569169960474. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 19840/60000][Iteration 155][Wall Clock 22.082268s] Trained 128 records in 0.10019235 seconds. Throughput is 1277.5426 records/second. Loss is 2.170816. Sequential266afc8b's hyper parameters: Current learning rate is 0.003937007874015748. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 156][Wall Clock 22.189094955s] Trained 128 records in 0.106826955 seconds. Throughput is 1198.1995 records/second. Loss is 2.1731992. Sequential266afc8b's hyper parameters: Current learning rate is 0.00392156862745098. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 20096/60000][Iteration 157][Wall Clock 22.287975538s] Trained 128 records in 0.098880583 seconds. Throughput is 1294.4907 records/second. Loss is 2.1678119. Sequential266afc8b's hyper parameters: Current learning rate is 0.00390625. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 158][Wall Clock 22.385636579s] Trained 128 records in 0.097661041 seconds. Throughput is 1310.6558 records/second. Loss is 2.154355. Sequential266afc8b's hyper parameters: Current learning rate is 0.003891050583657587. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 20352/60000][Iteration 159][Wall Clock 22.493260085s] Trained 128 records in 0.107623506 seconds. Throughput is 1189.3313 records/second. Loss is 2.1561227. Sequential266afc8b's hyper parameters: Current learning rate is 0.003875968992248062. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 160][Wall Clock 22.618335991s] Trained 128 records in 0.125075906 seconds. Throughput is 1023.37854 records/second. Loss is 2.1598368. Sequential266afc8b's hyper parameters: Current learning rate is 0.003861003861003861. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:40 INFO  DistriOptimizer$:408 - [Epoch 1 20608/60000][Iteration 161][Wall Clock 22.715582933s] Trained 128 records in 0.097246942 seconds. Throughput is 1316.2367 records/second. Loss is 2.1607187. Sequential266afc8b's hyper parameters: Current learning rate is 0.003846153846153846. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 162][Wall Clock 22.820636577s] Trained 128 records in 0.105053644 seconds. Throughput is 1218.4252 records/second. Loss is 2.1491938. Sequential266afc8b's hyper parameters: Current learning rate is 0.0038314176245210726. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 20864/60000][Iteration 163][Wall Clock 22.924055121s] Trained 128 records in 0.103418544 seconds. Throughput is 1237.6891 records/second. Loss is 2.170256. Sequential266afc8b's hyper parameters: Current learning rate is 0.003816793893129771. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 164][Wall Clock 23.028231094s] Trained 128 records in 0.104175973 seconds. Throughput is 1228.6903 records/second. Loss is 2.1555846. Sequential266afc8b's hyper parameters: Current learning rate is 0.003802281368821293. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 21120/60000][Iteration 165][Wall Clock 23.163112644s] Trained 128 records in 0.13488155 seconds. Throughput is 948.9808 records/second. Loss is 2.1540883. Sequential266afc8b's hyper parameters: Current learning rate is 0.003787878787878788. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 166][Wall Clock 23.264122946s] Trained 128 records in 0.101010302 seconds. Throughput is 1267.1975 records/second. Loss is 2.159247. Sequential266afc8b's hyper parameters: Current learning rate is 0.003773584905660377. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 21376/60000][Iteration 167][Wall Clock 23.363542709s] Trained 128 records in 0.099419763 seconds. Throughput is 1287.4703 records/second. Loss is 2.1476295. Sequential266afc8b's hyper parameters: Current learning rate is 0.0037593984962406013. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 168][Wall Clock 23.465830982s] Trained 128 records in 0.102288273 seconds. Throughput is 1251.3654 records/second. Loss is 2.1678596. Sequential266afc8b's hyper parameters: Current learning rate is 0.003745318352059925. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 21632/60000][Iteration 169][Wall Clock 23.576727265s] Trained 128 records in 0.110896283 seconds. Throughput is 1154.2317 records/second. Loss is 2.1508682. Sequential266afc8b's hyper parameters: Current learning rate is 0.00373134328358209. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:41 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 170][Wall Clock 23.686380759s] Trained 128 records in 0.109653494 seconds. Throughput is 1167.3135 records/second. Loss is 2.1664135. Sequential266afc8b's hyper parameters: Current learning rate is 0.003717472118959108. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 21888/60000][Iteration 171][Wall Clock 23.796525365s] Trained 128 records in 0.110144606 seconds. Throughput is 1162.1086 records/second. Loss is 2.1794784. Sequential266afc8b's hyper parameters: Current learning rate is 0.0037037037037037034. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 172][Wall Clock 23.926800587s] Trained 128 records in 0.130275222 seconds. Throughput is 982.5353 records/second. Loss is 2.1560893. Sequential266afc8b's hyper parameters: Current learning rate is 0.003690036900369004. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22144/60000][Iteration 173][Wall Clock 24.031857919s] Trained 128 records in 0.105057332 seconds. Throughput is 1218.3824 records/second. Loss is 2.1512456. Sequential266afc8b's hyper parameters: Current learning rate is 0.0036764705882352945. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 174][Wall Clock 24.134498621s] Trained 128 records in 0.102640702 seconds. Throughput is 1247.0686 records/second. Loss is 2.1249375. Sequential266afc8b's hyper parameters: Current learning rate is 0.003663003663003663. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22400/60000][Iteration 175][Wall Clock 24.231676815s] Trained 128 records in 0.097178194 seconds. Throughput is 1317.168 records/second. Loss is 2.1718016. Sequential266afc8b's hyper parameters: Current learning rate is 0.0036496350364963502. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 176][Wall Clock 24.331968145s] Trained 128 records in 0.10029133 seconds. Throughput is 1276.2819 records/second. Loss is 2.1736069. Sequential266afc8b's hyper parameters: Current learning rate is 0.0036363636363636364. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22656/60000][Iteration 177][Wall Clock 24.43480856s] Trained 128 records in 0.102840415 seconds. Throughput is 1244.6469 records/second. Loss is 2.1498616. Sequential266afc8b's hyper parameters: Current learning rate is 0.003623188405797102. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 178][Wall Clock 24.531855956s] Trained 128 records in 0.097047396 seconds. Throughput is 1318.9431 records/second. Loss is 2.1466582. Sequential266afc8b's hyper parameters: Current learning rate is 0.0036101083032490976. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:42 INFO  DistriOptimizer$:408 - [Epoch 1 22912/60000][Iteration 179][Wall Clock 24.649895897s] Trained 128 records in 0.118039941 seconds. Throughput is 1084.3787 records/second. Loss is 2.125271. Sequential266afc8b's hyper parameters: Current learning rate is 0.003597122302158273. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 180][Wall Clock 24.775350337s] Trained 128 records in 0.12545444 seconds. Throughput is 1020.2907 records/second. Loss is 2.1651864. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035842293906810036. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23168/60000][Iteration 181][Wall Clock 24.903468988s] Trained 128 records in 0.128118651 seconds. Throughput is 999.0739 records/second. Loss is 2.1303363. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035714285714285718. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 182][Wall Clock 25.004227732s] Trained 128 records in 0.100758744 seconds. Throughput is 1270.3612 records/second. Loss is 2.1595519. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035587188612099642. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23424/60000][Iteration 183][Wall Clock 25.107715985s] Trained 128 records in 0.103488253 seconds. Throughput is 1236.8553 records/second. Loss is 2.155927. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035460992907801418. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 184][Wall Clock 25.234239832s] Trained 128 records in 0.126523847 seconds. Throughput is 1011.66693 records/second. Loss is 2.1605675. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035335689045936395. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23680/60000][Iteration 185][Wall Clock 25.344220201s] Trained 128 records in 0.109980369 seconds. Throughput is 1163.8441 records/second. Loss is 2.1317043. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035211267605633804. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 186][Wall Clock 25.45387415s] Trained 128 records in 0.109653949 seconds. Throughput is 1167.3086 records/second. Loss is 2.1929986. Sequential266afc8b's hyper parameters: Current learning rate is 0.0035087719298245615. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 23936/60000][Iteration 187][Wall Clock 25.562132743s] Trained 128 records in 0.108258593 seconds. Throughput is 1182.3542 records/second. Loss is 2.1325657. Sequential266afc8b's hyper parameters: Current learning rate is 0.003496503496503496. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:43 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 188][Wall Clock 25.669262122s] Trained 128 records in 0.107129379 seconds. Throughput is 1194.817 records/second. Loss is 2.1606581. Sequential266afc8b's hyper parameters: Current learning rate is 0.003484320557491289. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24192/60000][Iteration 189][Wall Clock 25.774069382s] Trained 128 records in 0.10480726 seconds. Throughput is 1221.2894 records/second. Loss is 2.1475296. Sequential266afc8b's hyper parameters: Current learning rate is 0.0034722222222222225. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 190][Wall Clock 25.879330528s] Trained 128 records in 0.105261146 seconds. Throughput is 1216.0232 records/second. Loss is 2.1315467. Sequential266afc8b's hyper parameters: Current learning rate is 0.0034602076124567475. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24448/60000][Iteration 191][Wall Clock 25.979850473s] Trained 128 records in 0.100519945 seconds. Throughput is 1273.3792 records/second. Loss is 2.1464627. Sequential266afc8b's hyper parameters: Current learning rate is 0.003448275862068965. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 192][Wall Clock 26.095831086s] Trained 128 records in 0.115980613 seconds. Throughput is 1103.6327 records/second. Loss is 2.132165. Sequential266afc8b's hyper parameters: Current learning rate is 0.003436426116838488. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24704/60000][Iteration 193][Wall Clock 26.190435933s] Trained 128 records in 0.094604847 seconds. Throughput is 1352.9962 records/second. Loss is 2.1321015. Sequential266afc8b's hyper parameters: Current learning rate is 0.0034246575342465756. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 194][Wall Clock 26.284581973s] Trained 128 records in 0.09414604 seconds. Throughput is 1359.5898 records/second. Loss is 2.1362464. Sequential266afc8b's hyper parameters: Current learning rate is 0.003412969283276451. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 24960/60000][Iteration 195][Wall Clock 26.377999801s] Trained 128 records in 0.093417828 seconds. Throughput is 1370.1881 records/second. Loss is 2.143132. Sequential266afc8b's hyper parameters: Current learning rate is 0.0034013605442176874. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 196][Wall Clock 26.484557309s] Trained 128 records in 0.106557508 seconds. Throughput is 1201.2292 records/second. Loss is 2.1308. Sequential266afc8b's hyper parameters: Current learning rate is 0.003389830508474576. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 25216/60000][Iteration 197][Wall Clock 26.593904505s] Trained 128 records in 0.109347196 seconds. Throughput is 1170.5833 records/second. Loss is 2.1137486. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033783783783783786. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:44 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 198][Wall Clock 26.697330851s] Trained 128 records in 0.103426346 seconds. Throughput is 1237.5957 records/second. Loss is 2.1457067. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033670033670033673. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 25472/60000][Iteration 199][Wall Clock 26.799144125s] Trained 128 records in 0.101813274 seconds. Throughput is 1257.2035 records/second. Loss is 2.119697. Sequential266afc8b's hyper parameters: Current learning rate is 0.003355704697986577. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 200][Wall Clock 26.923775411s] Trained 128 records in 0.124631286 seconds. Throughput is 1027.0294 records/second. Loss is 2.1412044. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033444816053511705. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 25728/60000][Iteration 201][Wall Clock 27.022346563s] Trained 128 records in 0.098571152 seconds. Throughput is 1298.5543 records/second. Loss is 2.138707. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033333333333333335. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 202][Wall Clock 27.12777556s] Trained 128 records in 0.105428997 seconds. Throughput is 1214.0873 records/second. Loss is 2.1279387. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033222591362126242. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 25984/60000][Iteration 203][Wall Clock 27.224319694s] Trained 128 records in 0.096544134 seconds. Throughput is 1325.8186 records/second. Loss is 2.1308362. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033112582781456954. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 204][Wall Clock 27.327817287s] Trained 128 records in 0.103497593 seconds. Throughput is 1236.7438 records/second. Loss is 2.1169133. Sequential266afc8b's hyper parameters: Current learning rate is 0.0033003300330033. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 26240/60000][Iteration 205][Wall Clock 27.422920965s] Trained 128 records in 0.095103678 seconds. Throughput is 1345.8995 records/second. Loss is 2.1100874. Sequential266afc8b's hyper parameters: Current learning rate is 0.003289473684210526. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 206][Wall Clock 27.518914236s] Trained 128 records in 0.095993271 seconds. Throughput is 1333.4268 records/second. Loss is 2.1603098. Sequential266afc8b's hyper parameters: Current learning rate is 0.0032786885245901644. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 26496/60000][Iteration 207][Wall Clock 27.620511234s] Trained 128 records in 0.101596998 seconds. Throughput is 1259.8798 records/second. Loss is 2.1315918. Sequential266afc8b's hyper parameters: Current learning rate is 0.0032679738562091504. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:45 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 208][Wall Clock 27.7232113s] Trained 128 records in 0.102700066 seconds. Throughput is 1246.3478 records/second. Loss is 2.1522121. Sequential266afc8b's hyper parameters: Current learning rate is 0.003257328990228013. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 26752/60000][Iteration 209][Wall Clock 27.834908107s] Trained 128 records in 0.111696807 seconds. Throughput is 1145.9594 records/second. Loss is 2.114766. Sequential266afc8b's hyper parameters: Current learning rate is 0.0032467532467532465. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 210][Wall Clock 27.964883907s] Trained 128 records in 0.1299758 seconds. Throughput is 984.79877 records/second. Loss is 2.124803. Sequential266afc8b's hyper parameters: Current learning rate is 0.003236245954692557. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27008/60000][Iteration 211][Wall Clock 28.067430015s] Trained 128 records in 0.102546108 seconds. Throughput is 1248.219 records/second. Loss is 2.15679. Sequential266afc8b's hyper parameters: Current learning rate is 0.0032258064516129032. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 212][Wall Clock 28.186394712s] Trained 128 records in 0.118964697 seconds. Throughput is 1075.9495 records/second. Loss is 2.124513. Sequential266afc8b's hyper parameters: Current learning rate is 0.0032154340836012866. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27264/60000][Iteration 213][Wall Clock 28.280125901s] Trained 128 records in 0.093731189 seconds. Throughput is 1365.6074 records/second. Loss is 2.1332054. Sequential266afc8b's hyper parameters: Current learning rate is 0.003205128205128205. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 214][Wall Clock 28.374621919s] Trained 128 records in 0.094496018 seconds. Throughput is 1354.5544 records/second. Loss is 2.116571. Sequential266afc8b's hyper parameters: Current learning rate is 0.0031948881789137383. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27520/60000][Iteration 215][Wall Clock 28.467053464s] Trained 128 records in 0.092431545 seconds. Throughput is 1384.8086 records/second. Loss is 2.1282966. Sequential266afc8b's hyper parameters: Current learning rate is 0.003184713375796178. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 216][Wall Clock 28.567866879s] Trained 128 records in 0.100813415 seconds. Throughput is 1269.6722 records/second. Loss is 2.113451. Sequential266afc8b's hyper parameters: Current learning rate is 0.0031746031746031746. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:46 INFO  DistriOptimizer$:408 - [Epoch 1 27776/60000][Iteration 217][Wall Clock 28.666831286s] Trained 128 records in 0.098964407 seconds. Throughput is 1293.3943 records/second. Loss is 2.0989149. Sequential266afc8b's hyper parameters: Current learning rate is 0.0031645569620253164. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 218][Wall Clock 28.758561941s] Trained 128 records in 0.091730655 seconds. Throughput is 1395.3896 records/second. Loss is 2.1013985. Sequential266afc8b's hyper parameters: Current learning rate is 0.003154574132492114. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28032/60000][Iteration 219][Wall Clock 28.851758957s] Trained 128 records in 0.093197016 seconds. Throughput is 1373.4344 records/second. Loss is 2.0809412. Sequential266afc8b's hyper parameters: Current learning rate is 0.003144654088050314. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 220][Wall Clock 28.951401544s] Trained 128 records in 0.099642587 seconds. Throughput is 1284.5913 records/second. Loss is 2.1055331. Sequential266afc8b's hyper parameters: Current learning rate is 0.0031347962382445144. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28288/60000][Iteration 221][Wall Clock 29.057314262s] Trained 128 records in 0.105912718 seconds. Throughput is 1208.5424 records/second. Loss is 2.1126373. Sequential266afc8b's hyper parameters: Current learning rate is 0.0031249999999999997. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 222][Wall Clock 29.181031229s] Trained 128 records in 0.123716967 seconds. Throughput is 1034.6196 records/second. Loss is 2.1288931. Sequential266afc8b's hyper parameters: Current learning rate is 0.003115264797507788. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28544/60000][Iteration 223][Wall Clock 29.302936503s] Trained 128 records in 0.121905274 seconds. Throughput is 1049.9956 records/second. Loss is 2.108924. Sequential266afc8b's hyper parameters: Current learning rate is 0.003105590062111801. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 224][Wall Clock 29.413274841s] Trained 128 records in 0.110338338 seconds. Throughput is 1160.0682 records/second. Loss is 2.1272182. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030959752321981426. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28800/60000][Iteration 225][Wall Clock 29.541337547s] Trained 128 records in 0.128062706 seconds. Throughput is 999.5103 records/second. Loss is 2.125407. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030864197530864196. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:47 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 226][Wall Clock 29.63923561s] Trained 128 records in 0.097898063 seconds. Throughput is 1307.4824 records/second. Loss is 2.1371787. Sequential266afc8b's hyper parameters: Current learning rate is 0.003076923076923077. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29056/60000][Iteration 227][Wall Clock 29.732961216s] Trained 128 records in 0.093725606 seconds. Throughput is 1365.6887 records/second. Loss is 2.0883462. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030674846625766868. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 228][Wall Clock 29.833326459s] Trained 128 records in 0.100365243 seconds. Throughput is 1275.3419 records/second. Loss is 2.1009345. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030581039755351682. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29312/60000][Iteration 229][Wall Clock 29.930608359s] Trained 128 records in 0.0972819 seconds. Throughput is 1315.7638 records/second. Loss is 2.1307497. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030487804878048777. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 230][Wall Clock 30.026784239s] Trained 128 records in 0.09617588 seconds. Throughput is 1330.895 records/second. Loss is 2.1019614. Sequential266afc8b's hyper parameters: Current learning rate is 0.00303951367781155. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29568/60000][Iteration 231][Wall Clock 30.120933651s] Trained 128 records in 0.094149412 seconds. Throughput is 1359.5411 records/second. Loss is 2.1140163. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030303030303030303. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 232][Wall Clock 30.216201862s] Trained 128 records in 0.095268211 seconds. Throughput is 1343.5751 records/second. Loss is 2.0855684. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030211480362537764. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29824/60000][Iteration 233][Wall Clock 30.313590048s] Trained 128 records in 0.097388186 seconds. Throughput is 1314.3278 records/second. Loss is 2.1108806. Sequential266afc8b's hyper parameters: Current learning rate is 0.0030120481927710845. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 234][Wall Clock 30.41411742s] Trained 128 records in 0.100527372 seconds. Throughput is 1273.2852 records/second. Loss is 2.108789. Sequential266afc8b's hyper parameters: Current learning rate is 0.003003003003003003. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 30080/60000][Iteration 235][Wall Clock 30.510410241s] Trained 128 records in 0.096292821 seconds. Throughput is 1329.2787 records/second. Loss is 2.0916035. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029940119760479044. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:48 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 236][Wall Clock 30.624015309s] Trained 128 records in 0.113605068 seconds. Throughput is 1126.7103 records/second. Loss is 2.100115. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029850746268656717. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 30336/60000][Iteration 237][Wall Clock 30.724146645s] Trained 128 records in 0.100131336 seconds. Throughput is 1278.3212 records/second. Loss is 2.101328. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029761904761904765. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 238][Wall Clock 30.81835373s] Trained 128 records in 0.094207085 seconds. Throughput is 1358.7089 records/second. Loss is 2.111124. Sequential266afc8b's hyper parameters: Current learning rate is 0.002967359050445104. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 30592/60000][Iteration 239][Wall Clock 30.922664249s] Trained 128 records in 0.104310519 seconds. Throughput is 1227.1053 records/second. Loss is 2.0979087. Sequential266afc8b's hyper parameters: Current learning rate is 0.002958579881656805. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 240][Wall Clock 31.019817331s] Trained 128 records in 0.097153082 seconds. Throughput is 1317.5084 records/second. Loss is 2.1014154. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029498525073746312. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 30848/60000][Iteration 241][Wall Clock 31.124292772s] Trained 128 records in 0.104475441 seconds. Throughput is 1225.1683 records/second. Loss is 2.093702. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029411764705882353. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 242][Wall Clock 31.241593371s] Trained 128 records in 0.117300599 seconds. Throughput is 1091.2135 records/second. Loss is 2.0795357. Sequential266afc8b's hyper parameters: Current learning rate is 0.002932551319648094. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 31104/60000][Iteration 243][Wall Clock 31.358665463s] Trained 128 records in 0.117072092 seconds. Throughput is 1093.3434 records/second. Loss is 2.1364527. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029239766081871348. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 244][Wall Clock 31.476636587s] Trained 128 records in 0.117971124 seconds. Throughput is 1085.0114 records/second. Loss is 2.0707033. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029154518950437317. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:49 INFO  DistriOptimizer$:408 - [Epoch 1 31360/60000][Iteration 245][Wall Clock 31.597629049s] Trained 128 records in 0.120992462 seconds. Throughput is 1057.9171 records/second. Loss is 2.1026366. Sequential266afc8b's hyper parameters: Current learning rate is 0.0029069767441860465. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 246][Wall Clock 31.713689805s] Trained 128 records in 0.116060756 seconds. Throughput is 1102.8706 records/second. Loss is 2.084656. Sequential266afc8b's hyper parameters: Current learning rate is 0.002898550724637681. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 31616/60000][Iteration 247][Wall Clock 31.814939666s] Trained 128 records in 0.101249861 seconds. Throughput is 1264.1993 records/second. Loss is 2.107767. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028901734104046246. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 248][Wall Clock 31.924697332s] Trained 128 records in 0.109757666 seconds. Throughput is 1166.2056 records/second. Loss is 2.0379596. Sequential266afc8b's hyper parameters: Current learning rate is 0.002881844380403458. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 31872/60000][Iteration 249][Wall Clock 32.047676674s] Trained 128 records in 0.122979342 seconds. Throughput is 1040.8252 records/second. Loss is 2.0860977. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028735632183908046. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 250][Wall Clock 32.161316206s] Trained 128 records in 0.113639532 seconds. Throughput is 1126.3685 records/second. Loss is 2.0893629. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028653295128939827. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 32128/60000][Iteration 251][Wall Clock 32.270752596s] Trained 128 records in 0.10943639 seconds. Throughput is 1169.6292 records/second. Loss is 2.0745773. Sequential266afc8b's hyper parameters: Current learning rate is 0.002857142857142857. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 252][Wall Clock 32.39496461s] Trained 128 records in 0.124212014 seconds. Throughput is 1030.4961 records/second. Loss is 2.0934613. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028490028490028487. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 32384/60000][Iteration 253][Wall Clock 32.501885898s] Trained 128 records in 0.106921288 seconds. Throughput is 1197.1423 records/second. Loss is 2.0709405. Sequential266afc8b's hyper parameters: Current learning rate is 0.002840909090909091. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:50 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 254][Wall Clock 32.597706053s] Trained 128 records in 0.095820155 seconds. Throughput is 1335.8358 records/second. Loss is 2.066585. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028328611898016994. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 32640/60000][Iteration 255][Wall Clock 32.706801897s] Trained 128 records in 0.109095844 seconds. Throughput is 1173.2803 records/second. Loss is 2.0766568. Sequential266afc8b's hyper parameters: Current learning rate is 0.002824858757062147. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 256][Wall Clock 32.82100299s] Trained 128 records in 0.114201093 seconds. Throughput is 1120.83 records/second. Loss is 2.0814703. Sequential266afc8b's hyper parameters: Current learning rate is 0.002816901408450704. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 32896/60000][Iteration 257][Wall Clock 32.919132868s] Trained 128 records in 0.098129878 seconds. Throughput is 1304.3938 records/second. Loss is 2.0795672. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028089887640449437. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 258][Wall Clock 33.019195803s] Trained 128 records in 0.100062935 seconds. Throughput is 1279.195 records/second. Loss is 2.077702. Sequential266afc8b's hyper parameters: Current learning rate is 0.0028011204481792717. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33152/60000][Iteration 259][Wall Clock 33.113661007s] Trained 128 records in 0.094465204 seconds. Throughput is 1354.9963 records/second. Loss is 2.0822146. Sequential266afc8b's hyper parameters: Current learning rate is 0.002793296089385475. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 260][Wall Clock 33.204795485s] Trained 128 records in 0.091134478 seconds. Throughput is 1404.5178 records/second. Loss is 2.0957723. Sequential266afc8b's hyper parameters: Current learning rate is 0.002785515320334262. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33408/60000][Iteration 261][Wall Clock 33.306334214s] Trained 128 records in 0.101538729 seconds. Throughput is 1260.6027 records/second. Loss is 2.1060293. Sequential266afc8b's hyper parameters: Current learning rate is 0.002777777777777778. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 262][Wall Clock 33.400920371s] Trained 128 records in 0.094586157 seconds. Throughput is 1353.2635 records/second. Loss is 2.0388968. Sequential266afc8b's hyper parameters: Current learning rate is 0.002770083102493075. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33664/60000][Iteration 263][Wall Clock 33.496220425s] Trained 128 records in 0.095300054 seconds. Throughput is 1343.1262 records/second. Loss is 2.079507. Sequential266afc8b's hyper parameters: Current learning rate is 0.0027624309392265192. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:51 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 264][Wall Clock 33.60316663s] Trained 128 records in 0.106946205 seconds. Throughput is 1196.8634 records/second. Loss is 2.0771344. Sequential266afc8b's hyper parameters: Current learning rate is 0.0027548209366391185. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 33920/60000][Iteration 265][Wall Clock 33.722066669s] Trained 128 records in 0.118900039 seconds. Throughput is 1076.5345 records/second. Loss is 2.0367632. Sequential266afc8b's hyper parameters: Current learning rate is 0.002747252747252747. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 266][Wall Clock 33.810980502s] Trained 128 records in 0.088913833 seconds. Throughput is 1439.596 records/second. Loss is 2.098731. Sequential266afc8b's hyper parameters: Current learning rate is 0.0027397260273972603. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34176/60000][Iteration 267][Wall Clock 33.904208257s] Trained 128 records in 0.093227755 seconds. Throughput is 1372.9817 records/second. Loss is 2.0759864. Sequential266afc8b's hyper parameters: Current learning rate is 0.00273224043715847. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 268][Wall Clock 34.021019826s] Trained 128 records in 0.116811569 seconds. Throughput is 1095.7819 records/second. Loss is 2.065013. Sequential266afc8b's hyper parameters: Current learning rate is 0.0027247956403269754. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34432/60000][Iteration 269][Wall Clock 34.132315773s] Trained 128 records in 0.111295947 seconds. Throughput is 1150.0868 records/second. Loss is 2.0867. Sequential266afc8b's hyper parameters: Current learning rate is 0.002717391304347826. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 270][Wall Clock 34.226949557s] Trained 128 records in 0.094633784 seconds. Throughput is 1352.5825 records/second. Loss is 2.0715275. Sequential266afc8b's hyper parameters: Current learning rate is 0.0027100271002710027. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34688/60000][Iteration 271][Wall Clock 34.320051649s] Trained 128 records in 0.093102092 seconds. Throughput is 1374.8348 records/second. Loss is 2.1118298. Sequential266afc8b's hyper parameters: Current learning rate is 0.0027027027027027024. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 272][Wall Clock 34.430742254s] Trained 128 records in 0.110690605 seconds. Throughput is 1156.3763 records/second. Loss is 2.0723944. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026954177897574125. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 34944/60000][Iteration 273][Wall Clock 34.530870045s] Trained 128 records in 0.100127791 seconds. Throughput is 1278.3663 records/second. Loss is 2.1067216. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026881720430107525. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:52 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 274][Wall Clock 34.632345927s] Trained 128 records in 0.101475882 seconds. Throughput is 1261.3835 records/second. Loss is 2.0470924. Sequential266afc8b's hyper parameters: Current learning rate is 0.002680965147453083. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35200/60000][Iteration 275][Wall Clock 34.725018908s] Trained 128 records in 0.092672981 seconds. Throughput is 1381.2008 records/second. Loss is 2.0408442. Sequential266afc8b's hyper parameters: Current learning rate is 0.00267379679144385. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 276][Wall Clock 34.824116658s] Trained 128 records in 0.09909775 seconds. Throughput is 1291.6539 records/second. Loss is 2.0438082. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026666666666666666. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35456/60000][Iteration 277][Wall Clock 34.938029485s] Trained 128 records in 0.113912827 seconds. Throughput is 1123.6663 records/second. Loss is 2.0862262. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026595744680851063. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 278][Wall Clock 35.031132729s] Trained 128 records in 0.093103244 seconds. Throughput is 1374.8179 records/second. Loss is 2.0869935. Sequential266afc8b's hyper parameters: Current learning rate is 0.002652519893899204. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35712/60000][Iteration 279][Wall Clock 35.120969885s] Trained 128 records in 0.089837156 seconds. Throughput is 1424.8002 records/second. Loss is 2.077753. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026455026455026454. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 280][Wall Clock 35.221255998s] Trained 128 records in 0.100286113 seconds. Throughput is 1276.3483 records/second. Loss is 2.036309. Sequential266afc8b's hyper parameters: Current learning rate is 0.002638522427440633. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 35968/60000][Iteration 281][Wall Clock 35.314386437s] Trained 128 records in 0.093130439 seconds. Throughput is 1374.4164 records/second. Loss is 2.0641432. Sequential266afc8b's hyper parameters: Current learning rate is 0.002631578947368421. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 282][Wall Clock 35.430979661s] Trained 128 records in 0.116593224 seconds. Throughput is 1097.834 records/second. Loss is 2.0592074. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026246719160104987. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 36224/60000][Iteration 283][Wall Clock 35.520859362s] Trained 128 records in 0.089879701 seconds. Throughput is 1424.1259 records/second. Loss is 2.0382297. Sequential266afc8b's hyper parameters: Current learning rate is 0.002617801047120419. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:53 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 284][Wall Clock 35.614806258s] Trained 128 records in 0.093946896 seconds. Throughput is 1362.4718 records/second. Loss is 2.0087876. Sequential266afc8b's hyper parameters: Current learning rate is 0.0026109660574412533. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 36480/60000][Iteration 285][Wall Clock 35.71202897s] Trained 128 records in 0.097222712 seconds. Throughput is 1316.5647 records/second. Loss is 2.0706527. Sequential266afc8b's hyper parameters: Current learning rate is 0.002604166666666667. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 286][Wall Clock 35.803114194s] Trained 128 records in 0.091085224 seconds. Throughput is 1405.2773 records/second. Loss is 2.052818. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025974025974025974. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 36736/60000][Iteration 287][Wall Clock 35.899471532s] Trained 128 records in 0.096357338 seconds. Throughput is 1328.3887 records/second. Loss is 2.0440178. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025906735751295338. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 288][Wall Clock 35.996058927s] Trained 128 records in 0.096587395 seconds. Throughput is 1325.2246 records/second. Loss is 2.0217643. Sequential266afc8b's hyper parameters: Current learning rate is 0.002583979328165375. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 36992/60000][Iteration 289][Wall Clock 36.093283093s] Trained 128 records in 0.097224166 seconds. Throughput is 1316.545 records/second. Loss is 2.0680933. Sequential266afc8b's hyper parameters: Current learning rate is 0.002577319587628866. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 290][Wall Clock 36.193459103s] Trained 128 records in 0.10017601 seconds. Throughput is 1277.7511 records/second. Loss is 2.0194807. Sequential266afc8b's hyper parameters: Current learning rate is 0.002570694087403599. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 37248/60000][Iteration 291][Wall Clock 36.285093575s] Trained 128 records in 0.091634472 seconds. Throughput is 1396.8542 records/second. Loss is 2.0753958. Sequential266afc8b's hyper parameters: Current learning rate is 0.002564102564102564. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 292][Wall Clock 36.376798172s] Trained 128 records in 0.091704597 seconds. Throughput is 1395.786 records/second. Loss is 2.0387864. Sequential266afc8b's hyper parameters: Current learning rate is 0.002557544757033248. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 37504/60000][Iteration 293][Wall Clock 36.468656723s] Trained 128 records in 0.091858551 seconds. Throughput is 1393.4468 records/second. Loss is 2.0290322. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025510204081632655. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 294][Wall Clock 36.564221197s] Trained 128 records in 0.095564474 seconds. Throughput is 1339.4098 records/second. Loss is 2.0366502. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025445292620865138. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:54 INFO  DistriOptimizer$:408 - [Epoch 1 37760/60000][Iteration 295][Wall Clock 36.672889231s] Trained 128 records in 0.108668034 seconds. Throughput is 1177.8993 records/second. Loss is 2.067799. Sequential266afc8b's hyper parameters: Current learning rate is 0.002538071065989848. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 296][Wall Clock 36.799599121s] Trained 128 records in 0.12670989 seconds. Throughput is 1010.1816 records/second. Loss is 2.0364687. Sequential266afc8b's hyper parameters: Current learning rate is 0.002531645569620253. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38016/60000][Iteration 297][Wall Clock 36.896547496s] Trained 128 records in 0.096948375 seconds. Throughput is 1320.2903 records/second. Loss is 2.0408049. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025252525252525255. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 298][Wall Clock 36.99506307s] Trained 128 records in 0.098515574 seconds. Throughput is 1299.2869 records/second. Loss is 2.0474398. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025188916876574307. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38272/60000][Iteration 299][Wall Clock 37.094817176s] Trained 128 records in 0.099754106 seconds. Throughput is 1283.1553 records/second. Loss is 2.0395424. Sequential266afc8b's hyper parameters: Current learning rate is 0.002512562814070352. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 300][Wall Clock 37.188332089s] Trained 128 records in 0.093514913 seconds. Throughput is 1368.7656 records/second. Loss is 2.0653634. Sequential266afc8b's hyper parameters: Current learning rate is 0.002506265664160401. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38528/60000][Iteration 301][Wall Clock 37.277388491s] Trained 128 records in 0.089056402 seconds. Throughput is 1437.2914 records/second. Loss is 2.0533426. Sequential266afc8b's hyper parameters: Current learning rate is 0.0025. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 302][Wall Clock 37.399384954s] Trained 128 records in 0.121996463 seconds. Throughput is 1049.2107 records/second. Loss is 2.036762. Sequential266afc8b's hyper parameters: Current learning rate is 0.002493765586034913. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38784/60000][Iteration 303][Wall Clock 37.520019995s] Trained 128 records in 0.120635041 seconds. Throughput is 1061.0516 records/second. Loss is 2.0109715. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024875621890547268. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:55 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 304][Wall Clock 37.63242682s] Trained 128 records in 0.112406825 seconds. Throughput is 1138.7208 records/second. Loss is 2.0618238. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024813895781637717. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39040/60000][Iteration 305][Wall Clock 37.72422797s] Trained 128 records in 0.09180115 seconds. Throughput is 1394.318 records/second. Loss is 2.076459. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024752475247524753. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 306][Wall Clock 37.815162964s] Trained 128 records in 0.090934994 seconds. Throughput is 1407.599 records/second. Loss is 2.0298793. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024691358024691353. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39296/60000][Iteration 307][Wall Clock 37.909002405s] Trained 128 records in 0.093839441 seconds. Throughput is 1364.032 records/second. Loss is 2.0464418. Sequential266afc8b's hyper parameters: Current learning rate is 0.002463054187192118. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 308][Wall Clock 38.004625181s] Trained 128 records in 0.095622776 seconds. Throughput is 1338.5931 records/second. Loss is 1.9996308. Sequential266afc8b's hyper parameters: Current learning rate is 0.002457002457002457. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39552/60000][Iteration 309][Wall Clock 38.125650086s] Trained 128 records in 0.121024905 seconds. Throughput is 1057.6335 records/second. Loss is 2.0520735. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024509803921568627. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 310][Wall Clock 38.229848228s] Trained 128 records in 0.104198142 seconds. Throughput is 1228.4288 records/second. Loss is 2.0595396. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024449877750611247. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39808/60000][Iteration 311][Wall Clock 38.326001273s] Trained 128 records in 0.096153045 seconds. Throughput is 1331.211 records/second. Loss is 2.0384855. Sequential266afc8b's hyper parameters: Current learning rate is 0.002439024390243903. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 312][Wall Clock 38.416965918s] Trained 128 records in 0.090964645 seconds. Throughput is 1407.1401 records/second. Loss is 1.9820936. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024330900243309007. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 40064/60000][Iteration 313][Wall Clock 38.518961898s] Trained 128 records in 0.10199598 seconds. Throughput is 1254.9514 records/second. Loss is 2.044008. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024271844660194173. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:56 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 314][Wall Clock 38.616937096s] Trained 128 records in 0.097975198 seconds. Throughput is 1306.4531 records/second. Loss is 2.033155. Sequential266afc8b's hyper parameters: Current learning rate is 0.002421307506053269. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 40320/60000][Iteration 315][Wall Clock 38.714823583s] Trained 128 records in 0.097886487 seconds. Throughput is 1307.6371 records/second. Loss is 2.07671. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024154589371980675. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 316][Wall Clock 38.811393594s] Trained 128 records in 0.096570011 seconds. Throughput is 1325.4633 records/second. Loss is 2.0280502. Sequential266afc8b's hyper parameters: Current learning rate is 0.0024096385542168672. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 40576/60000][Iteration 317][Wall Clock 38.903488725s] Trained 128 records in 0.092095131 seconds. Throughput is 1389.8672 records/second. Loss is 2.0577314. Sequential266afc8b's hyper parameters: Current learning rate is 0.002403846153846154. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 318][Wall Clock 38.995853773s] Trained 128 records in 0.092365048 seconds. Throughput is 1385.8055 records/second. Loss is 2.011288. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023980815347721825. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 40832/60000][Iteration 319][Wall Clock 39.103260401s] Trained 128 records in 0.107406628 seconds. Throughput is 1191.7328 records/second. Loss is 2.033049. Sequential266afc8b's hyper parameters: Current learning rate is 0.002392344497607656. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 320][Wall Clock 39.195230692s] Trained 128 records in 0.091970291 seconds. Throughput is 1391.7537 records/second. Loss is 2.0279484. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023866348448687356. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 41088/60000][Iteration 321][Wall Clock 39.286604891s] Trained 128 records in 0.091374199 seconds. Throughput is 1400.8331 records/second. Loss is 2.0407019. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023809523809523807. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 322][Wall Clock 39.37444167s] Trained 128 records in 0.087836779 seconds. Throughput is 1457.2483 records/second. Loss is 1.9596522. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023752969121140144. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 41344/60000][Iteration 323][Wall Clock 39.463942987s] Trained 128 records in 0.089501317 seconds. Throughput is 1430.1466 records/second. Loss is 2.0586872. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023696682464454974. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 324][Wall Clock 39.555519105s] Trained 128 records in 0.091576118 seconds. Throughput is 1397.7444 records/second. Loss is 2.0326498. Sequential266afc8b's hyper parameters: Current learning rate is 0.002364066193853428. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:57 INFO  DistriOptimizer$:408 - [Epoch 1 41600/60000][Iteration 325][Wall Clock 39.648478424s] Trained 128 records in 0.092959319 seconds. Throughput is 1376.9464 records/second. Loss is 2.0440567. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023584905660377358. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 326][Wall Clock 39.739849954s] Trained 128 records in 0.09137153 seconds. Throughput is 1400.874 records/second. Loss is 2.007917. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023529411764705885. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 41856/60000][Iteration 327][Wall Clock 39.840744307s] Trained 128 records in 0.100894353 seconds. Throughput is 1268.6537 records/second. Loss is 2.0335755. Sequential266afc8b's hyper parameters: Current learning rate is 0.002347417840375587. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 328][Wall Clock 39.960149327s] Trained 128 records in 0.11940502 seconds. Throughput is 1071.9818 records/second. Loss is 2.008082. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023419203747072604. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42112/60000][Iteration 329][Wall Clock 40.063139983s] Trained 128 records in 0.102990656 seconds. Throughput is 1242.8312 records/second. Loss is 2.0529182. Sequential266afc8b's hyper parameters: Current learning rate is 0.002336448598130841. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 330][Wall Clock 40.156570637s] Trained 128 records in 0.093430654 seconds. Throughput is 1370.0 records/second. Loss is 1.997572. Sequential266afc8b's hyper parameters: Current learning rate is 0.002331002331002331. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42368/60000][Iteration 331][Wall Clock 40.27428981s] Trained 128 records in 0.117719173 seconds. Throughput is 1087.3335 records/second. Loss is 1.9954479. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023255813953488367. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 332][Wall Clock 40.368447862s] Trained 128 records in 0.094158052 seconds. Throughput is 1359.4164 records/second. Loss is 2.015278. Sequential266afc8b's hyper parameters: Current learning rate is 0.002320185614849188. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42624/60000][Iteration 333][Wall Clock 40.457000371s] Trained 128 records in 0.088552509 seconds. Throughput is 1445.47 records/second. Loss is 1.9847151. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023148148148148147. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 334][Wall Clock 40.547112631s] Trained 128 records in 0.09011226 seconds. Throughput is 1420.4504 records/second. Loss is 2.0295568. Sequential266afc8b's hyper parameters: Current learning rate is 0.0023094688221709007. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:58 INFO  DistriOptimizer$:408 - [Epoch 1 42880/60000][Iteration 335][Wall Clock 40.647498393s] Trained 128 records in 0.100385762 seconds. Throughput is 1275.0812 records/second. Loss is 1.9953107. Sequential266afc8b's hyper parameters: Current learning rate is 0.002304147465437788. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 336][Wall Clock 40.743474462s] Trained 128 records in 0.095976069 seconds. Throughput is 1333.6658 records/second. Loss is 2.0248532. Sequential266afc8b's hyper parameters: Current learning rate is 0.002298850574712644. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43136/60000][Iteration 337][Wall Clock 40.840232826s] Trained 128 records in 0.096758364 seconds. Throughput is 1322.883 records/second. Loss is 2.056856. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022935779816513767. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 338][Wall Clock 40.931957747s] Trained 128 records in 0.091724921 seconds. Throughput is 1395.4768 records/second. Loss is 2.0187237. Sequential266afc8b's hyper parameters: Current learning rate is 0.002288329519450801. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43392/60000][Iteration 339][Wall Clock 41.024245041s] Trained 128 records in 0.092287294 seconds. Throughput is 1386.9731 records/second. Loss is 2.0143156. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022831050228310505. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 340][Wall Clock 41.117119979s] Trained 128 records in 0.092874938 seconds. Throughput is 1378.1974 records/second. Loss is 2.0020719. Sequential266afc8b's hyper parameters: Current learning rate is 0.002277904328018223. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43648/60000][Iteration 341][Wall Clock 41.214250968s] Trained 128 records in 0.097130989 seconds. Throughput is 1317.808 records/second. Loss is 1.9774126. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022727272727272726. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 342][Wall Clock 41.31136656s] Trained 128 records in 0.097115592 seconds. Throughput is 1318.017 records/second. Loss is 1.9752352. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022675736961451248. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 43904/60000][Iteration 343][Wall Clock 41.417614631s] Trained 128 records in 0.106248071 seconds. Throughput is 1204.7278 records/second. Loss is 2.0011451. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022624434389140274. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 344][Wall Clock 41.50833652s] Trained 128 records in 0.090721889 seconds. Throughput is 1410.9054 records/second. Loss is 2.04224. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022573363431151244. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:18:59 INFO  DistriOptimizer$:408 - [Epoch 1 44160/60000][Iteration 345][Wall Clock 41.601671071s] Trained 128 records in 0.093334551 seconds. Throughput is 1371.4108 records/second. Loss is 2.0078757. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022522522522522527. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 346][Wall Clock 41.685443339s] Trained 128 records in 0.083772268 seconds. Throughput is 1527.952 records/second. Loss is 2.0088959. Sequential266afc8b's hyper parameters: Current learning rate is 0.002247191011235955. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 44416/60000][Iteration 347][Wall Clock 41.77943092s] Trained 128 records in 0.093987581 seconds. Throughput is 1361.882 records/second. Loss is 1.9957739. Sequential266afc8b's hyper parameters: Current learning rate is 0.002242152466367713. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 348][Wall Clock 41.872689657s] Trained 128 records in 0.093258737 seconds. Throughput is 1372.5255 records/second. Loss is 2.0253804. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022371364653243843. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 44672/60000][Iteration 349][Wall Clock 41.964232253s] Trained 128 records in 0.091542596 seconds. Throughput is 1398.2562 records/second. Loss is 2.0288696. Sequential266afc8b's hyper parameters: Current learning rate is 0.002232142857142857. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 350][Wall Clock 42.054961583s] Trained 128 records in 0.09072933 seconds. Throughput is 1410.7896 records/second. Loss is 1.9908214. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022271714922048997. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 44928/60000][Iteration 351][Wall Clock 42.145338099s] Trained 128 records in 0.090376516 seconds. Throughput is 1416.2971 records/second. Loss is 1.9987721. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022222222222222222. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 352][Wall Clock 42.243635899s] Trained 128 records in 0.0982978 seconds. Throughput is 1302.1655 records/second. Loss is 1.9972736. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022172949002217295. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 45184/60000][Iteration 353][Wall Clock 42.334919826s] Trained 128 records in 0.091283927 seconds. Throughput is 1402.2184 records/second. Loss is 2.0417154. Sequential266afc8b's hyper parameters: Current learning rate is 0.002212389380530974. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 354][Wall Clock 42.427868553s] Trained 128 records in 0.092948727 seconds. Throughput is 1377.1033 records/second. Loss is 1.973042. Sequential266afc8b's hyper parameters: Current learning rate is 0.002207505518763797. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 45440/60000][Iteration 355][Wall Clock 42.519329748s] Trained 128 records in 0.091461195 seconds. Throughput is 1399.5006 records/second. Loss is 1.9718072. Sequential266afc8b's hyper parameters: Current learning rate is 0.0022026431718061676. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:00 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 356][Wall Clock 42.616402773s] Trained 128 records in 0.097073025 seconds. Throughput is 1318.595 records/second. Loss is 2.0031097. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021978021978021974. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 45696/60000][Iteration 357][Wall Clock 42.71130219s] Trained 128 records in 0.094899417 seconds. Throughput is 1348.7965 records/second. Loss is 2.0041754. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021929824561403508. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 358][Wall Clock 42.814817321s] Trained 128 records in 0.103515131 seconds. Throughput is 1236.5342 records/second. Loss is 1.987432. Sequential266afc8b's hyper parameters: Current learning rate is 0.002188183807439825. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 45952/60000][Iteration 359][Wall Clock 42.911207623s] Trained 128 records in 0.096390302 seconds. Throughput is 1327.9344 records/second. Loss is 1.9969993. Sequential266afc8b's hyper parameters: Current learning rate is 0.002183406113537118. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 360][Wall Clock 43.002249778s] Trained 128 records in 0.091042155 seconds. Throughput is 1405.9421 records/second. Loss is 2.022665. Sequential266afc8b's hyper parameters: Current learning rate is 0.002178649237472767. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46208/60000][Iteration 361][Wall Clock 43.094936577s] Trained 128 records in 0.092686799 seconds. Throughput is 1380.9949 records/second. Loss is 1.985652. Sequential266afc8b's hyper parameters: Current learning rate is 0.002173913043478261. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 362][Wall Clock 43.183331649s] Trained 128 records in 0.088395072 seconds. Throughput is 1448.0444 records/second. Loss is 1.9493525. Sequential266afc8b's hyper parameters: Current learning rate is 0.002169197396963124. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46464/60000][Iteration 363][Wall Clock 43.27124337s] Trained 128 records in 0.087911721 seconds. Throughput is 1456.0061 records/second. Loss is 2.0201194. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021645021645021645. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 364][Wall Clock 43.365526631s] Trained 128 records in 0.094283261 seconds. Throughput is 1357.6111 records/second. Loss is 2.0010438. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021598272138228943. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46720/60000][Iteration 365][Wall Clock 43.455231764s] Trained 128 records in 0.089705133 seconds. Throughput is 1426.8972 records/second. Loss is 1.9851605. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021551724137931034. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 366][Wall Clock 43.546263391s] Trained 128 records in 0.091031627 seconds. Throughput is 1406.1047 records/second. Loss is 1.9891968. Sequential266afc8b's hyper parameters: Current learning rate is 0.002150537634408602. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:01 INFO  DistriOptimizer$:408 - [Epoch 1 46976/60000][Iteration 367][Wall Clock 43.637844286s] Trained 128 records in 0.091580895 seconds. Throughput is 1397.6714 records/second. Loss is 1.9902205. Sequential266afc8b's hyper parameters: Current learning rate is 0.002145922746781116. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 368][Wall Clock 43.745545657s] Trained 128 records in 0.107701371 seconds. Throughput is 1188.4714 records/second. Loss is 1.9904708. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021413276231263384. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47232/60000][Iteration 369][Wall Clock 43.840617449s] Trained 128 records in 0.095071792 seconds. Throughput is 1346.351 records/second. Loss is 2.0003662. Sequential266afc8b's hyper parameters: Current learning rate is 0.002136752136752137. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 370][Wall Clock 43.927697529s] Trained 128 records in 0.08708008 seconds. Throughput is 1469.9114 records/second. Loss is 1.9871926. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021321961620469087. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47488/60000][Iteration 371][Wall Clock 44.020000113s] Trained 128 records in 0.092302584 seconds. Throughput is 1386.7434 records/second. Loss is 1.9498359. Sequential266afc8b's hyper parameters: Current learning rate is 0.002127659574468085. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 372][Wall Clock 44.112973545s] Trained 128 records in 0.092973432 seconds. Throughput is 1376.7374 records/second. Loss is 1.9586011. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021231422505307855. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47744/60000][Iteration 373][Wall Clock 44.214951155s] Trained 128 records in 0.10197761 seconds. Throughput is 1255.1775 records/second. Loss is 2.0178308. Sequential266afc8b's hyper parameters: Current learning rate is 0.0021186440677966097. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 374][Wall Clock 44.305805624s] Trained 128 records in 0.090854469 seconds. Throughput is 1408.8466 records/second. Loss is 2.0109437. Sequential266afc8b's hyper parameters: Current learning rate is 0.002114164904862579. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 48000/60000][Iteration 375][Wall Clock 44.397438153s] Trained 128 records in 0.091632529 seconds. Throughput is 1396.8838 records/second. Loss is 1.9711176. Sequential266afc8b's hyper parameters: Current learning rate is 0.002109704641350211. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 376][Wall Clock 44.502809139s] Trained 128 records in 0.105370986 seconds. Throughput is 1214.7556 records/second. Loss is 2.0011933. Sequential266afc8b's hyper parameters: Current learning rate is 0.002105263157894737. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:02 INFO  DistriOptimizer$:408 - [Epoch 1 48256/60000][Iteration 377][Wall Clock 44.608902293s] Trained 128 records in 0.106093154 seconds. Throughput is 1206.4869 records/second. Loss is 2.0385914. Sequential266afc8b's hyper parameters: Current learning rate is 0.002100840336134454. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 378][Wall Clock 44.707625304s] Trained 128 records in 0.098723011 seconds. Throughput is 1296.5569 records/second. Loss is 1.9767774. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020964360587002098. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 48512/60000][Iteration 379][Wall Clock 44.8031645s] Trained 128 records in 0.095539196 seconds. Throughput is 1339.7643 records/second. Loss is 1.9531393. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020920502092050207. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 380][Wall Clock 44.900410329s] Trained 128 records in 0.097245829 seconds. Throughput is 1316.2518 records/second. Loss is 1.9622173. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020876826722338207. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 48768/60000][Iteration 381][Wall Clock 44.99238439s] Trained 128 records in 0.091974061 seconds. Throughput is 1391.6967 records/second. Loss is 2.008126. Sequential266afc8b's hyper parameters: Current learning rate is 0.002083333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 382][Wall Clock 45.089287377s] Trained 128 records in 0.096902987 seconds. Throughput is 1320.9087 records/second. Loss is 1.9749539. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020790020790020787. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 49024/60000][Iteration 383][Wall Clock 45.193090696s] Trained 128 records in 0.103803319 seconds. Throughput is 1233.1012 records/second. Loss is 2.01379. Sequential266afc8b's hyper parameters: Current learning rate is 0.002074688796680498. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 384][Wall Clock 45.298824577s] Trained 128 records in 0.105733881 seconds. Throughput is 1210.5864 records/second. Loss is 1.9759748. Sequential266afc8b's hyper parameters: Current learning rate is 0.002070393374741201. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 49280/60000][Iteration 385][Wall Clock 45.393248733s] Trained 128 records in 0.094424156 seconds. Throughput is 1355.5853 records/second. Loss is 1.9761322. Sequential266afc8b's hyper parameters: Current learning rate is 0.002066115702479339. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 386][Wall Clock 45.483666399s] Trained 128 records in 0.090417666 seconds. Throughput is 1415.6525 records/second. Loss is 1.9314913. Sequential266afc8b's hyper parameters: Current learning rate is 0.002061855670103093. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:03 INFO  DistriOptimizer$:408 - [Epoch 1 49536/60000][Iteration 387][Wall Clock 45.574832248s] Trained 128 records in 0.091165849 seconds. Throughput is 1404.0345 records/second. Loss is 1.9737681. Sequential266afc8b's hyper parameters: Current learning rate is 0.00205761316872428. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 388][Wall Clock 45.665090365s] Trained 128 records in 0.090258117 seconds. Throughput is 1418.155 records/second. Loss is 1.9586662. Sequential266afc8b's hyper parameters: Current learning rate is 0.002053388090349076. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 49792/60000][Iteration 389][Wall Clock 45.755398461s] Trained 128 records in 0.090308096 seconds. Throughput is 1417.3702 records/second. Loss is 1.97369. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020491803278688526. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 390][Wall Clock 45.847629316s] Trained 128 records in 0.092230855 seconds. Throughput is 1387.8219 records/second. Loss is 1.9854907. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020449897750511245. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50048/60000][Iteration 391][Wall Clock 45.944178662s] Trained 128 records in 0.096549346 seconds. Throughput is 1325.747 records/second. Loss is 1.981629. Sequential266afc8b's hyper parameters: Current learning rate is 0.002040816326530612. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 392][Wall Clock 46.036744216s] Trained 128 records in 0.092565554 seconds. Throughput is 1382.8038 records/second. Loss is 1.9901983. Sequential266afc8b's hyper parameters: Current learning rate is 0.002036659877800407. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50304/60000][Iteration 393][Wall Clock 46.13913376s] Trained 128 records in 0.102389544 seconds. Throughput is 1250.1277 records/second. Loss is 2.0412066. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020325203252032522. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 394][Wall Clock 46.235816063s] Trained 128 records in 0.096682303 seconds. Throughput is 1323.9238 records/second. Loss is 1.9221228. Sequential266afc8b's hyper parameters: Current learning rate is 0.002028397565922921. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50560/60000][Iteration 395][Wall Clock 46.321616131s] Trained 128 records in 0.085800068 seconds. Throughput is 1491.8403 records/second. Loss is 1.9939743. Sequential266afc8b's hyper parameters: Current learning rate is 0.002024291497975709. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 396][Wall Clock 46.408211831s] Trained 128 records in 0.0865957 seconds. Throughput is 1478.1334 records/second. Loss is 1.9296982. Sequential266afc8b's hyper parameters: Current learning rate is 0.00202020202020202. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50816/60000][Iteration 397][Wall Clock 46.49805237s] Trained 128 records in 0.089840539 seconds. Throughput is 1424.7466 records/second. Loss is 1.9582655. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020161290322580645. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:04 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 398][Wall Clock 46.58970389s] Trained 128 records in 0.09165152 seconds. Throughput is 1396.5944 records/second. Loss is 1.9702883. Sequential266afc8b's hyper parameters: Current learning rate is 0.0020120724346076456. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51072/60000][Iteration 399][Wall Clock 46.683223026s] Trained 128 records in 0.093519136 seconds. Throughput is 1368.7039 records/second. Loss is 1.9709178. Sequential266afc8b's hyper parameters: Current learning rate is 0.002008032128514056. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 400][Wall Clock 46.77304702s] Trained 128 records in 0.089823994 seconds. Throughput is 1425.009 records/second. Loss is 1.9435164. Sequential266afc8b's hyper parameters: Current learning rate is 0.002004008016032064. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51328/60000][Iteration 401][Wall Clock 46.876849099s] Trained 128 records in 0.103802079 seconds. Throughput is 1233.116 records/second. Loss is 1.9391961. Sequential266afc8b's hyper parameters: Current learning rate is 0.002. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 402][Wall Clock 46.972091344s] Trained 128 records in 0.095242245 seconds. Throughput is 1343.9414 records/second. Loss is 1.9616907. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019960079840319364. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51584/60000][Iteration 403][Wall Clock 47.06440356s] Trained 128 records in 0.092312216 seconds. Throughput is 1386.5988 records/second. Loss is 1.9948391. Sequential266afc8b's hyper parameters: Current learning rate is 0.00199203187250996. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 404][Wall Clock 47.155529512s] Trained 128 records in 0.091125952 seconds. Throughput is 1404.6493 records/second. Loss is 1.9973698. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019880715705765406. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51840/60000][Iteration 405][Wall Clock 47.243846144s] Trained 128 records in 0.088316632 seconds. Throughput is 1449.3306 records/second. Loss is 1.9835955. Sequential266afc8b's hyper parameters: Current learning rate is 0.001984126984126984. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 406][Wall Clock 47.332038147s] Trained 128 records in 0.088192003 seconds. Throughput is 1451.3788 records/second. Loss is 1.9284313. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019801980198019802. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 52096/60000][Iteration 407][Wall Clock 47.425083409s] Trained 128 records in 0.093045262 seconds. Throughput is 1375.6746 records/second. Loss is 1.9398652. Sequential266afc8b's hyper parameters: Current learning rate is 0.001976284584980237. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 408][Wall Clock 47.519571856s] Trained 128 records in 0.094488447 seconds. Throughput is 1354.663 records/second. Loss is 1.9284046. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019723865877712033. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:05 INFO  DistriOptimizer$:408 - [Epoch 1 52352/60000][Iteration 409][Wall Clock 47.607559849s] Trained 128 records in 0.087987993 seconds. Throughput is 1454.7439 records/second. Loss is 1.9468493. Sequential266afc8b's hyper parameters: Current learning rate is 0.001968503937007874. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 410][Wall Clock 47.694545253s] Trained 128 records in 0.086985404 seconds. Throughput is 1471.5112 records/second. Loss is 1.9977579. Sequential266afc8b's hyper parameters: Current learning rate is 0.001964636542239686. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 52608/60000][Iteration 411][Wall Clock 47.782122093s] Trained 128 records in 0.08757684 seconds. Throughput is 1461.5737 records/second. Loss is 1.9657204. Sequential266afc8b's hyper parameters: Current learning rate is 0.00196078431372549. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 412][Wall Clock 47.901333s] Trained 128 records in 0.119210907 seconds. Throughput is 1073.7273 records/second. Loss is 1.9554089. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019569471624266144. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 52864/60000][Iteration 413][Wall Clock 47.996811274s] Trained 128 records in 0.095478274 seconds. Throughput is 1340.6191 records/second. Loss is 2.0007138. Sequential266afc8b's hyper parameters: Current learning rate is 0.001953125. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 414][Wall Clock 48.11087814s] Trained 128 records in 0.114066866 seconds. Throughput is 1122.1488 records/second. Loss is 1.9764556. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019493177387914231. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 53120/60000][Iteration 415][Wall Clock 48.225546361s] Trained 128 records in 0.114668221 seconds. Throughput is 1116.2639 records/second. Loss is 2.0069332. Sequential266afc8b's hyper parameters: Current learning rate is 0.001945525291828794. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 416][Wall Clock 48.336640925s] Trained 128 records in 0.111094564 seconds. Throughput is 1152.1716 records/second. Loss is 1.9846162. Sequential266afc8b's hyper parameters: Current learning rate is 0.001941747572815534. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 53376/60000][Iteration 417][Wall Clock 48.452655708s] Trained 128 records in 0.116014783 seconds. Throughput is 1103.3076 records/second. Loss is 1.9292196. Sequential266afc8b's hyper parameters: Current learning rate is 0.001937984496124031. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:06 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 418][Wall Clock 48.556018472s] Trained 128 records in 0.103362764 seconds. Throughput is 1238.357 records/second. Loss is 1.9511793. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019342359767891683. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 53632/60000][Iteration 419][Wall Clock 48.644647678s] Trained 128 records in 0.088629206 seconds. Throughput is 1444.2191 records/second. Loss is 1.9996101. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019305019305019305. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 420][Wall Clock 48.734307061s] Trained 128 records in 0.089659383 seconds. Throughput is 1427.6252 records/second. Loss is 1.940492. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019267822736030828. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 53888/60000][Iteration 421][Wall Clock 48.825417787s] Trained 128 records in 0.091110726 seconds. Throughput is 1404.8839 records/second. Loss is 1.9622074. Sequential266afc8b's hyper parameters: Current learning rate is 0.001923076923076923. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 422][Wall Clock 48.920460106s] Trained 128 records in 0.095042319 seconds. Throughput is 1346.7686 records/second. Loss is 1.9293226. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019193857965451057. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54144/60000][Iteration 423][Wall Clock 49.012378112s] Trained 128 records in 0.091918006 seconds. Throughput is 1392.5454 records/second. Loss is 1.9606082. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019157088122605365. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 424][Wall Clock 49.113467921s] Trained 128 records in 0.101089809 seconds. Throughput is 1266.2009 records/second. Loss is 1.9218245. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019120458891013384. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54400/60000][Iteration 425][Wall Clock 49.204531386s] Trained 128 records in 0.091063465 seconds. Throughput is 1405.6132 records/second. Loss is 1.9420296. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019083969465648854. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 426][Wall Clock 49.307418735s] Trained 128 records in 0.102887349 seconds. Throughput is 1244.0791 records/second. Loss is 1.9391747. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019047619047619048. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54656/60000][Iteration 427][Wall Clock 49.399697442s] Trained 128 records in 0.092278707 seconds. Throughput is 1387.1023 records/second. Loss is 1.9315974. Sequential266afc8b's hyper parameters: Current learning rate is 0.0019011406844106466. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 428][Wall Clock 49.484000851s] Trained 128 records in 0.084303409 seconds. Throughput is 1518.3253 records/second. Loss is 1.9509467. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018975332068311194. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:07 INFO  DistriOptimizer$:408 - [Epoch 1 54912/60000][Iteration 429][Wall Clock 49.600653659s] Trained 128 records in 0.116652808 seconds. Throughput is 1097.2732 records/second. Loss is 1.8840442. Sequential266afc8b's hyper parameters: Current learning rate is 0.001893939393939394. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 430][Wall Clock 49.691369773s] Trained 128 records in 0.090716114 seconds. Throughput is 1410.9951 records/second. Loss is 1.9492074. Sequential266afc8b's hyper parameters: Current learning rate is 0.001890359168241966. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55168/60000][Iteration 431][Wall Clock 49.781272822s] Trained 128 records in 0.089903049 seconds. Throughput is 1423.756 records/second. Loss is 1.8927002. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018867924528301887. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 432][Wall Clock 49.885741751s] Trained 128 records in 0.104468929 seconds. Throughput is 1225.2448 records/second. Loss is 1.9500982. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018832391713747645. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55424/60000][Iteration 433][Wall Clock 49.980150809s] Trained 128 records in 0.094409058 seconds. Throughput is 1355.8021 records/second. Loss is 1.986515. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018796992481203006. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 434][Wall Clock 50.076164778s] Trained 128 records in 0.096013969 seconds. Throughput is 1333.1393 records/second. Loss is 1.9000765. Sequential266afc8b's hyper parameters: Current learning rate is 0.001876172607879925. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55680/60000][Iteration 435][Wall Clock 50.166819626s] Trained 128 records in 0.090654848 seconds. Throughput is 1411.9487 records/second. Loss is 1.9342304. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018726591760299626. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 436][Wall Clock 50.257351416s] Trained 128 records in 0.09053179 seconds. Throughput is 1413.868 records/second. Loss is 1.9075655. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018691588785046728. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 55936/60000][Iteration 437][Wall Clock 50.348964173s] Trained 128 records in 0.091612757 seconds. Throughput is 1397.1853 records/second. Loss is 1.9219168. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018656716417910447. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 438][Wall Clock 50.458031992s] Trained 128 records in 0.109067819 seconds. Throughput is 1173.5817 records/second. Loss is 1.9425349. Sequential266afc8b's hyper parameters: Current learning rate is 0.00186219739292365. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:08 INFO  DistriOptimizer$:408 - [Epoch 1 56192/60000][Iteration 439][Wall Clock 50.553362633s] Trained 128 records in 0.095330641 seconds. Throughput is 1342.6953 records/second. Loss is 1.924854. Sequential266afc8b's hyper parameters: Current learning rate is 0.001858736059479554. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 440][Wall Clock 50.643357801s] Trained 128 records in 0.089995168 seconds. Throughput is 1422.2986 records/second. Loss is 1.9370269. Sequential266afc8b's hyper parameters: Current learning rate is 0.001855287569573284. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 56448/60000][Iteration 441][Wall Clock 50.732598784s] Trained 128 records in 0.089240983 seconds. Throughput is 1434.3186 records/second. Loss is 1.9619018. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018518518518518517. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 442][Wall Clock 50.824117102s] Trained 128 records in 0.091518318 seconds. Throughput is 1398.6271 records/second. Loss is 1.9195064. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018484288354898336. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 56704/60000][Iteration 443][Wall Clock 50.935744595s] Trained 128 records in 0.111627493 seconds. Throughput is 1146.6709 records/second. Loss is 1.967572. Sequential266afc8b's hyper parameters: Current learning rate is 0.001845018450184502. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 444][Wall Clock 51.031126661s] Trained 128 records in 0.095382066 seconds. Throughput is 1341.9713 records/second. Loss is 1.8862242. Sequential266afc8b's hyper parameters: Current learning rate is 0.001841620626151013. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 56960/60000][Iteration 445][Wall Clock 51.130587717s] Trained 128 records in 0.099461056 seconds. Throughput is 1286.9359 records/second. Loss is 1.9375892. Sequential266afc8b's hyper parameters: Current learning rate is 0.001838235294117647. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 446][Wall Clock 51.217923989s] Trained 128 records in 0.087336272 seconds. Throughput is 1465.5995 records/second. Loss is 1.9793077. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018348623853211008. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 57216/60000][Iteration 447][Wall Clock 51.304650338s] Trained 128 records in 0.086726349 seconds. Throughput is 1475.9066 records/second. Loss is 1.9904011. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018315018315018315. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 448][Wall Clock 51.397446863s] Trained 128 records in 0.092796525 seconds. Throughput is 1379.3619 records/second. Loss is 1.8602645. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018281535648994518. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 57472/60000][Iteration 449][Wall Clock 51.493263114s] Trained 128 records in 0.095816251 seconds. Throughput is 1335.8903 records/second. Loss is 1.9665838. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018248175182481751. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:09 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 450][Wall Clock 51.587017646s] Trained 128 records in 0.093754532 seconds. Throughput is 1365.2673 records/second. Loss is 1.8995721. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018214936247723133. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 57728/60000][Iteration 451][Wall Clock 51.688450525s] Trained 128 records in 0.101432879 seconds. Throughput is 1261.9182 records/second. Loss is 1.9412558. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018181818181818182. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 452][Wall Clock 51.781723324s] Trained 128 records in 0.093272799 seconds. Throughput is 1372.3186 records/second. Loss is 1.8853322. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018148820326678767. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 57984/60000][Iteration 453][Wall Clock 51.877008789s] Trained 128 records in 0.095285465 seconds. Throughput is 1343.3318 records/second. Loss is 1.9126915. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018115942028985505. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 454][Wall Clock 51.968238079s] Trained 128 records in 0.09122929 seconds. Throughput is 1403.0581 records/second. Loss is 1.9056025. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018083182640144665. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58240/60000][Iteration 455][Wall Clock 52.070630358s] Trained 128 records in 0.102392279 seconds. Throughput is 1250.0942 records/second. Loss is 1.9553132. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018050541516245488. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 456][Wall Clock 52.15936253s] Trained 128 records in 0.088732172 seconds. Throughput is 1442.5432 records/second. Loss is 1.9105598. Sequential266afc8b's hyper parameters: Current learning rate is 0.0018018018018018018. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58496/60000][Iteration 457][Wall Clock 52.251897559s] Trained 128 records in 0.092535029 seconds. Throughput is 1383.26 records/second. Loss is 1.9069239. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017985611510791366. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 458][Wall Clock 52.3410688s] Trained 128 records in 0.089171241 seconds. Throughput is 1435.4404 records/second. Loss is 1.9252917. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017953321364452422. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58752/60000][Iteration 459][Wall Clock 52.434471284s] Trained 128 records in 0.093402484 seconds. Throughput is 1370.4132 records/second. Loss is 1.9101614. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017921146953405018. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:10 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 460][Wall Clock 52.524796068s] Trained 128 records in 0.090324784 seconds. Throughput is 1417.1083 records/second. Loss is 1.9009792. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017889087656529517. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59008/60000][Iteration 461][Wall Clock 52.61789395s] Trained 128 records in 0.093097882 seconds. Throughput is 1374.8971 records/second. Loss is 1.9661325. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017857142857142857. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 462][Wall Clock 52.718631156s] Trained 128 records in 0.100737206 seconds. Throughput is 1270.6328 records/second. Loss is 1.9189712. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017825311942959. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59264/60000][Iteration 463][Wall Clock 52.812572593s] Trained 128 records in 0.093941437 seconds. Throughput is 1362.551 records/second. Loss is 1.9001784. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017793594306049821. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 464][Wall Clock 52.911086075s] Trained 128 records in 0.098513482 seconds. Throughput is 1299.3146 records/second. Loss is 1.932145. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017761989342806395. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59520/60000][Iteration 465][Wall Clock 53.00389029s] Trained 128 records in 0.092804215 seconds. Throughput is 1379.2477 records/second. Loss is 1.8976235. Sequential266afc8b's hyper parameters: Current learning rate is 0.001773049645390071. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 466][Wall Clock 53.101617528s] Trained 128 records in 0.097727238 seconds. Throughput is 1309.768 records/second. Loss is 1.9269674. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017699115044247787. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59776/60000][Iteration 467][Wall Clock 53.19208826s] Trained 128 records in 0.090470732 seconds. Throughput is 1414.8223 records/second. Loss is 1.8952174. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017667844522968198. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 468][Wall Clock 53.297437798s] Trained 128 records in 0.105349538 seconds. Throughput is 1215.0029 records/second. Loss is 1.9139613. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017636684303350971. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:408 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 53.389791265s] Trained 128 records in 0.092353467 seconds. Throughput is 1385.9794 records/second. Loss is 1.866708. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017605633802816902. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:11 INFO  DistriOptimizer$:452 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 53.389791265s] Epoch finished. Wall clock time is 53732.484995 ms
2019-10-15 08:19:11 INFO  DistriOptimizer$:111 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 53.389791265s] Validate model...
2019-10-15 08:19:12 INFO  DistriOptimizer$:178 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 53.389791265s] validate model throughput is 9576.85 records/second
2019-10-15 08:19:12 INFO  DistriOptimizer$:181 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 53.389791265s] Top1Accuracy is Accuracy(correct: 5834, count: 10000, accuracy: 0.5834)
2019-10-15 08:19:12 INFO  DistriOptimizer$:221 - [Wall Clock 53.732484995s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:19:13 INFO  DistriOptimizer$:226 - [Wall Clock 53.732484995s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 128/60000][Iteration 470][Wall Clock 53.877074741s] Trained 128 records in 0.144589746 seconds. Throughput is 885.2633 records/second. Loss is 1.9062526. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017574692442882249. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 471][Wall Clock 53.983631283s] Trained 128 records in 0.106556542 seconds. Throughput is 1201.2402 records/second. Loss is 1.906761. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017543859649122807. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 384/60000][Iteration 472][Wall Clock 54.084090598s] Trained 128 records in 0.100459315 seconds. Throughput is 1274.1477 records/second. Loss is 1.9305499. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017513134851138354. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 473][Wall Clock 54.189814158s] Trained 128 records in 0.10572356 seconds. Throughput is 1210.7046 records/second. Loss is 1.8413864. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017482517482517485. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 640/60000][Iteration 474][Wall Clock 54.306214633s] Trained 128 records in 0.116400475 seconds. Throughput is 1099.6519 records/second. Loss is 1.9156396. Sequential266afc8b's hyper parameters: Current learning rate is 0.001745200698080279. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 475][Wall Clock 54.403590938s] Trained 128 records in 0.097376305 seconds. Throughput is 1314.4882 records/second. Loss is 1.8542359. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017421602787456446. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 896/60000][Iteration 476][Wall Clock 54.500630754s] Trained 128 records in 0.097039816 seconds. Throughput is 1319.0461 records/second. Loss is 1.9046572. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017391304347826088. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 477][Wall Clock 54.601365291s] Trained 128 records in 0.100734537 seconds. Throughput is 1270.6665 records/second. Loss is 1.8855288. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017361111111111112. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:13 INFO  DistriOptimizer$:408 - [Epoch 2 1152/60000][Iteration 478][Wall Clock 54.697329573s] Trained 128 records in 0.095964282 seconds. Throughput is 1333.8296 records/second. Loss is 1.9005082. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017331022530329288. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 479][Wall Clock 54.800531634s] Trained 128 records in 0.103202061 seconds. Throughput is 1240.2853 records/second. Loss is 1.905429. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017301038062283738. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 1408/60000][Iteration 480][Wall Clock 54.897916011s] Trained 128 records in 0.097384377 seconds. Throughput is 1314.3792 records/second. Loss is 1.8862257. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017271157167530224. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 481][Wall Clock 54.994101412s] Trained 128 records in 0.096185401 seconds. Throughput is 1330.7633 records/second. Loss is 1.8608918. Sequential266afc8b's hyper parameters: Current learning rate is 0.001724137931034483. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 1664/60000][Iteration 482][Wall Clock 55.086079049s] Trained 128 records in 0.091977637 seconds. Throughput is 1391.6427 records/second. Loss is 1.8932405. Sequential266afc8b's hyper parameters: Current learning rate is 0.001721170395869191. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 483][Wall Clock 55.182176826s] Trained 128 records in 0.096097777 seconds. Throughput is 1331.9767 records/second. Loss is 1.951018. Sequential266afc8b's hyper parameters: Current learning rate is 0.001718213058419244. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 1920/60000][Iteration 484][Wall Clock 55.278796892s] Trained 128 records in 0.096620066 seconds. Throughput is 1324.7765 records/second. Loss is 1.856114. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017152658662092624. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 485][Wall Clock 55.376886338s] Trained 128 records in 0.098089446 seconds. Throughput is 1304.9314 records/second. Loss is 1.8684471. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017123287671232878. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 2176/60000][Iteration 486][Wall Clock 55.476642352s] Trained 128 records in 0.099756014 seconds. Throughput is 1283.1306 records/second. Loss is 1.9135761. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017094017094017092. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 487][Wall Clock 55.567512498s] Trained 128 records in 0.090870146 seconds. Throughput is 1408.6034 records/second. Loss is 1.8489414. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017064846416382253. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:14 INFO  DistriOptimizer$:408 - [Epoch 2 2432/60000][Iteration 488][Wall Clock 55.659743638s] Trained 128 records in 0.09223114 seconds. Throughput is 1387.8176 records/second. Loss is 1.8794702. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017035775127768314. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 489][Wall Clock 55.758145105s] Trained 128 records in 0.098401467 seconds. Throughput is 1300.7937 records/second. Loss is 1.8597028. Sequential266afc8b's hyper parameters: Current learning rate is 0.0017006802721088437. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 2688/60000][Iteration 490][Wall Clock 55.85338527s] Trained 128 records in 0.095240165 seconds. Throughput is 1343.9707 records/second. Loss is 1.89273. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016977928692699493. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 491][Wall Clock 55.957153575s] Trained 128 records in 0.103768305 seconds. Throughput is 1233.5173 records/second. Loss is 1.9132222. Sequential266afc8b's hyper parameters: Current learning rate is 0.001694915254237288. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 2944/60000][Iteration 492][Wall Clock 56.050055783s] Trained 128 records in 0.092902208 seconds. Throughput is 1377.7928 records/second. Loss is 1.9516993. Sequential266afc8b's hyper parameters: Current learning rate is 0.001692047377326565. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 493][Wall Clock 56.147123293s] Trained 128 records in 0.09706751 seconds. Throughput is 1318.6698 records/second. Loss is 1.8834392. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016891891891891893. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 3200/60000][Iteration 494][Wall Clock 56.244116954s] Trained 128 records in 0.096993661 seconds. Throughput is 1319.6738 records/second. Loss is 1.8830836. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016863406408094436. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 495][Wall Clock 56.351022422s] Trained 128 records in 0.106905468 seconds. Throughput is 1197.3195 records/second. Loss is 1.9156379. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016835016835016834. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 3456/60000][Iteration 496][Wall Clock 56.468012137s] Trained 128 records in 0.116989715 seconds. Throughput is 1094.1133 records/second. Loss is 1.9160268. Sequential266afc8b's hyper parameters: Current learning rate is 0.001680672268907563. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 497][Wall Clock 56.565920896s] Trained 128 records in 0.097908759 seconds. Throughput is 1307.3396 records/second. Loss is 1.8201456. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016778523489932886. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:15 INFO  DistriOptimizer$:408 - [Epoch 2 3712/60000][Iteration 498][Wall Clock 56.673860877s] Trained 128 records in 0.107939981 seconds. Throughput is 1185.8442 records/second. Loss is 1.9096514. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016750418760469012. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 499][Wall Clock 56.764463136s] Trained 128 records in 0.090602259 seconds. Throughput is 1412.7683 records/second. Loss is 1.8377775. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016722408026755853. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 3968/60000][Iteration 500][Wall Clock 56.862167683s] Trained 128 records in 0.097704547 seconds. Throughput is 1310.0721 records/second. Loss is 1.9339832. Sequential266afc8b's hyper parameters: Current learning rate is 0.001669449081803005. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 501][Wall Clock 56.955631447s] Trained 128 records in 0.093463764 seconds. Throughput is 1369.5148 records/second. Loss is 1.9056219. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016666666666666668. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4224/60000][Iteration 502][Wall Clock 57.050624675s] Trained 128 records in 0.094993228 seconds. Throughput is 1347.4645 records/second. Loss is 1.9142371. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016638935108153079. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 503][Wall Clock 57.145122632s] Trained 128 records in 0.094497957 seconds. Throughput is 1354.5266 records/second. Loss is 1.8139986. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016611295681063121. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4480/60000][Iteration 504][Wall Clock 57.23973626s] Trained 128 records in 0.094613628 seconds. Throughput is 1352.8706 records/second. Loss is 1.9085206. Sequential266afc8b's hyper parameters: Current learning rate is 0.001658374792703151. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 505][Wall Clock 57.333603685s] Trained 128 records in 0.093867425 seconds. Throughput is 1363.6252 records/second. Loss is 1.9029363. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016556291390728477. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4736/60000][Iteration 506][Wall Clock 57.43399073s] Trained 128 records in 0.100387045 seconds. Throughput is 1275.065 records/second. Loss is 1.9022608. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016528925619834713. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 507][Wall Clock 57.527032397s] Trained 128 records in 0.093041667 seconds. Throughput is 1375.7278 records/second. Loss is 1.8419714. Sequential266afc8b's hyper parameters: Current learning rate is 0.00165016501650165. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:16 INFO  DistriOptimizer$:408 - [Epoch 2 4992/60000][Iteration 508][Wall Clock 57.621327948s] Trained 128 records in 0.094295551 seconds. Throughput is 1357.4341 records/second. Loss is 1.8400329. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016474464579901153. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 509][Wall Clock 57.72197963s] Trained 128 records in 0.100651682 seconds. Throughput is 1271.7125 records/second. Loss is 1.8678267. Sequential266afc8b's hyper parameters: Current learning rate is 0.001644736842105263. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5248/60000][Iteration 510][Wall Clock 57.815588982s] Trained 128 records in 0.093609352 seconds. Throughput is 1367.3846 records/second. Loss is 1.9485929. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016420361247947456. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 511][Wall Clock 57.908386134s] Trained 128 records in 0.092797152 seconds. Throughput is 1379.3527 records/second. Loss is 1.8539313. Sequential266afc8b's hyper parameters: Current learning rate is 0.001639344262295082. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5504/60000][Iteration 512][Wall Clock 58.013014949s] Trained 128 records in 0.104628815 seconds. Throughput is 1223.3723 records/second. Loss is 1.869018. Sequential266afc8b's hyper parameters: Current learning rate is 0.001636661211129296. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 513][Wall Clock 58.103962858s] Trained 128 records in 0.090947909 seconds. Throughput is 1407.399 records/second. Loss is 1.8666643. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016339869281045752. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5760/60000][Iteration 514][Wall Clock 58.19712951s] Trained 128 records in 0.093166652 seconds. Throughput is 1373.8822 records/second. Loss is 1.887223. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016313213703099511. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 515][Wall Clock 58.293869388s] Trained 128 records in 0.096739878 seconds. Throughput is 1323.1359 records/second. Loss is 1.7964649. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016286644951140066. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 6016/60000][Iteration 516][Wall Clock 58.381609813s] Trained 128 records in 0.087740425 seconds. Throughput is 1458.8488 records/second. Loss is 1.8917792. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016260162601626016. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 517][Wall Clock 58.478444639s] Trained 128 records in 0.096834826 seconds. Throughput is 1321.8385 records/second. Loss is 1.7893375. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016233766233766233. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 6272/60000][Iteration 518][Wall Clock 58.570321084s] Trained 128 records in 0.091876445 seconds. Throughput is 1393.1753 records/second. Loss is 1.8994963. Sequential266afc8b's hyper parameters: Current learning rate is 0.001620745542949757. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:17 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 519][Wall Clock 58.660133406s] Trained 128 records in 0.089812322 seconds. Throughput is 1425.1942 records/second. Loss is 1.8523244. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016181229773462784. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 6528/60000][Iteration 520][Wall Clock 58.75306759s] Trained 128 records in 0.092934184 seconds. Throughput is 1377.3188 records/second. Loss is 1.8810877. Sequential266afc8b's hyper parameters: Current learning rate is 0.001615508885298869. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 521][Wall Clock 58.849095103s] Trained 128 records in 0.096027513 seconds. Throughput is 1332.9513 records/second. Loss is 1.8963871. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016129032258064516. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 6784/60000][Iteration 522][Wall Clock 58.943527207s] Trained 128 records in 0.094432104 seconds. Throughput is 1355.4713 records/second. Loss is 1.9172419. Sequential266afc8b's hyper parameters: Current learning rate is 0.001610305958132045. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 523][Wall Clock 59.049213869s] Trained 128 records in 0.105686662 seconds. Throughput is 1211.1272 records/second. Loss is 1.8312181. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016077170418006433. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 7040/60000][Iteration 524][Wall Clock 59.147128126s] Trained 128 records in 0.097914257 seconds. Throughput is 1307.2662 records/second. Loss is 1.8461972. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016051364365971107. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 525][Wall Clock 59.24021148s] Trained 128 records in 0.093083354 seconds. Throughput is 1375.1117 records/second. Loss is 1.8591882. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016025641025641025. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 7296/60000][Iteration 526][Wall Clock 59.335229376s] Trained 128 records in 0.095017896 seconds. Throughput is 1347.1146 records/second. Loss is 1.7948663. Sequential266afc8b's hyper parameters: Current learning rate is 0.0016. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 527][Wall Clock 59.434658498s] Trained 128 records in 0.099429122 seconds. Throughput is 1287.3491 records/second. Loss is 1.852808. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015974440894568692. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 7552/60000][Iteration 528][Wall Clock 59.527107269s] Trained 128 records in 0.092448771 seconds. Throughput is 1384.5505 records/second. Loss is 1.8981572. Sequential266afc8b's hyper parameters: Current learning rate is 0.001594896331738437. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:18 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 529][Wall Clock 59.621370113s] Trained 128 records in 0.094262844 seconds. Throughput is 1357.9052 records/second. Loss is 1.852574. Sequential266afc8b's hyper parameters: Current learning rate is 0.001592356687898089. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 7808/60000][Iteration 530][Wall Clock 59.715819362s] Trained 128 records in 0.094449249 seconds. Throughput is 1355.2251 records/second. Loss is 1.8613745. Sequential266afc8b's hyper parameters: Current learning rate is 0.001589825119236884. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 531][Wall Clock 59.811023694s] Trained 128 records in 0.095204332 seconds. Throughput is 1344.4767 records/second. Loss is 1.875387. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015873015873015873. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8064/60000][Iteration 532][Wall Clock 59.906644561s] Trained 128 records in 0.095620867 seconds. Throughput is 1338.6199 records/second. Loss is 1.8874812. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015847860538827257. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 533][Wall Clock 60.013680915s] Trained 128 records in 0.107036354 seconds. Throughput is 1195.8553 records/second. Loss is 1.8978344. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015822784810126582. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8320/60000][Iteration 534][Wall Clock 60.125799108s] Trained 128 records in 0.112118193 seconds. Throughput is 1141.6523 records/second. Loss is 1.8629299. Sequential266afc8b's hyper parameters: Current learning rate is 0.001579778830963665. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 535][Wall Clock 60.23059883s] Trained 128 records in 0.104799722 seconds. Throughput is 1221.3772 records/second. Loss is 1.8558137. Sequential266afc8b's hyper parameters: Current learning rate is 0.001577287066246057. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8576/60000][Iteration 536][Wall Clock 60.324174982s] Trained 128 records in 0.093576152 seconds. Throughput is 1367.8699 records/second. Loss is 1.8526341. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015748031496062992. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 537][Wall Clock 60.422728187s] Trained 128 records in 0.098553205 seconds. Throughput is 1298.7909 records/second. Loss is 1.8840072. Sequential266afc8b's hyper parameters: Current learning rate is 0.001572327044025157. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8832/60000][Iteration 538][Wall Clock 60.523365091s] Trained 128 records in 0.100636904 seconds. Throughput is 1271.8992 records/second. Loss is 1.7982852. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015698587127158557. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:19 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 539][Wall Clock 60.618069911s] Trained 128 records in 0.09470482 seconds. Throughput is 1351.5679 records/second. Loss is 1.880829. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015673981191222572. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9088/60000][Iteration 540][Wall Clock 60.719515452s] Trained 128 records in 0.101445541 seconds. Throughput is 1261.7607 records/second. Loss is 1.8230292. Sequential266afc8b's hyper parameters: Current learning rate is 0.001564945226917058. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 541][Wall Clock 60.809440116s] Trained 128 records in 0.089924664 seconds. Throughput is 1423.4137 records/second. Loss is 1.7812136. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015624999999999999. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9344/60000][Iteration 542][Wall Clock 60.913695354s] Trained 128 records in 0.104255238 seconds. Throughput is 1227.7561 records/second. Loss is 1.8484092. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015600624024961. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 543][Wall Clock 61.035375781s] Trained 128 records in 0.121680427 seconds. Throughput is 1051.9358 records/second. Loss is 1.8809713. Sequential266afc8b's hyper parameters: Current learning rate is 0.001557632398753894. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9600/60000][Iteration 544][Wall Clock 61.137196959s] Trained 128 records in 0.101821178 seconds. Throughput is 1257.1058 records/second. Loss is 1.8016984. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015552099533437014. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 545][Wall Clock 61.231745435s] Trained 128 records in 0.094548476 seconds. Throughput is 1353.8029 records/second. Loss is 1.913421. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015527950310559005. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9856/60000][Iteration 546][Wall Clock 61.323630551s] Trained 128 records in 0.091885116 seconds. Throughput is 1393.0438 records/second. Loss is 1.8788161. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015503875968992248. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 547][Wall Clock 61.438831464s] Trained 128 records in 0.115200913 seconds. Throughput is 1111.1023 records/second. Loss is 1.8130519. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015479876160990713. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 10112/60000][Iteration 548][Wall Clock 61.548187108s] Trained 128 records in 0.109355644 seconds. Throughput is 1170.4929 records/second. Loss is 1.816564. Sequential266afc8b's hyper parameters: Current learning rate is 0.001545595054095827. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:20 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 549][Wall Clock 61.653378819s] Trained 128 records in 0.105191711 seconds. Throughput is 1216.8259 records/second. Loss is 1.8586262. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015432098765432098. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 10368/60000][Iteration 550][Wall Clock 61.747710365s] Trained 128 records in 0.094331546 seconds. Throughput is 1356.9161 records/second. Loss is 1.897827. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015408320493066256. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 551][Wall Clock 61.848890123s] Trained 128 records in 0.101179758 seconds. Throughput is 1265.0752 records/second. Loss is 1.8734226. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015384615384615385. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 10624/60000][Iteration 552][Wall Clock 61.941479623s] Trained 128 records in 0.0925895 seconds. Throughput is 1382.4462 records/second. Loss is 1.8515158. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015360983102918587. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 553][Wall Clock 62.032019174s] Trained 128 records in 0.090539551 seconds. Throughput is 1413.7468 records/second. Loss is 1.8414713. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015337423312883434. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 10880/60000][Iteration 554][Wall Clock 62.12318147s] Trained 128 records in 0.091162296 seconds. Throughput is 1404.0892 records/second. Loss is 1.8338447. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015313935681470138. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 555][Wall Clock 62.211806179s] Trained 128 records in 0.088624709 seconds. Throughput is 1444.2925 records/second. Loss is 1.8812625. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015290519877675841. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 11136/60000][Iteration 556][Wall Clock 62.305089928s] Trained 128 records in 0.093283749 seconds. Throughput is 1372.1575 records/second. Loss is 1.8117841. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015267175572519084. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 557][Wall Clock 62.415952037s] Trained 128 records in 0.110862109 seconds. Throughput is 1154.5875 records/second. Loss is 1.7884009. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015243902439024389. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 11392/60000][Iteration 558][Wall Clock 62.511496543s] Trained 128 records in 0.095544506 seconds. Throughput is 1339.6897 records/second. Loss is 1.8271377. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015220700152207. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:21 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 559][Wall Clock 62.600785068s] Trained 128 records in 0.089288525 seconds. Throughput is 1433.5548 records/second. Loss is 1.8746088. Sequential266afc8b's hyper parameters: Current learning rate is 0.001519756838905775. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 11648/60000][Iteration 560][Wall Clock 62.721226483s] Trained 128 records in 0.120441415 seconds. Throughput is 1062.7573 records/second. Loss is 1.8612347. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015174506828528073. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 561][Wall Clock 62.812682459s] Trained 128 records in 0.091455976 seconds. Throughput is 1399.5806 records/second. Loss is 1.8212006. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015151515151515152. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 11904/60000][Iteration 562][Wall Clock 62.905245731s] Trained 128 records in 0.092563272 seconds. Throughput is 1382.8379 records/second. Loss is 1.8360356. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015128593040847202. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 563][Wall Clock 62.996984467s] Trained 128 records in 0.091738736 seconds. Throughput is 1395.2666 records/second. Loss is 1.8361292. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015105740181268882. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12160/60000][Iteration 564][Wall Clock 63.096856776s] Trained 128 records in 0.099872309 seconds. Throughput is 1281.6366 records/second. Loss is 1.8438424. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015082956259426848. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 565][Wall Clock 63.194734729s] Trained 128 records in 0.097877953 seconds. Throughput is 1307.7511 records/second. Loss is 1.8612388. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015060240963855422. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12416/60000][Iteration 566][Wall Clock 63.287150243s] Trained 128 records in 0.092415514 seconds. Throughput is 1385.0488 records/second. Loss is 1.8873191. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015037593984962405. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 567][Wall Clock 63.379154981s] Trained 128 records in 0.092004738 seconds. Throughput is 1391.2327 records/second. Loss is 1.8268158. Sequential266afc8b's hyper parameters: Current learning rate is 0.0015015015015015015. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12672/60000][Iteration 568][Wall Clock 63.471865056s] Trained 128 records in 0.092710075 seconds. Throughput is 1380.6482 records/second. Loss is 1.8368453. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014992503748125937. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 569][Wall Clock 63.564137329s] Trained 128 records in 0.092272273 seconds. Throughput is 1387.199 records/second. Loss is 1.8991586. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014970059880239522. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:22 INFO  DistriOptimizer$:408 - [Epoch 2 12928/60000][Iteration 570][Wall Clock 63.65920335s] Trained 128 records in 0.095066021 seconds. Throughput is 1346.4327 records/second. Loss is 1.8108895. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014947683109118087. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 571][Wall Clock 63.752407305s] Trained 128 records in 0.093203955 seconds. Throughput is 1373.3323 records/second. Loss is 1.8352919. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014925373134328358. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13184/60000][Iteration 572][Wall Clock 63.848927163s] Trained 128 records in 0.096519858 seconds. Throughput is 1326.152 records/second. Loss is 1.867886. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014903129657228018. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 573][Wall Clock 63.942331079s] Trained 128 records in 0.093403916 seconds. Throughput is 1370.3922 records/second. Loss is 1.8553826. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014880952380952382. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13440/60000][Iteration 574][Wall Clock 64.03247389s] Trained 128 records in 0.090142811 seconds. Throughput is 1419.9691 records/second. Loss is 1.8555852. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014858841010401188. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 575][Wall Clock 64.12559104s] Trained 128 records in 0.09311715 seconds. Throughput is 1374.6125 records/second. Loss is 1.829491. Sequential266afc8b's hyper parameters: Current learning rate is 0.001483679525222552. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13696/60000][Iteration 576][Wall Clock 64.216096589s] Trained 128 records in 0.090505549 seconds. Throughput is 1414.278 records/second. Loss is 1.8882519. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014814814814814814. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 577][Wall Clock 64.306318574s] Trained 128 records in 0.090221985 seconds. Throughput is 1418.7229 records/second. Loss is 1.7735332. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014792899408284025. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 13952/60000][Iteration 578][Wall Clock 64.39643683s] Trained 128 records in 0.090118256 seconds. Throughput is 1420.3558 records/second. Loss is 1.744489. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014771048744460856. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 579][Wall Clock 64.488013389s] Trained 128 records in 0.091576559 seconds. Throughput is 1397.7375 records/second. Loss is 1.7519772. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014749262536873156. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:23 INFO  DistriOptimizer$:408 - [Epoch 2 14208/60000][Iteration 580][Wall Clock 64.576890586s] Trained 128 records in 0.088877197 seconds. Throughput is 1440.1895 records/second. Loss is 1.8313028. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014727540500736377. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 581][Wall Clock 64.663756729s] Trained 128 records in 0.086866143 seconds. Throughput is 1473.5316 records/second. Loss is 1.8391186. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014705882352941176. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 14464/60000][Iteration 582][Wall Clock 64.755086004s] Trained 128 records in 0.091329275 seconds. Throughput is 1401.5221 records/second. Loss is 1.837432. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014684287812041115. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 583][Wall Clock 64.851952112s] Trained 128 records in 0.096866108 seconds. Throughput is 1321.4116 records/second. Loss is 1.9070152. Sequential266afc8b's hyper parameters: Current learning rate is 0.001466275659824047. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 14720/60000][Iteration 584][Wall Clock 64.941674932s] Trained 128 records in 0.08972282 seconds. Throughput is 1426.6158 records/second. Loss is 1.831511. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014641288433382138. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 585][Wall Clock 65.032828699s] Trained 128 records in 0.091153767 seconds. Throughput is 1404.2206 records/second. Loss is 1.8539033. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014619883040935674. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 14976/60000][Iteration 586][Wall Clock 65.121353896s] Trained 128 records in 0.088525197 seconds. Throughput is 1445.916 records/second. Loss is 1.8922843. Sequential266afc8b's hyper parameters: Current learning rate is 0.00145985401459854. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 587][Wall Clock 65.214829004s] Trained 128 records in 0.093475108 seconds. Throughput is 1369.3485 records/second. Loss is 1.8045566. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014577259475218659. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 15232/60000][Iteration 588][Wall Clock 65.304319474s] Trained 128 records in 0.08949047 seconds. Throughput is 1430.3198 records/second. Loss is 1.8181573. Sequential266afc8b's hyper parameters: Current learning rate is 0.001455604075691412. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 589][Wall Clock 65.394589443s] Trained 128 records in 0.090269969 seconds. Throughput is 1417.9689 records/second. Loss is 1.8799379. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014534883720930232. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 15488/60000][Iteration 590][Wall Clock 65.500043922s] Trained 128 records in 0.105454479 seconds. Throughput is 1213.7938 records/second. Loss is 1.864215. Sequential266afc8b's hyper parameters: Current learning rate is 0.001451378809869376. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:24 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 591][Wall Clock 65.621074889s] Trained 128 records in 0.121030967 seconds. Throughput is 1057.5806 records/second. Loss is 1.7777834. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014492753623188406. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 15744/60000][Iteration 592][Wall Clock 65.712575692s] Trained 128 records in 0.091500803 seconds. Throughput is 1398.8948 records/second. Loss is 1.8417435. Sequential266afc8b's hyper parameters: Current learning rate is 0.001447178002894356. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 593][Wall Clock 65.809069318s] Trained 128 records in 0.096493626 seconds. Throughput is 1326.5126 records/second. Loss is 1.8323218. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014450867052023123. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16000/60000][Iteration 594][Wall Clock 65.898832498s] Trained 128 records in 0.08976318 seconds. Throughput is 1425.9745 records/second. Loss is 1.8040234. Sequential266afc8b's hyper parameters: Current learning rate is 0.001443001443001443. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 595][Wall Clock 65.989350253s] Trained 128 records in 0.090517755 seconds. Throughput is 1414.0873 records/second. Loss is 1.8114831. Sequential266afc8b's hyper parameters: Current learning rate is 0.001440922190201729. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16256/60000][Iteration 596][Wall Clock 66.078609985s] Trained 128 records in 0.089259732 seconds. Throughput is 1434.0173 records/second. Loss is 1.8616666. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014388489208633094. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 597][Wall Clock 66.170193617s] Trained 128 records in 0.091583632 seconds. Throughput is 1397.6296 records/second. Loss is 1.8161428. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014367816091954023. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16512/60000][Iteration 598][Wall Clock 66.275587526s] Trained 128 records in 0.105393909 seconds. Throughput is 1214.4915 records/second. Loss is 1.8545872. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014347202295552368. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 599][Wall Clock 66.370158381s] Trained 128 records in 0.094570855 seconds. Throughput is 1353.4825 records/second. Loss is 1.7318519. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014326647564469914. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16768/60000][Iteration 600][Wall Clock 66.459431665s] Trained 128 records in 0.089273284 seconds. Throughput is 1433.7997 records/second. Loss is 1.8577578. Sequential266afc8b's hyper parameters: Current learning rate is 0.001430615164520744. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 601][Wall Clock 66.548781264s] Trained 128 records in 0.089349599 seconds. Throughput is 1432.575 records/second. Loss is 1.8134637. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014285714285714286. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:25 INFO  DistriOptimizer$:408 - [Epoch 2 17024/60000][Iteration 602][Wall Clock 66.635445972s] Trained 128 records in 0.086664708 seconds. Throughput is 1476.9565 records/second. Loss is 1.8672066. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014265335235378032. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 603][Wall Clock 66.7228671s] Trained 128 records in 0.087421128 seconds. Throughput is 1464.177 records/second. Loss is 1.81956. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014245014245014244. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17280/60000][Iteration 604][Wall Clock 66.812207054s] Trained 128 records in 0.089339954 seconds. Throughput is 1432.7296 records/second. Loss is 1.8031962. Sequential266afc8b's hyper parameters: Current learning rate is 0.001422475106685633. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 605][Wall Clock 66.903340717s] Trained 128 records in 0.091133663 seconds. Throughput is 1404.5304 records/second. Loss is 1.7962934. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014204545454545455. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17536/60000][Iteration 606][Wall Clock 66.997350665s] Trained 128 records in 0.094009948 seconds. Throughput is 1361.558 records/second. Loss is 1.7561835. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014184397163120568. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 607][Wall Clock 67.085886848s] Trained 128 records in 0.088536183 seconds. Throughput is 1445.7367 records/second. Loss is 1.8104796. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014164305949008497. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17792/60000][Iteration 608][Wall Clock 67.174331719s] Trained 128 records in 0.088444871 seconds. Throughput is 1447.2291 records/second. Loss is 1.8269676. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014144271570014145. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 609][Wall Clock 67.263881154s] Trained 128 records in 0.089549435 seconds. Throughput is 1429.378 records/second. Loss is 1.7716049. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014124293785310734. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 18048/60000][Iteration 610][Wall Clock 67.354130623s] Trained 128 records in 0.090249469 seconds. Throughput is 1418.2909 records/second. Loss is 1.8402996. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014104372355430183. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 611][Wall Clock 67.443877605s] Trained 128 records in 0.089746982 seconds. Throughput is 1426.2318 records/second. Loss is 1.8188477. Sequential266afc8b's hyper parameters: Current learning rate is 0.001408450704225352. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 18304/60000][Iteration 612][Wall Clock 67.539827385s] Trained 128 records in 0.09594978 seconds. Throughput is 1334.0312 records/second. Loss is 1.8290838. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014064697609001407. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:26 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 613][Wall Clock 67.630145798s] Trained 128 records in 0.090318413 seconds. Throughput is 1417.2083 records/second. Loss is 1.7916133. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014044943820224719. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 18560/60000][Iteration 614][Wall Clock 67.725962136s] Trained 128 records in 0.095816338 seconds. Throughput is 1335.8892 records/second. Loss is 1.8693779. Sequential266afc8b's hyper parameters: Current learning rate is 0.001402524544179523. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 615][Wall Clock 67.824780893s] Trained 128 records in 0.098818757 seconds. Throughput is 1295.3007 records/second. Loss is 1.793958. Sequential266afc8b's hyper parameters: Current learning rate is 0.0014005602240896359. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 18816/60000][Iteration 616][Wall Clock 67.912582879s] Trained 128 records in 0.087801986 seconds. Throughput is 1457.8258 records/second. Loss is 1.827004. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013986013986013986. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 617][Wall Clock 68.003871417s] Trained 128 records in 0.091288538 seconds. Throughput is 1402.1476 records/second. Loss is 1.7719665. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013966480446927375. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 19072/60000][Iteration 618][Wall Clock 68.104430616s] Trained 128 records in 0.100559199 seconds. Throughput is 1272.8821 records/second. Loss is 1.7676828. Sequential266afc8b's hyper parameters: Current learning rate is 0.001394700139470014. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 619][Wall Clock 68.195904257s] Trained 128 records in 0.091473641 seconds. Throughput is 1399.3103 records/second. Loss is 1.8263006. Sequential266afc8b's hyper parameters: Current learning rate is 0.001392757660167131. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 19328/60000][Iteration 620][Wall Clock 68.287297374s] Trained 128 records in 0.091393117 seconds. Throughput is 1400.5431 records/second. Loss is 1.8768684. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013908205841446453. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 621][Wall Clock 68.385545035s] Trained 128 records in 0.098247661 seconds. Throughput is 1302.83 records/second. Loss is 1.8101025. Sequential266afc8b's hyper parameters: Current learning rate is 0.001388888888888889. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 19584/60000][Iteration 622][Wall Clock 68.474362275s] Trained 128 records in 0.08881724 seconds. Throughput is 1441.1616 records/second. Loss is 1.742173. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013869625520110957. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:27 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 623][Wall Clock 68.568708105s] Trained 128 records in 0.09434583 seconds. Throughput is 1356.7107 records/second. Loss is 1.8716799. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013850415512465374. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 19840/60000][Iteration 624][Wall Clock 68.659784355s] Trained 128 records in 0.09107625 seconds. Throughput is 1405.4158 records/second. Loss is 1.8342885. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013831258644536651. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 625][Wall Clock 68.748395873s] Trained 128 records in 0.088611518 seconds. Throughput is 1444.5074 records/second. Loss is 1.8295108. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013812154696132596. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20096/60000][Iteration 626][Wall Clock 68.840280926s] Trained 128 records in 0.091885053 seconds. Throughput is 1393.0448 records/second. Loss is 1.8223469. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013793103448275863. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 627][Wall Clock 68.932170541s] Trained 128 records in 0.091889615 seconds. Throughput is 1392.9757 records/second. Loss is 1.8183559. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013774104683195593. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20352/60000][Iteration 628][Wall Clock 69.021478894s] Trained 128 records in 0.089308353 seconds. Throughput is 1433.2366 records/second. Loss is 1.8061507. Sequential266afc8b's hyper parameters: Current learning rate is 0.001375515818431912. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 629][Wall Clock 69.137864365s] Trained 128 records in 0.116385471 seconds. Throughput is 1099.7937 records/second. Loss is 1.7897103. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013736263736263735. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20608/60000][Iteration 630][Wall Clock 69.236403412s] Trained 128 records in 0.098539047 seconds. Throughput is 1298.9774 records/second. Loss is 1.8125584. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013717421124828533. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 631][Wall Clock 69.32679995s] Trained 128 records in 0.090396538 seconds. Throughput is 1415.9834 records/second. Loss is 1.8174715. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013698630136986301. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20864/60000][Iteration 632][Wall Clock 69.417682884s] Trained 128 records in 0.090882934 seconds. Throughput is 1408.4053 records/second. Loss is 1.8021818. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013679890560875513. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 633][Wall Clock 69.509016831s] Trained 128 records in 0.091333947 seconds. Throughput is 1401.4504 records/second. Loss is 1.8402171. Sequential266afc8b's hyper parameters: Current learning rate is 0.001366120218579235. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:28 INFO  DistriOptimizer$:408 - [Epoch 2 21120/60000][Iteration 634][Wall Clock 69.608544442s] Trained 128 records in 0.099527611 seconds. Throughput is 1286.0753 records/second. Loss is 1.8042294. Sequential266afc8b's hyper parameters: Current learning rate is 0.001364256480218281. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 635][Wall Clock 69.699706808s] Trained 128 records in 0.091162366 seconds. Throughput is 1404.0881 records/second. Loss is 1.7942204. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013623978201634877. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 21376/60000][Iteration 636][Wall Clock 69.791735766s] Trained 128 records in 0.092028958 seconds. Throughput is 1390.8666 records/second. Loss is 1.7640222. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013605442176870747. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 637][Wall Clock 69.896527135s] Trained 128 records in 0.104791369 seconds. Throughput is 1221.4747 records/second. Loss is 1.8659731. Sequential266afc8b's hyper parameters: Current learning rate is 0.001358695652173913. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 21632/60000][Iteration 638][Wall Clock 70.011868424s] Trained 128 records in 0.115341289 seconds. Throughput is 1109.75 records/second. Loss is 1.7086142. Sequential266afc8b's hyper parameters: Current learning rate is 0.00135685210312076. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 639][Wall Clock 70.126893152s] Trained 128 records in 0.115024728 seconds. Throughput is 1112.8042 records/second. Loss is 1.7959075. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013550135501355014. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 21888/60000][Iteration 640][Wall Clock 70.243075041s] Trained 128 records in 0.116181889 seconds. Throughput is 1101.7208 records/second. Loss is 1.7428153. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013531799729364004. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 641][Wall Clock 70.361525466s] Trained 128 records in 0.118450425 seconds. Throughput is 1080.6208 records/second. Loss is 1.8106799. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013513513513513512. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 22144/60000][Iteration 642][Wall Clock 70.440859959s] Trained 128 records in 0.079334493 seconds. Throughput is 1613.4219 records/second. Loss is 1.799868. Sequential266afc8b's hyper parameters: Current learning rate is 0.001349527665317139. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:29 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 643][Wall Clock 70.563610587s] Trained 128 records in 0.122750628 seconds. Throughput is 1042.7645 records/second. Loss is 1.872118. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013477088948787063. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 22400/60000][Iteration 644][Wall Clock 70.652034458s] Trained 128 records in 0.088423871 seconds. Throughput is 1447.5729 records/second. Loss is 1.7865844. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013458950201884253. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 645][Wall Clock 70.74416086s] Trained 128 records in 0.092126402 seconds. Throughput is 1389.3955 records/second. Loss is 1.8024282. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013440860215053762. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 22656/60000][Iteration 646][Wall Clock 70.833949201s] Trained 128 records in 0.089788341 seconds. Throughput is 1425.5748 records/second. Loss is 1.7443205. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013422818791946308. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 647][Wall Clock 70.92076956s] Trained 128 records in 0.086820359 seconds. Throughput is 1474.3086 records/second. Loss is 1.737574. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013404825737265416. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 22912/60000][Iteration 648][Wall Clock 71.024623429s] Trained 128 records in 0.103853869 seconds. Throughput is 1232.5011 records/second. Loss is 1.8181167. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013386880856760376. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 649][Wall Clock 71.116959517s] Trained 128 records in 0.092336088 seconds. Throughput is 1386.2402 records/second. Loss is 1.7892107. Sequential266afc8b's hyper parameters: Current learning rate is 0.001336898395721925. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 23168/60000][Iteration 650][Wall Clock 71.203218077s] Trained 128 records in 0.08625856 seconds. Throughput is 1483.9106 records/second. Loss is 1.7552251. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013351134846461949. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 651][Wall Clock 71.290251376s] Trained 128 records in 0.087033299 seconds. Throughput is 1470.7014 records/second. Loss is 1.8259058. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013333333333333333. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 23424/60000][Iteration 652][Wall Clock 71.381585546s] Trained 128 records in 0.09133417 seconds. Throughput is 1401.447 records/second. Loss is 1.76825. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013315579227696406. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 653][Wall Clock 71.471122257s] Trained 128 records in 0.089536711 seconds. Throughput is 1429.5812 records/second. Loss is 1.8702984. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013297872340425532. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:30 INFO  DistriOptimizer$:408 - [Epoch 2 23680/60000][Iteration 654][Wall Clock 71.561339281s] Trained 128 records in 0.090217024 seconds. Throughput is 1418.8009 records/second. Loss is 1.8014784. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013280212483399733. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 655][Wall Clock 71.651899548s] Trained 128 records in 0.090560267 seconds. Throughput is 1413.4235 records/second. Loss is 1.8015853. Sequential266afc8b's hyper parameters: Current learning rate is 0.001326259946949602. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 23936/60000][Iteration 656][Wall Clock 71.744016678s] Trained 128 records in 0.09211713 seconds. Throughput is 1389.5353 records/second. Loss is 1.8191793. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013245033112582781. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 657][Wall Clock 71.835663268s] Trained 128 records in 0.09164659 seconds. Throughput is 1396.6696 records/second. Loss is 1.7697543. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013227513227513227. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24192/60000][Iteration 658][Wall Clock 71.92355582s] Trained 128 records in 0.087892552 seconds. Throughput is 1456.3236 records/second. Loss is 1.8040813. Sequential266afc8b's hyper parameters: Current learning rate is 0.001321003963011889. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 659][Wall Clock 72.024673747s] Trained 128 records in 0.101117927 seconds. Throughput is 1265.8488 records/second. Loss is 1.855761. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013192612137203166. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24448/60000][Iteration 660][Wall Clock 72.118619749s] Trained 128 records in 0.093946002 seconds. Throughput is 1362.4847 records/second. Loss is 1.7540135. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013175230566534915. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 661][Wall Clock 72.210518489s] Trained 128 records in 0.09189874 seconds. Throughput is 1392.8374 records/second. Loss is 1.7934186. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013157894736842105. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24704/60000][Iteration 662][Wall Clock 72.299750341s] Trained 128 records in 0.089231852 seconds. Throughput is 1434.4655 records/second. Loss is 1.7469974. Sequential266afc8b's hyper parameters: Current learning rate is 0.001314060446780552. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 663][Wall Clock 72.417203237s] Trained 128 records in 0.117452896 seconds. Throughput is 1089.7986 records/second. Loss is 1.8250016. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013123359580052493. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:31 INFO  DistriOptimizer$:408 - [Epoch 2 24960/60000][Iteration 664][Wall Clock 72.52502226s] Trained 128 records in 0.107819023 seconds. Throughput is 1187.1746 records/second. Loss is 1.7440168. Sequential266afc8b's hyper parameters: Current learning rate is 0.001310615989515072. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 665][Wall Clock 72.64071292s] Trained 128 records in 0.11569066 seconds. Throughput is 1106.3987 records/second. Loss is 1.8195069. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013089005235602093. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25216/60000][Iteration 666][Wall Clock 72.734085832s] Trained 128 records in 0.093372912 seconds. Throughput is 1370.8473 records/second. Loss is 1.7904028. Sequential266afc8b's hyper parameters: Current learning rate is 0.00130718954248366. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 667][Wall Clock 72.838640124s] Trained 128 records in 0.104554292 seconds. Throughput is 1224.2443 records/second. Loss is 1.7719414. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013054830287206266. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25472/60000][Iteration 668][Wall Clock 72.952004448s] Trained 128 records in 0.113364324 seconds. Throughput is 1129.103 records/second. Loss is 1.7816858. Sequential266afc8b's hyper parameters: Current learning rate is 0.001303780964797914. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 669][Wall Clock 73.055646142s] Trained 128 records in 0.103641694 seconds. Throughput is 1235.0242 records/second. Loss is 1.7780783. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013020833333333335. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25728/60000][Iteration 670][Wall Clock 73.142745757s] Trained 128 records in 0.087099615 seconds. Throughput is 1469.5818 records/second. Loss is 1.7856338. Sequential266afc8b's hyper parameters: Current learning rate is 0.0013003901170351106. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 671][Wall Clock 73.231892996s] Trained 128 records in 0.089147239 seconds. Throughput is 1435.8268 records/second. Loss is 1.7830898. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012987012987012987. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 25984/60000][Iteration 672][Wall Clock 73.319643088s] Trained 128 records in 0.087750092 seconds. Throughput is 1458.6879 records/second. Loss is 1.7212279. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012970168612191958. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 673][Wall Clock 73.417619423s] Trained 128 records in 0.097976335 seconds. Throughput is 1306.438 records/second. Loss is 1.7540324. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012953367875647669. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 26240/60000][Iteration 674][Wall Clock 73.51242527s] Trained 128 records in 0.094805847 seconds. Throughput is 1350.1277 records/second. Loss is 1.7951465. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012936610608020697. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:32 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 675][Wall Clock 73.602966768s] Trained 128 records in 0.090541498 seconds. Throughput is 1413.7164 records/second. Loss is 1.7762539. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012919896640826874. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 26496/60000][Iteration 676][Wall Clock 73.693298906s] Trained 128 records in 0.090332138 seconds. Throughput is 1416.9929 records/second. Loss is 1.7559661. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012903225806451613. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 677][Wall Clock 73.783532189s] Trained 128 records in 0.090233283 seconds. Throughput is 1418.5453 records/second. Loss is 1.7432935. Sequential266afc8b's hyper parameters: Current learning rate is 0.001288659793814433. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 26752/60000][Iteration 678][Wall Clock 73.873876525s] Trained 128 records in 0.090344336 seconds. Throughput is 1416.8015 records/second. Loss is 1.7551271. Sequential266afc8b's hyper parameters: Current learning rate is 0.001287001287001287. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 679][Wall Clock 73.964224639s] Trained 128 records in 0.090348114 seconds. Throughput is 1416.7423 records/second. Loss is 1.792494. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012853470437017994. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 27008/60000][Iteration 680][Wall Clock 74.056563733s] Trained 128 records in 0.092339094 seconds. Throughput is 1386.1952 records/second. Loss is 1.8332773. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012836970474967909. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 681][Wall Clock 74.144913192s] Trained 128 records in 0.088349459 seconds. Throughput is 1448.7921 records/second. Loss is 1.6921055. Sequential266afc8b's hyper parameters: Current learning rate is 0.001282051282051282. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 27264/60000][Iteration 682][Wall Clock 74.235103352s] Trained 128 records in 0.09019016 seconds. Throughput is 1419.2236 records/second. Loss is 1.8165107. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012804097311139564. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 683][Wall Clock 74.33621547s] Trained 128 records in 0.101112118 seconds. Throughput is 1265.9214 records/second. Loss is 1.719525. Sequential266afc8b's hyper parameters: Current learning rate is 0.001278772378516624. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 27520/60000][Iteration 684][Wall Clock 74.445562004s] Trained 128 records in 0.109346534 seconds. Throughput is 1170.5905 records/second. Loss is 1.7732947. Sequential266afc8b's hyper parameters: Current learning rate is 0.001277139208173691. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:33 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 685][Wall Clock 74.558653925s] Trained 128 records in 0.113091921 seconds. Throughput is 1131.8226 records/second. Loss is 1.7982204. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012755102040816328. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 27776/60000][Iteration 686][Wall Clock 74.676319332s] Trained 128 records in 0.117665407 seconds. Throughput is 1087.8303 records/second. Loss is 1.7684872. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012738853503184713. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 687][Wall Clock 74.767847451s] Trained 128 records in 0.091528119 seconds. Throughput is 1398.4774 records/second. Loss is 1.786169. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012722646310432569. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28032/60000][Iteration 688][Wall Clock 74.863611751s] Trained 128 records in 0.0957643 seconds. Throughput is 1336.615 records/second. Loss is 1.7914073. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012706480304955528. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 689][Wall Clock 74.978808652s] Trained 128 records in 0.115196901 seconds. Throughput is 1111.141 records/second. Loss is 1.8367922. Sequential266afc8b's hyper parameters: Current learning rate is 0.001269035532994924. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28288/60000][Iteration 690][Wall Clock 75.0776165s] Trained 128 records in 0.098807848 seconds. Throughput is 1295.4436 records/second. Loss is 1.7756988. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012674271229404308. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 691][Wall Clock 75.167065234s] Trained 128 records in 0.089448734 seconds. Throughput is 1430.9873 records/second. Loss is 1.7652738. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012658227848101266. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28544/60000][Iteration 692][Wall Clock 75.254493917s] Trained 128 records in 0.087428683 seconds. Throughput is 1464.0504 records/second. Loss is 1.8368647. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012642225031605564. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 693][Wall Clock 75.372508315s] Trained 128 records in 0.118014398 seconds. Throughput is 1084.6134 records/second. Loss is 1.7862765. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012626262626262627. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:34 INFO  DistriOptimizer$:408 - [Epoch 2 28800/60000][Iteration 694][Wall Clock 75.485903954s] Trained 128 records in 0.113395639 seconds. Throughput is 1128.7913 records/second. Loss is 1.7447559. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012610340479192938. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 695][Wall Clock 75.599578087s] Trained 128 records in 0.113674133 seconds. Throughput is 1126.0258 records/second. Loss is 1.7835698. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012594458438287153. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29056/60000][Iteration 696][Wall Clock 75.687044959s] Trained 128 records in 0.087466872 seconds. Throughput is 1463.4111 records/second. Loss is 1.843708. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012578616352201257. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 697][Wall Clock 75.783270434s] Trained 128 records in 0.096225475 seconds. Throughput is 1330.209 records/second. Loss is 1.7089784. Sequential266afc8b's hyper parameters: Current learning rate is 0.001256281407035176. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29312/60000][Iteration 698][Wall Clock 75.888395944s] Trained 128 records in 0.10512551 seconds. Throughput is 1217.5922 records/second. Loss is 1.7945683. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012547051442910917. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 699][Wall Clock 75.981541402s] Trained 128 records in 0.093145458 seconds. Throughput is 1374.1947 records/second. Loss is 1.7495244. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012531328320802004. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29568/60000][Iteration 700][Wall Clock 76.074459215s] Trained 128 records in 0.092917813 seconds. Throughput is 1377.5614 records/second. Loss is 1.8027941. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012515644555694619. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 701][Wall Clock 76.172568875s] Trained 128 records in 0.09810966 seconds. Throughput is 1304.6625 records/second. Loss is 1.8007696. Sequential266afc8b's hyper parameters: Current learning rate is 0.00125. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29824/60000][Iteration 702][Wall Clock 76.26166055s] Trained 128 records in 0.089091675 seconds. Throughput is 1436.7224 records/second. Loss is 1.7811548. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012484394506866417. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 703][Wall Clock 76.351136379s] Trained 128 records in 0.089475829 seconds. Throughput is 1430.554 records/second. Loss is 1.7105786. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012468827930174565. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 30080/60000][Iteration 704][Wall Clock 76.439755857s] Trained 128 records in 0.088619478 seconds. Throughput is 1444.3777 records/second. Loss is 1.7701046. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012453300124533. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:35 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 705][Wall Clock 76.525616945s] Trained 128 records in 0.085861088 seconds. Throughput is 1490.7802 records/second. Loss is 1.8258916. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012437810945273634. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 30336/60000][Iteration 706][Wall Clock 76.615645106s] Trained 128 records in 0.090028161 seconds. Throughput is 1421.7773 records/second. Loss is 1.7207701. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012422360248447203. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 707][Wall Clock 76.704331249s] Trained 128 records in 0.088686143 seconds. Throughput is 1443.292 records/second. Loss is 1.7646686. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012406947890818859. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 30592/60000][Iteration 708][Wall Clock 76.791929479s] Trained 128 records in 0.08759823 seconds. Throughput is 1461.2168 records/second. Loss is 1.7782315. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012391573729863693. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 709][Wall Clock 76.88152569s] Trained 128 records in 0.089596211 seconds. Throughput is 1428.6318 records/second. Loss is 1.6949869. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012376237623762376. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 30848/60000][Iteration 710][Wall Clock 76.970494027s] Trained 128 records in 0.088968337 seconds. Throughput is 1438.7141 records/second. Loss is 1.8100363. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012360939431396787. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 711][Wall Clock 77.061828417s] Trained 128 records in 0.09133439 seconds. Throughput is 1401.4437 records/second. Loss is 1.7907948. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012345679012345677. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 31104/60000][Iteration 712][Wall Clock 77.152983969s] Trained 128 records in 0.091155552 seconds. Throughput is 1404.1931 records/second. Loss is 1.7585799. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012330456226880395. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 713][Wall Clock 77.241986142s] Trained 128 records in 0.089002173 seconds. Throughput is 1438.1672 records/second. Loss is 1.7470382. Sequential266afc8b's hyper parameters: Current learning rate is 0.001231527093596059. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 31360/60000][Iteration 714][Wall Clock 77.332409663s] Trained 128 records in 0.090423521 seconds. Throughput is 1415.5608 records/second. Loss is 1.6870639. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012300123001230015. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 715][Wall Clock 77.442474293s] Trained 128 records in 0.11006463 seconds. Throughput is 1162.953 records/second. Loss is 1.7863702. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012285012285012285. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:36 INFO  DistriOptimizer$:408 - [Epoch 2 31616/60000][Iteration 716][Wall Clock 77.524976077s] Trained 128 records in 0.082501784 seconds. Throughput is 1551.4816 records/second. Loss is 1.7614022. Sequential266afc8b's hyper parameters: Current learning rate is 0.001226993865030675. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 717][Wall Clock 77.615141657s] Trained 128 records in 0.09016558 seconds. Throughput is 1419.6105 records/second. Loss is 1.7694124. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012254901960784314. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 31872/60000][Iteration 718][Wall Clock 77.698972063s] Trained 128 records in 0.083830406 seconds. Throughput is 1526.8922 records/second. Loss is 1.69958. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012239902080783355. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 719][Wall Clock 77.786985649s] Trained 128 records in 0.088013586 seconds. Throughput is 1454.3209 records/second. Loss is 1.7319939. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012224938875305623. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32128/60000][Iteration 720][Wall Clock 77.882105915s] Trained 128 records in 0.095120266 seconds. Throughput is 1345.6649 records/second. Loss is 1.7934113. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012210012210012208. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 721][Wall Clock 77.973860594s] Trained 128 records in 0.091754679 seconds. Throughput is 1395.0242 records/second. Loss is 1.6609385. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012195121951219514. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32384/60000][Iteration 722][Wall Clock 78.065480902s] Trained 128 records in 0.091620308 seconds. Throughput is 1397.0702 records/second. Loss is 1.7500802. Sequential266afc8b's hyper parameters: Current learning rate is 0.001218026796589525. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 723][Wall Clock 78.161569709s] Trained 128 records in 0.096088807 seconds. Throughput is 1332.1011 records/second. Loss is 1.756972. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012165450121654504. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32640/60000][Iteration 724][Wall Clock 78.252133807s] Trained 128 records in 0.090564098 seconds. Throughput is 1413.3636 records/second. Loss is 1.7245374. Sequential266afc8b's hyper parameters: Current learning rate is 0.001215066828675577. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 725][Wall Clock 78.34281308s] Trained 128 records in 0.090679273 seconds. Throughput is 1411.5685 records/second. Loss is 1.7187871. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012135922330097086. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 32896/60000][Iteration 726][Wall Clock 78.432572611s] Trained 128 records in 0.089759531 seconds. Throughput is 1426.0325 records/second. Loss is 1.7064055. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012121212121212121. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:37 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 727][Wall Clock 78.520105203s] Trained 128 records in 0.087532592 seconds. Throughput is 1462.3124 records/second. Loss is 1.6791222. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012106537530266344. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33152/60000][Iteration 728][Wall Clock 78.61172716s] Trained 128 records in 0.091621957 seconds. Throughput is 1397.045 records/second. Loss is 1.7706739. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012091898428053206. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 729][Wall Clock 78.701533219s] Trained 128 records in 0.089806059 seconds. Throughput is 1425.2936 records/second. Loss is 1.7793374. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012077294685990338. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33408/60000][Iteration 730][Wall Clock 78.792200336s] Trained 128 records in 0.090667117 seconds. Throughput is 1411.7577 records/second. Loss is 1.8489499. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012062726176115804. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 731][Wall Clock 78.880858828s] Trained 128 records in 0.088658492 seconds. Throughput is 1443.7422 records/second. Loss is 1.7313952. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012048192771084336. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33664/60000][Iteration 732][Wall Clock 78.976090615s] Trained 128 records in 0.095231787 seconds. Throughput is 1344.089 records/second. Loss is 1.7490599. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012033694344163659. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 733][Wall Clock 79.063439204s] Trained 128 records in 0.087348589 seconds. Throughput is 1465.393 records/second. Loss is 1.7889735. Sequential266afc8b's hyper parameters: Current learning rate is 0.001201923076923077. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 33920/60000][Iteration 734][Wall Clock 79.150592423s] Trained 128 records in 0.087153219 seconds. Throughput is 1468.6779 records/second. Loss is 1.737765. Sequential266afc8b's hyper parameters: Current learning rate is 0.0012004801920768306. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 735][Wall Clock 79.238792902s] Trained 128 records in 0.088200479 seconds. Throughput is 1451.2393 records/second. Loss is 1.7542576. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011990407673860913. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 34176/60000][Iteration 736][Wall Clock 79.328672892s] Trained 128 records in 0.08987999 seconds. Throughput is 1424.1212 records/second. Loss is 1.7299621. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011976047904191614. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 737][Wall Clock 79.416156293s] Trained 128 records in 0.087483401 seconds. Throughput is 1463.1348 records/second. Loss is 1.759806. Sequential266afc8b's hyper parameters: Current learning rate is 0.001196172248803828. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:38 INFO  DistriOptimizer$:408 - [Epoch 2 34432/60000][Iteration 738][Wall Clock 79.503502307s] Trained 128 records in 0.087346014 seconds. Throughput is 1465.436 records/second. Loss is 1.7324514. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011947431302270011. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 739][Wall Clock 79.591660263s] Trained 128 records in 0.088157956 seconds. Throughput is 1451.9392 records/second. Loss is 1.7383981. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011933174224343678. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 34688/60000][Iteration 740][Wall Clock 79.692027224s] Trained 128 records in 0.100366961 seconds. Throughput is 1275.3201 records/second. Loss is 1.7632484. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011918951132300357. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 741][Wall Clock 79.776052796s] Trained 128 records in 0.084025572 seconds. Throughput is 1523.3458 records/second. Loss is 1.7538117. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011904761904761904. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 34944/60000][Iteration 742][Wall Clock 79.865910315s] Trained 128 records in 0.089857519 seconds. Throughput is 1424.4773 records/second. Loss is 1.7584599. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011890606420927468. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 743][Wall Clock 79.95335388s] Trained 128 records in 0.087443565 seconds. Throughput is 1463.8011 records/second. Loss is 1.7758592. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011876484560570072. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35200/60000][Iteration 744][Wall Clock 80.042056916s] Trained 128 records in 0.088703036 seconds. Throughput is 1443.0171 records/second. Loss is 1.7678995. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011862396204033216. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 745][Wall Clock 80.130676635s] Trained 128 records in 0.088619719 seconds. Throughput is 1444.3738 records/second. Loss is 1.7375053. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011848341232227487. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35456/60000][Iteration 746][Wall Clock 80.220319344s] Trained 128 records in 0.089642709 seconds. Throughput is 1427.8907 records/second. Loss is 1.7488096. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011834319526627221. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 747][Wall Clock 80.310243227s] Trained 128 records in 0.089923883 seconds. Throughput is 1423.4261 records/second. Loss is 1.7516333. Sequential266afc8b's hyper parameters: Current learning rate is 0.001182033096926714. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35712/60000][Iteration 748][Wall Clock 80.406516983s] Trained 128 records in 0.096273756 seconds. Throughput is 1329.542 records/second. Loss is 1.7796769. Sequential266afc8b's hyper parameters: Current learning rate is 0.001180637544273908. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:39 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 749][Wall Clock 80.487794502s] Trained 128 records in 0.081277519 seconds. Throughput is 1574.8512 records/second. Loss is 1.7428993. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011792452830188679. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 35968/60000][Iteration 750][Wall Clock 80.574618545s] Trained 128 records in 0.086824043 seconds. Throughput is 1474.246 records/second. Loss is 1.7173575. Sequential266afc8b's hyper parameters: Current learning rate is 0.001177856301531213. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 751][Wall Clock 80.664338233s] Trained 128 records in 0.089719688 seconds. Throughput is 1426.6656 records/second. Loss is 1.7600715. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011764705882352942. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36224/60000][Iteration 752][Wall Clock 80.756174607s] Trained 128 records in 0.091836374 seconds. Throughput is 1393.7833 records/second. Loss is 1.7352388. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011750881316098707. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 753][Wall Clock 80.847520258s] Trained 128 records in 0.091345651 seconds. Throughput is 1401.2709 records/second. Loss is 1.6875545. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011737089201877935. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36480/60000][Iteration 754][Wall Clock 80.967221563s] Trained 128 records in 0.119701305 seconds. Throughput is 1069.3284 records/second. Loss is 1.7486453. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011723329425556857. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 755][Wall Clock 81.055488498s] Trained 128 records in 0.088266935 seconds. Throughput is 1450.1467 records/second. Loss is 1.7168283. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011709601873536302. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36736/60000][Iteration 756][Wall Clock 81.144667243s] Trained 128 records in 0.089178745 seconds. Throughput is 1435.3196 records/second. Loss is 1.7414758. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011695906432748538. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 757][Wall Clock 81.235033684s] Trained 128 records in 0.090366441 seconds. Throughput is 1416.4551 records/second. Loss is 1.8028. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011682242990654205. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 36992/60000][Iteration 758][Wall Clock 81.323828858s] Trained 128 records in 0.088795174 seconds. Throughput is 1441.5198 records/second. Loss is 1.8030319. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011668611435239206. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 759][Wall Clock 81.415267997s] Trained 128 records in 0.091439139 seconds. Throughput is 1399.8383 records/second. Loss is 1.6878839. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011655011655011655. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:40 INFO  DistriOptimizer$:408 - [Epoch 2 37248/60000][Iteration 760][Wall Clock 81.507987673s] Trained 128 records in 0.092719676 seconds. Throughput is 1380.5052 records/second. Loss is 1.694899. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011641443538998836. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 761][Wall Clock 81.599902376s] Trained 128 records in 0.091914703 seconds. Throughput is 1392.5955 records/second. Loss is 1.7564747. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011627906976744184. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 37504/60000][Iteration 762][Wall Clock 81.694333054s] Trained 128 records in 0.094430678 seconds. Throughput is 1355.4917 records/second. Loss is 1.721411. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011614401858304297. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 763][Wall Clock 81.785137876s] Trained 128 records in 0.090804822 seconds. Throughput is 1409.6167 records/second. Loss is 1.7641244. Sequential266afc8b's hyper parameters: Current learning rate is 0.001160092807424594. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 37760/60000][Iteration 764][Wall Clock 81.878426723s] Trained 128 records in 0.093288847 seconds. Throughput is 1372.0825 records/second. Loss is 1.7506381. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011587485515643107. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 765][Wall Clock 81.980674655s] Trained 128 records in 0.102247932 seconds. Throughput is 1251.8591 records/second. Loss is 1.7001284. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011574074074074073. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 38016/60000][Iteration 766][Wall Clock 82.069122505s] Trained 128 records in 0.08844785 seconds. Throughput is 1447.1805 records/second. Loss is 1.7865739. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011560693641618498. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 767][Wall Clock 82.164506911s] Trained 128 records in 0.095384406 seconds. Throughput is 1341.9385 records/second. Loss is 1.7400492. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011547344110854503. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 38272/60000][Iteration 768][Wall Clock 82.254830998s] Trained 128 records in 0.090324087 seconds. Throughput is 1417.1191 records/second. Loss is 1.7006025. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011534025374855825. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 769][Wall Clock 82.346942914s] Trained 128 records in 0.092111916 seconds. Throughput is 1389.6139 records/second. Loss is 1.689885. Sequential266afc8b's hyper parameters: Current learning rate is 0.001152073732718894. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 38528/60000][Iteration 770][Wall Clock 82.440897182s] Trained 128 records in 0.093954268 seconds. Throughput is 1362.365 records/second. Loss is 1.7335576. Sequential266afc8b's hyper parameters: Current learning rate is 0.001150747986191024. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:41 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 771][Wall Clock 82.529468332s] Trained 128 records in 0.08857115 seconds. Throughput is 1445.1658 records/second. Loss is 1.7092137. Sequential266afc8b's hyper parameters: Current learning rate is 0.001149425287356322. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 38784/60000][Iteration 772][Wall Clock 82.61968439s] Trained 128 records in 0.090216058 seconds. Throughput is 1418.8162 records/second. Loss is 1.808981. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011481056257175658. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 773][Wall Clock 82.720317537s] Trained 128 records in 0.100633147 seconds. Throughput is 1271.9468 records/second. Loss is 1.752204. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011467889908256884. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39040/60000][Iteration 774][Wall Clock 82.80801982s] Trained 128 records in 0.087702283 seconds. Throughput is 1459.4832 records/second. Loss is 1.7140946. Sequential266afc8b's hyper parameters: Current learning rate is 0.001145475372279496. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 775][Wall Clock 82.908892698s] Trained 128 records in 0.100872878 seconds. Throughput is 1268.9238 records/second. Loss is 1.7623954. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011441647597254005. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39296/60000][Iteration 776][Wall Clock 82.999342999s] Trained 128 records in 0.090450301 seconds. Throughput is 1415.1417 records/second. Loss is 1.7822512. Sequential266afc8b's hyper parameters: Current learning rate is 0.001142857142857143. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 777][Wall Clock 83.085213677s] Trained 128 records in 0.085870678 seconds. Throughput is 1490.6136 records/second. Loss is 1.6675991. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011415525114155253. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39552/60000][Iteration 778][Wall Clock 83.174484887s] Trained 128 records in 0.08927121 seconds. Throughput is 1433.8329 records/second. Loss is 1.6625476. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011402508551881414. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 779][Wall Clock 83.262845965s] Trained 128 records in 0.088361078 seconds. Throughput is 1448.6017 records/second. Loss is 1.7841203. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011389521640091116. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39808/60000][Iteration 780][Wall Clock 83.350724657s] Trained 128 records in 0.087878692 seconds. Throughput is 1456.5533 records/second. Loss is 1.6754769. Sequential266afc8b's hyper parameters: Current learning rate is 0.001137656427758817. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 781][Wall Clock 83.440103698s] Trained 128 records in 0.089379041 seconds. Throughput is 1432.103 records/second. Loss is 1.7067972. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011363636363636363. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:42 INFO  DistriOptimizer$:408 - [Epoch 2 40064/60000][Iteration 782][Wall Clock 83.547311619s] Trained 128 records in 0.107207921 seconds. Throughput is 1193.9417 records/second. Loss is 1.7219757. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011350737797956867. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 783][Wall Clock 83.633678848s] Trained 128 records in 0.086367229 seconds. Throughput is 1482.0437 records/second. Loss is 1.722648. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011337868480725624. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40320/60000][Iteration 784][Wall Clock 83.724758636s] Trained 128 records in 0.091079788 seconds. Throughput is 1405.3612 records/second. Loss is 1.8118632. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011325028312570782. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 785][Wall Clock 83.82139975s] Trained 128 records in 0.096641114 seconds. Throughput is 1324.488 records/second. Loss is 1.7116079. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011312217194570137. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40576/60000][Iteration 786][Wall Clock 83.911996337s] Trained 128 records in 0.090596587 seconds. Throughput is 1412.8568 records/second. Loss is 1.7230419. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011299435028248586. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 787][Wall Clock 83.999730994s] Trained 128 records in 0.087734657 seconds. Throughput is 1458.9446 records/second. Loss is 1.7551247. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011286681715575622. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40832/60000][Iteration 788][Wall Clock 84.093358299s] Trained 128 records in 0.093627305 seconds. Throughput is 1367.1226 records/second. Loss is 1.6416788. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011273957158962795. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 789][Wall Clock 84.190243015s] Trained 128 records in 0.096884716 seconds. Throughput is 1321.1578 records/second. Loss is 1.6833907. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011261261261261263. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 41088/60000][Iteration 790][Wall Clock 84.284385071s] Trained 128 records in 0.094142056 seconds. Throughput is 1359.6473 records/second. Loss is 1.7170637. Sequential266afc8b's hyper parameters: Current learning rate is 0.001124859392575928. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 791][Wall Clock 84.375401815s] Trained 128 records in 0.091016744 seconds. Throughput is 1406.3346 records/second. Loss is 1.6910037. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011235955056179774. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:43 INFO  DistriOptimizer$:408 - [Epoch 2 41344/60000][Iteration 792][Wall Clock 84.471850103s] Trained 128 records in 0.096448288 seconds. Throughput is 1327.1361 records/second. Loss is 1.6951829. Sequential266afc8b's hyper parameters: Current learning rate is 0.001122334455667789. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 793][Wall Clock 84.562671027s] Trained 128 records in 0.090820924 seconds. Throughput is 1409.3668 records/second. Loss is 1.6989862. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011210762331838565. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 41600/60000][Iteration 794][Wall Clock 84.651442718s] Trained 128 records in 0.088771691 seconds. Throughput is 1441.9011 records/second. Loss is 1.7517282. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011198208286674132. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 795][Wall Clock 84.743069821s] Trained 128 records in 0.091627103 seconds. Throughput is 1396.9666 records/second. Loss is 1.6990272. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011185682326621922. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 41856/60000][Iteration 796][Wall Clock 84.83503377s] Trained 128 records in 0.091963949 seconds. Throughput is 1391.8497 records/second. Loss is 1.7561786. Sequential266afc8b's hyper parameters: Current learning rate is 0.00111731843575419. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 797][Wall Clock 84.924904354s] Trained 128 records in 0.089870584 seconds. Throughput is 1424.2703 records/second. Loss is 1.7652221. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011160714285714285. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 42112/60000][Iteration 798][Wall Clock 85.023126793s] Trained 128 records in 0.098222439 seconds. Throughput is 1303.1646 records/second. Loss is 1.698927. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011148272017837237. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 799][Wall Clock 85.105686071s] Trained 128 records in 0.082559278 seconds. Throughput is 1550.4011 records/second. Loss is 1.6806549. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011135857461024498. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 42368/60000][Iteration 800][Wall Clock 85.188644408s] Trained 128 records in 0.082958337 seconds. Throughput is 1542.9431 records/second. Loss is 1.6756102. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011123470522803114. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 801][Wall Clock 85.280289023s] Trained 128 records in 0.091644615 seconds. Throughput is 1396.6996 records/second. Loss is 1.6690071. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011111111111111111. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 42624/60000][Iteration 802][Wall Clock 85.368783735s] Trained 128 records in 0.088494712 seconds. Throughput is 1446.4142 records/second. Loss is 1.7184689. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011098779134295228. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:44 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 803][Wall Clock 85.455688225s] Trained 128 records in 0.08690449 seconds. Throughput is 1472.8813 records/second. Loss is 1.7882015. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011086474501108647. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 42880/60000][Iteration 804][Wall Clock 85.54424085s] Trained 128 records in 0.088552625 seconds. Throughput is 1445.4681 records/second. Loss is 1.7466073. Sequential266afc8b's hyper parameters: Current learning rate is 0.001107419712070875. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 805][Wall Clock 85.63426117s] Trained 128 records in 0.09002032 seconds. Throughput is 1421.9011 records/second. Loss is 1.6545541. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011061946902654867. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43136/60000][Iteration 806][Wall Clock 85.723799421s] Trained 128 records in 0.089538251 seconds. Throughput is 1429.5566 records/second. Loss is 1.7476262. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011049723756906076. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 807][Wall Clock 85.814433931s] Trained 128 records in 0.09063451 seconds. Throughput is 1412.2656 records/second. Loss is 1.7789652. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011037527593818985. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43392/60000][Iteration 808][Wall Clock 85.904643615s] Trained 128 records in 0.090209684 seconds. Throughput is 1418.9164 records/second. Loss is 1.7412349. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011025358324145535. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 809][Wall Clock 85.993944295s] Trained 128 records in 0.08930068 seconds. Throughput is 1433.3597 records/second. Loss is 1.7213397. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011013215859030838. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43648/60000][Iteration 810][Wall Clock 86.083774549s] Trained 128 records in 0.089830254 seconds. Throughput is 1424.9097 records/second. Loss is 1.6878548. Sequential266afc8b's hyper parameters: Current learning rate is 0.0011001100110011. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 811][Wall Clock 86.175257977s] Trained 128 records in 0.091483428 seconds. Throughput is 1399.1605 records/second. Loss is 1.7255689. Sequential266afc8b's hyper parameters: Current learning rate is 0.001098901098901099. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 43904/60000][Iteration 812][Wall Clock 86.264147888s] Trained 128 records in 0.088889911 seconds. Throughput is 1439.9834 records/second. Loss is 1.7753918. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010976948408342481. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 813][Wall Clock 86.359222388s] Trained 128 records in 0.0950745 seconds. Throughput is 1346.3126 records/second. Loss is 1.7183594. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010964912280701754. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:45 INFO  DistriOptimizer$:408 - [Epoch 2 44160/60000][Iteration 814][Wall Clock 86.447945926s] Trained 128 records in 0.088723538 seconds. Throughput is 1442.6836 records/second. Loss is 1.7372401. Sequential266afc8b's hyper parameters: Current learning rate is 0.001095290251916758. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 815][Wall Clock 86.547893083s] Trained 128 records in 0.099947157 seconds. Throughput is 1280.6768 records/second. Loss is 1.7156821. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010940919037199124. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 44416/60000][Iteration 816][Wall Clock 86.634309754s] Trained 128 records in 0.086416671 seconds. Throughput is 1481.1957 records/second. Loss is 1.6972848. Sequential266afc8b's hyper parameters: Current learning rate is 0.001092896174863388. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 817][Wall Clock 86.724372262s] Trained 128 records in 0.090062508 seconds. Throughput is 1421.2351 records/second. Loss is 1.741281. Sequential266afc8b's hyper parameters: Current learning rate is 0.001091703056768559. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 44672/60000][Iteration 818][Wall Clock 86.810789569s] Trained 128 records in 0.086417307 seconds. Throughput is 1481.1847 records/second. Loss is 1.7376496. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010905125408942203. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 819][Wall Clock 86.899700511s] Trained 128 records in 0.088910942 seconds. Throughput is 1439.6428 records/second. Loss is 1.7716196. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010893246187363835. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 44928/60000][Iteration 820][Wall Clock 86.988825221s] Trained 128 records in 0.08912471 seconds. Throughput is 1436.1898 records/second. Loss is 1.7799004. Sequential266afc8b's hyper parameters: Current learning rate is 0.001088139281828074. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 821][Wall Clock 87.076407858s] Trained 128 records in 0.087582637 seconds. Throughput is 1461.4768 records/second. Loss is 1.7053424. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010869565217391304. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 45184/60000][Iteration 822][Wall Clock 87.16554312s] Trained 128 records in 0.089135262 seconds. Throughput is 1436.0198 records/second. Loss is 1.7260402. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010857763300760042. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 823][Wall Clock 87.262749512s] Trained 128 records in 0.097206392 seconds. Throughput is 1316.7859 records/second. Loss is 1.6805661. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010845986984815619. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 45440/60000][Iteration 824][Wall Clock 87.360037123s] Trained 128 records in 0.097287611 seconds. Throughput is 1315.6865 records/second. Loss is 1.6792716. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010834236186348862. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:46 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 825][Wall Clock 87.449202195s] Trained 128 records in 0.089165072 seconds. Throughput is 1435.5398 records/second. Loss is 1.7507259. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010822510822510823. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 45696/60000][Iteration 826][Wall Clock 87.535451933s] Trained 128 records in 0.086249738 seconds. Throughput is 1484.0625 records/second. Loss is 1.7111156. Sequential266afc8b's hyper parameters: Current learning rate is 0.001081081081081081. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 827][Wall Clock 87.624908029s] Trained 128 records in 0.089456096 seconds. Throughput is 1430.8695 records/second. Loss is 1.6392049. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010799136069114472. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 45952/60000][Iteration 828][Wall Clock 87.719752915s] Trained 128 records in 0.094844886 seconds. Throughput is 1349.572 records/second. Loss is 1.7049032. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010787486515641857. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 829][Wall Clock 87.811459464s] Trained 128 records in 0.091706549 seconds. Throughput is 1395.7563 records/second. Loss is 1.7464293. Sequential266afc8b's hyper parameters: Current learning rate is 0.001077586206896552. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46208/60000][Iteration 830][Wall Clock 87.902796291s] Trained 128 records in 0.091336827 seconds. Throughput is 1401.4062 records/second. Loss is 1.7271945. Sequential266afc8b's hyper parameters: Current learning rate is 0.001076426264800861. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 831][Wall Clock 87.99388946s] Trained 128 records in 0.091093169 seconds. Throughput is 1405.1548 records/second. Loss is 1.704823. Sequential266afc8b's hyper parameters: Current learning rate is 0.001075268817204301. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46464/60000][Iteration 832][Wall Clock 88.08103439s] Trained 128 records in 0.08714493 seconds. Throughput is 1468.8175 records/second. Loss is 1.724666. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010741138560687433. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 833][Wall Clock 88.167346301s] Trained 128 records in 0.086311911 seconds. Throughput is 1482.9934 records/second. Loss is 1.6968962. Sequential266afc8b's hyper parameters: Current learning rate is 0.001072961373390558. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46720/60000][Iteration 834][Wall Clock 88.25479498s] Trained 128 records in 0.087448679 seconds. Throughput is 1463.7157 records/second. Loss is 1.7239767. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010718113612004287. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 835][Wall Clock 88.344238961s] Trained 128 records in 0.089443981 seconds. Throughput is 1431.0634 records/second. Loss is 1.7494956. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010706638115631692. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 46976/60000][Iteration 836][Wall Clock 88.433196411s] Trained 128 records in 0.08895745 seconds. Throughput is 1438.8901 records/second. Loss is 1.705374. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010695187165775401. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:47 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 837][Wall Clock 88.52260077s] Trained 128 records in 0.089404359 seconds. Throughput is 1431.6975 records/second. Loss is 1.6048292. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010683760683760685. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 47232/60000][Iteration 838][Wall Clock 88.611978503s] Trained 128 records in 0.089377733 seconds. Throughput is 1432.124 records/second. Loss is 1.723402. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010672358591248664. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 839][Wall Clock 88.717079861s] Trained 128 records in 0.105101358 seconds. Throughput is 1217.8721 records/second. Loss is 1.691015. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010660980810234541. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 47488/60000][Iteration 840][Wall Clock 88.817725002s] Trained 128 records in 0.100645141 seconds. Throughput is 1271.7952 records/second. Loss is 1.6962001. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010649627263045792. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 841][Wall Clock 88.904888847s] Trained 128 records in 0.087163845 seconds. Throughput is 1468.4988 records/second. Loss is 1.7396437. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010638297872340426. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 47744/60000][Iteration 842][Wall Clock 88.990113031s] Trained 128 records in 0.085224184 seconds. Throughput is 1501.9211 records/second. Loss is 1.6643366. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010626992561105207. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 843][Wall Clock 89.081635734s] Trained 128 records in 0.091522703 seconds. Throughput is 1398.5602 records/second. Loss is 1.692471. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010615711252653928. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 48000/60000][Iteration 844][Wall Clock 89.164479278s] Trained 128 records in 0.082843544 seconds. Throughput is 1545.0812 records/second. Loss is 1.7428075. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010604453870625664. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 845][Wall Clock 89.25714282s] Trained 128 records in 0.092663542 seconds. Throughput is 1381.3416 records/second. Loss is 1.707142. Sequential266afc8b's hyper parameters: Current learning rate is 0.001059322033898305. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 48256/60000][Iteration 846][Wall Clock 89.343156557s] Trained 128 records in 0.086013737 seconds. Throughput is 1488.1344 records/second. Loss is 1.7169759. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010582010582010583. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:48 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 847][Wall Clock 89.432206748s] Trained 128 records in 0.089050191 seconds. Throughput is 1437.3917 records/second. Loss is 1.7603384. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010570824524312895. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 48512/60000][Iteration 848][Wall Clock 89.533753793s] Trained 128 records in 0.101547045 seconds. Throughput is 1260.4995 records/second. Loss is 1.6669961. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010559662090813093. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 849][Wall Clock 89.621153553s] Trained 128 records in 0.08739976 seconds. Throughput is 1464.5349 records/second. Loss is 1.7346734. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010548523206751054. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 48768/60000][Iteration 850][Wall Clock 89.706286407s] Trained 128 records in 0.085132854 seconds. Throughput is 1503.5323 records/second. Loss is 1.6175151. Sequential266afc8b's hyper parameters: Current learning rate is 0.001053740779768177. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 851][Wall Clock 89.793998997s] Trained 128 records in 0.08771259 seconds. Throughput is 1459.3115 records/second. Loss is 1.7365289. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010526315789473684. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49024/60000][Iteration 852][Wall Clock 89.879866772s] Trained 128 records in 0.085867775 seconds. Throughput is 1490.664 records/second. Loss is 1.7061434. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010515247108307045. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 853][Wall Clock 89.967639468s] Trained 128 records in 0.087772696 seconds. Throughput is 1458.3123 records/second. Loss is 1.7787608. Sequential266afc8b's hyper parameters: Current learning rate is 0.001050420168067227. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49280/60000][Iteration 854][Wall Clock 90.062463591s] Trained 128 records in 0.094824123 seconds. Throughput is 1349.8676 records/second. Loss is 1.6742083. Sequential266afc8b's hyper parameters: Current learning rate is 0.001049317943336831. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 855][Wall Clock 90.148860969s] Trained 128 records in 0.086397378 seconds. Throughput is 1481.5264 records/second. Loss is 1.788518. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010482180293501047. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49536/60000][Iteration 856][Wall Clock 90.237073647s] Trained 128 records in 0.088212678 seconds. Throughput is 1451.0386 records/second. Loss is 1.6962109. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010471204188481674. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 857][Wall Clock 90.32632383s] Trained 128 records in 0.089250183 seconds. Throughput is 1434.1707 records/second. Loss is 1.6335717. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010460251046025104. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49792/60000][Iteration 858][Wall Clock 90.412837137s] Trained 128 records in 0.086513307 seconds. Throughput is 1479.5411 records/second. Loss is 1.6611824. Sequential266afc8b's hyper parameters: Current learning rate is 0.001044932079414838. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:49 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 859][Wall Clock 90.501353859s] Trained 128 records in 0.088516722 seconds. Throughput is 1446.0544 records/second. Loss is 1.7310333. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010438413361169103. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50048/60000][Iteration 860][Wall Clock 90.590296138s] Trained 128 records in 0.088942279 seconds. Throughput is 1439.1355 records/second. Loss is 1.7991576. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010427528675703858. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 861][Wall Clock 90.676762177s] Trained 128 records in 0.086466039 seconds. Throughput is 1480.35 records/second. Loss is 1.6774743. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010416666666666667. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50304/60000][Iteration 862][Wall Clock 90.768674477s] Trained 128 records in 0.0919123 seconds. Throughput is 1392.632 records/second. Loss is 1.6886714. Sequential266afc8b's hyper parameters: Current learning rate is 0.001040582726326743. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 863][Wall Clock 90.859288485s] Trained 128 records in 0.090614008 seconds. Throughput is 1412.5852 records/second. Loss is 1.6917794. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010395010395010393. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50560/60000][Iteration 864][Wall Clock 90.956358255s] Trained 128 records in 0.09706977 seconds. Throughput is 1318.6392 records/second. Loss is 1.7662668. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010384215991692627. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 865][Wall Clock 91.054566385s] Trained 128 records in 0.09820813 seconds. Throughput is 1303.3544 records/second. Loss is 1.697216. Sequential266afc8b's hyper parameters: Current learning rate is 0.001037344398340249. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50816/60000][Iteration 866][Wall Clock 91.142017392s] Trained 128 records in 0.087451007 seconds. Throughput is 1463.6768 records/second. Loss is 1.6878552. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010362694300518134. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 867][Wall Clock 91.230848843s] Trained 128 records in 0.088831451 seconds. Throughput is 1440.931 records/second. Loss is 1.6531774. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010351966873706005. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 51072/60000][Iteration 868][Wall Clock 91.319034375s] Trained 128 records in 0.088185532 seconds. Throughput is 1451.4852 records/second. Loss is 1.6941335. Sequential266afc8b's hyper parameters: Current learning rate is 0.001034126163391934. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 869][Wall Clock 91.408277989s] Trained 128 records in 0.089243614 seconds. Throughput is 1434.2764 records/second. Loss is 1.6836668. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010330578512396695. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:50 INFO  DistriOptimizer$:408 - [Epoch 2 51328/60000][Iteration 870][Wall Clock 91.497799077s] Trained 128 records in 0.089521088 seconds. Throughput is 1429.8307 records/second. Loss is 1.6390266. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010319917440660476. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 871][Wall Clock 91.585496975s] Trained 128 records in 0.087697898 seconds. Throughput is 1459.556 records/second. Loss is 1.704488. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010309278350515462. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 51584/60000][Iteration 872][Wall Clock 91.672482047s] Trained 128 records in 0.086985072 seconds. Throughput is 1471.5168 records/second. Loss is 1.7657754. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010298661174047373. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 873][Wall Clock 91.771779077s] Trained 128 records in 0.09929703 seconds. Throughput is 1289.0616 records/second. Loss is 1.6543325. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010288065843621398. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 51840/60000][Iteration 874][Wall Clock 91.875025842s] Trained 128 records in 0.103246765 seconds. Throughput is 1239.7483 records/second. Loss is 1.6210656. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010277492291880781. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 875][Wall Clock 91.964527836s] Trained 128 records in 0.089501994 seconds. Throughput is 1430.1357 records/second. Loss is 1.6954275. Sequential266afc8b's hyper parameters: Current learning rate is 0.001026694045174538. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 52096/60000][Iteration 876][Wall Clock 92.053604165s] Trained 128 records in 0.089076329 seconds. Throughput is 1436.97 records/second. Loss is 1.6897604. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010256410256410256. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 877][Wall Clock 92.141718554s] Trained 128 records in 0.088114389 seconds. Throughput is 1452.6572 records/second. Loss is 1.7526883. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010245901639344263. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 52352/60000][Iteration 878][Wall Clock 92.230670245s] Trained 128 records in 0.088951691 seconds. Throughput is 1438.9833 records/second. Loss is 1.5995443. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010235414534288639. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 879][Wall Clock 92.319253574s] Trained 128 records in 0.088583329 seconds. Throughput is 1444.9672 records/second. Loss is 1.608849. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010224948875255625. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 52608/60000][Iteration 880][Wall Clock 92.408061931s] Trained 128 records in 0.088808357 seconds. Throughput is 1441.3058 records/second. Loss is 1.7020469. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010214504596527069. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:51 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 881][Wall Clock 92.494003483s] Trained 128 records in 0.085941552 seconds. Throughput is 1489.3843 records/second. Loss is 1.7323309. Sequential266afc8b's hyper parameters: Current learning rate is 0.001020408163265306. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 52864/60000][Iteration 882][Wall Clock 92.581983681s] Trained 128 records in 0.087980198 seconds. Throughput is 1454.8729 records/second. Loss is 1.7276703. Sequential266afc8b's hyper parameters: Current learning rate is 0.001019367991845056. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 883][Wall Clock 92.668711765s] Trained 128 records in 0.086728084 seconds. Throughput is 1475.8772 records/second. Loss is 1.6135899. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010183299389002036. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53120/60000][Iteration 884][Wall Clock 92.764615563s] Trained 128 records in 0.095903798 seconds. Throughput is 1334.6708 records/second. Loss is 1.7299752. Sequential266afc8b's hyper parameters: Current learning rate is 0.001017293997965412. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 885][Wall Clock 92.864703784s] Trained 128 records in 0.100088221 seconds. Throughput is 1278.8717 records/second. Loss is 1.655691. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010162601626016261. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53376/60000][Iteration 886][Wall Clock 92.954055843s] Trained 128 records in 0.089352059 seconds. Throughput is 1432.5355 records/second. Loss is 1.6850775. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010152284263959391. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 887][Wall Clock 93.066717995s] Trained 128 records in 0.112662152 seconds. Throughput is 1136.1403 records/second. Loss is 1.6497854. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010141987829614604. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53632/60000][Iteration 888][Wall Clock 93.158836977s] Trained 128 records in 0.092118982 seconds. Throughput is 1389.5073 records/second. Loss is 1.6911. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010131712259371832. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 889][Wall Clock 93.247351519s] Trained 128 records in 0.088514542 seconds. Throughput is 1446.0901 records/second. Loss is 1.7458125. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010121457489878543. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 53888/60000][Iteration 890][Wall Clock 93.352473407s] Trained 128 records in 0.105121888 seconds. Throughput is 1217.6342 records/second. Loss is 1.700714. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010111223458038423. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:52 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 891][Wall Clock 93.45324034s] Trained 128 records in 0.100766933 seconds. Throughput is 1270.2579 records/second. Loss is 1.6253564. Sequential266afc8b's hyper parameters: Current learning rate is 0.00101010101010101. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54144/60000][Iteration 892][Wall Clock 93.557536123s] Trained 128 records in 0.104295783 seconds. Throughput is 1227.2788 records/second. Loss is 1.6723553. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010090817356205853. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 893][Wall Clock 93.654614843s] Trained 128 records in 0.09707872 seconds. Throughput is 1318.5176 records/second. Loss is 1.7027856. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010080645161290322. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54400/60000][Iteration 894][Wall Clock 93.768103951s] Trained 128 records in 0.113489108 seconds. Throughput is 1127.8616 records/second. Loss is 1.7455027. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010070493454179255. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 895][Wall Clock 93.856296698s] Trained 128 records in 0.088192747 seconds. Throughput is 1451.3666 records/second. Loss is 1.6733079. Sequential266afc8b's hyper parameters: Current learning rate is 0.001006036217303823. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54656/60000][Iteration 896][Wall Clock 93.948148721s] Trained 128 records in 0.091852023 seconds. Throughput is 1393.5458 records/second. Loss is 1.6895012. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010050251256281406. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 897][Wall Clock 94.038896963s] Trained 128 records in 0.090748242 seconds. Throughput is 1410.4956 records/second. Loss is 1.7436044. Sequential266afc8b's hyper parameters: Current learning rate is 0.001004016064257028. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 54912/60000][Iteration 898][Wall Clock 94.133549147s] Trained 128 records in 0.094652184 seconds. Throughput is 1352.3196 records/second. Loss is 1.6164387. Sequential266afc8b's hyper parameters: Current learning rate is 0.0010030090270812437. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 899][Wall Clock 94.220995452s] Trained 128 records in 0.087446305 seconds. Throughput is 1463.7555 records/second. Loss is 1.6099436. Sequential266afc8b's hyper parameters: Current learning rate is 0.001002004008016032. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 55168/60000][Iteration 900][Wall Clock 94.316452713s] Trained 128 records in 0.095457261 seconds. Throughput is 1340.9142 records/second. Loss is 1.5818453. Sequential266afc8b's hyper parameters: Current learning rate is 0.001001001001001001. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:53 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 901][Wall Clock 94.407533928s] Trained 128 records in 0.091081215 seconds. Throughput is 1405.3391 records/second. Loss is 1.7416767. Sequential266afc8b's hyper parameters: Current learning rate is 0.001. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 55424/60000][Iteration 902][Wall Clock 94.499526999s] Trained 128 records in 0.091993071 seconds. Throughput is 1391.4092 records/second. Loss is 1.655745. Sequential266afc8b's hyper parameters: Current learning rate is 9.99000999000999E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 903][Wall Clock 94.589167828s] Trained 128 records in 0.089640829 seconds. Throughput is 1427.9208 records/second. Loss is 1.7171129. Sequential266afc8b's hyper parameters: Current learning rate is 9.980039920159682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 55680/60000][Iteration 904][Wall Clock 94.683400708s] Trained 128 records in 0.09423288 seconds. Throughput is 1358.3369 records/second. Loss is 1.7194973. Sequential266afc8b's hyper parameters: Current learning rate is 9.970089730807579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 905][Wall Clock 94.777296534s] Trained 128 records in 0.093895826 seconds. Throughput is 1363.2129 records/second. Loss is 1.6936669. Sequential266afc8b's hyper parameters: Current learning rate is 9.9601593625498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 55936/60000][Iteration 906][Wall Clock 94.871355876s] Trained 128 records in 0.094059342 seconds. Throughput is 1360.843 records/second. Loss is 1.756177. Sequential266afc8b's hyper parameters: Current learning rate is 9.950248756218905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 907][Wall Clock 94.97506867s] Trained 128 records in 0.103712794 seconds. Throughput is 1234.1775 records/second. Loss is 1.7094752. Sequential266afc8b's hyper parameters: Current learning rate is 9.940357852882703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 56192/60000][Iteration 908][Wall Clock 95.089036111s] Trained 128 records in 0.113967441 seconds. Throughput is 1123.1278 records/second. Loss is 1.6648822. Sequential266afc8b's hyper parameters: Current learning rate is 9.930486593843098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 909][Wall Clock 95.20320993s] Trained 128 records in 0.114173819 seconds. Throughput is 1121.0977 records/second. Loss is 1.7139902. Sequential266afc8b's hyper parameters: Current learning rate is 9.92063492063492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 56448/60000][Iteration 910][Wall Clock 95.29548991s] Trained 128 records in 0.09227998 seconds. Throughput is 1387.0831 records/second. Loss is 1.6680734. Sequential266afc8b's hyper parameters: Current learning rate is 9.910802775024777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 911][Wall Clock 95.386410313s] Trained 128 records in 0.090920403 seconds. Throughput is 1407.8248 records/second. Loss is 1.7441856. Sequential266afc8b's hyper parameters: Current learning rate is 9.900990099009901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:54 INFO  DistriOptimizer$:408 - [Epoch 2 56704/60000][Iteration 912][Wall Clock 95.474175826s] Trained 128 records in 0.087765513 seconds. Throughput is 1458.4316 records/second. Loss is 1.6769212. Sequential266afc8b's hyper parameters: Current learning rate is 9.891196834817015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 913][Wall Clock 95.564048979s] Trained 128 records in 0.089873153 seconds. Throughput is 1424.2296 records/second. Loss is 1.6201673. Sequential266afc8b's hyper parameters: Current learning rate is 9.881422924901185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 56960/60000][Iteration 914][Wall Clock 95.654770633s] Trained 128 records in 0.090721654 seconds. Throughput is 1410.909 records/second. Loss is 1.6221145. Sequential266afc8b's hyper parameters: Current learning rate is 9.871668311944718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 915][Wall Clock 95.751254029s] Trained 128 records in 0.096483396 seconds. Throughput is 1326.6532 records/second. Loss is 1.6847671. Sequential266afc8b's hyper parameters: Current learning rate is 9.861932938856016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57216/60000][Iteration 916][Wall Clock 95.842519854s] Trained 128 records in 0.091265825 seconds. Throughput is 1402.4965 records/second. Loss is 1.6625308. Sequential266afc8b's hyper parameters: Current learning rate is 9.852216748768472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 917][Wall Clock 95.934718665s] Trained 128 records in 0.092198811 seconds. Throughput is 1388.3042 records/second. Loss is 1.6625954. Sequential266afc8b's hyper parameters: Current learning rate is 9.84251968503937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57472/60000][Iteration 918][Wall Clock 96.024631124s] Trained 128 records in 0.089912459 seconds. Throughput is 1423.6069 records/second. Loss is 1.6846261. Sequential266afc8b's hyper parameters: Current learning rate is 9.832841691248771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 919][Wall Clock 96.118091034s] Trained 128 records in 0.09345991 seconds. Throughput is 1369.5712 records/second. Loss is 1.657042. Sequential266afc8b's hyper parameters: Current learning rate is 9.82318271119843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57728/60000][Iteration 920][Wall Clock 96.207073629s] Trained 128 records in 0.088982595 seconds. Throughput is 1438.4835 records/second. Loss is 1.6493211. Sequential266afc8b's hyper parameters: Current learning rate is 9.813542688910698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 921][Wall Clock 96.297181847s] Trained 128 records in 0.090108218 seconds. Throughput is 1420.5142 records/second. Loss is 1.6328509. Sequential266afc8b's hyper parameters: Current learning rate is 9.80392156862745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:55 INFO  DistriOptimizer$:408 - [Epoch 2 57984/60000][Iteration 922][Wall Clock 96.387404797s] Trained 128 records in 0.09022295 seconds. Throughput is 1418.7078 records/second. Loss is 1.6199125. Sequential266afc8b's hyper parameters: Current learning rate is 9.794319294809011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 923][Wall Clock 96.480044042s] Trained 128 records in 0.092639245 seconds. Throughput is 1381.7039 records/second. Loss is 1.6163453. Sequential266afc8b's hyper parameters: Current learning rate is 9.784735812133072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58240/60000][Iteration 924][Wall Clock 96.560160902s] Trained 128 records in 0.08011686 seconds. Throughput is 1597.6661 records/second. Loss is 1.7081707. Sequential266afc8b's hyper parameters: Current learning rate is 9.775171065493646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 925][Wall Clock 96.651678756s] Trained 128 records in 0.091517854 seconds. Throughput is 1398.6343 records/second. Loss is 1.6689101. Sequential266afc8b's hyper parameters: Current learning rate is 9.765625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58496/60000][Iteration 926][Wall Clock 96.750634357s] Trained 128 records in 0.098955601 seconds. Throughput is 1293.5094 records/second. Loss is 1.6510183. Sequential266afc8b's hyper parameters: Current learning rate is 9.75609756097561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 927][Wall Clock 96.844008991s] Trained 128 records in 0.093374634 seconds. Throughput is 1370.822 records/second. Loss is 1.6431901. Sequential266afc8b's hyper parameters: Current learning rate is 9.746588693957116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58752/60000][Iteration 928][Wall Clock 96.934941528s] Trained 128 records in 0.090932537 seconds. Throughput is 1407.637 records/second. Loss is 1.5921072. Sequential266afc8b's hyper parameters: Current learning rate is 9.737098344693282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 929][Wall Clock 97.025503829s] Trained 128 records in 0.090562301 seconds. Throughput is 1413.3917 records/second. Loss is 1.7499912. Sequential266afc8b's hyper parameters: Current learning rate is 9.72762645914397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 59008/60000][Iteration 930][Wall Clock 97.117510683s] Trained 128 records in 0.092006854 seconds. Throughput is 1391.2007 records/second. Loss is 1.6106292. Sequential266afc8b's hyper parameters: Current learning rate is 9.718172983479105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 931][Wall Clock 97.210739041s] Trained 128 records in 0.093228358 seconds. Throughput is 1372.9729 records/second. Loss is 1.6445218. Sequential266afc8b's hyper parameters: Current learning rate is 9.70873786407767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 59264/60000][Iteration 932][Wall Clock 97.30333878s] Trained 128 records in 0.092599739 seconds. Throughput is 1382.2932 records/second. Loss is 1.6123552. Sequential266afc8b's hyper parameters: Current learning rate is 9.699321047526673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:56 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 933][Wall Clock 97.396582264s] Trained 128 records in 0.093243484 seconds. Throughput is 1372.75 records/second. Loss is 1.726316. Sequential266afc8b's hyper parameters: Current learning rate is 9.689922480620155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:57 INFO  DistriOptimizer$:408 - [Epoch 2 59520/60000][Iteration 934][Wall Clock 97.490253219s] Trained 128 records in 0.093670955 seconds. Throughput is 1366.4855 records/second. Loss is 1.6502469. Sequential266afc8b's hyper parameters: Current learning rate is 9.68054211035818E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:57 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 935][Wall Clock 97.583120168s] Trained 128 records in 0.092866949 seconds. Throughput is 1378.3159 records/second. Loss is 1.6407557. Sequential266afc8b's hyper parameters: Current learning rate is 9.671179883945841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:57 INFO  DistriOptimizer$:408 - [Epoch 2 59776/60000][Iteration 936][Wall Clock 97.676670864s] Trained 128 records in 0.093550696 seconds. Throughput is 1368.2421 records/second. Loss is 1.6885172. Sequential266afc8b's hyper parameters: Current learning rate is 9.661835748792271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:57 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 937][Wall Clock 97.767268463s] Trained 128 records in 0.090597599 seconds. Throughput is 1412.841 records/second. Loss is 1.6803857. Sequential266afc8b's hyper parameters: Current learning rate is 9.652509652509653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:57 INFO  DistriOptimizer$:408 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 97.853519683s] Trained 128 records in 0.08625122 seconds. Throughput is 1484.037 records/second. Loss is 1.6169543. Sequential266afc8b's hyper parameters: Current learning rate is 9.643201542912246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:57 INFO  DistriOptimizer$:452 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 97.853519683s] Epoch finished. Wall clock time is 99304.156065 ms
2019-10-15 08:19:57 INFO  DistriOptimizer$:111 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 97.853519683s] Validate model...
2019-10-15 08:19:58 INFO  DistriOptimizer$:178 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 97.853519683s] validate model throughput is 11967.907 records/second
2019-10-15 08:19:58 INFO  DistriOptimizer$:181 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 97.853519683s] Top1Accuracy is Accuracy(correct: 6603, count: 10000, accuracy: 0.6603)
2019-10-15 08:19:58 INFO  DistriOptimizer$:221 - [Wall Clock 99.304156065s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:19:58 INFO  DistriOptimizer$:226 - [Wall Clock 99.304156065s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:19:58 INFO  DistriOptimizer$:408 - [Epoch 3 128/60000][Iteration 939][Wall Clock 99.453794045s] Trained 128 records in 0.14963798 seconds. Throughput is 855.39777 records/second. Loss is 1.666829. Sequential266afc8b's hyper parameters: Current learning rate is 9.633911368015414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:58 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 940][Wall Clock 99.542221621s] Trained 128 records in 0.088427576 seconds. Throughput is 1447.5123 records/second. Loss is 1.6935225. Sequential266afc8b's hyper parameters: Current learning rate is 9.624639076034648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:58 INFO  DistriOptimizer$:408 - [Epoch 3 384/60000][Iteration 941][Wall Clock 99.630598448s] Trained 128 records in 0.088376827 seconds. Throughput is 1448.3435 records/second. Loss is 1.6242002. Sequential266afc8b's hyper parameters: Current learning rate is 9.615384615384615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:58 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 942][Wall Clock 99.715320932s] Trained 128 records in 0.084722484 seconds. Throughput is 1510.8151 records/second. Loss is 1.6559024. Sequential266afc8b's hyper parameters: Current learning rate is 9.606147934678194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:58 INFO  DistriOptimizer$:408 - [Epoch 3 640/60000][Iteration 943][Wall Clock 99.807168721s] Trained 128 records in 0.091847789 seconds. Throughput is 1393.61 records/second. Loss is 1.6620115. Sequential266afc8b's hyper parameters: Current learning rate is 9.596928982725529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:58 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 944][Wall Clock 99.899385633s] Trained 128 records in 0.092216912 seconds. Throughput is 1388.0317 records/second. Loss is 1.7126468. Sequential266afc8b's hyper parameters: Current learning rate is 9.587727708533078E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 896/60000][Iteration 945][Wall Clock 99.99466348s] Trained 128 records in 0.095277847 seconds. Throughput is 1343.4393 records/second. Loss is 1.6156037. Sequential266afc8b's hyper parameters: Current learning rate is 9.578544061302683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 946][Wall Clock 100.091077519s] Trained 128 records in 0.096414039 seconds. Throughput is 1327.6075 records/second. Loss is 1.647501. Sequential266afc8b's hyper parameters: Current learning rate is 9.569377990430621E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1152/60000][Iteration 947][Wall Clock 100.190525679s] Trained 128 records in 0.09944816 seconds. Throughput is 1287.1028 records/second. Loss is 1.6983728. Sequential266afc8b's hyper parameters: Current learning rate is 9.560229445506692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 948][Wall Clock 100.280691248s] Trained 128 records in 0.090165569 seconds. Throughput is 1419.6106 records/second. Loss is 1.6270978. Sequential266afc8b's hyper parameters: Current learning rate is 9.551098376313276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1408/60000][Iteration 949][Wall Clock 100.367371166s] Trained 128 records in 0.086679918 seconds. Throughput is 1476.6973 records/second. Loss is 1.6647087. Sequential266afc8b's hyper parameters: Current learning rate is 9.541984732824427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 950][Wall Clock 100.461327629s] Trained 128 records in 0.093956463 seconds. Throughput is 1362.3331 records/second. Loss is 1.6667525. Sequential266afc8b's hyper parameters: Current learning rate is 9.532888465204957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1664/60000][Iteration 951][Wall Clock 100.55091789s] Trained 128 records in 0.089590261 seconds. Throughput is 1428.7268 records/second. Loss is 1.6099097. Sequential266afc8b's hyper parameters: Current learning rate is 9.523809523809524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 952][Wall Clock 100.63990236s] Trained 128 records in 0.08898447 seconds. Throughput is 1438.4532 records/second. Loss is 1.665288. Sequential266afc8b's hyper parameters: Current learning rate is 9.514747859181732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 1920/60000][Iteration 953][Wall Clock 100.727072428s] Trained 128 records in 0.087170068 seconds. Throughput is 1468.394 records/second. Loss is 1.6217338. Sequential266afc8b's hyper parameters: Current learning rate is 9.505703422053233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 954][Wall Clock 100.815444949s] Trained 128 records in 0.088372521 seconds. Throughput is 1448.4141 records/second. Loss is 1.6735605. Sequential266afc8b's hyper parameters: Current learning rate is 9.49667616334283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:19:59 INFO  DistriOptimizer$:408 - [Epoch 3 2176/60000][Iteration 955][Wall Clock 100.902424547s] Trained 128 records in 0.086979598 seconds. Throughput is 1471.6095 records/second. Loss is 1.6022037. Sequential266afc8b's hyper parameters: Current learning rate is 9.487666034155597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 956][Wall Clock 100.98910719s] Trained 128 records in 0.086682643 seconds. Throughput is 1476.6509 records/second. Loss is 1.6304523. Sequential266afc8b's hyper parameters: Current learning rate is 9.47867298578199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 2432/60000][Iteration 957][Wall Clock 101.075784427s] Trained 128 records in 0.086677237 seconds. Throughput is 1476.7429 records/second. Loss is 1.653416. Sequential266afc8b's hyper parameters: Current learning rate is 9.46969696969697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 958][Wall Clock 101.163056261s] Trained 128 records in 0.087271834 seconds. Throughput is 1466.6818 records/second. Loss is 1.5777396. Sequential266afc8b's hyper parameters: Current learning rate is 9.46073793755913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 2688/60000][Iteration 959][Wall Clock 101.249940838s] Trained 128 records in 0.086884577 seconds. Throughput is 1473.2189 records/second. Loss is 1.6306977. Sequential266afc8b's hyper parameters: Current learning rate is 9.45179584120983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 960][Wall Clock 101.339401174s] Trained 128 records in 0.089460336 seconds. Throughput is 1430.8016 records/second. Loss is 1.6808624. Sequential266afc8b's hyper parameters: Current learning rate is 9.442870632672333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 2944/60000][Iteration 961][Wall Clock 101.42711562s] Trained 128 records in 0.087714446 seconds. Throughput is 1459.2806 records/second. Loss is 1.6156766. Sequential266afc8b's hyper parameters: Current learning rate is 9.433962264150943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 962][Wall Clock 101.51750165s] Trained 128 records in 0.09038603 seconds. Throughput is 1416.148 records/second. Loss is 1.6132122. Sequential266afc8b's hyper parameters: Current learning rate is 9.425070688030161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 3200/60000][Iteration 963][Wall Clock 101.609686743s] Trained 128 records in 0.092185093 seconds. Throughput is 1388.5107 records/second. Loss is 1.6885282. Sequential266afc8b's hyper parameters: Current learning rate is 9.416195856873823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 964][Wall Clock 101.704972221s] Trained 128 records in 0.095285478 seconds. Throughput is 1343.3317 records/second. Loss is 1.5640385. Sequential266afc8b's hyper parameters: Current learning rate is 9.40733772342427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 3456/60000][Iteration 965][Wall Clock 101.803524566s] Trained 128 records in 0.098552345 seconds. Throughput is 1298.8021 records/second. Loss is 1.700645. Sequential266afc8b's hyper parameters: Current learning rate is 9.398496240601503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:00 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 966][Wall Clock 101.889866797s] Trained 128 records in 0.086342231 seconds. Throughput is 1482.4727 records/second. Loss is 1.5787979. Sequential266afc8b's hyper parameters: Current learning rate is 9.389671361502347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 3712/60000][Iteration 967][Wall Clock 101.986375731s] Trained 128 records in 0.096508934 seconds. Throughput is 1326.3021 records/second. Loss is 1.6235509. Sequential266afc8b's hyper parameters: Current learning rate is 9.380863039399625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 968][Wall Clock 102.07548693s] Trained 128 records in 0.089111199 seconds. Throughput is 1436.4075 records/second. Loss is 1.6138808. Sequential266afc8b's hyper parameters: Current learning rate is 9.372071227741331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 3968/60000][Iteration 969][Wall Clock 102.163778163s] Trained 128 records in 0.088291233 seconds. Throughput is 1449.7476 records/second. Loss is 1.6302687. Sequential266afc8b's hyper parameters: Current learning rate is 9.363295880149813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 970][Wall Clock 102.255045391s] Trained 128 records in 0.091267228 seconds. Throughput is 1402.475 records/second. Loss is 1.6415458. Sequential266afc8b's hyper parameters: Current learning rate is 9.354536950420954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4224/60000][Iteration 971][Wall Clock 102.346310343s] Trained 128 records in 0.091264952 seconds. Throughput is 1402.5099 records/second. Loss is 1.6021771. Sequential266afc8b's hyper parameters: Current learning rate is 9.345794392523364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 972][Wall Clock 102.438940604s] Trained 128 records in 0.092630261 seconds. Throughput is 1381.8379 records/second. Loss is 1.6453246. Sequential266afc8b's hyper parameters: Current learning rate is 9.337068160597572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4480/60000][Iteration 973][Wall Clock 102.534128502s] Trained 128 records in 0.095187898 seconds. Throughput is 1344.7087 records/second. Loss is 1.6833215. Sequential266afc8b's hyper parameters: Current learning rate is 9.328358208955224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 974][Wall Clock 102.622774662s] Trained 128 records in 0.08864616 seconds. Throughput is 1443.943 records/second. Loss is 1.6119933. Sequential266afc8b's hyper parameters: Current learning rate is 9.319664492078285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4736/60000][Iteration 975][Wall Clock 102.711238062s] Trained 128 records in 0.0884634 seconds. Throughput is 1446.926 records/second. Loss is 1.6451021. Sequential266afc8b's hyper parameters: Current learning rate is 9.31098696461825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 976][Wall Clock 102.799031677s] Trained 128 records in 0.087793615 seconds. Throughput is 1457.9647 records/second. Loss is 1.665167. Sequential266afc8b's hyper parameters: Current learning rate is 9.302325581395349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:01 INFO  DistriOptimizer$:408 - [Epoch 3 4992/60000][Iteration 977][Wall Clock 102.890040355s] Trained 128 records in 0.091008678 seconds. Throughput is 1406.4592 records/second. Loss is 1.6463512. Sequential266afc8b's hyper parameters: Current learning rate is 9.29368029739777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 978][Wall Clock 102.977238631s] Trained 128 records in 0.087198276 seconds. Throughput is 1467.919 records/second. Loss is 1.577729. Sequential266afc8b's hyper parameters: Current learning rate is 9.285051067780873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5248/60000][Iteration 979][Wall Clock 103.065950952s] Trained 128 records in 0.088712321 seconds. Throughput is 1442.8661 records/second. Loss is 1.5991828. Sequential266afc8b's hyper parameters: Current learning rate is 9.27643784786642E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 980][Wall Clock 103.15653995s] Trained 128 records in 0.090588998 seconds. Throughput is 1412.9752 records/second. Loss is 1.6380566. Sequential266afc8b's hyper parameters: Current learning rate is 9.267840593141797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5504/60000][Iteration 981][Wall Clock 103.245265599s] Trained 128 records in 0.088725649 seconds. Throughput is 1442.6494 records/second. Loss is 1.610728. Sequential266afc8b's hyper parameters: Current learning rate is 9.259259259259259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 982][Wall Clock 103.33408855s] Trained 128 records in 0.088822951 seconds. Throughput is 1441.069 records/second. Loss is 1.6506449. Sequential266afc8b's hyper parameters: Current learning rate is 9.250693802035152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5760/60000][Iteration 983][Wall Clock 103.423368463s] Trained 128 records in 0.089279913 seconds. Throughput is 1433.6931 records/second. Loss is 1.5999434. Sequential266afc8b's hyper parameters: Current learning rate is 9.242144177449168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 984][Wall Clock 103.515039506s] Trained 128 records in 0.091671043 seconds. Throughput is 1396.297 records/second. Loss is 1.6974487. Sequential266afc8b's hyper parameters: Current learning rate is 9.233610341643582E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 6016/60000][Iteration 985][Wall Clock 103.605143298s] Trained 128 records in 0.090103792 seconds. Throughput is 1420.584 records/second. Loss is 1.682014. Sequential266afc8b's hyper parameters: Current learning rate is 9.22509225092251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 986][Wall Clock 103.696428156s] Trained 128 records in 0.091284858 seconds. Throughput is 1402.2041 records/second. Loss is 1.598957. Sequential266afc8b's hyper parameters: Current learning rate is 9.216589861751152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 6272/60000][Iteration 987][Wall Clock 103.786355689s] Trained 128 records in 0.089927533 seconds. Throughput is 1423.3683 records/second. Loss is 1.6806848. Sequential266afc8b's hyper parameters: Current learning rate is 9.208103130755065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:02 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 988][Wall Clock 103.874034858s] Trained 128 records in 0.087679169 seconds. Throughput is 1459.8678 records/second. Loss is 1.6791103. Sequential266afc8b's hyper parameters: Current learning rate is 9.19963201471941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 6528/60000][Iteration 989][Wall Clock 103.962798564s] Trained 128 records in 0.088763706 seconds. Throughput is 1442.0308 records/second. Loss is 1.6306086. Sequential266afc8b's hyper parameters: Current learning rate is 9.191176470588235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 990][Wall Clock 104.06457822s] Trained 128 records in 0.101779656 seconds. Throughput is 1257.6188 records/second. Loss is 1.5412973. Sequential266afc8b's hyper parameters: Current learning rate is 9.182736455463728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 6784/60000][Iteration 991][Wall Clock 104.154126424s] Trained 128 records in 0.089548204 seconds. Throughput is 1429.3978 records/second. Loss is 1.6428409. Sequential266afc8b's hyper parameters: Current learning rate is 9.174311926605504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 992][Wall Clock 104.246819396s] Trained 128 records in 0.092692972 seconds. Throughput is 1380.903 records/second. Loss is 1.6056465. Sequential266afc8b's hyper parameters: Current learning rate is 9.165902841429881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7040/60000][Iteration 993][Wall Clock 104.3401836s] Trained 128 records in 0.093364204 seconds. Throughput is 1370.9751 records/second. Loss is 1.6021135. Sequential266afc8b's hyper parameters: Current learning rate is 9.157509157509158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 994][Wall Clock 104.433067572s] Trained 128 records in 0.092883972 seconds. Throughput is 1378.0634 records/second. Loss is 1.6534393. Sequential266afc8b's hyper parameters: Current learning rate is 9.149130832570906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7296/60000][Iteration 995][Wall Clock 104.526579362s] Trained 128 records in 0.09351179 seconds. Throughput is 1368.8114 records/second. Loss is 1.6575736. Sequential266afc8b's hyper parameters: Current learning rate is 9.140767824497259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 996][Wall Clock 104.618094619s] Trained 128 records in 0.091515257 seconds. Throughput is 1398.6738 records/second. Loss is 1.6523892. Sequential266afc8b's hyper parameters: Current learning rate is 9.132420091324201E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7552/60000][Iteration 997][Wall Clock 104.709020613s] Trained 128 records in 0.090925994 seconds. Throughput is 1407.7383 records/second. Loss is 1.7119068. Sequential266afc8b's hyper parameters: Current learning rate is 9.124087591240876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 998][Wall Clock 104.806895144s] Trained 128 records in 0.097874531 seconds. Throughput is 1307.7969 records/second. Loss is 1.6030529. Sequential266afc8b's hyper parameters: Current learning rate is 9.115770282588879E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:03 INFO  DistriOptimizer$:408 - [Epoch 3 7808/60000][Iteration 999][Wall Clock 104.899045297s] Trained 128 records in 0.092150153 seconds. Throughput is 1389.0374 records/second. Loss is 1.6738062. Sequential266afc8b's hyper parameters: Current learning rate is 9.107468123861566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 1000][Wall Clock 104.987580997s] Trained 128 records in 0.0885357 seconds. Throughput is 1445.7444 records/second. Loss is 1.6699964. Sequential266afc8b's hyper parameters: Current learning rate is 9.099181073703367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8064/60000][Iteration 1001][Wall Clock 105.081989639s] Trained 128 records in 0.094408642 seconds. Throughput is 1355.8081 records/second. Loss is 1.6380606. Sequential266afc8b's hyper parameters: Current learning rate is 9.090909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 1002][Wall Clock 105.171486468s] Trained 128 records in 0.089496829 seconds. Throughput is 1430.2183 records/second. Loss is 1.6652796. Sequential266afc8b's hyper parameters: Current learning rate is 9.082652134423252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8320/60000][Iteration 1003][Wall Clock 105.260586158s] Trained 128 records in 0.08909969 seconds. Throughput is 1436.5931 records/second. Loss is 1.6469471. Sequential266afc8b's hyper parameters: Current learning rate is 9.074410163339384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 1004][Wall Clock 105.350219087s] Trained 128 records in 0.089632929 seconds. Throughput is 1428.0466 records/second. Loss is 1.6729783. Sequential266afc8b's hyper parameters: Current learning rate is 9.066183136899366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8576/60000][Iteration 1005][Wall Clock 105.438676295s] Trained 128 records in 0.088457208 seconds. Throughput is 1447.0275 records/second. Loss is 1.6667415. Sequential266afc8b's hyper parameters: Current learning rate is 9.057971014492753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 1006][Wall Clock 105.528947816s] Trained 128 records in 0.090271521 seconds. Throughput is 1417.9445 records/second. Loss is 1.5827341. Sequential266afc8b's hyper parameters: Current learning rate is 9.049773755656108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8832/60000][Iteration 1007][Wall Clock 105.618623988s] Trained 128 records in 0.089676172 seconds. Throughput is 1427.358 records/second. Loss is 1.6128325. Sequential266afc8b's hyper parameters: Current learning rate is 9.041591320072332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 1008][Wall Clock 105.715777702s] Trained 128 records in 0.097153714 seconds. Throughput is 1317.4998 records/second. Loss is 1.6970643. Sequential266afc8b's hyper parameters: Current learning rate is 9.033423667570009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 9088/60000][Iteration 1009][Wall Clock 105.807437337s] Trained 128 records in 0.091659635 seconds. Throughput is 1396.4707 records/second. Loss is 1.5961446. Sequential266afc8b's hyper parameters: Current learning rate is 9.025270758122744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:04 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 1010][Wall Clock 105.89497704s] Trained 128 records in 0.087539703 seconds. Throughput is 1462.1937 records/second. Loss is 1.6613361. Sequential266afc8b's hyper parameters: Current learning rate is 9.017132551848513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 9344/60000][Iteration 1011][Wall Clock 105.985312785s] Trained 128 records in 0.090335745 seconds. Throughput is 1416.9364 records/second. Loss is 1.622563. Sequential266afc8b's hyper parameters: Current learning rate is 9.009009009009009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 1012][Wall Clock 106.077117212s] Trained 128 records in 0.091804427 seconds. Throughput is 1394.2682 records/second. Loss is 1.5779915. Sequential266afc8b's hyper parameters: Current learning rate is 9.000900090009002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 9600/60000][Iteration 1013][Wall Clock 106.169681308s] Trained 128 records in 0.092564096 seconds. Throughput is 1382.8256 records/second. Loss is 1.6823324. Sequential266afc8b's hyper parameters: Current learning rate is 8.992805755395683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 1014][Wall Clock 106.263056298s] Trained 128 records in 0.09337499 seconds. Throughput is 1370.8168 records/second. Loss is 1.6599216. Sequential266afc8b's hyper parameters: Current learning rate is 8.984725965858041E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 9856/60000][Iteration 1015][Wall Clock 106.354088207s] Trained 128 records in 0.091031909 seconds. Throughput is 1406.1003 records/second. Loss is 1.6735243. Sequential266afc8b's hyper parameters: Current learning rate is 8.976660682226211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 1016][Wall Clock 106.454680564s] Trained 128 records in 0.100592357 seconds. Throughput is 1272.4624 records/second. Loss is 1.6635671. Sequential266afc8b's hyper parameters: Current learning rate is 8.968609865470852E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 10112/60000][Iteration 1017][Wall Clock 106.554564912s] Trained 128 records in 0.099884348 seconds. Throughput is 1281.482 records/second. Loss is 1.592316. Sequential266afc8b's hyper parameters: Current learning rate is 8.960573476702509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 1018][Wall Clock 106.646114939s] Trained 128 records in 0.091550027 seconds. Throughput is 1398.1426 records/second. Loss is 1.6674733. Sequential266afc8b's hyper parameters: Current learning rate is 8.952551477170994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 10368/60000][Iteration 1019][Wall Clock 106.735004241s] Trained 128 records in 0.088889302 seconds. Throughput is 1439.9933 records/second. Loss is 1.5600014. Sequential266afc8b's hyper parameters: Current learning rate is 8.944543828264759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 1020][Wall Clock 106.834341468s] Trained 128 records in 0.099337227 seconds. Throughput is 1288.54 records/second. Loss is 1.6518588. Sequential266afc8b's hyper parameters: Current learning rate is 8.936550491510278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:05 INFO  DistriOptimizer$:408 - [Epoch 3 10624/60000][Iteration 1021][Wall Clock 106.924647295s] Trained 128 records in 0.090305827 seconds. Throughput is 1417.4058 records/second. Loss is 1.6109504. Sequential266afc8b's hyper parameters: Current learning rate is 8.928571428571428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 1022][Wall Clock 107.013252085s] Trained 128 records in 0.08860479 seconds. Throughput is 1444.6171 records/second. Loss is 1.6922536. Sequential266afc8b's hyper parameters: Current learning rate is 8.920606601248884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 10880/60000][Iteration 1023][Wall Clock 107.103471754s] Trained 128 records in 0.090219669 seconds. Throughput is 1418.7594 records/second. Loss is 1.7200538. Sequential266afc8b's hyper parameters: Current learning rate is 8.9126559714795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 1024][Wall Clock 107.199008062s] Trained 128 records in 0.095536308 seconds. Throughput is 1339.8048 records/second. Loss is 1.5310247. Sequential266afc8b's hyper parameters: Current learning rate is 8.904719501335708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11136/60000][Iteration 1025][Wall Clock 107.283517155s] Trained 128 records in 0.084509093 seconds. Throughput is 1514.63 records/second. Loss is 1.5633836. Sequential266afc8b's hyper parameters: Current learning rate is 8.896797153024911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 1026][Wall Clock 107.373069592s] Trained 128 records in 0.089552437 seconds. Throughput is 1429.3301 records/second. Loss is 1.6551615. Sequential266afc8b's hyper parameters: Current learning rate is 8.888888888888889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11392/60000][Iteration 1027][Wall Clock 107.462622584s] Trained 128 records in 0.089552992 seconds. Throughput is 1429.3213 records/second. Loss is 1.6997023. Sequential266afc8b's hyper parameters: Current learning rate is 8.880994671403197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 1028][Wall Clock 107.552173039s] Trained 128 records in 0.089550455 seconds. Throughput is 1429.3618 records/second. Loss is 1.58076. Sequential266afc8b's hyper parameters: Current learning rate is 8.873114463176575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11648/60000][Iteration 1029][Wall Clock 107.641591966s] Trained 128 records in 0.089418927 seconds. Throughput is 1431.4644 records/second. Loss is 1.6843404. Sequential266afc8b's hyper parameters: Current learning rate is 8.865248226950355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 1030][Wall Clock 107.732200051s] Trained 128 records in 0.090608085 seconds. Throughput is 1412.6775 records/second. Loss is 1.6535037. Sequential266afc8b's hyper parameters: Current learning rate is 8.857395925597873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 11904/60000][Iteration 1031][Wall Clock 107.820860407s] Trained 128 records in 0.088660356 seconds. Throughput is 1443.7117 records/second. Loss is 1.6294377. Sequential266afc8b's hyper parameters: Current learning rate is 8.849557522123894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:06 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 1032][Wall Clock 107.90932643s] Trained 128 records in 0.088466023 seconds. Throughput is 1446.8832 records/second. Loss is 1.6492504. Sequential266afc8b's hyper parameters: Current learning rate is 8.841732979664014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12160/60000][Iteration 1033][Wall Clock 107.998771769s] Trained 128 records in 0.089445339 seconds. Throughput is 1431.0416 records/second. Loss is 1.6188179. Sequential266afc8b's hyper parameters: Current learning rate is 8.833922261484099E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 1034][Wall Clock 108.088430388s] Trained 128 records in 0.089658619 seconds. Throughput is 1427.6375 records/second. Loss is 1.6211349. Sequential266afc8b's hyper parameters: Current learning rate is 8.8261253309797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12416/60000][Iteration 1035][Wall Clock 108.178951788s] Trained 128 records in 0.0905214 seconds. Throughput is 1414.0303 records/second. Loss is 1.6114168. Sequential266afc8b's hyper parameters: Current learning rate is 8.818342151675486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 1036][Wall Clock 108.267305335s] Trained 128 records in 0.088353547 seconds. Throughput is 1448.7251 records/second. Loss is 1.5552814. Sequential266afc8b's hyper parameters: Current learning rate is 8.81057268722467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12672/60000][Iteration 1037][Wall Clock 108.355744811s] Trained 128 records in 0.088439476 seconds. Throughput is 1447.3174 records/second. Loss is 1.670038. Sequential266afc8b's hyper parameters: Current learning rate is 8.802816901408451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 1038][Wall Clock 108.447142027s] Trained 128 records in 0.091397216 seconds. Throughput is 1400.4802 records/second. Loss is 1.6163938. Sequential266afc8b's hyper parameters: Current learning rate is 8.795074758135443E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 12928/60000][Iteration 1039][Wall Clock 108.536253658s] Trained 128 records in 0.089111631 seconds. Throughput is 1436.4005 records/second. Loss is 1.5664035. Sequential266afc8b's hyper parameters: Current learning rate is 8.787346221441124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 1040][Wall Clock 108.629669009s] Trained 128 records in 0.093415351 seconds. Throughput is 1370.2245 records/second. Loss is 1.6365143. Sequential266afc8b's hyper parameters: Current learning rate is 8.77963125548727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 13184/60000][Iteration 1041][Wall Clock 108.727742378s] Trained 128 records in 0.098073369 seconds. Throughput is 1305.1453 records/second. Loss is 1.6221843. Sequential266afc8b's hyper parameters: Current learning rate is 8.771929824561404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 1042][Wall Clock 108.810048415s] Trained 128 records in 0.082306037 seconds. Throughput is 1555.1715 records/second. Loss is 1.5956789. Sequential266afc8b's hyper parameters: Current learning rate is 8.764241893076249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:07 INFO  DistriOptimizer$:408 - [Epoch 3 13440/60000][Iteration 1043][Wall Clock 108.901696977s] Trained 128 records in 0.091648562 seconds. Throughput is 1396.6394 records/second. Loss is 1.6111977. Sequential266afc8b's hyper parameters: Current learning rate is 8.756567425569177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 1044][Wall Clock 108.986874771s] Trained 128 records in 0.085177794 seconds. Throughput is 1502.7391 records/second. Loss is 1.6591204. Sequential266afc8b's hyper parameters: Current learning rate is 8.748906386701663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 13696/60000][Iteration 1045][Wall Clock 109.085445431s] Trained 128 records in 0.09857066 seconds. Throughput is 1298.5609 records/second. Loss is 1.6409408. Sequential266afc8b's hyper parameters: Current learning rate is 8.741258741258742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 1046][Wall Clock 109.175387202s] Trained 128 records in 0.089941771 seconds. Throughput is 1423.143 records/second. Loss is 1.6054533. Sequential266afc8b's hyper parameters: Current learning rate is 8.733624454148471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 13952/60000][Iteration 1047][Wall Clock 109.263100183s] Trained 128 records in 0.087712981 seconds. Throughput is 1459.305 records/second. Loss is 1.6961704. Sequential266afc8b's hyper parameters: Current learning rate is 8.726003490401395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 1048][Wall Clock 109.35191853s] Trained 128 records in 0.088818347 seconds. Throughput is 1441.1437 records/second. Loss is 1.6195636. Sequential266afc8b's hyper parameters: Current learning rate is 8.718395815170008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14208/60000][Iteration 1049][Wall Clock 109.444330385s] Trained 128 records in 0.092411855 seconds. Throughput is 1385.1038 records/second. Loss is 1.6052215. Sequential266afc8b's hyper parameters: Current learning rate is 8.710801393728223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 1050][Wall Clock 109.527728502s] Trained 128 records in 0.083398117 seconds. Throughput is 1534.8068 records/second. Loss is 1.6463461. Sequential266afc8b's hyper parameters: Current learning rate is 8.703220191470844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14464/60000][Iteration 1051][Wall Clock 109.617527976s] Trained 128 records in 0.089799474 seconds. Throughput is 1425.3982 records/second. Loss is 1.698477. Sequential266afc8b's hyper parameters: Current learning rate is 8.695652173913044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 1052][Wall Clock 109.709001658s] Trained 128 records in 0.091473682 seconds. Throughput is 1399.3096 records/second. Loss is 1.5975082. Sequential266afc8b's hyper parameters: Current learning rate is 8.688097306689836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14720/60000][Iteration 1053][Wall Clock 109.797080564s] Trained 128 records in 0.088078906 seconds. Throughput is 1453.2423 records/second. Loss is 1.6393006. Sequential266afc8b's hyper parameters: Current learning rate is 8.680555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:08 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 1054][Wall Clock 109.888291346s] Trained 128 records in 0.091210782 seconds. Throughput is 1403.3429 records/second. Loss is 1.6702006. Sequential266afc8b's hyper parameters: Current learning rate is 8.673026886383349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 14976/60000][Iteration 1055][Wall Clock 109.980320929s] Trained 128 records in 0.092029583 seconds. Throughput is 1390.857 records/second. Loss is 1.6641746. Sequential266afc8b's hyper parameters: Current learning rate is 8.665511265164644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 1056][Wall Clock 110.06977712s] Trained 128 records in 0.089456191 seconds. Throughput is 1430.8679 records/second. Loss is 1.6149042. Sequential266afc8b's hyper parameters: Current learning rate is 8.658008658008658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15232/60000][Iteration 1057][Wall Clock 110.160894923s] Trained 128 records in 0.091117803 seconds. Throughput is 1404.7749 records/second. Loss is 1.6510856. Sequential266afc8b's hyper parameters: Current learning rate is 8.650519031141869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 1058][Wall Clock 110.253027122s] Trained 128 records in 0.092132199 seconds. Throughput is 1389.308 records/second. Loss is 1.6343865. Sequential266afc8b's hyper parameters: Current learning rate is 8.64304235090752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15488/60000][Iteration 1059][Wall Clock 110.345067168s] Trained 128 records in 0.092040046 seconds. Throughput is 1390.699 records/second. Loss is 1.606898. Sequential266afc8b's hyper parameters: Current learning rate is 8.635578583765112E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 1060][Wall Clock 110.438333219s] Trained 128 records in 0.093266051 seconds. Throughput is 1372.418 records/second. Loss is 1.6135266. Sequential266afc8b's hyper parameters: Current learning rate is 8.628127696289905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15744/60000][Iteration 1061][Wall Clock 110.532628676s] Trained 128 records in 0.094295457 seconds. Throughput is 1357.4355 records/second. Loss is 1.5770779. Sequential266afc8b's hyper parameters: Current learning rate is 8.620689655172415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 1062][Wall Clock 110.634573875s] Trained 128 records in 0.101945199 seconds. Throughput is 1255.5765 records/second. Loss is 1.6848911. Sequential266afc8b's hyper parameters: Current learning rate is 8.613264427217917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 16000/60000][Iteration 1063][Wall Clock 110.726080714s] Trained 128 records in 0.091506839 seconds. Throughput is 1398.8026 records/second. Loss is 1.6163017. Sequential266afc8b's hyper parameters: Current learning rate is 8.605851979345954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 1064][Wall Clock 110.818613122s] Trained 128 records in 0.092532408 seconds. Throughput is 1383.2991 records/second. Loss is 1.5670035. Sequential266afc8b's hyper parameters: Current learning rate is 8.598452278589853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:09 INFO  DistriOptimizer$:408 - [Epoch 3 16256/60000][Iteration 1065][Wall Clock 110.912399005s] Trained 128 records in 0.093785883 seconds. Throughput is 1364.8109 records/second. Loss is 1.5526356. Sequential266afc8b's hyper parameters: Current learning rate is 8.59106529209622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 1066][Wall Clock 111.008901117s] Trained 128 records in 0.096502112 seconds. Throughput is 1326.3959 records/second. Loss is 1.5922345. Sequential266afc8b's hyper parameters: Current learning rate is 8.583690987124463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 16512/60000][Iteration 1067][Wall Clock 111.124234809s] Trained 128 records in 0.115333692 seconds. Throughput is 1109.8231 records/second. Loss is 1.6047214. Sequential266afc8b's hyper parameters: Current learning rate is 8.576329331046312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 1068][Wall Clock 111.219270275s] Trained 128 records in 0.095035466 seconds. Throughput is 1346.8656 records/second. Loss is 1.5832908. Sequential266afc8b's hyper parameters: Current learning rate is 8.56898029134533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 16768/60000][Iteration 1069][Wall Clock 111.307463878s] Trained 128 records in 0.088193603 seconds. Throughput is 1451.3524 records/second. Loss is 1.6237742. Sequential266afc8b's hyper parameters: Current learning rate is 8.561643835616439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 1070][Wall Clock 111.402978014s] Trained 128 records in 0.095514136 seconds. Throughput is 1340.1158 records/second. Loss is 1.5930445. Sequential266afc8b's hyper parameters: Current learning rate is 8.554319931565441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 17024/60000][Iteration 1071][Wall Clock 111.492287353s] Trained 128 records in 0.089309339 seconds. Throughput is 1433.2207 records/second. Loss is 1.6014527. Sequential266afc8b's hyper parameters: Current learning rate is 8.547008547008546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 1072][Wall Clock 111.587990852s] Trained 128 records in 0.095703499 seconds. Throughput is 1337.4642 records/second. Loss is 1.6986456. Sequential266afc8b's hyper parameters: Current learning rate is 8.539709649871904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 17280/60000][Iteration 1073][Wall Clock 111.675647497s] Trained 128 records in 0.087656645 seconds. Throughput is 1460.2429 records/second. Loss is 1.6589296. Sequential266afc8b's hyper parameters: Current learning rate is 8.532423208191126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 1074][Wall Clock 111.765483801s] Trained 128 records in 0.089836304 seconds. Throughput is 1424.8137 records/second. Loss is 1.5821753. Sequential266afc8b's hyper parameters: Current learning rate is 8.525149190110827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:10 INFO  DistriOptimizer$:408 - [Epoch 3 17536/60000][Iteration 1075][Wall Clock 111.859771165s] Trained 128 records in 0.094287364 seconds. Throughput is 1357.552 records/second. Loss is 1.6298182. Sequential266afc8b's hyper parameters: Current learning rate is 8.517887563884157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 1076][Wall Clock 111.949558921s] Trained 128 records in 0.089787756 seconds. Throughput is 1425.5841 records/second. Loss is 1.5966948. Sequential266afc8b's hyper parameters: Current learning rate is 8.51063829787234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 17792/60000][Iteration 1077][Wall Clock 112.041761889s] Trained 128 records in 0.092202968 seconds. Throughput is 1388.2416 records/second. Loss is 1.6809118. Sequential266afc8b's hyper parameters: Current learning rate is 8.503401360544218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 1078][Wall Clock 112.132115879s] Trained 128 records in 0.09035399 seconds. Throughput is 1416.6503 records/second. Loss is 1.6059165. Sequential266afc8b's hyper parameters: Current learning rate is 8.496176720475786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18048/60000][Iteration 1079][Wall Clock 112.221928096s] Trained 128 records in 0.089812217 seconds. Throughput is 1425.1958 records/second. Loss is 1.5867014. Sequential266afc8b's hyper parameters: Current learning rate is 8.488964346349746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 1080][Wall Clock 112.310598031s] Trained 128 records in 0.088669935 seconds. Throughput is 1443.5558 records/second. Loss is 1.6437153. Sequential266afc8b's hyper parameters: Current learning rate is 8.481764206955047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18304/60000][Iteration 1081][Wall Clock 112.401945935s] Trained 128 records in 0.091347904 seconds. Throughput is 1401.2363 records/second. Loss is 1.604844. Sequential266afc8b's hyper parameters: Current learning rate is 8.47457627118644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 1082][Wall Clock 112.494680328s] Trained 128 records in 0.092734393 seconds. Throughput is 1380.2861 records/second. Loss is 1.5463547. Sequential266afc8b's hyper parameters: Current learning rate is 8.46740050804403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18560/60000][Iteration 1083][Wall Clock 112.588487735s] Trained 128 records in 0.093807407 seconds. Throughput is 1364.4978 records/second. Loss is 1.6379706. Sequential266afc8b's hyper parameters: Current learning rate is 8.460236886632825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 1084][Wall Clock 112.682438657s] Trained 128 records in 0.093950922 seconds. Throughput is 1362.4135 records/second. Loss is 1.6370902. Sequential266afc8b's hyper parameters: Current learning rate is 8.4530853761623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18816/60000][Iteration 1085][Wall Clock 112.772253366s] Trained 128 records in 0.089814709 seconds. Throughput is 1425.1564 records/second. Loss is 1.5821388. Sequential266afc8b's hyper parameters: Current learning rate is 8.445945945945946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:11 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 1086][Wall Clock 112.861344969s] Trained 128 records in 0.089091603 seconds. Throughput is 1436.7234 records/second. Loss is 1.5363638. Sequential266afc8b's hyper parameters: Current learning rate is 8.438818565400844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19072/60000][Iteration 1087][Wall Clock 112.955334818s] Trained 128 records in 0.093989849 seconds. Throughput is 1361.8492 records/second. Loss is 1.5699804. Sequential266afc8b's hyper parameters: Current learning rate is 8.431703204047218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 1088][Wall Clock 113.049896278s] Trained 128 records in 0.09456146 seconds. Throughput is 1353.6171 records/second. Loss is 1.5944008. Sequential266afc8b's hyper parameters: Current learning rate is 8.424599831508003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19328/60000][Iteration 1089][Wall Clock 113.144075191s] Trained 128 records in 0.094178913 seconds. Throughput is 1359.1152 records/second. Loss is 1.6114591. Sequential266afc8b's hyper parameters: Current learning rate is 8.417508417508417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 1090][Wall Clock 113.233244119s] Trained 128 records in 0.089168928 seconds. Throughput is 1435.4777 records/second. Loss is 1.6708455. Sequential266afc8b's hyper parameters: Current learning rate is 8.410428931875525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19584/60000][Iteration 1091][Wall Clock 113.324774865s] Trained 128 records in 0.091530746 seconds. Throughput is 1398.4371 records/second. Loss is 1.5778266. Sequential266afc8b's hyper parameters: Current learning rate is 8.403361344537815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 1092][Wall Clock 113.424842521s] Trained 128 records in 0.100067656 seconds. Throughput is 1279.1346 records/second. Loss is 1.5652378. Sequential266afc8b's hyper parameters: Current learning rate is 8.396305625524769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19840/60000][Iteration 1093][Wall Clock 113.513978145s] Trained 128 records in 0.089135624 seconds. Throughput is 1436.0139 records/second. Loss is 1.6200241. Sequential266afc8b's hyper parameters: Current learning rate is 8.389261744966443E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 1094][Wall Clock 113.599824613s] Trained 128 records in 0.085846468 seconds. Throughput is 1491.0339 records/second. Loss is 1.5293787. Sequential266afc8b's hyper parameters: Current learning rate is 8.382229673093043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 20096/60000][Iteration 1095][Wall Clock 113.6894668s] Trained 128 records in 0.089642187 seconds. Throughput is 1427.899 records/second. Loss is 1.6394348. Sequential266afc8b's hyper parameters: Current learning rate is 8.375209380234506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 1096][Wall Clock 113.784757683s] Trained 128 records in 0.095290883 seconds. Throughput is 1343.2555 records/second. Loss is 1.6495534. Sequential266afc8b's hyper parameters: Current learning rate is 8.368200836820083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:12 INFO  DistriOptimizer$:408 - [Epoch 3 20352/60000][Iteration 1097][Wall Clock 113.872955324s] Trained 128 records in 0.088197641 seconds. Throughput is 1451.286 records/second. Loss is 1.5925547. Sequential266afc8b's hyper parameters: Current learning rate is 8.361204013377926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 1098][Wall Clock 113.960647585s] Trained 128 records in 0.087692261 seconds. Throughput is 1459.6499 records/second. Loss is 1.5658507. Sequential266afc8b's hyper parameters: Current learning rate is 8.35421888053467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 20608/60000][Iteration 1099][Wall Clock 114.053508682s] Trained 128 records in 0.092861097 seconds. Throughput is 1378.4028 records/second. Loss is 1.5938537. Sequential266afc8b's hyper parameters: Current learning rate is 8.347245409015025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 1100][Wall Clock 114.150717801s] Trained 128 records in 0.097209119 seconds. Throughput is 1316.7489 records/second. Loss is 1.5179342. Sequential266afc8b's hyper parameters: Current learning rate is 8.340283569641367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 20864/60000][Iteration 1101][Wall Clock 114.236470036s] Trained 128 records in 0.085752235 seconds. Throughput is 1492.6725 records/second. Loss is 1.583777. Sequential266afc8b's hyper parameters: Current learning rate is 8.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 1102][Wall Clock 114.329221664s] Trained 128 records in 0.092751628 seconds. Throughput is 1380.0297 records/second. Loss is 1.6404079. Sequential266afc8b's hyper parameters: Current learning rate is 8.326394671107411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 21120/60000][Iteration 1103][Wall Clock 114.420317516s] Trained 128 records in 0.091095852 seconds. Throughput is 1405.1134 records/second. Loss is 1.595459. Sequential266afc8b's hyper parameters: Current learning rate is 8.319467554076539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 1104][Wall Clock 114.511349921s] Trained 128 records in 0.091032405 seconds. Throughput is 1406.0927 records/second. Loss is 1.61277. Sequential266afc8b's hyper parameters: Current learning rate is 8.312551953449709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 21376/60000][Iteration 1105][Wall Clock 114.602355155s] Trained 128 records in 0.091005234 seconds. Throughput is 1406.5125 records/second. Loss is 1.5811588. Sequential266afc8b's hyper parameters: Current learning rate is 8.305647840531561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 1106][Wall Clock 114.692137071s] Trained 128 records in 0.089781916 seconds. Throughput is 1425.6769 records/second. Loss is 1.5935698. Sequential266afc8b's hyper parameters: Current learning rate is 8.298755186721991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 21632/60000][Iteration 1107][Wall Clock 114.780922816s] Trained 128 records in 0.088785745 seconds. Throughput is 1441.6729 records/second. Loss is 1.6070858. Sequential266afc8b's hyper parameters: Current learning rate is 8.291873963515755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:13 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 1108][Wall Clock 114.871844648s] Trained 128 records in 0.090921832 seconds. Throughput is 1407.8026 records/second. Loss is 1.5836611. Sequential266afc8b's hyper parameters: Current learning rate is 8.285004142502071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 21888/60000][Iteration 1109][Wall Clock 114.958921509s] Trained 128 records in 0.087076861 seconds. Throughput is 1469.9658 records/second. Loss is 1.5872406. Sequential266afc8b's hyper parameters: Current learning rate is 8.278145695364238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 1110][Wall Clock 115.044147517s] Trained 128 records in 0.085226008 seconds. Throughput is 1501.8889 records/second. Loss is 1.6083207. Sequential266afc8b's hyper parameters: Current learning rate is 8.271298593879239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22144/60000][Iteration 1111][Wall Clock 115.133578714s] Trained 128 records in 0.089431197 seconds. Throughput is 1431.268 records/second. Loss is 1.6741608. Sequential266afc8b's hyper parameters: Current learning rate is 8.264462809917356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 1112][Wall Clock 115.223483101s] Trained 128 records in 0.089904387 seconds. Throughput is 1423.7347 records/second. Loss is 1.6195235. Sequential266afc8b's hyper parameters: Current learning rate is 8.257638315441784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22400/60000][Iteration 1113][Wall Clock 115.316397202s] Trained 128 records in 0.092914101 seconds. Throughput is 1377.6165 records/second. Loss is 1.6538485. Sequential266afc8b's hyper parameters: Current learning rate is 8.25082508250825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 1114][Wall Clock 115.407671327s] Trained 128 records in 0.091274125 seconds. Throughput is 1402.3689 records/second. Loss is 1.5037762. Sequential266afc8b's hyper parameters: Current learning rate is 8.244023083264633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22656/60000][Iteration 1115][Wall Clock 115.500965059s] Trained 128 records in 0.093293732 seconds. Throughput is 1372.0107 records/second. Loss is 1.592356. Sequential266afc8b's hyper parameters: Current learning rate is 8.237232289950577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 1116][Wall Clock 115.588864838s] Trained 128 records in 0.087899779 seconds. Throughput is 1456.2039 records/second. Loss is 1.5870225. Sequential266afc8b's hyper parameters: Current learning rate is 8.230452674897119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 22912/60000][Iteration 1117][Wall Clock 115.678159902s] Trained 128 records in 0.089295064 seconds. Throughput is 1433.4498 records/second. Loss is 1.6252413. Sequential266afc8b's hyper parameters: Current learning rate is 8.223684210526315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 1118][Wall Clock 115.780773405s] Trained 128 records in 0.102613503 seconds. Throughput is 1247.3992 records/second. Loss is 1.5987825. Sequential266afc8b's hyper parameters: Current learning rate is 8.216926869350863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:14 INFO  DistriOptimizer$:408 - [Epoch 3 23168/60000][Iteration 1119][Wall Clock 115.869649386s] Trained 128 records in 0.088875981 seconds. Throughput is 1440.2092 records/second. Loss is 1.6692848. Sequential266afc8b's hyper parameters: Current learning rate is 8.210180623973728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 1120][Wall Clock 115.961108554s] Trained 128 records in 0.091459168 seconds. Throughput is 1399.5316 records/second. Loss is 1.5833274. Sequential266afc8b's hyper parameters: Current learning rate is 8.203445447087777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 23424/60000][Iteration 1121][Wall Clock 116.055156869s] Trained 128 records in 0.094048315 seconds. Throughput is 1361.0026 records/second. Loss is 1.5745243. Sequential266afc8b's hyper parameters: Current learning rate is 8.19672131147541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 1122][Wall Clock 116.148446069s] Trained 128 records in 0.0932892 seconds. Throughput is 1372.0774 records/second. Loss is 1.5695237. Sequential266afc8b's hyper parameters: Current learning rate is 8.190008190008189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 23680/60000][Iteration 1123][Wall Clock 116.240019407s] Trained 128 records in 0.091573338 seconds. Throughput is 1397.7869 records/second. Loss is 1.6089219. Sequential266afc8b's hyper parameters: Current learning rate is 8.18330605564648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 1124][Wall Clock 116.333986011s] Trained 128 records in 0.093966604 seconds. Throughput is 1362.186 records/second. Loss is 1.5954571. Sequential266afc8b's hyper parameters: Current learning rate is 8.176614881439084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 23936/60000][Iteration 1125][Wall Clock 116.421785846s] Trained 128 records in 0.087799835 seconds. Throughput is 1457.8616 records/second. Loss is 1.5419669. Sequential266afc8b's hyper parameters: Current learning rate is 8.169934640522876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 1126][Wall Clock 116.517119353s] Trained 128 records in 0.095333507 seconds. Throughput is 1342.6549 records/second. Loss is 1.5968326. Sequential266afc8b's hyper parameters: Current learning rate is 8.163265306122449E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 24192/60000][Iteration 1127][Wall Clock 116.610035958s] Trained 128 records in 0.092916605 seconds. Throughput is 1377.5793 records/second. Loss is 1.5603946. Sequential266afc8b's hyper parameters: Current learning rate is 8.156606851549756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 1128][Wall Clock 116.698501787s] Trained 128 records in 0.088465829 seconds. Throughput is 1446.8864 records/second. Loss is 1.5826069. Sequential266afc8b's hyper parameters: Current learning rate is 8.14995925020375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 24448/60000][Iteration 1129][Wall Clock 116.787609099s] Trained 128 records in 0.089107312 seconds. Throughput is 1436.4702 records/second. Loss is 1.6379925. Sequential266afc8b's hyper parameters: Current learning rate is 8.143322475570033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:15 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 1130][Wall Clock 116.880411874s] Trained 128 records in 0.092802775 seconds. Throughput is 1379.269 records/second. Loss is 1.5663717. Sequential266afc8b's hyper parameters: Current learning rate is 8.136696501220504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 24704/60000][Iteration 1131][Wall Clock 116.968308968s] Trained 128 records in 0.087897094 seconds. Throughput is 1456.2484 records/second. Loss is 1.538107. Sequential266afc8b's hyper parameters: Current learning rate is 8.130081300813008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 1132][Wall Clock 117.057587901s] Trained 128 records in 0.089278933 seconds. Throughput is 1433.7089 records/second. Loss is 1.584017. Sequential266afc8b's hyper parameters: Current learning rate is 8.123476848090983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 24960/60000][Iteration 1133][Wall Clock 117.151724173s] Trained 128 records in 0.094136272 seconds. Throughput is 1359.7308 records/second. Loss is 1.6267211. Sequential266afc8b's hyper parameters: Current learning rate is 8.116883116883116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 1134][Wall Clock 117.240513396s] Trained 128 records in 0.088789223 seconds. Throughput is 1441.6163 records/second. Loss is 1.5717992. Sequential266afc8b's hyper parameters: Current learning rate is 8.110300081103001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25216/60000][Iteration 1135][Wall Clock 117.331409661s] Trained 128 records in 0.090896265 seconds. Throughput is 1408.1987 records/second. Loss is 1.6144012. Sequential266afc8b's hyper parameters: Current learning rate is 8.103727714748785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 1136][Wall Clock 117.421628008s] Trained 128 records in 0.090218347 seconds. Throughput is 1418.7802 records/second. Loss is 1.6063333. Sequential266afc8b's hyper parameters: Current learning rate is 8.097165991902835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25472/60000][Iteration 1137][Wall Clock 117.50842784s] Trained 128 records in 0.086799832 seconds. Throughput is 1474.6572 records/second. Loss is 1.6244571. Sequential266afc8b's hyper parameters: Current learning rate is 8.090614886731392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 1138][Wall Clock 117.597482177s] Trained 128 records in 0.089054337 seconds. Throughput is 1437.3247 records/second. Loss is 1.6409743. Sequential266afc8b's hyper parameters: Current learning rate is 8.084074373484236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25728/60000][Iteration 1139][Wall Clock 117.688917845s] Trained 128 records in 0.091435668 seconds. Throughput is 1399.8914 records/second. Loss is 1.590156. Sequential266afc8b's hyper parameters: Current learning rate is 8.077544426494345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 1140][Wall Clock 117.776698516s] Trained 128 records in 0.087780671 seconds. Throughput is 1458.1798 records/second. Loss is 1.5895724. Sequential266afc8b's hyper parameters: Current learning rate is 8.071025020177562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:16 INFO  DistriOptimizer$:408 - [Epoch 3 25984/60000][Iteration 1141][Wall Clock 117.866483818s] Trained 128 records in 0.089785302 seconds. Throughput is 1425.6232 records/second. Loss is 1.637755. Sequential266afc8b's hyper parameters: Current learning rate is 8.064516129032258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 1142][Wall Clock 117.962410137s] Trained 128 records in 0.095926319 seconds. Throughput is 1334.3574 records/second. Loss is 1.5790681. Sequential266afc8b's hyper parameters: Current learning rate is 8.058017727639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26240/60000][Iteration 1143][Wall Clock 118.057509519s] Trained 128 records in 0.095099382 seconds. Throughput is 1345.9603 records/second. Loss is 1.5757365. Sequential266afc8b's hyper parameters: Current learning rate is 8.051529790660225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 1144][Wall Clock 118.147875244s] Trained 128 records in 0.090365725 seconds. Throughput is 1416.4663 records/second. Loss is 1.5632443. Sequential266afc8b's hyper parameters: Current learning rate is 8.045052292839904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26496/60000][Iteration 1145][Wall Clock 118.231783129s] Trained 128 records in 0.083907885 seconds. Throughput is 1525.4823 records/second. Loss is 1.5892357. Sequential266afc8b's hyper parameters: Current learning rate is 8.038585209003216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 1146][Wall Clock 118.323709915s] Trained 128 records in 0.091926786 seconds. Throughput is 1392.4125 records/second. Loss is 1.6361088. Sequential266afc8b's hyper parameters: Current learning rate is 8.032128514056224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26752/60000][Iteration 1147][Wall Clock 118.412006319s] Trained 128 records in 0.088296404 seconds. Throughput is 1449.6626 records/second. Loss is 1.5473654. Sequential266afc8b's hyper parameters: Current learning rate is 8.025682182985554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 1148][Wall Clock 118.499682678s] Trained 128 records in 0.087676359 seconds. Throughput is 1459.9146 records/second. Loss is 1.5735288. Sequential266afc8b's hyper parameters: Current learning rate is 8.019246190858059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 27008/60000][Iteration 1149][Wall Clock 118.589146039s] Trained 128 records in 0.089463361 seconds. Throughput is 1430.7533 records/second. Loss is 1.5419861. Sequential266afc8b's hyper parameters: Current learning rate is 8.012820512820513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 1150][Wall Clock 118.67821179s] Trained 128 records in 0.089065751 seconds. Throughput is 1437.1405 records/second. Loss is 1.4907229. Sequential266afc8b's hyper parameters: Current learning rate is 8.00640512409928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 27264/60000][Iteration 1151][Wall Clock 118.774906426s] Trained 128 records in 0.096694636 seconds. Throughput is 1323.755 records/second. Loss is 1.5715034. Sequential266afc8b's hyper parameters: Current learning rate is 8.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:17 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 1152][Wall Clock 118.863974564s] Trained 128 records in 0.089068138 seconds. Throughput is 1437.102 records/second. Loss is 1.6319984. Sequential266afc8b's hyper parameters: Current learning rate is 7.993605115907274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 27520/60000][Iteration 1153][Wall Clock 118.959614259s] Trained 128 records in 0.095639695 seconds. Throughput is 1338.3563 records/second. Loss is 1.6029004. Sequential266afc8b's hyper parameters: Current learning rate is 7.987220447284346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 1154][Wall Clock 119.05146287s] Trained 128 records in 0.091848611 seconds. Throughput is 1393.5975 records/second. Loss is 1.5379512. Sequential266afc8b's hyper parameters: Current learning rate is 7.980845969672786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 27776/60000][Iteration 1155][Wall Clock 119.142102915s] Trained 128 records in 0.090640045 seconds. Throughput is 1412.1793 records/second. Loss is 1.607131. Sequential266afc8b's hyper parameters: Current learning rate is 7.974481658692185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 1156][Wall Clock 119.231862535s] Trained 128 records in 0.08975962 seconds. Throughput is 1426.031 records/second. Loss is 1.5329888. Sequential266afc8b's hyper parameters: Current learning rate is 7.96812749003984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28032/60000][Iteration 1157][Wall Clock 119.319638834s] Trained 128 records in 0.087776299 seconds. Throughput is 1458.2524 records/second. Loss is 1.5705372. Sequential266afc8b's hyper parameters: Current learning rate is 7.961783439490445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 1158][Wall Clock 119.410065479s] Trained 128 records in 0.090426645 seconds. Throughput is 1415.512 records/second. Loss is 1.5924731. Sequential266afc8b's hyper parameters: Current learning rate is 7.955449482895784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28288/60000][Iteration 1159][Wall Clock 119.502989103s] Trained 128 records in 0.092923624 seconds. Throughput is 1377.4753 records/second. Loss is 1.6632351. Sequential266afc8b's hyper parameters: Current learning rate is 7.94912559618442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 1160][Wall Clock 119.592054137s] Trained 128 records in 0.089065034 seconds. Throughput is 1437.152 records/second. Loss is 1.587352. Sequential266afc8b's hyper parameters: Current learning rate is 7.942811755361399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28544/60000][Iteration 1161][Wall Clock 119.68129221s] Trained 128 records in 0.089238073 seconds. Throughput is 1434.3654 records/second. Loss is 1.6482722. Sequential266afc8b's hyper parameters: Current learning rate is 7.936507936507937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 1162][Wall Clock 119.770047154s] Trained 128 records in 0.088754944 seconds. Throughput is 1442.1732 records/second. Loss is 1.5890216. Sequential266afc8b's hyper parameters: Current learning rate is 7.930214115781126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:18 INFO  DistriOptimizer$:408 - [Epoch 3 28800/60000][Iteration 1163][Wall Clock 119.858542455s] Trained 128 records in 0.088495301 seconds. Throughput is 1446.4045 records/second. Loss is 1.6365662. Sequential266afc8b's hyper parameters: Current learning rate is 7.923930269413628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 1164][Wall Clock 119.951154738s] Trained 128 records in 0.092612283 seconds. Throughput is 1382.1061 records/second. Loss is 1.6153755. Sequential266afc8b's hyper parameters: Current learning rate is 7.91765637371338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29056/60000][Iteration 1165][Wall Clock 120.039512489s] Trained 128 records in 0.088357751 seconds. Throughput is 1448.6561 records/second. Loss is 1.5737273. Sequential266afc8b's hyper parameters: Current learning rate is 7.911392405063291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 1166][Wall Clock 120.129525516s] Trained 128 records in 0.090013027 seconds. Throughput is 1422.0164 records/second. Loss is 1.4885167. Sequential266afc8b's hyper parameters: Current learning rate is 7.905138339920949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29312/60000][Iteration 1167][Wall Clock 120.217838611s] Trained 128 records in 0.088313095 seconds. Throughput is 1449.3887 records/second. Loss is 1.6281316. Sequential266afc8b's hyper parameters: Current learning rate is 7.898894154818325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 1168][Wall Clock 120.313866331s] Trained 128 records in 0.09602772 seconds. Throughput is 1332.9485 records/second. Loss is 1.597887. Sequential266afc8b's hyper parameters: Current learning rate is 7.892659826361484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29568/60000][Iteration 1169][Wall Clock 120.404450608s] Trained 128 records in 0.090584277 seconds. Throughput is 1413.0487 records/second. Loss is 1.6439162. Sequential266afc8b's hyper parameters: Current learning rate is 7.886435331230285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 1170][Wall Clock 120.489410795s] Trained 128 records in 0.084960187 seconds. Throughput is 1506.588 records/second. Loss is 1.6228805. Sequential266afc8b's hyper parameters: Current learning rate is 7.880220646178094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29824/60000][Iteration 1171][Wall Clock 120.578992166s] Trained 128 records in 0.089581371 seconds. Throughput is 1428.8685 records/second. Loss is 1.5997323. Sequential266afc8b's hyper parameters: Current learning rate is 7.874015748031496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 1172][Wall Clock 120.670277684s] Trained 128 records in 0.091285518 seconds. Throughput is 1402.194 records/second. Loss is 1.5680294. Sequential266afc8b's hyper parameters: Current learning rate is 7.867820613690008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 30080/60000][Iteration 1173][Wall Clock 120.757468206s] Trained 128 records in 0.087190522 seconds. Throughput is 1468.0494 records/second. Loss is 1.515333. Sequential266afc8b's hyper parameters: Current learning rate is 7.861635220125786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:19 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 1174][Wall Clock 120.851219215s] Trained 128 records in 0.093751009 seconds. Throughput is 1365.3187 records/second. Loss is 1.631728. Sequential266afc8b's hyper parameters: Current learning rate is 7.855459544383346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 30336/60000][Iteration 1175][Wall Clock 120.936974236s] Trained 128 records in 0.085755021 seconds. Throughput is 1492.624 records/second. Loss is 1.5549355. Sequential266afc8b's hyper parameters: Current learning rate is 7.849293563579278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 1176][Wall Clock 121.033844825s] Trained 128 records in 0.096870589 seconds. Throughput is 1321.3505 records/second. Loss is 1.6241313. Sequential266afc8b's hyper parameters: Current learning rate is 7.84313725490196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 30592/60000][Iteration 1177][Wall Clock 121.123595009s] Trained 128 records in 0.089750184 seconds. Throughput is 1426.1809 records/second. Loss is 1.6440368. Sequential266afc8b's hyper parameters: Current learning rate is 7.836990595611286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 1178][Wall Clock 121.208429245s] Trained 128 records in 0.084834236 seconds. Throughput is 1508.8248 records/second. Loss is 1.5434656. Sequential266afc8b's hyper parameters: Current learning rate is 7.830853563038371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 30848/60000][Iteration 1179][Wall Clock 121.295594888s] Trained 128 records in 0.087165643 seconds. Throughput is 1468.4684 records/second. Loss is 1.5924387. Sequential266afc8b's hyper parameters: Current learning rate is 7.82472613458529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 1180][Wall Clock 121.385488807s] Trained 128 records in 0.089893919 seconds. Throughput is 1423.9005 records/second. Loss is 1.5901963. Sequential266afc8b's hyper parameters: Current learning rate is 7.818608287724785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 31104/60000][Iteration 1181][Wall Clock 121.476261368s] Trained 128 records in 0.090772561 seconds. Throughput is 1410.1178 records/second. Loss is 1.5483141. Sequential266afc8b's hyper parameters: Current learning rate is 7.812499999999999E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 1182][Wall Clock 121.564362697s] Trained 128 records in 0.088101329 seconds. Throughput is 1452.8726 records/second. Loss is 1.5619942. Sequential266afc8b's hyper parameters: Current learning rate is 7.8064012490242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 31360/60000][Iteration 1183][Wall Clock 121.651749149s] Trained 128 records in 0.087386452 seconds. Throughput is 1464.7579 records/second. Loss is 1.6360259. Sequential266afc8b's hyper parameters: Current learning rate is 7.8003120124805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 1184][Wall Clock 121.741985604s] Trained 128 records in 0.090236455 seconds. Throughput is 1418.4955 records/second. Loss is 1.609097. Sequential266afc8b's hyper parameters: Current learning rate is 7.79423226812159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:20 INFO  DistriOptimizer$:408 - [Epoch 3 31616/60000][Iteration 1185][Wall Clock 121.830482917s] Trained 128 records in 0.088497313 seconds. Throughput is 1446.3716 records/second. Loss is 1.5874408. Sequential266afc8b's hyper parameters: Current learning rate is 7.78816199376947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 1186][Wall Clock 121.91808683s] Trained 128 records in 0.087603913 seconds. Throughput is 1461.122 records/second. Loss is 1.5807297. Sequential266afc8b's hyper parameters: Current learning rate is 7.782101167315176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 31872/60000][Iteration 1187][Wall Clock 122.007966309s] Trained 128 records in 0.089879479 seconds. Throughput is 1424.1294 records/second. Loss is 1.6077448. Sequential266afc8b's hyper parameters: Current learning rate is 7.776049766718507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 1188][Wall Clock 122.094106045s] Trained 128 records in 0.086139736 seconds. Throughput is 1485.9576 records/second. Loss is 1.4995754. Sequential266afc8b's hyper parameters: Current learning rate is 7.77000777000777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32128/60000][Iteration 1189][Wall Clock 122.183126282s] Trained 128 records in 0.089020237 seconds. Throughput is 1437.8752 records/second. Loss is 1.5872263. Sequential266afc8b's hyper parameters: Current learning rate is 7.763975155279503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 1190][Wall Clock 122.273814252s] Trained 128 records in 0.09068797 seconds. Throughput is 1411.4331 records/second. Loss is 1.5647066. Sequential266afc8b's hyper parameters: Current learning rate is 7.757951900698216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32384/60000][Iteration 1191][Wall Clock 122.363189141s] Trained 128 records in 0.089374889 seconds. Throughput is 1432.1696 records/second. Loss is 1.5847479. Sequential266afc8b's hyper parameters: Current learning rate is 7.751937984496124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 1192][Wall Clock 122.45156876s] Trained 128 records in 0.088379619 seconds. Throughput is 1448.2977 records/second. Loss is 1.596531. Sequential266afc8b's hyper parameters: Current learning rate is 7.74593338497289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32640/60000][Iteration 1193][Wall Clock 122.545819969s] Trained 128 records in 0.094251209 seconds. Throughput is 1358.0728 records/second. Loss is 1.5125638. Sequential266afc8b's hyper parameters: Current learning rate is 7.739938080495357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 1194][Wall Clock 122.640730389s] Trained 128 records in 0.09491042 seconds. Throughput is 1348.6401 records/second. Loss is 1.6062038. Sequential266afc8b's hyper parameters: Current learning rate is 7.733952049497294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 32896/60000][Iteration 1195][Wall Clock 122.729614262s] Trained 128 records in 0.088883873 seconds. Throughput is 1440.0813 records/second. Loss is 1.5998657. Sequential266afc8b's hyper parameters: Current learning rate is 7.727975270479135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:21 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 1196][Wall Clock 122.815419044s] Trained 128 records in 0.085804782 seconds. Throughput is 1491.7583 records/second. Loss is 1.5078433. Sequential266afc8b's hyper parameters: Current learning rate is 7.722007722007722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33152/60000][Iteration 1197][Wall Clock 122.910957446s] Trained 128 records in 0.095538402 seconds. Throughput is 1339.7754 records/second. Loss is 1.5955793. Sequential266afc8b's hyper parameters: Current learning rate is 7.716049382716049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 1198][Wall Clock 123.003802674s] Trained 128 records in 0.092845228 seconds. Throughput is 1378.6384 records/second. Loss is 1.5571796. Sequential266afc8b's hyper parameters: Current learning rate is 7.710100231303007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33408/60000][Iteration 1199][Wall Clock 123.096555775s] Trained 128 records in 0.092753101 seconds. Throughput is 1380.0078 records/second. Loss is 1.5884281. Sequential266afc8b's hyper parameters: Current learning rate is 7.704160246533128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 1200][Wall Clock 123.187665516s] Trained 128 records in 0.091109741 seconds. Throughput is 1404.8992 records/second. Loss is 1.5812676. Sequential266afc8b's hyper parameters: Current learning rate is 7.698229407236335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33664/60000][Iteration 1201][Wall Clock 123.292915108s] Trained 128 records in 0.105249592 seconds. Throughput is 1216.1567 records/second. Loss is 1.5392023. Sequential266afc8b's hyper parameters: Current learning rate is 7.692307692307692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 1202][Wall Clock 123.375415552s] Trained 128 records in 0.082500444 seconds. Throughput is 1551.5068 records/second. Loss is 1.5679646. Sequential266afc8b's hyper parameters: Current learning rate is 7.686395080707148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 33920/60000][Iteration 1203][Wall Clock 123.463383338s] Trained 128 records in 0.087967786 seconds. Throughput is 1455.0781 records/second. Loss is 1.5725205. Sequential266afc8b's hyper parameters: Current learning rate is 7.680491551459293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 1204][Wall Clock 123.551694214s] Trained 128 records in 0.088310876 seconds. Throughput is 1449.4252 records/second. Loss is 1.4865665. Sequential266afc8b's hyper parameters: Current learning rate is 7.674597083653108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 34176/60000][Iteration 1205][Wall Clock 123.643424798s] Trained 128 records in 0.091730584 seconds. Throughput is 1395.3906 records/second. Loss is 1.536028. Sequential266afc8b's hyper parameters: Current learning rate is 7.668711656441717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 1206][Wall Clock 123.731450554s] Trained 128 records in 0.088025756 seconds. Throughput is 1454.1199 records/second. Loss is 1.6064487. Sequential266afc8b's hyper parameters: Current learning rate is 7.662835249042146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:22 INFO  DistriOptimizer$:408 - [Epoch 3 34432/60000][Iteration 1207][Wall Clock 123.820456307s] Trained 128 records in 0.089005753 seconds. Throughput is 1438.1093 records/second. Loss is 1.5290313. Sequential266afc8b's hyper parameters: Current learning rate is 7.656967840735069E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 1208][Wall Clock 123.914769296s] Trained 128 records in 0.094312989 seconds. Throughput is 1357.1832 records/second. Loss is 1.5563085. Sequential266afc8b's hyper parameters: Current learning rate is 7.651109410864575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 34688/60000][Iteration 1209][Wall Clock 124.004207035s] Trained 128 records in 0.089437739 seconds. Throughput is 1431.1632 records/second. Loss is 1.4858216. Sequential266afc8b's hyper parameters: Current learning rate is 7.645259938837921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 1210][Wall Clock 124.096238648s] Trained 128 records in 0.092031613 seconds. Throughput is 1390.8264 records/second. Loss is 1.5412734. Sequential266afc8b's hyper parameters: Current learning rate is 7.639419404125286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 34944/60000][Iteration 1211][Wall Clock 124.188563228s] Trained 128 records in 0.09232458 seconds. Throughput is 1386.4131 records/second. Loss is 1.5639222. Sequential266afc8b's hyper parameters: Current learning rate is 7.633587786259542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 1212][Wall Clock 124.277855199s] Trained 128 records in 0.089291971 seconds. Throughput is 1433.4996 records/second. Loss is 1.5479867. Sequential266afc8b's hyper parameters: Current learning rate is 7.627765064836003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35200/60000][Iteration 1213][Wall Clock 124.368739658s] Trained 128 records in 0.090884459 seconds. Throughput is 1408.3816 records/second. Loss is 1.6533074. Sequential266afc8b's hyper parameters: Current learning rate is 7.621951219512194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 1214][Wall Clock 124.46353131s] Trained 128 records in 0.094791652 seconds. Throughput is 1350.33 records/second. Loss is 1.5990161. Sequential266afc8b's hyper parameters: Current learning rate is 7.616146230007616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35456/60000][Iteration 1215][Wall Clock 124.550562979s] Trained 128 records in 0.087031669 seconds. Throughput is 1470.729 records/second. Loss is 1.4838312. Sequential266afc8b's hyper parameters: Current learning rate is 7.6103500761035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 1216][Wall Clock 124.637948479s] Trained 128 records in 0.0873855 seconds. Throughput is 1464.7739 records/second. Loss is 1.6806884. Sequential266afc8b's hyper parameters: Current learning rate is 7.604562737642585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35712/60000][Iteration 1217][Wall Clock 124.725958508s] Trained 128 records in 0.088010029 seconds. Throughput is 1454.3798 records/second. Loss is 1.5087805. Sequential266afc8b's hyper parameters: Current learning rate is 7.598784194528875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:23 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 1218][Wall Clock 124.818770764s] Trained 128 records in 0.092812256 seconds. Throughput is 1379.1282 records/second. Loss is 1.5795429. Sequential266afc8b's hyper parameters: Current learning rate is 7.593014426727411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 35968/60000][Iteration 1219][Wall Clock 124.9162641s] Trained 128 records in 0.097493336 seconds. Throughput is 1312.9103 records/second. Loss is 1.632842. Sequential266afc8b's hyper parameters: Current learning rate is 7.587253414264037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 1220][Wall Clock 125.006535625s] Trained 128 records in 0.090271525 seconds. Throughput is 1417.9443 records/second. Loss is 1.5623142. Sequential266afc8b's hyper parameters: Current learning rate is 7.58150113722517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36224/60000][Iteration 1221][Wall Clock 125.094135277s] Trained 128 records in 0.087599652 seconds. Throughput is 1461.193 records/second. Loss is 1.5465959. Sequential266afc8b's hyper parameters: Current learning rate is 7.575757575757576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 1222][Wall Clock 125.180003149s] Trained 128 records in 0.085867872 seconds. Throughput is 1490.6622 records/second. Loss is 1.43319. Sequential266afc8b's hyper parameters: Current learning rate is 7.57002271006813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36480/60000][Iteration 1223][Wall Clock 125.270361722s] Trained 128 records in 0.090358573 seconds. Throughput is 1416.5784 records/second. Loss is 1.466706. Sequential266afc8b's hyper parameters: Current learning rate is 7.564296520423601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 1224][Wall Clock 125.35869928s] Trained 128 records in 0.088337558 seconds. Throughput is 1448.9873 records/second. Loss is 1.5464398. Sequential266afc8b's hyper parameters: Current learning rate is 7.558578987150416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36736/60000][Iteration 1225][Wall Clock 125.446485544s] Trained 128 records in 0.087786264 seconds. Throughput is 1458.0869 records/second. Loss is 1.5959089. Sequential266afc8b's hyper parameters: Current learning rate is 7.552870090634441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 1226][Wall Clock 125.534924786s] Trained 128 records in 0.088439242 seconds. Throughput is 1447.3213 records/second. Loss is 1.546999. Sequential266afc8b's hyper parameters: Current learning rate is 7.547169811320754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 36992/60000][Iteration 1227][Wall Clock 125.632302591s] Trained 128 records in 0.097377805 seconds. Throughput is 1314.4679 records/second. Loss is 1.529511. Sequential266afc8b's hyper parameters: Current learning rate is 7.541478129713424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 1228][Wall Clock 125.721658254s] Trained 128 records in 0.089355663 seconds. Throughput is 1432.4778 records/second. Loss is 1.5694304. Sequential266afc8b's hyper parameters: Current learning rate is 7.535795026375283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:24 INFO  DistriOptimizer$:408 - [Epoch 3 37248/60000][Iteration 1229][Wall Clock 125.810551184s] Trained 128 records in 0.08889293 seconds. Throughput is 1439.9346 records/second. Loss is 1.4636098. Sequential266afc8b's hyper parameters: Current learning rate is 7.53012048192771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 1230][Wall Clock 125.90177008s] Trained 128 records in 0.091218896 seconds. Throughput is 1403.218 records/second. Loss is 1.5869195. Sequential266afc8b's hyper parameters: Current learning rate is 7.524454477050414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 37504/60000][Iteration 1231][Wall Clock 125.992429629s] Trained 128 records in 0.090659549 seconds. Throughput is 1411.8755 records/second. Loss is 1.5776293. Sequential266afc8b's hyper parameters: Current learning rate is 7.518796992481202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 1232][Wall Clock 126.081447452s] Trained 128 records in 0.089017823 seconds. Throughput is 1437.9143 records/second. Loss is 1.4951663. Sequential266afc8b's hyper parameters: Current learning rate is 7.513148009015778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 37760/60000][Iteration 1233][Wall Clock 126.17212765s] Trained 128 records in 0.090680198 seconds. Throughput is 1411.5541 records/second. Loss is 1.5850434. Sequential266afc8b's hyper parameters: Current learning rate is 7.507507507507507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 1234][Wall Clock 126.262474548s] Trained 128 records in 0.090346898 seconds. Throughput is 1416.7615 records/second. Loss is 1.5748278. Sequential266afc8b's hyper parameters: Current learning rate is 7.501875468867217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 38016/60000][Iteration 1235][Wall Clock 126.350254149s] Trained 128 records in 0.087779601 seconds. Throughput is 1458.1975 records/second. Loss is 1.5740008. Sequential266afc8b's hyper parameters: Current learning rate is 7.496251874062968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 1236][Wall Clock 126.43856192s] Trained 128 records in 0.088307771 seconds. Throughput is 1449.4761 records/second. Loss is 1.5961826. Sequential266afc8b's hyper parameters: Current learning rate is 7.49063670411985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 38272/60000][Iteration 1237][Wall Clock 126.527877674s] Trained 128 records in 0.089315754 seconds. Throughput is 1433.1178 records/second. Loss is 1.5174247. Sequential266afc8b's hyper parameters: Current learning rate is 7.485029940119761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 1238][Wall Clock 126.617504222s] Trained 128 records in 0.089626548 seconds. Throughput is 1428.1482 records/second. Loss is 1.5104015. Sequential266afc8b's hyper parameters: Current learning rate is 7.479431563201197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 38528/60000][Iteration 1239][Wall Clock 126.705890128s] Trained 128 records in 0.088385906 seconds. Throughput is 1448.1947 records/second. Loss is 1.5499926. Sequential266afc8b's hyper parameters: Current learning rate is 7.473841554559044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:25 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 1240][Wall Clock 126.79469435s] Trained 128 records in 0.088804222 seconds. Throughput is 1441.3729 records/second. Loss is 1.5537163. Sequential266afc8b's hyper parameters: Current learning rate is 7.468259895444361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 38784/60000][Iteration 1241][Wall Clock 126.881349657s] Trained 128 records in 0.086655307 seconds. Throughput is 1477.1167 records/second. Loss is 1.544363. Sequential266afc8b's hyper parameters: Current learning rate is 7.462686567164179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 1242][Wall Clock 126.973932691s] Trained 128 records in 0.092583034 seconds. Throughput is 1382.5427 records/second. Loss is 1.4794192. Sequential266afc8b's hyper parameters: Current learning rate is 7.457121551081283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39040/60000][Iteration 1243][Wall Clock 127.062740707s] Trained 128 records in 0.088808016 seconds. Throughput is 1441.3114 records/second. Loss is 1.5459017. Sequential266afc8b's hyper parameters: Current learning rate is 7.451564828614009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 1244][Wall Clock 127.170457168s] Trained 128 records in 0.107716461 seconds. Throughput is 1188.3049 records/second. Loss is 1.5522041. Sequential266afc8b's hyper parameters: Current learning rate is 7.446016381236039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39296/60000][Iteration 1245][Wall Clock 127.278114189s] Trained 128 records in 0.107657021 seconds. Throughput is 1188.9609 records/second. Loss is 1.5235227. Sequential266afc8b's hyper parameters: Current learning rate is 7.440476190476191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 1246][Wall Clock 127.375662945s] Trained 128 records in 0.097548756 seconds. Throughput is 1312.1644 records/second. Loss is 1.547071. Sequential266afc8b's hyper parameters: Current learning rate is 7.434944237918215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39552/60000][Iteration 1247][Wall Clock 127.460927983s] Trained 128 records in 0.085265038 seconds. Throughput is 1501.2014 records/second. Loss is 1.5931808. Sequential266afc8b's hyper parameters: Current learning rate is 7.429420505200594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 1248][Wall Clock 127.553539386s] Trained 128 records in 0.092611403 seconds. Throughput is 1382.1193 records/second. Loss is 1.5241672. Sequential266afc8b's hyper parameters: Current learning rate is 7.423904974016332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39808/60000][Iteration 1249][Wall Clock 127.650324083s] Trained 128 records in 0.096784697 seconds. Throughput is 1322.5232 records/second. Loss is 1.5876774. Sequential266afc8b's hyper parameters: Current learning rate is 7.41839762611276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:26 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 1250][Wall Clock 127.739731093s] Trained 128 records in 0.08940701 seconds. Throughput is 1431.655 records/second. Loss is 1.5025257. Sequential266afc8b's hyper parameters: Current learning rate is 7.412898443291327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40064/60000][Iteration 1251][Wall Clock 127.836106945s] Trained 128 records in 0.096375852 seconds. Throughput is 1328.1335 records/second. Loss is 1.5680424. Sequential266afc8b's hyper parameters: Current learning rate is 7.407407407407407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 1252][Wall Clock 127.93565454s] Trained 128 records in 0.099547595 seconds. Throughput is 1285.8171 records/second. Loss is 1.5063764. Sequential266afc8b's hyper parameters: Current learning rate is 7.401924500370097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40320/60000][Iteration 1253][Wall Clock 128.023419576s] Trained 128 records in 0.087765036 seconds. Throughput is 1458.4396 records/second. Loss is 1.4768009. Sequential266afc8b's hyper parameters: Current learning rate is 7.396449704142013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 1254][Wall Clock 128.115844914s] Trained 128 records in 0.092425338 seconds. Throughput is 1384.9016 records/second. Loss is 1.6041728. Sequential266afc8b's hyper parameters: Current learning rate is 7.390983000739098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40576/60000][Iteration 1255][Wall Clock 128.208537809s] Trained 128 records in 0.092692895 seconds. Throughput is 1380.904 records/second. Loss is 1.5954391. Sequential266afc8b's hyper parameters: Current learning rate is 7.385524372230428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 1256][Wall Clock 128.298794849s] Trained 128 records in 0.09025704 seconds. Throughput is 1418.1719 records/second. Loss is 1.5057949. Sequential266afc8b's hyper parameters: Current learning rate is 7.380073800738007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40832/60000][Iteration 1257][Wall Clock 128.389961303s] Trained 128 records in 0.091166454 seconds. Throughput is 1404.0253 records/second. Loss is 1.5183095. Sequential266afc8b's hyper parameters: Current learning rate is 7.374631268436578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 1258][Wall Clock 128.481451654s] Trained 128 records in 0.091490351 seconds. Throughput is 1399.0547 records/second. Loss is 1.5487226. Sequential266afc8b's hyper parameters: Current learning rate is 7.369196757553427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 41088/60000][Iteration 1259][Wall Clock 128.569059515s] Trained 128 records in 0.087607861 seconds. Throughput is 1461.0562 records/second. Loss is 1.5843215. Sequential266afc8b's hyper parameters: Current learning rate is 7.363770250368188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 1260][Wall Clock 128.662484217s] Trained 128 records in 0.093424702 seconds. Throughput is 1370.0874 records/second. Loss is 1.6066363. Sequential266afc8b's hyper parameters: Current learning rate is 7.358351729212656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:27 INFO  DistriOptimizer$:408 - [Epoch 3 41344/60000][Iteration 1261][Wall Clock 128.751856723s] Trained 128 records in 0.089372506 seconds. Throughput is 1432.2078 records/second. Loss is 1.5670455. Sequential266afc8b's hyper parameters: Current learning rate is 7.352941176470588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 1262][Wall Clock 128.838085038s] Trained 128 records in 0.086228315 seconds. Throughput is 1484.4312 records/second. Loss is 1.524578. Sequential266afc8b's hyper parameters: Current learning rate is 7.347538574577517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 41600/60000][Iteration 1263][Wall Clock 128.928308811s] Trained 128 records in 0.090223773 seconds. Throughput is 1418.6948 records/second. Loss is 1.5628296. Sequential266afc8b's hyper parameters: Current learning rate is 7.342143906020558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 1264][Wall Clock 129.019314246s] Trained 128 records in 0.091005435 seconds. Throughput is 1406.5094 records/second. Loss is 1.4738843. Sequential266afc8b's hyper parameters: Current learning rate is 7.336757153338224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 41856/60000][Iteration 1265][Wall Clock 129.10979582s] Trained 128 records in 0.090481574 seconds. Throughput is 1414.6527 records/second. Loss is 1.6860425. Sequential266afc8b's hyper parameters: Current learning rate is 7.331378299120235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 1266][Wall Clock 129.19942669s] Trained 128 records in 0.08963087 seconds. Throughput is 1428.0793 records/second. Loss is 1.662922. Sequential266afc8b's hyper parameters: Current learning rate is 7.326007326007326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 42112/60000][Iteration 1267][Wall Clock 129.290270267s] Trained 128 records in 0.090843577 seconds. Throughput is 1409.0154 records/second. Loss is 1.5838201. Sequential266afc8b's hyper parameters: Current learning rate is 7.320644216691069E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 1268][Wall Clock 129.380891664s] Trained 128 records in 0.090621397 seconds. Throughput is 1412.47 records/second. Loss is 1.4771273. Sequential266afc8b's hyper parameters: Current learning rate is 7.31528895391368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 42368/60000][Iteration 1269][Wall Clock 129.472369502s] Trained 128 records in 0.091477838 seconds. Throughput is 1399.246 records/second. Loss is 1.5812325. Sequential266afc8b's hyper parameters: Current learning rate is 7.309941520467837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 1270][Wall Clock 129.570335911s] Trained 128 records in 0.097966409 seconds. Throughput is 1306.5703 records/second. Loss is 1.4825666. Sequential266afc8b's hyper parameters: Current learning rate is 7.304601899196494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 42624/60000][Iteration 1271][Wall Clock 129.658648955s] Trained 128 records in 0.088313044 seconds. Throughput is 1449.3895 records/second. Loss is 1.5335854. Sequential266afc8b's hyper parameters: Current learning rate is 7.2992700729927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:28 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 1272][Wall Clock 129.749774618s] Trained 128 records in 0.091125663 seconds. Throughput is 1404.6538 records/second. Loss is 1.5522172. Sequential266afc8b's hyper parameters: Current learning rate is 7.293946024799417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 42880/60000][Iteration 1273][Wall Clock 129.836903895s] Trained 128 records in 0.087129277 seconds. Throughput is 1469.0813 records/second. Loss is 1.5279757. Sequential266afc8b's hyper parameters: Current learning rate is 7.288629737609329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 1274][Wall Clock 129.923401328s] Trained 128 records in 0.086497433 seconds. Throughput is 1479.8127 records/second. Loss is 1.5247425. Sequential266afc8b's hyper parameters: Current learning rate is 7.283321194464676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43136/60000][Iteration 1275][Wall Clock 130.0142485s] Trained 128 records in 0.090847172 seconds. Throughput is 1408.9597 records/second. Loss is 1.6182684. Sequential266afc8b's hyper parameters: Current learning rate is 7.27802037845706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 1276][Wall Clock 130.110480091s] Trained 128 records in 0.096231591 seconds. Throughput is 1330.1245 records/second. Loss is 1.5991493. Sequential266afc8b's hyper parameters: Current learning rate is 7.272727272727273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43392/60000][Iteration 1277][Wall Clock 130.200430744s] Trained 128 records in 0.089950653 seconds. Throughput is 1423.0024 records/second. Loss is 1.537314. Sequential266afc8b's hyper parameters: Current learning rate is 7.267441860465116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 1278][Wall Clock 130.30228954s] Trained 128 records in 0.101858796 seconds. Throughput is 1256.6416 records/second. Loss is 1.5601795. Sequential266afc8b's hyper parameters: Current learning rate is 7.262164124909223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43648/60000][Iteration 1279][Wall Clock 130.395019485s] Trained 128 records in 0.092729945 seconds. Throughput is 1380.3523 records/second. Loss is 1.5474281. Sequential266afc8b's hyper parameters: Current learning rate is 7.25689404934688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 1280][Wall Clock 130.485971495s] Trained 128 records in 0.09095201 seconds. Throughput is 1407.3356 records/second. Loss is 1.5688496. Sequential266afc8b's hyper parameters: Current learning rate is 7.25163161711385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 43904/60000][Iteration 1281][Wall Clock 130.57832725s] Trained 128 records in 0.092355755 seconds. Throughput is 1385.945 records/second. Loss is 1.5858299. Sequential266afc8b's hyper parameters: Current learning rate is 7.246376811594203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 1282][Wall Clock 130.671700553s] Trained 128 records in 0.093373303 seconds. Throughput is 1370.8414 records/second. Loss is 1.5342714. Sequential266afc8b's hyper parameters: Current learning rate is 7.24112961622013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:29 INFO  DistriOptimizer$:408 - [Epoch 3 44160/60000][Iteration 1283][Wall Clock 130.758671357s] Trained 128 records in 0.086970804 seconds. Throughput is 1471.7582 records/second. Loss is 1.5082359. Sequential266afc8b's hyper parameters: Current learning rate is 7.23589001447178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 1284][Wall Clock 130.849126467s] Trained 128 records in 0.09045511 seconds. Throughput is 1415.0665 records/second. Loss is 1.6029404. Sequential266afc8b's hyper parameters: Current learning rate is 7.230657989877079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 44416/60000][Iteration 1285][Wall Clock 130.939787091s] Trained 128 records in 0.090660624 seconds. Throughput is 1411.8588 records/second. Loss is 1.5169806. Sequential266afc8b's hyper parameters: Current learning rate is 7.225433526011561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 1286][Wall Clock 131.029570262s] Trained 128 records in 0.089783171 seconds. Throughput is 1425.657 records/second. Loss is 1.6054522. Sequential266afc8b's hyper parameters: Current learning rate is 7.220216606498196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 44672/60000][Iteration 1287][Wall Clock 131.119407777s] Trained 128 records in 0.089837515 seconds. Throughput is 1424.7946 records/second. Loss is 1.497854. Sequential266afc8b's hyper parameters: Current learning rate is 7.215007215007215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 1288][Wall Clock 131.211873384s] Trained 128 records in 0.092465607 seconds. Throughput is 1384.2985 records/second. Loss is 1.5914346. Sequential266afc8b's hyper parameters: Current learning rate is 7.209805335255948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 44928/60000][Iteration 1289][Wall Clock 131.303573625s] Trained 128 records in 0.091700241 seconds. Throughput is 1395.8524 records/second. Loss is 1.5637181. Sequential266afc8b's hyper parameters: Current learning rate is 7.204610951008645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 1290][Wall Clock 131.39619568s] Trained 128 records in 0.092622055 seconds. Throughput is 1381.9602 records/second. Loss is 1.500847. Sequential266afc8b's hyper parameters: Current learning rate is 7.199424046076314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 45184/60000][Iteration 1291][Wall Clock 131.484382564s] Trained 128 records in 0.088186884 seconds. Throughput is 1451.463 records/second. Loss is 1.648171. Sequential266afc8b's hyper parameters: Current learning rate is 7.194244604316547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 1292][Wall Clock 131.573546644s] Trained 128 records in 0.08916408 seconds. Throughput is 1435.5557 records/second. Loss is 1.4968837. Sequential266afc8b's hyper parameters: Current learning rate is 7.189072609633358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 45440/60000][Iteration 1293][Wall Clock 131.660808659s] Trained 128 records in 0.087262015 seconds. Throughput is 1466.8468 records/second. Loss is 1.5366699. Sequential266afc8b's hyper parameters: Current learning rate is 7.183908045977011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:30 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 1294][Wall Clock 131.750454885s] Trained 128 records in 0.089646226 seconds. Throughput is 1427.8347 records/second. Loss is 1.5613816. Sequential266afc8b's hyper parameters: Current learning rate is 7.178750897343862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 45696/60000][Iteration 1295][Wall Clock 131.849953504s] Trained 128 records in 0.099498619 seconds. Throughput is 1286.45 records/second. Loss is 1.4710239. Sequential266afc8b's hyper parameters: Current learning rate is 7.173601147776184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 1296][Wall Clock 131.93463515s] Trained 128 records in 0.084681646 seconds. Throughput is 1511.5436 records/second. Loss is 1.4789212. Sequential266afc8b's hyper parameters: Current learning rate is 7.168458781362007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 45952/60000][Iteration 1297][Wall Clock 132.028512902s] Trained 128 records in 0.093877752 seconds. Throughput is 1363.4753 records/second. Loss is 1.5744785. Sequential266afc8b's hyper parameters: Current learning rate is 7.163323782234957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 1298][Wall Clock 132.116939362s] Trained 128 records in 0.08842646 seconds. Throughput is 1447.5305 records/second. Loss is 1.5414815. Sequential266afc8b's hyper parameters: Current learning rate is 7.158196134574087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46208/60000][Iteration 1299][Wall Clock 132.211379417s] Trained 128 records in 0.094440055 seconds. Throughput is 1355.357 records/second. Loss is 1.5142416. Sequential266afc8b's hyper parameters: Current learning rate is 7.15307582260372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 1300][Wall Clock 132.300613326s] Trained 128 records in 0.089233909 seconds. Throughput is 1434.4323 records/second. Loss is 1.5221579. Sequential266afc8b's hyper parameters: Current learning rate is 7.147962830593281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46464/60000][Iteration 1301][Wall Clock 132.397973303s] Trained 128 records in 0.097359977 seconds. Throughput is 1314.7086 records/second. Loss is 1.5616229. Sequential266afc8b's hyper parameters: Current learning rate is 7.142857142857143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 1302][Wall Clock 132.48591266s] Trained 128 records in 0.087939357 seconds. Throughput is 1455.5485 records/second. Loss is 1.6030095. Sequential266afc8b's hyper parameters: Current learning rate is 7.137758743754461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46720/60000][Iteration 1303][Wall Clock 132.575273511s] Trained 128 records in 0.089360851 seconds. Throughput is 1432.3947 records/second. Loss is 1.5286069. Sequential266afc8b's hyper parameters: Current learning rate is 7.132667617689016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 1304][Wall Clock 132.6651606s] Trained 128 records in 0.089887089 seconds. Throughput is 1424.0087 records/second. Loss is 1.5658886. Sequential266afc8b's hyper parameters: Current learning rate is 7.127583749109051E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:31 INFO  DistriOptimizer$:408 - [Epoch 3 46976/60000][Iteration 1305][Wall Clock 132.753649662s] Trained 128 records in 0.088489062 seconds. Throughput is 1446.5065 records/second. Loss is 1.5363932. Sequential266afc8b's hyper parameters: Current learning rate is 7.122507122507122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 1306][Wall Clock 132.840067639s] Trained 128 records in 0.086417977 seconds. Throughput is 1481.1732 records/second. Loss is 1.613433. Sequential266afc8b's hyper parameters: Current learning rate is 7.117437722419928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47232/60000][Iteration 1307][Wall Clock 132.927942664s] Trained 128 records in 0.087875025 seconds. Throughput is 1456.6141 records/second. Loss is 1.4909085. Sequential266afc8b's hyper parameters: Current learning rate is 7.112375533428165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 1308][Wall Clock 133.016589002s] Trained 128 records in 0.088646338 seconds. Throughput is 1443.9401 records/second. Loss is 1.5365552. Sequential266afc8b's hyper parameters: Current learning rate is 7.107320540156361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47488/60000][Iteration 1309][Wall Clock 133.105239359s] Trained 128 records in 0.088650357 seconds. Throughput is 1443.8745 records/second. Loss is 1.43829. Sequential266afc8b's hyper parameters: Current learning rate is 7.102272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 1310][Wall Clock 133.196563803s] Trained 128 records in 0.091324444 seconds. Throughput is 1401.5963 records/second. Loss is 1.6017089. Sequential266afc8b's hyper parameters: Current learning rate is 7.097232079489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47744/60000][Iteration 1311][Wall Clock 133.280463529s] Trained 128 records in 0.083899726 seconds. Throughput is 1525.6306 records/second. Loss is 1.5167425. Sequential266afc8b's hyper parameters: Current learning rate is 7.092198581560284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 1312][Wall Clock 133.369251935s] Trained 128 records in 0.088788406 seconds. Throughput is 1441.6296 records/second. Loss is 1.5429441. Sequential266afc8b's hyper parameters: Current learning rate is 7.087172218284905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 48000/60000][Iteration 1313][Wall Clock 133.461285621s] Trained 128 records in 0.092033686 seconds. Throughput is 1390.7952 records/second. Loss is 1.5658722. Sequential266afc8b's hyper parameters: Current learning rate is 7.082152974504249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 1314][Wall Clock 133.553939345s] Trained 128 records in 0.092653724 seconds. Throughput is 1381.4879 records/second. Loss is 1.4930958. Sequential266afc8b's hyper parameters: Current learning rate is 7.077140835102619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 48256/60000][Iteration 1315][Wall Clock 133.642780692s] Trained 128 records in 0.088841347 seconds. Throughput is 1440.7705 records/second. Loss is 1.6200912. Sequential266afc8b's hyper parameters: Current learning rate is 7.072135785007072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:32 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 1316][Wall Clock 133.732485854s] Trained 128 records in 0.089705162 seconds. Throughput is 1426.8967 records/second. Loss is 1.4675269. Sequential266afc8b's hyper parameters: Current learning rate is 7.067137809187279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 48512/60000][Iteration 1317][Wall Clock 133.823389094s] Trained 128 records in 0.09090324 seconds. Throughput is 1408.0907 records/second. Loss is 1.4649411. Sequential266afc8b's hyper parameters: Current learning rate is 7.062146892655367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 1318][Wall Clock 133.913765575s] Trained 128 records in 0.090376481 seconds. Throughput is 1416.2977 records/second. Loss is 1.5763872. Sequential266afc8b's hyper parameters: Current learning rate is 7.057163020465773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 48768/60000][Iteration 1319][Wall Clock 134.00664071s] Trained 128 records in 0.092875135 seconds. Throughput is 1378.1945 records/second. Loss is 1.4991853. Sequential266afc8b's hyper parameters: Current learning rate is 7.052186177715092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 1320][Wall Clock 134.110349835s] Trained 128 records in 0.103709125 seconds. Throughput is 1234.2212 records/second. Loss is 1.5166078. Sequential266afc8b's hyper parameters: Current learning rate is 7.047216349541931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49024/60000][Iteration 1321][Wall Clock 134.202298809s] Trained 128 records in 0.091948974 seconds. Throughput is 1392.0765 records/second. Loss is 1.4971944. Sequential266afc8b's hyper parameters: Current learning rate is 7.04225352112676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 1322][Wall Clock 134.285223899s] Trained 128 records in 0.08292509 seconds. Throughput is 1543.5618 records/second. Loss is 1.583574. Sequential266afc8b's hyper parameters: Current learning rate is 7.037297677691766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49280/60000][Iteration 1323][Wall Clock 134.374032237s] Trained 128 records in 0.088808338 seconds. Throughput is 1441.3062 records/second. Loss is 1.484707. Sequential266afc8b's hyper parameters: Current learning rate is 7.032348804500703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 1324][Wall Clock 134.461830128s] Trained 128 records in 0.087797891 seconds. Throughput is 1457.8938 records/second. Loss is 1.4650447. Sequential266afc8b's hyper parameters: Current learning rate is 7.027406886858749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49536/60000][Iteration 1325][Wall Clock 134.556275257s] Trained 128 records in 0.094445129 seconds. Throughput is 1355.2843 records/second. Loss is 1.5373433. Sequential266afc8b's hyper parameters: Current learning rate is 7.022471910112359E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 1326][Wall Clock 134.64313297s] Trained 128 records in 0.086857713 seconds. Throughput is 1473.6746 records/second. Loss is 1.5147853. Sequential266afc8b's hyper parameters: Current learning rate is 7.017543859649123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:33 INFO  DistriOptimizer$:408 - [Epoch 3 49792/60000][Iteration 1327][Wall Clock 134.731734538s] Trained 128 records in 0.088601568 seconds. Throughput is 1444.6697 records/second. Loss is 1.6527239. Sequential266afc8b's hyper parameters: Current learning rate is 7.012622720897616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 1328][Wall Clock 134.820321324s] Trained 128 records in 0.088586786 seconds. Throughput is 1444.9108 records/second. Loss is 1.5466999. Sequential266afc8b's hyper parameters: Current learning rate is 7.007708479327261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50048/60000][Iteration 1329][Wall Clock 134.917663651s] Trained 128 records in 0.097342327 seconds. Throughput is 1314.947 records/second. Loss is 1.5255591. Sequential266afc8b's hyper parameters: Current learning rate is 7.002801120448179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 1330][Wall Clock 135.01897237s] Trained 128 records in 0.101308719 seconds. Throughput is 1263.4648 records/second. Loss is 1.4871947. Sequential266afc8b's hyper parameters: Current learning rate is 6.997900629811056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50304/60000][Iteration 1331][Wall Clock 135.132614758s] Trained 128 records in 0.113642388 seconds. Throughput is 1126.3403 records/second. Loss is 1.527804. Sequential266afc8b's hyper parameters: Current learning rate is 6.993006993006993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 1332][Wall Clock 135.247553968s] Trained 128 records in 0.11493921 seconds. Throughput is 1113.6321 records/second. Loss is 1.4801645. Sequential266afc8b's hyper parameters: Current learning rate is 6.988120195667365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50560/60000][Iteration 1333][Wall Clock 135.360248235s] Trained 128 records in 0.112694267 seconds. Throughput is 1135.8164 records/second. Loss is 1.4794471. Sequential266afc8b's hyper parameters: Current learning rate is 6.983240223463687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 1334][Wall Clock 135.451370457s] Trained 128 records in 0.091122222 seconds. Throughput is 1404.7067 records/second. Loss is 1.5113419. Sequential266afc8b's hyper parameters: Current learning rate is 6.978367062107467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50816/60000][Iteration 1335][Wall Clock 135.54660831s] Trained 128 records in 0.095237853 seconds. Throughput is 1344.0034 records/second. Loss is 1.4572852. Sequential266afc8b's hyper parameters: Current learning rate is 6.97350069735007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 1336][Wall Clock 135.643575786s] Trained 128 records in 0.096967476 seconds. Throughput is 1320.0303 records/second. Loss is 1.5516089. Sequential266afc8b's hyper parameters: Current learning rate is 6.968641114982578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:34 INFO  DistriOptimizer$:408 - [Epoch 3 51072/60000][Iteration 1337][Wall Clock 135.738676061s] Trained 128 records in 0.095100275 seconds. Throughput is 1345.9478 records/second. Loss is 1.4789344. Sequential266afc8b's hyper parameters: Current learning rate is 6.963788300835655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 1338][Wall Clock 135.829129051s] Trained 128 records in 0.09045299 seconds. Throughput is 1415.0997 records/second. Loss is 1.5083203. Sequential266afc8b's hyper parameters: Current learning rate is 6.958942240779401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51328/60000][Iteration 1339][Wall Clock 135.944432485s] Trained 128 records in 0.115303434 seconds. Throughput is 1110.1144 records/second. Loss is 1.5096848. Sequential266afc8b's hyper parameters: Current learning rate is 6.954102920723226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 1340][Wall Clock 136.035449836s] Trained 128 records in 0.091017351 seconds. Throughput is 1406.3253 records/second. Loss is 1.5577145. Sequential266afc8b's hyper parameters: Current learning rate is 6.949270326615705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51584/60000][Iteration 1341][Wall Clock 136.131232907s] Trained 128 records in 0.095783071 seconds. Throughput is 1336.353 records/second. Loss is 1.4002131. Sequential266afc8b's hyper parameters: Current learning rate is 6.944444444444445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 1342][Wall Clock 136.226275698s] Trained 128 records in 0.095042791 seconds. Throughput is 1346.7618 records/second. Loss is 1.6087762. Sequential266afc8b's hyper parameters: Current learning rate is 6.939625260235947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51840/60000][Iteration 1343][Wall Clock 136.325956408s] Trained 128 records in 0.09968071 seconds. Throughput is 1284.1001 records/second. Loss is 1.441541. Sequential266afc8b's hyper parameters: Current learning rate is 6.934812760055479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 1344][Wall Clock 136.421354319s] Trained 128 records in 0.095397911 seconds. Throughput is 1341.7484 records/second. Loss is 1.5794168. Sequential266afc8b's hyper parameters: Current learning rate is 6.93000693000693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 52096/60000][Iteration 1345][Wall Clock 136.519546519s] Trained 128 records in 0.0981922 seconds. Throughput is 1303.5659 records/second. Loss is 1.5448992. Sequential266afc8b's hyper parameters: Current learning rate is 6.925207756232687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 1346][Wall Clock 136.61084256s] Trained 128 records in 0.091296041 seconds. Throughput is 1402.0323 records/second. Loss is 1.4927287. Sequential266afc8b's hyper parameters: Current learning rate is 6.920415224913495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:35 INFO  DistriOptimizer$:408 - [Epoch 3 52352/60000][Iteration 1347][Wall Clock 136.711077629s] Trained 128 records in 0.100235069 seconds. Throughput is 1276.9982 records/second. Loss is 1.4013969. Sequential266afc8b's hyper parameters: Current learning rate is 6.915629322268326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 1348][Wall Clock 136.80826295s] Trained 128 records in 0.097185321 seconds. Throughput is 1317.0713 records/second. Loss is 1.5314933. Sequential266afc8b's hyper parameters: Current learning rate is 6.91085003455425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 52608/60000][Iteration 1349][Wall Clock 136.897102299s] Trained 128 records in 0.088839349 seconds. Throughput is 1440.803 records/second. Loss is 1.5193195. Sequential266afc8b's hyper parameters: Current learning rate is 6.906077348066298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 1350][Wall Clock 136.986138635s] Trained 128 records in 0.089036336 seconds. Throughput is 1437.6152 records/second. Loss is 1.5106857. Sequential266afc8b's hyper parameters: Current learning rate is 6.901311249137336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 52864/60000][Iteration 1351][Wall Clock 137.075289855s] Trained 128 records in 0.08915122 seconds. Throughput is 1435.7628 records/second. Loss is 1.45526. Sequential266afc8b's hyper parameters: Current learning rate is 6.896551724137932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 1352][Wall Clock 137.163150604s] Trained 128 records in 0.087860749 seconds. Throughput is 1456.8508 records/second. Loss is 1.494942. Sequential266afc8b's hyper parameters: Current learning rate is 6.891798759476223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 53120/60000][Iteration 1353][Wall Clock 137.255918919s] Trained 128 records in 0.092768315 seconds. Throughput is 1379.7815 records/second. Loss is 1.4880729. Sequential266afc8b's hyper parameters: Current learning rate is 6.887052341597796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 1354][Wall Clock 137.356352142s] Trained 128 records in 0.100433223 seconds. Throughput is 1274.4786 records/second. Loss is 1.4689382. Sequential266afc8b's hyper parameters: Current learning rate is 6.882312456985547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 53376/60000][Iteration 1355][Wall Clock 137.440967042s] Trained 128 records in 0.0846149 seconds. Throughput is 1512.7358 records/second. Loss is 1.5217652. Sequential266afc8b's hyper parameters: Current learning rate is 6.87757909215956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 1356][Wall Clock 137.536512559s] Trained 128 records in 0.095545517 seconds. Throughput is 1339.6757 records/second. Loss is 1.5504932. Sequential266afc8b's hyper parameters: Current learning rate is 6.872852233676975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 53632/60000][Iteration 1357][Wall Clock 137.624737875s] Trained 128 records in 0.088225316 seconds. Throughput is 1450.8308 records/second. Loss is 1.584035. Sequential266afc8b's hyper parameters: Current learning rate is 6.868131868131868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:36 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 1358][Wall Clock 137.715074453s] Trained 128 records in 0.090336578 seconds. Throughput is 1416.9233 records/second. Loss is 1.4640135. Sequential266afc8b's hyper parameters: Current learning rate is 6.863417982155113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 53888/60000][Iteration 1359][Wall Clock 137.803037261s] Trained 128 records in 0.087962808 seconds. Throughput is 1455.1605 records/second. Loss is 1.4408815. Sequential266afc8b's hyper parameters: Current learning rate is 6.858710562414267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 1360][Wall Clock 137.902012492s] Trained 128 records in 0.098975231 seconds. Throughput is 1293.2528 records/second. Loss is 1.5066448. Sequential266afc8b's hyper parameters: Current learning rate is 6.854009595613434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54144/60000][Iteration 1361][Wall Clock 138.02180129s] Trained 128 records in 0.119788798 seconds. Throughput is 1068.5474 records/second. Loss is 1.5481488. Sequential266afc8b's hyper parameters: Current learning rate is 6.849315068493151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 1362][Wall Clock 138.114878253s] Trained 128 records in 0.093076963 seconds. Throughput is 1375.2059 records/second. Loss is 1.4429677. Sequential266afc8b's hyper parameters: Current learning rate is 6.844626967830253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54400/60000][Iteration 1363][Wall Clock 138.210192815s] Trained 128 records in 0.095314562 seconds. Throughput is 1342.9218 records/second. Loss is 1.5585599. Sequential266afc8b's hyper parameters: Current learning rate is 6.839945280437756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 1364][Wall Clock 138.303434562s] Trained 128 records in 0.093241747 seconds. Throughput is 1372.7758 records/second. Loss is 1.4997505. Sequential266afc8b's hyper parameters: Current learning rate is 6.835269993164729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54656/60000][Iteration 1365][Wall Clock 138.392868677s] Trained 128 records in 0.089434115 seconds. Throughput is 1431.2212 records/second. Loss is 1.43248. Sequential266afc8b's hyper parameters: Current learning rate is 6.830601092896175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 1366][Wall Clock 138.484058743s] Trained 128 records in 0.091190066 seconds. Throughput is 1403.6617 records/second. Loss is 1.4584335. Sequential266afc8b's hyper parameters: Current learning rate is 6.825938566552901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 54912/60000][Iteration 1367][Wall Clock 138.577209511s] Trained 128 records in 0.093150768 seconds. Throughput is 1374.1165 records/second. Loss is 1.5403425. Sequential266afc8b's hyper parameters: Current learning rate is 6.821282401091405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:37 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 1368][Wall Clock 138.667271907s] Trained 128 records in 0.090062396 seconds. Throughput is 1421.2369 records/second. Loss is 1.470193. Sequential266afc8b's hyper parameters: Current learning rate is 6.816632583503749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55168/60000][Iteration 1369][Wall Clock 138.767896387s] Trained 128 records in 0.10062448 seconds. Throughput is 1272.0563 records/second. Loss is 1.5158098. Sequential266afc8b's hyper parameters: Current learning rate is 6.811989100817438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 1370][Wall Clock 138.85715188s] Trained 128 records in 0.089255493 seconds. Throughput is 1434.0854 records/second. Loss is 1.5077342. Sequential266afc8b's hyper parameters: Current learning rate is 6.807351940095304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55424/60000][Iteration 1371][Wall Clock 138.94470878s] Trained 128 records in 0.0875569 seconds. Throughput is 1461.9065 records/second. Loss is 1.4768424. Sequential266afc8b's hyper parameters: Current learning rate is 6.802721088435374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 1372][Wall Clock 139.031308375s] Trained 128 records in 0.086599595 seconds. Throughput is 1478.0669 records/second. Loss is 1.5234376. Sequential266afc8b's hyper parameters: Current learning rate is 6.798096532970768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55680/60000][Iteration 1373][Wall Clock 139.117716074s] Trained 128 records in 0.086407699 seconds. Throughput is 1481.3495 records/second. Loss is 1.5008663. Sequential266afc8b's hyper parameters: Current learning rate is 6.793478260869565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 1374][Wall Clock 139.207540253s] Trained 128 records in 0.089824179 seconds. Throughput is 1425.0061 records/second. Loss is 1.5748101. Sequential266afc8b's hyper parameters: Current learning rate is 6.788866259334691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 55936/60000][Iteration 1375][Wall Clock 139.294862399s] Trained 128 records in 0.087322146 seconds. Throughput is 1465.8367 records/second. Loss is 1.4503396. Sequential266afc8b's hyper parameters: Current learning rate is 6.7842605156038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 1376][Wall Clock 139.391390886s] Trained 128 records in 0.096528487 seconds. Throughput is 1326.0334 records/second. Loss is 1.5215237. Sequential266afc8b's hyper parameters: Current learning rate is 6.779661016949153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 56192/60000][Iteration 1377][Wall Clock 139.479972606s] Trained 128 records in 0.08858172 seconds. Throughput is 1444.9934 records/second. Loss is 1.5712656. Sequential266afc8b's hyper parameters: Current learning rate is 6.775067750677507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 1378][Wall Clock 139.569984987s] Trained 128 records in 0.090012381 seconds. Throughput is 1422.0266 records/second. Loss is 1.5758735. Sequential266afc8b's hyper parameters: Current learning rate is 6.770480704129994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:38 INFO  DistriOptimizer$:408 - [Epoch 3 56448/60000][Iteration 1379][Wall Clock 139.658743924s] Trained 128 records in 0.088758937 seconds. Throughput is 1442.1083 records/second. Loss is 1.5339106. Sequential266afc8b's hyper parameters: Current learning rate is 6.765899864682002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 1380][Wall Clock 139.793030588s] Trained 128 records in 0.134286664 seconds. Throughput is 953.1848 records/second. Loss is 1.4991921. Sequential266afc8b's hyper parameters: Current learning rate is 6.76132521974307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 56704/60000][Iteration 1381][Wall Clock 139.881379337s] Trained 128 records in 0.088348749 seconds. Throughput is 1448.8038 records/second. Loss is 1.5113412. Sequential266afc8b's hyper parameters: Current learning rate is 6.756756756756756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 1382][Wall Clock 139.971494096s] Trained 128 records in 0.090114759 seconds. Throughput is 1420.4111 records/second. Loss is 1.4836111. Sequential266afc8b's hyper parameters: Current learning rate is 6.75219446320054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 56960/60000][Iteration 1383][Wall Clock 140.062054087s] Trained 128 records in 0.090559991 seconds. Throughput is 1413.4277 records/second. Loss is 1.5047777. Sequential266afc8b's hyper parameters: Current learning rate is 6.747638326585695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 1384][Wall Clock 140.151110344s] Trained 128 records in 0.089056257 seconds. Throughput is 1437.2938 records/second. Loss is 1.4274579. Sequential266afc8b's hyper parameters: Current learning rate is 6.743088334457181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57216/60000][Iteration 1385][Wall Clock 140.242468272s] Trained 128 records in 0.091357928 seconds. Throughput is 1401.0825 records/second. Loss is 1.5307844. Sequential266afc8b's hyper parameters: Current learning rate is 6.738544474393531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 1386][Wall Clock 140.330976284s] Trained 128 records in 0.088508012 seconds. Throughput is 1446.1968 records/second. Loss is 1.527702. Sequential266afc8b's hyper parameters: Current learning rate is 6.734006734006734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57472/60000][Iteration 1387][Wall Clock 140.416586368s] Trained 128 records in 0.085610084 seconds. Throughput is 1495.151 records/second. Loss is 1.5490322. Sequential266afc8b's hyper parameters: Current learning rate is 6.729475100942127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 1388][Wall Clock 140.502671806s] Trained 128 records in 0.086085438 seconds. Throughput is 1486.8949 records/second. Loss is 1.5696818. Sequential266afc8b's hyper parameters: Current learning rate is 6.724949562878278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57728/60000][Iteration 1389][Wall Clock 140.589118936s] Trained 128 records in 0.08644713 seconds. Throughput is 1480.6738 records/second. Loss is 1.595434. Sequential266afc8b's hyper parameters: Current learning rate is 6.720430107526881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:39 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 1390][Wall Clock 140.683003312s] Trained 128 records in 0.093884376 seconds. Throughput is 1363.3792 records/second. Loss is 1.4888823. Sequential266afc8b's hyper parameters: Current learning rate is 6.71591672263264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 57984/60000][Iteration 1391][Wall Clock 140.771828874s] Trained 128 records in 0.088825562 seconds. Throughput is 1441.0266 records/second. Loss is 1.5385143. Sequential266afc8b's hyper parameters: Current learning rate is 6.711409395973154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 1392][Wall Clock 140.862138065s] Trained 128 records in 0.090309191 seconds. Throughput is 1417.353 records/second. Loss is 1.5651416. Sequential266afc8b's hyper parameters: Current learning rate is 6.706908115358819E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58240/60000][Iteration 1393][Wall Clock 140.946787717s] Trained 128 records in 0.084649652 seconds. Throughput is 1512.1149 records/second. Loss is 1.5178047. Sequential266afc8b's hyper parameters: Current learning rate is 6.702412868632708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 1394][Wall Clock 141.034669137s] Trained 128 records in 0.08788142 seconds. Throughput is 1456.508 records/second. Loss is 1.4247793. Sequential266afc8b's hyper parameters: Current learning rate is 6.697923643670462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58496/60000][Iteration 1395][Wall Clock 141.113762588s] Trained 128 records in 0.079093451 seconds. Throughput is 1618.3389 records/second. Loss is 1.5177696. Sequential266afc8b's hyper parameters: Current learning rate is 6.693440428380188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 1396][Wall Clock 141.204501263s] Trained 128 records in 0.090738675 seconds. Throughput is 1410.6443 records/second. Loss is 1.5478337. Sequential266afc8b's hyper parameters: Current learning rate is 6.688963210702341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58752/60000][Iteration 1397][Wall Clock 141.293678181s] Trained 128 records in 0.089176918 seconds. Throughput is 1435.349 records/second. Loss is 1.5211651. Sequential266afc8b's hyper parameters: Current learning rate is 6.684491978609625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 1398][Wall Clock 141.383208581s] Trained 128 records in 0.0895304 seconds. Throughput is 1429.682 records/second. Loss is 1.4510102. Sequential266afc8b's hyper parameters: Current learning rate is 6.68002672010688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 59008/60000][Iteration 1399][Wall Clock 141.469613025s] Trained 128 records in 0.086404444 seconds. Throughput is 1481.4053 records/second. Loss is 1.5289328. Sequential266afc8b's hyper parameters: Current learning rate is 6.675567423230974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 1400][Wall Clock 141.561334839s] Trained 128 records in 0.091721814 seconds. Throughput is 1395.5242 records/second. Loss is 1.5809402. Sequential266afc8b's hyper parameters: Current learning rate is 6.671114076050701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 59264/60000][Iteration 1401][Wall Clock 141.650367282s] Trained 128 records in 0.089032443 seconds. Throughput is 1437.6782 records/second. Loss is 1.476558. Sequential266afc8b's hyper parameters: Current learning rate is 6.666666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:40 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 1402][Wall Clock 141.738003479s] Trained 128 records in 0.087636197 seconds. Throughput is 1460.5837 records/second. Loss is 1.4367687. Sequential266afc8b's hyper parameters: Current learning rate is 6.662225183211193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:41 INFO  DistriOptimizer$:408 - [Epoch 3 59520/60000][Iteration 1403][Wall Clock 141.831322006s] Trained 128 records in 0.093318527 seconds. Throughput is 1371.6461 records/second. Loss is 1.5393573. Sequential266afc8b's hyper parameters: Current learning rate is 6.657789613848203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:41 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 1404][Wall Clock 141.921503527s] Trained 128 records in 0.090181521 seconds. Throughput is 1419.3595 records/second. Loss is 1.4306318. Sequential266afc8b's hyper parameters: Current learning rate is 6.653359946773121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:41 INFO  DistriOptimizer$:408 - [Epoch 3 59776/60000][Iteration 1405][Wall Clock 142.017202658s] Trained 128 records in 0.095699131 seconds. Throughput is 1337.5251 records/second. Loss is 1.5328988. Sequential266afc8b's hyper parameters: Current learning rate is 6.648936170212766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:41 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 1406][Wall Clock 142.105076652s] Trained 128 records in 0.087873994 seconds. Throughput is 1456.6311 records/second. Loss is 1.5094013. Sequential266afc8b's hyper parameters: Current learning rate is 6.644518272425248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:41 INFO  DistriOptimizer$:408 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 142.19988178s] Trained 128 records in 0.094805128 seconds. Throughput is 1350.138 records/second. Loss is 1.5074209. Sequential266afc8b's hyper parameters: Current learning rate is 6.640106241699867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:41 INFO  DistriOptimizer$:452 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 142.19988178s] Epoch finished. Wall clock time is 143376.925119 ms
2019-10-15 08:20:41 INFO  DistriOptimizer$:111 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 142.19988178s] Validate model...
2019-10-15 08:20:42 INFO  DistriOptimizer$:178 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 142.19988178s] validate model throughput is 10494.318 records/second
2019-10-15 08:20:42 INFO  DistriOptimizer$:181 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 142.19988178s] Top1Accuracy is Accuracy(correct: 6861, count: 10000, accuracy: 0.6861)
2019-10-15 08:20:42 INFO  DistriOptimizer$:221 - [Wall Clock 143.376925119s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:20:42 INFO  DistriOptimizer$:226 - [Wall Clock 143.376925119s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 128/60000][Iteration 1408][Wall Clock 143.509110571s] Trained 128 records in 0.132185452 seconds. Throughput is 968.3365 records/second. Loss is 1.5642352. Sequential266afc8b's hyper parameters: Current learning rate is 6.635700066357001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 1409][Wall Clock 143.592217711s] Trained 128 records in 0.08310714 seconds. Throughput is 1540.1804 records/second. Loss is 1.5382841. Sequential266afc8b's hyper parameters: Current learning rate is 6.63129973474801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 384/60000][Iteration 1410][Wall Clock 143.674757663s] Trained 128 records in 0.082539952 seconds. Throughput is 1550.7642 records/second. Loss is 1.5752436. Sequential266afc8b's hyper parameters: Current learning rate is 6.626905235255136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 1411][Wall Clock 143.757056233s] Trained 128 records in 0.08229857 seconds. Throughput is 1555.3126 records/second. Loss is 1.4837251. Sequential266afc8b's hyper parameters: Current learning rate is 6.622516556291391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:42 INFO  DistriOptimizer$:408 - [Epoch 4 640/60000][Iteration 1412][Wall Clock 143.835740271s] Trained 128 records in 0.078684038 seconds. Throughput is 1626.7594 records/second. Loss is 1.5319363. Sequential266afc8b's hyper parameters: Current learning rate is 6.618133686300463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 1413][Wall Clock 143.916261146s] Trained 128 records in 0.080520875 seconds. Throughput is 1589.6499 records/second. Loss is 1.4816078. Sequential266afc8b's hyper parameters: Current learning rate is 6.613756613756613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 896/60000][Iteration 1414][Wall Clock 143.993669694s] Trained 128 records in 0.077408548 seconds. Throughput is 1653.5642 records/second. Loss is 1.4880338. Sequential266afc8b's hyper parameters: Current learning rate is 6.609385327164573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 1415][Wall Clock 144.086885575s] Trained 128 records in 0.093215881 seconds. Throughput is 1373.1565 records/second. Loss is 1.5656877. Sequential266afc8b's hyper parameters: Current learning rate is 6.605019815059445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1152/60000][Iteration 1416][Wall Clock 144.17029484s] Trained 128 records in 0.083409265 seconds. Throughput is 1534.6017 records/second. Loss is 1.5349919. Sequential266afc8b's hyper parameters: Current learning rate is 6.600660066006601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 1417][Wall Clock 144.259334625s] Trained 128 records in 0.089039785 seconds. Throughput is 1437.5596 records/second. Loss is 1.5224973. Sequential266afc8b's hyper parameters: Current learning rate is 6.596306068601583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1408/60000][Iteration 1418][Wall Clock 144.368127969s] Trained 128 records in 0.108793344 seconds. Throughput is 1176.5426 records/second. Loss is 1.6684822. Sequential266afc8b's hyper parameters: Current learning rate is 6.591957811470007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 1419][Wall Clock 144.450296413s] Trained 128 records in 0.082168444 seconds. Throughput is 1557.7756 records/second. Loss is 1.48109. Sequential266afc8b's hyper parameters: Current learning rate is 6.587615283267457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1664/60000][Iteration 1420][Wall Clock 144.539179626s] Trained 128 records in 0.088883213 seconds. Throughput is 1440.0919 records/second. Loss is 1.4886078. Sequential266afc8b's hyper parameters: Current learning rate is 6.583278472679395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 1421][Wall Clock 144.62565239s] Trained 128 records in 0.086472764 seconds. Throughput is 1480.2349 records/second. Loss is 1.483963. Sequential266afc8b's hyper parameters: Current learning rate is 6.578947368421052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 1920/60000][Iteration 1422][Wall Clock 144.713759901s] Trained 128 records in 0.088107511 seconds. Throughput is 1452.7706 records/second. Loss is 1.4641358. Sequential266afc8b's hyper parameters: Current learning rate is 6.574621959237343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:43 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 1423][Wall Clock 144.801860035s] Trained 128 records in 0.088100134 seconds. Throughput is 1452.8922 records/second. Loss is 1.4790182. Sequential266afc8b's hyper parameters: Current learning rate is 6.57030223390276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2176/60000][Iteration 1424][Wall Clock 144.890391529s] Trained 128 records in 0.088531494 seconds. Throughput is 1445.8131 records/second. Loss is 1.4467881. Sequential266afc8b's hyper parameters: Current learning rate is 6.565988181221273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 1425][Wall Clock 144.979003169s] Trained 128 records in 0.08861164 seconds. Throughput is 1444.5055 records/second. Loss is 1.4983315. Sequential266afc8b's hyper parameters: Current learning rate is 6.561679790026247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2432/60000][Iteration 1426][Wall Clock 145.069768343s] Trained 128 records in 0.090765174 seconds. Throughput is 1410.2325 records/second. Loss is 1.4964904. Sequential266afc8b's hyper parameters: Current learning rate is 6.557377049180328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 1427][Wall Clock 145.160200444s] Trained 128 records in 0.090432101 seconds. Throughput is 1415.4266 records/second. Loss is 1.5758374. Sequential266afc8b's hyper parameters: Current learning rate is 6.55307994757536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2688/60000][Iteration 1428][Wall Clock 145.250470916s] Trained 128 records in 0.090270472 seconds. Throughput is 1417.9608 records/second. Loss is 1.5749029. Sequential266afc8b's hyper parameters: Current learning rate is 6.548788474132286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 1429][Wall Clock 145.347224145s] Trained 128 records in 0.096753229 seconds. Throughput is 1322.9532 records/second. Loss is 1.4705818. Sequential266afc8b's hyper parameters: Current learning rate is 6.544502617801046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 2944/60000][Iteration 1430][Wall Clock 145.436821038s] Trained 128 records in 0.089596893 seconds. Throughput is 1428.621 records/second. Loss is 1.5686444. Sequential266afc8b's hyper parameters: Current learning rate is 6.540222367560496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 1431][Wall Clock 145.526627524s] Trained 128 records in 0.089806486 seconds. Throughput is 1425.2867 records/second. Loss is 1.4337004. Sequential266afc8b's hyper parameters: Current learning rate is 6.5359477124183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 3200/60000][Iteration 1432][Wall Clock 145.615680145s] Trained 128 records in 0.089052621 seconds. Throughput is 1437.3524 records/second. Loss is 1.514529. Sequential266afc8b's hyper parameters: Current learning rate is 6.531678641410843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 1433][Wall Clock 145.70864489s] Trained 128 records in 0.092964745 seconds. Throughput is 1376.866 records/second. Loss is 1.4787827. Sequential266afc8b's hyper parameters: Current learning rate is 6.527415143603133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:44 INFO  DistriOptimizer$:408 - [Epoch 4 3456/60000][Iteration 1434][Wall Clock 145.798902801s] Trained 128 records in 0.090257911 seconds. Throughput is 1418.1582 records/second. Loss is 1.4732547. Sequential266afc8b's hyper parameters: Current learning rate is 6.523157208088715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 1435][Wall Clock 145.885667569s] Trained 128 records in 0.086764768 seconds. Throughput is 1475.2532 records/second. Loss is 1.4610978. Sequential266afc8b's hyper parameters: Current learning rate is 6.51890482398957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 3712/60000][Iteration 1436][Wall Clock 145.972328872s] Trained 128 records in 0.086661303 seconds. Throughput is 1477.0145 records/second. Loss is 1.4481204. Sequential266afc8b's hyper parameters: Current learning rate is 6.514657980456026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 1437][Wall Clock 146.061257587s] Trained 128 records in 0.088928715 seconds. Throughput is 1439.3551 records/second. Loss is 1.5567157. Sequential266afc8b's hyper parameters: Current learning rate is 6.510416666666667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 3968/60000][Iteration 1438][Wall Clock 146.151694543s] Trained 128 records in 0.090436956 seconds. Throughput is 1415.3506 records/second. Loss is 1.5568631. Sequential266afc8b's hyper parameters: Current learning rate is 6.506180871828236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 1439][Wall Clock 146.241930202s] Trained 128 records in 0.090235659 seconds. Throughput is 1418.5079 records/second. Loss is 1.468605. Sequential266afc8b's hyper parameters: Current learning rate is 6.501950585175553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4224/60000][Iteration 1440][Wall Clock 146.332005838s] Trained 128 records in 0.090075636 seconds. Throughput is 1421.0281 records/second. Loss is 1.475053. Sequential266afc8b's hyper parameters: Current learning rate is 6.49772579597141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 1441][Wall Clock 146.422850708s] Trained 128 records in 0.09084487 seconds. Throughput is 1408.9954 records/second. Loss is 1.6142992. Sequential266afc8b's hyper parameters: Current learning rate is 6.493506493506494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4480/60000][Iteration 1442][Wall Clock 146.512667915s] Trained 128 records in 0.089817207 seconds. Throughput is 1425.1167 records/second. Loss is 1.5409466. Sequential266afc8b's hyper parameters: Current learning rate is 6.489292667099286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 1443][Wall Clock 146.614951148s] Trained 128 records in 0.102283233 seconds. Throughput is 1251.427 records/second. Loss is 1.4891089. Sequential266afc8b's hyper parameters: Current learning rate is 6.485084306095979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4736/60000][Iteration 1444][Wall Clock 146.705114135s] Trained 128 records in 0.090162987 seconds. Throughput is 1419.6514 records/second. Loss is 1.5918821. Sequential266afc8b's hyper parameters: Current learning rate is 6.480881399870382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:45 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 1445][Wall Clock 146.797654349s] Trained 128 records in 0.092540214 seconds. Throughput is 1383.1825 records/second. Loss is 1.4626212. Sequential266afc8b's hyper parameters: Current learning rate is 6.476683937823834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 4992/60000][Iteration 1446][Wall Clock 146.88901134s] Trained 128 records in 0.091356991 seconds. Throughput is 1401.0969 records/second. Loss is 1.4483317. Sequential266afc8b's hyper parameters: Current learning rate is 6.472491909385113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 1447][Wall Clock 146.975604438s] Trained 128 records in 0.086593098 seconds. Throughput is 1478.1779 records/second. Loss is 1.5309187. Sequential266afc8b's hyper parameters: Current learning rate is 6.468305304010349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5248/60000][Iteration 1448][Wall Clock 147.063385345s] Trained 128 records in 0.087780907 seconds. Throughput is 1458.1759 records/second. Loss is 1.4337871. Sequential266afc8b's hyper parameters: Current learning rate is 6.464124111182935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 1449][Wall Clock 147.149885176s] Trained 128 records in 0.086499831 seconds. Throughput is 1479.7716 records/second. Loss is 1.4792621. Sequential266afc8b's hyper parameters: Current learning rate is 6.459948320413437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5504/60000][Iteration 1450][Wall Clock 147.238222512s] Trained 128 records in 0.088337336 seconds. Throughput is 1448.9908 records/second. Loss is 1.537196. Sequential266afc8b's hyper parameters: Current learning rate is 6.455777921239509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 1451][Wall Clock 147.327373023s] Trained 128 records in 0.089150511 seconds. Throughput is 1435.7742 records/second. Loss is 1.4921203. Sequential266afc8b's hyper parameters: Current learning rate is 6.451612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5760/60000][Iteration 1452][Wall Clock 147.412617441s] Trained 128 records in 0.085244418 seconds. Throughput is 1501.5646 records/second. Loss is 1.5583453. Sequential266afc8b's hyper parameters: Current learning rate is 6.447453255963894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 1453][Wall Clock 147.500521935s] Trained 128 records in 0.087904494 seconds. Throughput is 1456.1259 records/second. Loss is 1.505173. Sequential266afc8b's hyper parameters: Current learning rate is 6.443298969072165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 6016/60000][Iteration 1454][Wall Clock 147.590256269s] Trained 128 records in 0.089734334 seconds. Throughput is 1426.4329 records/second. Loss is 1.4291217. Sequential266afc8b's hyper parameters: Current learning rate is 6.43915003219575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 1455][Wall Clock 147.687649832s] Trained 128 records in 0.097393563 seconds. Throughput is 1314.2552 records/second. Loss is 1.4799365. Sequential266afc8b's hyper parameters: Current learning rate is 6.435006435006435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 6272/60000][Iteration 1456][Wall Clock 147.774595897s] Trained 128 records in 0.086946065 seconds. Throughput is 1472.1771 records/second. Loss is 1.404495. Sequential266afc8b's hyper parameters: Current learning rate is 6.430868167202572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:46 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 1457][Wall Clock 147.857926826s] Trained 128 records in 0.083330929 seconds. Throughput is 1536.0443 records/second. Loss is 1.5584575. Sequential266afc8b's hyper parameters: Current learning rate is 6.426735218508997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 6528/60000][Iteration 1458][Wall Clock 147.954364607s] Trained 128 records in 0.096437781 seconds. Throughput is 1327.2806 records/second. Loss is 1.4844441. Sequential266afc8b's hyper parameters: Current learning rate is 6.422607578676942E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 1459][Wall Clock 148.043939065s] Trained 128 records in 0.089574458 seconds. Throughput is 1428.9788 records/second. Loss is 1.4976423. Sequential266afc8b's hyper parameters: Current learning rate is 6.418485237483954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 6784/60000][Iteration 1460][Wall Clock 148.133123349s] Trained 128 records in 0.089184284 seconds. Throughput is 1435.2305 records/second. Loss is 1.4743482. Sequential266afc8b's hyper parameters: Current learning rate is 6.414368184733804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 1461][Wall Clock 148.222973569s] Trained 128 records in 0.08985022 seconds. Throughput is 1424.5931 records/second. Loss is 1.5449368. Sequential266afc8b's hyper parameters: Current learning rate is 6.41025641025641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 7040/60000][Iteration 1462][Wall Clock 148.312330016s] Trained 128 records in 0.089356447 seconds. Throughput is 1432.4652 records/second. Loss is 1.5484226. Sequential266afc8b's hyper parameters: Current learning rate is 6.406149903907752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 1463][Wall Clock 148.402130479s] Trained 128 records in 0.089800463 seconds. Throughput is 1425.3824 records/second. Loss is 1.5780985. Sequential266afc8b's hyper parameters: Current learning rate is 6.402048655569782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 7296/60000][Iteration 1464][Wall Clock 148.487906077s] Trained 128 records in 0.085775598 seconds. Throughput is 1492.2659 records/second. Loss is 1.5569633. Sequential266afc8b's hyper parameters: Current learning rate is 6.397952655150352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 1465][Wall Clock 148.577306874s] Trained 128 records in 0.089400797 seconds. Throughput is 1431.7545 records/second. Loss is 1.4688007. Sequential266afc8b's hyper parameters: Current learning rate is 6.39386189258312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 7552/60000][Iteration 1466][Wall Clock 148.671977969s] Trained 128 records in 0.094671095 seconds. Throughput is 1352.0494 records/second. Loss is 1.4251345. Sequential266afc8b's hyper parameters: Current learning rate is 6.389776357827476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:47 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 1467][Wall Clock 148.762857306s] Trained 128 records in 0.090879337 seconds. Throughput is 1408.4609 records/second. Loss is 1.5538224. Sequential266afc8b's hyper parameters: Current learning rate is 6.385696040868455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 7808/60000][Iteration 1468][Wall Clock 148.860120271s] Trained 128 records in 0.097262965 seconds. Throughput is 1316.0199 records/second. Loss is 1.4140033. Sequential266afc8b's hyper parameters: Current learning rate is 6.381620931716656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 1469][Wall Clock 148.953763787s] Trained 128 records in 0.093643516 seconds. Throughput is 1366.8859 records/second. Loss is 1.4996359. Sequential266afc8b's hyper parameters: Current learning rate is 6.377551020408164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8064/60000][Iteration 1470][Wall Clock 149.04239826s] Trained 128 records in 0.088634473 seconds. Throughput is 1444.1333 records/second. Loss is 1.4484222. Sequential266afc8b's hyper parameters: Current learning rate is 6.373486297004462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 1471][Wall Clock 149.129829613s] Trained 128 records in 0.087431353 seconds. Throughput is 1464.0056 records/second. Loss is 1.4984924. Sequential266afc8b's hyper parameters: Current learning rate is 6.369426751592356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8320/60000][Iteration 1472][Wall Clock 149.218961101s] Trained 128 records in 0.089131488 seconds. Throughput is 1436.0806 records/second. Loss is 1.4664636. Sequential266afc8b's hyper parameters: Current learning rate is 6.365372374283895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 1473][Wall Clock 149.308144044s] Trained 128 records in 0.089182943 seconds. Throughput is 1435.2521 records/second. Loss is 1.5134791. Sequential266afc8b's hyper parameters: Current learning rate is 6.361323155216284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8576/60000][Iteration 1474][Wall Clock 149.398291726s] Trained 128 records in 0.090147682 seconds. Throughput is 1419.8923 records/second. Loss is 1.5312897. Sequential266afc8b's hyper parameters: Current learning rate is 6.357279084551812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 1475][Wall Clock 149.485097171s] Trained 128 records in 0.086805445 seconds. Throughput is 1474.5618 records/second. Loss is 1.460103. Sequential266afc8b's hyper parameters: Current learning rate is 6.353240152477764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8832/60000][Iteration 1476][Wall Clock 149.572713721s] Trained 128 records in 0.08761655 seconds. Throughput is 1460.9113 records/second. Loss is 1.4593632. Sequential266afc8b's hyper parameters: Current learning rate is 6.349206349206349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 1477][Wall Clock 149.663152715s] Trained 128 records in 0.090438994 seconds. Throughput is 1415.3187 records/second. Loss is 1.4321183. Sequential266afc8b's hyper parameters: Current learning rate is 6.34517766497462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 9088/60000][Iteration 1478][Wall Clock 149.753814239s] Trained 128 records in 0.090661524 seconds. Throughput is 1411.8447 records/second. Loss is 1.5210596. Sequential266afc8b's hyper parameters: Current learning rate is 6.341154090044388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:48 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 1479][Wall Clock 149.840552946s] Trained 128 records in 0.086738707 seconds. Throughput is 1475.6964 records/second. Loss is 1.4783697. Sequential266afc8b's hyper parameters: Current learning rate is 6.337135614702154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 9344/60000][Iteration 1480][Wall Clock 149.938626058s] Trained 128 records in 0.098073112 seconds. Throughput is 1305.1488 records/second. Loss is 1.4024737. Sequential266afc8b's hyper parameters: Current learning rate is 6.333122229259025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 1481][Wall Clock 150.019206016s] Trained 128 records in 0.080579958 seconds. Throughput is 1588.4843 records/second. Loss is 1.4571737. Sequential266afc8b's hyper parameters: Current learning rate is 6.329113924050633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 9600/60000][Iteration 1482][Wall Clock 150.109740782s] Trained 128 records in 0.090534766 seconds. Throughput is 1413.8214 records/second. Loss is 1.4745979. Sequential266afc8b's hyper parameters: Current learning rate is 6.325110689437065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 1483][Wall Clock 150.195989043s] Trained 128 records in 0.086248261 seconds. Throughput is 1484.0879 records/second. Loss is 1.5400751. Sequential266afc8b's hyper parameters: Current learning rate is 6.321112515802782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 9856/60000][Iteration 1484][Wall Clock 150.28365286s] Trained 128 records in 0.087663817 seconds. Throughput is 1460.1235 records/second. Loss is 1.5583608. Sequential266afc8b's hyper parameters: Current learning rate is 6.317119393556538E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 1485][Wall Clock 150.37546711s] Trained 128 records in 0.09181425 seconds. Throughput is 1394.1191 records/second. Loss is 1.4445938. Sequential266afc8b's hyper parameters: Current learning rate is 6.313131313131314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 10112/60000][Iteration 1486][Wall Clock 150.466976624s] Trained 128 records in 0.091509514 seconds. Throughput is 1398.7617 records/second. Loss is 1.4717789. Sequential266afc8b's hyper parameters: Current learning rate is 6.309148264984228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 1487][Wall Clock 150.554782428s] Trained 128 records in 0.087805804 seconds. Throughput is 1457.7623 records/second. Loss is 1.455226. Sequential266afc8b's hyper parameters: Current learning rate is 6.305170239596469E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 10368/60000][Iteration 1488][Wall Clock 150.643845134s] Trained 128 records in 0.089062706 seconds. Throughput is 1437.1897 records/second. Loss is 1.4708991. Sequential266afc8b's hyper parameters: Current learning rate is 6.30119722747322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 1489][Wall Clock 150.732570498s] Trained 128 records in 0.088725364 seconds. Throughput is 1442.6539 records/second. Loss is 1.4913139. Sequential266afc8b's hyper parameters: Current learning rate is 6.297229219143577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:49 INFO  DistriOptimizer$:408 - [Epoch 4 10624/60000][Iteration 1490][Wall Clock 150.821652453s] Trained 128 records in 0.089081955 seconds. Throughput is 1436.879 records/second. Loss is 1.4940739. Sequential266afc8b's hyper parameters: Current learning rate is 6.293266205160479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 1491][Wall Clock 150.910528655s] Trained 128 records in 0.088876202 seconds. Throughput is 1440.2056 records/second. Loss is 1.5330781. Sequential266afc8b's hyper parameters: Current learning rate is 6.289308176100629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 10880/60000][Iteration 1492][Wall Clock 151.001326525s] Trained 128 records in 0.09079787 seconds. Throughput is 1409.7247 records/second. Loss is 1.460241. Sequential266afc8b's hyper parameters: Current learning rate is 6.285355122564425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 1493][Wall Clock 151.099440316s] Trained 128 records in 0.098113791 seconds. Throughput is 1304.6077 records/second. Loss is 1.4731069. Sequential266afc8b's hyper parameters: Current learning rate is 6.28140703517588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11136/60000][Iteration 1494][Wall Clock 151.185812218s] Trained 128 records in 0.086371902 seconds. Throughput is 1481.9635 records/second. Loss is 1.4720662. Sequential266afc8b's hyper parameters: Current learning rate is 6.277463904582549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 1495][Wall Clock 151.278313646s] Trained 128 records in 0.092501428 seconds. Throughput is 1383.7623 records/second. Loss is 1.517646. Sequential266afc8b's hyper parameters: Current learning rate is 6.273525721455459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11392/60000][Iteration 1496][Wall Clock 151.371908791s] Trained 128 records in 0.093595145 seconds. Throughput is 1367.5923 records/second. Loss is 1.4940841. Sequential266afc8b's hyper parameters: Current learning rate is 6.269592476489028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 1497][Wall Clock 151.461314295s] Trained 128 records in 0.089405504 seconds. Throughput is 1431.6792 records/second. Loss is 1.4289932. Sequential266afc8b's hyper parameters: Current learning rate is 6.265664160401002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11648/60000][Iteration 1498][Wall Clock 151.551570288s] Trained 128 records in 0.090255993 seconds. Throughput is 1418.1884 records/second. Loss is 1.471905. Sequential266afc8b's hyper parameters: Current learning rate is 6.261740763932373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 1499][Wall Clock 151.64241116s] Trained 128 records in 0.090840872 seconds. Throughput is 1409.0574 records/second. Loss is 1.5415044. Sequential266afc8b's hyper parameters: Current learning rate is 6.257822277847309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 11904/60000][Iteration 1500][Wall Clock 151.73201176s] Trained 128 records in 0.0896006 seconds. Throughput is 1428.5619 records/second. Loss is 1.4702784. Sequential266afc8b's hyper parameters: Current learning rate is 6.253908692933083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:50 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 1501][Wall Clock 151.822241667s] Trained 128 records in 0.090229907 seconds. Throughput is 1418.5984 records/second. Loss is 1.5202397. Sequential266afc8b's hyper parameters: Current learning rate is 6.25E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12160/60000][Iteration 1502][Wall Clock 151.915032874s] Trained 128 records in 0.092791207 seconds. Throughput is 1379.441 records/second. Loss is 1.5159652. Sequential266afc8b's hyper parameters: Current learning rate is 6.246096189881325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 1503][Wall Clock 152.005139735s] Trained 128 records in 0.090106861 seconds. Throughput is 1420.5355 records/second. Loss is 1.5160393. Sequential266afc8b's hyper parameters: Current learning rate is 6.242197253433209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12416/60000][Iteration 1504][Wall Clock 152.094958429s] Trained 128 records in 0.089818694 seconds. Throughput is 1425.0931 records/second. Loss is 1.4996579. Sequential266afc8b's hyper parameters: Current learning rate is 6.238303181534623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 1505][Wall Clock 152.195744245s] Trained 128 records in 0.100785816 seconds. Throughput is 1270.02 records/second. Loss is 1.438038. Sequential266afc8b's hyper parameters: Current learning rate is 6.234413965087283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12672/60000][Iteration 1506][Wall Clock 152.293727808s] Trained 128 records in 0.097983563 seconds. Throughput is 1306.3416 records/second. Loss is 1.4633591. Sequential266afc8b's hyper parameters: Current learning rate is 6.230529595015577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 1507][Wall Clock 152.385039699s] Trained 128 records in 0.091311891 seconds. Throughput is 1401.789 records/second. Loss is 1.5090697. Sequential266afc8b's hyper parameters: Current learning rate is 6.2266500622665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 12928/60000][Iteration 1508][Wall Clock 152.47587721s] Trained 128 records in 0.090837511 seconds. Throughput is 1409.1095 records/second. Loss is 1.519189. Sequential266afc8b's hyper parameters: Current learning rate is 6.222775357809583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 1509][Wall Clock 152.567951597s] Trained 128 records in 0.092074387 seconds. Throughput is 1390.1803 records/second. Loss is 1.5360657. Sequential266afc8b's hyper parameters: Current learning rate is 6.218905472636817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 13184/60000][Iteration 1510][Wall Clock 152.661528699s] Trained 128 records in 0.093577102 seconds. Throughput is 1367.856 records/second. Loss is 1.5399425. Sequential266afc8b's hyper parameters: Current learning rate is 6.215040397762586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:51 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 1511][Wall Clock 152.752485577s] Trained 128 records in 0.090956878 seconds. Throughput is 1407.2603 records/second. Loss is 1.4625188. Sequential266afc8b's hyper parameters: Current learning rate is 6.211180124223602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 13440/60000][Iteration 1512][Wall Clock 152.841773561s] Trained 128 records in 0.089287984 seconds. Throughput is 1433.5636 records/second. Loss is 1.5207936. Sequential266afc8b's hyper parameters: Current learning rate is 6.207324643078833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 1513][Wall Clock 152.932931928s] Trained 128 records in 0.091158367 seconds. Throughput is 1404.1498 records/second. Loss is 1.4971949. Sequential266afc8b's hyper parameters: Current learning rate is 6.203473945409429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 13696/60000][Iteration 1514][Wall Clock 153.021096582s] Trained 128 records in 0.088164654 seconds. Throughput is 1451.829 records/second. Loss is 1.4650068. Sequential266afc8b's hyper parameters: Current learning rate is 6.19962802231866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 1515][Wall Clock 153.1119879s] Trained 128 records in 0.090891318 seconds. Throughput is 1408.2754 records/second. Loss is 1.5401714. Sequential266afc8b's hyper parameters: Current learning rate is 6.195786864931846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 13952/60000][Iteration 1516][Wall Clock 153.20123049s] Trained 128 records in 0.08924259 seconds. Throughput is 1434.2927 records/second. Loss is 1.4974533. Sequential266afc8b's hyper parameters: Current learning rate is 6.191950464396285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 1517][Wall Clock 153.293923331s] Trained 128 records in 0.092692841 seconds. Throughput is 1380.9049 records/second. Loss is 1.4387149. Sequential266afc8b's hyper parameters: Current learning rate is 6.188118811881188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 14208/60000][Iteration 1518][Wall Clock 153.394459339s] Trained 128 records in 0.100536008 seconds. Throughput is 1273.1757 records/second. Loss is 1.442488. Sequential266afc8b's hyper parameters: Current learning rate is 6.184291898577612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 1519][Wall Clock 153.494201457s] Trained 128 records in 0.099742118 seconds. Throughput is 1283.3094 records/second. Loss is 1.5099932. Sequential266afc8b's hyper parameters: Current learning rate is 6.180469715698394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 14464/60000][Iteration 1520][Wall Clock 153.581457628s] Trained 128 records in 0.087256171 seconds. Throughput is 1466.945 records/second. Loss is 1.5421181. Sequential266afc8b's hyper parameters: Current learning rate is 6.176652254478074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 1521][Wall Clock 153.671403112s] Trained 128 records in 0.089945484 seconds. Throughput is 1423.0842 records/second. Loss is 1.3734957. Sequential266afc8b's hyper parameters: Current learning rate is 6.172839506172838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:52 INFO  DistriOptimizer$:408 - [Epoch 4 14720/60000][Iteration 1522][Wall Clock 153.761424373s] Trained 128 records in 0.090021261 seconds. Throughput is 1421.8864 records/second. Loss is 1.4796277. Sequential266afc8b's hyper parameters: Current learning rate is 6.169031462060457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 1523][Wall Clock 153.854084977s] Trained 128 records in 0.092660604 seconds. Throughput is 1381.3853 records/second. Loss is 1.5414617. Sequential266afc8b's hyper parameters: Current learning rate is 6.165228113440197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 14976/60000][Iteration 1524][Wall Clock 153.945628727s] Trained 128 records in 0.09154375 seconds. Throughput is 1398.2385 records/second. Loss is 1.4699937. Sequential266afc8b's hyper parameters: Current learning rate is 6.161429451632779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 1525][Wall Clock 154.03868741s] Trained 128 records in 0.093058683 seconds. Throughput is 1375.4762 records/second. Loss is 1.3937975. Sequential266afc8b's hyper parameters: Current learning rate is 6.157635467980295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15232/60000][Iteration 1526][Wall Clock 154.128467771s] Trained 128 records in 0.089780361 seconds. Throughput is 1425.7015 records/second. Loss is 1.4414204. Sequential266afc8b's hyper parameters: Current learning rate is 6.153846153846154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 1527][Wall Clock 154.21872864s] Trained 128 records in 0.090260869 seconds. Throughput is 1418.1117 records/second. Loss is 1.5556769. Sequential266afc8b's hyper parameters: Current learning rate is 6.150061500615007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15488/60000][Iteration 1528][Wall Clock 154.309590421s] Trained 128 records in 0.090861781 seconds. Throughput is 1408.7332 records/second. Loss is 1.4304363. Sequential266afc8b's hyper parameters: Current learning rate is 6.146281499692687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 1529][Wall Clock 154.40169489s] Trained 128 records in 0.092104469 seconds. Throughput is 1389.7262 records/second. Loss is 1.4781615. Sequential266afc8b's hyper parameters: Current learning rate is 6.142506142506142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15744/60000][Iteration 1530][Wall Clock 154.4957085s] Trained 128 records in 0.09401361 seconds. Throughput is 1361.505 records/second. Loss is 1.4582438. Sequential266afc8b's hyper parameters: Current learning rate is 6.138735420503377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 1531][Wall Clock 154.586530135s] Trained 128 records in 0.090821635 seconds. Throughput is 1409.3557 records/second. Loss is 1.3817372. Sequential266afc8b's hyper parameters: Current learning rate is 6.134969325153375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 16000/60000][Iteration 1532][Wall Clock 154.683991488s] Trained 128 records in 0.097461353 seconds. Throughput is 1313.3412 records/second. Loss is 1.4730285. Sequential266afc8b's hyper parameters: Current learning rate is 6.131207847946045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:53 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 1533][Wall Clock 154.77093731s] Trained 128 records in 0.086945822 seconds. Throughput is 1472.1812 records/second. Loss is 1.3791356. Sequential266afc8b's hyper parameters: Current learning rate is 6.127450980392157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 16256/60000][Iteration 1534][Wall Clock 154.858386289s] Trained 128 records in 0.087448979 seconds. Throughput is 1463.7107 records/second. Loss is 1.4675214. Sequential266afc8b's hyper parameters: Current learning rate is 6.123698714023271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 1535][Wall Clock 154.947845392s] Trained 128 records in 0.089459103 seconds. Throughput is 1430.8214 records/second. Loss is 1.5357679. Sequential266afc8b's hyper parameters: Current learning rate is 6.119951040391677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 16512/60000][Iteration 1536][Wall Clock 155.043481683s] Trained 128 records in 0.095636291 seconds. Throughput is 1338.404 records/second. Loss is 1.4533721. Sequential266afc8b's hyper parameters: Current learning rate is 6.116207951070336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 1537][Wall Clock 155.131470063s] Trained 128 records in 0.08798838 seconds. Throughput is 1454.7375 records/second. Loss is 1.5178999. Sequential266afc8b's hyper parameters: Current learning rate is 6.112469437652812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 16768/60000][Iteration 1538][Wall Clock 155.220758364s] Trained 128 records in 0.089288301 seconds. Throughput is 1433.5585 records/second. Loss is 1.585142. Sequential266afc8b's hyper parameters: Current learning rate is 6.108735491753207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 1539][Wall Clock 155.309771816s] Trained 128 records in 0.089013452 seconds. Throughput is 1437.985 records/second. Loss is 1.444844. Sequential266afc8b's hyper parameters: Current learning rate is 6.105006105006104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 17024/60000][Iteration 1540][Wall Clock 155.403992108s] Trained 128 records in 0.094220292 seconds. Throughput is 1358.5183 records/second. Loss is 1.5156995. Sequential266afc8b's hyper parameters: Current learning rate is 6.101281269066504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 1541][Wall Clock 155.496283552s] Trained 128 records in 0.092291444 seconds. Throughput is 1386.9108 records/second. Loss is 1.4374441. Sequential266afc8b's hyper parameters: Current learning rate is 6.097560975609757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 17280/60000][Iteration 1542][Wall Clock 155.584877255s] Trained 128 records in 0.088593703 seconds. Throughput is 1444.7979 records/second. Loss is 1.5156847. Sequential266afc8b's hyper parameters: Current learning rate is 6.093845216331506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 1543][Wall Clock 155.673800586s] Trained 128 records in 0.088923331 seconds. Throughput is 1439.4423 records/second. Loss is 1.5064867. Sequential266afc8b's hyper parameters: Current learning rate is 6.090133982947625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:54 INFO  DistriOptimizer$:408 - [Epoch 4 17536/60000][Iteration 1544][Wall Clock 155.773328971s] Trained 128 records in 0.099528385 seconds. Throughput is 1286.0653 records/second. Loss is 1.4203042. Sequential266afc8b's hyper parameters: Current learning rate is 6.086427267194157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 1545][Wall Clock 155.853994882s] Trained 128 records in 0.080665911 seconds. Throughput is 1586.7917 records/second. Loss is 1.4965237. Sequential266afc8b's hyper parameters: Current learning rate is 6.082725060827252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 17792/60000][Iteration 1546][Wall Clock 155.941965208s] Trained 128 records in 0.087970326 seconds. Throughput is 1455.0361 records/second. Loss is 1.4529178. Sequential266afc8b's hyper parameters: Current learning rate is 6.0790273556231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 1547][Wall Clock 156.031450228s] Trained 128 records in 0.08948502 seconds. Throughput is 1430.407 records/second. Loss is 1.5197055. Sequential266afc8b's hyper parameters: Current learning rate is 6.075334143377885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18048/60000][Iteration 1548][Wall Clock 156.120231352s] Trained 128 records in 0.088781124 seconds. Throughput is 1441.7479 records/second. Loss is 1.5260465. Sequential266afc8b's hyper parameters: Current learning rate is 6.071645415907711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 1549][Wall Clock 156.209297339s] Trained 128 records in 0.089065987 seconds. Throughput is 1437.1367 records/second. Loss is 1.4558359. Sequential266afc8b's hyper parameters: Current learning rate is 6.067961165048543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18304/60000][Iteration 1550][Wall Clock 156.300371387s] Trained 128 records in 0.091074048 seconds. Throughput is 1405.4497 records/second. Loss is 1.5561407. Sequential266afc8b's hyper parameters: Current learning rate is 6.064281382656154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 1551][Wall Clock 156.389365341s] Trained 128 records in 0.088993954 seconds. Throughput is 1438.3 records/second. Loss is 1.4831823. Sequential266afc8b's hyper parameters: Current learning rate is 6.060606060606061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18560/60000][Iteration 1552][Wall Clock 156.4788636s] Trained 128 records in 0.089498259 seconds. Throughput is 1430.1954 records/second. Loss is 1.4481828. Sequential266afc8b's hyper parameters: Current learning rate is 6.056935190793459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 1553][Wall Clock 156.568715825s] Trained 128 records in 0.089852225 seconds. Throughput is 1424.5613 records/second. Loss is 1.4952474. Sequential266afc8b's hyper parameters: Current learning rate is 6.053268765133172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18816/60000][Iteration 1554][Wall Clock 156.660576031s] Trained 128 records in 0.091860206 seconds. Throughput is 1393.4216 records/second. Loss is 1.5210038. Sequential266afc8b's hyper parameters: Current learning rate is 6.049606775559588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:55 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 1555][Wall Clock 156.773959706s] Trained 128 records in 0.113383675 seconds. Throughput is 1128.9103 records/second. Loss is 1.5349859. Sequential266afc8b's hyper parameters: Current learning rate is 6.045949214026603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19072/60000][Iteration 1556][Wall Clock 156.864689011s] Trained 128 records in 0.090729305 seconds. Throughput is 1410.79 records/second. Loss is 1.5039587. Sequential266afc8b's hyper parameters: Current learning rate is 6.042296072507553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 1557][Wall Clock 156.956268309s] Trained 128 records in 0.091579298 seconds. Throughput is 1397.6958 records/second. Loss is 1.4424232. Sequential266afc8b's hyper parameters: Current learning rate is 6.038647342995169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19328/60000][Iteration 1558][Wall Clock 157.055229304s] Trained 128 records in 0.098960995 seconds. Throughput is 1293.4388 records/second. Loss is 1.547721. Sequential266afc8b's hyper parameters: Current learning rate is 6.035003017501509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 1559][Wall Clock 157.146801088s] Trained 128 records in 0.091571784 seconds. Throughput is 1397.8104 records/second. Loss is 1.4618584. Sequential266afc8b's hyper parameters: Current learning rate is 6.031363088057902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19584/60000][Iteration 1560][Wall Clock 157.233080243s] Trained 128 records in 0.086279155 seconds. Throughput is 1483.5565 records/second. Loss is 1.5950677. Sequential266afc8b's hyper parameters: Current learning rate is 6.027727546714888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 1561][Wall Clock 157.3209696s] Trained 128 records in 0.087889357 seconds. Throughput is 1456.3766 records/second. Loss is 1.4807752. Sequential266afc8b's hyper parameters: Current learning rate is 6.024096385542168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19840/60000][Iteration 1562][Wall Clock 157.409632115s] Trained 128 records in 0.088662515 seconds. Throughput is 1443.6766 records/second. Loss is 1.4343119. Sequential266afc8b's hyper parameters: Current learning rate is 6.020469596628537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 1563][Wall Clock 157.503024326s] Trained 128 records in 0.093392211 seconds. Throughput is 1370.564 records/second. Loss is 1.4009571. Sequential266afc8b's hyper parameters: Current learning rate is 6.016847172081829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 20096/60000][Iteration 1564][Wall Clock 157.591398916s] Trained 128 records in 0.08837459 seconds. Throughput is 1448.3801 records/second. Loss is 1.4644996. Sequential266afc8b's hyper parameters: Current learning rate is 6.013229104028863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 1565][Wall Clock 157.680319922s] Trained 128 records in 0.088921006 seconds. Throughput is 1439.48 records/second. Loss is 1.5607313. Sequential266afc8b's hyper parameters: Current learning rate is 6.009615384615385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:56 INFO  DistriOptimizer$:408 - [Epoch 4 20352/60000][Iteration 1566][Wall Clock 157.769371281s] Trained 128 records in 0.089051359 seconds. Throughput is 1437.3728 records/second. Loss is 1.4505131. Sequential266afc8b's hyper parameters: Current learning rate is 6.006006006006007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 1567][Wall Clock 157.858572746s] Trained 128 records in 0.089201465 seconds. Throughput is 1434.954 records/second. Loss is 1.4403682. Sequential266afc8b's hyper parameters: Current learning rate is 6.002400960384153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 20608/60000][Iteration 1568][Wall Clock 157.947925449s] Trained 128 records in 0.089352703 seconds. Throughput is 1432.5251 records/second. Loss is 1.4654144. Sequential266afc8b's hyper parameters: Current learning rate is 5.998800239952009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 1569][Wall Clock 158.054820696s] Trained 128 records in 0.106895247 seconds. Throughput is 1197.434 records/second. Loss is 1.4461361. Sequential266afc8b's hyper parameters: Current learning rate is 5.995203836930456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 20864/60000][Iteration 1570][Wall Clock 158.138953988s] Trained 128 records in 0.084133292 seconds. Throughput is 1521.3954 records/second. Loss is 1.3841869. Sequential266afc8b's hyper parameters: Current learning rate is 5.991611743559019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 1571][Wall Clock 158.224585064s] Trained 128 records in 0.085631076 seconds. Throughput is 1494.7845 records/second. Loss is 1.5731776. Sequential266afc8b's hyper parameters: Current learning rate is 5.988023952095807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 21120/60000][Iteration 1572][Wall Clock 158.312366439s] Trained 128 records in 0.087781375 seconds. Throughput is 1458.1681 records/second. Loss is 1.4740396. Sequential266afc8b's hyper parameters: Current learning rate is 5.984440454817474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 1573][Wall Clock 158.403044484s] Trained 128 records in 0.090678045 seconds. Throughput is 1411.5875 records/second. Loss is 1.4964914. Sequential266afc8b's hyper parameters: Current learning rate is 5.98086124401914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 21376/60000][Iteration 1574][Wall Clock 158.492109119s] Trained 128 records in 0.089064635 seconds. Throughput is 1437.1586 records/second. Loss is 1.4756483. Sequential266afc8b's hyper parameters: Current learning rate is 5.977286312014345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 1575][Wall Clock 158.581583567s] Trained 128 records in 0.089474448 seconds. Throughput is 1430.576 records/second. Loss is 1.5039002. Sequential266afc8b's hyper parameters: Current learning rate is 5.973715651135006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 21632/60000][Iteration 1576][Wall Clock 158.671815184s] Trained 128 records in 0.090231617 seconds. Throughput is 1418.5714 records/second. Loss is 1.4877359. Sequential266afc8b's hyper parameters: Current learning rate is 5.970149253731343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:57 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 1577][Wall Clock 158.760092679s] Trained 128 records in 0.088277495 seconds. Throughput is 1449.9731 records/second. Loss is 1.4150064. Sequential266afc8b's hyper parameters: Current learning rate is 5.966587112171839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 21888/60000][Iteration 1578][Wall Clock 158.848148509s] Trained 128 records in 0.08805583 seconds. Throughput is 1453.6233 records/second. Loss is 1.5147822. Sequential266afc8b's hyper parameters: Current learning rate is 5.963029218843173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 1579][Wall Clock 158.935968731s] Trained 128 records in 0.087820222 seconds. Throughput is 1457.5231 records/second. Loss is 1.467662. Sequential266afc8b's hyper parameters: Current learning rate is 5.959475566150178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22144/60000][Iteration 1580][Wall Clock 159.023991912s] Trained 128 records in 0.088023181 seconds. Throughput is 1454.1625 records/second. Loss is 1.444675. Sequential266afc8b's hyper parameters: Current learning rate is 5.955926146515784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 1581][Wall Clock 159.111825321s] Trained 128 records in 0.087833409 seconds. Throughput is 1457.3042 records/second. Loss is 1.4551375. Sequential266afc8b's hyper parameters: Current learning rate is 5.952380952380952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22400/60000][Iteration 1582][Wall Clock 159.203014088s] Trained 128 records in 0.091188767 seconds. Throughput is 1403.6816 records/second. Loss is 1.5250068. Sequential266afc8b's hyper parameters: Current learning rate is 5.948839976204639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 1583][Wall Clock 159.290762627s] Trained 128 records in 0.087748539 seconds. Throughput is 1458.7137 records/second. Loss is 1.5320545. Sequential266afc8b's hyper parameters: Current learning rate is 5.945303210463734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22656/60000][Iteration 1584][Wall Clock 159.39084593s] Trained 128 records in 0.100083303 seconds. Throughput is 1278.9346 records/second. Loss is 1.4252796. Sequential266afc8b's hyper parameters: Current learning rate is 5.941770647653001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 1585][Wall Clock 159.478631853s] Trained 128 records in 0.087785923 seconds. Throughput is 1458.0925 records/second. Loss is 1.4277934. Sequential266afc8b's hyper parameters: Current learning rate is 5.938242280285036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 22912/60000][Iteration 1586][Wall Clock 159.581791151s] Trained 128 records in 0.103159298 seconds. Throughput is 1240.7994 records/second. Loss is 1.444747. Sequential266afc8b's hyper parameters: Current learning rate is 5.934718100890207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 1587][Wall Clock 159.688581663s] Trained 128 records in 0.106790512 seconds. Throughput is 1198.6084 records/second. Loss is 1.4627318. Sequential266afc8b's hyper parameters: Current learning rate is 5.931198102016608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:58 INFO  DistriOptimizer$:408 - [Epoch 4 23168/60000][Iteration 1588][Wall Clock 159.778244406s] Trained 128 records in 0.089662743 seconds. Throughput is 1427.5718 records/second. Loss is 1.4486405. Sequential266afc8b's hyper parameters: Current learning rate is 5.927682276229994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 1589][Wall Clock 159.8667209s] Trained 128 records in 0.088476494 seconds. Throughput is 1446.7119 records/second. Loss is 1.4704715. Sequential266afc8b's hyper parameters: Current learning rate is 5.924170616113743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 23424/60000][Iteration 1590][Wall Clock 159.957777274s] Trained 128 records in 0.091056374 seconds. Throughput is 1405.7225 records/second. Loss is 1.4373426. Sequential266afc8b's hyper parameters: Current learning rate is 5.920663114268798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 1591][Wall Clock 160.048641703s] Trained 128 records in 0.090864429 seconds. Throughput is 1408.6921 records/second. Loss is 1.4509664. Sequential266afc8b's hyper parameters: Current learning rate is 5.917159763313611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 23680/60000][Iteration 1592][Wall Clock 160.141569961s] Trained 128 records in 0.092928258 seconds. Throughput is 1377.4066 records/second. Loss is 1.4734348. Sequential266afc8b's hyper parameters: Current learning rate is 5.913660555884093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 1593][Wall Clock 160.23310533s] Trained 128 records in 0.091535369 seconds. Throughput is 1398.3666 records/second. Loss is 1.4352202. Sequential266afc8b's hyper parameters: Current learning rate is 5.91016548463357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 23936/60000][Iteration 1594][Wall Clock 160.316798049s] Trained 128 records in 0.083692719 seconds. Throughput is 1529.4042 records/second. Loss is 1.5068599. Sequential266afc8b's hyper parameters: Current learning rate is 5.906674542232723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 1595][Wall Clock 160.398721961s] Trained 128 records in 0.081923912 seconds. Throughput is 1562.4254 records/second. Loss is 1.5016726. Sequential266afc8b's hyper parameters: Current learning rate is 5.90318772136954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 24192/60000][Iteration 1596][Wall Clock 160.481355163s] Trained 128 records in 0.082633202 seconds. Throughput is 1549.0142 records/second. Loss is 1.4879684. Sequential266afc8b's hyper parameters: Current learning rate is 5.899705014749261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 1597][Wall Clock 160.570742337s] Trained 128 records in 0.089387174 seconds. Throughput is 1431.9728 records/second. Loss is 1.5143405. Sequential266afc8b's hyper parameters: Current learning rate is 5.896226415094339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 24448/60000][Iteration 1598][Wall Clock 160.65957072s] Trained 128 records in 0.088828383 seconds. Throughput is 1440.9808 records/second. Loss is 1.415013. Sequential266afc8b's hyper parameters: Current learning rate is 5.892751915144373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:20:59 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 1599][Wall Clock 160.747743904s] Trained 128 records in 0.088173184 seconds. Throughput is 1451.6886 records/second. Loss is 1.4774243. Sequential266afc8b's hyper parameters: Current learning rate is 5.889281507656066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 24704/60000][Iteration 1600][Wall Clock 160.834300311s] Trained 128 records in 0.086556407 seconds. Throughput is 1478.8044 records/second. Loss is 1.4495298. Sequential266afc8b's hyper parameters: Current learning rate is 5.885815185403178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 1601][Wall Clock 160.922591117s] Trained 128 records in 0.088290806 seconds. Throughput is 1449.7546 records/second. Loss is 1.513332. Sequential266afc8b's hyper parameters: Current learning rate is 5.882352941176471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 24960/60000][Iteration 1602][Wall Clock 161.014441535s] Trained 128 records in 0.091850418 seconds. Throughput is 1393.5702 records/second. Loss is 1.4538836. Sequential266afc8b's hyper parameters: Current learning rate is 5.878894767783657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 1603][Wall Clock 161.10174432s] Trained 128 records in 0.087302785 seconds. Throughput is 1466.1617 records/second. Loss is 1.533832. Sequential266afc8b's hyper parameters: Current learning rate is 5.875440658049354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25216/60000][Iteration 1604][Wall Clock 161.195888595s] Trained 128 records in 0.094144275 seconds. Throughput is 1359.6154 records/second. Loss is 1.4456161. Sequential266afc8b's hyper parameters: Current learning rate is 5.871990604815032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 1605][Wall Clock 161.282167502s] Trained 128 records in 0.086278907 seconds. Throughput is 1483.5608 records/second. Loss is 1.5641985. Sequential266afc8b's hyper parameters: Current learning rate is 5.868544600938967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25472/60000][Iteration 1606][Wall Clock 161.376562548s] Trained 128 records in 0.094395046 seconds. Throughput is 1356.0033 records/second. Loss is 1.3509392. Sequential266afc8b's hyper parameters: Current learning rate is 5.865102639296188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 1607][Wall Clock 161.464583965s] Trained 128 records in 0.088021417 seconds. Throughput is 1454.1915 records/second. Loss is 1.4236741. Sequential266afc8b's hyper parameters: Current learning rate is 5.86166471277843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25728/60000][Iteration 1608][Wall Clock 161.554412933s] Trained 128 records in 0.089828968 seconds. Throughput is 1424.93 records/second. Loss is 1.4532416. Sequential266afc8b's hyper parameters: Current learning rate is 5.858230814294083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 1609][Wall Clock 161.642796379s] Trained 128 records in 0.088383446 seconds. Throughput is 1448.235 records/second. Loss is 1.4279652. Sequential266afc8b's hyper parameters: Current learning rate is 5.85480093676815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:00 INFO  DistriOptimizer$:408 - [Epoch 4 25984/60000][Iteration 1610][Wall Clock 161.740363127s] Trained 128 records in 0.097566748 seconds. Throughput is 1311.9224 records/second. Loss is 1.4722319. Sequential266afc8b's hyper parameters: Current learning rate is 5.851375073142189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 1611][Wall Clock 161.839660385s] Trained 128 records in 0.099297258 seconds. Throughput is 1289.0588 records/second. Loss is 1.4808931. Sequential266afc8b's hyper parameters: Current learning rate is 5.847953216374269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26240/60000][Iteration 1612][Wall Clock 161.929573532s] Trained 128 records in 0.089913147 seconds. Throughput is 1423.5961 records/second. Loss is 1.5426911. Sequential266afc8b's hyper parameters: Current learning rate is 5.844535359438925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 1613][Wall Clock 162.031653042s] Trained 128 records in 0.10207951 seconds. Throughput is 1253.9246 records/second. Loss is 1.4529872. Sequential266afc8b's hyper parameters: Current learning rate is 5.841121495327102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26496/60000][Iteration 1614][Wall Clock 162.124589156s] Trained 128 records in 0.092936114 seconds. Throughput is 1377.2902 records/second. Loss is 1.454966. Sequential266afc8b's hyper parameters: Current learning rate is 5.837711617046118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 1615][Wall Clock 162.212014517s] Trained 128 records in 0.087425361 seconds. Throughput is 1464.1061 records/second. Loss is 1.5168383. Sequential266afc8b's hyper parameters: Current learning rate is 5.834305717619603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26752/60000][Iteration 1616][Wall Clock 162.300505754s] Trained 128 records in 0.088491237 seconds. Throughput is 1446.4708 records/second. Loss is 1.4584134. Sequential266afc8b's hyper parameters: Current learning rate is 5.830903790087465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 1617][Wall Clock 162.390923183s] Trained 128 records in 0.090417429 seconds. Throughput is 1415.6562 records/second. Loss is 1.484884. Sequential266afc8b's hyper parameters: Current learning rate is 5.827505827505828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 27008/60000][Iteration 1618][Wall Clock 162.481074745s] Trained 128 records in 0.090151562 seconds. Throughput is 1419.8312 records/second. Loss is 1.415763. Sequential266afc8b's hyper parameters: Current learning rate is 5.824111822947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 1619][Wall Clock 162.570942141s] Trained 128 records in 0.089867396 seconds. Throughput is 1424.3208 records/second. Loss is 1.4585242. Sequential266afc8b's hyper parameters: Current learning rate is 5.820721769499418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 27264/60000][Iteration 1620][Wall Clock 162.658967462s] Trained 128 records in 0.088025321 seconds. Throughput is 1454.127 records/second. Loss is 1.4986916. Sequential266afc8b's hyper parameters: Current learning rate is 5.817335660267597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:01 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 1621][Wall Clock 162.744957307s] Trained 128 records in 0.085989845 seconds. Throughput is 1488.5479 records/second. Loss is 1.4572605. Sequential266afc8b's hyper parameters: Current learning rate is 5.813953488372093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 27520/60000][Iteration 1622][Wall Clock 162.832507909s] Trained 128 records in 0.087550602 seconds. Throughput is 1462.0116 records/second. Loss is 1.5104132. Sequential266afc8b's hyper parameters: Current learning rate is 5.810575246949448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 1623][Wall Clock 162.923486213s] Trained 128 records in 0.090978304 seconds. Throughput is 1406.9288 records/second. Loss is 1.4702432. Sequential266afc8b's hyper parameters: Current learning rate is 5.807200929152149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 27776/60000][Iteration 1624][Wall Clock 163.014773782s] Trained 128 records in 0.091287569 seconds. Throughput is 1402.1625 records/second. Loss is 1.4427205. Sequential266afc8b's hyper parameters: Current learning rate is 5.803830528148578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 1625][Wall Clock 163.104921045s] Trained 128 records in 0.090147263 seconds. Throughput is 1419.8989 records/second. Loss is 1.3933021. Sequential266afc8b's hyper parameters: Current learning rate is 5.80046403712297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28032/60000][Iteration 1626][Wall Clock 163.192929578s] Trained 128 records in 0.088008533 seconds. Throughput is 1454.4044 records/second. Loss is 1.4792941. Sequential266afc8b's hyper parameters: Current learning rate is 5.797101449275362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 1627][Wall Clock 163.284819985s] Trained 128 records in 0.091890407 seconds. Throughput is 1392.9636 records/second. Loss is 1.4261596. Sequential266afc8b's hyper parameters: Current learning rate is 5.793742757821553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28288/60000][Iteration 1628][Wall Clock 163.375615501s] Trained 128 records in 0.090795516 seconds. Throughput is 1409.7612 records/second. Loss is 1.4330275. Sequential266afc8b's hyper parameters: Current learning rate is 5.790387955993052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 1629][Wall Clock 163.4663904s] Trained 128 records in 0.090774899 seconds. Throughput is 1410.0814 records/second. Loss is 1.4998255. Sequential266afc8b's hyper parameters: Current learning rate is 5.787037037037037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28544/60000][Iteration 1630][Wall Clock 163.555563667s] Trained 128 records in 0.089173267 seconds. Throughput is 1435.4078 records/second. Loss is 1.471018. Sequential266afc8b's hyper parameters: Current learning rate is 5.783689994216311E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 1631][Wall Clock 163.644388965s] Trained 128 records in 0.088825298 seconds. Throughput is 1441.0309 records/second. Loss is 1.4984205. Sequential266afc8b's hyper parameters: Current learning rate is 5.780346820809249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:02 INFO  DistriOptimizer$:408 - [Epoch 4 28800/60000][Iteration 1632][Wall Clock 163.738548848s] Trained 128 records in 0.094159883 seconds. Throughput is 1359.3899 records/second. Loss is 1.4700801. Sequential266afc8b's hyper parameters: Current learning rate is 5.777007510109764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 1633][Wall Clock 163.827884853s] Trained 128 records in 0.089336005 seconds. Throughput is 1432.793 records/second. Loss is 1.4354614. Sequential266afc8b's hyper parameters: Current learning rate is 5.773672055427252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29056/60000][Iteration 1634][Wall Clock 163.917832579s] Trained 128 records in 0.089947726 seconds. Throughput is 1423.0488 records/second. Loss is 1.4053125. Sequential266afc8b's hyper parameters: Current learning rate is 5.770340450086555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 1635][Wall Clock 164.006793989s] Trained 128 records in 0.08896141 seconds. Throughput is 1438.8262 records/second. Loss is 1.3486054. Sequential266afc8b's hyper parameters: Current learning rate is 5.767012687427913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29312/60000][Iteration 1636][Wall Clock 164.103635163s] Trained 128 records in 0.096841174 seconds. Throughput is 1321.7518 records/second. Loss is 1.5148108. Sequential266afc8b's hyper parameters: Current learning rate is 5.763688760806916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 1637][Wall Clock 164.18523363s] Trained 128 records in 0.081598467 seconds. Throughput is 1568.6569 records/second. Loss is 1.4575558. Sequential266afc8b's hyper parameters: Current learning rate is 5.76036866359447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29568/60000][Iteration 1638][Wall Clock 164.268542594s] Trained 128 records in 0.083308964 seconds. Throughput is 1536.4493 records/second. Loss is 1.4576457. Sequential266afc8b's hyper parameters: Current learning rate is 5.757052389176741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 1639][Wall Clock 164.349318907s] Trained 128 records in 0.080776313 seconds. Throughput is 1584.623 records/second. Loss is 1.4539527. Sequential266afc8b's hyper parameters: Current learning rate is 5.753739930955121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29824/60000][Iteration 1640][Wall Clock 164.436358006s] Trained 128 records in 0.087039099 seconds. Throughput is 1470.6035 records/second. Loss is 1.4184045. Sequential266afc8b's hyper parameters: Current learning rate is 5.750431282346176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 1641][Wall Clock 164.526602386s] Trained 128 records in 0.09024438 seconds. Throughput is 1418.3708 records/second. Loss is 1.4494721. Sequential266afc8b's hyper parameters: Current learning rate is 5.74712643678161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 30080/60000][Iteration 1642][Wall Clock 164.615869007s] Trained 128 records in 0.089266621 seconds. Throughput is 1433.9066 records/second. Loss is 1.4677566. Sequential266afc8b's hyper parameters: Current learning rate is 5.743825387708214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:03 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 1643][Wall Clock 164.704764513s] Trained 128 records in 0.088895506 seconds. Throughput is 1439.8928 records/second. Loss is 1.4151735. Sequential266afc8b's hyper parameters: Current learning rate is 5.740528128587829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 30336/60000][Iteration 1644][Wall Clock 164.800811352s] Trained 128 records in 0.096046839 seconds. Throughput is 1332.6831 records/second. Loss is 1.4845275. Sequential266afc8b's hyper parameters: Current learning rate is 5.737234652897304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 1645][Wall Clock 164.890386278s] Trained 128 records in 0.089574926 seconds. Throughput is 1428.9713 records/second. Loss is 1.4958742. Sequential266afc8b's hyper parameters: Current learning rate is 5.73394495412844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 30592/60000][Iteration 1646][Wall Clock 164.979118402s] Trained 128 records in 0.088732124 seconds. Throughput is 1442.5441 records/second. Loss is 1.518639. Sequential266afc8b's hyper parameters: Current learning rate is 5.730659025787966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 1647][Wall Clock 165.0667506s] Trained 128 records in 0.087632198 seconds. Throughput is 1460.6503 records/second. Loss is 1.52342. Sequential266afc8b's hyper parameters: Current learning rate is 5.72737686139748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 30848/60000][Iteration 1648][Wall Clock 165.187273379s] Trained 128 records in 0.120522779 seconds. Throughput is 1062.0399 records/second. Loss is 1.5314076. Sequential266afc8b's hyper parameters: Current learning rate is 5.724098454493418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 1649][Wall Clock 165.278560366s] Trained 128 records in 0.091286987 seconds. Throughput is 1402.1714 records/second. Loss is 1.4970859. Sequential266afc8b's hyper parameters: Current learning rate is 5.720823798627002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 31104/60000][Iteration 1650][Wall Clock 165.369094152s] Trained 128 records in 0.090533786 seconds. Throughput is 1413.8368 records/second. Loss is 1.3950344. Sequential266afc8b's hyper parameters: Current learning rate is 5.717552887364208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 1651][Wall Clock 165.455514865s] Trained 128 records in 0.086420713 seconds. Throughput is 1481.1263 records/second. Loss is 1.4359512. Sequential266afc8b's hyper parameters: Current learning rate is 5.714285714285715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 31360/60000][Iteration 1652][Wall Clock 165.54578246s] Trained 128 records in 0.090267595 seconds. Throughput is 1418.006 records/second. Loss is 1.5384041. Sequential266afc8b's hyper parameters: Current learning rate is 5.711022272986865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 1653][Wall Clock 165.63407942s] Trained 128 records in 0.08829696 seconds. Throughput is 1449.6536 records/second. Loss is 1.431164. Sequential266afc8b's hyper parameters: Current learning rate is 5.707762557077626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:04 INFO  DistriOptimizer$:408 - [Epoch 4 31616/60000][Iteration 1654][Wall Clock 165.723070246s] Trained 128 records in 0.088990826 seconds. Throughput is 1438.3506 records/second. Loss is 1.4447228. Sequential266afc8b's hyper parameters: Current learning rate is 5.704506560182544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 1655][Wall Clock 165.814509095s] Trained 128 records in 0.091438849 seconds. Throughput is 1399.8427 records/second. Loss is 1.4314629. Sequential266afc8b's hyper parameters: Current learning rate is 5.701254275940707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 31872/60000][Iteration 1656][Wall Clock 165.904279308s] Trained 128 records in 0.089770213 seconds. Throughput is 1425.8627 records/second. Loss is 1.4200945. Sequential266afc8b's hyper parameters: Current learning rate is 5.698005698005698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 1657][Wall Clock 165.998086827s] Trained 128 records in 0.093807519 seconds. Throughput is 1364.4962 records/second. Loss is 1.4390805. Sequential266afc8b's hyper parameters: Current learning rate is 5.694760820045559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32128/60000][Iteration 1658][Wall Clock 166.086855565s] Trained 128 records in 0.088768738 seconds. Throughput is 1441.9491 records/second. Loss is 1.3831202. Sequential266afc8b's hyper parameters: Current learning rate is 5.691519635742744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 1659][Wall Clock 166.180048443s] Trained 128 records in 0.093192878 seconds. Throughput is 1373.4956 records/second. Loss is 1.4482203. Sequential266afc8b's hyper parameters: Current learning rate is 5.688282138794084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32384/60000][Iteration 1660][Wall Clock 166.269549882s] Trained 128 records in 0.089501439 seconds. Throughput is 1430.1445 records/second. Loss is 1.4806281. Sequential266afc8b's hyper parameters: Current learning rate is 5.685048322910744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 1661][Wall Clock 166.361007128s] Trained 128 records in 0.091457246 seconds. Throughput is 1399.561 records/second. Loss is 1.4982381. Sequential266afc8b's hyper parameters: Current learning rate is 5.681818181818182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32640/60000][Iteration 1662][Wall Clock 166.461954374s] Trained 128 records in 0.100947246 seconds. Throughput is 1267.989 records/second. Loss is 1.437883. Sequential266afc8b's hyper parameters: Current learning rate is 5.678591709256105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 1663][Wall Clock 166.546691999s] Trained 128 records in 0.084737625 seconds. Throughput is 1510.545 records/second. Loss is 1.4443916. Sequential266afc8b's hyper parameters: Current learning rate is 5.675368898978433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 32896/60000][Iteration 1664][Wall Clock 166.633004934s] Trained 128 records in 0.086312935 seconds. Throughput is 1482.9758 records/second. Loss is 1.4310349. Sequential266afc8b's hyper parameters: Current learning rate is 5.672149744753262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:05 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 1665][Wall Clock 166.723952474s] Trained 128 records in 0.09094754 seconds. Throughput is 1407.4048 records/second. Loss is 1.4455988. Sequential266afc8b's hyper parameters: Current learning rate is 5.668934240362812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33152/60000][Iteration 1666][Wall Clock 166.812227692s] Trained 128 records in 0.088275218 seconds. Throughput is 1450.0106 records/second. Loss is 1.3790439. Sequential266afc8b's hyper parameters: Current learning rate is 5.6657223796034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 1667][Wall Clock 166.900762991s] Trained 128 records in 0.088535299 seconds. Throughput is 1445.751 records/second. Loss is 1.43053. Sequential266afc8b's hyper parameters: Current learning rate is 5.662514156285391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33408/60000][Iteration 1668][Wall Clock 166.990207138s] Trained 128 records in 0.089444147 seconds. Throughput is 1431.0607 records/second. Loss is 1.4259839. Sequential266afc8b's hyper parameters: Current learning rate is 5.659309564233163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 1669][Wall Clock 167.079630496s] Trained 128 records in 0.089423358 seconds. Throughput is 1431.3933 records/second. Loss is 1.4845188. Sequential266afc8b's hyper parameters: Current learning rate is 5.656108597285068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33664/60000][Iteration 1670][Wall Clock 167.181008292s] Trained 128 records in 0.101377796 seconds. Throughput is 1262.6039 records/second. Loss is 1.3397595. Sequential266afc8b's hyper parameters: Current learning rate is 5.652911249293386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 1671][Wall Clock 167.271660528s] Trained 128 records in 0.090652236 seconds. Throughput is 1411.9895 records/second. Loss is 1.4550197. Sequential266afc8b's hyper parameters: Current learning rate is 5.649717514124294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 33920/60000][Iteration 1672][Wall Clock 167.359110383s] Trained 128 records in 0.087449855 seconds. Throughput is 1463.6959 records/second. Loss is 1.4704581. Sequential266afc8b's hyper parameters: Current learning rate is 5.64652738565782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 1673][Wall Clock 167.450548559s] Trained 128 records in 0.091438176 seconds. Throughput is 1399.853 records/second. Loss is 1.4206859. Sequential266afc8b's hyper parameters: Current learning rate is 5.643340857787811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 34176/60000][Iteration 1674][Wall Clock 167.53902067s] Trained 128 records in 0.088472111 seconds. Throughput is 1446.7836 records/second. Loss is 1.485836. Sequential266afc8b's hyper parameters: Current learning rate is 5.640157924421884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 1675][Wall Clock 167.627451004s] Trained 128 records in 0.088430334 seconds. Throughput is 1447.467 records/second. Loss is 1.4544796. Sequential266afc8b's hyper parameters: Current learning rate is 5.636978579481398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:06 INFO  DistriOptimizer$:408 - [Epoch 4 34432/60000][Iteration 1676][Wall Clock 167.728705152s] Trained 128 records in 0.101254148 seconds. Throughput is 1264.1458 records/second. Loss is 1.4786406. Sequential266afc8b's hyper parameters: Current learning rate is 5.633802816901409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 1677][Wall Clock 167.818423047s] Trained 128 records in 0.089717895 seconds. Throughput is 1426.6942 records/second. Loss is 1.3950616. Sequential266afc8b's hyper parameters: Current learning rate is 5.630630630630631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 34688/60000][Iteration 1678][Wall Clock 167.908197347s] Trained 128 records in 0.0897743 seconds. Throughput is 1425.7977 records/second. Loss is 1.4645482. Sequential266afc8b's hyper parameters: Current learning rate is 5.627462014631402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 1679][Wall Clock 167.999047005s] Trained 128 records in 0.090849658 seconds. Throughput is 1408.921 records/second. Loss is 1.4075793. Sequential266afc8b's hyper parameters: Current learning rate is 5.62429696287964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 34944/60000][Iteration 1680][Wall Clock 168.093360882s] Trained 128 records in 0.094313877 seconds. Throughput is 1357.1704 records/second. Loss is 1.5374948. Sequential266afc8b's hyper parameters: Current learning rate is 5.621135469364812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 1681][Wall Clock 168.180674353s] Trained 128 records in 0.087313471 seconds. Throughput is 1465.9822 records/second. Loss is 1.471327. Sequential266afc8b's hyper parameters: Current learning rate is 5.617977528089887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35200/60000][Iteration 1682][Wall Clock 168.268466963s] Trained 128 records in 0.08779261 seconds. Throughput is 1457.9814 records/second. Loss is 1.422568. Sequential266afc8b's hyper parameters: Current learning rate is 5.614823133071309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 1683][Wall Clock 168.35967876s] Trained 128 records in 0.091211797 seconds. Throughput is 1403.3273 records/second. Loss is 1.4460894. Sequential266afc8b's hyper parameters: Current learning rate is 5.611672278338945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35456/60000][Iteration 1684][Wall Clock 168.448204745s] Trained 128 records in 0.088525985 seconds. Throughput is 1445.9031 records/second. Loss is 1.4399604. Sequential266afc8b's hyper parameters: Current learning rate is 5.608524957936063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 1685][Wall Clock 168.537286113s] Trained 128 records in 0.089081368 seconds. Throughput is 1436.8885 records/second. Loss is 1.3692962. Sequential266afc8b's hyper parameters: Current learning rate is 5.605381165919282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35712/60000][Iteration 1686][Wall Clock 168.628678298s] Trained 128 records in 0.091392185 seconds. Throughput is 1400.5575 records/second. Loss is 1.3547552. Sequential266afc8b's hyper parameters: Current learning rate is 5.602240896358543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:07 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 1687][Wall Clock 168.718458781s] Trained 128 records in 0.089780483 seconds. Throughput is 1425.6997 records/second. Loss is 1.4401168. Sequential266afc8b's hyper parameters: Current learning rate is 5.599104143337066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 35968/60000][Iteration 1688][Wall Clock 168.819688536s] Trained 128 records in 0.101229755 seconds. Throughput is 1264.4503 records/second. Loss is 1.4767002. Sequential266afc8b's hyper parameters: Current learning rate is 5.595970900951314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 1689][Wall Clock 168.909935614s] Trained 128 records in 0.090247078 seconds. Throughput is 1418.3285 records/second. Loss is 1.5024554. Sequential266afc8b's hyper parameters: Current learning rate is 5.592841163310963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36224/60000][Iteration 1690][Wall Clock 168.98942312s] Trained 128 records in 0.079487506 seconds. Throughput is 1610.316 records/second. Loss is 1.4981138. Sequential266afc8b's hyper parameters: Current learning rate is 5.589714924538849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 1691][Wall Clock 169.077219501s] Trained 128 records in 0.087796381 seconds. Throughput is 1457.9188 records/second. Loss is 1.4865991. Sequential266afc8b's hyper parameters: Current learning rate is 5.58659217877095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36480/60000][Iteration 1692][Wall Clock 169.165108352s] Trained 128 records in 0.087888851 seconds. Throughput is 1456.3849 records/second. Loss is 1.5168942. Sequential266afc8b's hyper parameters: Current learning rate is 5.583472920156337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 1693][Wall Clock 169.256847543s] Trained 128 records in 0.091739191 seconds. Throughput is 1395.2598 records/second. Loss is 1.4263227. Sequential266afc8b's hyper parameters: Current learning rate is 5.580357142857143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36736/60000][Iteration 1694][Wall Clock 169.35281724s] Trained 128 records in 0.095969697 seconds. Throughput is 1333.7543 records/second. Loss is 1.4447873. Sequential266afc8b's hyper parameters: Current learning rate is 5.577244841048522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 1695][Wall Clock 169.443974157s] Trained 128 records in 0.091156917 seconds. Throughput is 1404.1721 records/second. Loss is 1.4239911. Sequential266afc8b's hyper parameters: Current learning rate is 5.574136008918618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 36992/60000][Iteration 1696][Wall Clock 169.539117712s] Trained 128 records in 0.095143555 seconds. Throughput is 1345.3354 records/second. Loss is 1.5231265. Sequential266afc8b's hyper parameters: Current learning rate is 5.571030640668524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 1697][Wall Clock 169.634725789s] Trained 128 records in 0.095608077 seconds. Throughput is 1338.799 records/second. Loss is 1.362149. Sequential266afc8b's hyper parameters: Current learning rate is 5.567928730512249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:08 INFO  DistriOptimizer$:408 - [Epoch 4 37248/60000][Iteration 1698][Wall Clock 169.723185667s] Trained 128 records in 0.088459878 seconds. Throughput is 1446.9836 records/second. Loss is 1.3994565. Sequential266afc8b's hyper parameters: Current learning rate is 5.564830272676684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 1699][Wall Clock 169.809382672s] Trained 128 records in 0.086197005 seconds. Throughput is 1484.9705 records/second. Loss is 1.4716417. Sequential266afc8b's hyper parameters: Current learning rate is 5.561735261401557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 37504/60000][Iteration 1700][Wall Clock 169.900946328s] Trained 128 records in 0.091563656 seconds. Throughput is 1397.9346 records/second. Loss is 1.4045511. Sequential266afc8b's hyper parameters: Current learning rate is 5.558643690939411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 1701][Wall Clock 169.991109159s] Trained 128 records in 0.090162831 seconds. Throughput is 1419.6538 records/second. Loss is 1.5333673. Sequential266afc8b's hyper parameters: Current learning rate is 5.555555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 37760/60000][Iteration 1702][Wall Clock 170.080231855s] Trained 128 records in 0.089122696 seconds. Throughput is 1436.2223 records/second. Loss is 1.4391125. Sequential266afc8b's hyper parameters: Current learning rate is 5.552470849528039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 1703][Wall Clock 170.170463172s] Trained 128 records in 0.090231317 seconds. Throughput is 1418.5763 records/second. Loss is 1.3574915. Sequential266afc8b's hyper parameters: Current learning rate is 5.549389567147614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 38016/60000][Iteration 1704][Wall Clock 170.268386149s] Trained 128 records in 0.097922977 seconds. Throughput is 1307.1499 records/second. Loss is 1.4533516. Sequential266afc8b's hyper parameters: Current learning rate is 5.546311702717692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 1705][Wall Clock 170.355877882s] Trained 128 records in 0.087491733 seconds. Throughput is 1462.9954 records/second. Loss is 1.4221784. Sequential266afc8b's hyper parameters: Current learning rate is 5.543237250554324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 38272/60000][Iteration 1706][Wall Clock 170.443111433s] Trained 128 records in 0.087233551 seconds. Throughput is 1467.3253 records/second. Loss is 1.4849919. Sequential266afc8b's hyper parameters: Current learning rate is 5.540166204986149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 1707][Wall Clock 170.53119991s] Trained 128 records in 0.088088477 seconds. Throughput is 1453.0845 records/second. Loss is 1.4814137. Sequential266afc8b's hyper parameters: Current learning rate is 5.537098560354375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 38528/60000][Iteration 1708][Wall Clock 170.623614221s] Trained 128 records in 0.092414311 seconds. Throughput is 1385.0669 records/second. Loss is 1.4228417. Sequential266afc8b's hyper parameters: Current learning rate is 5.534034311012728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:09 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 1709][Wall Clock 170.712719046s] Trained 128 records in 0.089104825 seconds. Throughput is 1436.5104 records/second. Loss is 1.4181161. Sequential266afc8b's hyper parameters: Current learning rate is 5.530973451327434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 38784/60000][Iteration 1710][Wall Clock 170.802028099s] Trained 128 records in 0.089309053 seconds. Throughput is 1433.2253 records/second. Loss is 1.4225786. Sequential266afc8b's hyper parameters: Current learning rate is 5.52791597567717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 1711][Wall Clock 170.890250402s] Trained 128 records in 0.088222303 seconds. Throughput is 1450.8802 records/second. Loss is 1.5199101. Sequential266afc8b's hyper parameters: Current learning rate is 5.524861878453038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39040/60000][Iteration 1712][Wall Clock 170.979914617s] Trained 128 records in 0.089664215 seconds. Throughput is 1427.5483 records/second. Loss is 1.4904977. Sequential266afc8b's hyper parameters: Current learning rate is 5.521811154058532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 1713][Wall Clock 171.080296965s] Trained 128 records in 0.100382348 seconds. Throughput is 1275.1245 records/second. Loss is 1.4819587. Sequential266afc8b's hyper parameters: Current learning rate is 5.518763796909492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39296/60000][Iteration 1714][Wall Clock 171.169639114s] Trained 128 records in 0.089342149 seconds. Throughput is 1432.6945 records/second. Loss is 1.4580933. Sequential266afc8b's hyper parameters: Current learning rate is 5.515719801434088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 1715][Wall Clock 171.256194441s] Trained 128 records in 0.086555327 seconds. Throughput is 1478.823 records/second. Loss is 1.4582418. Sequential266afc8b's hyper parameters: Current learning rate is 5.512679162072767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39552/60000][Iteration 1716][Wall Clock 171.34156868s] Trained 128 records in 0.085374239 seconds. Throughput is 1499.2814 records/second. Loss is 1.3433019. Sequential266afc8b's hyper parameters: Current learning rate is 5.509641873278236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 1717][Wall Clock 171.425976641s] Trained 128 records in 0.084407961 seconds. Throughput is 1516.4446 records/second. Loss is 1.4416586. Sequential266afc8b's hyper parameters: Current learning rate is 5.506607929515419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39808/60000][Iteration 1718][Wall Clock 171.515736795s] Trained 128 records in 0.089760154 seconds. Throughput is 1426.0225 records/second. Loss is 1.511286. Sequential266afc8b's hyper parameters: Current learning rate is 5.50357732526142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 1719][Wall Clock 171.604849646s] Trained 128 records in 0.089112851 seconds. Throughput is 1436.381 records/second. Loss is 1.5561938. Sequential266afc8b's hyper parameters: Current learning rate is 5.5005500550055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:10 INFO  DistriOptimizer$:408 - [Epoch 4 40064/60000][Iteration 1720][Wall Clock 171.692727079s] Trained 128 records in 0.087877433 seconds. Throughput is 1456.5742 records/second. Loss is 1.3883222. Sequential266afc8b's hyper parameters: Current learning rate is 5.497526113249038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 1721][Wall Clock 171.784998724s] Trained 128 records in 0.092271645 seconds. Throughput is 1387.2084 records/second. Loss is 1.4527731. Sequential266afc8b's hyper parameters: Current learning rate is 5.494505494505495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40320/60000][Iteration 1722][Wall Clock 171.872987841s] Trained 128 records in 0.087989117 seconds. Throughput is 1454.7255 records/second. Loss is 1.4000826. Sequential266afc8b's hyper parameters: Current learning rate is 5.491488193300384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 1723][Wall Clock 171.957942381s] Trained 128 records in 0.08495454 seconds. Throughput is 1506.6882 records/second. Loss is 1.4528091. Sequential266afc8b's hyper parameters: Current learning rate is 5.488474204171241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40576/60000][Iteration 1724][Wall Clock 172.048637499s] Trained 128 records in 0.090695118 seconds. Throughput is 1411.3218 records/second. Loss is 1.4408015. Sequential266afc8b's hyper parameters: Current learning rate is 5.485463521667581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 1725][Wall Clock 172.136948775s] Trained 128 records in 0.088311276 seconds. Throughput is 1449.4185 records/second. Loss is 1.390055. Sequential266afc8b's hyper parameters: Current learning rate is 5.482456140350877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40832/60000][Iteration 1726][Wall Clock 172.226513274s] Trained 128 records in 0.089564499 seconds. Throughput is 1429.1376 records/second. Loss is 1.3978329. Sequential266afc8b's hyper parameters: Current learning rate is 5.47945205479452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 1727][Wall Clock 172.316726304s] Trained 128 records in 0.09021303 seconds. Throughput is 1418.8638 records/second. Loss is 1.4129093. Sequential266afc8b's hyper parameters: Current learning rate is 5.47645125958379E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 41088/60000][Iteration 1728][Wall Clock 172.406332297s] Trained 128 records in 0.089605993 seconds. Throughput is 1428.4758 records/second. Loss is 1.3104273. Sequential266afc8b's hyper parameters: Current learning rate is 5.473453749315818E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 1729][Wall Clock 172.496187063s] Trained 128 records in 0.089854766 seconds. Throughput is 1424.5209 records/second. Loss is 1.3536824. Sequential266afc8b's hyper parameters: Current learning rate is 5.470459518599562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 41344/60000][Iteration 1730][Wall Clock 172.5854658s] Trained 128 records in 0.089278737 seconds. Throughput is 1433.712 records/second. Loss is 1.433725. Sequential266afc8b's hyper parameters: Current learning rate is 5.467468562055769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:11 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 1731][Wall Clock 172.672927891s] Trained 128 records in 0.087462091 seconds. Throughput is 1463.4912 records/second. Loss is 1.4145613. Sequential266afc8b's hyper parameters: Current learning rate is 5.46448087431694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 41600/60000][Iteration 1732][Wall Clock 172.764333721s] Trained 128 records in 0.09140583 seconds. Throughput is 1400.3483 records/second. Loss is 1.3962209. Sequential266afc8b's hyper parameters: Current learning rate is 5.461496450027308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 1733][Wall Clock 172.854227998s] Trained 128 records in 0.089894277 seconds. Throughput is 1423.8948 records/second. Loss is 1.4444478. Sequential266afc8b's hyper parameters: Current learning rate is 5.458515283842794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 41856/60000][Iteration 1734][Wall Clock 172.942256115s] Trained 128 records in 0.088028117 seconds. Throughput is 1454.0808 records/second. Loss is 1.423018. Sequential266afc8b's hyper parameters: Current learning rate is 5.455537370430987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 1735][Wall Clock 173.029995095s] Trained 128 records in 0.08773898 seconds. Throughput is 1458.8726 records/second. Loss is 1.5294838. Sequential266afc8b's hyper parameters: Current learning rate is 5.452562704471102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42112/60000][Iteration 1736][Wall Clock 173.118254437s] Trained 128 records in 0.088259342 seconds. Throughput is 1450.2715 records/second. Loss is 1.4301715. Sequential266afc8b's hyper parameters: Current learning rate is 5.44959128065395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 1737][Wall Clock 173.206738323s] Trained 128 records in 0.088483886 seconds. Throughput is 1446.5911 records/second. Loss is 1.412235. Sequential266afc8b's hyper parameters: Current learning rate is 5.446623093681918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42368/60000][Iteration 1738][Wall Clock 173.29389592s] Trained 128 records in 0.087157597 seconds. Throughput is 1468.604 records/second. Loss is 1.4059644. Sequential266afc8b's hyper parameters: Current learning rate is 5.443658138268916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 1739][Wall Clock 173.3951144s] Trained 128 records in 0.10121848 seconds. Throughput is 1264.5913 records/second. Loss is 1.3169005. Sequential266afc8b's hyper parameters: Current learning rate is 5.44069640914037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42624/60000][Iteration 1740][Wall Clock 173.477069603s] Trained 128 records in 0.081955203 seconds. Throughput is 1561.8289 records/second. Loss is 1.3984642. Sequential266afc8b's hyper parameters: Current learning rate is 5.43773790103317E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 1741][Wall Clock 173.565188091s] Trained 128 records in 0.088118488 seconds. Throughput is 1452.5896 records/second. Loss is 1.4573416. Sequential266afc8b's hyper parameters: Current learning rate is 5.434782608695651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:12 INFO  DistriOptimizer$:408 - [Epoch 4 42880/60000][Iteration 1742][Wall Clock 173.653645835s] Trained 128 records in 0.088457744 seconds. Throughput is 1447.0187 records/second. Loss is 1.4542767. Sequential266afc8b's hyper parameters: Current learning rate is 5.431830526887562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 1743][Wall Clock 173.743807195s] Trained 128 records in 0.09016136 seconds. Throughput is 1419.6769 records/second. Loss is 1.3558923. Sequential266afc8b's hyper parameters: Current learning rate is 5.428881650380021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43136/60000][Iteration 1744][Wall Clock 173.830871994s] Trained 128 records in 0.087064799 seconds. Throughput is 1470.1693 records/second. Loss is 1.3448933. Sequential266afc8b's hyper parameters: Current learning rate is 5.425935973955507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 1745][Wall Clock 173.923690304s] Trained 128 records in 0.09281831 seconds. Throughput is 1379.0382 records/second. Loss is 1.4173247. Sequential266afc8b's hyper parameters: Current learning rate is 5.422993492407809E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43392/60000][Iteration 1746][Wall Clock 174.011853939s] Trained 128 records in 0.088163635 seconds. Throughput is 1451.8457 records/second. Loss is 1.4467733. Sequential266afc8b's hyper parameters: Current learning rate is 5.420054200542005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 1747][Wall Clock 174.110816213s] Trained 128 records in 0.098962274 seconds. Throughput is 1293.4221 records/second. Loss is 1.5382111. Sequential266afc8b's hyper parameters: Current learning rate is 5.417118093174431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43648/60000][Iteration 1748][Wall Clock 174.194104186s] Trained 128 records in 0.083287973 seconds. Throughput is 1536.8364 records/second. Loss is 1.3470769. Sequential266afc8b's hyper parameters: Current learning rate is 5.414185165132648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 1749][Wall Clock 174.281877784s] Trained 128 records in 0.087773598 seconds. Throughput is 1458.2972 records/second. Loss is 1.3435205. Sequential266afc8b's hyper parameters: Current learning rate is 5.411255411255411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 43904/60000][Iteration 1750][Wall Clock 174.371796306s] Trained 128 records in 0.089918522 seconds. Throughput is 1423.5109 records/second. Loss is 1.4570513. Sequential266afc8b's hyper parameters: Current learning rate is 5.408328826392644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 1751][Wall Clock 174.460576674s] Trained 128 records in 0.088780368 seconds. Throughput is 1441.7603 records/second. Loss is 1.3452214. Sequential266afc8b's hyper parameters: Current learning rate is 5.405405405405405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 44160/60000][Iteration 1752][Wall Clock 174.550205s] Trained 128 records in 0.089628326 seconds. Throughput is 1428.12 records/second. Loss is 1.4318736. Sequential266afc8b's hyper parameters: Current learning rate is 5.402485143165856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:13 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 1753][Wall Clock 174.639018417s] Trained 128 records in 0.088813417 seconds. Throughput is 1441.2236 records/second. Loss is 1.4181339. Sequential266afc8b's hyper parameters: Current learning rate is 5.399568034557236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 44416/60000][Iteration 1754][Wall Clock 174.728843831s] Trained 128 records in 0.089825414 seconds. Throughput is 1424.9865 records/second. Loss is 1.5074573. Sequential266afc8b's hyper parameters: Current learning rate is 5.396654074473826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 1755][Wall Clock 174.815620975s] Trained 128 records in 0.086777144 seconds. Throughput is 1475.0428 records/second. Loss is 1.3267213. Sequential266afc8b's hyper parameters: Current learning rate is 5.393743257820928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 44672/60000][Iteration 1756][Wall Clock 174.904594526s] Trained 128 records in 0.088973551 seconds. Throughput is 1438.6298 records/second. Loss is 1.3775747. Sequential266afc8b's hyper parameters: Current learning rate is 5.390835579514824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 1757][Wall Clock 174.995508283s] Trained 128 records in 0.090913757 seconds. Throughput is 1407.9277 records/second. Loss is 1.3499272. Sequential266afc8b's hyper parameters: Current learning rate is 5.38793103448276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 44928/60000][Iteration 1758][Wall Clock 175.089835651s] Trained 128 records in 0.094327368 seconds. Throughput is 1356.9763 records/second. Loss is 1.37201. Sequential266afc8b's hyper parameters: Current learning rate is 5.385029617662897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 1759][Wall Clock 175.177093662s] Trained 128 records in 0.087258011 seconds. Throughput is 1466.9141 records/second. Loss is 1.399472. Sequential266afc8b's hyper parameters: Current learning rate is 5.382131324004305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 45184/60000][Iteration 1760][Wall Clock 175.264406565s] Trained 128 records in 0.087312903 seconds. Throughput is 1465.9918 records/second. Loss is 1.4093504. Sequential266afc8b's hyper parameters: Current learning rate is 5.379236148466918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 1761][Wall Clock 175.356655864s] Trained 128 records in 0.092249299 seconds. Throughput is 1387.5444 records/second. Loss is 1.356058. Sequential266afc8b's hyper parameters: Current learning rate is 5.376344086021505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 45440/60000][Iteration 1762][Wall Clock 175.447807574s] Trained 128 records in 0.09115171 seconds. Throughput is 1404.2523 records/second. Loss is 1.4413936. Sequential266afc8b's hyper parameters: Current learning rate is 5.373455131649651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 1763][Wall Clock 175.536607082s] Trained 128 records in 0.088799508 seconds. Throughput is 1441.4495 records/second. Loss is 1.3874474. Sequential266afc8b's hyper parameters: Current learning rate is 5.370569280343716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:14 INFO  DistriOptimizer$:408 - [Epoch 4 45696/60000][Iteration 1764][Wall Clock 175.63149862s] Trained 128 records in 0.094891538 seconds. Throughput is 1348.9084 records/second. Loss is 1.4403425. Sequential266afc8b's hyper parameters: Current learning rate is 5.367686527106817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 1765][Wall Clock 175.729988623s] Trained 128 records in 0.098490003 seconds. Throughput is 1299.6244 records/second. Loss is 1.4409242. Sequential266afc8b's hyper parameters: Current learning rate is 5.36480686695279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 45952/60000][Iteration 1766][Wall Clock 175.818488268s] Trained 128 records in 0.088499645 seconds. Throughput is 1446.3335 records/second. Loss is 1.4353793. Sequential266afc8b's hyper parameters: Current learning rate is 5.361930294906166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 1767][Wall Clock 175.901835386s] Trained 128 records in 0.083347118 seconds. Throughput is 1535.746 records/second. Loss is 1.4191761. Sequential266afc8b's hyper parameters: Current learning rate is 5.359056806002144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46208/60000][Iteration 1768][Wall Clock 175.992231015s] Trained 128 records in 0.090395629 seconds. Throughput is 1415.9977 records/second. Loss is 1.43026. Sequential266afc8b's hyper parameters: Current learning rate is 5.356186395286556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 1769][Wall Clock 176.082880577s] Trained 128 records in 0.090649562 seconds. Throughput is 1412.0311 records/second. Loss is 1.4699122. Sequential266afc8b's hyper parameters: Current learning rate is 5.353319057815846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46464/60000][Iteration 1770][Wall Clock 176.175338477s] Trained 128 records in 0.0924579 seconds. Throughput is 1384.414 records/second. Loss is 1.4121763. Sequential266afc8b's hyper parameters: Current learning rate is 5.350454788657035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 1771][Wall Clock 176.266890877s] Trained 128 records in 0.0915524 seconds. Throughput is 1398.1064 records/second. Loss is 1.4383456. Sequential266afc8b's hyper parameters: Current learning rate is 5.347593582887701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46720/60000][Iteration 1772][Wall Clock 176.355093917s] Trained 128 records in 0.08820304 seconds. Throughput is 1451.1971 records/second. Loss is 1.4736447. Sequential266afc8b's hyper parameters: Current learning rate is 5.344735435595938E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 1773][Wall Clock 176.451567269s] Trained 128 records in 0.096473352 seconds. Throughput is 1326.7913 records/second. Loss is 1.4564075. Sequential266afc8b's hyper parameters: Current learning rate is 5.341880341880342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 46976/60000][Iteration 1774][Wall Clock 176.53817569s] Trained 128 records in 0.086608421 seconds. Throughput is 1477.9164 records/second. Loss is 1.32973. Sequential266afc8b's hyper parameters: Current learning rate is 5.339028296849973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:15 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 1775][Wall Clock 176.628923706s] Trained 128 records in 0.090748016 seconds. Throughput is 1410.4991 records/second. Loss is 1.4604955. Sequential266afc8b's hyper parameters: Current learning rate is 5.336179295624332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 47232/60000][Iteration 1776][Wall Clock 176.716880651s] Trained 128 records in 0.087956945 seconds. Throughput is 1455.2574 records/second. Loss is 1.3743644. Sequential266afc8b's hyper parameters: Current learning rate is 5.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 1777][Wall Clock 176.80698097s] Trained 128 records in 0.090100319 seconds. Throughput is 1420.6387 records/second. Loss is 1.424163. Sequential266afc8b's hyper parameters: Current learning rate is 5.330490405117271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 47488/60000][Iteration 1778][Wall Clock 176.895467179s] Trained 128 records in 0.088486209 seconds. Throughput is 1446.5531 records/second. Loss is 1.4842771. Sequential266afc8b's hyper parameters: Current learning rate is 5.327650506126799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 1779][Wall Clock 176.983725973s] Trained 128 records in 0.088258794 seconds. Throughput is 1450.2804 records/second. Loss is 1.3537186. Sequential266afc8b's hyper parameters: Current learning rate is 5.324813631522896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 47744/60000][Iteration 1780][Wall Clock 177.073134154s] Trained 128 records in 0.089408181 seconds. Throughput is 1431.6364 records/second. Loss is 1.42956. Sequential266afc8b's hyper parameters: Current learning rate is 5.32197977647685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 1781][Wall Clock 177.162049138s] Trained 128 records in 0.088914984 seconds. Throughput is 1439.5774 records/second. Loss is 1.4481034. Sequential266afc8b's hyper parameters: Current learning rate is 5.319148936170213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 48000/60000][Iteration 1782][Wall Clock 177.251007307s] Trained 128 records in 0.088958169 seconds. Throughput is 1438.8785 records/second. Loss is 1.456969. Sequential266afc8b's hyper parameters: Current learning rate is 5.31632110579479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 1783][Wall Clock 177.343162821s] Trained 128 records in 0.092155514 seconds. Throughput is 1388.9564 records/second. Loss is 1.4234124. Sequential266afc8b's hyper parameters: Current learning rate is 5.313496280552603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 48256/60000][Iteration 1784][Wall Clock 177.432095443s] Trained 128 records in 0.088932622 seconds. Throughput is 1439.2919 records/second. Loss is 1.369685. Sequential266afc8b's hyper parameters: Current learning rate is 5.310674455655868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 1785][Wall Clock 177.526858034s] Trained 128 records in 0.094762591 seconds. Throughput is 1350.7439 records/second. Loss is 1.4121279. Sequential266afc8b's hyper parameters: Current learning rate is 5.307855626326964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:16 INFO  DistriOptimizer$:408 - [Epoch 4 48512/60000][Iteration 1786][Wall Clock 177.619173105s] Trained 128 records in 0.092315071 seconds. Throughput is 1386.5558 records/second. Loss is 1.4816326. Sequential266afc8b's hyper parameters: Current learning rate is 5.305039787798408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 1787][Wall Clock 177.713864086s] Trained 128 records in 0.094690981 seconds. Throughput is 1351.7655 records/second. Loss is 1.4543943. Sequential266afc8b's hyper parameters: Current learning rate is 5.302226935312832E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 48768/60000][Iteration 1788][Wall Clock 177.803586359s] Trained 128 records in 0.089722273 seconds. Throughput is 1426.6245 records/second. Loss is 1.4376698. Sequential266afc8b's hyper parameters: Current learning rate is 5.299417064122947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 1789][Wall Clock 177.894545761s] Trained 128 records in 0.090959402 seconds. Throughput is 1407.2212 records/second. Loss is 1.384758. Sequential266afc8b's hyper parameters: Current learning rate is 5.296610169491525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49024/60000][Iteration 1790][Wall Clock 177.995360843s] Trained 128 records in 0.100815082 seconds. Throughput is 1269.6514 records/second. Loss is 1.3684659. Sequential266afc8b's hyper parameters: Current learning rate is 5.293806246691371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 1791][Wall Clock 178.08356168s] Trained 128 records in 0.088200837 seconds. Throughput is 1451.2334 records/second. Loss is 1.4348551. Sequential266afc8b's hyper parameters: Current learning rate is 5.29100529100529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49280/60000][Iteration 1792][Wall Clock 178.193316265s] Trained 128 records in 0.109754585 seconds. Throughput is 1166.2383 records/second. Loss is 1.4805723. Sequential266afc8b's hyper parameters: Current learning rate is 5.288207297726071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 1793][Wall Clock 178.283957428s] Trained 128 records in 0.090641163 seconds. Throughput is 1412.162 records/second. Loss is 1.471543. Sequential266afc8b's hyper parameters: Current learning rate is 5.285412262156447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49536/60000][Iteration 1794][Wall Clock 178.375837833s] Trained 128 records in 0.091880405 seconds. Throughput is 1393.1154 records/second. Loss is 1.4087622. Sequential266afc8b's hyper parameters: Current learning rate is 5.282620179609086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 1795][Wall Clock 178.463523966s] Trained 128 records in 0.087686133 seconds. Throughput is 1459.7518 records/second. Loss is 1.4291258. Sequential266afc8b's hyper parameters: Current learning rate is 5.279831045406547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49792/60000][Iteration 1796][Wall Clock 178.552516338s] Trained 128 records in 0.088992372 seconds. Throughput is 1438.3256 records/second. Loss is 1.4980271. Sequential266afc8b's hyper parameters: Current learning rate is 5.277044854881266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:17 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 1797][Wall Clock 178.641016125s] Trained 128 records in 0.088499787 seconds. Throughput is 1446.3312 records/second. Loss is 1.3631339. Sequential266afc8b's hyper parameters: Current learning rate is 5.274261603375527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50048/60000][Iteration 1798][Wall Clock 178.737217942s] Trained 128 records in 0.096201817 seconds. Throughput is 1330.5363 records/second. Loss is 1.4009719. Sequential266afc8b's hyper parameters: Current learning rate is 5.271481286241434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 1799][Wall Clock 178.829222132s] Trained 128 records in 0.09200419 seconds. Throughput is 1391.241 records/second. Loss is 1.4412533. Sequential266afc8b's hyper parameters: Current learning rate is 5.268703898840885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50304/60000][Iteration 1800][Wall Clock 178.914292634s] Trained 128 records in 0.085070502 seconds. Throughput is 1504.6344 records/second. Loss is 1.4280674. Sequential266afc8b's hyper parameters: Current learning rate is 5.26592943654555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 1801][Wall Clock 179.004974218s] Trained 128 records in 0.090681584 seconds. Throughput is 1411.5325 records/second. Loss is 1.2598892. Sequential266afc8b's hyper parameters: Current learning rate is 5.263157894736842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50560/60000][Iteration 1802][Wall Clock 179.095527577s] Trained 128 records in 0.090553359 seconds. Throughput is 1413.5312 records/second. Loss is 1.4740292. Sequential266afc8b's hyper parameters: Current learning rate is 5.260389268805891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 1803][Wall Clock 179.183687609s] Trained 128 records in 0.088160032 seconds. Throughput is 1451.9052 records/second. Loss is 1.3920356. Sequential266afc8b's hyper parameters: Current learning rate is 5.257623554153522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50816/60000][Iteration 1804][Wall Clock 179.271342025s] Trained 128 records in 0.087654416 seconds. Throughput is 1460.28 records/second. Loss is 1.4153733. Sequential266afc8b's hyper parameters: Current learning rate is 5.254860746190226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 1805][Wall Clock 179.361106802s] Trained 128 records in 0.089764777 seconds. Throughput is 1425.9491 records/second. Loss is 1.4204129. Sequential266afc8b's hyper parameters: Current learning rate is 5.252100840336135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 51072/60000][Iteration 1806][Wall Clock 179.45083727s] Trained 128 records in 0.089730468 seconds. Throughput is 1426.4943 records/second. Loss is 1.357589. Sequential266afc8b's hyper parameters: Current learning rate is 5.249343832020997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 1807][Wall Clock 179.539468207s] Trained 128 records in 0.088630937 seconds. Throughput is 1444.191 records/second. Loss is 1.4387453. Sequential266afc8b's hyper parameters: Current learning rate is 5.246589716684155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:18 INFO  DistriOptimizer$:408 - [Epoch 4 51328/60000][Iteration 1808][Wall Clock 179.63067595s] Trained 128 records in 0.091207743 seconds. Throughput is 1403.3896 records/second. Loss is 1.468283. Sequential266afc8b's hyper parameters: Current learning rate is 5.243838489774515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 1809][Wall Clock 179.718177056s] Trained 128 records in 0.087501106 seconds. Throughput is 1462.8386 records/second. Loss is 1.4486917. Sequential266afc8b's hyper parameters: Current learning rate is 5.241090146750523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 51584/60000][Iteration 1810][Wall Clock 179.80839179s] Trained 128 records in 0.090214734 seconds. Throughput is 1418.8369 records/second. Loss is 1.3540093. Sequential266afc8b's hyper parameters: Current learning rate is 5.238344683080147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 1811][Wall Clock 179.897361107s] Trained 128 records in 0.088969317 seconds. Throughput is 1438.6982 records/second. Loss is 1.4141849. Sequential266afc8b's hyper parameters: Current learning rate is 5.235602094240837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 51840/60000][Iteration 1812][Wall Clock 179.985451118s] Trained 128 records in 0.088090011 seconds. Throughput is 1453.0592 records/second. Loss is 1.4980096. Sequential266afc8b's hyper parameters: Current learning rate is 5.232862375719519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 1813][Wall Clock 180.074790533s] Trained 128 records in 0.089339415 seconds. Throughput is 1432.7383 records/second. Loss is 1.4154276. Sequential266afc8b's hyper parameters: Current learning rate is 5.230125523012552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 52096/60000][Iteration 1814][Wall Clock 180.161287764s] Trained 128 records in 0.086497231 seconds. Throughput is 1479.8162 records/second. Loss is 1.4733043. Sequential266afc8b's hyper parameters: Current learning rate is 5.22739153162572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 1815][Wall Clock 180.249356771s] Trained 128 records in 0.088069007 seconds. Throughput is 1453.4058 records/second. Loss is 1.4711179. Sequential266afc8b's hyper parameters: Current learning rate is 5.22466039707419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 52352/60000][Iteration 1816][Wall Clock 180.347585336s] Trained 128 records in 0.098228565 seconds. Throughput is 1303.0833 records/second. Loss is 1.4003379. Sequential266afc8b's hyper parameters: Current learning rate is 5.221932114882506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 1817][Wall Clock 180.433847959s] Trained 128 records in 0.086262623 seconds. Throughput is 1483.8408 records/second. Loss is 1.4069937. Sequential266afc8b's hyper parameters: Current learning rate is 5.219206680584552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 52608/60000][Iteration 1818][Wall Clock 180.528213327s] Trained 128 records in 0.094365368 seconds. Throughput is 1356.4298 records/second. Loss is 1.4036802. Sequential266afc8b's hyper parameters: Current learning rate is 5.216484089723526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:19 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 1819][Wall Clock 180.615166768s] Trained 128 records in 0.086953441 seconds. Throughput is 1472.0522 records/second. Loss is 1.3516647. Sequential266afc8b's hyper parameters: Current learning rate is 5.213764337851929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 52864/60000][Iteration 1820][Wall Clock 180.705293511s] Trained 128 records in 0.090126743 seconds. Throughput is 1420.2222 records/second. Loss is 1.3629303. Sequential266afc8b's hyper parameters: Current learning rate is 5.211047420531526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 1821][Wall Clock 180.793341977s] Trained 128 records in 0.088048466 seconds. Throughput is 1453.7449 records/second. Loss is 1.417464. Sequential266afc8b's hyper parameters: Current learning rate is 5.208333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53120/60000][Iteration 1822][Wall Clock 180.881804354s] Trained 128 records in 0.088462377 seconds. Throughput is 1446.9429 records/second. Loss is 1.3876158. Sequential266afc8b's hyper parameters: Current learning rate is 5.205622071837585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 1823][Wall Clock 180.97523151s] Trained 128 records in 0.093427156 seconds. Throughput is 1370.0513 records/second. Loss is 1.42693. Sequential266afc8b's hyper parameters: Current learning rate is 5.202913631633715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53376/60000][Iteration 1824][Wall Clock 181.075897434s] Trained 128 records in 0.100665924 seconds. Throughput is 1271.5325 records/second. Loss is 1.4472435. Sequential266afc8b's hyper parameters: Current learning rate is 5.200208008320332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 1825][Wall Clock 181.159443973s] Trained 128 records in 0.083546539 seconds. Throughput is 1532.0802 records/second. Loss is 1.4255685. Sequential266afc8b's hyper parameters: Current learning rate is 5.197505197505197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53632/60000][Iteration 1826][Wall Clock 181.248825192s] Trained 128 records in 0.089381219 seconds. Throughput is 1432.0682 records/second. Loss is 1.4471256. Sequential266afc8b's hyper parameters: Current learning rate is 5.194805194805195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 1827][Wall Clock 181.337340994s] Trained 128 records in 0.088515802 seconds. Throughput is 1446.0695 records/second. Loss is 1.3976413. Sequential266afc8b's hyper parameters: Current learning rate is 5.192107995846313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 53888/60000][Iteration 1828][Wall Clock 181.426620246s] Trained 128 records in 0.089279252 seconds. Throughput is 1433.7039 records/second. Loss is 1.4843851. Sequential266afc8b's hyper parameters: Current learning rate is 5.189413596263622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 1829][Wall Clock 181.514179124s] Trained 128 records in 0.087558878 seconds. Throughput is 1461.8734 records/second. Loss is 1.3854569. Sequential266afc8b's hyper parameters: Current learning rate is 5.186721991701245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:20 INFO  DistriOptimizer$:408 - [Epoch 4 54144/60000][Iteration 1830][Wall Clock 181.601566243s] Trained 128 records in 0.087387119 seconds. Throughput is 1464.7467 records/second. Loss is 1.4906634. Sequential266afc8b's hyper parameters: Current learning rate is 5.184033177812338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 1831][Wall Clock 181.689361727s] Trained 128 records in 0.087795484 seconds. Throughput is 1457.9338 records/second. Loss is 1.4635469. Sequential266afc8b's hyper parameters: Current learning rate is 5.181347150259067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54400/60000][Iteration 1832][Wall Clock 181.776270408s] Trained 128 records in 0.086908681 seconds. Throughput is 1472.8103 records/second. Loss is 1.4025127. Sequential266afc8b's hyper parameters: Current learning rate is 5.178663904712585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 1833][Wall Clock 181.863873028s] Trained 128 records in 0.08760262 seconds. Throughput is 1461.1434 records/second. Loss is 1.3652519. Sequential266afc8b's hyper parameters: Current learning rate is 5.175983436853002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54656/60000][Iteration 1834][Wall Clock 181.95266433s] Trained 128 records in 0.088791302 seconds. Throughput is 1441.5826 records/second. Loss is 1.4095329. Sequential266afc8b's hyper parameters: Current learning rate is 5.173305742369374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 1835][Wall Clock 182.039662986s] Trained 128 records in 0.086998656 seconds. Throughput is 1471.2871 records/second. Loss is 1.4025793. Sequential266afc8b's hyper parameters: Current learning rate is 5.17063081695967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 54912/60000][Iteration 1836][Wall Clock 182.131087415s] Trained 128 records in 0.091424429 seconds. Throughput is 1400.0635 records/second. Loss is 1.3985214. Sequential266afc8b's hyper parameters: Current learning rate is 5.167958656330749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 1837][Wall Clock 182.22034908s] Trained 128 records in 0.089261665 seconds. Throughput is 1433.9862 records/second. Loss is 1.4205728. Sequential266afc8b's hyper parameters: Current learning rate is 5.165289256198347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 55168/60000][Iteration 1838][Wall Clock 182.308656399s] Trained 128 records in 0.088307319 seconds. Throughput is 1449.4834 records/second. Loss is 1.358082. Sequential266afc8b's hyper parameters: Current learning rate is 5.162622612287041E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 1839][Wall Clock 182.395308004s] Trained 128 records in 0.086651605 seconds. Throughput is 1477.1797 records/second. Loss is 1.3890219. Sequential266afc8b's hyper parameters: Current learning rate is 5.159958720330238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 55424/60000][Iteration 1840][Wall Clock 182.485371429s] Trained 128 records in 0.090063425 seconds. Throughput is 1421.2207 records/second. Loss is 1.39636. Sequential266afc8b's hyper parameters: Current learning rate is 5.157297576070139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:21 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 1841][Wall Clock 182.581006787s] Trained 128 records in 0.095635358 seconds. Throughput is 1338.4171 records/second. Loss is 1.4074423. Sequential266afc8b's hyper parameters: Current learning rate is 5.154639175257731E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55680/60000][Iteration 1842][Wall Clock 182.692594543s] Trained 128 records in 0.111587756 seconds. Throughput is 1147.0792 records/second. Loss is 1.5177628. Sequential266afc8b's hyper parameters: Current learning rate is 5.151983513652757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 1843][Wall Clock 182.777150949s] Trained 128 records in 0.084556406 seconds. Throughput is 1513.7823 records/second. Loss is 1.362881. Sequential266afc8b's hyper parameters: Current learning rate is 5.149330587023687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 55936/60000][Iteration 1844][Wall Clock 182.864709822s] Trained 128 records in 0.087558873 seconds. Throughput is 1461.8735 records/second. Loss is 1.3403431. Sequential266afc8b's hyper parameters: Current learning rate is 5.14668039114771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 1845][Wall Clock 182.954326963s] Trained 128 records in 0.089617141 seconds. Throughput is 1428.2982 records/second. Loss is 1.4370388. Sequential266afc8b's hyper parameters: Current learning rate is 5.144032921810699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56192/60000][Iteration 1846][Wall Clock 183.043687609s] Trained 128 records in 0.089360646 seconds. Throughput is 1432.3978 records/second. Loss is 1.3135009. Sequential266afc8b's hyper parameters: Current learning rate is 5.141388174807199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 1847][Wall Clock 183.130070769s] Trained 128 records in 0.08638316 seconds. Throughput is 1481.7704 records/second. Loss is 1.4031782. Sequential266afc8b's hyper parameters: Current learning rate is 5.138746145940391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56448/60000][Iteration 1848][Wall Clock 183.219813318s] Trained 128 records in 0.089742549 seconds. Throughput is 1426.3022 records/second. Loss is 1.4755487. Sequential266afc8b's hyper parameters: Current learning rate is 5.136106831022085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 1849][Wall Clock 183.316682255s] Trained 128 records in 0.096868937 seconds. Throughput is 1321.3729 records/second. Loss is 1.4370351. Sequential266afc8b's hyper parameters: Current learning rate is 5.13347022587269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56704/60000][Iteration 1850][Wall Clock 183.401551832s] Trained 128 records in 0.084869577 seconds. Throughput is 1508.1965 records/second. Loss is 1.4771668. Sequential266afc8b's hyper parameters: Current learning rate is 5.13083632632119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 1851][Wall Clock 183.485634069s] Trained 128 records in 0.084082237 seconds. Throughput is 1522.3191 records/second. Loss is 1.4984595. Sequential266afc8b's hyper parameters: Current learning rate is 5.128205128205128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:22 INFO  DistriOptimizer$:408 - [Epoch 4 56960/60000][Iteration 1852][Wall Clock 183.573561339s] Trained 128 records in 0.08792727 seconds. Throughput is 1455.7487 records/second. Loss is 1.4396876. Sequential266afc8b's hyper parameters: Current learning rate is 5.125576627370579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 1853][Wall Clock 183.663743832s] Trained 128 records in 0.090182493 seconds. Throughput is 1419.3442 records/second. Loss is 1.4004931. Sequential266afc8b's hyper parameters: Current learning rate is 5.122950819672131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57216/60000][Iteration 1854][Wall Clock 183.749461454s] Trained 128 records in 0.085717622 seconds. Throughput is 1493.2753 records/second. Loss is 1.3084059. Sequential266afc8b's hyper parameters: Current learning rate is 5.120327700972862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 1855][Wall Clock 183.844335809s] Trained 128 records in 0.094874355 seconds. Throughput is 1349.1528 records/second. Loss is 1.4421593. Sequential266afc8b's hyper parameters: Current learning rate is 5.117707267144319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57472/60000][Iteration 1856][Wall Clock 183.938912935s] Trained 128 records in 0.094577126 seconds. Throughput is 1353.3928 records/second. Loss is 1.3562828. Sequential266afc8b's hyper parameters: Current learning rate is 5.115089514066496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 1857][Wall Clock 184.039775512s] Trained 128 records in 0.100862577 seconds. Throughput is 1269.0535 records/second. Loss is 1.3754618. Sequential266afc8b's hyper parameters: Current learning rate is 5.112474437627812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57728/60000][Iteration 1858][Wall Clock 184.127524706s] Trained 128 records in 0.087749194 seconds. Throughput is 1458.7029 records/second. Loss is 1.3869251. Sequential266afc8b's hyper parameters: Current learning rate is 5.10986203372509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 1859][Wall Clock 184.219882827s] Trained 128 records in 0.092358121 seconds. Throughput is 1385.9095 records/second. Loss is 1.369583. Sequential266afc8b's hyper parameters: Current learning rate is 5.107252298263534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 57984/60000][Iteration 1860][Wall Clock 184.31188238s] Trained 128 records in 0.091999553 seconds. Throughput is 1391.3112 records/second. Loss is 1.4206315. Sequential266afc8b's hyper parameters: Current learning rate is 5.104645227156713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 1861][Wall Clock 184.404004486s] Trained 128 records in 0.092122106 seconds. Throughput is 1389.4602 records/second. Loss is 1.4018896. Sequential266afc8b's hyper parameters: Current learning rate is 5.10204081632653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 58240/60000][Iteration 1862][Wall Clock 184.490018399s] Trained 128 records in 0.086013913 seconds. Throughput is 1488.1313 records/second. Loss is 1.4757546. Sequential266afc8b's hyper parameters: Current learning rate is 5.099439061703213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:23 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 1863][Wall Clock 184.583347412s] Trained 128 records in 0.093329013 seconds. Throughput is 1371.4921 records/second. Loss is 1.5187489. Sequential266afc8b's hyper parameters: Current learning rate is 5.09683995922528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 58496/60000][Iteration 1864][Wall Clock 184.67292281s] Trained 128 records in 0.089575398 seconds. Throughput is 1428.9639 records/second. Loss is 1.3856434. Sequential266afc8b's hyper parameters: Current learning rate is 5.094243504839531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 1865][Wall Clock 184.770232673s] Trained 128 records in 0.097309863 seconds. Throughput is 1315.3856 records/second. Loss is 1.3824449. Sequential266afc8b's hyper parameters: Current learning rate is 5.091649694501018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 58752/60000][Iteration 1866][Wall Clock 184.887353462s] Trained 128 records in 0.117120789 seconds. Throughput is 1092.8888 records/second. Loss is 1.4097236. Sequential266afc8b's hyper parameters: Current learning rate is 5.089058524173028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 1867][Wall Clock 184.989370939s] Trained 128 records in 0.102017477 seconds. Throughput is 1254.687 records/second. Loss is 1.4095391. Sequential266afc8b's hyper parameters: Current learning rate is 5.08646998982706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59008/60000][Iteration 1868][Wall Clock 185.074634175s] Trained 128 records in 0.085263236 seconds. Throughput is 1501.2332 records/second. Loss is 1.4199975. Sequential266afc8b's hyper parameters: Current learning rate is 5.083884087442806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 1869][Wall Clock 185.156652302s] Trained 128 records in 0.082018127 seconds. Throughput is 1560.6306 records/second. Loss is 1.3947977. Sequential266afc8b's hyper parameters: Current learning rate is 5.081300813008131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59264/60000][Iteration 1870][Wall Clock 185.242879677s] Trained 128 records in 0.086227375 seconds. Throughput is 1484.4474 records/second. Loss is 1.4035141. Sequential266afc8b's hyper parameters: Current learning rate is 5.078720162519045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 1871][Wall Clock 185.330957471s] Trained 128 records in 0.088077794 seconds. Throughput is 1453.2607 records/second. Loss is 1.4198167. Sequential266afc8b's hyper parameters: Current learning rate is 5.076142131979696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59520/60000][Iteration 1872][Wall Clock 185.419967181s] Trained 128 records in 0.08900971 seconds. Throughput is 1438.0454 records/second. Loss is 1.3852235. Sequential266afc8b's hyper parameters: Current learning rate is 5.073566717402334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 1873][Wall Clock 185.508362622s] Trained 128 records in 0.088395441 seconds. Throughput is 1448.0385 records/second. Loss is 1.4431292. Sequential266afc8b's hyper parameters: Current learning rate is 5.070993914807302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:24 INFO  DistriOptimizer$:408 - [Epoch 4 59776/60000][Iteration 1874][Wall Clock 185.595963576s] Trained 128 records in 0.087600954 seconds. Throughput is 1461.1713 records/second. Loss is 1.3093703. Sequential266afc8b's hyper parameters: Current learning rate is 5.068423720223011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 1875][Wall Clock 185.692368969s] Trained 128 records in 0.096405393 seconds. Throughput is 1327.7266 records/second. Loss is 1.3851539. Sequential266afc8b's hyper parameters: Current learning rate is 5.065856129685916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:25 INFO  DistriOptimizer$:408 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 185.778440906s] Trained 128 records in 0.086071937 seconds. Throughput is 1487.1282 records/second. Loss is 1.406865. Sequential266afc8b's hyper parameters: Current learning rate is 5.063291139240507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:25 INFO  DistriOptimizer$:452 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 185.778440906s] Epoch finished. Wall clock time is 187054.370322 ms
2019-10-15 08:21:25 INFO  DistriOptimizer$:111 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 185.778440906s] Validate model...
2019-10-15 08:21:25 INFO  DistriOptimizer$:178 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 185.778440906s] validate model throughput is 11797.897 records/second
2019-10-15 08:21:25 INFO  DistriOptimizer$:181 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 185.778440906s] Top1Accuracy is Accuracy(correct: 7051, count: 10000, accuracy: 0.7051)
2019-10-15 08:21:26 INFO  DistriOptimizer$:221 - [Wall Clock 187.054370322s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:21:26 INFO  DistriOptimizer$:226 - [Wall Clock 187.054370322s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 128/60000][Iteration 1877][Wall Clock 187.148922436s] Trained 128 records in 0.094552114 seconds. Throughput is 1353.7507 records/second. Loss is 1.303994. Sequential266afc8b's hyper parameters: Current learning rate is 5.060728744939271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 1878][Wall Clock 187.231366418s] Trained 128 records in 0.082443982 seconds. Throughput is 1552.5693 records/second. Loss is 1.4779867. Sequential266afc8b's hyper parameters: Current learning rate is 5.058168942842691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 384/60000][Iteration 1879][Wall Clock 187.316377912s] Trained 128 records in 0.085011494 seconds. Throughput is 1505.6787 records/second. Loss is 1.3431216. Sequential266afc8b's hyper parameters: Current learning rate is 5.055611729019212E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 1880][Wall Clock 187.400649182s] Trained 128 records in 0.08427127 seconds. Throughput is 1518.9044 records/second. Loss is 1.3874929. Sequential266afc8b's hyper parameters: Current learning rate is 5.053057099545225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 640/60000][Iteration 1881][Wall Clock 187.506562808s] Trained 128 records in 0.105913626 seconds. Throughput is 1208.532 records/second. Loss is 1.4222504. Sequential266afc8b's hyper parameters: Current learning rate is 5.05050505050505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 1882][Wall Clock 187.598451959s] Trained 128 records in 0.091889151 seconds. Throughput is 1392.9828 records/second. Loss is 1.436213. Sequential266afc8b's hyper parameters: Current learning rate is 5.047955577990914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 896/60000][Iteration 1883][Wall Clock 187.69323914s] Trained 128 records in 0.094787181 seconds. Throughput is 1350.3936 records/second. Loss is 1.4312657. Sequential266afc8b's hyper parameters: Current learning rate is 5.045408678102926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 1884][Wall Clock 187.781307588s] Trained 128 records in 0.088068448 seconds. Throughput is 1453.4149 records/second. Loss is 1.3843348. Sequential266afc8b's hyper parameters: Current learning rate is 5.042864346949066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 1152/60000][Iteration 1885][Wall Clock 187.869279024s] Trained 128 records in 0.087971436 seconds. Throughput is 1455.0178 records/second. Loss is 1.3379072. Sequential266afc8b's hyper parameters: Current learning rate is 5.040322580645161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:26 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 1886][Wall Clock 187.959701028s] Trained 128 records in 0.090422004 seconds. Throughput is 1415.5846 records/second. Loss is 1.3539803. Sequential266afc8b's hyper parameters: Current learning rate is 5.037783375314861E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 1408/60000][Iteration 1887][Wall Clock 188.048288785s] Trained 128 records in 0.088587757 seconds. Throughput is 1444.895 records/second. Loss is 1.4240427. Sequential266afc8b's hyper parameters: Current learning rate is 5.035246727089627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 1888][Wall Clock 188.141503492s] Trained 128 records in 0.093214707 seconds. Throughput is 1373.174 records/second. Loss is 1.4126755. Sequential266afc8b's hyper parameters: Current learning rate is 5.032712632108706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 1664/60000][Iteration 1889][Wall Clock 188.233636932s] Trained 128 records in 0.09213344 seconds. Throughput is 1389.2893 records/second. Loss is 1.4254009. Sequential266afc8b's hyper parameters: Current learning rate is 5.030181086519115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 1890][Wall Clock 188.324517533s] Trained 128 records in 0.090880601 seconds. Throughput is 1408.4414 records/second. Loss is 1.4343755. Sequential266afc8b's hyper parameters: Current learning rate is 5.027652086475615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 1920/60000][Iteration 1891][Wall Clock 188.446516594s] Trained 128 records in 0.121999061 seconds. Throughput is 1049.1884 records/second. Loss is 1.5552324. Sequential266afc8b's hyper parameters: Current learning rate is 5.025125628140703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 1892][Wall Clock 188.542215936s] Trained 128 records in 0.095699342 seconds. Throughput is 1337.5223 records/second. Loss is 1.3710126. Sequential266afc8b's hyper parameters: Current learning rate is 5.022601707684581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 2176/60000][Iteration 1893][Wall Clock 188.631330783s] Trained 128 records in 0.089114847 seconds. Throughput is 1436.3488 records/second. Loss is 1.3769419. Sequential266afc8b's hyper parameters: Current learning rate is 5.02008032128514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 1894][Wall Clock 188.72572533s] Trained 128 records in 0.094394547 seconds. Throughput is 1356.0105 records/second. Loss is 1.4264779. Sequential266afc8b's hyper parameters: Current learning rate is 5.017561465127947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 2432/60000][Iteration 1895][Wall Clock 188.816542534s] Trained 128 records in 0.090817204 seconds. Throughput is 1409.4246 records/second. Loss is 1.2840458. Sequential266afc8b's hyper parameters: Current learning rate is 5.015045135406219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:27 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 1896][Wall Clock 188.905749951s] Trained 128 records in 0.089207417 seconds. Throughput is 1434.8583 records/second. Loss is 1.3514847. Sequential266afc8b's hyper parameters: Current learning rate is 5.012531328320802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 2688/60000][Iteration 1897][Wall Clock 188.995783592s] Trained 128 records in 0.090033641 seconds. Throughput is 1421.6908 records/second. Loss is 1.3940504. Sequential266afc8b's hyper parameters: Current learning rate is 5.01002004008016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 1898][Wall Clock 189.088843244s] Trained 128 records in 0.093059652 seconds. Throughput is 1375.4618 records/second. Loss is 1.3865538. Sequential266afc8b's hyper parameters: Current learning rate is 5.007511266900351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 2944/60000][Iteration 1899][Wall Clock 189.183882705s] Trained 128 records in 0.095039461 seconds. Throughput is 1346.809 records/second. Loss is 1.4534315. Sequential266afc8b's hyper parameters: Current learning rate is 5.005005005005005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 1900][Wall Clock 189.26892065s] Trained 128 records in 0.085037945 seconds. Throughput is 1505.2103 records/second. Loss is 1.4700361. Sequential266afc8b's hyper parameters: Current learning rate is 5.002501250625312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3200/60000][Iteration 1901][Wall Clock 189.357264947s] Trained 128 records in 0.088344297 seconds. Throughput is 1448.8767 records/second. Loss is 1.4348059. Sequential266afc8b's hyper parameters: Current learning rate is 5.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 1902][Wall Clock 189.445473549s] Trained 128 records in 0.088208602 seconds. Throughput is 1451.1057 records/second. Loss is 1.4107524. Sequential266afc8b's hyper parameters: Current learning rate is 4.997501249375312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3456/60000][Iteration 1903][Wall Clock 189.535665041s] Trained 128 records in 0.090191492 seconds. Throughput is 1419.2026 records/second. Loss is 1.3357105. Sequential266afc8b's hyper parameters: Current learning rate is 4.995004995004995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 1904][Wall Clock 189.626393991s] Trained 128 records in 0.09072895 seconds. Throughput is 1410.7955 records/second. Loss is 1.3930076. Sequential266afc8b's hyper parameters: Current learning rate is 4.992511233150274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3712/60000][Iteration 1905][Wall Clock 189.715262692s] Trained 128 records in 0.088868701 seconds. Throughput is 1440.3271 records/second. Loss is 1.4709756. Sequential266afc8b's hyper parameters: Current learning rate is 4.990019960079841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 1906][Wall Clock 189.804893566s] Trained 128 records in 0.089630874 seconds. Throughput is 1428.0793 records/second. Loss is 1.3673905. Sequential266afc8b's hyper parameters: Current learning rate is 4.987531172069825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:28 INFO  DistriOptimizer$:408 - [Epoch 5 3968/60000][Iteration 1907][Wall Clock 189.896073176s] Trained 128 records in 0.09117961 seconds. Throughput is 1403.8226 records/second. Loss is 1.3801132. Sequential266afc8b's hyper parameters: Current learning rate is 4.985044865403789E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 1908][Wall Clock 189.987642974s] Trained 128 records in 0.091569798 seconds. Throughput is 1397.8408 records/second. Loss is 1.4395257. Sequential266afc8b's hyper parameters: Current learning rate is 4.982561036372695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4224/60000][Iteration 1909][Wall Clock 190.076392733s] Trained 128 records in 0.088749759 seconds. Throughput is 1442.2574 records/second. Loss is 1.3467013. Sequential266afc8b's hyper parameters: Current learning rate is 4.9800796812749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 1910][Wall Clock 190.166112431s] Trained 128 records in 0.089719698 seconds. Throughput is 1426.6655 records/second. Loss is 1.4094417. Sequential266afc8b's hyper parameters: Current learning rate is 4.977600796416127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4480/60000][Iteration 1911][Wall Clock 190.253766116s] Trained 128 records in 0.087653685 seconds. Throughput is 1460.2924 records/second. Loss is 1.4078141. Sequential266afc8b's hyper parameters: Current learning rate is 4.975124378109452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 1912][Wall Clock 190.344467304s] Trained 128 records in 0.090701188 seconds. Throughput is 1411.2274 records/second. Loss is 1.4420408. Sequential266afc8b's hyper parameters: Current learning rate is 4.972650422675287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4736/60000][Iteration 1913][Wall Clock 190.43527469s] Trained 128 records in 0.090807386 seconds. Throughput is 1409.577 records/second. Loss is 1.5149282. Sequential266afc8b's hyper parameters: Current learning rate is 4.970178926441351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 1914][Wall Clock 190.527577481s] Trained 128 records in 0.092302791 seconds. Throughput is 1386.7402 records/second. Loss is 1.4209902. Sequential266afc8b's hyper parameters: Current learning rate is 4.967709885742673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 4992/60000][Iteration 1915][Wall Clock 190.616678899s] Trained 128 records in 0.089101418 seconds. Throughput is 1436.5652 records/second. Loss is 1.3635173. Sequential266afc8b's hyper parameters: Current learning rate is 4.965243296921549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 1916][Wall Clock 190.718384994s] Trained 128 records in 0.101706095 seconds. Throughput is 1258.5283 records/second. Loss is 1.3613275. Sequential266afc8b's hyper parameters: Current learning rate is 4.962779156327543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 5248/60000][Iteration 1917][Wall Clock 190.805008783s] Trained 128 records in 0.086623789 seconds. Throughput is 1477.6542 records/second. Loss is 1.4740717. Sequential266afc8b's hyper parameters: Current learning rate is 4.96031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 1918][Wall Clock 190.890814267s] Trained 128 records in 0.085805484 seconds. Throughput is 1491.7462 records/second. Loss is 1.2618663. Sequential266afc8b's hyper parameters: Current learning rate is 4.957858205255329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:29 INFO  DistriOptimizer$:408 - [Epoch 5 5504/60000][Iteration 1919][Wall Clock 190.972766633s] Trained 128 records in 0.081952366 seconds. Throughput is 1561.8829 records/second. Loss is 1.3868623. Sequential266afc8b's hyper parameters: Current learning rate is 4.955401387512388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 1920][Wall Clock 191.061451929s] Trained 128 records in 0.088685296 seconds. Throughput is 1443.3058 records/second. Loss is 1.4515102. Sequential266afc8b's hyper parameters: Current learning rate is 4.952947003467063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 5760/60000][Iteration 1921][Wall Clock 191.150333795s] Trained 128 records in 0.088881866 seconds. Throughput is 1440.1138 records/second. Loss is 1.3846622. Sequential266afc8b's hyper parameters: Current learning rate is 4.950495049504951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 1922][Wall Clock 191.239776695s] Trained 128 records in 0.0894429 seconds. Throughput is 1431.0806 records/second. Loss is 1.3218431. Sequential266afc8b's hyper parameters: Current learning rate is 4.948045522018802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6016/60000][Iteration 1923][Wall Clock 191.326673461s] Trained 128 records in 0.086896766 seconds. Throughput is 1473.0122 records/second. Loss is 1.3235494. Sequential266afc8b's hyper parameters: Current learning rate is 4.945598417408507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 1924][Wall Clock 191.419983897s] Trained 128 records in 0.093310436 seconds. Throughput is 1371.765 records/second. Loss is 1.4388553. Sequential266afc8b's hyper parameters: Current learning rate is 4.943153732081067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6272/60000][Iteration 1925][Wall Clock 191.508410958s] Trained 128 records in 0.088427061 seconds. Throughput is 1447.5208 records/second. Loss is 1.345222. Sequential266afc8b's hyper parameters: Current learning rate is 4.940711462450593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 1926][Wall Clock 191.595112667s] Trained 128 records in 0.086701709 seconds. Throughput is 1476.3262 records/second. Loss is 1.4105088. Sequential266afc8b's hyper parameters: Current learning rate is 4.938271604938272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6528/60000][Iteration 1927][Wall Clock 191.684356554s] Trained 128 records in 0.089243887 seconds. Throughput is 1434.2719 records/second. Loss is 1.5068166. Sequential266afc8b's hyper parameters: Current learning rate is 4.935834155972359E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 1928][Wall Clock 191.770347728s] Trained 128 records in 0.085991174 seconds. Throughput is 1488.5249 records/second. Loss is 1.3327839. Sequential266afc8b's hyper parameters: Current learning rate is 4.93339911198816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6784/60000][Iteration 1929][Wall Clock 191.861290322s] Trained 128 records in 0.090942594 seconds. Throughput is 1407.4813 records/second. Loss is 1.4206277. Sequential266afc8b's hyper parameters: Current learning rate is 4.930966469428008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:30 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 1930][Wall Clock 191.948804659s] Trained 128 records in 0.087514337 seconds. Throughput is 1462.6176 records/second. Loss is 1.4134246. Sequential266afc8b's hyper parameters: Current learning rate is 4.928536224741252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7040/60000][Iteration 1931][Wall Clock 192.04258369s] Trained 128 records in 0.093779031 seconds. Throughput is 1364.9108 records/second. Loss is 1.4067522. Sequential266afc8b's hyper parameters: Current learning rate is 4.926108374384236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 1932][Wall Clock 192.132384457s] Trained 128 records in 0.089800767 seconds. Throughput is 1425.3776 records/second. Loss is 1.4488341. Sequential266afc8b's hyper parameters: Current learning rate is 4.923682914820286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7296/60000][Iteration 1933][Wall Clock 192.219163602s] Trained 128 records in 0.086779145 seconds. Throughput is 1475.0088 records/second. Loss is 1.3232913. Sequential266afc8b's hyper parameters: Current learning rate is 4.921259842519685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 1934][Wall Clock 192.308465631s] Trained 128 records in 0.089302029 seconds. Throughput is 1433.3381 records/second. Loss is 1.4239285. Sequential266afc8b's hyper parameters: Current learning rate is 4.918839153959665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7552/60000][Iteration 1935][Wall Clock 192.401789389s] Trained 128 records in 0.093323758 seconds. Throughput is 1371.5692 records/second. Loss is 1.4303253. Sequential266afc8b's hyper parameters: Current learning rate is 4.916420845624386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 1936][Wall Clock 192.493124725s] Trained 128 records in 0.091335336 seconds. Throughput is 1401.4292 records/second. Loss is 1.3461792. Sequential266afc8b's hyper parameters: Current learning rate is 4.914004914004914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7808/60000][Iteration 1937][Wall Clock 192.582886387s] Trained 128 records in 0.089761662 seconds. Throughput is 1425.9985 records/second. Loss is 1.4006696. Sequential266afc8b's hyper parameters: Current learning rate is 4.911591355599215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 1938][Wall Clock 192.674229602s] Trained 128 records in 0.091343215 seconds. Throughput is 1401.3082 records/second. Loss is 1.2963492. Sequential266afc8b's hyper parameters: Current learning rate is 4.909180166912126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 8064/60000][Iteration 1939][Wall Clock 192.762872249s] Trained 128 records in 0.088642647 seconds. Throughput is 1444.0001 records/second. Loss is 1.3773187. Sequential266afc8b's hyper parameters: Current learning rate is 4.906771344455349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 1940][Wall Clock 192.853371082s] Trained 128 records in 0.090498833 seconds. Throughput is 1414.3828 records/second. Loss is 1.382649. Sequential266afc8b's hyper parameters: Current learning rate is 4.904364884747426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:31 INFO  DistriOptimizer$:408 - [Epoch 5 8320/60000][Iteration 1941][Wall Clock 192.953477967s] Trained 128 records in 0.100106885 seconds. Throughput is 1278.6333 records/second. Loss is 1.3197376. Sequential266afc8b's hyper parameters: Current learning rate is 4.901960784313725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 1942][Wall Clock 193.040934163s] Trained 128 records in 0.087456196 seconds. Throughput is 1463.5898 records/second. Loss is 1.3664794. Sequential266afc8b's hyper parameters: Current learning rate is 4.899559039686428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 8576/60000][Iteration 1943][Wall Clock 193.12376848s] Trained 128 records in 0.082834317 seconds. Throughput is 1545.2533 records/second. Loss is 1.4154354. Sequential266afc8b's hyper parameters: Current learning rate is 4.897159647404506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 1944][Wall Clock 193.208014514s] Trained 128 records in 0.084246034 seconds. Throughput is 1519.3594 records/second. Loss is 1.4391946. Sequential266afc8b's hyper parameters: Current learning rate is 4.894762604013706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 8832/60000][Iteration 1945][Wall Clock 193.291674061s] Trained 128 records in 0.083659547 seconds. Throughput is 1530.0107 records/second. Loss is 1.3259028. Sequential266afc8b's hyper parameters: Current learning rate is 4.892367906066536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 1946][Wall Clock 193.381634005s] Trained 128 records in 0.089959944 seconds. Throughput is 1422.8555 records/second. Loss is 1.3950579. Sequential266afc8b's hyper parameters: Current learning rate is 4.88997555012225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 9088/60000][Iteration 1947][Wall Clock 193.472799553s] Trained 128 records in 0.091165548 seconds. Throughput is 1404.0392 records/second. Loss is 1.3334315. Sequential266afc8b's hyper parameters: Current learning rate is 4.887585532746823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 1948][Wall Clock 193.565437042s] Trained 128 records in 0.092637489 seconds. Throughput is 1381.7301 records/second. Loss is 1.3419546. Sequential266afc8b's hyper parameters: Current learning rate is 4.885197850512946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 9344/60000][Iteration 1949][Wall Clock 193.654543919s] Trained 128 records in 0.089106877 seconds. Throughput is 1436.4772 records/second. Loss is 1.3982501. Sequential266afc8b's hyper parameters: Current learning rate is 4.8828125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 1950][Wall Clock 193.753573425s] Trained 128 records in 0.099029506 seconds. Throughput is 1292.5441 records/second. Loss is 1.4451704. Sequential266afc8b's hyper parameters: Current learning rate is 4.8804294777940455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 9600/60000][Iteration 1951][Wall Clock 193.843680214s] Trained 128 records in 0.090106789 seconds. Throughput is 1420.5367 records/second. Loss is 1.4462997. Sequential266afc8b's hyper parameters: Current learning rate is 4.878048780487805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:32 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 1952][Wall Clock 193.934716653s] Trained 128 records in 0.091036439 seconds. Throughput is 1406.0304 records/second. Loss is 1.4221909. Sequential266afc8b's hyper parameters: Current learning rate is 4.8756704046806434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 9856/60000][Iteration 1953][Wall Clock 194.024285545s] Trained 128 records in 0.089568892 seconds. Throughput is 1429.0676 records/second. Loss is 1.3670698. Sequential266afc8b's hyper parameters: Current learning rate is 4.873294346978558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 1954][Wall Clock 194.112306185s] Trained 128 records in 0.08802064 seconds. Throughput is 1454.2045 records/second. Loss is 1.4605898. Sequential266afc8b's hyper parameters: Current learning rate is 4.8709206039941545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10112/60000][Iteration 1955][Wall Clock 194.223418997s] Trained 128 records in 0.111112812 seconds. Throughput is 1151.9824 records/second. Loss is 1.3535961. Sequential266afc8b's hyper parameters: Current learning rate is 4.868549172346641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 1956][Wall Clock 194.313592401s] Trained 128 records in 0.090173404 seconds. Throughput is 1419.4873 records/second. Loss is 1.3696625. Sequential266afc8b's hyper parameters: Current learning rate is 4.8661800486618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10368/60000][Iteration 1957][Wall Clock 194.40804908s] Trained 128 records in 0.094456679 seconds. Throughput is 1355.1185 records/second. Loss is 1.3718567. Sequential266afc8b's hyper parameters: Current learning rate is 4.863813229571985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 1958][Wall Clock 194.498757693s] Trained 128 records in 0.090708613 seconds. Throughput is 1411.1118 records/second. Loss is 1.3882897. Sequential266afc8b's hyper parameters: Current learning rate is 4.861448711716091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10624/60000][Iteration 1959][Wall Clock 194.58941104s] Trained 128 records in 0.090653347 seconds. Throughput is 1411.9722 records/second. Loss is 1.3354405. Sequential266afc8b's hyper parameters: Current learning rate is 4.8590864917395527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 1960][Wall Clock 194.677901797s] Trained 128 records in 0.088490757 seconds. Throughput is 1446.4788 records/second. Loss is 1.3250042. Sequential266afc8b's hyper parameters: Current learning rate is 4.856726566294318E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 10880/60000][Iteration 1961][Wall Clock 194.768706369s] Trained 128 records in 0.090804572 seconds. Throughput is 1409.6207 records/second. Loss is 1.3646665. Sequential266afc8b's hyper parameters: Current learning rate is 4.854368932038835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 1962][Wall Clock 194.856863026s] Trained 128 records in 0.088156657 seconds. Throughput is 1451.9607 records/second. Loss is 1.3041619. Sequential266afc8b's hyper parameters: Current learning rate is 4.85201358563804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:33 INFO  DistriOptimizer$:408 - [Epoch 5 11136/60000][Iteration 1963][Wall Clock 194.94280856s] Trained 128 records in 0.085945534 seconds. Throughput is 1489.3153 records/second. Loss is 1.3779107. Sequential266afc8b's hyper parameters: Current learning rate is 4.8496605237633366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 1964][Wall Clock 195.032862569s] Trained 128 records in 0.090054009 seconds. Throughput is 1421.3693 records/second. Loss is 1.3711174. Sequential266afc8b's hyper parameters: Current learning rate is 4.847309743092584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 11392/60000][Iteration 1965][Wall Clock 195.119922496s] Trained 128 records in 0.087059927 seconds. Throughput is 1470.2516 records/second. Loss is 1.4412233. Sequential266afc8b's hyper parameters: Current learning rate is 4.8449612403100775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 1966][Wall Clock 195.218883459s] Trained 128 records in 0.098960963 seconds. Throughput is 1293.4393 records/second. Loss is 1.4008422. Sequential266afc8b's hyper parameters: Current learning rate is 4.842615012106537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 11648/60000][Iteration 1967][Wall Clock 195.311082214s] Trained 128 records in 0.092198755 seconds. Throughput is 1388.3052 records/second. Loss is 1.3678551. Sequential266afc8b's hyper parameters: Current learning rate is 4.84027105517909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 1968][Wall Clock 195.400630813s] Trained 128 records in 0.089548599 seconds. Throughput is 1429.3914 records/second. Loss is 1.462518. Sequential266afc8b's hyper parameters: Current learning rate is 4.837929366231253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 11904/60000][Iteration 1969][Wall Clock 195.491519282s] Trained 128 records in 0.090888469 seconds. Throughput is 1408.3195 records/second. Loss is 1.4461269. Sequential266afc8b's hyper parameters: Current learning rate is 4.8355899419729207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 1970][Wall Clock 195.579017975s] Trained 128 records in 0.087498693 seconds. Throughput is 1462.8789 records/second. Loss is 1.4086856. Sequential266afc8b's hyper parameters: Current learning rate is 4.833252779120348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 12160/60000][Iteration 1971][Wall Clock 195.66601882s] Trained 128 records in 0.087000845 seconds. Throughput is 1471.25 records/second. Loss is 1.4083853. Sequential266afc8b's hyper parameters: Current learning rate is 4.8309178743961357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 1972][Wall Clock 195.754203175s] Trained 128 records in 0.088184355 seconds. Throughput is 1451.5046 records/second. Loss is 1.4146413. Sequential266afc8b's hyper parameters: Current learning rate is 4.828585224529213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 12416/60000][Iteration 1973][Wall Clock 195.841706361s] Trained 128 records in 0.087503186 seconds. Throughput is 1462.8038 records/second. Loss is 1.3186262. Sequential266afc8b's hyper parameters: Current learning rate is 4.8262548262548264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:34 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 1974][Wall Clock 195.928282284s] Trained 128 records in 0.086575923 seconds. Throughput is 1478.4711 records/second. Loss is 1.3709023. Sequential266afc8b's hyper parameters: Current learning rate is 4.82392667631452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 12672/60000][Iteration 1975][Wall Clock 196.023520156s] Trained 128 records in 0.095237872 seconds. Throughput is 1344.0032 records/second. Loss is 1.3781124. Sequential266afc8b's hyper parameters: Current learning rate is 4.821600771456123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 1976][Wall Clock 196.104802071s] Trained 128 records in 0.081281915 seconds. Throughput is 1574.766 records/second. Loss is 1.2869984. Sequential266afc8b's hyper parameters: Current learning rate is 4.819277108433735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 12928/60000][Iteration 1977][Wall Clock 196.19277847s] Trained 128 records in 0.087976399 seconds. Throughput is 1454.9357 records/second. Loss is 1.3805753. Sequential266afc8b's hyper parameters: Current learning rate is 4.816955684007707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 1978][Wall Clock 196.277901643s] Trained 128 records in 0.085123173 seconds. Throughput is 1503.7034 records/second. Loss is 1.376253. Sequential266afc8b's hyper parameters: Current learning rate is 4.814636494944632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13184/60000][Iteration 1979][Wall Clock 196.365630638s] Trained 128 records in 0.087728995 seconds. Throughput is 1459.0388 records/second. Loss is 1.3491375. Sequential266afc8b's hyper parameters: Current learning rate is 4.812319538017324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 1980][Wall Clock 196.457247187s] Trained 128 records in 0.091616549 seconds. Throughput is 1397.1276 records/second. Loss is 1.3575294. Sequential266afc8b's hyper parameters: Current learning rate is 4.81000481000481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13440/60000][Iteration 1981][Wall Clock 196.547424183s] Trained 128 records in 0.090176996 seconds. Throughput is 1419.4307 records/second. Loss is 1.4095341. Sequential266afc8b's hyper parameters: Current learning rate is 4.8076923076923074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 1982][Wall Clock 196.637826747s] Trained 128 records in 0.090402564 seconds. Throughput is 1415.889 records/second. Loss is 1.4103252. Sequential266afc8b's hyper parameters: Current learning rate is 4.805382027871216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13696/60000][Iteration 1983][Wall Clock 196.728351686s] Trained 128 records in 0.090524939 seconds. Throughput is 1413.975 records/second. Loss is 1.3960999. Sequential266afc8b's hyper parameters: Current learning rate is 4.803073967339097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 1984][Wall Clock 196.816216718s] Trained 128 records in 0.087865032 seconds. Throughput is 1456.7798 records/second. Loss is 1.3688791. Sequential266afc8b's hyper parameters: Current learning rate is 4.8007681228996637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:35 INFO  DistriOptimizer$:408 - [Epoch 5 13952/60000][Iteration 1985][Wall Clock 196.905011611s] Trained 128 records in 0.088794893 seconds. Throughput is 1441.5243 records/second. Loss is 1.3519473. Sequential266afc8b's hyper parameters: Current learning rate is 4.7984644913627643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 1986][Wall Clock 196.996476026s] Trained 128 records in 0.091464415 seconds. Throughput is 1399.4514 records/second. Loss is 1.3045421. Sequential266afc8b's hyper parameters: Current learning rate is 4.796163069544364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14208/60000][Iteration 1987][Wall Clock 197.084514811s] Trained 128 records in 0.088038785 seconds. Throughput is 1453.9047 records/second. Loss is 1.4218391. Sequential266afc8b's hyper parameters: Current learning rate is 4.793863854266539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 1988][Wall Clock 197.17452884s] Trained 128 records in 0.090014029 seconds. Throughput is 1422.0006 records/second. Loss is 1.4156724. Sequential266afc8b's hyper parameters: Current learning rate is 4.7915668423574505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14464/60000][Iteration 1989][Wall Clock 197.263469306s] Trained 128 records in 0.088940466 seconds. Throughput is 1439.1649 records/second. Loss is 1.2830929. Sequential266afc8b's hyper parameters: Current learning rate is 4.7892720306513413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 1990][Wall Clock 197.350392361s] Trained 128 records in 0.086923055 seconds. Throughput is 1472.5668 records/second. Loss is 1.3761352. Sequential266afc8b's hyper parameters: Current learning rate is 4.786979415988511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14720/60000][Iteration 1991][Wall Clock 197.447780052s] Trained 128 records in 0.097387691 seconds. Throughput is 1314.3345 records/second. Loss is 1.3719331. Sequential266afc8b's hyper parameters: Current learning rate is 4.7846889952153106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 1992][Wall Clock 197.535367233s] Trained 128 records in 0.087587181 seconds. Throughput is 1461.4011 records/second. Loss is 1.4759369. Sequential266afc8b's hyper parameters: Current learning rate is 4.7824007651841227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 14976/60000][Iteration 1993][Wall Clock 197.622721075s] Trained 128 records in 0.087353842 seconds. Throughput is 1465.3048 records/second. Loss is 1.3278328. Sequential266afc8b's hyper parameters: Current learning rate is 4.780114722753346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 1994][Wall Clock 197.710233233s] Trained 128 records in 0.087512158 seconds. Throughput is 1462.6539 records/second. Loss is 1.4491347. Sequential266afc8b's hyper parameters: Current learning rate is 4.777830864787387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 15232/60000][Iteration 1995][Wall Clock 197.798089261s] Trained 128 records in 0.087856028 seconds. Throughput is 1456.9291 records/second. Loss is 1.3749142. Sequential266afc8b's hyper parameters: Current learning rate is 4.775549188156638E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:36 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 1996][Wall Clock 197.890621514s] Trained 128 records in 0.092532253 seconds. Throughput is 1383.3014 records/second. Loss is 1.3114086. Sequential266afc8b's hyper parameters: Current learning rate is 4.7732696897374703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 15488/60000][Iteration 1997][Wall Clock 197.976755375s] Trained 128 records in 0.086133861 seconds. Throughput is 1486.0591 records/second. Loss is 1.3219126. Sequential266afc8b's hyper parameters: Current learning rate is 4.7709923664122136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 1998][Wall Clock 198.068136042s] Trained 128 records in 0.091380667 seconds. Throughput is 1400.7339 records/second. Loss is 1.3267031. Sequential266afc8b's hyper parameters: Current learning rate is 4.768717215069147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 15744/60000][Iteration 1999][Wall Clock 198.159385208s] Trained 128 records in 0.091249166 seconds. Throughput is 1402.7526 records/second. Loss is 1.3446273. Sequential266afc8b's hyper parameters: Current learning rate is 4.7664442326024784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 2000][Wall Clock 198.253614154s] Trained 128 records in 0.094228946 seconds. Throughput is 1358.3937 records/second. Loss is 1.4337654. Sequential266afc8b's hyper parameters: Current learning rate is 4.764173415912339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16000/60000][Iteration 2001][Wall Clock 198.348351075s] Trained 128 records in 0.094736921 seconds. Throughput is 1351.11 records/second. Loss is 1.4772835. Sequential266afc8b's hyper parameters: Current learning rate is 4.761904761904762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 2002][Wall Clock 198.437413138s] Trained 128 records in 0.089062063 seconds. Throughput is 1437.2 records/second. Loss is 1.4229202. Sequential266afc8b's hyper parameters: Current learning rate is 4.7596382674916705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16256/60000][Iteration 2003][Wall Clock 198.528404036s] Trained 128 records in 0.090990898 seconds. Throughput is 1406.734 records/second. Loss is 1.352935. Sequential266afc8b's hyper parameters: Current learning rate is 4.757373929590866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 2004][Wall Clock 198.619869583s] Trained 128 records in 0.091465547 seconds. Throughput is 1399.4341 records/second. Loss is 1.4353318. Sequential266afc8b's hyper parameters: Current learning rate is 4.75511174512601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16512/60000][Iteration 2005][Wall Clock 198.711685544s] Trained 128 records in 0.091815961 seconds. Throughput is 1394.0931 records/second. Loss is 1.3854043. Sequential266afc8b's hyper parameters: Current learning rate is 4.7528517110266165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 2006][Wall Clock 198.801760579s] Trained 128 records in 0.090075035 seconds. Throughput is 1421.0375 records/second. Loss is 1.424411. Sequential266afc8b's hyper parameters: Current learning rate is 4.7505938242280285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:37 INFO  DistriOptimizer$:408 - [Epoch 5 16768/60000][Iteration 2007][Wall Clock 198.896255957s] Trained 128 records in 0.094495378 seconds. Throughput is 1354.5636 records/second. Loss is 1.3446687. Sequential266afc8b's hyper parameters: Current learning rate is 4.748338081671415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 2008][Wall Clock 198.987170169s] Trained 128 records in 0.090914212 seconds. Throughput is 1407.9207 records/second. Loss is 1.3263466. Sequential266afc8b's hyper parameters: Current learning rate is 4.7460844803037496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17024/60000][Iteration 2009][Wall Clock 199.078378278s] Trained 128 records in 0.091208109 seconds. Throughput is 1403.384 records/second. Loss is 1.3795408. Sequential266afc8b's hyper parameters: Current learning rate is 4.7438330170777984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 2010][Wall Clock 199.170878549s] Trained 128 records in 0.092500271 seconds. Throughput is 1383.7798 records/second. Loss is 1.4087455. Sequential266afc8b's hyper parameters: Current learning rate is 4.74158368895211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17280/60000][Iteration 2011][Wall Clock 199.263349235s] Trained 128 records in 0.092470686 seconds. Throughput is 1384.2225 records/second. Loss is 1.469964. Sequential266afc8b's hyper parameters: Current learning rate is 4.739336492890995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 2012][Wall Clock 199.356170929s] Trained 128 records in 0.092821694 seconds. Throughput is 1378.9879 records/second. Loss is 1.4012939. Sequential266afc8b's hyper parameters: Current learning rate is 4.737091425864519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17536/60000][Iteration 2013][Wall Clock 199.44400133s] Trained 128 records in 0.087830401 seconds. Throughput is 1457.3541 records/second. Loss is 1.3889357. Sequential266afc8b's hyper parameters: Current learning rate is 4.734848484848485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 2014][Wall Clock 199.533197043s] Trained 128 records in 0.089195713 seconds. Throughput is 1435.0465 records/second. Loss is 1.412398. Sequential266afc8b's hyper parameters: Current learning rate is 4.7326076668244207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17792/60000][Iteration 2015][Wall Clock 199.620622043s] Trained 128 records in 0.087425 seconds. Throughput is 1464.112 records/second. Loss is 1.262177. Sequential266afc8b's hyper parameters: Current learning rate is 4.730368968779565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 2016][Wall Clock 199.721039326s] Trained 128 records in 0.100417283 seconds. Throughput is 1274.6809 records/second. Loss is 1.4098017. Sequential266afc8b's hyper parameters: Current learning rate is 4.7281323877068556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 18048/60000][Iteration 2017][Wall Clock 199.806211488s] Trained 128 records in 0.085172162 seconds. Throughput is 1502.8385 records/second. Loss is 1.4254035. Sequential266afc8b's hyper parameters: Current learning rate is 4.725897920604915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:38 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 2018][Wall Clock 199.892784861s] Trained 128 records in 0.086573373 seconds. Throughput is 1478.5146 records/second. Loss is 1.3171331. Sequential266afc8b's hyper parameters: Current learning rate is 4.7236655644780347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 18304/60000][Iteration 2019][Wall Clock 199.976955937s] Trained 128 records in 0.084171076 seconds. Throughput is 1520.7124 records/second. Loss is 1.3488472. Sequential266afc8b's hyper parameters: Current learning rate is 4.7214353163361664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 2020][Wall Clock 200.063656092s] Trained 128 records in 0.086700155 seconds. Throughput is 1476.3525 records/second. Loss is 1.220167. Sequential266afc8b's hyper parameters: Current learning rate is 4.719207173194903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 18560/60000][Iteration 2021][Wall Clock 200.153684672s] Trained 128 records in 0.09002858 seconds. Throughput is 1421.7708 records/second. Loss is 1.3676491. Sequential266afc8b's hyper parameters: Current learning rate is 4.716981132075472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 2022][Wall Clock 200.245520224s] Trained 128 records in 0.091835552 seconds. Throughput is 1393.7958 records/second. Loss is 1.382378. Sequential266afc8b's hyper parameters: Current learning rate is 4.714757190004715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 18816/60000][Iteration 2023][Wall Clock 200.334631612s] Trained 128 records in 0.089111388 seconds. Throughput is 1436.4045 records/second. Loss is 1.4106157. Sequential266afc8b's hyper parameters: Current learning rate is 4.7125353440150805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 2024][Wall Clock 200.42052484s] Trained 128 records in 0.085893228 seconds. Throughput is 1490.2223 records/second. Loss is 1.3572632. Sequential266afc8b's hyper parameters: Current learning rate is 4.710315591144607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 19072/60000][Iteration 2025][Wall Clock 200.508120646s] Trained 128 records in 0.087595806 seconds. Throughput is 1461.2572 records/second. Loss is 1.3855851. Sequential266afc8b's hyper parameters: Current learning rate is 4.7080979284369113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 2026][Wall Clock 200.600385516s] Trained 128 records in 0.09226487 seconds. Throughput is 1387.3103 records/second. Loss is 1.4640902. Sequential266afc8b's hyper parameters: Current learning rate is 4.7058823529411766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 19328/60000][Iteration 2027][Wall Clock 200.685047572s] Trained 128 records in 0.084662056 seconds. Throughput is 1511.8933 records/second. Loss is 1.3406936. Sequential266afc8b's hyper parameters: Current learning rate is 4.703668861712135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 2028][Wall Clock 200.774558348s] Trained 128 records in 0.089510776 seconds. Throughput is 1429.9954 records/second. Loss is 1.3381581. Sequential266afc8b's hyper parameters: Current learning rate is 4.7014574518100614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:39 INFO  DistriOptimizer$:408 - [Epoch 5 19584/60000][Iteration 2029][Wall Clock 200.866096137s] Trained 128 records in 0.091537789 seconds. Throughput is 1398.3296 records/second. Loss is 1.3517226. Sequential266afc8b's hyper parameters: Current learning rate is 4.6992481203007516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 2030][Wall Clock 200.959977541s] Trained 128 records in 0.093881404 seconds. Throughput is 1363.4222 records/second. Loss is 1.437167. Sequential266afc8b's hyper parameters: Current learning rate is 4.697040864255519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 19840/60000][Iteration 2031][Wall Clock 201.05004361s] Trained 128 records in 0.090066069 seconds. Throughput is 1421.179 records/second. Loss is 1.3958162. Sequential266afc8b's hyper parameters: Current learning rate is 4.6948356807511736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 2032][Wall Clock 201.138961354s] Trained 128 records in 0.088917744 seconds. Throughput is 1439.5326 records/second. Loss is 1.378392. Sequential266afc8b's hyper parameters: Current learning rate is 4.6926325668700144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20096/60000][Iteration 2033][Wall Clock 201.227739537s] Trained 128 records in 0.088778183 seconds. Throughput is 1441.7957 records/second. Loss is 1.3650607. Sequential266afc8b's hyper parameters: Current learning rate is 4.6904315196998124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 2034][Wall Clock 201.31800123s] Trained 128 records in 0.090261693 seconds. Throughput is 1418.0989 records/second. Loss is 1.3995426. Sequential266afc8b's hyper parameters: Current learning rate is 4.688232536333802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20352/60000][Iteration 2035][Wall Clock 201.407757884s] Trained 128 records in 0.089756654 seconds. Throughput is 1426.0781 records/second. Loss is 1.3613473. Sequential266afc8b's hyper parameters: Current learning rate is 4.6860356138706655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 2036][Wall Clock 201.497093815s] Trained 128 records in 0.089335931 seconds. Throughput is 1432.7941 records/second. Loss is 1.4582175. Sequential266afc8b's hyper parameters: Current learning rate is 4.68384074941452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20608/60000][Iteration 2037][Wall Clock 201.585599857s] Trained 128 records in 0.088506042 seconds. Throughput is 1446.2289 records/second. Loss is 1.3872437. Sequential266afc8b's hyper parameters: Current learning rate is 4.6816479400749064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 2038][Wall Clock 201.677662206s] Trained 128 records in 0.092062349 seconds. Throughput is 1390.3622 records/second. Loss is 1.4023353. Sequential266afc8b's hyper parameters: Current learning rate is 4.6794571829667756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20864/60000][Iteration 2039][Wall Clock 201.76765094s] Trained 128 records in 0.089988734 seconds. Throughput is 1422.4003 records/second. Loss is 1.3893466. Sequential266afc8b's hyper parameters: Current learning rate is 4.677268475210477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:40 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 2040][Wall Clock 201.85821921s] Trained 128 records in 0.09056827 seconds. Throughput is 1413.2986 records/second. Loss is 1.3939133. Sequential266afc8b's hyper parameters: Current learning rate is 4.675081813931744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21120/60000][Iteration 2041][Wall Clock 201.949343613s] Trained 128 records in 0.091124403 seconds. Throughput is 1404.6732 records/second. Loss is 1.4053761. Sequential266afc8b's hyper parameters: Current learning rate is 4.672897196261682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 2042][Wall Clock 202.05752157s] Trained 128 records in 0.108177957 seconds. Throughput is 1183.2355 records/second. Loss is 1.3257473. Sequential266afc8b's hyper parameters: Current learning rate is 4.670714619336759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21376/60000][Iteration 2043][Wall Clock 202.148313761s] Trained 128 records in 0.090792191 seconds. Throughput is 1409.8129 records/second. Loss is 1.3715117. Sequential266afc8b's hyper parameters: Current learning rate is 4.668534080298786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 2044][Wall Clock 202.249887852s] Trained 128 records in 0.101574091 seconds. Throughput is 1260.1638 records/second. Loss is 1.371067. Sequential266afc8b's hyper parameters: Current learning rate is 4.666355576294914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21632/60000][Iteration 2045][Wall Clock 202.341039161s] Trained 128 records in 0.091151309 seconds. Throughput is 1404.2584 records/second. Loss is 1.3506494. Sequential266afc8b's hyper parameters: Current learning rate is 4.664179104477612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 2046][Wall Clock 202.428947563s] Trained 128 records in 0.087908402 seconds. Throughput is 1456.061 records/second. Loss is 1.3622997. Sequential266afc8b's hyper parameters: Current learning rate is 4.662004662004662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 21888/60000][Iteration 2047][Wall Clock 202.523662789s] Trained 128 records in 0.094715226 seconds. Throughput is 1351.4196 records/second. Loss is 1.3355446. Sequential266afc8b's hyper parameters: Current learning rate is 4.6598322460391424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 2048][Wall Clock 202.612015545s] Trained 128 records in 0.088352756 seconds. Throughput is 1448.738 records/second. Loss is 1.4208094. Sequential266afc8b's hyper parameters: Current learning rate is 4.657661853749418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 22144/60000][Iteration 2049][Wall Clock 202.700400857s] Trained 128 records in 0.088385312 seconds. Throughput is 1448.2043 records/second. Loss is 1.333706. Sequential266afc8b's hyper parameters: Current learning rate is 4.655493482309125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 2050][Wall Clock 202.788223632s] Trained 128 records in 0.087822775 seconds. Throughput is 1457.4807 records/second. Loss is 1.4514937. Sequential266afc8b's hyper parameters: Current learning rate is 4.653327128897161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:41 INFO  DistriOptimizer$:408 - [Epoch 5 22400/60000][Iteration 2051][Wall Clock 202.880836121s] Trained 128 records in 0.092612489 seconds. Throughput is 1382.103 records/second. Loss is 1.4313089. Sequential266afc8b's hyper parameters: Current learning rate is 4.6511627906976747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 2052][Wall Clock 202.967166367s] Trained 128 records in 0.086330246 seconds. Throughput is 1482.6786 records/second. Loss is 1.4252073. Sequential266afc8b's hyper parameters: Current learning rate is 4.6490004649000463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 22656/60000][Iteration 2053][Wall Clock 203.051015282s] Trained 128 records in 0.083848915 seconds. Throughput is 1526.5552 records/second. Loss is 1.3580254. Sequential266afc8b's hyper parameters: Current learning rate is 4.646840148698885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 2054][Wall Clock 203.138462749s] Trained 128 records in 0.087447467 seconds. Throughput is 1463.736 records/second. Loss is 1.4757153. Sequential266afc8b's hyper parameters: Current learning rate is 4.6446818392940084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 22912/60000][Iteration 2055][Wall Clock 203.226990158s] Trained 128 records in 0.088527409 seconds. Throughput is 1445.8799 records/second. Loss is 1.2807407. Sequential266afc8b's hyper parameters: Current learning rate is 4.6425255338904364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 2056][Wall Clock 203.315094425s] Trained 128 records in 0.088104267 seconds. Throughput is 1452.824 records/second. Loss is 1.3920988. Sequential266afc8b's hyper parameters: Current learning rate is 4.640371229698376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23168/60000][Iteration 2057][Wall Clock 203.403935772s] Trained 128 records in 0.088841347 seconds. Throughput is 1440.7705 records/second. Loss is 1.3425745. Sequential266afc8b's hyper parameters: Current learning rate is 4.63821892393321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 2058][Wall Clock 203.494627498s] Trained 128 records in 0.090691726 seconds. Throughput is 1411.3746 records/second. Loss is 1.3214102. Sequential266afc8b's hyper parameters: Current learning rate is 4.636068613815484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23424/60000][Iteration 2059][Wall Clock 203.5832481s] Trained 128 records in 0.088620602 seconds. Throughput is 1444.3594 records/second. Loss is 1.3383838. Sequential266afc8b's hyper parameters: Current learning rate is 4.6339202965708985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 2060][Wall Clock 203.67159209s] Trained 128 records in 0.08834399 seconds. Throughput is 1448.8817 records/second. Loss is 1.4129571. Sequential266afc8b's hyper parameters: Current learning rate is 4.631773969430292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23680/60000][Iteration 2061][Wall Clock 203.762210204s] Trained 128 records in 0.090618114 seconds. Throughput is 1412.5211 records/second. Loss is 1.372288. Sequential266afc8b's hyper parameters: Current learning rate is 4.629629629629629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:42 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 2062][Wall Clock 203.849966001s] Trained 128 records in 0.087755797 seconds. Throughput is 1458.593 records/second. Loss is 1.275347. Sequential266afc8b's hyper parameters: Current learning rate is 4.6274872744099955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 23936/60000][Iteration 2063][Wall Clock 203.937988132s] Trained 128 records in 0.088022131 seconds. Throughput is 1454.1798 records/second. Loss is 1.3474114. Sequential266afc8b's hyper parameters: Current learning rate is 4.625346901017576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 2064][Wall Clock 204.023943363s] Trained 128 records in 0.085955231 seconds. Throughput is 1489.1472 records/second. Loss is 1.3516178. Sequential266afc8b's hyper parameters: Current learning rate is 4.6232085067036526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24192/60000][Iteration 2065][Wall Clock 204.111728411s] Trained 128 records in 0.087785048 seconds. Throughput is 1458.107 records/second. Loss is 1.2964504. Sequential266afc8b's hyper parameters: Current learning rate is 4.621072088724584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 2066][Wall Clock 204.200403328s] Trained 128 records in 0.088674917 seconds. Throughput is 1443.4747 records/second. Loss is 1.4129617. Sequential266afc8b's hyper parameters: Current learning rate is 4.618937644341801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24448/60000][Iteration 2067][Wall Clock 204.304225658s] Trained 128 records in 0.10382233 seconds. Throughput is 1232.8755 records/second. Loss is 1.4205166. Sequential266afc8b's hyper parameters: Current learning rate is 4.616805170821791E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 2068][Wall Clock 204.390466642s] Trained 128 records in 0.086240984 seconds. Throughput is 1484.2131 records/second. Loss is 1.3906312. Sequential266afc8b's hyper parameters: Current learning rate is 4.6146746654360867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24704/60000][Iteration 2069][Wall Clock 204.475582477s] Trained 128 records in 0.085115835 seconds. Throughput is 1503.833 records/second. Loss is 1.2929678. Sequential266afc8b's hyper parameters: Current learning rate is 4.612546125461255E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 2070][Wall Clock 204.563728856s] Trained 128 records in 0.088146379 seconds. Throughput is 1452.13 records/second. Loss is 1.2932755. Sequential266afc8b's hyper parameters: Current learning rate is 4.610419548178884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 24960/60000][Iteration 2071][Wall Clock 204.651948895s] Trained 128 records in 0.088220039 seconds. Throughput is 1450.9176 records/second. Loss is 1.3404167. Sequential266afc8b's hyper parameters: Current learning rate is 4.608294930875576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 2072][Wall Clock 204.737085826s] Trained 128 records in 0.085136931 seconds. Throughput is 1503.4604 records/second. Loss is 1.3180281. Sequential266afc8b's hyper parameters: Current learning rate is 4.6061722708429296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:43 INFO  DistriOptimizer$:408 - [Epoch 5 25216/60000][Iteration 2073][Wall Clock 204.825573013s] Trained 128 records in 0.088487187 seconds. Throughput is 1446.5371 records/second. Loss is 1.4730476. Sequential266afc8b's hyper parameters: Current learning rate is 4.6040515653775324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 2074][Wall Clock 204.912694739s] Trained 128 records in 0.087121726 seconds. Throughput is 1469.2087 records/second. Loss is 1.2545636. Sequential266afc8b's hyper parameters: Current learning rate is 4.601932811780948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 25472/60000][Iteration 2075][Wall Clock 205.000845003s] Trained 128 records in 0.088150264 seconds. Throughput is 1452.066 records/second. Loss is 1.28023. Sequential266afc8b's hyper parameters: Current learning rate is 4.599816007359705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 2076][Wall Clock 205.094901525s] Trained 128 records in 0.094056522 seconds. Throughput is 1360.8838 records/second. Loss is 1.3818753. Sequential266afc8b's hyper parameters: Current learning rate is 4.597701149425287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 25728/60000][Iteration 2077][Wall Clock 205.177642584s] Trained 128 records in 0.082741059 seconds. Throughput is 1546.995 records/second. Loss is 1.4460196. Sequential266afc8b's hyper parameters: Current learning rate is 4.5955882352941176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 2078][Wall Clock 205.262940028s] Trained 128 records in 0.085297444 seconds. Throughput is 1500.6311 records/second. Loss is 1.3978306. Sequential266afc8b's hyper parameters: Current learning rate is 4.5934772622875517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 25984/60000][Iteration 2079][Wall Clock 205.350942077s] Trained 128 records in 0.088002049 seconds. Throughput is 1454.5116 records/second. Loss is 1.4532692. Sequential266afc8b's hyper parameters: Current learning rate is 4.591368227731864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 2080][Wall Clock 205.438597398s] Trained 128 records in 0.087655321 seconds. Throughput is 1460.265 records/second. Loss is 1.3315423. Sequential266afc8b's hyper parameters: Current learning rate is 4.589261128958238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 26240/60000][Iteration 2081][Wall Clock 205.529581838s] Trained 128 records in 0.09098444 seconds. Throughput is 1406.834 records/second. Loss is 1.323755. Sequential266afc8b's hyper parameters: Current learning rate is 4.587155963302752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 2082][Wall Clock 205.616587941s] Trained 128 records in 0.087006103 seconds. Throughput is 1471.1613 records/second. Loss is 1.3818297. Sequential266afc8b's hyper parameters: Current learning rate is 4.5850527281063736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 26496/60000][Iteration 2083][Wall Clock 205.706205812s] Trained 128 records in 0.089617871 seconds. Throughput is 1428.2865 records/second. Loss is 1.4345175. Sequential266afc8b's hyper parameters: Current learning rate is 4.5829514207149406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 2084][Wall Clock 205.795959273s] Trained 128 records in 0.089753461 seconds. Throughput is 1426.1288 records/second. Loss is 1.3498931. Sequential266afc8b's hyper parameters: Current learning rate is 4.580852038479157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:44 INFO  DistriOptimizer$:408 - [Epoch 5 26752/60000][Iteration 2085][Wall Clock 205.884341514s] Trained 128 records in 0.088382241 seconds. Throughput is 1448.2546 records/second. Loss is 1.3872727. Sequential266afc8b's hyper parameters: Current learning rate is 4.578754578754579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 2086][Wall Clock 205.97411701s] Trained 128 records in 0.089775496 seconds. Throughput is 1425.7788 records/second. Loss is 1.3625317. Sequential266afc8b's hyper parameters: Current learning rate is 4.5766590389016015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27008/60000][Iteration 2087][Wall Clock 206.060558833s] Trained 128 records in 0.086441823 seconds. Throughput is 1480.7648 records/second. Loss is 1.4005979. Sequential266afc8b's hyper parameters: Current learning rate is 4.574565416285453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 2088][Wall Clock 206.151155176s] Trained 128 records in 0.090596343 seconds. Throughput is 1412.8606 records/second. Loss is 1.3089248. Sequential266afc8b's hyper parameters: Current learning rate is 4.572473708276177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27264/60000][Iteration 2089][Wall Clock 206.240848139s] Trained 128 records in 0.089692963 seconds. Throughput is 1427.0907 records/second. Loss is 1.361182. Sequential266afc8b's hyper parameters: Current learning rate is 4.5703839122486294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 2090][Wall Clock 206.328529543s] Trained 128 records in 0.087681404 seconds. Throughput is 1459.8306 records/second. Loss is 1.2552363. Sequential266afc8b's hyper parameters: Current learning rate is 4.5682960255824577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27520/60000][Iteration 2091][Wall Clock 206.416932118s] Trained 128 records in 0.088402575 seconds. Throughput is 1447.9216 records/second. Loss is 1.4181325. Sequential266afc8b's hyper parameters: Current learning rate is 4.5662100456621003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 2092][Wall Clock 206.517891257s] Trained 128 records in 0.100959139 seconds. Throughput is 1267.8397 records/second. Loss is 1.3550451. Sequential266afc8b's hyper parameters: Current learning rate is 4.5641259698767686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27776/60000][Iteration 2093][Wall Clock 206.603282307s] Trained 128 records in 0.08539105 seconds. Throughput is 1498.9861 records/second. Loss is 1.2975801. Sequential266afc8b's hyper parameters: Current learning rate is 4.562043795620438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 2094][Wall Clock 206.695423s] Trained 128 records in 0.092140693 seconds. Throughput is 1389.1799 records/second. Loss is 1.2393851. Sequential266afc8b's hyper parameters: Current learning rate is 4.5599635202918376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 28032/60000][Iteration 2095][Wall Clock 206.781323212s] Trained 128 records in 0.085900212 seconds. Throughput is 1490.1011 records/second. Loss is 1.4579982. Sequential266afc8b's hyper parameters: Current learning rate is 4.5578851412944393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:45 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 2096][Wall Clock 206.871328087s] Trained 128 records in 0.090004875 seconds. Throughput is 1422.1451 records/second. Loss is 1.3509946. Sequential266afc8b's hyper parameters: Current learning rate is 4.5558086560364467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 28288/60000][Iteration 2097][Wall Clock 206.961803712s] Trained 128 records in 0.090475625 seconds. Throughput is 1414.7456 records/second. Loss is 1.3639896. Sequential266afc8b's hyper parameters: Current learning rate is 4.553734061930783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 2098][Wall Clock 207.052407667s] Trained 128 records in 0.090603955 seconds. Throughput is 1412.7418 records/second. Loss is 1.4563463. Sequential266afc8b's hyper parameters: Current learning rate is 4.551661356395084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 28544/60000][Iteration 2099][Wall Clock 207.140617027s] Trained 128 records in 0.08820936 seconds. Throughput is 1451.0931 records/second. Loss is 1.3548484. Sequential266afc8b's hyper parameters: Current learning rate is 4.5495905368516835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 2100][Wall Clock 207.231066453s] Trained 128 records in 0.090449426 seconds. Throughput is 1415.1555 records/second. Loss is 1.4238417. Sequential266afc8b's hyper parameters: Current learning rate is 4.5475216007276033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 28800/60000][Iteration 2101][Wall Clock 207.319954342s] Trained 128 records in 0.088887889 seconds. Throughput is 1440.0161 records/second. Loss is 1.3652983. Sequential266afc8b's hyper parameters: Current learning rate is 4.5454545454545455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 2102][Wall Clock 207.422013408s] Trained 128 records in 0.102059066 seconds. Throughput is 1254.1757 records/second. Loss is 1.387897. Sequential266afc8b's hyper parameters: Current learning rate is 4.5433893684688776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 29056/60000][Iteration 2103][Wall Clock 207.510232709s] Trained 128 records in 0.088219301 seconds. Throughput is 1450.9297 records/second. Loss is 1.3241606. Sequential266afc8b's hyper parameters: Current learning rate is 4.541326067211626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 2104][Wall Clock 207.600529845s] Trained 128 records in 0.090297136 seconds. Throughput is 1417.5422 records/second. Loss is 1.3439473. Sequential266afc8b's hyper parameters: Current learning rate is 4.5392646391284613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 29312/60000][Iteration 2105][Wall Clock 207.690154578s] Trained 128 records in 0.089624733 seconds. Throughput is 1428.1772 records/second. Loss is 1.4221048. Sequential266afc8b's hyper parameters: Current learning rate is 4.537205081669692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 2106][Wall Clock 207.779589092s] Trained 128 records in 0.089434514 seconds. Throughput is 1431.2148 records/second. Loss is 1.4052038. Sequential266afc8b's hyper parameters: Current learning rate is 4.535147392290249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:46 INFO  DistriOptimizer$:408 - [Epoch 5 29568/60000][Iteration 2107][Wall Clock 207.868785958s] Trained 128 records in 0.089196866 seconds. Throughput is 1435.028 records/second. Loss is 1.4020189. Sequential266afc8b's hyper parameters: Current learning rate is 4.533091568449683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 2108][Wall Clock 207.963222984s] Trained 128 records in 0.094437026 seconds. Throughput is 1355.4006 records/second. Loss is 1.3879831. Sequential266afc8b's hyper parameters: Current learning rate is 4.5310376076121433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 29824/60000][Iteration 2109][Wall Clock 208.052210371s] Trained 128 records in 0.088987387 seconds. Throughput is 1438.4061 records/second. Loss is 1.306572. Sequential266afc8b's hyper parameters: Current learning rate is 4.5289855072463763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 2110][Wall Clock 208.139493166s] Trained 128 records in 0.087282795 seconds. Throughput is 1466.4976 records/second. Loss is 1.4013255. Sequential266afc8b's hyper parameters: Current learning rate is 4.526935264825713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30080/60000][Iteration 2111][Wall Clock 208.229297144s] Trained 128 records in 0.089803978 seconds. Throughput is 1425.3267 records/second. Loss is 1.3385297. Sequential266afc8b's hyper parameters: Current learning rate is 4.524886877828054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 2112][Wall Clock 208.31769591s] Trained 128 records in 0.088398766 seconds. Throughput is 1447.984 records/second. Loss is 1.4356225. Sequential266afc8b's hyper parameters: Current learning rate is 4.522840343735866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30336/60000][Iteration 2113][Wall Clock 208.406037138s] Trained 128 records in 0.088341228 seconds. Throughput is 1448.9271 records/second. Loss is 1.4228443. Sequential266afc8b's hyper parameters: Current learning rate is 4.520795660036166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 2114][Wall Clock 208.494982232s] Trained 128 records in 0.088945094 seconds. Throughput is 1439.0901 records/second. Loss is 1.374405. Sequential266afc8b's hyper parameters: Current learning rate is 4.5187528242205153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30592/60000][Iteration 2115][Wall Clock 208.583282959s] Trained 128 records in 0.088300727 seconds. Throughput is 1449.5917 records/second. Loss is 1.4011519. Sequential266afc8b's hyper parameters: Current learning rate is 4.5167118337850043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 2116][Wall Clock 208.671071154s] Trained 128 records in 0.087788195 seconds. Throughput is 1458.0548 records/second. Loss is 1.3461401. Sequential266afc8b's hyper parameters: Current learning rate is 4.514672686230248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30848/60000][Iteration 2117][Wall Clock 208.768942267s] Trained 128 records in 0.097871113 seconds. Throughput is 1307.8425 records/second. Loss is 1.3228658. Sequential266afc8b's hyper parameters: Current learning rate is 4.512635379061372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:47 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 2118][Wall Clock 208.85022621s] Trained 128 records in 0.081283943 seconds. Throughput is 1574.7268 records/second. Loss is 1.2601873. Sequential266afc8b's hyper parameters: Current learning rate is 4.510599909788002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31104/60000][Iteration 2119][Wall Clock 208.937786504s] Trained 128 records in 0.087560294 seconds. Throughput is 1461.8497 records/second. Loss is 1.3587015. Sequential266afc8b's hyper parameters: Current learning rate is 4.5085662759242564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 2120][Wall Clock 209.02724605s] Trained 128 records in 0.089459546 seconds. Throughput is 1430.8143 records/second. Loss is 1.2806349. Sequential266afc8b's hyper parameters: Current learning rate is 4.506534474988734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31360/60000][Iteration 2121][Wall Clock 209.115910462s] Trained 128 records in 0.088664412 seconds. Throughput is 1443.6458 records/second. Loss is 1.381963. Sequential266afc8b's hyper parameters: Current learning rate is 4.5045045045045046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 2122][Wall Clock 209.204686585s] Trained 128 records in 0.088776123 seconds. Throughput is 1441.8291 records/second. Loss is 1.3203211. Sequential266afc8b's hyper parameters: Current learning rate is 4.5024763619990995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31616/60000][Iteration 2123][Wall Clock 209.293086115s] Trained 128 records in 0.08839953 seconds. Throughput is 1447.9716 records/second. Loss is 1.3464276. Sequential266afc8b's hyper parameters: Current learning rate is 4.500450045004501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 2124][Wall Clock 209.380534579s] Trained 128 records in 0.087448464 seconds. Throughput is 1463.7192 records/second. Loss is 1.386826. Sequential266afc8b's hyper parameters: Current learning rate is 4.49842555105713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 31872/60000][Iteration 2125][Wall Clock 209.467338272s] Trained 128 records in 0.086803693 seconds. Throughput is 1474.5917 records/second. Loss is 1.3126317. Sequential266afc8b's hyper parameters: Current learning rate is 4.4964028776978414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 2126][Wall Clock 209.558489571s] Trained 128 records in 0.091151299 seconds. Throughput is 1404.2587 records/second. Loss is 1.3842428. Sequential266afc8b's hyper parameters: Current learning rate is 4.4943820224719103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 32128/60000][Iteration 2127][Wall Clock 209.645750647s] Trained 128 records in 0.087261076 seconds. Throughput is 1466.8625 records/second. Loss is 1.3873086. Sequential266afc8b's hyper parameters: Current learning rate is 4.4923629829290204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 2128][Wall Clock 209.746630768s] Trained 128 records in 0.100880121 seconds. Throughput is 1268.8328 records/second. Loss is 1.3902423. Sequential266afc8b's hyper parameters: Current learning rate is 4.4903457566232603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:48 INFO  DistriOptimizer$:408 - [Epoch 5 32384/60000][Iteration 2129][Wall Clock 209.827745105s] Trained 128 records in 0.081114337 seconds. Throughput is 1578.0194 records/second. Loss is 1.3148134. Sequential266afc8b's hyper parameters: Current learning rate is 4.4883303411131055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 2130][Wall Clock 209.91871715s] Trained 128 records in 0.090972045 seconds. Throughput is 1407.0256 records/second. Loss is 1.3125037. Sequential266afc8b's hyper parameters: Current learning rate is 4.486316733961418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 32640/60000][Iteration 2131][Wall Clock 210.018113998s] Trained 128 records in 0.099396848 seconds. Throughput is 1287.7672 records/second. Loss is 1.4324427. Sequential266afc8b's hyper parameters: Current learning rate is 4.484304932735426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 2132][Wall Clock 210.113227391s] Trained 128 records in 0.095113393 seconds. Throughput is 1345.7621 records/second. Loss is 1.3390006. Sequential266afc8b's hyper parameters: Current learning rate is 4.4822949350067237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 32896/60000][Iteration 2133][Wall Clock 210.218690992s] Trained 128 records in 0.105463601 seconds. Throughput is 1213.6888 records/second. Loss is 1.3844295. Sequential266afc8b's hyper parameters: Current learning rate is 4.4802867383512545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 2134][Wall Clock 210.31293984s] Trained 128 records in 0.094248848 seconds. Throughput is 1358.1068 records/second. Loss is 1.3822291. Sequential266afc8b's hyper parameters: Current learning rate is 4.478280340349306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 33152/60000][Iteration 2135][Wall Clock 210.40700108s] Trained 128 records in 0.09406124 seconds. Throughput is 1360.8156 records/second. Loss is 1.4228494. Sequential266afc8b's hyper parameters: Current learning rate is 4.476275738585497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 2136][Wall Clock 210.50151742s] Trained 128 records in 0.09451634 seconds. Throughput is 1354.2632 records/second. Loss is 1.3990636. Sequential266afc8b's hyper parameters: Current learning rate is 4.474272930648769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 33408/60000][Iteration 2137][Wall Clock 210.591692494s] Trained 128 records in 0.090175074 seconds. Throughput is 1419.4609 records/second. Loss is 1.3106873. Sequential266afc8b's hyper parameters: Current learning rate is 4.472271914132379E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 2138][Wall Clock 210.684875465s] Trained 128 records in 0.093182971 seconds. Throughput is 1373.6415 records/second. Loss is 1.4021262. Sequential266afc8b's hyper parameters: Current learning rate is 4.470272686633885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:49 INFO  DistriOptimizer$:408 - [Epoch 5 33664/60000][Iteration 2139][Wall Clock 210.774885056s] Trained 128 records in 0.090009591 seconds. Throughput is 1422.0707 records/second. Loss is 1.452333. Sequential266afc8b's hyper parameters: Current learning rate is 4.468275245755139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 2140][Wall Clock 210.864587607s] Trained 128 records in 0.089702551 seconds. Throughput is 1426.9382 records/second. Loss is 1.3337343. Sequential266afc8b's hyper parameters: Current learning rate is 4.4662795891022776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 33920/60000][Iteration 2141][Wall Clock 210.95827718s] Trained 128 records in 0.093689573 seconds. Throughput is 1366.2139 records/second. Loss is 1.4487494. Sequential266afc8b's hyper parameters: Current learning rate is 4.464285714285714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 2142][Wall Clock 211.064263503s] Trained 128 records in 0.105986323 seconds. Throughput is 1207.703 records/second. Loss is 1.2076727. Sequential266afc8b's hyper parameters: Current learning rate is 4.462293618920125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34176/60000][Iteration 2143][Wall Clock 211.158097056s] Trained 128 records in 0.093833553 seconds. Throughput is 1364.1177 records/second. Loss is 1.4202689. Sequential266afc8b's hyper parameters: Current learning rate is 4.460303300624442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 2144][Wall Clock 211.246804145s] Trained 128 records in 0.088707089 seconds. Throughput is 1442.9512 records/second. Loss is 1.2790667. Sequential266afc8b's hyper parameters: Current learning rate is 4.458314757021846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34432/60000][Iteration 2145][Wall Clock 211.33868899s] Trained 128 records in 0.091884845 seconds. Throughput is 1393.048 records/second. Loss is 1.3839763. Sequential266afc8b's hyper parameters: Current learning rate is 4.45632798573975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 2146][Wall Clock 211.43048469s] Trained 128 records in 0.0917957 seconds. Throughput is 1394.4009 records/second. Loss is 1.3526533. Sequential266afc8b's hyper parameters: Current learning rate is 4.4543429844097997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34688/60000][Iteration 2147][Wall Clock 211.528662301s] Trained 128 records in 0.098177611 seconds. Throughput is 1303.7595 records/second. Loss is 1.4073913. Sequential266afc8b's hyper parameters: Current learning rate is 4.452359750667854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 2148][Wall Clock 211.623717255s] Trained 128 records in 0.095054954 seconds. Throughput is 1346.5895 records/second. Loss is 1.2765652. Sequential266afc8b's hyper parameters: Current learning rate is 4.4503782821539835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 34944/60000][Iteration 2149][Wall Clock 211.719593907s] Trained 128 records in 0.095876652 seconds. Throughput is 1335.0487 records/second. Loss is 1.3679544. Sequential266afc8b's hyper parameters: Current learning rate is 4.4483985765124553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:50 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 2150][Wall Clock 211.811677206s] Trained 128 records in 0.092083299 seconds. Throughput is 1390.0458 records/second. Loss is 1.3828741. Sequential266afc8b's hyper parameters: Current learning rate is 4.4464206313917296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35200/60000][Iteration 2151][Wall Clock 211.906809505s] Trained 128 records in 0.095132299 seconds. Throughput is 1345.4946 records/second. Loss is 1.3197544. Sequential266afc8b's hyper parameters: Current learning rate is 4.4444444444444447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 2152][Wall Clock 212.003764692s] Trained 128 records in 0.096955187 seconds. Throughput is 1320.1975 records/second. Loss is 1.3191723. Sequential266afc8b's hyper parameters: Current learning rate is 4.44247001332741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35456/60000][Iteration 2153][Wall Clock 212.110278586s] Trained 128 records in 0.106513894 seconds. Throughput is 1201.7212 records/second. Loss is 1.3520278. Sequential266afc8b's hyper parameters: Current learning rate is 4.440497335701599E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 2154][Wall Clock 212.208287143s] Trained 128 records in 0.098008557 seconds. Throughput is 1306.0084 records/second. Loss is 1.5064106. Sequential266afc8b's hyper parameters: Current learning rate is 4.438526409232135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35712/60000][Iteration 2155][Wall Clock 212.31003551s] Trained 128 records in 0.101748367 seconds. Throughput is 1258.0054 records/second. Loss is 1.4967024. Sequential266afc8b's hyper parameters: Current learning rate is 4.4365572315882877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 2156][Wall Clock 212.402316843s] Trained 128 records in 0.092281333 seconds. Throughput is 1387.0627 records/second. Loss is 1.4025643. Sequential266afc8b's hyper parameters: Current learning rate is 4.434589800443459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 35968/60000][Iteration 2157][Wall Clock 212.491169162s] Trained 128 records in 0.088852319 seconds. Throughput is 1440.5928 records/second. Loss is 1.3409649. Sequential266afc8b's hyper parameters: Current learning rate is 4.432624113475178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 2158][Wall Clock 212.581169473s] Trained 128 records in 0.090000311 seconds. Throughput is 1422.2173 records/second. Loss is 1.3140057. Sequential266afc8b's hyper parameters: Current learning rate is 4.4306601683650863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 36224/60000][Iteration 2159][Wall Clock 212.675407478s] Trained 128 records in 0.094238005 seconds. Throughput is 1358.2631 records/second. Loss is 1.379499. Sequential266afc8b's hyper parameters: Current learning rate is 4.4286979627989367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:51 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 2160][Wall Clock 212.769516313s] Trained 128 records in 0.094108835 seconds. Throughput is 1360.1273 records/second. Loss is 1.3100944. Sequential266afc8b's hyper parameters: Current learning rate is 4.426737494466578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 36480/60000][Iteration 2161][Wall Clock 212.861122708s] Trained 128 records in 0.091606395 seconds. Throughput is 1397.2823 records/second. Loss is 1.4094818. Sequential266afc8b's hyper parameters: Current learning rate is 4.424778761061947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 2162][Wall Clock 212.954525957s] Trained 128 records in 0.093403249 seconds. Throughput is 1370.402 records/second. Loss is 1.392424. Sequential266afc8b's hyper parameters: Current learning rate is 4.422821760283061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 36736/60000][Iteration 2163][Wall Clock 213.047929872s] Trained 128 records in 0.093403915 seconds. Throughput is 1370.3922 records/second. Loss is 1.3327812. Sequential266afc8b's hyper parameters: Current learning rate is 4.420866489832007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 2164][Wall Clock 213.138563264s] Trained 128 records in 0.090633392 seconds. Throughput is 1412.283 records/second. Loss is 1.4081588. Sequential266afc8b's hyper parameters: Current learning rate is 4.418912947414936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 36992/60000][Iteration 2165][Wall Clock 213.232024005s] Trained 128 records in 0.093460741 seconds. Throughput is 1369.5591 records/second. Loss is 1.4877048. Sequential266afc8b's hyper parameters: Current learning rate is 4.4169611307420494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 2166][Wall Clock 213.322451378s] Trained 128 records in 0.090427373 seconds. Throughput is 1415.5005 records/second. Loss is 1.3370206. Sequential266afc8b's hyper parameters: Current learning rate is 4.4150110375275933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 37248/60000][Iteration 2167][Wall Clock 213.413841393s] Trained 128 records in 0.091390015 seconds. Throughput is 1400.5907 records/second. Loss is 1.2703935. Sequential266afc8b's hyper parameters: Current learning rate is 4.41306266548985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 2168][Wall Clock 213.508321529s] Trained 128 records in 0.094480136 seconds. Throughput is 1354.7821 records/second. Loss is 1.391957. Sequential266afc8b's hyper parameters: Current learning rate is 4.411116012351125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 37504/60000][Iteration 2169][Wall Clock 213.599880666s] Trained 128 records in 0.091559137 seconds. Throughput is 1398.0037 records/second. Loss is 1.332628. Sequential266afc8b's hyper parameters: Current learning rate is 4.409171075837743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 2170][Wall Clock 213.693172426s] Trained 128 records in 0.09329176 seconds. Throughput is 1372.0397 records/second. Loss is 1.3989736. Sequential266afc8b's hyper parameters: Current learning rate is 4.407227853680035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:52 INFO  DistriOptimizer$:408 - [Epoch 5 37760/60000][Iteration 2171][Wall Clock 213.783949618s] Trained 128 records in 0.090777192 seconds. Throughput is 1410.0459 records/second. Loss is 1.2632267. Sequential266afc8b's hyper parameters: Current learning rate is 4.405286343612335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 2172][Wall Clock 213.873196783s] Trained 128 records in 0.089247165 seconds. Throughput is 1434.2192 records/second. Loss is 1.3343893. Sequential266afc8b's hyper parameters: Current learning rate is 4.4033465433729633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38016/60000][Iteration 2173][Wall Clock 213.968031781s] Trained 128 records in 0.094834998 seconds. Throughput is 1349.7126 records/second. Loss is 1.3442544. Sequential266afc8b's hyper parameters: Current learning rate is 4.4014084507042255E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 2174][Wall Clock 214.062292344s] Trained 128 records in 0.094260563 seconds. Throughput is 1357.938 records/second. Loss is 1.3791786. Sequential266afc8b's hyper parameters: Current learning rate is 4.399472063352398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38272/60000][Iteration 2175][Wall Clock 214.154234968s] Trained 128 records in 0.091942624 seconds. Throughput is 1392.1726 records/second. Loss is 1.3263556. Sequential266afc8b's hyper parameters: Current learning rate is 4.397537379067722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 2176][Wall Clock 214.24651066s] Trained 128 records in 0.092275692 seconds. Throughput is 1387.1475 records/second. Loss is 1.4240458. Sequential266afc8b's hyper parameters: Current learning rate is 4.3956043956043956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38528/60000][Iteration 2177][Wall Clock 214.339213102s] Trained 128 records in 0.092702442 seconds. Throughput is 1380.762 records/second. Loss is 1.2971289. Sequential266afc8b's hyper parameters: Current learning rate is 4.393673110720562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 2178][Wall Clock 214.436130722s] Trained 128 records in 0.09691762 seconds. Throughput is 1320.7092 records/second. Loss is 1.3151175. Sequential266afc8b's hyper parameters: Current learning rate is 4.391743522178305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38784/60000][Iteration 2179][Wall Clock 214.543038239s] Trained 128 records in 0.106907517 seconds. Throughput is 1197.2965 records/second. Loss is 1.3455608. Sequential266afc8b's hyper parameters: Current learning rate is 4.389815627743635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 2180][Wall Clock 214.632746624s] Trained 128 records in 0.089708385 seconds. Throughput is 1426.8453 records/second. Loss is 1.295546. Sequential266afc8b's hyper parameters: Current learning rate is 4.3878894251864854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 39040/60000][Iteration 2181][Wall Clock 214.725905888s] Trained 128 records in 0.093159264 seconds. Throughput is 1373.9911 records/second. Loss is 1.2152305. Sequential266afc8b's hyper parameters: Current learning rate is 4.385964912280702E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:53 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 2182][Wall Clock 214.820341014s] Trained 128 records in 0.094435126 seconds. Throughput is 1355.4279 records/second. Loss is 1.3946438. Sequential266afc8b's hyper parameters: Current learning rate is 4.3840420868040335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 39296/60000][Iteration 2183][Wall Clock 214.914759613s] Trained 128 records in 0.094418599 seconds. Throughput is 1355.665 records/second. Loss is 1.3629161. Sequential266afc8b's hyper parameters: Current learning rate is 4.3821209465381246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 2184][Wall Clock 215.007887805s] Trained 128 records in 0.093128192 seconds. Throughput is 1374.4496 records/second. Loss is 1.3058854. Sequential266afc8b's hyper parameters: Current learning rate is 4.380201489268506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 39552/60000][Iteration 2185][Wall Clock 215.102630279s] Trained 128 records in 0.094742474 seconds. Throughput is 1351.0308 records/second. Loss is 1.3798376. Sequential266afc8b's hyper parameters: Current learning rate is 4.3782837127845885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 2186][Wall Clock 215.196550771s] Trained 128 records in 0.093920492 seconds. Throughput is 1362.8549 records/second. Loss is 1.3972828. Sequential266afc8b's hyper parameters: Current learning rate is 4.3763676148796495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 39808/60000][Iteration 2187][Wall Clock 215.286936251s] Trained 128 records in 0.09038548 seconds. Throughput is 1416.1566 records/second. Loss is 1.2488654. Sequential266afc8b's hyper parameters: Current learning rate is 4.374453193350831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 2188][Wall Clock 215.381161299s] Trained 128 records in 0.094225048 seconds. Throughput is 1358.4498 records/second. Loss is 1.392465. Sequential266afc8b's hyper parameters: Current learning rate is 4.3725404459991256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 40064/60000][Iteration 2189][Wall Clock 215.472566428s] Trained 128 records in 0.091405129 seconds. Throughput is 1400.359 records/second. Loss is 1.3478041. Sequential266afc8b's hyper parameters: Current learning rate is 4.370629370629371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 2190][Wall Clock 215.567484876s] Trained 128 records in 0.094918448 seconds. Throughput is 1348.5261 records/second. Loss is 1.4659824. Sequential266afc8b's hyper parameters: Current learning rate is 4.3687199650502403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 40320/60000][Iteration 2191][Wall Clock 215.667261787s] Trained 128 records in 0.099776911 seconds. Throughput is 1282.8619 records/second. Loss is 1.3089907. Sequential266afc8b's hyper parameters: Current learning rate is 4.3668122270742354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:54 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 2192][Wall Clock 215.760408698s] Trained 128 records in 0.093146911 seconds. Throughput is 1374.1733 records/second. Loss is 1.3785121. Sequential266afc8b's hyper parameters: Current learning rate is 4.3649061545176777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 40576/60000][Iteration 2193][Wall Clock 215.860602549s] Trained 128 records in 0.100193851 seconds. Throughput is 1277.5236 records/second. Loss is 1.2875184. Sequential266afc8b's hyper parameters: Current learning rate is 4.3630017452006976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 2194][Wall Clock 215.950061373s] Trained 128 records in 0.089458824 seconds. Throughput is 1430.8259 records/second. Loss is 1.2946029. Sequential266afc8b's hyper parameters: Current learning rate is 4.361098996947231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 40832/60000][Iteration 2195][Wall Clock 216.045495632s] Trained 128 records in 0.095434259 seconds. Throughput is 1341.2374 records/second. Loss is 1.4256177. Sequential266afc8b's hyper parameters: Current learning rate is 4.359197907585004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 2196][Wall Clock 216.137682865s] Trained 128 records in 0.092187233 seconds. Throughput is 1388.4786 records/second. Loss is 1.3992089. Sequential266afc8b's hyper parameters: Current learning rate is 4.357298474945534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41088/60000][Iteration 2197][Wall Clock 216.227058271s] Trained 128 records in 0.089375406 seconds. Throughput is 1432.1614 records/second. Loss is 1.2815245. Sequential266afc8b's hyper parameters: Current learning rate is 4.3554006968641115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 2198][Wall Clock 216.322376218s] Trained 128 records in 0.095317947 seconds. Throughput is 1342.8741 records/second. Loss is 1.4317883. Sequential266afc8b's hyper parameters: Current learning rate is 4.3535045711798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41344/60000][Iteration 2199][Wall Clock 216.411603423s] Trained 128 records in 0.089227205 seconds. Throughput is 1434.54 records/second. Loss is 1.3056982. Sequential266afc8b's hyper parameters: Current learning rate is 4.351610095735422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 2200][Wall Clock 216.498792645s] Trained 128 records in 0.087189222 seconds. Throughput is 1468.0714 records/second. Loss is 1.3868792. Sequential266afc8b's hyper parameters: Current learning rate is 4.3497172683775554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41600/60000][Iteration 2201][Wall Clock 216.588197392s] Trained 128 records in 0.089404747 seconds. Throughput is 1431.6913 records/second. Loss is 1.4141614. Sequential266afc8b's hyper parameters: Current learning rate is 4.347826086956522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 2202][Wall Clock 216.679108911s] Trained 128 records in 0.090911519 seconds. Throughput is 1407.9623 records/second. Loss is 1.365569. Sequential266afc8b's hyper parameters: Current learning rate is 4.3459365493263795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:55 INFO  DistriOptimizer$:408 - [Epoch 5 41856/60000][Iteration 2203][Wall Clock 216.767092016s] Trained 128 records in 0.087983105 seconds. Throughput is 1454.8248 records/second. Loss is 1.3476565. Sequential266afc8b's hyper parameters: Current learning rate is 4.344048653344918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 2204][Wall Clock 216.867182328s] Trained 128 records in 0.100090312 seconds. Throughput is 1278.8451 records/second. Loss is 1.3673129. Sequential266afc8b's hyper parameters: Current learning rate is 4.342162396873643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42112/60000][Iteration 2205][Wall Clock 216.952881798s] Trained 128 records in 0.08569947 seconds. Throughput is 1493.5916 records/second. Loss is 1.3097634. Sequential266afc8b's hyper parameters: Current learning rate is 4.340277777777778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 2206][Wall Clock 217.042529942s] Trained 128 records in 0.089648144 seconds. Throughput is 1427.8043 records/second. Loss is 1.4209315. Sequential266afc8b's hyper parameters: Current learning rate is 4.338394793926247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42368/60000][Iteration 2207][Wall Clock 217.126417829s] Trained 128 records in 0.083887887 seconds. Throughput is 1525.846 records/second. Loss is 1.2638229. Sequential266afc8b's hyper parameters: Current learning rate is 4.3365134431916743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 2208][Wall Clock 217.213829541s] Trained 128 records in 0.087411712 seconds. Throughput is 1464.3347 records/second. Loss is 1.3629552. Sequential266afc8b's hyper parameters: Current learning rate is 4.3346337234503684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42624/60000][Iteration 2209][Wall Clock 217.300546999s] Trained 128 records in 0.086717458 seconds. Throughput is 1476.0581 records/second. Loss is 1.339772. Sequential266afc8b's hyper parameters: Current learning rate is 4.332755632582322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 2210][Wall Clock 217.3891594s] Trained 128 records in 0.088612401 seconds. Throughput is 1444.493 records/second. Loss is 1.3917885. Sequential266afc8b's hyper parameters: Current learning rate is 4.3308791684712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 42880/60000][Iteration 2211][Wall Clock 217.480050207s] Trained 128 records in 0.090890807 seconds. Throughput is 1408.2832 records/second. Loss is 1.3521119. Sequential266afc8b's hyper parameters: Current learning rate is 4.329004329004329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 2212][Wall Clock 217.565862682s] Trained 128 records in 0.085812475 seconds. Throughput is 1491.6246 records/second. Loss is 1.304966. Sequential266afc8b's hyper parameters: Current learning rate is 4.327131112072696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 43136/60000][Iteration 2213][Wall Clock 217.652271259s] Trained 128 records in 0.086408577 seconds. Throughput is 1481.3345 records/second. Loss is 1.3303977. Sequential266afc8b's hyper parameters: Current learning rate is 4.3252595155709344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:56 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 2214][Wall Clock 217.745297068s] Trained 128 records in 0.093025809 seconds. Throughput is 1375.9622 records/second. Loss is 1.384427. Sequential266afc8b's hyper parameters: Current learning rate is 4.32338953739732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 43392/60000][Iteration 2215][Wall Clock 217.833306753s] Trained 128 records in 0.088009685 seconds. Throughput is 1454.3854 records/second. Loss is 1.3541498. Sequential266afc8b's hyper parameters: Current learning rate is 4.32152117545376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 2216][Wall Clock 217.924124228s] Trained 128 records in 0.090817475 seconds. Throughput is 1409.4204 records/second. Loss is 1.33063. Sequential266afc8b's hyper parameters: Current learning rate is 4.3196544276457883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 43648/60000][Iteration 2217][Wall Clock 218.019303719s] Trained 128 records in 0.095179491 seconds. Throughput is 1344.8275 records/second. Loss is 1.4164442. Sequential266afc8b's hyper parameters: Current learning rate is 4.317789291882556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 2218][Wall Clock 218.107187956s] Trained 128 records in 0.087884237 seconds. Throughput is 1456.4614 records/second. Loss is 1.3218884. Sequential266afc8b's hyper parameters: Current learning rate is 4.3159257660768235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 43904/60000][Iteration 2219][Wall Clock 218.192915s] Trained 128 records in 0.085727044 seconds. Throughput is 1493.1111 records/second. Loss is 1.428505. Sequential266afc8b's hyper parameters: Current learning rate is 4.314063848144953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 2220][Wall Clock 218.282293548s] Trained 128 records in 0.089378548 seconds. Throughput is 1432.111 records/second. Loss is 1.3757806. Sequential266afc8b's hyper parameters: Current learning rate is 4.312203536006899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 44160/60000][Iteration 2221][Wall Clock 218.368814765s] Trained 128 records in 0.086521217 seconds. Throughput is 1479.4059 records/second. Loss is 1.3614618. Sequential266afc8b's hyper parameters: Current learning rate is 4.3103448275862074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 2222][Wall Clock 218.456382284s] Trained 128 records in 0.087567519 seconds. Throughput is 1461.7292 records/second. Loss is 1.3149475. Sequential266afc8b's hyper parameters: Current learning rate is 4.3084877208099956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 44416/60000][Iteration 2223][Wall Clock 218.545603236s] Trained 128 records in 0.089220952 seconds. Throughput is 1434.6406 records/second. Loss is 1.3216804. Sequential266afc8b's hyper parameters: Current learning rate is 4.3066322136089583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 2224][Wall Clock 218.638132699s] Trained 128 records in 0.092529463 seconds. Throughput is 1383.3431 records/second. Loss is 1.2295145. Sequential266afc8b's hyper parameters: Current learning rate is 4.3047783039173483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:57 INFO  DistriOptimizer$:408 - [Epoch 5 44672/60000][Iteration 2225][Wall Clock 218.727032602s] Trained 128 records in 0.088899903 seconds. Throughput is 1439.8215 records/second. Loss is 1.4090621. Sequential266afc8b's hyper parameters: Current learning rate is 4.302925989672977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 2226][Wall Clock 218.815260395s] Trained 128 records in 0.088227793 seconds. Throughput is 1450.79 records/second. Loss is 1.324149. Sequential266afc8b's hyper parameters: Current learning rate is 4.3010752688172043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 44928/60000][Iteration 2227][Wall Clock 218.904446224s] Trained 128 records in 0.089185829 seconds. Throughput is 1435.2056 records/second. Loss is 1.3034502. Sequential266afc8b's hyper parameters: Current learning rate is 4.2992261392949265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 2228][Wall Clock 218.994339565s] Trained 128 records in 0.089893341 seconds. Throughput is 1423.9097 records/second. Loss is 1.4633934. Sequential266afc8b's hyper parameters: Current learning rate is 4.297378599054577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45184/60000][Iteration 2229][Wall Clock 219.083524906s] Trained 128 records in 0.089185341 seconds. Throughput is 1435.2134 records/second. Loss is 1.3140815. Sequential266afc8b's hyper parameters: Current learning rate is 4.29553264604811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 2230][Wall Clock 219.179295284s] Trained 128 records in 0.095770378 seconds. Throughput is 1336.5302 records/second. Loss is 1.3778666. Sequential266afc8b's hyper parameters: Current learning rate is 4.2936882782310007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45440/60000][Iteration 2231][Wall Clock 219.27727193s] Trained 128 records in 0.097976646 seconds. Throughput is 1306.4337 records/second. Loss is 1.3885695. Sequential266afc8b's hyper parameters: Current learning rate is 4.2918454935622315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 2232][Wall Clock 219.362617311s] Trained 128 records in 0.085345381 seconds. Throughput is 1499.7883 records/second. Loss is 1.3565917. Sequential266afc8b's hyper parameters: Current learning rate is 4.2900042900042906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45696/60000][Iteration 2233][Wall Clock 219.449947641s] Trained 128 records in 0.08733033 seconds. Throughput is 1465.6993 records/second. Loss is 1.4175828. Sequential266afc8b's hyper parameters: Current learning rate is 4.288164665523156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 2234][Wall Clock 219.53889583s] Trained 128 records in 0.088948189 seconds. Throughput is 1439.0399 records/second. Loss is 1.2362634. Sequential266afc8b's hyper parameters: Current learning rate is 4.286326618088298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 45952/60000][Iteration 2235][Wall Clock 219.625574455s] Trained 128 records in 0.086678625 seconds. Throughput is 1476.7194 records/second. Loss is 1.3244511. Sequential266afc8b's hyper parameters: Current learning rate is 4.284490145672665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 2236][Wall Clock 219.712535865s] Trained 128 records in 0.08696141 seconds. Throughput is 1471.9172 records/second. Loss is 1.2709818. Sequential266afc8b's hyper parameters: Current learning rate is 4.2826552462526765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:58 INFO  DistriOptimizer$:408 - [Epoch 5 46208/60000][Iteration 2237][Wall Clock 219.797690499s] Trained 128 records in 0.085154634 seconds. Throughput is 1503.1477 records/second. Loss is 1.3626521. Sequential266afc8b's hyper parameters: Current learning rate is 4.2808219178082195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 2238][Wall Clock 219.885055841s] Trained 128 records in 0.087365342 seconds. Throughput is 1465.1118 records/second. Loss is 1.3050866. Sequential266afc8b's hyper parameters: Current learning rate is 4.278990158322636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 46464/60000][Iteration 2239][Wall Clock 219.974998863s] Trained 128 records in 0.089943022 seconds. Throughput is 1423.1232 records/second. Loss is 1.445582. Sequential266afc8b's hyper parameters: Current learning rate is 4.2771599657827206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 2240][Wall Clock 220.062805175s] Trained 128 records in 0.087806312 seconds. Throughput is 1457.7539 records/second. Loss is 1.4302669. Sequential266afc8b's hyper parameters: Current learning rate is 4.2753313381787086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 46720/60000][Iteration 2241][Wall Clock 220.148787682s] Trained 128 records in 0.085982507 seconds. Throughput is 1488.6749 records/second. Loss is 1.313332. Sequential266afc8b's hyper parameters: Current learning rate is 4.273504273504273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 2242][Wall Clock 220.242023533s] Trained 128 records in 0.093235851 seconds. Throughput is 1372.8624 records/second. Loss is 1.3176782. Sequential266afc8b's hyper parameters: Current learning rate is 4.2716787697565144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 46976/60000][Iteration 2243][Wall Clock 220.342121604s] Trained 128 records in 0.100098071 seconds. Throughput is 1278.7458 records/second. Loss is 1.3033167. Sequential266afc8b's hyper parameters: Current learning rate is 4.269854824935952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 2244][Wall Clock 220.422830881s] Trained 128 records in 0.080709277 seconds. Throughput is 1585.9391 records/second. Loss is 1.2951891. Sequential266afc8b's hyper parameters: Current learning rate is 4.268032437046522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 47232/60000][Iteration 2245][Wall Clock 220.508191244s] Trained 128 records in 0.085360363 seconds. Throughput is 1499.525 records/second. Loss is 1.3758298. Sequential266afc8b's hyper parameters: Current learning rate is 4.266211604095563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 2246][Wall Clock 220.595660629s] Trained 128 records in 0.087469385 seconds. Throughput is 1463.3691 records/second. Loss is 1.3174311. Sequential266afc8b's hyper parameters: Current learning rate is 4.264392324093817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 47488/60000][Iteration 2247][Wall Clock 220.681062186s] Trained 128 records in 0.085401557 seconds. Throughput is 1498.8018 records/second. Loss is 1.336209. Sequential266afc8b's hyper parameters: Current learning rate is 4.2625745950554135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:21:59 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 2248][Wall Clock 220.767225754s] Trained 128 records in 0.086163568 seconds. Throughput is 1485.5468 records/second. Loss is 1.3667439. Sequential266afc8b's hyper parameters: Current learning rate is 4.26075841499787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 47744/60000][Iteration 2249][Wall Clock 220.854362736s] Trained 128 records in 0.087136982 seconds. Throughput is 1468.9514 records/second. Loss is 1.3489075. Sequential266afc8b's hyper parameters: Current learning rate is 4.2589437819420784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 2250][Wall Clock 220.940761204s] Trained 128 records in 0.086398468 seconds. Throughput is 1481.5078 records/second. Loss is 1.4078064. Sequential266afc8b's hyper parameters: Current learning rate is 4.2571306939123026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48000/60000][Iteration 2251][Wall Clock 221.028486638s] Trained 128 records in 0.087725434 seconds. Throughput is 1459.098 records/second. Loss is 1.3212593. Sequential266afc8b's hyper parameters: Current learning rate is 4.25531914893617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 2252][Wall Clock 221.113443388s] Trained 128 records in 0.08495675 seconds. Throughput is 1506.6489 records/second. Loss is 1.3434926. Sequential266afc8b's hyper parameters: Current learning rate is 4.2535091450446614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48256/60000][Iteration 2253][Wall Clock 221.201004723s] Trained 128 records in 0.087561335 seconds. Throughput is 1461.8325 records/second. Loss is 1.3248969. Sequential266afc8b's hyper parameters: Current learning rate is 4.251700680272109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 2254][Wall Clock 221.28998115s] Trained 128 records in 0.088976427 seconds. Throughput is 1438.5833 records/second. Loss is 1.3394179. Sequential266afc8b's hyper parameters: Current learning rate is 4.2498937526561835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48512/60000][Iteration 2255][Wall Clock 221.379181731s] Trained 128 records in 0.089200581 seconds. Throughput is 1434.9683 records/second. Loss is 1.2933966. Sequential266afc8b's hyper parameters: Current learning rate is 4.248088360237893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 2256][Wall Clock 221.472418878s] Trained 128 records in 0.093237147 seconds. Throughput is 1372.8434 records/second. Loss is 1.4039531. Sequential266afc8b's hyper parameters: Current learning rate is 4.246284501061571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48768/60000][Iteration 2257][Wall Clock 221.575370789s] Trained 128 records in 0.102951911 seconds. Throughput is 1243.2988 records/second. Loss is 1.3852139. Sequential266afc8b's hyper parameters: Current learning rate is 4.244482173174873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 2258][Wall Clock 221.669289508s] Trained 128 records in 0.093918719 seconds. Throughput is 1362.8806 records/second. Loss is 1.2779381. Sequential266afc8b's hyper parameters: Current learning rate is 4.2426813746287653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:00 INFO  DistriOptimizer$:408 - [Epoch 5 49024/60000][Iteration 2259][Wall Clock 221.751774922s] Trained 128 records in 0.082485414 seconds. Throughput is 1551.7894 records/second. Loss is 1.3536153. Sequential266afc8b's hyper parameters: Current learning rate is 4.2408821034775233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 2260][Wall Clock 221.841265753s] Trained 128 records in 0.089490831 seconds. Throughput is 1430.3141 records/second. Loss is 1.2970247. Sequential266afc8b's hyper parameters: Current learning rate is 4.23908435777872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49280/60000][Iteration 2261][Wall Clock 221.928629842s] Trained 128 records in 0.087364089 seconds. Throughput is 1465.1328 records/second. Loss is 1.286359. Sequential266afc8b's hyper parameters: Current learning rate is 4.23728813559322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 2262][Wall Clock 222.017654944s] Trained 128 records in 0.089025102 seconds. Throughput is 1437.7968 records/second. Loss is 1.2736673. Sequential266afc8b's hyper parameters: Current learning rate is 4.235493434985176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49536/60000][Iteration 2263][Wall Clock 222.106220843s] Trained 128 records in 0.088565899 seconds. Throughput is 1445.2515 records/second. Loss is 1.3688387. Sequential266afc8b's hyper parameters: Current learning rate is 4.233700254022015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 2264][Wall Clock 222.196814489s] Trained 128 records in 0.090593646 seconds. Throughput is 1412.9027 records/second. Loss is 1.4336662. Sequential266afc8b's hyper parameters: Current learning rate is 4.2319085907744394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49792/60000][Iteration 2265][Wall Clock 222.2873097s] Trained 128 records in 0.090495211 seconds. Throughput is 1414.4395 records/second. Loss is 1.3714495. Sequential266afc8b's hyper parameters: Current learning rate is 4.2301184433164127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 2266][Wall Clock 222.374340444s] Trained 128 records in 0.087030744 seconds. Throughput is 1470.7446 records/second. Loss is 1.3029656. Sequential266afc8b's hyper parameters: Current learning rate is 4.2283298097251583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 50048/60000][Iteration 2267][Wall Clock 222.473639355s] Trained 128 records in 0.099298911 seconds. Throughput is 1289.0374 records/second. Loss is 1.3494743. Sequential266afc8b's hyper parameters: Current learning rate is 4.22654268808115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 2268][Wall Clock 222.565614408s] Trained 128 records in 0.091975053 seconds. Throughput is 1391.6816 records/second. Loss is 1.2673807. Sequential266afc8b's hyper parameters: Current learning rate is 4.224757076468103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 50304/60000][Iteration 2269][Wall Clock 222.653292225s] Trained 128 records in 0.087677817 seconds. Throughput is 1459.8904 records/second. Loss is 1.3559022. Sequential266afc8b's hyper parameters: Current learning rate is 4.222972972972973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:01 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 2270][Wall Clock 222.741757024s] Trained 128 records in 0.088464799 seconds. Throughput is 1446.9032 records/second. Loss is 1.3625642. Sequential266afc8b's hyper parameters: Current learning rate is 4.2211903756859433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 50560/60000][Iteration 2271][Wall Clock 222.834673793s] Trained 128 records in 0.092916769 seconds. Throughput is 1377.5769 records/second. Loss is 1.3919202. Sequential266afc8b's hyper parameters: Current learning rate is 4.219409282700422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 2272][Wall Clock 222.923927076s] Trained 128 records in 0.089253283 seconds. Throughput is 1434.1208 records/second. Loss is 1.3463874. Sequential266afc8b's hyper parameters: Current learning rate is 4.2176296921130323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 50816/60000][Iteration 2273][Wall Clock 223.01498856s] Trained 128 records in 0.091061484 seconds. Throughput is 1405.6438 records/second. Loss is 1.3500099. Sequential266afc8b's hyper parameters: Current learning rate is 4.215851602023609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 2274][Wall Clock 223.101576331s] Trained 128 records in 0.086587771 seconds. Throughput is 1478.2688 records/second. Loss is 1.2845592. Sequential266afc8b's hyper parameters: Current learning rate is 4.2140750105351877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51072/60000][Iteration 2275][Wall Clock 223.192053397s] Trained 128 records in 0.090477066 seconds. Throughput is 1414.7231 records/second. Loss is 1.4162095. Sequential266afc8b's hyper parameters: Current learning rate is 4.2122999157540015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 2276][Wall Clock 223.279590258s] Trained 128 records in 0.087536861 seconds. Throughput is 1462.2411 records/second. Loss is 1.3224862. Sequential266afc8b's hyper parameters: Current learning rate is 4.210526315789474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51328/60000][Iteration 2277][Wall Clock 223.370142848s] Trained 128 records in 0.09055259 seconds. Throughput is 1413.5432 records/second. Loss is 1.3717551. Sequential266afc8b's hyper parameters: Current learning rate is 4.2087542087542086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 2278][Wall Clock 223.459651507s] Trained 128 records in 0.089508659 seconds. Throughput is 1430.0292 records/second. Loss is 1.3984342. Sequential266afc8b's hyper parameters: Current learning rate is 4.2069835927639884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51584/60000][Iteration 2279][Wall Clock 223.548792262s] Trained 128 records in 0.089140755 seconds. Throughput is 1435.9313 records/second. Loss is 1.2830514. Sequential266afc8b's hyper parameters: Current learning rate is 4.2052144659377626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 2280][Wall Clock 223.638410304s] Trained 128 records in 0.089618042 seconds. Throughput is 1428.2838 records/second. Loss is 1.4016666. Sequential266afc8b's hyper parameters: Current learning rate is 4.203446826397646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:02 INFO  DistriOptimizer$:408 - [Epoch 5 51840/60000][Iteration 2281][Wall Clock 223.724925205s] Trained 128 records in 0.086514901 seconds. Throughput is 1479.5139 records/second. Loss is 1.3963495. Sequential266afc8b's hyper parameters: Current learning rate is 4.2016806722689073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 2282][Wall Clock 223.809485763s] Trained 128 records in 0.084560558 seconds. Throughput is 1513.7081 records/second. Loss is 1.3339373. Sequential266afc8b's hyper parameters: Current learning rate is 4.1999160016799666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52096/60000][Iteration 2283][Wall Clock 223.906784861s] Trained 128 records in 0.097299098 seconds. Throughput is 1315.5312 records/second. Loss is 1.4012018. Sequential266afc8b's hyper parameters: Current learning rate is 4.1981528127623844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 2284][Wall Clock 223.989391079s] Trained 128 records in 0.082606218 seconds. Throughput is 1549.5201 records/second. Loss is 1.2852229. Sequential266afc8b's hyper parameters: Current learning rate is 4.19639110365086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52352/60000][Iteration 2285][Wall Clock 224.072093924s] Trained 128 records in 0.082702845 seconds. Throughput is 1547.7097 records/second. Loss is 1.3933884. Sequential266afc8b's hyper parameters: Current learning rate is 4.1946308724832214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 2286][Wall Clock 224.163665903s] Trained 128 records in 0.091571979 seconds. Throughput is 1397.8075 records/second. Loss is 1.1990482. Sequential266afc8b's hyper parameters: Current learning rate is 4.192872117400419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52608/60000][Iteration 2287][Wall Clock 224.252493375s] Trained 128 records in 0.088827472 seconds. Throughput is 1440.9957 records/second. Loss is 1.3357098. Sequential266afc8b's hyper parameters: Current learning rate is 4.1911148365465214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 2288][Wall Clock 224.340034086s] Trained 128 records in 0.087540711 seconds. Throughput is 1462.1769 records/second. Loss is 1.2930248. Sequential266afc8b's hyper parameters: Current learning rate is 4.1893590280687055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52864/60000][Iteration 2289][Wall Clock 224.427246514s] Trained 128 records in 0.087212428 seconds. Throughput is 1467.6807 records/second. Loss is 1.2729051. Sequential266afc8b's hyper parameters: Current learning rate is 4.187604690117253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 2290][Wall Clock 224.515413175s] Trained 128 records in 0.088166661 seconds. Throughput is 1451.7959 records/second. Loss is 1.32444. Sequential266afc8b's hyper parameters: Current learning rate is 4.185851820845542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 53120/60000][Iteration 2291][Wall Clock 224.601140252s] Trained 128 records in 0.085727077 seconds. Throughput is 1493.1105 records/second. Loss is 1.3142824. Sequential266afc8b's hyper parameters: Current learning rate is 4.1841004184100416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:03 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 2292][Wall Clock 224.716970121s] Trained 128 records in 0.115829869 seconds. Throughput is 1105.069 records/second. Loss is 1.3349687. Sequential266afc8b's hyper parameters: Current learning rate is 4.182350480970305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 53376/60000][Iteration 2293][Wall Clock 224.796427453s] Trained 128 records in 0.079457332 seconds. Throughput is 1610.9274 records/second. Loss is 1.3703673. Sequential266afc8b's hyper parameters: Current learning rate is 4.180602006688963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 2294][Wall Clock 224.883724746s] Trained 128 records in 0.087297293 seconds. Throughput is 1466.254 records/second. Loss is 1.367162. Sequential266afc8b's hyper parameters: Current learning rate is 4.178854993731718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 53632/60000][Iteration 2295][Wall Clock 224.972502712s] Trained 128 records in 0.088777966 seconds. Throughput is 1441.7992 records/second. Loss is 1.3524982. Sequential266afc8b's hyper parameters: Current learning rate is 4.177109440267335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 2296][Wall Clock 225.06238655s] Trained 128 records in 0.089883838 seconds. Throughput is 1424.0602 records/second. Loss is 1.3160937. Sequential266afc8b's hyper parameters: Current learning rate is 4.175365344467641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 53888/60000][Iteration 2297][Wall Clock 225.150535061s] Trained 128 records in 0.088148511 seconds. Throughput is 1452.0948 records/second. Loss is 1.3309817. Sequential266afc8b's hyper parameters: Current learning rate is 4.1736227045075126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 2298][Wall Clock 225.240625983s] Trained 128 records in 0.090090922 seconds. Throughput is 1420.7869 records/second. Loss is 1.3173048. Sequential266afc8b's hyper parameters: Current learning rate is 4.171881518564873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 54144/60000][Iteration 2299][Wall Clock 225.330329433s] Trained 128 records in 0.08970345 seconds. Throughput is 1426.924 records/second. Loss is 1.4529864. Sequential266afc8b's hyper parameters: Current learning rate is 4.170141784820684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 2300][Wall Clock 225.418520975s] Trained 128 records in 0.088191542 seconds. Throughput is 1451.3864 records/second. Loss is 1.305888. Sequential266afc8b's hyper parameters: Current learning rate is 4.168403501458941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 54400/60000][Iteration 2301][Wall Clock 225.505788417s] Trained 128 records in 0.087267442 seconds. Throughput is 1466.7555 records/second. Loss is 1.3189464. Sequential266afc8b's hyper parameters: Current learning rate is 4.166666666666667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 2302][Wall Clock 225.594727591s] Trained 128 records in 0.088939174 seconds. Throughput is 1439.1858 records/second. Loss is 1.2770593. Sequential266afc8b's hyper parameters: Current learning rate is 4.164931278633902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:04 INFO  DistriOptimizer$:408 - [Epoch 5 54656/60000][Iteration 2303][Wall Clock 225.684557698s] Trained 128 records in 0.089830107 seconds. Throughput is 1424.912 records/second. Loss is 1.3072934. Sequential266afc8b's hyper parameters: Current learning rate is 4.1631973355537054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 2304][Wall Clock 225.771982002s] Trained 128 records in 0.087424304 seconds. Throughput is 1464.1238 records/second. Loss is 1.3081176. Sequential266afc8b's hyper parameters: Current learning rate is 4.1614648356221387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 54912/60000][Iteration 2305][Wall Clock 225.859349967s] Trained 128 records in 0.087367965 seconds. Throughput is 1465.0679 records/second. Loss is 1.3362468. Sequential266afc8b's hyper parameters: Current learning rate is 4.1597337770382697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 2306][Wall Clock 225.946602844s] Trained 128 records in 0.087252877 seconds. Throughput is 1467.0004 records/second. Loss is 1.2601955. Sequential266afc8b's hyper parameters: Current learning rate is 4.158004158004158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55168/60000][Iteration 2307][Wall Clock 226.033005625s] Trained 128 records in 0.086402781 seconds. Throughput is 1481.4338 records/second. Loss is 1.2655042. Sequential266afc8b's hyper parameters: Current learning rate is 4.1562759767248546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 2308][Wall Clock 226.119253114s] Trained 128 records in 0.086247489 seconds. Throughput is 1484.1012 records/second. Loss is 1.27565. Sequential266afc8b's hyper parameters: Current learning rate is 4.154549231408392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55424/60000][Iteration 2309][Wall Clock 226.218808011s] Trained 128 records in 0.099554897 seconds. Throughput is 1285.7228 records/second. Loss is 1.3252662. Sequential266afc8b's hyper parameters: Current learning rate is 4.1528239202657803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 2310][Wall Clock 226.302693868s] Trained 128 records in 0.083885857 seconds. Throughput is 1525.8829 records/second. Loss is 1.3392906. Sequential266afc8b's hyper parameters: Current learning rate is 4.1511000415110004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55680/60000][Iteration 2311][Wall Clock 226.384239414s] Trained 128 records in 0.081545546 seconds. Throughput is 1569.6749 records/second. Loss is 1.3763565. Sequential266afc8b's hyper parameters: Current learning rate is 4.149377593360996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 2312][Wall Clock 226.468005695s] Trained 128 records in 0.083766281 seconds. Throughput is 1528.0612 records/second. Loss is 1.3390268. Sequential266afc8b's hyper parameters: Current learning rate is 4.14765657403567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 55936/60000][Iteration 2313][Wall Clock 226.556183361s] Trained 128 records in 0.088177666 seconds. Throughput is 1451.6147 records/second. Loss is 1.371862. Sequential266afc8b's hyper parameters: Current learning rate is 4.1459369817578774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 2314][Wall Clock 226.64538982s] Trained 128 records in 0.089206459 seconds. Throughput is 1434.8737 records/second. Loss is 1.301665. Sequential266afc8b's hyper parameters: Current learning rate is 4.1442188147534193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:05 INFO  DistriOptimizer$:408 - [Epoch 5 56192/60000][Iteration 2315][Wall Clock 226.730418983s] Trained 128 records in 0.085029163 seconds. Throughput is 1505.3658 records/second. Loss is 1.2317286. Sequential266afc8b's hyper parameters: Current learning rate is 4.1425020712510354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 2316][Wall Clock 226.818185901s] Trained 128 records in 0.087766918 seconds. Throughput is 1458.4083 records/second. Loss is 1.328508. Sequential266afc8b's hyper parameters: Current learning rate is 4.1407867494824016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 56448/60000][Iteration 2317][Wall Clock 226.908676059s] Trained 128 records in 0.090490158 seconds. Throughput is 1414.5186 records/second. Loss is 1.2686354. Sequential266afc8b's hyper parameters: Current learning rate is 4.139072847682119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 2318][Wall Clock 227.001073112s] Trained 128 records in 0.092397053 seconds. Throughput is 1385.3256 records/second. Loss is 1.2358842. Sequential266afc8b's hyper parameters: Current learning rate is 4.137360364087712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 56704/60000][Iteration 2319][Wall Clock 227.093414281s] Trained 128 records in 0.092341169 seconds. Throughput is 1386.164 records/second. Loss is 1.3211619. Sequential266afc8b's hyper parameters: Current learning rate is 4.1356492969396195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 2320][Wall Clock 227.180529491s] Trained 128 records in 0.08711521 seconds. Throughput is 1469.3186 records/second. Loss is 1.3647199. Sequential266afc8b's hyper parameters: Current learning rate is 4.1339396444811904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 56960/60000][Iteration 2321][Wall Clock 227.270458352s] Trained 128 records in 0.089928861 seconds. Throughput is 1423.3473 records/second. Loss is 1.3100019. Sequential266afc8b's hyper parameters: Current learning rate is 4.132231404958678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 2322][Wall Clock 227.362530421s] Trained 128 records in 0.092072069 seconds. Throughput is 1390.2153 records/second. Loss is 1.4186049. Sequential266afc8b's hyper parameters: Current learning rate is 4.1305245766212306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 57216/60000][Iteration 2323][Wall Clock 227.452165484s] Trained 128 records in 0.089635063 seconds. Throughput is 1428.0126 records/second. Loss is 1.3074315. Sequential266afc8b's hyper parameters: Current learning rate is 4.128819157720892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 2324][Wall Clock 227.540903887s] Trained 128 records in 0.088738403 seconds. Throughput is 1442.442 records/second. Loss is 1.2779671. Sequential266afc8b's hyper parameters: Current learning rate is 4.127115146512588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 57472/60000][Iteration 2325][Wall Clock 227.627703748s] Trained 128 records in 0.086799861 seconds. Throughput is 1474.6567 records/second. Loss is 1.3472909. Sequential266afc8b's hyper parameters: Current learning rate is 4.125412541254125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:06 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 2326][Wall Clock 227.715238977s] Trained 128 records in 0.087535229 seconds. Throughput is 1462.2683 records/second. Loss is 1.2956129. Sequential266afc8b's hyper parameters: Current learning rate is 4.123711340206186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 57728/60000][Iteration 2327][Wall Clock 227.800285875s] Trained 128 records in 0.085046898 seconds. Throughput is 1505.052 records/second. Loss is 1.355914. Sequential266afc8b's hyper parameters: Current learning rate is 4.1220115416323167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 2328][Wall Clock 227.889037785s] Trained 128 records in 0.08875191 seconds. Throughput is 1442.2224 records/second. Loss is 1.3225467. Sequential266afc8b's hyper parameters: Current learning rate is 4.1203131437989287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 57984/60000][Iteration 2329][Wall Clock 227.981998217s] Trained 128 records in 0.092960432 seconds. Throughput is 1376.9299 records/second. Loss is 1.3115239. Sequential266afc8b's hyper parameters: Current learning rate is 4.1186161449752884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 2330][Wall Clock 228.072209194s] Trained 128 records in 0.090210977 seconds. Throughput is 1418.8961 records/second. Loss is 1.2598277. Sequential266afc8b's hyper parameters: Current learning rate is 4.116920543433512E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58240/60000][Iteration 2331][Wall Clock 228.161506878s] Trained 128 records in 0.089297684 seconds. Throughput is 1433.4078 records/second. Loss is 1.3197037. Sequential266afc8b's hyper parameters: Current learning rate is 4.1152263374485596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 2332][Wall Clock 228.254931543s] Trained 128 records in 0.093424665 seconds. Throughput is 1370.0879 records/second. Loss is 1.347455. Sequential266afc8b's hyper parameters: Current learning rate is 4.1135335252982314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58496/60000][Iteration 2333][Wall Clock 228.342378608s] Trained 128 records in 0.087447065 seconds. Throughput is 1463.7427 records/second. Loss is 1.3091234. Sequential266afc8b's hyper parameters: Current learning rate is 4.1118421052631577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 2334][Wall Clock 228.430961715s] Trained 128 records in 0.088583107 seconds. Throughput is 1444.9708 records/second. Loss is 1.3398877. Sequential266afc8b's hyper parameters: Current learning rate is 4.110152075626798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58752/60000][Iteration 2335][Wall Clock 228.532758999s] Trained 128 records in 0.101797284 seconds. Throughput is 1257.401 records/second. Loss is 1.2458842. Sequential266afc8b's hyper parameters: Current learning rate is 4.108463434675432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 2336][Wall Clock 228.626712653s] Trained 128 records in 0.093953654 seconds. Throughput is 1362.3738 records/second. Loss is 1.3231664. Sequential266afc8b's hyper parameters: Current learning rate is 4.106776180698152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:07 INFO  DistriOptimizer$:408 - [Epoch 5 59008/60000][Iteration 2337][Wall Clock 228.709179138s] Trained 128 records in 0.082466485 seconds. Throughput is 1552.1458 records/second. Loss is 1.3153234. Sequential266afc8b's hyper parameters: Current learning rate is 4.105090311986864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 2338][Wall Clock 228.791974572s] Trained 128 records in 0.082795434 seconds. Throughput is 1545.979 records/second. Loss is 1.327209. Sequential266afc8b's hyper parameters: Current learning rate is 4.103405826836274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59264/60000][Iteration 2339][Wall Clock 228.881130942s] Trained 128 records in 0.08915637 seconds. Throughput is 1435.6798 records/second. Loss is 1.2772869. Sequential266afc8b's hyper parameters: Current learning rate is 4.1017227235438887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 2340][Wall Clock 228.968698299s] Trained 128 records in 0.087567357 seconds. Throughput is 1461.7319 records/second. Loss is 1.3693354. Sequential266afc8b's hyper parameters: Current learning rate is 4.100041000410004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59520/60000][Iteration 2341][Wall Clock 229.05731862s] Trained 128 records in 0.088620321 seconds. Throughput is 1444.364 records/second. Loss is 1.3490201. Sequential266afc8b's hyper parameters: Current learning rate is 4.098360655737705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 2342][Wall Clock 229.147277798s] Trained 128 records in 0.089959178 seconds. Throughput is 1422.8677 records/second. Loss is 1.3738543. Sequential266afc8b's hyper parameters: Current learning rate is 4.0966816878328555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59776/60000][Iteration 2343][Wall Clock 229.243734783s] Trained 128 records in 0.096456985 seconds. Throughput is 1327.0165 records/second. Loss is 1.2572278. Sequential266afc8b's hyper parameters: Current learning rate is 4.0950040950040947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 2344][Wall Clock 229.331303894s] Trained 128 records in 0.087569111 seconds. Throughput is 1461.7026 records/second. Loss is 1.30963. Sequential266afc8b's hyper parameters: Current learning rate is 4.0933278755628325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:408 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 229.420298887s] Trained 128 records in 0.088994993 seconds. Throughput is 1438.2831 records/second. Loss is 1.3695908. Sequential266afc8b's hyper parameters: Current learning rate is 4.09165302782324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:08 INFO  DistriOptimizer$:452 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 229.420298887s] Epoch finished. Wall clock time is 230595.18773 ms
2019-10-15 08:22:08 INFO  DistriOptimizer$:111 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 229.420298887s] Validate model...
2019-10-15 08:22:09 INFO  DistriOptimizer$:178 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 229.420298887s] validate model throughput is 10066.611 records/second
2019-10-15 08:22:09 INFO  DistriOptimizer$:181 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 229.420298887s] Top1Accuracy is Accuracy(correct: 7171, count: 10000, accuracy: 0.7171)
2019-10-15 08:22:09 INFO  DistriOptimizer$:221 - [Wall Clock 230.59518773s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:22:09 INFO  DistriOptimizer$:226 - [Wall Clock 230.59518773s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:22:09 INFO  DistriOptimizer$:408 - [Epoch 6 128/60000][Iteration 2346][Wall Clock 230.689226172s] Trained 128 records in 0.094038442 seconds. Throughput is 1361.1455 records/second. Loss is 1.3386751. Sequential266afc8b's hyper parameters: Current learning rate is 4.0899795501022495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:09 INFO  DistriOptimizer$:408 - [Epoch 6 256/60000][Iteration 2347][Wall Clock 230.772756313s] Trained 128 records in 0.083530141 seconds. Throughput is 1532.381 records/second. Loss is 1.3312793. Sequential266afc8b's hyper parameters: Current learning rate is 4.088307440719542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 384/60000][Iteration 2348][Wall Clock 230.856765256s] Trained 128 records in 0.084008943 seconds. Throughput is 1523.6473 records/second. Loss is 1.3340659. Sequential266afc8b's hyper parameters: Current learning rate is 4.086636697997548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 512/60000][Iteration 2349][Wall Clock 230.941196741s] Trained 128 records in 0.084431485 seconds. Throughput is 1516.0221 records/second. Loss is 1.2899414. Sequential266afc8b's hyper parameters: Current learning rate is 4.084967320261438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 640/60000][Iteration 2350][Wall Clock 231.025103973s] Trained 128 records in 0.083907232 seconds. Throughput is 1525.4943 records/second. Loss is 1.4046888. Sequential266afc8b's hyper parameters: Current learning rate is 4.0832993058391177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 768/60000][Iteration 2351][Wall Clock 231.109910656s] Trained 128 records in 0.084806683 seconds. Throughput is 1509.3151 records/second. Loss is 1.3074534. Sequential266afc8b's hyper parameters: Current learning rate is 4.0816326530612246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 896/60000][Iteration 2352][Wall Clock 231.198706375s] Trained 128 records in 0.088795719 seconds. Throughput is 1441.5109 records/second. Loss is 1.2911837. Sequential266afc8b's hyper parameters: Current learning rate is 4.079967360261118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1024/60000][Iteration 2353][Wall Clock 231.277606852s] Trained 128 records in 0.078900477 seconds. Throughput is 1622.2969 records/second. Loss is 1.3581792. Sequential266afc8b's hyper parameters: Current learning rate is 4.078303425774878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1152/60000][Iteration 2354][Wall Clock 231.365356582s] Trained 128 records in 0.08774973 seconds. Throughput is 1458.694 records/second. Loss is 1.3590721. Sequential266afc8b's hyper parameters: Current learning rate is 4.0766408479412964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1280/60000][Iteration 2355][Wall Clock 231.456824116s] Trained 128 records in 0.091467534 seconds. Throughput is 1399.4036 records/second. Loss is 1.3616594. Sequential266afc8b's hyper parameters: Current learning rate is 4.074979625101875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1408/60000][Iteration 2356][Wall Clock 231.547996472s] Trained 128 records in 0.091172356 seconds. Throughput is 1403.9343 records/second. Loss is 1.3088589. Sequential266afc8b's hyper parameters: Current learning rate is 4.073319755600815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1536/60000][Iteration 2357][Wall Clock 231.634479585s] Trained 128 records in 0.086483113 seconds. Throughput is 1480.0577 records/second. Loss is 1.4118868. Sequential266afc8b's hyper parameters: Current learning rate is 4.0716612377850165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1664/60000][Iteration 2358][Wall Clock 231.723638411s] Trained 128 records in 0.089158826 seconds. Throughput is 1435.6403 records/second. Loss is 1.338563. Sequential266afc8b's hyper parameters: Current learning rate is 4.07000407000407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:10 INFO  DistriOptimizer$:408 - [Epoch 6 1792/60000][Iteration 2359][Wall Clock 231.833427027s] Trained 128 records in 0.109788616 seconds. Throughput is 1165.8767 records/second. Loss is 1.3045175. Sequential266afc8b's hyper parameters: Current learning rate is 4.068348250610252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 1920/60000][Iteration 2360][Wall Clock 231.920189564s] Trained 128 records in 0.086762537 seconds. Throughput is 1475.291 records/second. Loss is 1.2654225. Sequential266afc8b's hyper parameters: Current learning rate is 4.0666937779585197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2048/60000][Iteration 2361][Wall Clock 232.011466351s] Trained 128 records in 0.091276787 seconds. Throughput is 1402.328 records/second. Loss is 1.3534557. Sequential266afc8b's hyper parameters: Current learning rate is 4.065040650406504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2176/60000][Iteration 2362][Wall Clock 232.098183572s] Trained 128 records in 0.086717221 seconds. Throughput is 1476.0621 records/second. Loss is 1.3067122. Sequential266afc8b's hyper parameters: Current learning rate is 4.0633888663145067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2304/60000][Iteration 2363][Wall Clock 232.183430255s] Trained 128 records in 0.085246683 seconds. Throughput is 1501.5247 records/second. Loss is 1.3266202. Sequential266afc8b's hyper parameters: Current learning rate is 4.0617384240454913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2432/60000][Iteration 2364][Wall Clock 232.280199259s] Trained 128 records in 0.096769004 seconds. Throughput is 1322.7375 records/second. Loss is 1.3842734. Sequential266afc8b's hyper parameters: Current learning rate is 4.060089321965084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2560/60000][Iteration 2365][Wall Clock 232.373201233s] Trained 128 records in 0.093001974 seconds. Throughput is 1376.3148 records/second. Loss is 1.3090183. Sequential266afc8b's hyper parameters: Current learning rate is 4.058441558441558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2688/60000][Iteration 2366][Wall Clock 232.463678266s] Trained 128 records in 0.090477033 seconds. Throughput is 1414.7236 records/second. Loss is 1.3255275. Sequential266afc8b's hyper parameters: Current learning rate is 4.0567951318458417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2816/60000][Iteration 2367][Wall Clock 232.562213004s] Trained 128 records in 0.098534738 seconds. Throughput is 1299.0342 records/second. Loss is 1.3546635. Sequential266afc8b's hyper parameters: Current learning rate is 4.0551500405515005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 2944/60000][Iteration 2368][Wall Clock 232.65026898s] Trained 128 records in 0.088055976 seconds. Throughput is 1453.6208 records/second. Loss is 1.4372383. Sequential266afc8b's hyper parameters: Current learning rate is 4.0535062829347385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 3072/60000][Iteration 2369][Wall Clock 232.736158167s] Trained 128 records in 0.085889187 seconds. Throughput is 1490.2924 records/second. Loss is 1.2814344. Sequential266afc8b's hyper parameters: Current learning rate is 4.0518638573743926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:11 INFO  DistriOptimizer$:408 - [Epoch 6 3200/60000][Iteration 2370][Wall Clock 232.825318088s] Trained 128 records in 0.089159921 seconds. Throughput is 1435.6227 records/second. Loss is 1.274792. Sequential266afc8b's hyper parameters: Current learning rate is 4.0502227622519235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 3328/60000][Iteration 2371][Wall Clock 232.916622357s] Trained 128 records in 0.091304269 seconds. Throughput is 1401.9059 records/second. Loss is 1.315486. Sequential266afc8b's hyper parameters: Current learning rate is 4.0485829959514174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 3456/60000][Iteration 2372][Wall Clock 233.00768151s] Trained 128 records in 0.091059153 seconds. Throughput is 1405.6796 records/second. Loss is 1.3350078. Sequential266afc8b's hyper parameters: Current learning rate is 4.046944556859571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 3584/60000][Iteration 2373][Wall Clock 233.09824757s] Trained 128 records in 0.09056606 seconds. Throughput is 1413.333 records/second. Loss is 1.2880547. Sequential266afc8b's hyper parameters: Current learning rate is 4.045307443365696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 3712/60000][Iteration 2374][Wall Clock 233.18802031s] Trained 128 records in 0.08977274 seconds. Throughput is 1425.8226 records/second. Loss is 1.2236489. Sequential266afc8b's hyper parameters: Current learning rate is 4.043671653861706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 3840/60000][Iteration 2375][Wall Clock 233.279823727s] Trained 128 records in 0.091803417 seconds. Throughput is 1394.2836 records/second. Loss is 1.2607341. Sequential266afc8b's hyper parameters: Current learning rate is 4.042037186742118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 3968/60000][Iteration 2376][Wall Clock 233.367674061s] Trained 128 records in 0.087850334 seconds. Throughput is 1457.0236 records/second. Loss is 1.388388. Sequential266afc8b's hyper parameters: Current learning rate is 4.0404040404040404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 4096/60000][Iteration 2377][Wall Clock 233.456294682s] Trained 128 records in 0.088620621 seconds. Throughput is 1444.3591 records/second. Loss is 1.4031543. Sequential266afc8b's hyper parameters: Current learning rate is 4.0387722132471726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 4224/60000][Iteration 2378][Wall Clock 233.544947995s] Trained 128 records in 0.088653313 seconds. Throughput is 1443.8265 records/second. Loss is 1.3101887. Sequential266afc8b's hyper parameters: Current learning rate is 4.0371417036737993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 4352/60000][Iteration 2379][Wall Clock 233.633736159s] Trained 128 records in 0.088788164 seconds. Throughput is 1441.6335 records/second. Loss is 1.3460213. Sequential266afc8b's hyper parameters: Current learning rate is 4.035512510088781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 4480/60000][Iteration 2380][Wall Clock 233.723431765s] Trained 128 records in 0.089695606 seconds. Throughput is 1427.0488 records/second. Loss is 1.3505869. Sequential266afc8b's hyper parameters: Current learning rate is 4.0338846308995567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:12 INFO  DistriOptimizer$:408 - [Epoch 6 4608/60000][Iteration 2381][Wall Clock 233.812100145s] Trained 128 records in 0.08866838 seconds. Throughput is 1443.581 records/second. Loss is 1.4042728. Sequential266afc8b's hyper parameters: Current learning rate is 4.032258064516129E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 4736/60000][Iteration 2382][Wall Clock 233.901479051s] Trained 128 records in 0.089378906 seconds. Throughput is 1432.1052 records/second. Loss is 1.2844098. Sequential266afc8b's hyper parameters: Current learning rate is 4.0306328093510683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 4864/60000][Iteration 2383][Wall Clock 233.989911116s] Trained 128 records in 0.088432065 seconds. Throughput is 1447.4387 records/second. Loss is 1.345764. Sequential266afc8b's hyper parameters: Current learning rate is 4.0290088638195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 4992/60000][Iteration 2384][Wall Clock 234.084022563s] Trained 128 records in 0.094111447 seconds. Throughput is 1360.0896 records/second. Loss is 1.2811424. Sequential266afc8b's hyper parameters: Current learning rate is 4.0273862263391055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5120/60000][Iteration 2385][Wall Clock 234.185793925s] Trained 128 records in 0.101771362 seconds. Throughput is 1257.7212 records/second. Loss is 1.3123635. Sequential266afc8b's hyper parameters: Current learning rate is 4.0257648953301127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5248/60000][Iteration 2386][Wall Clock 234.281250577s] Trained 128 records in 0.095456652 seconds. Throughput is 1340.9227 records/second. Loss is 1.3845671. Sequential266afc8b's hyper parameters: Current learning rate is 4.0241448692152917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5376/60000][Iteration 2387][Wall Clock 234.369409489s] Trained 128 records in 0.088158912 seconds. Throughput is 1451.9236 records/second. Loss is 1.210509. Sequential266afc8b's hyper parameters: Current learning rate is 4.022526146419952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5504/60000][Iteration 2388][Wall Clock 234.457930808s] Trained 128 records in 0.088521319 seconds. Throughput is 1445.9794 records/second. Loss is 1.3311666. Sequential266afc8b's hyper parameters: Current learning rate is 4.020908725371934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5632/60000][Iteration 2389][Wall Clock 234.548176902s] Trained 128 records in 0.090246094 seconds. Throughput is 1418.3439 records/second. Loss is 1.2972796. Sequential266afc8b's hyper parameters: Current learning rate is 4.019292604501608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5760/60000][Iteration 2390][Wall Clock 234.640150341s] Trained 128 records in 0.091973439 seconds. Throughput is 1391.7062 records/second. Loss is 1.2777197. Sequential266afc8b's hyper parameters: Current learning rate is 4.017677782241864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:13 INFO  DistriOptimizer$:408 - [Epoch 6 5888/60000][Iteration 2391][Wall Clock 234.73274836s] Trained 128 records in 0.092598019 seconds. Throughput is 1382.319 records/second. Loss is 1.2732648. Sequential266afc8b's hyper parameters: Current learning rate is 4.016064257028112E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6016/60000][Iteration 2392][Wall Clock 234.82251894s] Trained 128 records in 0.08977058 seconds. Throughput is 1425.8569 records/second. Loss is 1.4253025. Sequential266afc8b's hyper parameters: Current learning rate is 4.014452027298274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6144/60000][Iteration 2393][Wall Clock 234.914689973s] Trained 128 records in 0.092171033 seconds. Throughput is 1388.7227 records/second. Loss is 1.4256738. Sequential266afc8b's hyper parameters: Current learning rate is 4.012841091492777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6272/60000][Iteration 2394][Wall Clock 234.998789415s] Trained 128 records in 0.084099442 seconds. Throughput is 1522.0077 records/second. Loss is 1.3286908. Sequential266afc8b's hyper parameters: Current learning rate is 4.011231448054553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6400/60000][Iteration 2395][Wall Clock 235.085680144s] Trained 128 records in 0.086890729 seconds. Throughput is 1473.1146 records/second. Loss is 1.387257. Sequential266afc8b's hyper parameters: Current learning rate is 4.0096230954290296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6528/60000][Iteration 2396][Wall Clock 235.177265503s] Trained 128 records in 0.091585359 seconds. Throughput is 1397.6033 records/second. Loss is 1.3782864. Sequential266afc8b's hyper parameters: Current learning rate is 4.008016032064128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6656/60000][Iteration 2397][Wall Clock 235.269069304s] Trained 128 records in 0.091803801 seconds. Throughput is 1394.2777 records/second. Loss is 1.3249047. Sequential266afc8b's hyper parameters: Current learning rate is 4.0064102564102563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6784/60000][Iteration 2398][Wall Clock 235.359013685s] Trained 128 records in 0.089944381 seconds. Throughput is 1423.1017 records/second. Loss is 1.321201. Sequential266afc8b's hyper parameters: Current learning rate is 4.004805766920305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 6912/60000][Iteration 2399][Wall Clock 235.4459352s] Trained 128 records in 0.086921515 seconds. Throughput is 1472.5929 records/second. Loss is 1.3064563. Sequential266afc8b's hyper parameters: Current learning rate is 4.00320256204964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 7040/60000][Iteration 2400][Wall Clock 235.537307462s] Trained 128 records in 0.091372262 seconds. Throughput is 1400.8628 records/second. Loss is 1.4135237. Sequential266afc8b's hyper parameters: Current learning rate is 4.001600640256102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 7168/60000][Iteration 2401][Wall Clock 235.625505003s] Trained 128 records in 0.088197541 seconds. Throughput is 1451.2876 records/second. Loss is 1.2490845. Sequential266afc8b's hyper parameters: Current learning rate is 4.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 7296/60000][Iteration 2402][Wall Clock 235.715975359s] Trained 128 records in 0.090470356 seconds. Throughput is 1414.828 records/second. Loss is 1.287073. Sequential266afc8b's hyper parameters: Current learning rate is 3.9984006397441024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:14 INFO  DistriOptimizer$:408 - [Epoch 6 7424/60000][Iteration 2403][Wall Clock 235.805969973s] Trained 128 records in 0.089994614 seconds. Throughput is 1422.3073 records/second. Loss is 1.2779787. Sequential266afc8b's hyper parameters: Current learning rate is 3.996802557953637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 7552/60000][Iteration 2404][Wall Clock 235.893192492s] Trained 128 records in 0.087222519 seconds. Throughput is 1467.511 records/second. Loss is 1.3605714. Sequential266afc8b's hyper parameters: Current learning rate is 3.9952057530962844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 7680/60000][Iteration 2405][Wall Clock 235.98120476s] Trained 128 records in 0.088012268 seconds. Throughput is 1454.3427 records/second. Loss is 1.2722952. Sequential266afc8b's hyper parameters: Current learning rate is 3.993610223642173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 7808/60000][Iteration 2406][Wall Clock 236.06994552s] Trained 128 records in 0.08874076 seconds. Throughput is 1442.4037 records/second. Loss is 1.1742558. Sequential266afc8b's hyper parameters: Current learning rate is 3.992015968063872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 7936/60000][Iteration 2407][Wall Clock 236.158946233s] Trained 128 records in 0.089000713 seconds. Throughput is 1438.1908 records/second. Loss is 1.3380691. Sequential266afc8b's hyper parameters: Current learning rate is 3.9904229848363923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8064/60000][Iteration 2408][Wall Clock 236.248897282s] Trained 128 records in 0.089951049 seconds. Throughput is 1422.9962 records/second. Loss is 1.4411112. Sequential266afc8b's hyper parameters: Current learning rate is 3.988831272437176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8192/60000][Iteration 2409][Wall Clock 236.336628618s] Trained 128 records in 0.087731336 seconds. Throughput is 1458.9998 records/second. Loss is 1.3143338. Sequential266afc8b's hyper parameters: Current learning rate is 3.9872408293460925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8320/60000][Iteration 2410][Wall Clock 236.427178691s] Trained 128 records in 0.090550073 seconds. Throughput is 1413.5825 records/second. Loss is 1.3239666. Sequential266afc8b's hyper parameters: Current learning rate is 3.9856516540454366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8448/60000][Iteration 2411][Wall Clock 236.516708206s] Trained 128 records in 0.089529515 seconds. Throughput is 1429.6962 records/second. Loss is 1.2754968. Sequential266afc8b's hyper parameters: Current learning rate is 3.98406374501992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8576/60000][Iteration 2412][Wall Clock 236.602049498s] Trained 128 records in 0.085341292 seconds. Throughput is 1499.8601 records/second. Loss is 1.3101226. Sequential266afc8b's hyper parameters: Current learning rate is 3.9824771007566706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8704/60000][Iteration 2413][Wall Clock 236.691082372s] Trained 128 records in 0.089032874 seconds. Throughput is 1437.6713 records/second. Loss is 1.2573481. Sequential266afc8b's hyper parameters: Current learning rate is 3.9808917197452226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:15 INFO  DistriOptimizer$:408 - [Epoch 6 8832/60000][Iteration 2414][Wall Clock 236.781055355s] Trained 128 records in 0.089972983 seconds. Throughput is 1422.6493 records/second. Loss is 1.2393923. Sequential266afc8b's hyper parameters: Current learning rate is 3.9793076004775174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 8960/60000][Iteration 2415][Wall Clock 236.870797891s] Trained 128 records in 0.089742536 seconds. Throughput is 1426.3025 records/second. Loss is 1.333727. Sequential266afc8b's hyper parameters: Current learning rate is 3.977724741447892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9088/60000][Iteration 2416][Wall Clock 236.962041113s] Trained 128 records in 0.091243222 seconds. Throughput is 1402.8439 records/second. Loss is 1.2993466. Sequential266afc8b's hyper parameters: Current learning rate is 3.976143141153081E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9216/60000][Iteration 2417][Wall Clock 237.051707889s] Trained 128 records in 0.089666776 seconds. Throughput is 1427.5076 records/second. Loss is 1.2696136. Sequential266afc8b's hyper parameters: Current learning rate is 3.97456279809221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9344/60000][Iteration 2418][Wall Clock 237.142012016s] Trained 128 records in 0.090304127 seconds. Throughput is 1417.4324 records/second. Loss is 1.37591. Sequential266afc8b's hyper parameters: Current learning rate is 3.972983710766786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9472/60000][Iteration 2419][Wall Clock 237.232800263s] Trained 128 records in 0.090788247 seconds. Throughput is 1409.8741 records/second. Loss is 1.4015713. Sequential266afc8b's hyper parameters: Current learning rate is 3.9714058776806993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9600/60000][Iteration 2420][Wall Clock 237.322031522s] Trained 128 records in 0.089231259 seconds. Throughput is 1434.4749 records/second. Loss is 1.2946813. Sequential266afc8b's hyper parameters: Current learning rate is 3.969829297340214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9728/60000][Iteration 2421][Wall Clock 237.4066504s] Trained 128 records in 0.084618878 seconds. Throughput is 1512.6648 records/second. Loss is 1.2275835. Sequential266afc8b's hyper parameters: Current learning rate is 3.968253968253968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9856/60000][Iteration 2422][Wall Clock 237.493180052s] Trained 128 records in 0.086529652 seconds. Throughput is 1479.2617 records/second. Loss is 1.3255537. Sequential266afc8b's hyper parameters: Current learning rate is 3.966679888932963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 9984/60000][Iteration 2423][Wall Clock 237.582526943s] Trained 128 records in 0.089346891 seconds. Throughput is 1432.6184 records/second. Loss is 1.3409436. Sequential266afc8b's hyper parameters: Current learning rate is 3.965107057890563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 10112/60000][Iteration 2424][Wall Clock 237.668954323s] Trained 128 records in 0.08642738 seconds. Throughput is 1481.0121 records/second. Loss is 1.4422942. Sequential266afc8b's hyper parameters: Current learning rate is 3.9635354736424893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:16 INFO  DistriOptimizer$:408 - [Epoch 6 10240/60000][Iteration 2425][Wall Clock 237.759096549s] Trained 128 records in 0.090142226 seconds. Throughput is 1419.9783 records/second. Loss is 1.3102621. Sequential266afc8b's hyper parameters: Current learning rate is 3.961965134706814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 10368/60000][Iteration 2426][Wall Clock 237.846716471s] Trained 128 records in 0.087619922 seconds. Throughput is 1460.855 records/second. Loss is 1.242956. Sequential266afc8b's hyper parameters: Current learning rate is 3.9603960396039607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 10496/60000][Iteration 2427][Wall Clock 237.940160612s] Trained 128 records in 0.093444141 seconds. Throughput is 1369.8024 records/second. Loss is 1.351383. Sequential266afc8b's hyper parameters: Current learning rate is 3.95882818685669E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 10624/60000][Iteration 2428][Wall Clock 238.030310413s] Trained 128 records in 0.090149801 seconds. Throughput is 1419.859 records/second. Loss is 1.3291494. Sequential266afc8b's hyper parameters: Current learning rate is 3.957261574990107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 10752/60000][Iteration 2429][Wall Clock 238.122248803s] Trained 128 records in 0.09193839 seconds. Throughput is 1392.2367 records/second. Loss is 1.3312227. Sequential266afc8b's hyper parameters: Current learning rate is 3.9556962025316455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 10880/60000][Iteration 2430][Wall Clock 238.211691297s] Trained 128 records in 0.089442494 seconds. Throughput is 1431.0872 records/second. Loss is 1.3027894. Sequential266afc8b's hyper parameters: Current learning rate is 3.9541320680110717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 11008/60000][Iteration 2431][Wall Clock 238.299052026s] Trained 128 records in 0.087360729 seconds. Throughput is 1465.1892 records/second. Loss is 1.2481153. Sequential266afc8b's hyper parameters: Current learning rate is 3.952569169960474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 11136/60000][Iteration 2432][Wall Clock 238.386838745s] Trained 128 records in 0.087786719 seconds. Throughput is 1458.0793 records/second. Loss is 1.3049494. Sequential266afc8b's hyper parameters: Current learning rate is 3.951007506914263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 11264/60000][Iteration 2433][Wall Clock 238.474523145s] Trained 128 records in 0.0876844 seconds. Throughput is 1459.7808 records/second. Loss is 1.3273807. Sequential266afc8b's hyper parameters: Current learning rate is 3.9494470774091627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 11392/60000][Iteration 2434][Wall Clock 238.562244234s] Trained 128 records in 0.087721089 seconds. Throughput is 1459.1703 records/second. Loss is 1.2814242. Sequential266afc8b's hyper parameters: Current learning rate is 3.9478878799842083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 11520/60000][Iteration 2435][Wall Clock 238.652005826s] Trained 128 records in 0.089761592 seconds. Throughput is 1425.9996 records/second. Loss is 1.2575026. Sequential266afc8b's hyper parameters: Current learning rate is 3.946329913180742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:17 INFO  DistriOptimizer$:408 - [Epoch 6 11648/60000][Iteration 2436][Wall Clock 238.751704964s] Trained 128 records in 0.099699138 seconds. Throughput is 1283.8627 records/second. Loss is 1.3897804. Sequential266afc8b's hyper parameters: Current learning rate is 3.944773175542406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 11776/60000][Iteration 2437][Wall Clock 238.83722685s] Trained 128 records in 0.085521886 seconds. Throughput is 1496.693 records/second. Loss is 1.3255023. Sequential266afc8b's hyper parameters: Current learning rate is 3.9432176656151424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 11904/60000][Iteration 2438][Wall Clock 238.921278553s] Trained 128 records in 0.084051703 seconds. Throughput is 1522.8721 records/second. Loss is 1.2905153. Sequential266afc8b's hyper parameters: Current learning rate is 3.9416633819471815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12032/60000][Iteration 2439][Wall Clock 239.010849467s] Trained 128 records in 0.089570914 seconds. Throughput is 1429.0353 records/second. Loss is 1.3694535. Sequential266afc8b's hyper parameters: Current learning rate is 3.940110323089047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12160/60000][Iteration 2440][Wall Clock 239.108415519s] Trained 128 records in 0.097566052 seconds. Throughput is 1311.9318 records/second. Loss is 1.3725028. Sequential266afc8b's hyper parameters: Current learning rate is 3.9385584875935406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12288/60000][Iteration 2441][Wall Clock 239.195082313s] Trained 128 records in 0.086666794 seconds. Throughput is 1476.9209 records/second. Loss is 1.3529768. Sequential266afc8b's hyper parameters: Current learning rate is 3.937007874015748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12416/60000][Iteration 2442][Wall Clock 239.283577067s] Trained 128 records in 0.088494754 seconds. Throughput is 1446.4135 records/second. Loss is 1.2421011. Sequential266afc8b's hyper parameters: Current learning rate is 3.935458480913026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12544/60000][Iteration 2443][Wall Clock 239.368029969s] Trained 128 records in 0.084452902 seconds. Throughput is 1515.6376 records/second. Loss is 1.2950143. Sequential266afc8b's hyper parameters: Current learning rate is 3.933910306845004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12672/60000][Iteration 2444][Wall Clock 239.468102914s] Trained 128 records in 0.100072945 seconds. Throughput is 1279.067 records/second. Loss is 1.2720699. Sequential266afc8b's hyper parameters: Current learning rate is 3.932363350373575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12800/60000][Iteration 2445][Wall Clock 239.554875219s] Trained 128 records in 0.086772305 seconds. Throughput is 1475.125 records/second. Loss is 1.3035678. Sequential266afc8b's hyper parameters: Current learning rate is 3.930817610062893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 12928/60000][Iteration 2446][Wall Clock 239.636693909s] Trained 128 records in 0.08181869 seconds. Throughput is 1564.4347 records/second. Loss is 1.3616465. Sequential266afc8b's hyper parameters: Current learning rate is 3.9292730844793717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:18 INFO  DistriOptimizer$:408 - [Epoch 6 13056/60000][Iteration 2447][Wall Clock 239.724676415s] Trained 128 records in 0.087982506 seconds. Throughput is 1454.8347 records/second. Loss is 1.3424273. Sequential266afc8b's hyper parameters: Current learning rate is 3.927729772191673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13184/60000][Iteration 2448][Wall Clock 239.811824521s] Trained 128 records in 0.087148106 seconds. Throughput is 1468.7639 records/second. Loss is 1.2853974. Sequential266afc8b's hyper parameters: Current learning rate is 3.9261876717707107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13312/60000][Iteration 2449][Wall Clock 239.898428504s] Trained 128 records in 0.086603983 seconds. Throughput is 1477.9921 records/second. Loss is 1.2932049. Sequential266afc8b's hyper parameters: Current learning rate is 3.924646781789639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13440/60000][Iteration 2450][Wall Clock 239.988886504s] Trained 128 records in 0.090458 seconds. Throughput is 1415.0214 records/second. Loss is 1.3019623. Sequential266afc8b's hyper parameters: Current learning rate is 3.9231071008238524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13568/60000][Iteration 2451][Wall Clock 240.077052483s] Trained 128 records in 0.088165979 seconds. Throughput is 1451.8073 records/second. Loss is 1.2871382. Sequential266afc8b's hyper parameters: Current learning rate is 3.92156862745098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13696/60000][Iteration 2452][Wall Clock 240.165235227s] Trained 128 records in 0.088182744 seconds. Throughput is 1451.5311 records/second. Loss is 1.312716. Sequential266afc8b's hyper parameters: Current learning rate is 3.920031360250882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13824/60000][Iteration 2453][Wall Clock 240.252875731s] Trained 128 records in 0.087640504 seconds. Throughput is 1460.512 records/second. Loss is 1.3411765. Sequential266afc8b's hyper parameters: Current learning rate is 3.918495297805643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 13952/60000][Iteration 2454][Wall Clock 240.33962695s] Trained 128 records in 0.086751219 seconds. Throughput is 1475.4835 records/second. Loss is 1.2905356. Sequential266afc8b's hyper parameters: Current learning rate is 3.916960438699569E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 14080/60000][Iteration 2455][Wall Clock 240.428633626s] Trained 128 records in 0.089006676 seconds. Throughput is 1438.0944 records/second. Loss is 1.3883597. Sequential266afc8b's hyper parameters: Current learning rate is 3.9154267815191856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 14208/60000][Iteration 2456][Wall Clock 240.514022927s] Trained 128 records in 0.085389301 seconds. Throughput is 1499.0168 records/second. Loss is 1.3140962. Sequential266afc8b's hyper parameters: Current learning rate is 3.913894324853229E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 14336/60000][Iteration 2457][Wall Clock 240.60244954s] Trained 128 records in 0.088426613 seconds. Throughput is 1447.5281 records/second. Loss is 1.2050264. Sequential266afc8b's hyper parameters: Current learning rate is 3.9123630672926443E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 14464/60000][Iteration 2458][Wall Clock 240.692937651s] Trained 128 records in 0.090488111 seconds. Throughput is 1414.5504 records/second. Loss is 1.355024. Sequential266afc8b's hyper parameters: Current learning rate is 3.910833007430583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:19 INFO  DistriOptimizer$:408 - [Epoch 6 14592/60000][Iteration 2459][Wall Clock 240.780759614s] Trained 128 records in 0.087821963 seconds. Throughput is 1457.4943 records/second. Loss is 1.2743348. Sequential266afc8b's hyper parameters: Current learning rate is 3.9093041438623924E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 14720/60000][Iteration 2460][Wall Clock 240.867839019s] Trained 128 records in 0.087079405 seconds. Throughput is 1469.9227 records/second. Loss is 1.3851192. Sequential266afc8b's hyper parameters: Current learning rate is 3.9077764751856197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 14848/60000][Iteration 2461][Wall Clock 240.955568729s] Trained 128 records in 0.08772971 seconds. Throughput is 1459.0269 records/second. Loss is 1.2237918. Sequential266afc8b's hyper parameters: Current learning rate is 3.9062499999999997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 14976/60000][Iteration 2462][Wall Clock 241.04955206s] Trained 128 records in 0.093983331 seconds. Throughput is 1361.9436 records/second. Loss is 1.3324671. Sequential266afc8b's hyper parameters: Current learning rate is 3.904724716907458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15104/60000][Iteration 2463][Wall Clock 241.137055386s] Trained 128 records in 0.087503326 seconds. Throughput is 1462.8015 records/second. Loss is 1.2811685. Sequential266afc8b's hyper parameters: Current learning rate is 3.9032006245121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15232/60000][Iteration 2464][Wall Clock 241.223345328s] Trained 128 records in 0.086289942 seconds. Throughput is 1483.371 records/second. Loss is 1.3245316. Sequential266afc8b's hyper parameters: Current learning rate is 3.901677721420211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15360/60000][Iteration 2465][Wall Clock 241.316847504s] Trained 128 records in 0.093502176 seconds. Throughput is 1368.952 records/second. Loss is 1.3567845. Sequential266afc8b's hyper parameters: Current learning rate is 3.90015600624025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15488/60000][Iteration 2466][Wall Clock 241.404906503s] Trained 128 records in 0.088058999 seconds. Throughput is 1453.5709 records/second. Loss is 1.3890979. Sequential266afc8b's hyper parameters: Current learning rate is 3.898635477582846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15616/60000][Iteration 2467][Wall Clock 241.492333085s] Trained 128 records in 0.087426582 seconds. Throughput is 1464.0856 records/second. Loss is 1.2964427. Sequential266afc8b's hyper parameters: Current learning rate is 3.897116134060795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15744/60000][Iteration 2468][Wall Clock 241.578261275s] Trained 128 records in 0.08592819 seconds. Throughput is 1489.616 records/second. Loss is 1.3262789. Sequential266afc8b's hyper parameters: Current learning rate is 3.8955979742890534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 15872/60000][Iteration 2469][Wall Clock 241.666934051s] Trained 128 records in 0.088672776 seconds. Throughput is 1443.5095 records/second. Loss is 1.3672692. Sequential266afc8b's hyper parameters: Current learning rate is 3.894080996884735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:20 INFO  DistriOptimizer$:408 - [Epoch 6 16000/60000][Iteration 2470][Wall Clock 241.764744417s] Trained 128 records in 0.097810366 seconds. Throughput is 1308.6548 records/second. Loss is 1.2344031. Sequential266afc8b's hyper parameters: Current learning rate is 3.8925652004671076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16128/60000][Iteration 2471][Wall Clock 241.848471099s] Trained 128 records in 0.083726682 seconds. Throughput is 1528.7838 records/second. Loss is 1.2855026. Sequential266afc8b's hyper parameters: Current learning rate is 3.891050583657588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16256/60000][Iteration 2472][Wall Clock 241.931423821s] Trained 128 records in 0.082952722 seconds. Throughput is 1543.0476 records/second. Loss is 1.2757843. Sequential266afc8b's hyper parameters: Current learning rate is 3.8895371450797355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16384/60000][Iteration 2473][Wall Clock 242.021661996s] Trained 128 records in 0.090238175 seconds. Throughput is 1418.4684 records/second. Loss is 1.2969882. Sequential266afc8b's hyper parameters: Current learning rate is 3.8880248833592535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16512/60000][Iteration 2474][Wall Clock 242.11084239s] Trained 128 records in 0.089180394 seconds. Throughput is 1435.2931 records/second. Loss is 1.2758894. Sequential266afc8b's hyper parameters: Current learning rate is 3.88651379712398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16640/60000][Iteration 2475][Wall Clock 242.200604515s] Trained 128 records in 0.089762125 seconds. Throughput is 1425.9912 records/second. Loss is 1.3222778. Sequential266afc8b's hyper parameters: Current learning rate is 3.885003885003885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16768/60000][Iteration 2476][Wall Clock 242.288211102s] Trained 128 records in 0.087606587 seconds. Throughput is 1461.0774 records/second. Loss is 1.2830826. Sequential266afc8b's hyper parameters: Current learning rate is 3.883495145631068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 16896/60000][Iteration 2477][Wall Clock 242.381037604s] Trained 128 records in 0.092826502 seconds. Throughput is 1378.9166 records/second. Loss is 1.3393568. Sequential266afc8b's hyper parameters: Current learning rate is 3.8819875776397513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 17024/60000][Iteration 2478][Wall Clock 242.470304842s] Trained 128 records in 0.089267238 seconds. Throughput is 1433.8967 records/second. Loss is 1.2993522. Sequential266afc8b's hyper parameters: Current learning rate is 3.880481179666279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 17152/60000][Iteration 2479][Wall Clock 242.560627143s] Trained 128 records in 0.090322301 seconds. Throughput is 1417.1472 records/second. Loss is 1.2488327. Sequential266afc8b's hyper parameters: Current learning rate is 3.878975950349108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 17280/60000][Iteration 2480][Wall Clock 242.649660964s] Trained 128 records in 0.089033821 seconds. Throughput is 1437.6559 records/second. Loss is 1.2573545. Sequential266afc8b's hyper parameters: Current learning rate is 3.87747188832881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:21 INFO  DistriOptimizer$:408 - [Epoch 6 17408/60000][Iteration 2481][Wall Clock 242.739688544s] Trained 128 records in 0.09002758 seconds. Throughput is 1421.7865 records/second. Loss is 1.2341541. Sequential266afc8b's hyper parameters: Current learning rate is 3.875968992248062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 17536/60000][Iteration 2482][Wall Clock 242.829866473s] Trained 128 records in 0.090177929 seconds. Throughput is 1419.416 records/second. Loss is 1.3331314. Sequential266afc8b's hyper parameters: Current learning rate is 3.874467260751646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 17664/60000][Iteration 2483][Wall Clock 242.915439123s] Trained 128 records in 0.08557265 seconds. Throughput is 1495.8049 records/second. Loss is 1.2666647. Sequential266afc8b's hyper parameters: Current learning rate is 3.872966692486445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 17792/60000][Iteration 2484][Wall Clock 243.005322211s] Trained 128 records in 0.089883088 seconds. Throughput is 1424.0721 records/second. Loss is 1.3368399. Sequential266afc8b's hyper parameters: Current learning rate is 3.8714672861014324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 17920/60000][Iteration 2485][Wall Clock 243.09191771s] Trained 128 records in 0.086595499 seconds. Throughput is 1478.1368 records/second. Loss is 1.3149225. Sequential266afc8b's hyper parameters: Current learning rate is 3.869969040247678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18048/60000][Iteration 2486][Wall Clock 243.177092327s] Trained 128 records in 0.085174617 seconds. Throughput is 1502.795 records/second. Loss is 1.277151. Sequential266afc8b's hyper parameters: Current learning rate is 3.8684719535783365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18176/60000][Iteration 2487][Wall Clock 243.264699043s] Trained 128 records in 0.087606716 seconds. Throughput is 1461.0752 records/second. Loss is 1.3818963. Sequential266afc8b's hyper parameters: Current learning rate is 3.866976024748647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18304/60000][Iteration 2488][Wall Clock 243.36353926s] Trained 128 records in 0.098840217 seconds. Throughput is 1295.0194 records/second. Loss is 1.3561254. Sequential266afc8b's hyper parameters: Current learning rate is 3.8654812524159255E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18432/60000][Iteration 2489][Wall Clock 243.448144399s] Trained 128 records in 0.084605139 seconds. Throughput is 1512.9104 records/second. Loss is 1.3013023. Sequential266afc8b's hyper parameters: Current learning rate is 3.8639876352395677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18560/60000][Iteration 2490][Wall Clock 243.539280874s] Trained 128 records in 0.091136475 seconds. Throughput is 1404.487 records/second. Loss is 1.2748057. Sequential266afc8b's hyper parameters: Current learning rate is 3.862495171881035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18688/60000][Iteration 2491][Wall Clock 243.626942725s] Trained 128 records in 0.087661851 seconds. Throughput is 1460.1564 records/second. Loss is 1.2966784. Sequential266afc8b's hyper parameters: Current learning rate is 3.861003861003861E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:22 INFO  DistriOptimizer$:408 - [Epoch 6 18816/60000][Iteration 2492][Wall Clock 243.716748397s] Trained 128 records in 0.089805672 seconds. Throughput is 1425.2998 records/second. Loss is 1.3291719. Sequential266afc8b's hyper parameters: Current learning rate is 3.8595137012736397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 18944/60000][Iteration 2493][Wall Clock 243.809107873s] Trained 128 records in 0.092359476 seconds. Throughput is 1385.8892 records/second. Loss is 1.3425232. Sequential266afc8b's hyper parameters: Current learning rate is 3.8580246913580245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19072/60000][Iteration 2494][Wall Clock 243.900716887s] Trained 128 records in 0.091609014 seconds. Throughput is 1397.2424 records/second. Loss is 1.2710966. Sequential266afc8b's hyper parameters: Current learning rate is 3.856536829926726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19200/60000][Iteration 2495][Wall Clock 243.992369625s] Trained 128 records in 0.091652738 seconds. Throughput is 1396.5759 records/second. Loss is 1.2987238. Sequential266afc8b's hyper parameters: Current learning rate is 3.8550501156515033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19328/60000][Iteration 2496][Wall Clock 244.091500094s] Trained 128 records in 0.099130469 seconds. Throughput is 1291.2277 records/second. Loss is 1.2774235. Sequential266afc8b's hyper parameters: Current learning rate is 3.853564547206166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19456/60000][Iteration 2497][Wall Clock 244.180236841s] Trained 128 records in 0.088736747 seconds. Throughput is 1442.4689 records/second. Loss is 1.3750972. Sequential266afc8b's hyper parameters: Current learning rate is 3.852080123266564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19584/60000][Iteration 2498][Wall Clock 244.270445101s] Trained 128 records in 0.09020826 seconds. Throughput is 1418.9387 records/second. Loss is 1.2887987. Sequential266afc8b's hyper parameters: Current learning rate is 3.8505968425105896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19712/60000][Iteration 2499][Wall Clock 244.358820191s] Trained 128 records in 0.08837509 seconds. Throughput is 1448.372 records/second. Loss is 1.3178024. Sequential266afc8b's hyper parameters: Current learning rate is 3.8491147036181676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19840/60000][Iteration 2500][Wall Clock 244.448581161s] Trained 128 records in 0.08976097 seconds. Throughput is 1426.0096 records/second. Loss is 1.2843431. Sequential266afc8b's hyper parameters: Current learning rate is 3.847633705271258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 19968/60000][Iteration 2501][Wall Clock 244.536575464s] Trained 128 records in 0.087994303 seconds. Throughput is 1454.6396 records/second. Loss is 1.35586. Sequential266afc8b's hyper parameters: Current learning rate is 3.846153846153846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 20096/60000][Iteration 2502][Wall Clock 244.623287431s] Trained 128 records in 0.086711967 seconds. Throughput is 1476.1515 records/second. Loss is 1.241831. Sequential266afc8b's hyper parameters: Current learning rate is 3.8446751249519417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:23 INFO  DistriOptimizer$:408 - [Epoch 6 20224/60000][Iteration 2503][Wall Clock 244.712014795s] Trained 128 records in 0.088727364 seconds. Throughput is 1442.6215 records/second. Loss is 1.2899592. Sequential266afc8b's hyper parameters: Current learning rate is 3.843197540353574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 20352/60000][Iteration 2504][Wall Clock 244.798300438s] Trained 128 records in 0.086285643 seconds. Throughput is 1483.445 records/second. Loss is 1.3213917. Sequential266afc8b's hyper parameters: Current learning rate is 3.84172109104879E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 20480/60000][Iteration 2505][Wall Clock 244.885547576s] Trained 128 records in 0.087247138 seconds. Throughput is 1467.0968 records/second. Loss is 1.3141859. Sequential266afc8b's hyper parameters: Current learning rate is 3.8402457757296467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 20608/60000][Iteration 2506][Wall Clock 244.974937715s] Trained 128 records in 0.089390139 seconds. Throughput is 1431.9253 records/second. Loss is 1.3022481. Sequential266afc8b's hyper parameters: Current learning rate is 3.8387715930902113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 20736/60000][Iteration 2507][Wall Clock 245.064764038s] Trained 128 records in 0.089826323 seconds. Throughput is 1424.972 records/second. Loss is 1.2651485. Sequential266afc8b's hyper parameters: Current learning rate is 3.837298541826554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 20864/60000][Iteration 2508][Wall Clock 245.153623854s] Trained 128 records in 0.088859816 seconds. Throughput is 1440.4711 records/second. Loss is 1.225693. Sequential266afc8b's hyper parameters: Current learning rate is 3.835826620636747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 20992/60000][Iteration 2509][Wall Clock 245.244761722s] Trained 128 records in 0.091137868 seconds. Throughput is 1404.4656 records/second. Loss is 1.3690351. Sequential266afc8b's hyper parameters: Current learning rate is 3.8343558282208584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 21120/60000][Iteration 2510][Wall Clock 245.337416379s] Trained 128 records in 0.092654657 seconds. Throughput is 1381.474 records/second. Loss is 1.3145424. Sequential266afc8b's hyper parameters: Current learning rate is 3.832886163280951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 21248/60000][Iteration 2511][Wall Clock 245.429302752s] Trained 128 records in 0.091886373 seconds. Throughput is 1393.0249 records/second. Loss is 1.2700919. Sequential266afc8b's hyper parameters: Current learning rate is 3.831417624521073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 21376/60000][Iteration 2512][Wall Clock 245.517998128s] Trained 128 records in 0.088695376 seconds. Throughput is 1443.1417 records/second. Loss is 1.3094473. Sequential266afc8b's hyper parameters: Current learning rate is 3.8299502106472615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 21504/60000][Iteration 2513][Wall Clock 245.617257256s] Trained 128 records in 0.099259128 seconds. Throughput is 1289.554 records/second. Loss is 1.3957549. Sequential266afc8b's hyper parameters: Current learning rate is 3.8284839203675346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:24 INFO  DistriOptimizer$:408 - [Epoch 6 21632/60000][Iteration 2514][Wall Clock 245.700360733s] Trained 128 records in 0.083103477 seconds. Throughput is 1540.2484 records/second. Loss is 1.3898125. Sequential266afc8b's hyper parameters: Current learning rate is 3.827018752391887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 21760/60000][Iteration 2515][Wall Clock 245.781825263s] Trained 128 records in 0.08146453 seconds. Throughput is 1571.236 records/second. Loss is 1.2837708. Sequential266afc8b's hyper parameters: Current learning rate is 3.8255547054322876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 21888/60000][Iteration 2516][Wall Clock 245.869147731s] Trained 128 records in 0.087322468 seconds. Throughput is 1465.8313 records/second. Loss is 1.2913488. Sequential266afc8b's hyper parameters: Current learning rate is 3.824091778202677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22016/60000][Iteration 2517][Wall Clock 245.956081378s] Trained 128 records in 0.086933647 seconds. Throughput is 1472.3873 records/second. Loss is 1.2143358. Sequential266afc8b's hyper parameters: Current learning rate is 3.8226299694189603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22144/60000][Iteration 2518][Wall Clock 246.043815967s] Trained 128 records in 0.087734589 seconds. Throughput is 1458.9457 records/second. Loss is 1.3737799. Sequential266afc8b's hyper parameters: Current learning rate is 3.8211692777990065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22272/60000][Iteration 2519][Wall Clock 246.134920499s] Trained 128 records in 0.091104532 seconds. Throughput is 1404.9795 records/second. Loss is 1.2403114. Sequential266afc8b's hyper parameters: Current learning rate is 3.819709702062643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22400/60000][Iteration 2520][Wall Clock 246.223838237s] Trained 128 records in 0.088917738 seconds. Throughput is 1439.5327 records/second. Loss is 1.289181. Sequential266afc8b's hyper parameters: Current learning rate is 3.818251240931653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22528/60000][Iteration 2521][Wall Clock 246.31792298s] Trained 128 records in 0.094084743 seconds. Throughput is 1360.4757 records/second. Loss is 1.3931515. Sequential266afc8b's hyper parameters: Current learning rate is 3.816793893129771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22656/60000][Iteration 2522][Wall Clock 246.409889005s] Trained 128 records in 0.091966025 seconds. Throughput is 1391.8184 records/second. Loss is 1.3325523. Sequential266afc8b's hyper parameters: Current learning rate is 3.8153376573826786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22784/60000][Iteration 2523][Wall Clock 246.501515898s] Trained 128 records in 0.091626893 seconds. Throughput is 1396.9698 records/second. Loss is 1.3079842. Sequential266afc8b's hyper parameters: Current learning rate is 3.8138825324180017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 22912/60000][Iteration 2524][Wall Clock 246.590484503s] Trained 128 records in 0.088968605 seconds. Throughput is 1438.7097 records/second. Loss is 1.2667136. Sequential266afc8b's hyper parameters: Current learning rate is 3.812428516965307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:25 INFO  DistriOptimizer$:408 - [Epoch 6 23040/60000][Iteration 2525][Wall Clock 246.680792499s] Trained 128 records in 0.090307996 seconds. Throughput is 1417.3717 records/second. Loss is 1.2755767. Sequential266afc8b's hyper parameters: Current learning rate is 3.810975609756097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23168/60000][Iteration 2526][Wall Clock 246.768078908s] Trained 128 records in 0.087286409 seconds. Throughput is 1466.4368 records/second. Loss is 1.1922839. Sequential266afc8b's hyper parameters: Current learning rate is 3.8095238095238096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23296/60000][Iteration 2527][Wall Clock 246.854944367s] Trained 128 records in 0.086865459 seconds. Throughput is 1473.5431 records/second. Loss is 1.3560092. Sequential266afc8b's hyper parameters: Current learning rate is 3.808073115003808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23424/60000][Iteration 2528][Wall Clock 246.944869676s] Trained 128 records in 0.089925309 seconds. Throughput is 1423.4034 records/second. Loss is 1.2864156. Sequential266afc8b's hyper parameters: Current learning rate is 3.8066235249333843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23552/60000][Iteration 2529][Wall Clock 247.032585713s] Trained 128 records in 0.087716037 seconds. Throughput is 1459.2543 records/second. Loss is 1.3869845. Sequential266afc8b's hyper parameters: Current learning rate is 3.80517503805175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23680/60000][Iteration 2530][Wall Clock 247.145042841s] Trained 128 records in 0.112457128 seconds. Throughput is 1138.2115 records/second. Loss is 1.2567741. Sequential266afc8b's hyper parameters: Current learning rate is 3.803727653100038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23808/60000][Iteration 2531][Wall Clock 247.233445004s] Trained 128 records in 0.088402163 seconds. Throughput is 1447.9285 records/second. Loss is 1.2725396. Sequential266afc8b's hyper parameters: Current learning rate is 3.8022813688212925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 23936/60000][Iteration 2532][Wall Clock 247.322979917s] Trained 128 records in 0.089534913 seconds. Throughput is 1429.6099 records/second. Loss is 1.2999988. Sequential266afc8b's hyper parameters: Current learning rate is 3.800836183960471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 24064/60000][Iteration 2533][Wall Clock 247.411918101s] Trained 128 records in 0.088938184 seconds. Throughput is 1439.2019 records/second. Loss is 1.3366634. Sequential266afc8b's hyper parameters: Current learning rate is 3.7993920972644377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 24192/60000][Iteration 2534][Wall Clock 247.500285638s] Trained 128 records in 0.088367537 seconds. Throughput is 1448.4957 records/second. Loss is 1.3002551. Sequential266afc8b's hyper parameters: Current learning rate is 3.7979491074819596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 24320/60000][Iteration 2535][Wall Clock 247.589073705s] Trained 128 records in 0.088788067 seconds. Throughput is 1441.6351 records/second. Loss is 1.296713. Sequential266afc8b's hyper parameters: Current learning rate is 3.7965072133637056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:26 INFO  DistriOptimizer$:408 - [Epoch 6 24448/60000][Iteration 2536][Wall Clock 247.679479316s] Trained 128 records in 0.090405611 seconds. Throughput is 1415.8413 records/second. Loss is 1.2833766. Sequential266afc8b's hyper parameters: Current learning rate is 3.795066413662239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 24576/60000][Iteration 2537][Wall Clock 247.766668215s] Trained 128 records in 0.087188899 seconds. Throughput is 1468.0768 records/second. Loss is 1.2432339. Sequential266afc8b's hyper parameters: Current learning rate is 3.7936267071320183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 24704/60000][Iteration 2538][Wall Clock 247.854172973s] Trained 128 records in 0.087504758 seconds. Throughput is 1462.7776 records/second. Loss is 1.1991686. Sequential266afc8b's hyper parameters: Current learning rate is 3.792188092529389E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 24832/60000][Iteration 2539][Wall Clock 247.961060309s] Trained 128 records in 0.106887336 seconds. Throughput is 1197.5226 records/second. Loss is 1.244054. Sequential266afc8b's hyper parameters: Current learning rate is 3.790750568612585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 24960/60000][Iteration 2540][Wall Clock 248.048383382s] Trained 128 records in 0.087323073 seconds. Throughput is 1465.8212 records/second. Loss is 1.4269035. Sequential266afc8b's hyper parameters: Current learning rate is 3.7893141341417203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25088/60000][Iteration 2541][Wall Clock 248.135491379s] Trained 128 records in 0.087107997 seconds. Throughput is 1469.4403 records/second. Loss is 1.1503401. Sequential266afc8b's hyper parameters: Current learning rate is 3.787878787878788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25216/60000][Iteration 2542][Wall Clock 248.223715648s] Trained 128 records in 0.088224269 seconds. Throughput is 1450.8479 records/second. Loss is 1.3287554. Sequential266afc8b's hyper parameters: Current learning rate is 3.786444528587656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25344/60000][Iteration 2543][Wall Clock 248.316446622s] Trained 128 records in 0.092730974 seconds. Throughput is 1380.337 records/second. Loss is 1.2759484. Sequential266afc8b's hyper parameters: Current learning rate is 3.785011355034065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25472/60000][Iteration 2544][Wall Clock 248.406961867s] Trained 128 records in 0.090515245 seconds. Throughput is 1414.1263 records/second. Loss is 1.2004244. Sequential266afc8b's hyper parameters: Current learning rate is 3.7835792659856227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25600/60000][Iteration 2545][Wall Clock 248.495962982s] Trained 128 records in 0.089001115 seconds. Throughput is 1438.1843 records/second. Loss is 1.4782226. Sequential266afc8b's hyper parameters: Current learning rate is 3.7821482602118004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25728/60000][Iteration 2546][Wall Clock 248.584073212s] Trained 128 records in 0.08811023 seconds. Throughput is 1452.7257 records/second. Loss is 1.2783439. Sequential266afc8b's hyper parameters: Current learning rate is 3.780718336483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:27 INFO  DistriOptimizer$:408 - [Epoch 6 25856/60000][Iteration 2547][Wall Clock 248.682260424s] Trained 128 records in 0.098187212 seconds. Throughput is 1303.6321 records/second. Loss is 1.3256525. Sequential266afc8b's hyper parameters: Current learning rate is 3.779289493575208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 25984/60000][Iteration 2548][Wall Clock 248.76696003s] Trained 128 records in 0.084699606 seconds. Throughput is 1511.223 records/second. Loss is 1.327085. Sequential266afc8b's hyper parameters: Current learning rate is 3.777861730260673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26112/60000][Iteration 2549][Wall Clock 248.857790853s] Trained 128 records in 0.090830823 seconds. Throughput is 1409.2133 records/second. Loss is 1.2307366. Sequential266afc8b's hyper parameters: Current learning rate is 3.7764350453172205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26240/60000][Iteration 2550][Wall Clock 248.946704203s] Trained 128 records in 0.08891335 seconds. Throughput is 1439.6038 records/second. Loss is 1.3504226. Sequential266afc8b's hyper parameters: Current learning rate is 3.7750094375235937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26368/60000][Iteration 2551][Wall Clock 249.04627324s] Trained 128 records in 0.099569037 seconds. Throughput is 1285.5402 records/second. Loss is 1.3489882. Sequential266afc8b's hyper parameters: Current learning rate is 3.773584905660377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26496/60000][Iteration 2552][Wall Clock 249.143879284s] Trained 128 records in 0.097606044 seconds. Throughput is 1311.3943 records/second. Loss is 1.2862653. Sequential266afc8b's hyper parameters: Current learning rate is 3.772161448509996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26624/60000][Iteration 2553][Wall Clock 249.240452405s] Trained 128 records in 0.096573121 seconds. Throughput is 1325.4205 records/second. Loss is 1.3128583. Sequential266afc8b's hyper parameters: Current learning rate is 3.770739064856712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26752/60000][Iteration 2554][Wall Clock 249.33284362s] Trained 128 records in 0.092391215 seconds. Throughput is 1385.4131 records/second. Loss is 1.3181086. Sequential266afc8b's hyper parameters: Current learning rate is 3.769317753486619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 26880/60000][Iteration 2555][Wall Clock 249.423527144s] Trained 128 records in 0.090683524 seconds. Throughput is 1411.5022 records/second. Loss is 1.2258242. Sequential266afc8b's hyper parameters: Current learning rate is 3.7678975131876413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 27008/60000][Iteration 2556][Wall Clock 249.51210178s] Trained 128 records in 0.088574636 seconds. Throughput is 1445.109 records/second. Loss is 1.2958002. Sequential266afc8b's hyper parameters: Current learning rate is 3.766478342749529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 27136/60000][Iteration 2557][Wall Clock 249.602795139s] Trained 128 records in 0.090693359 seconds. Throughput is 1411.3491 records/second. Loss is 1.3574253. Sequential266afc8b's hyper parameters: Current learning rate is 3.765060240963855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:28 INFO  DistriOptimizer$:408 - [Epoch 6 27264/60000][Iteration 2558][Wall Clock 249.689030064s] Trained 128 records in 0.086234925 seconds. Throughput is 1484.3174 records/second. Loss is 1.2911146. Sequential266afc8b's hyper parameters: Current learning rate is 3.763643206624012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 27392/60000][Iteration 2559][Wall Clock 249.783642702s] Trained 128 records in 0.094612638 seconds. Throughput is 1352.8849 records/second. Loss is 1.2976084. Sequential266afc8b's hyper parameters: Current learning rate is 3.762227238525207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 27520/60000][Iteration 2560][Wall Clock 249.86951434s] Trained 128 records in 0.085871638 seconds. Throughput is 1490.5969 records/second. Loss is 1.2781283. Sequential266afc8b's hyper parameters: Current learning rate is 3.76081233546446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 27648/60000][Iteration 2561][Wall Clock 249.957497539s] Trained 128 records in 0.087983199 seconds. Throughput is 1454.8232 records/second. Loss is 1.3658912. Sequential266afc8b's hyper parameters: Current learning rate is 3.759398496240601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 27776/60000][Iteration 2562][Wall Clock 250.043123458s] Trained 128 records in 0.085625919 seconds. Throughput is 1494.8745 records/second. Loss is 1.4126697. Sequential266afc8b's hyper parameters: Current learning rate is 3.7579857196542657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 27904/60000][Iteration 2563][Wall Clock 250.130494497s] Trained 128 records in 0.087371039 seconds. Throughput is 1465.0164 records/second. Loss is 1.3576567. Sequential266afc8b's hyper parameters: Current learning rate is 3.756574004507889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 28032/60000][Iteration 2564][Wall Clock 250.243178935s] Trained 128 records in 0.112684438 seconds. Throughput is 1135.9155 records/second. Loss is 1.3907952. Sequential266afc8b's hyper parameters: Current learning rate is 3.755163349605708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 28160/60000][Iteration 2565][Wall Clock 250.334981551s] Trained 128 records in 0.091802616 seconds. Throughput is 1394.2958 records/second. Loss is 1.2795044. Sequential266afc8b's hyper parameters: Current learning rate is 3.7537537537537537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 28288/60000][Iteration 2566][Wall Clock 250.427284771s] Trained 128 records in 0.09230322 seconds. Throughput is 1386.7339 records/second. Loss is 1.3815408. Sequential266afc8b's hyper parameters: Current learning rate is 3.75234521575985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 28416/60000][Iteration 2567][Wall Clock 250.513333987s] Trained 128 records in 0.086049216 seconds. Throughput is 1487.5209 records/second. Loss is 1.254719. Sequential266afc8b's hyper parameters: Current learning rate is 3.7509377344336085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 28544/60000][Iteration 2568][Wall Clock 250.598746222s] Trained 128 records in 0.085412235 seconds. Throughput is 1498.6144 records/second. Loss is 1.204842. Sequential266afc8b's hyper parameters: Current learning rate is 3.7495313085864263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:29 INFO  DistriOptimizer$:408 - [Epoch 6 28672/60000][Iteration 2569][Wall Clock 250.68596233s] Trained 128 records in 0.087216108 seconds. Throughput is 1467.6188 records/second. Loss is 1.3127705. Sequential266afc8b's hyper parameters: Current learning rate is 3.748125937031484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 28800/60000][Iteration 2570][Wall Clock 250.797383372s] Trained 128 records in 0.111421042 seconds. Throughput is 1148.7955 records/second. Loss is 1.3079373. Sequential266afc8b's hyper parameters: Current learning rate is 3.746721618583739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 28928/60000][Iteration 2571][Wall Clock 250.887002638s] Trained 128 records in 0.089619266 seconds. Throughput is 1428.2644 records/second. Loss is 1.3720536. Sequential266afc8b's hyper parameters: Current learning rate is 3.745318352059925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29056/60000][Iteration 2572][Wall Clock 250.981798418s] Trained 128 records in 0.09479578 seconds. Throughput is 1350.2711 records/second. Loss is 1.2229409. Sequential266afc8b's hyper parameters: Current learning rate is 3.743916136278547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29184/60000][Iteration 2573][Wall Clock 251.064388452s] Trained 128 records in 0.082590034 seconds. Throughput is 1549.8237 records/second. Loss is 1.3012489. Sequential266afc8b's hyper parameters: Current learning rate is 3.7425149700598805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29312/60000][Iteration 2574][Wall Clock 251.151194303s] Trained 128 records in 0.086805851 seconds. Throughput is 1474.555 records/second. Loss is 1.2926197. Sequential266afc8b's hyper parameters: Current learning rate is 3.741114852225963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29440/60000][Iteration 2575][Wall Clock 251.246843982s] Trained 128 records in 0.095649679 seconds. Throughput is 1338.2167 records/second. Loss is 1.309513. Sequential266afc8b's hyper parameters: Current learning rate is 3.7397157816005983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29568/60000][Iteration 2576][Wall Clock 251.334182279s] Trained 128 records in 0.087338297 seconds. Throughput is 1465.5656 records/second. Loss is 1.2848119. Sequential266afc8b's hyper parameters: Current learning rate is 3.7383177570093456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29696/60000][Iteration 2577][Wall Clock 251.426111632s] Trained 128 records in 0.091929353 seconds. Throughput is 1392.3735 records/second. Loss is 1.2940961. Sequential266afc8b's hyper parameters: Current learning rate is 3.736920777279522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29824/60000][Iteration 2578][Wall Clock 251.514542503s] Trained 128 records in 0.088430871 seconds. Throughput is 1447.4583 records/second. Loss is 1.3512127. Sequential266afc8b's hyper parameters: Current learning rate is 3.7355248412401944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 29952/60000][Iteration 2579][Wall Clock 251.601922481s] Trained 128 records in 0.087379978 seconds. Throughput is 1464.8665 records/second. Loss is 1.2742257. Sequential266afc8b's hyper parameters: Current learning rate is 3.7341299477221804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:30 INFO  DistriOptimizer$:408 - [Epoch 6 30080/60000][Iteration 2580][Wall Clock 251.688276624s] Trained 128 records in 0.086354143 seconds. Throughput is 1482.2682 records/second. Loss is 1.2401748. Sequential266afc8b's hyper parameters: Current learning rate is 3.732736095558044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30208/60000][Iteration 2581][Wall Clock 251.77474188s] Trained 128 records in 0.086465256 seconds. Throughput is 1480.3634 records/second. Loss is 1.1606278. Sequential266afc8b's hyper parameters: Current learning rate is 3.7313432835820896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30336/60000][Iteration 2582][Wall Clock 251.861395707s] Trained 128 records in 0.086653827 seconds. Throughput is 1477.1418 records/second. Loss is 1.3692762. Sequential266afc8b's hyper parameters: Current learning rate is 3.7299515106303615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30464/60000][Iteration 2583][Wall Clock 251.953790335s] Trained 128 records in 0.092394628 seconds. Throughput is 1385.3619 records/second. Loss is 1.2710654. Sequential266afc8b's hyper parameters: Current learning rate is 3.7285607755406416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30592/60000][Iteration 2584][Wall Clock 252.044763904s] Trained 128 records in 0.090973569 seconds. Throughput is 1407.0021 records/second. Loss is 1.3576802. Sequential266afc8b's hyper parameters: Current learning rate is 3.727171077152441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30720/60000][Iteration 2585][Wall Clock 252.137943482s] Trained 128 records in 0.093179578 seconds. Throughput is 1373.6917 records/second. Loss is 1.2392051. Sequential266afc8b's hyper parameters: Current learning rate is 3.7257824143070045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30848/60000][Iteration 2586][Wall Clock 252.226071386s] Trained 128 records in 0.088127904 seconds. Throughput is 1452.4344 records/second. Loss is 1.1961197. Sequential266afc8b's hyper parameters: Current learning rate is 3.7243947858472997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 30976/60000][Iteration 2587][Wall Clock 252.317815827s] Trained 128 records in 0.091744441 seconds. Throughput is 1395.1799 records/second. Loss is 1.2302865. Sequential266afc8b's hyper parameters: Current learning rate is 3.7230081906180194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 31104/60000][Iteration 2588][Wall Clock 252.408269948s] Trained 128 records in 0.090454121 seconds. Throughput is 1415.082 records/second. Loss is 1.3248538. Sequential266afc8b's hyper parameters: Current learning rate is 3.7216226274655747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 31232/60000][Iteration 2589][Wall Clock 252.505588553s] Trained 128 records in 0.097318605 seconds. Throughput is 1315.2676 records/second. Loss is 1.2237586. Sequential266afc8b's hyper parameters: Current learning rate is 3.7202380952380956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 31360/60000][Iteration 2590][Wall Clock 252.590758926s] Trained 128 records in 0.085170373 seconds. Throughput is 1502.87 records/second. Loss is 1.3039734. Sequential266afc8b's hyper parameters: Current learning rate is 3.718854592785422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:31 INFO  DistriOptimizer$:408 - [Epoch 6 31488/60000][Iteration 2591][Wall Clock 252.673230493s] Trained 128 records in 0.082471567 seconds. Throughput is 1552.05 records/second. Loss is 1.258172. Sequential266afc8b's hyper parameters: Current learning rate is 3.717472118959108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 31616/60000][Iteration 2592][Wall Clock 252.757288982s] Trained 128 records in 0.084058489 seconds. Throughput is 1522.7493 records/second. Loss is 1.2774123. Sequential266afc8b's hyper parameters: Current learning rate is 3.716090672612412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 31744/60000][Iteration 2593][Wall Clock 252.850833249s] Trained 128 records in 0.093544267 seconds. Throughput is 1368.3362 records/second. Loss is 1.2732981. Sequential266afc8b's hyper parameters: Current learning rate is 3.714710252600297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 31872/60000][Iteration 2594][Wall Clock 252.935988541s] Trained 128 records in 0.085155292 seconds. Throughput is 1503.1361 records/second. Loss is 1.2264991. Sequential266afc8b's hyper parameters: Current learning rate is 3.713330857779428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32000/60000][Iteration 2595][Wall Clock 253.025485508s] Trained 128 records in 0.089496967 seconds. Throughput is 1430.2161 records/second. Loss is 1.1903315. Sequential266afc8b's hyper parameters: Current learning rate is 3.711952487008166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32128/60000][Iteration 2596][Wall Clock 253.116560452s] Trained 128 records in 0.091074944 seconds. Throughput is 1405.4359 records/second. Loss is 1.2921463. Sequential266afc8b's hyper parameters: Current learning rate is 3.710575139146568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32256/60000][Iteration 2597][Wall Clock 253.20445684s] Trained 128 records in 0.087896388 seconds. Throughput is 1456.2601 records/second. Loss is 1.3384788. Sequential266afc8b's hyper parameters: Current learning rate is 3.70919881305638E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32384/60000][Iteration 2598][Wall Clock 253.302961306s] Trained 128 records in 0.098504466 seconds. Throughput is 1299.4335 records/second. Loss is 1.2790639. Sequential266afc8b's hyper parameters: Current learning rate is 3.7078235076010385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32512/60000][Iteration 2599][Wall Clock 253.41863964s] Trained 128 records in 0.115678334 seconds. Throughput is 1106.5166 records/second. Loss is 1.3673857. Sequential266afc8b's hyper parameters: Current learning rate is 3.7064492216456633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32640/60000][Iteration 2600][Wall Clock 253.537907794s] Trained 128 records in 0.119268154 seconds. Throughput is 1073.2119 records/second. Loss is 1.3163562. Sequential266afc8b's hyper parameters: Current learning rate is 3.705075954057058E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:32 INFO  DistriOptimizer$:408 - [Epoch 6 32768/60000][Iteration 2601][Wall Clock 253.648119215s] Trained 128 records in 0.110211421 seconds. Throughput is 1161.404 records/second. Loss is 1.2635779. Sequential266afc8b's hyper parameters: Current learning rate is 3.7037037037037035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 32896/60000][Iteration 2602][Wall Clock 253.76008597s] Trained 128 records in 0.111966755 seconds. Throughput is 1143.1965 records/second. Loss is 1.2181919. Sequential266afc8b's hyper parameters: Current learning rate is 3.702332469455757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33024/60000][Iteration 2603][Wall Clock 253.872688342s] Trained 128 records in 0.112602372 seconds. Throughput is 1136.7433 records/second. Loss is 1.3283504. Sequential266afc8b's hyper parameters: Current learning rate is 3.7009622501850485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33152/60000][Iteration 2604][Wall Clock 253.984917817s] Trained 128 records in 0.112229475 seconds. Throughput is 1140.5204 records/second. Loss is 1.3689886. Sequential266afc8b's hyper parameters: Current learning rate is 3.699593044765076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33280/60000][Iteration 2605][Wall Clock 254.096476332s] Trained 128 records in 0.111558515 seconds. Throughput is 1147.38 records/second. Loss is 1.2444263. Sequential266afc8b's hyper parameters: Current learning rate is 3.6982248520710064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33408/60000][Iteration 2606][Wall Clock 254.185113268s] Trained 128 records in 0.088636936 seconds. Throughput is 1444.0933 records/second. Loss is 1.2775111. Sequential266afc8b's hyper parameters: Current learning rate is 3.696857670979667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33536/60000][Iteration 2607][Wall Clock 254.274463481s] Trained 128 records in 0.089350213 seconds. Throughput is 1432.5651 records/second. Loss is 1.3253685. Sequential266afc8b's hyper parameters: Current learning rate is 3.695491500369549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33664/60000][Iteration 2608][Wall Clock 254.360171983s] Trained 128 records in 0.085708502 seconds. Throughput is 1493.4342 records/second. Loss is 1.3624158. Sequential266afc8b's hyper parameters: Current learning rate is 3.694126339120798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33792/60000][Iteration 2609][Wall Clock 254.445995412s] Trained 128 records in 0.085823429 seconds. Throughput is 1491.4342 records/second. Loss is 1.2674311. Sequential266afc8b's hyper parameters: Current learning rate is 3.692762186115214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 33920/60000][Iteration 2610][Wall Clock 254.535609331s] Trained 128 records in 0.089613919 seconds. Throughput is 1428.3495 records/second. Loss is 1.3136895. Sequential266afc8b's hyper parameters: Current learning rate is 3.6913990402362494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:33 INFO  DistriOptimizer$:408 - [Epoch 6 34048/60000][Iteration 2611][Wall Clock 254.626484273s] Trained 128 records in 0.090874942 seconds. Throughput is 1408.5292 records/second. Loss is 1.241937. Sequential266afc8b's hyper parameters: Current learning rate is 3.6900369003690036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34176/60000][Iteration 2612][Wall Clock 254.712632644s] Trained 128 records in 0.086148371 seconds. Throughput is 1485.8087 records/second. Loss is 1.3587085. Sequential266afc8b's hyper parameters: Current learning rate is 3.6886757654002215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34304/60000][Iteration 2613][Wall Clock 254.805098507s] Trained 128 records in 0.092465863 seconds. Throughput is 1384.2947 records/second. Loss is 1.3309937. Sequential266afc8b's hyper parameters: Current learning rate is 3.687315634218289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34432/60000][Iteration 2614][Wall Clock 254.896904742s] Trained 128 records in 0.091806235 seconds. Throughput is 1394.2408 records/second. Loss is 1.2664351. Sequential266afc8b's hyper parameters: Current learning rate is 3.6859565057132326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34560/60000][Iteration 2615][Wall Clock 255.013489104s] Trained 128 records in 0.116584362 seconds. Throughput is 1097.9174 records/second. Loss is 1.3125736. Sequential266afc8b's hyper parameters: Current learning rate is 3.6845983787767134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34688/60000][Iteration 2616][Wall Clock 255.10055436s] Trained 128 records in 0.087065256 seconds. Throughput is 1470.1616 records/second. Loss is 1.3425329. Sequential266afc8b's hyper parameters: Current learning rate is 3.6832412523020257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34816/60000][Iteration 2617][Wall Clock 255.181238292s] Trained 128 records in 0.080683932 seconds. Throughput is 1586.4373 records/second. Loss is 1.2695146. Sequential266afc8b's hyper parameters: Current learning rate is 3.681885125184094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 34944/60000][Iteration 2618][Wall Clock 255.270827935s] Trained 128 records in 0.089589643 seconds. Throughput is 1428.7366 records/second. Loss is 1.1459246. Sequential266afc8b's hyper parameters: Current learning rate is 3.68052999631947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 35072/60000][Iteration 2619][Wall Clock 255.358060823s] Trained 128 records in 0.087232888 seconds. Throughput is 1467.3365 records/second. Loss is 1.2321384. Sequential266afc8b's hyper parameters: Current learning rate is 3.679175864606328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 35200/60000][Iteration 2620][Wall Clock 255.443697365s] Trained 128 records in 0.085636542 seconds. Throughput is 1494.6891 records/second. Loss is 1.200633. Sequential266afc8b's hyper parameters: Current learning rate is 3.677822728944465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 35328/60000][Iteration 2621][Wall Clock 255.530637077s] Trained 128 records in 0.086939712 seconds. Throughput is 1472.2845 records/second. Loss is 1.3068825. Sequential266afc8b's hyper parameters: Current learning rate is 3.676470588235294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:34 INFO  DistriOptimizer$:408 - [Epoch 6 35456/60000][Iteration 2622][Wall Clock 255.617206941s] Trained 128 records in 0.086569864 seconds. Throughput is 1478.5746 records/second. Loss is 1.1746587. Sequential266afc8b's hyper parameters: Current learning rate is 3.6751194413818446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 35584/60000][Iteration 2623][Wall Clock 255.701643776s] Trained 128 records in 0.084436835 seconds. Throughput is 1515.9261 records/second. Loss is 1.376533. Sequential266afc8b's hyper parameters: Current learning rate is 3.6737692872887586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 35712/60000][Iteration 2624][Wall Clock 255.804016264s] Trained 128 records in 0.102372488 seconds. Throughput is 1250.3359 records/second. Loss is 1.3256953. Sequential266afc8b's hyper parameters: Current learning rate is 3.672420124862284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 35840/60000][Iteration 2625][Wall Clock 255.890317548s] Trained 128 records in 0.086301284 seconds. Throughput is 1483.1761 records/second. Loss is 1.2567236. Sequential266afc8b's hyper parameters: Current learning rate is 3.671071953010279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 35968/60000][Iteration 2626][Wall Clock 255.978153623s] Trained 128 records in 0.087836075 seconds. Throughput is 1457.26 records/second. Loss is 1.2253687. Sequential266afc8b's hyper parameters: Current learning rate is 3.669724770642202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36096/60000][Iteration 2627][Wall Clock 256.066470691s] Trained 128 records in 0.088317068 seconds. Throughput is 1449.3235 records/second. Loss is 1.3055037. Sequential266afc8b's hyper parameters: Current learning rate is 3.668378576669112E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36224/60000][Iteration 2628][Wall Clock 256.153429207s] Trained 128 records in 0.086958516 seconds. Throughput is 1471.9663 records/second. Loss is 1.2330363. Sequential266afc8b's hyper parameters: Current learning rate is 3.667033370003667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36352/60000][Iteration 2629][Wall Clock 256.239996895s] Trained 128 records in 0.086567688 seconds. Throughput is 1478.6118 records/second. Loss is 1.2507368. Sequential266afc8b's hyper parameters: Current learning rate is 3.6656891495601173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36480/60000][Iteration 2630][Wall Clock 256.329539503s] Trained 128 records in 0.089542608 seconds. Throughput is 1429.487 records/second. Loss is 1.3448004. Sequential266afc8b's hyper parameters: Current learning rate is 3.6643459142543056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36608/60000][Iteration 2631][Wall Clock 256.415937359s] Trained 128 records in 0.086397856 seconds. Throughput is 1481.5182 records/second. Loss is 1.2272953. Sequential266afc8b's hyper parameters: Current learning rate is 3.663003663003663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36736/60000][Iteration 2632][Wall Clock 256.502920956s] Trained 128 records in 0.086983597 seconds. Throughput is 1471.5417 records/second. Loss is 1.2922738. Sequential266afc8b's hyper parameters: Current learning rate is 3.661662394727206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36864/60000][Iteration 2633][Wall Clock 256.588093883s] Trained 128 records in 0.085172927 seconds. Throughput is 1502.825 records/second. Loss is 1.2511488. Sequential266afc8b's hyper parameters: Current learning rate is 3.6603221083455345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:35 INFO  DistriOptimizer$:408 - [Epoch 6 36992/60000][Iteration 2634][Wall Clock 256.677543709s] Trained 128 records in 0.089449826 seconds. Throughput is 1430.9698 records/second. Loss is 1.3964925. Sequential266afc8b's hyper parameters: Current learning rate is 3.6589828027808267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37120/60000][Iteration 2635][Wall Clock 256.764464886s] Trained 128 records in 0.086921177 seconds. Throughput is 1472.5985 records/second. Loss is 1.3196402. Sequential266afc8b's hyper parameters: Current learning rate is 3.65764447695684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37248/60000][Iteration 2636][Wall Clock 256.851360395s] Trained 128 records in 0.086895509 seconds. Throughput is 1473.0336 records/second. Loss is 1.3016837. Sequential266afc8b's hyper parameters: Current learning rate is 3.656307129798903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37376/60000][Iteration 2637][Wall Clock 256.939668487s] Trained 128 records in 0.088308092 seconds. Throughput is 1449.4708 records/second. Loss is 1.248821. Sequential266afc8b's hyper parameters: Current learning rate is 3.6549707602339185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37504/60000][Iteration 2638][Wall Clock 257.026147929s] Trained 128 records in 0.086479442 seconds. Throughput is 1480.1206 records/second. Loss is 1.3775626. Sequential266afc8b's hyper parameters: Current learning rate is 3.6536353671903543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37632/60000][Iteration 2639][Wall Clock 257.11231451s] Trained 128 records in 0.086166581 seconds. Throughput is 1485.4946 records/second. Loss is 1.2687922. Sequential266afc8b's hyper parameters: Current learning rate is 3.652300949598247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37760/60000][Iteration 2640][Wall Clock 257.198046975s] Trained 128 records in 0.085732465 seconds. Throughput is 1493.0166 records/second. Loss is 1.181445. Sequential266afc8b's hyper parameters: Current learning rate is 3.650967506389193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 37888/60000][Iteration 2641][Wall Clock 257.284023192s] Trained 128 records in 0.085976217 seconds. Throughput is 1488.7837 records/second. Loss is 1.246043. Sequential266afc8b's hyper parameters: Current learning rate is 3.64963503649635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 38016/60000][Iteration 2642][Wall Clock 257.37037324s] Trained 128 records in 0.086350048 seconds. Throughput is 1482.3385 records/second. Loss is 1.1931391. Sequential266afc8b's hyper parameters: Current learning rate is 3.6483035388544326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 38144/60000][Iteration 2643][Wall Clock 257.455341633s] Trained 128 records in 0.084968393 seconds. Throughput is 1506.4425 records/second. Loss is 1.3040739. Sequential266afc8b's hyper parameters: Current learning rate is 3.6469730123997083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 38272/60000][Iteration 2644][Wall Clock 257.541257021s] Trained 128 records in 0.085915388 seconds. Throughput is 1489.8379 records/second. Loss is 1.24686. Sequential266afc8b's hyper parameters: Current learning rate is 3.6456434560699967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:36 INFO  DistriOptimizer$:408 - [Epoch 6 38400/60000][Iteration 2645][Wall Clock 257.630891502s] Trained 128 records in 0.089634481 seconds. Throughput is 1428.022 records/second. Loss is 1.2447033. Sequential266afc8b's hyper parameters: Current learning rate is 3.6443148688046647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 38528/60000][Iteration 2646][Wall Clock 257.717493149s] Trained 128 records in 0.086601647 seconds. Throughput is 1478.032 records/second. Loss is 1.2623733. Sequential266afc8b's hyper parameters: Current learning rate is 3.6429872495446266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 38656/60000][Iteration 2647][Wall Clock 257.803384115s] Trained 128 records in 0.085890966 seconds. Throughput is 1490.2616 records/second. Loss is 1.3217882. Sequential266afc8b's hyper parameters: Current learning rate is 3.641660597232338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 38784/60000][Iteration 2648][Wall Clock 257.890484787s] Trained 128 records in 0.087100672 seconds. Throughput is 1469.5638 records/second. Loss is 1.2163138. Sequential266afc8b's hyper parameters: Current learning rate is 3.640334910811795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 38912/60000][Iteration 2649][Wall Clock 257.982761326s] Trained 128 records in 0.092276539 seconds. Throughput is 1387.1349 records/second. Loss is 1.2590045. Sequential266afc8b's hyper parameters: Current learning rate is 3.63901018922853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39040/60000][Iteration 2650][Wall Clock 258.062641405s] Trained 128 records in 0.079880079 seconds. Throughput is 1602.402 records/second. Loss is 1.269038. Sequential266afc8b's hyper parameters: Current learning rate is 3.637686431429611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39168/60000][Iteration 2651][Wall Clock 258.149104666s] Trained 128 records in 0.086463261 seconds. Throughput is 1480.3976 records/second. Loss is 1.2385658. Sequential266afc8b's hyper parameters: Current learning rate is 3.6363636363636367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39296/60000][Iteration 2652][Wall Clock 258.237471657s] Trained 128 records in 0.088366991 seconds. Throughput is 1448.5046 records/second. Loss is 1.3164052. Sequential266afc8b's hyper parameters: Current learning rate is 3.635041802980734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39424/60000][Iteration 2653][Wall Clock 258.323993052s] Trained 128 records in 0.086521395 seconds. Throughput is 1479.4028 records/second. Loss is 1.2667397. Sequential266afc8b's hyper parameters: Current learning rate is 3.633720930232558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39552/60000][Iteration 2654][Wall Clock 258.409278377s] Trained 128 records in 0.085285325 seconds. Throughput is 1500.8444 records/second. Loss is 1.3043172. Sequential266afc8b's hyper parameters: Current learning rate is 3.632401017072285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39680/60000][Iteration 2655][Wall Clock 258.526131627s] Trained 128 records in 0.11685325 seconds. Throughput is 1095.391 records/second. Loss is 1.2931621. Sequential266afc8b's hyper parameters: Current learning rate is 3.6310820624546115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:37 INFO  DistriOptimizer$:408 - [Epoch 6 39808/60000][Iteration 2656][Wall Clock 258.616228128s] Trained 128 records in 0.090096501 seconds. Throughput is 1420.6989 records/second. Loss is 1.2564242. Sequential266afc8b's hyper parameters: Current learning rate is 3.629764065335753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 39936/60000][Iteration 2657][Wall Clock 258.704954136s] Trained 128 records in 0.088726008 seconds. Throughput is 1442.6436 records/second. Loss is 1.2861096. Sequential266afc8b's hyper parameters: Current learning rate is 3.62844702467344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40064/60000][Iteration 2658][Wall Clock 258.790325479s] Trained 128 records in 0.085371343 seconds. Throughput is 1499.3322 records/second. Loss is 1.2757604. Sequential266afc8b's hyper parameters: Current learning rate is 3.627130939426913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40192/60000][Iteration 2659][Wall Clock 258.878468635s] Trained 128 records in 0.088143156 seconds. Throughput is 1452.1831 records/second. Loss is 1.2660693. Sequential266afc8b's hyper parameters: Current learning rate is 3.625815808556925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40320/60000][Iteration 2660][Wall Clock 258.964419787s] Trained 128 records in 0.085951152 seconds. Throughput is 1489.218 records/second. Loss is 1.3334591. Sequential266afc8b's hyper parameters: Current learning rate is 3.624501631025734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40448/60000][Iteration 2661][Wall Clock 259.055512441s] Trained 128 records in 0.091092654 seconds. Throughput is 1405.1627 records/second. Loss is 1.2527072. Sequential266afc8b's hyper parameters: Current learning rate is 3.6231884057971015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40576/60000][Iteration 2662][Wall Clock 259.142475935s] Trained 128 records in 0.086963494 seconds. Throughput is 1471.882 records/second. Loss is 1.3395321. Sequential266afc8b's hyper parameters: Current learning rate is 3.621876131836291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40704/60000][Iteration 2663][Wall Clock 259.260479295s] Trained 128 records in 0.11800336 seconds. Throughput is 1084.7148 records/second. Loss is 1.3691342. Sequential266afc8b's hyper parameters: Current learning rate is 3.620564808110065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40832/60000][Iteration 2664][Wall Clock 259.365995708s] Trained 128 records in 0.105516413 seconds. Throughput is 1213.0814 records/second. Loss is 1.3647064. Sequential266afc8b's hyper parameters: Current learning rate is 3.619254433586681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 40960/60000][Iteration 2665][Wall Clock 259.485799477s] Trained 128 records in 0.119803769 seconds. Throughput is 1068.4138 records/second. Loss is 1.3400055. Sequential266afc8b's hyper parameters: Current learning rate is 3.61794500723589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:38 INFO  DistriOptimizer$:408 - [Epoch 6 41088/60000][Iteration 2666][Wall Clock 259.588258593s] Trained 128 records in 0.102459116 seconds. Throughput is 1249.2788 records/second. Loss is 1.304139. Sequential266afc8b's hyper parameters: Current learning rate is 3.616636528028933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41216/60000][Iteration 2667][Wall Clock 259.701272158s] Trained 128 records in 0.113013565 seconds. Throughput is 1132.6074 records/second. Loss is 1.183229. Sequential266afc8b's hyper parameters: Current learning rate is 3.6153289949385393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41344/60000][Iteration 2668][Wall Clock 259.794395413s] Trained 128 records in 0.093123255 seconds. Throughput is 1374.5223 records/second. Loss is 1.2620391. Sequential266afc8b's hyper parameters: Current learning rate is 3.614022406938923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41472/60000][Iteration 2669][Wall Clock 259.886715798s] Trained 128 records in 0.092320385 seconds. Throughput is 1386.4761 records/second. Loss is 1.2692465. Sequential266afc8b's hyper parameters: Current learning rate is 3.6127167630057807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41600/60000][Iteration 2670][Wall Clock 259.980172487s] Trained 128 records in 0.093456689 seconds. Throughput is 1369.6184 records/second. Loss is 1.2321115. Sequential266afc8b's hyper parameters: Current learning rate is 3.6114120621162876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41728/60000][Iteration 2671][Wall Clock 260.077212263s] Trained 128 records in 0.097039776 seconds. Throughput is 1319.0468 records/second. Loss is 1.3082064. Sequential266afc8b's hyper parameters: Current learning rate is 3.610108303249098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41856/60000][Iteration 2672][Wall Clock 260.170933448s] Trained 128 records in 0.093721185 seconds. Throughput is 1365.753 records/second. Loss is 1.3182609. Sequential266afc8b's hyper parameters: Current learning rate is 3.6088054853843375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 41984/60000][Iteration 2673][Wall Clock 260.290602164s] Trained 128 records in 0.119668716 seconds. Throughput is 1069.6196 records/second. Loss is 1.2735736. Sequential266afc8b's hyper parameters: Current learning rate is 3.6075036075036075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 42112/60000][Iteration 2674][Wall Clock 260.392022161s] Trained 128 records in 0.101419997 seconds. Throughput is 1262.0785 records/second. Loss is 1.2789096. Sequential266afc8b's hyper parameters: Current learning rate is 3.606202668589975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 42240/60000][Iteration 2675][Wall Clock 260.515399574s] Trained 128 records in 0.123377413 seconds. Throughput is 1037.467 records/second. Loss is 1.3312892. Sequential266afc8b's hyper parameters: Current learning rate is 3.604902667627974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:39 INFO  DistriOptimizer$:408 - [Epoch 6 42368/60000][Iteration 2676][Wall Clock 260.607926199s] Trained 128 records in 0.092526625 seconds. Throughput is 1383.3856 records/second. Loss is 1.2853683. Sequential266afc8b's hyper parameters: Current learning rate is 3.6036036036036037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 42496/60000][Iteration 2677][Wall Clock 260.699779206s] Trained 128 records in 0.091853007 seconds. Throughput is 1393.5309 records/second. Loss is 1.2766373. Sequential266afc8b's hyper parameters: Current learning rate is 3.6023054755043225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 42624/60000][Iteration 2678][Wall Clock 260.796682835s] Trained 128 records in 0.096903629 seconds. Throughput is 1320.8999 records/second. Loss is 1.3137625. Sequential266afc8b's hyper parameters: Current learning rate is 3.6010082823190496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 42752/60000][Iteration 2679][Wall Clock 260.892186207s] Trained 128 records in 0.095503372 seconds. Throughput is 1340.2667 records/second. Loss is 1.2758257. Sequential266afc8b's hyper parameters: Current learning rate is 3.599712023038157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 42880/60000][Iteration 2680][Wall Clock 260.990347203s] Trained 128 records in 0.098160996 seconds. Throughput is 1303.9802 records/second. Loss is 1.4101654. Sequential266afc8b's hyper parameters: Current learning rate is 3.598416696653473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43008/60000][Iteration 2681][Wall Clock 261.081666694s] Trained 128 records in 0.091319491 seconds. Throughput is 1401.6722 records/second. Loss is 1.2212727. Sequential266afc8b's hyper parameters: Current learning rate is 3.5971223021582735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43136/60000][Iteration 2682][Wall Clock 261.178135876s] Trained 128 records in 0.096469182 seconds. Throughput is 1326.8486 records/second. Loss is 1.3822958. Sequential266afc8b's hyper parameters: Current learning rate is 3.595828838547285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43264/60000][Iteration 2683][Wall Clock 261.263252152s] Trained 128 records in 0.085116276 seconds. Throughput is 1503.8252 records/second. Loss is 1.3439401. Sequential266afc8b's hyper parameters: Current learning rate is 3.594536304816679E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43392/60000][Iteration 2684][Wall Clock 261.355244753s] Trained 128 records in 0.091992601 seconds. Throughput is 1391.4163 records/second. Loss is 1.2267231. Sequential266afc8b's hyper parameters: Current learning rate is 3.5932446999640676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43520/60000][Iteration 2685][Wall Clock 261.447371708s] Trained 128 records in 0.092126955 seconds. Throughput is 1389.387 records/second. Loss is 1.3404552. Sequential266afc8b's hyper parameters: Current learning rate is 3.5919540229885057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43648/60000][Iteration 2686][Wall Clock 261.541115132s] Trained 128 records in 0.093743424 seconds. Throughput is 1365.4292 records/second. Loss is 1.2826903. Sequential266afc8b's hyper parameters: Current learning rate is 3.5906642728904844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:40 INFO  DistriOptimizer$:408 - [Epoch 6 43776/60000][Iteration 2687][Wall Clock 261.633798097s] Trained 128 records in 0.092682965 seconds. Throughput is 1381.052 records/second. Loss is 1.2543703. Sequential266afc8b's hyper parameters: Current learning rate is 3.589375448671931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 43904/60000][Iteration 2688][Wall Clock 261.752206657s] Trained 128 records in 0.11840856 seconds. Throughput is 1081.0029 records/second. Loss is 1.2466536. Sequential266afc8b's hyper parameters: Current learning rate is 3.5880875493362035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44032/60000][Iteration 2689][Wall Clock 261.867078187s] Trained 128 records in 0.11487153 seconds. Throughput is 1114.2882 records/second. Loss is 1.1763433. Sequential266afc8b's hyper parameters: Current learning rate is 3.586800573888092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44160/60000][Iteration 2690][Wall Clock 261.981027742s] Trained 128 records in 0.113949555 seconds. Throughput is 1123.3041 records/second. Loss is 1.2138677. Sequential266afc8b's hyper parameters: Current learning rate is 3.5855145213338117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44288/60000][Iteration 2691][Wall Clock 262.084437931s] Trained 128 records in 0.103410189 seconds. Throughput is 1237.7891 records/second. Loss is 1.211289. Sequential266afc8b's hyper parameters: Current learning rate is 3.5842293906810036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44416/60000][Iteration 2692][Wall Clock 262.192974263s] Trained 128 records in 0.108536332 seconds. Throughput is 1179.3286 records/second. Loss is 1.2620181. Sequential266afc8b's hyper parameters: Current learning rate is 3.582945180938732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44544/60000][Iteration 2693][Wall Clock 262.303348918s] Trained 128 records in 0.110374655 seconds. Throughput is 1159.6865 records/second. Loss is 1.3371341. Sequential266afc8b's hyper parameters: Current learning rate is 3.5816618911174784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44672/60000][Iteration 2694][Wall Clock 262.411007321s] Trained 128 records in 0.107658403 seconds. Throughput is 1188.9458 records/second. Loss is 1.3789247. Sequential266afc8b's hyper parameters: Current learning rate is 3.5803795202291446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44800/60000][Iteration 2695][Wall Clock 262.517960009s] Trained 128 records in 0.106952688 seconds. Throughput is 1196.7909 records/second. Loss is 1.329506. Sequential266afc8b's hyper parameters: Current learning rate is 3.5790980672870435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:41 INFO  DistriOptimizer$:408 - [Epoch 6 44928/60000][Iteration 2696][Wall Clock 262.624276962s] Trained 128 records in 0.106316953 seconds. Throughput is 1203.9473 records/second. Loss is 1.2848401. Sequential266afc8b's hyper parameters: Current learning rate is 3.5778175313059033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45056/60000][Iteration 2697][Wall Clock 262.733235609s] Trained 128 records in 0.108958647 seconds. Throughput is 1174.7576 records/second. Loss is 1.3322121. Sequential266afc8b's hyper parameters: Current learning rate is 3.57653791130186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45184/60000][Iteration 2698][Wall Clock 262.82011998s] Trained 128 records in 0.086884371 seconds. Throughput is 1473.2224 records/second. Loss is 1.355478. Sequential266afc8b's hyper parameters: Current learning rate is 3.5752592062924567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45312/60000][Iteration 2699][Wall Clock 262.906982117s] Trained 128 records in 0.086862137 seconds. Throughput is 1473.5995 records/second. Loss is 1.3002292. Sequential266afc8b's hyper parameters: Current learning rate is 3.5739814152966406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45440/60000][Iteration 2700][Wall Clock 262.9968124s] Trained 128 records in 0.089830283 seconds. Throughput is 1424.9093 records/second. Loss is 1.22091. Sequential266afc8b's hyper parameters: Current learning rate is 3.572704537334762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45568/60000][Iteration 2701][Wall Clock 263.087423492s] Trained 128 records in 0.090611092 seconds. Throughput is 1412.6306 records/second. Loss is 1.2645183. Sequential266afc8b's hyper parameters: Current learning rate is 3.5714285714285714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45696/60000][Iteration 2702][Wall Clock 263.168606753s] Trained 128 records in 0.081183261 seconds. Throughput is 1576.6797 records/second. Loss is 1.1610329. Sequential266afc8b's hyper parameters: Current learning rate is 3.5701535166012135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45824/60000][Iteration 2703][Wall Clock 263.250520455s] Trained 128 records in 0.081913702 seconds. Throughput is 1562.6201 records/second. Loss is 1.2636305. Sequential266afc8b's hyper parameters: Current learning rate is 3.5688793718772306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 45952/60000][Iteration 2704][Wall Clock 263.337395348s] Trained 128 records in 0.086874893 seconds. Throughput is 1473.383 records/second. Loss is 1.2959702. Sequential266afc8b's hyper parameters: Current learning rate is 3.5676061362825543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 46080/60000][Iteration 2705][Wall Clock 263.423117887s] Trained 128 records in 0.085722539 seconds. Throughput is 1493.1896 records/second. Loss is 1.2413582. Sequential266afc8b's hyper parameters: Current learning rate is 3.566333808844508E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 46208/60000][Iteration 2706][Wall Clock 263.513431172s] Trained 128 records in 0.090313285 seconds. Throughput is 1417.2887 records/second. Loss is 1.2700577. Sequential266afc8b's hyper parameters: Current learning rate is 3.5650623885918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:42 INFO  DistriOptimizer$:408 - [Epoch 6 46336/60000][Iteration 2707][Wall Clock 263.602197319s] Trained 128 records in 0.088766147 seconds. Throughput is 1441.9911 records/second. Loss is 1.3427972. Sequential266afc8b's hyper parameters: Current learning rate is 3.5637918745545257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 46464/60000][Iteration 2708][Wall Clock 263.689437435s] Trained 128 records in 0.087240116 seconds. Throughput is 1467.215 records/second. Loss is 1.24301. Sequential266afc8b's hyper parameters: Current learning rate is 3.562522265764161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 46592/60000][Iteration 2709][Wall Clock 263.771520159s] Trained 128 records in 0.082082724 seconds. Throughput is 1559.4023 records/second. Loss is 1.3188663. Sequential266afc8b's hyper parameters: Current learning rate is 3.561253561253561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 46720/60000][Iteration 2710][Wall Clock 263.859190094s] Trained 128 records in 0.087669935 seconds. Throughput is 1460.0217 records/second. Loss is 1.2858948. Sequential266afc8b's hyper parameters: Current learning rate is 3.55998576005696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 46848/60000][Iteration 2711][Wall Clock 263.945999164s] Trained 128 records in 0.08680907 seconds. Throughput is 1474.5004 records/second. Loss is 1.2033389. Sequential266afc8b's hyper parameters: Current learning rate is 3.558718861209964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 46976/60000][Iteration 2712][Wall Clock 264.034726987s] Trained 128 records in 0.088727823 seconds. Throughput is 1442.614 records/second. Loss is 1.1662725. Sequential266afc8b's hyper parameters: Current learning rate is 3.5574528637495557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 47104/60000][Iteration 2713][Wall Clock 264.121008391s] Trained 128 records in 0.086281404 seconds. Throughput is 1483.5178 records/second. Loss is 1.248671. Sequential266afc8b's hyper parameters: Current learning rate is 3.5561877667140827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 47232/60000][Iteration 2714][Wall Clock 264.20910716s] Trained 128 records in 0.088098769 seconds. Throughput is 1452.9147 records/second. Loss is 1.3293697. Sequential266afc8b's hyper parameters: Current learning rate is 3.554923569143264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 47360/60000][Iteration 2715][Wall Clock 264.311571718s] Trained 128 records in 0.102464558 seconds. Throughput is 1249.2124 records/second. Loss is 1.2668058. Sequential266afc8b's hyper parameters: Current learning rate is 3.5536602700781805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 47488/60000][Iteration 2716][Wall Clock 264.403643471s] Trained 128 records in 0.092071753 seconds. Throughput is 1390.22 records/second. Loss is 1.182439. Sequential266afc8b's hyper parameters: Current learning rate is 3.5523978685612787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 47616/60000][Iteration 2717][Wall Clock 264.489206848s] Trained 128 records in 0.085563377 seconds. Throughput is 1495.9672 records/second. Loss is 1.1290483. Sequential266afc8b's hyper parameters: Current learning rate is 3.551136363636364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:43 INFO  DistriOptimizer$:408 - [Epoch 6 47744/60000][Iteration 2718][Wall Clock 264.579507659s] Trained 128 records in 0.090300811 seconds. Throughput is 1417.4845 records/second. Loss is 1.2735662. Sequential266afc8b's hyper parameters: Current learning rate is 3.549875754348598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 47872/60000][Iteration 2719][Wall Clock 264.666926233s] Trained 128 records in 0.087418574 seconds. Throughput is 1464.2197 records/second. Loss is 1.2100419. Sequential266afc8b's hyper parameters: Current learning rate is 3.5486160397445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48000/60000][Iteration 2720][Wall Clock 264.757037828s] Trained 128 records in 0.090111595 seconds. Throughput is 1420.4608 records/second. Loss is 1.2626075. Sequential266afc8b's hyper parameters: Current learning rate is 3.54735721887194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48128/60000][Iteration 2721][Wall Clock 264.843550105s] Trained 128 records in 0.086512277 seconds. Throughput is 1479.5588 records/second. Loss is 1.247274. Sequential266afc8b's hyper parameters: Current learning rate is 3.546099290780142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48256/60000][Iteration 2722][Wall Clock 264.929957787s] Trained 128 records in 0.086407682 seconds. Throughput is 1481.3497 records/second. Loss is 1.1897782. Sequential266afc8b's hyper parameters: Current learning rate is 3.544842254519674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48384/60000][Iteration 2723][Wall Clock 265.01745729s] Trained 128 records in 0.087499503 seconds. Throughput is 1462.8655 records/second. Loss is 1.2883428. Sequential266afc8b's hyper parameters: Current learning rate is 3.5435861091424523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48512/60000][Iteration 2724][Wall Clock 265.101237157s] Trained 128 records in 0.083779867 seconds. Throughput is 1527.8134 records/second. Loss is 1.3717197. Sequential266afc8b's hyper parameters: Current learning rate is 3.5423308537017357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48640/60000][Iteration 2725][Wall Clock 265.186296815s] Trained 128 records in 0.085059658 seconds. Throughput is 1504.8262 records/second. Loss is 1.25935. Sequential266afc8b's hyper parameters: Current learning rate is 3.5410764872521243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48768/60000][Iteration 2726][Wall Clock 265.279868525s] Trained 128 records in 0.09357171 seconds. Throughput is 1367.9348 records/second. Loss is 1.3733971. Sequential266afc8b's hyper parameters: Current learning rate is 3.5398230088495576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 48896/60000][Iteration 2727][Wall Clock 265.373423354s] Trained 128 records in 0.093554829 seconds. Throughput is 1368.1816 records/second. Loss is 1.2040913. Sequential266afc8b's hyper parameters: Current learning rate is 3.5385704175513094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 49024/60000][Iteration 2728][Wall Clock 265.452819282s] Trained 128 records in 0.079395928 seconds. Throughput is 1612.1733 records/second. Loss is 1.2585944. Sequential266afc8b's hyper parameters: Current learning rate is 3.5373187124159886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 49152/60000][Iteration 2729][Wall Clock 265.540157497s] Trained 128 records in 0.087338215 seconds. Throughput is 1465.5669 records/second. Loss is 1.2446103. Sequential266afc8b's hyper parameters: Current learning rate is 3.536067892503536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:44 INFO  DistriOptimizer$:408 - [Epoch 6 49280/60000][Iteration 2730][Wall Clock 265.627597439s] Trained 128 records in 0.087439942 seconds. Throughput is 1463.8619 records/second. Loss is 1.277329. Sequential266afc8b's hyper parameters: Current learning rate is 3.534817956875221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 49408/60000][Iteration 2731][Wall Clock 265.721711673s] Trained 128 records in 0.094114234 seconds. Throughput is 1360.0493 records/second. Loss is 1.2213565. Sequential266afc8b's hyper parameters: Current learning rate is 3.5335689045936394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 49536/60000][Iteration 2732][Wall Clock 265.811639428s] Trained 128 records in 0.089927755 seconds. Throughput is 1423.3647 records/second. Loss is 1.2501484. Sequential266afc8b's hyper parameters: Current learning rate is 3.5323207347227127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 49664/60000][Iteration 2733][Wall Clock 265.924951452s] Trained 128 records in 0.113312024 seconds. Throughput is 1129.6241 records/second. Loss is 1.2322652. Sequential266afc8b's hyper parameters: Current learning rate is 3.5310734463276836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 49792/60000][Iteration 2734][Wall Clock 266.011710828s] Trained 128 records in 0.086759376 seconds. Throughput is 1475.3448 records/second. Loss is 1.3062073. Sequential266afc8b's hyper parameters: Current learning rate is 3.5298270384751147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 49920/60000][Iteration 2735][Wall Clock 266.101786558s] Trained 128 records in 0.09007573 seconds. Throughput is 1421.0265 records/second. Loss is 1.297097. Sequential266afc8b's hyper parameters: Current learning rate is 3.5285815102328866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 50048/60000][Iteration 2736][Wall Clock 266.200001829s] Trained 128 records in 0.098215271 seconds. Throughput is 1303.2596 records/second. Loss is 1.2084162. Sequential266afc8b's hyper parameters: Current learning rate is 3.5273368606701937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 50176/60000][Iteration 2737][Wall Clock 266.2898947s] Trained 128 records in 0.089892871 seconds. Throughput is 1423.9171 records/second. Loss is 1.3967718. Sequential266afc8b's hyper parameters: Current learning rate is 3.526093088857546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 50304/60000][Iteration 2738][Wall Clock 266.401453718s] Trained 128 records in 0.111559018 seconds. Throughput is 1147.3748 records/second. Loss is 1.259956. Sequential266afc8b's hyper parameters: Current learning rate is 3.5248501938667606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 50432/60000][Iteration 2739][Wall Clock 266.495687145s] Trained 128 records in 0.094233427 seconds. Throughput is 1358.3291 records/second. Loss is 1.2998291. Sequential266afc8b's hyper parameters: Current learning rate is 3.5236081747709656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:45 INFO  DistriOptimizer$:408 - [Epoch 6 50560/60000][Iteration 2740][Wall Clock 266.617283259s] Trained 128 records in 0.121596114 seconds. Throughput is 1052.6653 records/second. Loss is 1.1710668. Sequential266afc8b's hyper parameters: Current learning rate is 3.522367030644593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 50688/60000][Iteration 2741][Wall Clock 266.729413925s] Trained 128 records in 0.112130666 seconds. Throughput is 1141.5254 records/second. Loss is 1.3459566. Sequential266afc8b's hyper parameters: Current learning rate is 3.52112676056338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 50816/60000][Iteration 2742][Wall Clock 266.84765957s] Trained 128 records in 0.118245645 seconds. Throughput is 1082.4923 records/second. Loss is 1.2222489. Sequential266afc8b's hyper parameters: Current learning rate is 3.5198873636043646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 50944/60000][Iteration 2743][Wall Clock 266.93998727s] Trained 128 records in 0.0923277 seconds. Throughput is 1386.3662 records/second. Loss is 1.2705363. Sequential266afc8b's hyper parameters: Current learning rate is 3.518648838845883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51072/60000][Iteration 2744][Wall Clock 267.02803079s] Trained 128 records in 0.08804352 seconds. Throughput is 1453.8265 records/second. Loss is 1.2955571. Sequential266afc8b's hyper parameters: Current learning rate is 3.5174111853675694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51200/60000][Iteration 2745][Wall Clock 267.11355726s] Trained 128 records in 0.08552647 seconds. Throughput is 1496.6128 records/second. Loss is 1.1889311. Sequential266afc8b's hyper parameters: Current learning rate is 3.5161744022503517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51328/60000][Iteration 2746][Wall Clock 267.201454062s] Trained 128 records in 0.087896802 seconds. Throughput is 1456.2532 records/second. Loss is 1.2122768. Sequential266afc8b's hyper parameters: Current learning rate is 3.51493848857645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51456/60000][Iteration 2747][Wall Clock 267.287273791s] Trained 128 records in 0.085819729 seconds. Throughput is 1491.4985 records/second. Loss is 1.2526072. Sequential266afc8b's hyper parameters: Current learning rate is 3.5137034434293746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51584/60000][Iteration 2748][Wall Clock 267.37324171s] Trained 128 records in 0.085967919 seconds. Throughput is 1488.9275 records/second. Loss is 1.1494555. Sequential266afc8b's hyper parameters: Current learning rate is 3.512469265893924E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51712/60000][Iteration 2749][Wall Clock 267.459145738s] Trained 128 records in 0.085904028 seconds. Throughput is 1490.0349 records/second. Loss is 1.2871039. Sequential266afc8b's hyper parameters: Current learning rate is 3.5112359550561797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:46 INFO  DistriOptimizer$:408 - [Epoch 6 51840/60000][Iteration 2750][Wall Clock 267.562350292s] Trained 128 records in 0.103204554 seconds. Throughput is 1240.2554 records/second. Loss is 1.292197. Sequential266afc8b's hyper parameters: Current learning rate is 3.51000351000351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 51968/60000][Iteration 2751][Wall Clock 267.650404179s] Trained 128 records in 0.088053887 seconds. Throughput is 1453.6553 records/second. Loss is 1.2675408. Sequential266afc8b's hyper parameters: Current learning rate is 3.5087719298245617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52096/60000][Iteration 2752][Wall Clock 267.771672741s] Trained 128 records in 0.121268562 seconds. Throughput is 1055.5085 records/second. Loss is 1.2356298. Sequential266afc8b's hyper parameters: Current learning rate is 3.5075412136092597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52224/60000][Iteration 2753][Wall Clock 267.857009558s] Trained 128 records in 0.085336817 seconds. Throughput is 1499.9387 records/second. Loss is 1.3352449. Sequential266afc8b's hyper parameters: Current learning rate is 3.506311360448808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52352/60000][Iteration 2754][Wall Clock 267.94541464s] Trained 128 records in 0.088405082 seconds. Throughput is 1447.8806 records/second. Loss is 1.289607. Sequential266afc8b's hyper parameters: Current learning rate is 3.5050823694356814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52480/60000][Iteration 2755][Wall Clock 268.03676046s] Trained 128 records in 0.09134582 seconds. Throughput is 1401.2683 records/second. Loss is 1.1995002. Sequential266afc8b's hyper parameters: Current learning rate is 3.5038542396636303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52608/60000][Iteration 2756][Wall Clock 268.121423642s] Trained 128 records in 0.084663182 seconds. Throughput is 1511.8733 records/second. Loss is 1.3148041. Sequential266afc8b's hyper parameters: Current learning rate is 3.502626970227671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52736/60000][Iteration 2757][Wall Clock 268.208615353s] Trained 128 records in 0.087191711 seconds. Throughput is 1468.0295 records/second. Loss is 1.3074602. Sequential266afc8b's hyper parameters: Current learning rate is 3.5014005602240897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52864/60000][Iteration 2758][Wall Clock 268.298335296s] Trained 128 records in 0.089719943 seconds. Throughput is 1426.6616 records/second. Loss is 1.2621632. Sequential266afc8b's hyper parameters: Current learning rate is 3.5001750087504374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 52992/60000][Iteration 2759][Wall Clock 268.385224401s] Trained 128 records in 0.086889105 seconds. Throughput is 1473.1421 records/second. Loss is 1.3921628. Sequential266afc8b's hyper parameters: Current learning rate is 3.498950314905528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 53120/60000][Iteration 2760][Wall Clock 268.475410637s] Trained 128 records in 0.090186236 seconds. Throughput is 1419.2853 records/second. Loss is 1.2716886. Sequential266afc8b's hyper parameters: Current learning rate is 3.497726477789437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:47 INFO  DistriOptimizer$:408 - [Epoch 6 53248/60000][Iteration 2761][Wall Clock 268.560067716s] Trained 128 records in 0.084657079 seconds. Throughput is 1511.9822 records/second. Loss is 1.177876. Sequential266afc8b's hyper parameters: Current learning rate is 3.4965034965034965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 53376/60000][Iteration 2762][Wall Clock 268.645821016s] Trained 128 records in 0.0857533 seconds. Throughput is 1492.6539 records/second. Loss is 1.3084552. Sequential266afc8b's hyper parameters: Current learning rate is 3.4952813701502974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 53504/60000][Iteration 2763][Wall Clock 268.735816641s] Trained 128 records in 0.089995625 seconds. Throughput is 1422.2914 records/second. Loss is 1.3406086. Sequential266afc8b's hyper parameters: Current learning rate is 3.4940600978336826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 53632/60000][Iteration 2764][Wall Clock 268.825618353s] Trained 128 records in 0.089801712 seconds. Throughput is 1425.3625 records/second. Loss is 1.2164537. Sequential266afc8b's hyper parameters: Current learning rate is 3.49283967865875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 53760/60000][Iteration 2765][Wall Clock 268.911900771s] Trained 128 records in 0.086282418 seconds. Throughput is 1483.5004 records/second. Loss is 1.2045932. Sequential266afc8b's hyper parameters: Current learning rate is 3.4916201117318437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 53888/60000][Iteration 2766][Wall Clock 268.995510192s] Trained 128 records in 0.083609421 seconds. Throughput is 1530.9279 records/second. Loss is 1.3341459. Sequential266afc8b's hyper parameters: Current learning rate is 3.490401396160558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54016/60000][Iteration 2767][Wall Clock 269.072931727s] Trained 128 records in 0.077421535 seconds. Throughput is 1653.2867 records/second. Loss is 1.2548312. Sequential266afc8b's hyper parameters: Current learning rate is 3.489183531053734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54144/60000][Iteration 2768][Wall Clock 269.154113804s] Trained 128 records in 0.081182077 seconds. Throughput is 1576.7026 records/second. Loss is 1.2870923. Sequential266afc8b's hyper parameters: Current learning rate is 3.487966515521451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54272/60000][Iteration 2769][Wall Clock 269.236986114s] Trained 128 records in 0.08287231 seconds. Throughput is 1544.5449 records/second. Loss is 1.2821492. Sequential266afc8b's hyper parameters: Current learning rate is 3.486750348675035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54400/60000][Iteration 2770][Wall Clock 269.322029778s] Trained 128 records in 0.085043664 seconds. Throughput is 1505.1093 records/second. Loss is 1.2084392. Sequential266afc8b's hyper parameters: Current learning rate is 3.485535029627048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54528/60000][Iteration 2771][Wall Clock 269.40752283s] Trained 128 records in 0.085493052 seconds. Throughput is 1497.1978 records/second. Loss is 1.2681628. Sequential266afc8b's hyper parameters: Current learning rate is 3.484320557491289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54656/60000][Iteration 2772][Wall Clock 269.489876083s] Trained 128 records in 0.082353253 seconds. Throughput is 1554.2798 records/second. Loss is 1.1839354. Sequential266afc8b's hyper parameters: Current learning rate is 3.4831069313827936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:48 INFO  DistriOptimizer$:408 - [Epoch 6 54784/60000][Iteration 2773][Wall Clock 269.574490737s] Trained 128 records in 0.084614654 seconds. Throughput is 1512.7402 records/second. Loss is 1.3164668. Sequential266afc8b's hyper parameters: Current learning rate is 3.4818941504178273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 54912/60000][Iteration 2774][Wall Clock 269.660138868s] Trained 128 records in 0.085648131 seconds. Throughput is 1494.4867 records/second. Loss is 1.3363582. Sequential266afc8b's hyper parameters: Current learning rate is 3.480682213713888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55040/60000][Iteration 2775][Wall Clock 269.751844935s] Trained 128 records in 0.091706067 seconds. Throughput is 1395.7637 records/second. Loss is 1.2100059. Sequential266afc8b's hyper parameters: Current learning rate is 3.4794711203897004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55168/60000][Iteration 2776][Wall Clock 269.839151431s] Trained 128 records in 0.087306496 seconds. Throughput is 1466.0994 records/second. Loss is 1.223451. Sequential266afc8b's hyper parameters: Current learning rate is 3.4782608695652176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55296/60000][Iteration 2777][Wall Clock 269.927089126s] Trained 128 records in 0.087937695 seconds. Throughput is 1455.5759 records/second. Loss is 1.3431946. Sequential266afc8b's hyper parameters: Current learning rate is 3.477051460361613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55424/60000][Iteration 2778][Wall Clock 270.020599203s] Trained 128 records in 0.093510077 seconds. Throughput is 1368.8364 records/second. Loss is 1.2399546. Sequential266afc8b's hyper parameters: Current learning rate is 3.475842891901286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55552/60000][Iteration 2779][Wall Clock 270.108480916s] Trained 128 records in 0.087881713 seconds. Throughput is 1456.5032 records/second. Loss is 1.2163366. Sequential266afc8b's hyper parameters: Current learning rate is 3.4746351633078526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55680/60000][Iteration 2780][Wall Clock 270.187658365s] Trained 128 records in 0.079177449 seconds. Throughput is 1616.622 records/second. Loss is 1.3131331. Sequential266afc8b's hyper parameters: Current learning rate is 3.4734282737061483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55808/60000][Iteration 2781][Wall Clock 270.275467311s] Trained 128 records in 0.087808946 seconds. Throughput is 1457.7103 records/second. Loss is 1.2931008. Sequential266afc8b's hyper parameters: Current learning rate is 3.4722222222222224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 55936/60000][Iteration 2782][Wall Clock 270.358362993s] Trained 128 records in 0.082895682 seconds. Throughput is 1544.1094 records/second. Loss is 1.2851473. Sequential266afc8b's hyper parameters: Current learning rate is 3.471017007983339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 56064/60000][Iteration 2783][Wall Clock 270.443784425s] Trained 128 records in 0.085421432 seconds. Throughput is 1498.4529 records/second. Loss is 1.2438834. Sequential266afc8b's hyper parameters: Current learning rate is 3.4698126301179735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:49 INFO  DistriOptimizer$:408 - [Epoch 6 56192/60000][Iteration 2784][Wall Clock 270.531798694s] Trained 128 records in 0.088014269 seconds. Throughput is 1454.3097 records/second. Loss is 1.2382189. Sequential266afc8b's hyper parameters: Current learning rate is 3.46860908775581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 56320/60000][Iteration 2785][Wall Clock 270.617624345s] Trained 128 records in 0.085825651 seconds. Throughput is 1491.3956 records/second. Loss is 1.2817698. Sequential266afc8b's hyper parameters: Current learning rate is 3.4674063800277393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 56448/60000][Iteration 2786][Wall Clock 270.704587588s] Trained 128 records in 0.086963243 seconds. Throughput is 1471.8862 records/second. Loss is 1.1549741. Sequential266afc8b's hyper parameters: Current learning rate is 3.466204506065858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 56576/60000][Iteration 2787][Wall Clock 270.789866446s] Trained 128 records in 0.085278858 seconds. Throughput is 1500.9581 records/second. Loss is 1.2831415. Sequential266afc8b's hyper parameters: Current learning rate is 3.465003465003465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 56704/60000][Iteration 2788][Wall Clock 270.876009549s] Trained 128 records in 0.086143103 seconds. Throughput is 1485.8995 records/second. Loss is 1.300334. Sequential266afc8b's hyper parameters: Current learning rate is 3.4638032559750607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 56832/60000][Iteration 2789][Wall Clock 270.960561793s] Trained 128 records in 0.084552244 seconds. Throughput is 1513.8569 records/second. Loss is 1.3098596. Sequential266afc8b's hyper parameters: Current learning rate is 3.4626038781163435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 56960/60000][Iteration 2790][Wall Clock 271.06028748s] Trained 128 records in 0.099725687 seconds. Throughput is 1283.5209 records/second. Loss is 1.362331. Sequential266afc8b's hyper parameters: Current learning rate is 3.4614053305642093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 57088/60000][Iteration 2791][Wall Clock 271.14850484s] Trained 128 records in 0.08821736 seconds. Throughput is 1450.9615 records/second. Loss is 1.3737007. Sequential266afc8b's hyper parameters: Current learning rate is 3.4602076124567473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 57216/60000][Iteration 2792][Wall Clock 271.231876951s] Trained 128 records in 0.083372111 seconds. Throughput is 1535.2856 records/second. Loss is 1.2055682. Sequential266afc8b's hyper parameters: Current learning rate is 3.459010722933241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 57344/60000][Iteration 2793][Wall Clock 271.316021223s] Trained 128 records in 0.084144272 seconds. Throughput is 1521.1968 records/second. Loss is 1.2451867. Sequential266afc8b's hyper parameters: Current learning rate is 3.457814661134163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 57472/60000][Iteration 2794][Wall Clock 271.401749603s] Trained 128 records in 0.08572838 seconds. Throughput is 1493.0879 records/second. Loss is 1.2049346. Sequential266afc8b's hyper parameters: Current learning rate is 3.456619426201175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:50 INFO  DistriOptimizer$:408 - [Epoch 6 57600/60000][Iteration 2795][Wall Clock 271.521164944s] Trained 128 records in 0.119415341 seconds. Throughput is 1071.889 records/second. Loss is 1.2889818. Sequential266afc8b's hyper parameters: Current learning rate is 3.455425017277125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 57728/60000][Iteration 2796][Wall Clock 271.610701957s] Trained 128 records in 0.089537013 seconds. Throughput is 1429.5764 records/second. Loss is 1.2875813. Sequential266afc8b's hyper parameters: Current learning rate is 3.4542314335060453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 57856/60000][Iteration 2797][Wall Clock 271.697694431s] Trained 128 records in 0.086992474 seconds. Throughput is 1471.3917 records/second. Loss is 1.2385014. Sequential266afc8b's hyper parameters: Current learning rate is 3.453038674033149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 57984/60000][Iteration 2798][Wall Clock 271.78582114s] Trained 128 records in 0.088126709 seconds. Throughput is 1452.4541 records/second. Loss is 1.2681544. Sequential266afc8b's hyper parameters: Current learning rate is 3.451846738004833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58112/60000][Iteration 2799][Wall Clock 271.878051912s] Trained 128 records in 0.092230772 seconds. Throughput is 1387.8231 records/second. Loss is 1.2909683. Sequential266afc8b's hyper parameters: Current learning rate is 3.450655624568668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58240/60000][Iteration 2800][Wall Clock 271.971356978s] Trained 128 records in 0.093305066 seconds. Throughput is 1371.844 records/second. Loss is 1.2874957. Sequential266afc8b's hyper parameters: Current learning rate is 3.4494653328734045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58368/60000][Iteration 2801][Wall Clock 272.05754572s] Trained 128 records in 0.086188742 seconds. Throughput is 1485.1128 records/second. Loss is 1.2571094. Sequential266afc8b's hyper parameters: Current learning rate is 3.448275862068966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58496/60000][Iteration 2802][Wall Clock 272.171416229s] Trained 128 records in 0.113870509 seconds. Throughput is 1124.0839 records/second. Loss is 1.2397265. Sequential266afc8b's hyper parameters: Current learning rate is 3.447087211306446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58624/60000][Iteration 2803][Wall Clock 272.265189315s] Trained 128 records in 0.093773086 seconds. Throughput is 1364.9972 records/second. Loss is 1.3276755. Sequential266afc8b's hyper parameters: Current learning rate is 3.4458993797381116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58752/60000][Iteration 2804][Wall Clock 272.387370148s] Trained 128 records in 0.122180833 seconds. Throughput is 1047.6274 records/second. Loss is 1.3202931. Sequential266afc8b's hyper parameters: Current learning rate is 3.4447123665173955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 58880/60000][Iteration 2805][Wall Clock 272.483377643s] Trained 128 records in 0.096007495 seconds. Throughput is 1333.2292 records/second. Loss is 1.2548035. Sequential266afc8b's hyper parameters: Current learning rate is 3.443526170798898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:51 INFO  DistriOptimizer$:408 - [Epoch 6 59008/60000][Iteration 2806][Wall Clock 272.574363812s] Trained 128 records in 0.090986169 seconds. Throughput is 1406.8073 records/second. Loss is 1.2487504. Sequential266afc8b's hyper parameters: Current learning rate is 3.4423407917383823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59136/60000][Iteration 2807][Wall Clock 272.667442332s] Trained 128 records in 0.09307852 seconds. Throughput is 1375.1831 records/second. Loss is 1.1425712. Sequential266afc8b's hyper parameters: Current learning rate is 3.4411562284927734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59264/60000][Iteration 2808][Wall Clock 272.752788212s] Trained 128 records in 0.08534588 seconds. Throughput is 1499.7795 records/second. Loss is 1.1717014. Sequential266afc8b's hyper parameters: Current learning rate is 3.439972480220158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59392/60000][Iteration 2809][Wall Clock 272.842240723s] Trained 128 records in 0.089452511 seconds. Throughput is 1430.9269 records/second. Loss is 1.2514616. Sequential266afc8b's hyper parameters: Current learning rate is 3.43878954607978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59520/60000][Iteration 2810][Wall Clock 272.928126416s] Trained 128 records in 0.085885693 seconds. Throughput is 1490.3529 records/second. Loss is 1.219094. Sequential266afc8b's hyper parameters: Current learning rate is 3.4376074252320387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59648/60000][Iteration 2811][Wall Clock 273.012007546s] Trained 128 records in 0.08388113 seconds. Throughput is 1525.9689 records/second. Loss is 1.2800344. Sequential266afc8b's hyper parameters: Current learning rate is 3.4364261168384877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59776/60000][Iteration 2812][Wall Clock 273.098536426s] Trained 128 records in 0.08652888 seconds. Throughput is 1479.2749 records/second. Loss is 1.1791635. Sequential266afc8b's hyper parameters: Current learning rate is 3.4352456200618345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 59904/60000][Iteration 2813][Wall Clock 273.184213296s] Trained 128 records in 0.08567687 seconds. Throughput is 1493.9855 records/second. Loss is 1.3187286. Sequential266afc8b's hyper parameters: Current learning rate is 3.434065934065934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:408 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 273.272589626s] Trained 128 records in 0.08837633 seconds. Throughput is 1448.3517 records/second. Loss is 1.2397479. Sequential266afc8b's hyper parameters: Current learning rate is 3.4328870580157915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:52 INFO  DistriOptimizer$:452 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 273.272589626s] Epoch finished. Wall clock time is 274600.801193 ms
2019-10-15 08:22:52 INFO  DistriOptimizer$:111 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 273.272589626s] Validate model...
2019-10-15 08:22:53 INFO  DistriOptimizer$:178 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 273.272589626s] validate model throughput is 11980.621 records/second
2019-10-15 08:22:53 INFO  DistriOptimizer$:181 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 273.272589626s] Top1Accuracy is Accuracy(correct: 7269, count: 10000, accuracy: 0.7269)
2019-10-15 08:22:53 INFO  DistriOptimizer$:221 - [Wall Clock 274.600801193s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:22:53 INFO  DistriOptimizer$:226 - [Wall Clock 274.600801193s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:22:53 INFO  DistriOptimizer$:408 - [Epoch 7 128/60000][Iteration 2815][Wall Clock 274.69610996s] Trained 128 records in 0.095308767 seconds. Throughput is 1343.0034 records/second. Loss is 1.3533994. Sequential266afc8b's hyper parameters: Current learning rate is 3.4317089910775565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:53 INFO  DistriOptimizer$:408 - [Epoch 7 256/60000][Iteration 2816][Wall Clock 274.786426731s] Trained 128 records in 0.090316771 seconds. Throughput is 1417.234 records/second. Loss is 1.3534703. Sequential266afc8b's hyper parameters: Current learning rate is 3.4305317324185246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:53 INFO  DistriOptimizer$:408 - [Epoch 7 384/60000][Iteration 2817][Wall Clock 274.876144298s] Trained 128 records in 0.089717567 seconds. Throughput is 1426.6995 records/second. Loss is 1.2739675. Sequential266afc8b's hyper parameters: Current learning rate is 3.4293552812071334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:53 INFO  DistriOptimizer$:408 - [Epoch 7 512/60000][Iteration 2818][Wall Clock 274.96050276s] Trained 128 records in 0.084358462 seconds. Throughput is 1517.3345 records/second. Loss is 1.1481128. Sequential266afc8b's hyper parameters: Current learning rate is 3.428179636612958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 640/60000][Iteration 2819][Wall Clock 275.045773746s] Trained 128 records in 0.085270986 seconds. Throughput is 1501.0968 records/second. Loss is 1.3272355. Sequential266afc8b's hyper parameters: Current learning rate is 3.427004797806717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 768/60000][Iteration 2820][Wall Clock 275.131696515s] Trained 128 records in 0.085922769 seconds. Throughput is 1489.7098 records/second. Loss is 1.3087927. Sequential266afc8b's hyper parameters: Current learning rate is 3.4258307639602604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 896/60000][Iteration 2821][Wall Clock 275.217216378s] Trained 128 records in 0.085519863 seconds. Throughput is 1496.7283 records/second. Loss is 1.2860485. Sequential266afc8b's hyper parameters: Current learning rate is 3.4246575342465754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1024/60000][Iteration 2822][Wall Clock 275.29942243s] Trained 128 records in 0.082206052 seconds. Throughput is 1557.0629 records/second. Loss is 1.2301263. Sequential266afc8b's hyper parameters: Current learning rate is 3.4234851078397807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1152/60000][Iteration 2823][Wall Clock 275.385023028s] Trained 128 records in 0.085600598 seconds. Throughput is 1495.3167 records/second. Loss is 1.19666. Sequential266afc8b's hyper parameters: Current learning rate is 3.4223134839151266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1280/60000][Iteration 2824][Wall Clock 275.469783644s] Trained 128 records in 0.084760616 seconds. Throughput is 1510.1354 records/second. Loss is 1.3328896. Sequential266afc8b's hyper parameters: Current learning rate is 3.4211426616489907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1408/60000][Iteration 2825][Wall Clock 275.555663309s] Trained 128 records in 0.085879665 seconds. Throughput is 1490.4575 records/second. Loss is 1.1737571. Sequential266afc8b's hyper parameters: Current learning rate is 3.419972640218878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1536/60000][Iteration 2826][Wall Clock 275.641362387s] Trained 128 records in 0.085699078 seconds. Throughput is 1493.5983 records/second. Loss is 1.2758474. Sequential266afc8b's hyper parameters: Current learning rate is 3.418803418803419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1664/60000][Iteration 2827][Wall Clock 275.731830288s] Trained 128 records in 0.090467901 seconds. Throughput is 1414.8665 records/second. Loss is 1.1518216. Sequential266afc8b's hyper parameters: Current learning rate is 3.4176349965823647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1792/60000][Iteration 2828][Wall Clock 275.817555233s] Trained 128 records in 0.085724945 seconds. Throughput is 1493.1477 records/second. Loss is 1.3212436. Sequential266afc8b's hyper parameters: Current learning rate is 3.4164673727365904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:54 INFO  DistriOptimizer$:408 - [Epoch 7 1920/60000][Iteration 2829][Wall Clock 275.921210323s] Trained 128 records in 0.10365509 seconds. Throughput is 1234.8645 records/second. Loss is 1.2935579. Sequential266afc8b's hyper parameters: Current learning rate is 3.4153005464480874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2048/60000][Iteration 2830][Wall Clock 276.007230371s] Trained 128 records in 0.086020048 seconds. Throughput is 1488.0253 records/second. Loss is 1.2695432. Sequential266afc8b's hyper parameters: Current learning rate is 3.414134516899966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2176/60000][Iteration 2831][Wall Clock 276.094496369s] Trained 128 records in 0.087265998 seconds. Throughput is 1466.7798 records/second. Loss is 1.1749351. Sequential266afc8b's hyper parameters: Current learning rate is 3.4129692832764505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2304/60000][Iteration 2832][Wall Clock 276.180752784s] Trained 128 records in 0.086256415 seconds. Throughput is 1483.9476 records/second. Loss is 1.2325795. Sequential266afc8b's hyper parameters: Current learning rate is 3.4118048447628793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2432/60000][Iteration 2833][Wall Clock 276.268099686s] Trained 128 records in 0.087346902 seconds. Throughput is 1465.4211 records/second. Loss is 1.2900057. Sequential266afc8b's hyper parameters: Current learning rate is 3.4106412005457026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2560/60000][Iteration 2834][Wall Clock 276.352566594s] Trained 128 records in 0.084466908 seconds. Throughput is 1515.3865 records/second. Loss is 1.2261678. Sequential266afc8b's hyper parameters: Current learning rate is 3.4094783498124785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2688/60000][Iteration 2835][Wall Clock 276.438090801s] Trained 128 records in 0.085524207 seconds. Throughput is 1496.6522 records/second. Loss is 1.2869174. Sequential266afc8b's hyper parameters: Current learning rate is 3.4083162917518747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2816/60000][Iteration 2836][Wall Clock 276.523235427s] Trained 128 records in 0.085144626 seconds. Throughput is 1503.3245 records/second. Loss is 1.2188346. Sequential266afc8b's hyper parameters: Current learning rate is 3.4071550255536625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 2944/60000][Iteration 2837][Wall Clock 276.611214202s] Trained 128 records in 0.087978775 seconds. Throughput is 1454.8964 records/second. Loss is 1.3462226. Sequential266afc8b's hyper parameters: Current learning rate is 3.405994550408719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 3072/60000][Iteration 2838][Wall Clock 276.698043439s] Trained 128 records in 0.086829237 seconds. Throughput is 1474.1578 records/second. Loss is 1.2380432. Sequential266afc8b's hyper parameters: Current learning rate is 3.4048348655090226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 3200/60000][Iteration 2839][Wall Clock 276.795901601s] Trained 128 records in 0.097858162 seconds. Throughput is 1308.0156 records/second. Loss is 1.2688886. Sequential266afc8b's hyper parameters: Current learning rate is 3.403675970047652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 3328/60000][Iteration 2840][Wall Clock 276.879379079s] Trained 128 records in 0.083477478 seconds. Throughput is 1533.3478 records/second. Loss is 1.324511. Sequential266afc8b's hyper parameters: Current learning rate is 3.402517863218782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:55 INFO  DistriOptimizer$:408 - [Epoch 7 3456/60000][Iteration 2841][Wall Clock 276.964295316s] Trained 128 records in 0.084916237 seconds. Throughput is 1507.3678 records/second. Loss is 1.2376122. Sequential266afc8b's hyper parameters: Current learning rate is 3.401360544217687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 3584/60000][Iteration 2842][Wall Clock 277.051275233s] Trained 128 records in 0.086979917 seconds. Throughput is 1471.604 records/second. Loss is 1.1996888. Sequential266afc8b's hyper parameters: Current learning rate is 3.4002040122407346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 3712/60000][Iteration 2843][Wall Clock 277.140878744s] Trained 128 records in 0.089603511 seconds. Throughput is 1428.5154 records/second. Loss is 1.3075377. Sequential266afc8b's hyper parameters: Current learning rate is 3.399048266485384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 3840/60000][Iteration 2844][Wall Clock 277.22737449s] Trained 128 records in 0.086495746 seconds. Throughput is 1479.8416 records/second. Loss is 1.1886252. Sequential266afc8b's hyper parameters: Current learning rate is 3.397893306150187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 3968/60000][Iteration 2845][Wall Clock 277.311865865s] Trained 128 records in 0.084491375 seconds. Throughput is 1514.9476 records/second. Loss is 1.2365141. Sequential266afc8b's hyper parameters: Current learning rate is 3.3967391304347825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4096/60000][Iteration 2846][Wall Clock 277.399833479s] Trained 128 records in 0.087967614 seconds. Throughput is 1455.0809 records/second. Loss is 1.2719154. Sequential266afc8b's hyper parameters: Current learning rate is 3.3955857385398983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4224/60000][Iteration 2847][Wall Clock 277.489757621s] Trained 128 records in 0.089924142 seconds. Throughput is 1423.422 records/second. Loss is 1.256804. Sequential266afc8b's hyper parameters: Current learning rate is 3.3944331296673454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4352/60000][Iteration 2848][Wall Clock 277.575491191s] Trained 128 records in 0.08573357 seconds. Throughput is 1492.9974 records/second. Loss is 1.185419. Sequential266afc8b's hyper parameters: Current learning rate is 3.3932813030200206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4480/60000][Iteration 2849][Wall Clock 277.660948511s] Trained 128 records in 0.08545732 seconds. Throughput is 1497.8237 records/second. Loss is 1.2783426. Sequential266afc8b's hyper parameters: Current learning rate is 3.3921302578019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4608/60000][Iteration 2850][Wall Clock 277.744132816s] Trained 128 records in 0.083184305 seconds. Throughput is 1538.7518 records/second. Loss is 1.2577845. Sequential266afc8b's hyper parameters: Current learning rate is 3.39097999321804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4736/60000][Iteration 2851][Wall Clock 277.825653772s] Trained 128 records in 0.081520956 seconds. Throughput is 1570.1484 records/second. Loss is 1.2197733. Sequential266afc8b's hyper parameters: Current learning rate is 3.3898305084745765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:56 INFO  DistriOptimizer$:408 - [Epoch 7 4864/60000][Iteration 2852][Wall Clock 277.911722269s] Trained 128 records in 0.086068497 seconds. Throughput is 1487.1876 records/second. Loss is 1.2627224. Sequential266afc8b's hyper parameters: Current learning rate is 3.388681802778719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 4992/60000][Iteration 2853][Wall Clock 277.998520421s] Trained 128 records in 0.086798152 seconds. Throughput is 1474.6858 records/second. Loss is 1.3538381. Sequential266afc8b's hyper parameters: Current learning rate is 3.3875338753387534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5120/60000][Iteration 2854][Wall Clock 278.085482911s] Trained 128 records in 0.08696249 seconds. Throughput is 1471.8989 records/second. Loss is 1.2243896. Sequential266afc8b's hyper parameters: Current learning rate is 3.386386725364037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5248/60000][Iteration 2855][Wall Clock 278.18166664s] Trained 128 records in 0.096183729 seconds. Throughput is 1330.7864 records/second. Loss is 1.2628897. Sequential266afc8b's hyper parameters: Current learning rate is 3.385240352064997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5376/60000][Iteration 2856][Wall Clock 278.265014841s] Trained 128 records in 0.083348201 seconds. Throughput is 1535.7261 records/second. Loss is 1.2927098. Sequential266afc8b's hyper parameters: Current learning rate is 3.3840947546531303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5504/60000][Iteration 2857][Wall Clock 278.349721966s] Trained 128 records in 0.084707125 seconds. Throughput is 1511.0889 records/second. Loss is 1.2352034. Sequential266afc8b's hyper parameters: Current learning rate is 3.382949932341001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5632/60000][Iteration 2858][Wall Clock 278.432560333s] Trained 128 records in 0.082838367 seconds. Throughput is 1545.1777 records/second. Loss is 1.1829187. Sequential266afc8b's hyper parameters: Current learning rate is 3.3818058843422386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5760/60000][Iteration 2859][Wall Clock 278.518142041s] Trained 128 records in 0.085581708 seconds. Throughput is 1495.6467 records/second. Loss is 1.239862. Sequential266afc8b's hyper parameters: Current learning rate is 3.380662609871535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 5888/60000][Iteration 2860][Wall Clock 278.605627609s] Trained 128 records in 0.087485568 seconds. Throughput is 1463.0985 records/second. Loss is 1.22821. Sequential266afc8b's hyper parameters: Current learning rate is 3.379520108144644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 6016/60000][Iteration 2861][Wall Clock 278.693435883s] Trained 128 records in 0.087808274 seconds. Throughput is 1457.7214 records/second. Loss is 1.21232. Sequential266afc8b's hyper parameters: Current learning rate is 3.378378378378378E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 6144/60000][Iteration 2862][Wall Clock 278.781798947s] Trained 128 records in 0.088363064 seconds. Throughput is 1448.569 records/second. Loss is 1.3204365. Sequential266afc8b's hyper parameters: Current learning rate is 3.3772374197906115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 6272/60000][Iteration 2863][Wall Clock 278.866905131s] Trained 128 records in 0.085106184 seconds. Throughput is 1504.0034 records/second. Loss is 1.2620887. Sequential266afc8b's hyper parameters: Current learning rate is 3.37609723160027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:57 INFO  DistriOptimizer$:408 - [Epoch 7 6400/60000][Iteration 2864][Wall Clock 278.958550317s] Trained 128 records in 0.091645186 seconds. Throughput is 1396.6909 records/second. Loss is 1.2270998. Sequential266afc8b's hyper parameters: Current learning rate is 3.374957813027337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 6528/60000][Iteration 2865][Wall Clock 279.042205377s] Trained 128 records in 0.08365506 seconds. Throughput is 1530.0928 records/second. Loss is 1.354867. Sequential266afc8b's hyper parameters: Current learning rate is 3.3738191632928474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 6656/60000][Iteration 2866][Wall Clock 279.129513406s] Trained 128 records in 0.087308029 seconds. Throughput is 1466.0737 records/second. Loss is 1.2311585. Sequential266afc8b's hyper parameters: Current learning rate is 3.372681281618887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 6784/60000][Iteration 2867][Wall Clock 279.213977109s] Trained 128 records in 0.084463703 seconds. Throughput is 1515.4438 records/second. Loss is 1.2754009. Sequential266afc8b's hyper parameters: Current learning rate is 3.3715441672285906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 6912/60000][Iteration 2868][Wall Clock 279.299195332s] Trained 128 records in 0.085218223 seconds. Throughput is 1502.0262 records/second. Loss is 1.2808022. Sequential266afc8b's hyper parameters: Current learning rate is 3.370407819346141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7040/60000][Iteration 2869][Wall Clock 279.385854174s] Trained 128 records in 0.086658842 seconds. Throughput is 1477.0564 records/second. Loss is 1.2575835. Sequential266afc8b's hyper parameters: Current learning rate is 3.3692722371967657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7168/60000][Iteration 2870][Wall Clock 279.475455367s] Trained 128 records in 0.089601193 seconds. Throughput is 1428.5524 records/second. Loss is 1.2000692. Sequential266afc8b's hyper parameters: Current learning rate is 3.368137420006736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7296/60000][Iteration 2871][Wall Clock 279.561766755s] Trained 128 records in 0.086311388 seconds. Throughput is 1483.0026 records/second. Loss is 1.3000817. Sequential266afc8b's hyper parameters: Current learning rate is 3.367003367003367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7424/60000][Iteration 2872][Wall Clock 279.647918645s] Trained 128 records in 0.08615189 seconds. Throughput is 1485.748 records/second. Loss is 1.282479. Sequential266afc8b's hyper parameters: Current learning rate is 3.365870077415012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7552/60000][Iteration 2873][Wall Clock 279.731000277s] Trained 128 records in 0.083081632 seconds. Throughput is 1540.6534 records/second. Loss is 1.2826804. Sequential266afc8b's hyper parameters: Current learning rate is 3.3647375504710633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7680/60000][Iteration 2874][Wall Clock 279.816668763s] Trained 128 records in 0.085668486 seconds. Throughput is 1494.1316 records/second. Loss is 1.1619521. Sequential266afc8b's hyper parameters: Current learning rate is 3.363605785401951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:58 INFO  DistriOptimizer$:408 - [Epoch 7 7808/60000][Iteration 2875][Wall Clock 279.905110638s] Trained 128 records in 0.088441875 seconds. Throughput is 1447.2782 records/second. Loss is 1.2789245. Sequential266afc8b's hyper parameters: Current learning rate is 3.362474781439139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 7936/60000][Iteration 2876][Wall Clock 279.99286854s] Trained 128 records in 0.087757902 seconds. Throughput is 1458.5581 records/second. Loss is 1.2773887. Sequential266afc8b's hyper parameters: Current learning rate is 3.361344537815126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8064/60000][Iteration 2877][Wall Clock 280.07819894s] Trained 128 records in 0.0853304 seconds. Throughput is 1500.0516 records/second. Loss is 1.2076675. Sequential266afc8b's hyper parameters: Current learning rate is 3.3602150537634406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8192/60000][Iteration 2878][Wall Clock 280.169015826s] Trained 128 records in 0.090816886 seconds. Throughput is 1409.4296 records/second. Loss is 1.2496425. Sequential266afc8b's hyper parameters: Current learning rate is 3.359086328518643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8320/60000][Iteration 2879][Wall Clock 280.256257452s] Trained 128 records in 0.087241626 seconds. Throughput is 1467.1895 records/second. Loss is 1.2293925. Sequential266afc8b's hyper parameters: Current learning rate is 3.35795836131632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8448/60000][Iteration 2880][Wall Clock 280.342363739s] Trained 128 records in 0.086106287 seconds. Throughput is 1486.5349 records/second. Loss is 1.2993876. Sequential266afc8b's hyper parameters: Current learning rate is 3.356831151393085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8576/60000][Iteration 2881][Wall Clock 280.441145738s] Trained 128 records in 0.098781999 seconds. Throughput is 1295.7827 records/second. Loss is 1.2750432. Sequential266afc8b's hyper parameters: Current learning rate is 3.355704697986577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8704/60000][Iteration 2882][Wall Clock 280.530159207s] Trained 128 records in 0.089013469 seconds. Throughput is 1437.9846 records/second. Loss is 1.2210417. Sequential266afc8b's hyper parameters: Current learning rate is 3.354579000335458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8832/60000][Iteration 2883][Wall Clock 280.617654985s] Trained 128 records in 0.087495778 seconds. Throughput is 1462.9276 records/second. Loss is 1.3526464. Sequential266afc8b's hyper parameters: Current learning rate is 3.3534540576794097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 8960/60000][Iteration 2884][Wall Clock 280.699384961s] Trained 128 records in 0.081729976 seconds. Throughput is 1566.1328 records/second. Loss is 1.2318548. Sequential266afc8b's hyper parameters: Current learning rate is 3.352329869259135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 9088/60000][Iteration 2885][Wall Clock 280.789283282s] Trained 128 records in 0.089898321 seconds. Throughput is 1423.8308 records/second. Loss is 1.2248087. Sequential266afc8b's hyper parameters: Current learning rate is 3.351206434316354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:22:59 INFO  DistriOptimizer$:408 - [Epoch 7 9216/60000][Iteration 2886][Wall Clock 280.874813507s] Trained 128 records in 0.085530225 seconds. Throughput is 1496.547 records/second. Loss is 1.3069336. Sequential266afc8b's hyper parameters: Current learning rate is 3.3500837520938025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 9344/60000][Iteration 2887][Wall Clock 280.960312923s] Trained 128 records in 0.085499416 seconds. Throughput is 1497.0863 records/second. Loss is 1.2405999. Sequential266afc8b's hyper parameters: Current learning rate is 3.348961821835231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 9472/60000][Iteration 2888][Wall Clock 281.049350112s] Trained 128 records in 0.089037189 seconds. Throughput is 1437.6016 records/second. Loss is 1.3282208. Sequential266afc8b's hyper parameters: Current learning rate is 3.3478406427854036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 9600/60000][Iteration 2889][Wall Clock 281.130584369s] Trained 128 records in 0.081234257 seconds. Throughput is 1575.69 records/second. Loss is 1.1888478. Sequential266afc8b's hyper parameters: Current learning rate is 3.346720214190094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 9728/60000][Iteration 2890][Wall Clock 281.215174699s] Trained 128 records in 0.08459033 seconds. Throughput is 1513.1753 records/second. Loss is 1.2725425. Sequential266afc8b's hyper parameters: Current learning rate is 3.3456005352960856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 9856/60000][Iteration 2891][Wall Clock 281.302575596s] Trained 128 records in 0.087400897 seconds. Throughput is 1464.5159 records/second. Loss is 1.3252269. Sequential266afc8b's hyper parameters: Current learning rate is 3.3444816053511704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 9984/60000][Iteration 2892][Wall Clock 281.390589432s] Trained 128 records in 0.088013836 seconds. Throughput is 1454.3168 records/second. Loss is 1.2425194. Sequential266afc8b's hyper parameters: Current learning rate is 3.3433634236041456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 10112/60000][Iteration 2893][Wall Clock 281.477733641s] Trained 128 records in 0.087144209 seconds. Throughput is 1468.8296 records/second. Loss is 1.2489716. Sequential266afc8b's hyper parameters: Current learning rate is 3.3422459893048126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 10240/60000][Iteration 2894][Wall Clock 281.569520626s] Trained 128 records in 0.091786985 seconds. Throughput is 1394.5332 records/second. Loss is 1.2824546. Sequential266afc8b's hyper parameters: Current learning rate is 3.341129301703976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 10368/60000][Iteration 2895][Wall Clock 281.656394147s] Trained 128 records in 0.086873521 seconds. Throughput is 1473.4064 records/second. Loss is 1.3300546. Sequential266afc8b's hyper parameters: Current learning rate is 3.34001336005344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 10496/60000][Iteration 2896][Wall Clock 281.736946075s] Trained 128 records in 0.080551928 seconds. Throughput is 1589.037 records/second. Loss is 1.3538566. Sequential266afc8b's hyper parameters: Current learning rate is 3.33889816360601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 10624/60000][Iteration 2897][Wall Clock 281.823706875s] Trained 128 records in 0.0867608 seconds. Throughput is 1475.3207 records/second. Loss is 1.218338. Sequential266afc8b's hyper parameters: Current learning rate is 3.337783711615487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:00 INFO  DistriOptimizer$:408 - [Epoch 7 10752/60000][Iteration 2898][Wall Clock 281.910774715s] Trained 128 records in 0.08706784 seconds. Throughput is 1470.1179 records/second. Loss is 1.2219546. Sequential266afc8b's hyper parameters: Current learning rate is 3.33667000333667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 10880/60000][Iteration 2899][Wall Clock 281.994206455s] Trained 128 records in 0.08343174 seconds. Throughput is 1534.1882 records/second. Loss is 1.2214496. Sequential266afc8b's hyper parameters: Current learning rate is 3.3355570380253505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11008/60000][Iteration 2900][Wall Clock 282.08190476s] Trained 128 records in 0.087698305 seconds. Throughput is 1459.5493 records/second. Loss is 1.2521678. Sequential266afc8b's hyper parameters: Current learning rate is 3.3344448149383126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11136/60000][Iteration 2901][Wall Clock 282.167679589s] Trained 128 records in 0.085774829 seconds. Throughput is 1492.2793 records/second. Loss is 1.1985192. Sequential266afc8b's hyper parameters: Current learning rate is 3.333333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11264/60000][Iteration 2902][Wall Clock 282.252632897s] Trained 128 records in 0.084953308 seconds. Throughput is 1506.71 records/second. Loss is 1.26425. Sequential266afc8b's hyper parameters: Current learning rate is 3.332222592469177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11392/60000][Iteration 2903][Wall Clock 282.342926938s] Trained 128 records in 0.090294041 seconds. Throughput is 1417.5908 records/second. Loss is 1.3158362. Sequential266afc8b's hyper parameters: Current learning rate is 3.3311125916055963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11520/60000][Iteration 2904][Wall Clock 282.427698194s] Trained 128 records in 0.084771256 seconds. Throughput is 1509.9458 records/second. Loss is 1.280481. Sequential266afc8b's hyper parameters: Current learning rate is 3.33000333000333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11648/60000][Iteration 2905][Wall Clock 282.513101948s] Trained 128 records in 0.085403754 seconds. Throughput is 1498.7632 records/second. Loss is 1.2234731. Sequential266afc8b's hyper parameters: Current learning rate is 3.3288948069241014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11776/60000][Iteration 2906][Wall Clock 282.608244322s] Trained 128 records in 0.095142374 seconds. Throughput is 1345.3522 records/second. Loss is 1.2064756. Sequential266afc8b's hyper parameters: Current learning rate is 3.3277870216306157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 11904/60000][Iteration 2907][Wall Clock 282.706344218s] Trained 128 records in 0.098099896 seconds. Throughput is 1304.7925 records/second. Loss is 1.2468599. Sequential266afc8b's hyper parameters: Current learning rate is 3.3266799733865603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 12032/60000][Iteration 2908][Wall Clock 282.796492952s] Trained 128 records in 0.090148734 seconds. Throughput is 1419.8757 records/second. Loss is 1.2440717. Sequential266afc8b's hyper parameters: Current learning rate is 3.325573661456601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:01 INFO  DistriOptimizer$:408 - [Epoch 7 12160/60000][Iteration 2909][Wall Clock 282.880464087s] Trained 128 records in 0.083971135 seconds. Throughput is 1524.3334 records/second. Loss is 1.2795131. Sequential266afc8b's hyper parameters: Current learning rate is 3.324468085106383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 12288/60000][Iteration 2910][Wall Clock 282.965688599s] Trained 128 records in 0.085224512 seconds. Throughput is 1501.9154 records/second. Loss is 1.2727871. Sequential266afc8b's hyper parameters: Current learning rate is 3.323363243602526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 12416/60000][Iteration 2911][Wall Clock 283.051386893s] Trained 128 records in 0.085698294 seconds. Throughput is 1493.612 records/second. Loss is 1.1957415. Sequential266afc8b's hyper parameters: Current learning rate is 3.322259136212624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 12544/60000][Iteration 2912][Wall Clock 283.135001841s] Trained 128 records in 0.083614948 seconds. Throughput is 1530.8268 records/second. Loss is 1.2667766. Sequential266afc8b's hyper parameters: Current learning rate is 3.3211557622052476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 12672/60000][Iteration 2913][Wall Clock 283.219241774s] Trained 128 records in 0.084239933 seconds. Throughput is 1519.4695 records/second. Loss is 1.2696334. Sequential266afc8b's hyper parameters: Current learning rate is 3.3200531208499334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 12800/60000][Iteration 2914][Wall Clock 283.304432947s] Trained 128 records in 0.085191173 seconds. Throughput is 1502.503 records/second. Loss is 1.2728518. Sequential266afc8b's hyper parameters: Current learning rate is 3.3189512114171923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 12928/60000][Iteration 2915][Wall Clock 283.39536861s] Trained 128 records in 0.090935663 seconds. Throughput is 1407.5886 records/second. Loss is 1.2026861. Sequential266afc8b's hyper parameters: Current learning rate is 3.3178500331785003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 13056/60000][Iteration 2916][Wall Clock 283.494175293s] Trained 128 records in 0.098806683 seconds. Throughput is 1295.4589 records/second. Loss is 1.305293. Sequential266afc8b's hyper parameters: Current learning rate is 3.316749585406302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 13184/60000][Iteration 2917][Wall Clock 283.578265426s] Trained 128 records in 0.084090133 seconds. Throughput is 1522.1761 records/second. Loss is 1.1787109. Sequential266afc8b's hyper parameters: Current learning rate is 3.315649867374005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 13312/60000][Iteration 2918][Wall Clock 283.665273179s] Trained 128 records in 0.087007753 seconds. Throughput is 1471.1333 records/second. Loss is 1.0966076. Sequential266afc8b's hyper parameters: Current learning rate is 3.3145508783559825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 13440/60000][Iteration 2919][Wall Clock 283.752353481s] Trained 128 records in 0.087080302 seconds. Throughput is 1469.9077 records/second. Loss is 1.2141485. Sequential266afc8b's hyper parameters: Current learning rate is 3.313452617627568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 13568/60000][Iteration 2920][Wall Clock 283.837298808s] Trained 128 records in 0.084945327 seconds. Throughput is 1506.8516 records/second. Loss is 1.3374032. Sequential266afc8b's hyper parameters: Current learning rate is 3.312355084465055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:02 INFO  DistriOptimizer$:408 - [Epoch 7 13696/60000][Iteration 2921][Wall Clock 283.922361395s] Trained 128 records in 0.085062587 seconds. Throughput is 1504.7744 records/second. Loss is 1.2285844. Sequential266afc8b's hyper parameters: Current learning rate is 3.3112582781456954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 13824/60000][Iteration 2922][Wall Clock 284.00803299s] Trained 128 records in 0.085671595 seconds. Throughput is 1494.0774 records/second. Loss is 1.2526428. Sequential266afc8b's hyper parameters: Current learning rate is 3.3101621979476995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 13952/60000][Iteration 2923][Wall Clock 284.091650651s] Trained 128 records in 0.083617661 seconds. Throughput is 1530.7771 records/second. Loss is 1.2391236. Sequential266afc8b's hyper parameters: Current learning rate is 3.3090668431502316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14080/60000][Iteration 2924][Wall Clock 284.175390267s] Trained 128 records in 0.083739616 seconds. Throughput is 1528.5477 records/second. Loss is 1.2507406. Sequential266afc8b's hyper parameters: Current learning rate is 3.307972213033411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14208/60000][Iteration 2925][Wall Clock 284.259297772s] Trained 128 records in 0.083907505 seconds. Throughput is 1525.4893 records/second. Loss is 1.2123004. Sequential266afc8b's hyper parameters: Current learning rate is 3.3068783068783067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14336/60000][Iteration 2926][Wall Clock 284.345608115s] Trained 128 records in 0.086310343 seconds. Throughput is 1483.0204 records/second. Loss is 1.2241579. Sequential266afc8b's hyper parameters: Current learning rate is 3.3057851239669424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14464/60000][Iteration 2927][Wall Clock 284.432769003s] Trained 128 records in 0.087160888 seconds. Throughput is 1468.5486 records/second. Loss is 1.2219886. Sequential266afc8b's hyper parameters: Current learning rate is 3.3046926635822867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14592/60000][Iteration 2928][Wall Clock 284.518009704s] Trained 128 records in 0.085240701 seconds. Throughput is 1501.6301 records/second. Loss is 1.2673401. Sequential266afc8b's hyper parameters: Current learning rate is 3.3036009250082593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14720/60000][Iteration 2929][Wall Clock 284.604022499s] Trained 128 records in 0.086012795 seconds. Throughput is 1488.1506 records/second. Loss is 1.272483. Sequential266afc8b's hyper parameters: Current learning rate is 3.3025099075297226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14848/60000][Iteration 2930][Wall Clock 284.68953566s] Trained 128 records in 0.085513161 seconds. Throughput is 1496.8456 records/second. Loss is 1.2210929. Sequential266afc8b's hyper parameters: Current learning rate is 3.301419610432486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 14976/60000][Iteration 2931][Wall Clock 284.774936444s] Trained 128 records in 0.085400784 seconds. Throughput is 1498.8153 records/second. Loss is 1.287539. Sequential266afc8b's hyper parameters: Current learning rate is 3.3003300330033004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:03 INFO  DistriOptimizer$:408 - [Epoch 7 15104/60000][Iteration 2932][Wall Clock 284.870957845s] Trained 128 records in 0.096021401 seconds. Throughput is 1333.0361 records/second. Loss is 1.290823. Sequential266afc8b's hyper parameters: Current learning rate is 3.299241174529858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 15232/60000][Iteration 2933][Wall Clock 284.960035206s] Trained 128 records in 0.089077361 seconds. Throughput is 1436.9532 records/second. Loss is 1.2495565. Sequential266afc8b's hyper parameters: Current learning rate is 3.2981530343007914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 15360/60000][Iteration 2934][Wall Clock 285.050113606s] Trained 128 records in 0.0900784 seconds. Throughput is 1420.9844 records/second. Loss is 1.2797186. Sequential266afc8b's hyper parameters: Current learning rate is 3.297065611605671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 15488/60000][Iteration 2935][Wall Clock 285.133751217s] Trained 128 records in 0.083637611 seconds. Throughput is 1530.412 records/second. Loss is 1.2630752. Sequential266afc8b's hyper parameters: Current learning rate is 3.2959789057350036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 15616/60000][Iteration 2936][Wall Clock 285.226060098s] Trained 128 records in 0.092308881 seconds. Throughput is 1386.6488 records/second. Loss is 1.2823104. Sequential266afc8b's hyper parameters: Current learning rate is 3.2948929159802305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 15744/60000][Iteration 2937][Wall Clock 285.311113864s] Trained 128 records in 0.085053766 seconds. Throughput is 1504.9304 records/second. Loss is 1.1793058. Sequential266afc8b's hyper parameters: Current learning rate is 3.2938076416337287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 15872/60000][Iteration 2938][Wall Clock 285.397221457s] Trained 128 records in 0.086107593 seconds. Throughput is 1486.5125 records/second. Loss is 1.1785338. Sequential266afc8b's hyper parameters: Current learning rate is 3.2927230819888045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 16000/60000][Iteration 2939][Wall Clock 285.483990892s] Trained 128 records in 0.086769435 seconds. Throughput is 1475.1738 records/second. Loss is 1.2145463. Sequential266afc8b's hyper parameters: Current learning rate is 3.2916392363396976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 16128/60000][Iteration 2940][Wall Clock 285.574377829s] Trained 128 records in 0.090386937 seconds. Throughput is 1416.1339 records/second. Loss is 1.1835655. Sequential266afc8b's hyper parameters: Current learning rate is 3.290556103981573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 16256/60000][Iteration 2941][Wall Clock 285.658334076s] Trained 128 records in 0.083956247 seconds. Throughput is 1524.6036 records/second. Loss is 1.193349. Sequential266afc8b's hyper parameters: Current learning rate is 3.289473684210526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 16384/60000][Iteration 2942][Wall Clock 285.744107894s] Trained 128 records in 0.085773818 seconds. Throughput is 1492.2969 records/second. Loss is 1.1921377. Sequential266afc8b's hyper parameters: Current learning rate is 3.288391976323578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 16512/60000][Iteration 2943][Wall Clock 285.829464111s] Trained 128 records in 0.085356217 seconds. Throughput is 1499.5978 records/second. Loss is 1.2673588. Sequential266afc8b's hyper parameters: Current learning rate is 3.2873109796186715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:04 INFO  DistriOptimizer$:408 - [Epoch 7 16640/60000][Iteration 2944][Wall Clock 285.915480226s] Trained 128 records in 0.086016115 seconds. Throughput is 1488.0931 records/second. Loss is 1.3242923. Sequential266afc8b's hyper parameters: Current learning rate is 3.2862306933946765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 16768/60000][Iteration 2945][Wall Clock 286.001788839s] Trained 128 records in 0.086308613 seconds. Throughput is 1483.0502 records/second. Loss is 1.1735957. Sequential266afc8b's hyper parameters: Current learning rate is 3.28515111695138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 16896/60000][Iteration 2946][Wall Clock 286.087412858s] Trained 128 records in 0.085624019 seconds. Throughput is 1494.9077 records/second. Loss is 1.2598891. Sequential266afc8b's hyper parameters: Current learning rate is 3.284072249589491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17024/60000][Iteration 2947][Wall Clock 286.17452225s] Trained 128 records in 0.087109392 seconds. Throughput is 1469.4167 records/second. Loss is 1.2468094. Sequential266afc8b's hyper parameters: Current learning rate is 3.2829940906106366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17152/60000][Iteration 2948][Wall Clock 286.277001714s] Trained 128 records in 0.102479464 seconds. Throughput is 1249.0308 records/second. Loss is 1.3046428. Sequential266afc8b's hyper parameters: Current learning rate is 3.2819166393173617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17280/60000][Iteration 2949][Wall Clock 286.365353645s] Trained 128 records in 0.088351931 seconds. Throughput is 1448.7516 records/second. Loss is 1.2219799. Sequential266afc8b's hyper parameters: Current learning rate is 3.2808398950131233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17408/60000][Iteration 2950][Wall Clock 286.452394876s] Trained 128 records in 0.087041231 seconds. Throughput is 1470.5675 records/second. Loss is 1.2850443. Sequential266afc8b's hyper parameters: Current learning rate is 3.2797638570022957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17536/60000][Iteration 2951][Wall Clock 286.538265949s] Trained 128 records in 0.085871073 seconds. Throughput is 1490.6068 records/second. Loss is 1.2306577. Sequential266afc8b's hyper parameters: Current learning rate is 3.278688524590164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17664/60000][Iteration 2952][Wall Clock 286.623933312s] Trained 128 records in 0.085667363 seconds. Throughput is 1494.1512 records/second. Loss is 1.1839367. Sequential266afc8b's hyper parameters: Current learning rate is 3.2776138970829236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17792/60000][Iteration 2953][Wall Clock 286.714846339s] Trained 128 records in 0.090913027 seconds. Throughput is 1407.9391 records/second. Loss is 1.2189777. Sequential266afc8b's hyper parameters: Current learning rate is 3.27653997378768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 17920/60000][Iteration 2954][Wall Clock 286.802351638s] Trained 128 records in 0.087505299 seconds. Throughput is 1462.7686 records/second. Loss is 1.2639407. Sequential266afc8b's hyper parameters: Current learning rate is 3.2754667540124465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:05 INFO  DistriOptimizer$:408 - [Epoch 7 18048/60000][Iteration 2955][Wall Clock 286.888205321s] Trained 128 records in 0.085853683 seconds. Throughput is 1490.9087 records/second. Loss is 1.2723297. Sequential266afc8b's hyper parameters: Current learning rate is 3.274394237066143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18176/60000][Iteration 2956][Wall Clock 286.971876395s] Trained 128 records in 0.083671074 seconds. Throughput is 1529.7999 records/second. Loss is 1.1912951. Sequential266afc8b's hyper parameters: Current learning rate is 3.273322422258593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18304/60000][Iteration 2957][Wall Clock 287.056758368s] Trained 128 records in 0.084881973 seconds. Throughput is 1507.9762 records/second. Loss is 1.3191972. Sequential266afc8b's hyper parameters: Current learning rate is 3.272251308900523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18432/60000][Iteration 2958][Wall Clock 287.153954299s] Trained 128 records in 0.097195931 seconds. Throughput is 1316.9276 records/second. Loss is 1.2188787. Sequential266afc8b's hyper parameters: Current learning rate is 3.2711808963035657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18560/60000][Iteration 2959][Wall Clock 287.235153449s] Trained 128 records in 0.08119915 seconds. Throughput is 1576.3712 records/second. Loss is 1.3047814. Sequential266afc8b's hyper parameters: Current learning rate is 3.270111183780248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18688/60000][Iteration 2960][Wall Clock 287.316113052s] Trained 128 records in 0.080959603 seconds. Throughput is 1581.0354 records/second. Loss is 1.2466812. Sequential266afc8b's hyper parameters: Current learning rate is 3.2690421706440013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18816/60000][Iteration 2961][Wall Clock 287.395448318s] Trained 128 records in 0.079335266 seconds. Throughput is 1613.4061 records/second. Loss is 1.2751249. Sequential266afc8b's hyper parameters: Current learning rate is 3.26797385620915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 18944/60000][Iteration 2962][Wall Clock 287.481479061s] Trained 128 records in 0.086030743 seconds. Throughput is 1487.8402 records/second. Loss is 1.2925025. Sequential266afc8b's hyper parameters: Current learning rate is 3.266906239790918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 19072/60000][Iteration 2963][Wall Clock 287.57460923s] Trained 128 records in 0.093130169 seconds. Throughput is 1374.4203 records/second. Loss is 1.2716222. Sequential266afc8b's hyper parameters: Current learning rate is 3.2658393207054214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 19200/60000][Iteration 2964][Wall Clock 287.664670102s] Trained 128 records in 0.090060872 seconds. Throughput is 1421.2609 records/second. Loss is 1.2336383. Sequential266afc8b's hyper parameters: Current learning rate is 3.26477309826967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 19328/60000][Iteration 2965][Wall Clock 287.750160347s] Trained 128 records in 0.085490245 seconds. Throughput is 1497.247 records/second. Loss is 1.2649512. Sequential266afc8b's hyper parameters: Current learning rate is 3.2637075718015666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:06 INFO  DistriOptimizer$:408 - [Epoch 7 19456/60000][Iteration 2966][Wall Clock 287.838985372s] Trained 128 records in 0.088825025 seconds. Throughput is 1441.0354 records/second. Loss is 1.262287. Sequential266afc8b's hyper parameters: Current learning rate is 3.262642740619902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 19584/60000][Iteration 2967][Wall Clock 287.926681742s] Trained 128 records in 0.08769637 seconds. Throughput is 1459.5814 records/second. Loss is 1.2441003. Sequential266afc8b's hyper parameters: Current learning rate is 3.2615786040443573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 19712/60000][Iteration 2968][Wall Clock 288.010896716s] Trained 128 records in 0.084214974 seconds. Throughput is 1519.9198 records/second. Loss is 1.2996082. Sequential266afc8b's hyper parameters: Current learning rate is 3.2605151613955004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 19840/60000][Iteration 2969][Wall Clock 288.09480343s] Trained 128 records in 0.083906714 seconds. Throughput is 1525.5037 records/second. Loss is 1.1698331. Sequential266afc8b's hyper parameters: Current learning rate is 3.259452411994785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 19968/60000][Iteration 2970][Wall Clock 288.179721231s] Trained 128 records in 0.084917801 seconds. Throughput is 1507.3401 records/second. Loss is 1.2925276. Sequential266afc8b's hyper parameters: Current learning rate is 3.2583903551645487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20096/60000][Iteration 2971][Wall Clock 288.267812798s] Trained 128 records in 0.088091567 seconds. Throughput is 1453.0336 records/second. Loss is 1.191507. Sequential266afc8b's hyper parameters: Current learning rate is 3.257328990228013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20224/60000][Iteration 2972][Wall Clock 288.356089422s] Trained 128 records in 0.088276624 seconds. Throughput is 1449.9874 records/second. Loss is 1.2773064. Sequential266afc8b's hyper parameters: Current learning rate is 3.2562683165092806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20352/60000][Iteration 2973][Wall Clock 288.442874541s] Trained 128 records in 0.086785119 seconds. Throughput is 1474.9073 records/second. Loss is 1.3184457. Sequential266afc8b's hyper parameters: Current learning rate is 3.2552083333333337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20480/60000][Iteration 2974][Wall Clock 288.528873828s] Trained 128 records in 0.085999287 seconds. Throughput is 1488.3844 records/second. Loss is 1.3017495. Sequential266afc8b's hyper parameters: Current learning rate is 3.254149040026033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20608/60000][Iteration 2975][Wall Clock 288.613027411s] Trained 128 records in 0.084153583 seconds. Throughput is 1521.0284 records/second. Loss is 1.2712532. Sequential266afc8b's hyper parameters: Current learning rate is 3.253090435914118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20736/60000][Iteration 2976][Wall Clock 288.7008993s] Trained 128 records in 0.087871889 seconds. Throughput is 1456.6661 records/second. Loss is 1.2724211. Sequential266afc8b's hyper parameters: Current learning rate is 3.252032520325203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20864/60000][Iteration 2977][Wall Clock 288.788398101s] Trained 128 records in 0.087498801 seconds. Throughput is 1462.8772 records/second. Loss is 1.2986636. Sequential266afc8b's hyper parameters: Current learning rate is 3.2509752925877764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:07 INFO  DistriOptimizer$:408 - [Epoch 7 20992/60000][Iteration 2978][Wall Clock 288.872262524s] Trained 128 records in 0.083864423 seconds. Throughput is 1526.273 records/second. Loss is 1.2927861. Sequential266afc8b's hyper parameters: Current learning rate is 3.2499187520311994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21120/60000][Iteration 2979][Wall Clock 288.959712108s] Trained 128 records in 0.087449584 seconds. Throughput is 1463.7006 records/second. Loss is 1.1706234. Sequential266afc8b's hyper parameters: Current learning rate is 3.248862897985705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21248/60000][Iteration 2980][Wall Clock 289.045037829s] Trained 128 records in 0.085325721 seconds. Throughput is 1500.1339 records/second. Loss is 1.2406247. Sequential266afc8b's hyper parameters: Current learning rate is 3.2478077297823973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21376/60000][Iteration 2981][Wall Clock 289.131919869s] Trained 128 records in 0.08688204 seconds. Throughput is 1473.262 records/second. Loss is 1.2095479. Sequential266afc8b's hyper parameters: Current learning rate is 3.246753246753247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21504/60000][Iteration 2982][Wall Clock 289.219509693s] Trained 128 records in 0.087589824 seconds. Throughput is 1461.3569 records/second. Loss is 1.1877923. Sequential266afc8b's hyper parameters: Current learning rate is 3.245699448231094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21632/60000][Iteration 2983][Wall Clock 289.303558585s] Trained 128 records in 0.084048892 seconds. Throughput is 1522.9231 records/second. Loss is 1.236566. Sequential266afc8b's hyper parameters: Current learning rate is 3.244646333549643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21760/60000][Iteration 2984][Wall Clock 289.394434749s] Trained 128 records in 0.090876164 seconds. Throughput is 1408.5101 records/second. Loss is 1.2761971. Sequential266afc8b's hyper parameters: Current learning rate is 3.243593902043464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 21888/60000][Iteration 2985][Wall Clock 289.478494267s] Trained 128 records in 0.084059518 seconds. Throughput is 1522.7306 records/second. Loss is 1.2511181. Sequential266afc8b's hyper parameters: Current learning rate is 3.2425421530479895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 22016/60000][Iteration 2986][Wall Clock 289.560998886s] Trained 128 records in 0.082504619 seconds. Throughput is 1551.4282 records/second. Loss is 1.2666708. Sequential266afc8b's hyper parameters: Current learning rate is 3.2414910858995135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 22144/60000][Iteration 2987][Wall Clock 289.647150288s] Trained 128 records in 0.086151402 seconds. Throughput is 1485.7565 records/second. Loss is 1.100118. Sequential266afc8b's hyper parameters: Current learning rate is 3.240440699935191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 22272/60000][Iteration 2988][Wall Clock 289.733787919s] Trained 128 records in 0.086637631 seconds. Throughput is 1477.4181 records/second. Loss is 1.2839304. Sequential266afc8b's hyper parameters: Current learning rate is 3.2393909944930353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:08 INFO  DistriOptimizer$:408 - [Epoch 7 22400/60000][Iteration 2989][Wall Clock 289.818669282s] Trained 128 records in 0.084881363 seconds. Throughput is 1507.987 records/second. Loss is 1.2580065. Sequential266afc8b's hyper parameters: Current learning rate is 3.238341968911917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 22528/60000][Iteration 2990][Wall Clock 289.905311765s] Trained 128 records in 0.086642483 seconds. Throughput is 1477.3353 records/second. Loss is 1.3073486. Sequential266afc8b's hyper parameters: Current learning rate is 3.237293622531564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 22656/60000][Iteration 2991][Wall Clock 289.990339235s] Trained 128 records in 0.08502747 seconds. Throughput is 1505.3959 records/second. Loss is 1.2838385. Sequential266afc8b's hyper parameters: Current learning rate is 3.2362459546925567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 22784/60000][Iteration 2992][Wall Clock 290.082829989s] Trained 128 records in 0.092490754 seconds. Throughput is 1383.9221 records/second. Loss is 1.1766671. Sequential266afc8b's hyper parameters: Current learning rate is 3.2351989647363315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 22912/60000][Iteration 2993][Wall Clock 290.170451126s] Trained 128 records in 0.087621137 seconds. Throughput is 1460.8347 records/second. Loss is 1.3109213. Sequential266afc8b's hyper parameters: Current learning rate is 3.2341526520051744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23040/60000][Iteration 2994][Wall Clock 290.255084534s] Trained 128 records in 0.084633408 seconds. Throughput is 1512.405 records/second. Loss is 1.3235908. Sequential266afc8b's hyper parameters: Current learning rate is 3.2331070158422246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23168/60000][Iteration 2995][Wall Clock 290.340719551s] Trained 128 records in 0.085635017 seconds. Throughput is 1494.7157 records/second. Loss is 1.2277725. Sequential266afc8b's hyper parameters: Current learning rate is 3.232062055591467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23296/60000][Iteration 2996][Wall Clock 290.428318316s] Trained 128 records in 0.087598765 seconds. Throughput is 1461.2079 records/second. Loss is 1.2898479. Sequential266afc8b's hyper parameters: Current learning rate is 3.2310177705977385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23424/60000][Iteration 2997][Wall Clock 290.515949144s] Trained 128 records in 0.087630828 seconds. Throughput is 1460.6731 records/second. Loss is 1.1592336. Sequential266afc8b's hyper parameters: Current learning rate is 3.2299741602067185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23552/60000][Iteration 2998][Wall Clock 290.603275116s] Trained 128 records in 0.087325972 seconds. Throughput is 1465.7723 records/second. Loss is 1.3011396. Sequential266afc8b's hyper parameters: Current learning rate is 3.228931223764934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23680/60000][Iteration 2999][Wall Clock 290.691538287s] Trained 128 records in 0.088263171 seconds. Throughput is 1450.2085 records/second. Loss is 1.1935563. Sequential266afc8b's hyper parameters: Current learning rate is 3.2278889606197545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23808/60000][Iteration 3000][Wall Clock 290.77768432s] Trained 128 records in 0.086146033 seconds. Throughput is 1485.849 records/second. Loss is 1.2155445. Sequential266afc8b's hyper parameters: Current learning rate is 3.2268473701193933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:09 INFO  DistriOptimizer$:408 - [Epoch 7 23936/60000][Iteration 3001][Wall Clock 290.864505289s] Trained 128 records in 0.086820969 seconds. Throughput is 1474.2982 records/second. Loss is 1.1936836. Sequential266afc8b's hyper parameters: Current learning rate is 3.225806451612903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24064/60000][Iteration 3002][Wall Clock 290.952146736s] Trained 128 records in 0.087641447 seconds. Throughput is 1460.4962 records/second. Loss is 1.1725439. Sequential266afc8b's hyper parameters: Current learning rate is 3.224766204450177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24192/60000][Iteration 3003][Wall Clock 291.038954782s] Trained 128 records in 0.086808046 seconds. Throughput is 1474.5177 records/second. Loss is 1.2826277. Sequential266afc8b's hyper parameters: Current learning rate is 3.223726627981947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24320/60000][Iteration 3004][Wall Clock 291.125422098s] Trained 128 records in 0.086467316 seconds. Throughput is 1480.3281 records/second. Loss is 1.1729321. Sequential266afc8b's hyper parameters: Current learning rate is 3.2226877215597806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24448/60000][Iteration 3005][Wall Clock 291.212962059s] Trained 128 records in 0.087539961 seconds. Throughput is 1462.1893 records/second. Loss is 1.2142198. Sequential266afc8b's hyper parameters: Current learning rate is 3.2216494845360824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24576/60000][Iteration 3006][Wall Clock 291.300209727s] Trained 128 records in 0.087247668 seconds. Throughput is 1467.0879 records/second. Loss is 1.2450215. Sequential266afc8b's hyper parameters: Current learning rate is 3.2206119162640903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24704/60000][Iteration 3007][Wall Clock 291.383164829s] Trained 128 records in 0.082955102 seconds. Throughput is 1543.0034 records/second. Loss is 1.1266441. Sequential266afc8b's hyper parameters: Current learning rate is 3.219575016097875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24832/60000][Iteration 3008][Wall Clock 291.465495257s] Trained 128 records in 0.082330428 seconds. Throughput is 1554.7107 records/second. Loss is 1.2364429. Sequential266afc8b's hyper parameters: Current learning rate is 3.21853878339234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 24960/60000][Iteration 3009][Wall Clock 291.569290987s] Trained 128 records in 0.10379573 seconds. Throughput is 1233.1914 records/second. Loss is 1.2491387. Sequential266afc8b's hyper parameters: Current learning rate is 3.2175032175032174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 25088/60000][Iteration 3010][Wall Clock 291.65774025s] Trained 128 records in 0.088449263 seconds. Throughput is 1447.1573 records/second. Loss is 1.2731018. Sequential266afc8b's hyper parameters: Current learning rate is 3.21646831778707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 25216/60000][Iteration 3011][Wall Clock 291.744991024s] Trained 128 records in 0.087250774 seconds. Throughput is 1467.0356 records/second. Loss is 1.3342685. Sequential266afc8b's hyper parameters: Current learning rate is 3.215434083601286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:10 INFO  DistriOptimizer$:408 - [Epoch 7 25344/60000][Iteration 3012][Wall Clock 291.830722712s] Trained 128 records in 0.085731688 seconds. Throughput is 1493.0303 records/second. Loss is 1.3232615. Sequential266afc8b's hyper parameters: Current learning rate is 3.2144005143040826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 25472/60000][Iteration 3013][Wall Clock 291.918733696s] Trained 128 records in 0.088010984 seconds. Throughput is 1454.364 records/second. Loss is 1.2424004. Sequential266afc8b's hyper parameters: Current learning rate is 3.2133676092544985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 25600/60000][Iteration 3014][Wall Clock 292.009160532s] Trained 128 records in 0.090426836 seconds. Throughput is 1415.509 records/second. Loss is 1.2357438. Sequential266afc8b's hyper parameters: Current learning rate is 3.2123353678124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 25728/60000][Iteration 3015][Wall Clock 292.09535632s] Trained 128 records in 0.086195788 seconds. Throughput is 1484.9913 records/second. Loss is 1.2771845. Sequential266afc8b's hyper parameters: Current learning rate is 3.211303789338471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 25856/60000][Iteration 3016][Wall Clock 292.181232147s] Trained 128 records in 0.085875827 seconds. Throughput is 1490.5243 records/second. Loss is 1.256239. Sequential266afc8b's hyper parameters: Current learning rate is 3.2102728731942215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 25984/60000][Iteration 3017][Wall Clock 292.275227932s] Trained 128 records in 0.093995785 seconds. Throughput is 1361.7632 records/second. Loss is 1.0918046. Sequential266afc8b's hyper parameters: Current learning rate is 3.209242618741977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26112/60000][Iteration 3018][Wall Clock 292.351924661s] Trained 128 records in 0.076696729 seconds. Throughput is 1668.9108 records/second. Loss is 1.2362939. Sequential266afc8b's hyper parameters: Current learning rate is 3.208213025344883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26240/60000][Iteration 3019][Wall Clock 292.437644005s] Trained 128 records in 0.085719344 seconds. Throughput is 1493.2451 records/second. Loss is 1.238242. Sequential266afc8b's hyper parameters: Current learning rate is 3.207184092366902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26368/60000][Iteration 3020][Wall Clock 292.524356764s] Trained 128 records in 0.086712759 seconds. Throughput is 1476.138 records/second. Loss is 1.197663. Sequential266afc8b's hyper parameters: Current learning rate is 3.206155819172812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26496/60000][Iteration 3021][Wall Clock 292.61217607s] Trained 128 records in 0.087819306 seconds. Throughput is 1457.5382 records/second. Loss is 1.2248293. Sequential266afc8b's hyper parameters: Current learning rate is 3.205128205128205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26624/60000][Iteration 3022][Wall Clock 292.697457235s] Trained 128 records in 0.085281165 seconds. Throughput is 1500.9176 records/second. Loss is 1.2580566. Sequential266afc8b's hyper parameters: Current learning rate is 3.204101249599487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26752/60000][Iteration 3023][Wall Clock 292.783625092s] Trained 128 records in 0.086167857 seconds. Throughput is 1485.4727 records/second. Loss is 1.2723529. Sequential266afc8b's hyper parameters: Current learning rate is 3.203074951953876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:11 INFO  DistriOptimizer$:408 - [Epoch 7 26880/60000][Iteration 3024][Wall Clock 292.871089862s] Trained 128 records in 0.08746477 seconds. Throughput is 1463.4463 records/second. Loss is 1.2547855. Sequential266afc8b's hyper parameters: Current learning rate is 3.2020493115593983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27008/60000][Iteration 3025][Wall Clock 292.956705332s] Trained 128 records in 0.08561547 seconds. Throughput is 1495.0569 records/second. Loss is 1.2742481. Sequential266afc8b's hyper parameters: Current learning rate is 3.201024327784891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27136/60000][Iteration 3026][Wall Clock 293.044058285s] Trained 128 records in 0.087352953 seconds. Throughput is 1465.3197 records/second. Loss is 1.1801105. Sequential266afc8b's hyper parameters: Current learning rate is 3.2E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27264/60000][Iteration 3027][Wall Clock 293.132742106s] Trained 128 records in 0.088683821 seconds. Throughput is 1443.3298 records/second. Loss is 1.2812674. Sequential266afc8b's hyper parameters: Current learning rate is 3.198976327575176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27392/60000][Iteration 3028][Wall Clock 293.22158636s] Trained 128 records in 0.088844254 seconds. Throughput is 1440.7234 records/second. Loss is 1.2872144. Sequential266afc8b's hyper parameters: Current learning rate is 3.197953309881676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27520/60000][Iteration 3029][Wall Clock 293.307627853s] Trained 128 records in 0.086041493 seconds. Throughput is 1487.6543 records/second. Loss is 1.1586215. Sequential266afc8b's hyper parameters: Current learning rate is 3.19693094629156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27648/60000][Iteration 3030][Wall Clock 293.393958638s] Trained 128 records in 0.086330785 seconds. Throughput is 1482.6692 records/second. Loss is 1.3440343. Sequential266afc8b's hyper parameters: Current learning rate is 3.1959092361776926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27776/60000][Iteration 3031][Wall Clock 293.482024808s] Trained 128 records in 0.08806617 seconds. Throughput is 1453.4526 records/second. Loss is 1.2500111. Sequential266afc8b's hyper parameters: Current learning rate is 3.194888178913738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 27904/60000][Iteration 3032][Wall Clock 293.568618822s] Trained 128 records in 0.086594014 seconds. Throughput is 1478.1622 records/second. Loss is 1.3161172. Sequential266afc8b's hyper parameters: Current learning rate is 3.1938677738741617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 28032/60000][Iteration 3033][Wall Clock 293.659049495s] Trained 128 records in 0.090430673 seconds. Throughput is 1415.449 records/second. Loss is 1.1614989. Sequential266afc8b's hyper parameters: Current learning rate is 3.1928480204342275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 28160/60000][Iteration 3034][Wall Clock 293.746511944s] Trained 128 records in 0.087462449 seconds. Throughput is 1463.4852 records/second. Loss is 1.3158783. Sequential266afc8b's hyper parameters: Current learning rate is 3.191828917969997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:12 INFO  DistriOptimizer$:408 - [Epoch 7 28288/60000][Iteration 3035][Wall Clock 293.844897446s] Trained 128 records in 0.098385502 seconds. Throughput is 1301.0046 records/second. Loss is 1.2103652. Sequential266afc8b's hyper parameters: Current learning rate is 3.190810465858328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 28416/60000][Iteration 3036][Wall Clock 293.933681126s] Trained 128 records in 0.08878368 seconds. Throughput is 1441.7064 records/second. Loss is 1.226034. Sequential266afc8b's hyper parameters: Current learning rate is 3.189792663476874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 28544/60000][Iteration 3037][Wall Clock 294.022822345s] Trained 128 records in 0.089141219 seconds. Throughput is 1435.9238 records/second. Loss is 1.2214028. Sequential266afc8b's hyper parameters: Current learning rate is 3.188775510204082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 28672/60000][Iteration 3038][Wall Clock 294.111943836s] Trained 128 records in 0.089121491 seconds. Throughput is 1436.2417 records/second. Loss is 1.2001971. Sequential266afc8b's hyper parameters: Current learning rate is 3.18775900541919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 28800/60000][Iteration 3039][Wall Clock 294.200165952s] Trained 128 records in 0.088222116 seconds. Throughput is 1450.8833 records/second. Loss is 1.1159397. Sequential266afc8b's hyper parameters: Current learning rate is 3.186743148502231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 28928/60000][Iteration 3040][Wall Clock 294.285870864s] Trained 128 records in 0.085704912 seconds. Throughput is 1493.4966 records/second. Loss is 1.279758. Sequential266afc8b's hyper parameters: Current learning rate is 3.1857279388340236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 29056/60000][Iteration 3041][Wall Clock 294.374220356s] Trained 128 records in 0.088349492 seconds. Throughput is 1448.7916 records/second. Loss is 1.287534. Sequential266afc8b's hyper parameters: Current learning rate is 3.184713375796178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 29184/60000][Iteration 3042][Wall Clock 294.459571085s] Trained 128 records in 0.085350729 seconds. Throughput is 1499.6942 records/second. Loss is 1.212193. Sequential266afc8b's hyper parameters: Current learning rate is 3.183699458771092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 29312/60000][Iteration 3043][Wall Clock 294.549867165s] Trained 128 records in 0.09029608 seconds. Throughput is 1417.5587 records/second. Loss is 1.2542889. Sequential266afc8b's hyper parameters: Current learning rate is 3.1826861871419476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 29440/60000][Iteration 3044][Wall Clock 294.638393745s] Trained 128 records in 0.08852658 seconds. Throughput is 1445.8934 records/second. Loss is 1.1350011. Sequential266afc8b's hyper parameters: Current learning rate is 3.181673560292714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 29568/60000][Iteration 3045][Wall Clock 294.725650256s] Trained 128 records in 0.087256511 seconds. Throughput is 1466.9392 records/second. Loss is 1.2606094. Sequential266afc8b's hyper parameters: Current learning rate is 3.180661577608142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:13 INFO  DistriOptimizer$:408 - [Epoch 7 29696/60000][Iteration 3046][Wall Clock 294.810204474s] Trained 128 records in 0.084554218 seconds. Throughput is 1513.8215 records/second. Loss is 1.2207631. Sequential266afc8b's hyper parameters: Current learning rate is 3.179650238473768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 29824/60000][Iteration 3047][Wall Clock 294.895675144s] Trained 128 records in 0.08547067 seconds. Throughput is 1497.5897 records/second. Loss is 1.1019148. Sequential266afc8b's hyper parameters: Current learning rate is 3.178639542275906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 29952/60000][Iteration 3048][Wall Clock 294.983872853s] Trained 128 records in 0.088197709 seconds. Throughput is 1451.2849 records/second. Loss is 1.2281345. Sequential266afc8b's hyper parameters: Current learning rate is 3.1776294884016526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30080/60000][Iteration 3049][Wall Clock 295.070478144s] Trained 128 records in 0.086605291 seconds. Throughput is 1477.9698 records/second. Loss is 1.2042098. Sequential266afc8b's hyper parameters: Current learning rate is 3.176620076238882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30208/60000][Iteration 3050][Wall Clock 295.156694857s] Trained 128 records in 0.086216713 seconds. Throughput is 1484.631 records/second. Loss is 1.2884173. Sequential266afc8b's hyper parameters: Current learning rate is 3.1756113051762465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30336/60000][Iteration 3051][Wall Clock 295.242942136s] Trained 128 records in 0.086247279 seconds. Throughput is 1484.1047 records/second. Loss is 1.2531799. Sequential266afc8b's hyper parameters: Current learning rate is 3.1746031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30464/60000][Iteration 3052][Wall Clock 295.329649558s] Trained 128 records in 0.086707422 seconds. Throughput is 1476.2289 records/second. Loss is 1.2703902. Sequential266afc8b's hyper parameters: Current learning rate is 3.1735956839098697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30592/60000][Iteration 3053][Wall Clock 295.414250972s] Trained 128 records in 0.084601414 seconds. Throughput is 1512.977 records/second. Loss is 1.101078. Sequential266afc8b's hyper parameters: Current learning rate is 3.17258883248731E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30720/60000][Iteration 3054][Wall Clock 295.504014723s] Trained 128 records in 0.089763751 seconds. Throughput is 1425.9653 records/second. Loss is 1.3515934. Sequential266afc8b's hyper parameters: Current learning rate is 3.171582619727244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30848/60000][Iteration 3055][Wall Clock 295.594884471s] Trained 128 records in 0.090869748 seconds. Throughput is 1408.6096 records/second. Loss is 1.2607582. Sequential266afc8b's hyper parameters: Current learning rate is 3.170577045022194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 30976/60000][Iteration 3056][Wall Clock 295.682463251s] Trained 128 records in 0.08757878 seconds. Throughput is 1461.5413 records/second. Loss is 1.2528622. Sequential266afc8b's hyper parameters: Current learning rate is 3.169572107765452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 31104/60000][Iteration 3057][Wall Clock 295.771876359s] Trained 128 records in 0.089413108 seconds. Throughput is 1431.5575 records/second. Loss is 1.2617048. Sequential266afc8b's hyper parameters: Current learning rate is 3.168567807351077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:14 INFO  DistriOptimizer$:408 - [Epoch 7 31232/60000][Iteration 3058][Wall Clock 295.855460685s] Trained 128 records in 0.083584326 seconds. Throughput is 1531.3877 records/second. Loss is 1.1523966. Sequential266afc8b's hyper parameters: Current learning rate is 3.167564143173899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 31360/60000][Iteration 3059][Wall Clock 295.942614388s] Trained 128 records in 0.087153703 seconds. Throughput is 1468.6697 records/second. Loss is 1.2794614. Sequential266afc8b's hyper parameters: Current learning rate is 3.1665611146295124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 31488/60000][Iteration 3060][Wall Clock 296.043149382s] Trained 128 records in 0.100534994 seconds. Throughput is 1273.1886 records/second. Loss is 1.1749158. Sequential266afc8b's hyper parameters: Current learning rate is 3.1655587211142766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 31616/60000][Iteration 3061][Wall Clock 296.127937566s] Trained 128 records in 0.084788184 seconds. Throughput is 1509.6444 records/second. Loss is 1.1751581. Sequential266afc8b's hyper parameters: Current learning rate is 3.1645569620253165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 31744/60000][Iteration 3062][Wall Clock 296.217482543s] Trained 128 records in 0.089544977 seconds. Throughput is 1429.4493 records/second. Loss is 1.1905359. Sequential266afc8b's hyper parameters: Current learning rate is 3.1635558367605187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 31872/60000][Iteration 3063][Wall Clock 296.302330159s] Trained 128 records in 0.084847616 seconds. Throughput is 1508.5869 records/second. Loss is 1.2878526. Sequential266afc8b's hyper parameters: Current learning rate is 3.1625553447185326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 32000/60000][Iteration 3064][Wall Clock 296.389572933s] Trained 128 records in 0.087242774 seconds. Throughput is 1467.1702 records/second. Loss is 1.2223072. Sequential266afc8b's hyper parameters: Current learning rate is 3.161555485298767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 32128/60000][Iteration 3065][Wall Clock 296.474280097s] Trained 128 records in 0.084707164 seconds. Throughput is 1511.0883 records/second. Loss is 1.2245703. Sequential266afc8b's hyper parameters: Current learning rate is 3.160556257901391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 32256/60000][Iteration 3066][Wall Clock 296.561564452s] Trained 128 records in 0.087284355 seconds. Throughput is 1466.4713 records/second. Loss is 1.2350845. Sequential266afc8b's hyper parameters: Current learning rate is 3.15955766192733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 32384/60000][Iteration 3067][Wall Clock 296.648572874s] Trained 128 records in 0.087008422 seconds. Throughput is 1471.122 records/second. Loss is 1.234658. Sequential266afc8b's hyper parameters: Current learning rate is 3.158559696778269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 32512/60000][Iteration 3068][Wall Clock 296.741764233s] Trained 128 records in 0.093191359 seconds. Throughput is 1373.518 records/second. Loss is 1.1363231. Sequential266afc8b's hyper parameters: Current learning rate is 3.1575623618566466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:15 INFO  DistriOptimizer$:408 - [Epoch 7 32640/60000][Iteration 3069][Wall Clock 296.824547627s] Trained 128 records in 0.082783394 seconds. Throughput is 1546.2039 records/second. Loss is 1.1939892. Sequential266afc8b's hyper parameters: Current learning rate is 3.156565656565657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 32768/60000][Iteration 3070][Wall Clock 296.905783285s] Trained 128 records in 0.081235658 seconds. Throughput is 1575.6628 records/second. Loss is 1.2616129. Sequential266afc8b's hyper parameters: Current learning rate is 3.155569580309246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 32896/60000][Iteration 3071][Wall Clock 296.99169034s] Trained 128 records in 0.085907055 seconds. Throughput is 1489.9824 records/second. Loss is 1.1381191. Sequential266afc8b's hyper parameters: Current learning rate is 3.154574132492114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33024/60000][Iteration 3072][Wall Clock 297.077835908s] Trained 128 records in 0.086145568 seconds. Throughput is 1485.857 records/second. Loss is 1.216545. Sequential266afc8b's hyper parameters: Current learning rate is 3.15357931251971E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33152/60000][Iteration 3073][Wall Clock 297.163848719s] Trained 128 records in 0.086012811 seconds. Throughput is 1488.1504 records/second. Loss is 1.2743897. Sequential266afc8b's hyper parameters: Current learning rate is 3.1525851197982345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33280/60000][Iteration 3074][Wall Clock 297.250780446s] Trained 128 records in 0.086931727 seconds. Throughput is 1472.4198 records/second. Loss is 1.2396592. Sequential266afc8b's hyper parameters: Current learning rate is 3.151591553734636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33408/60000][Iteration 3075][Wall Clock 297.338627212s] Trained 128 records in 0.087846766 seconds. Throughput is 1457.0828 records/second. Loss is 1.1754348. Sequential266afc8b's hyper parameters: Current learning rate is 3.15059861373661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33536/60000][Iteration 3076][Wall Clock 297.422354631s] Trained 128 records in 0.083727419 seconds. Throughput is 1528.7704 records/second. Loss is 1.2017537. Sequential266afc8b's hyper parameters: Current learning rate is 3.1496062992125983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33664/60000][Iteration 3077][Wall Clock 297.507359641s] Trained 128 records in 0.08500501 seconds. Throughput is 1505.7937 records/second. Loss is 1.2000568. Sequential266afc8b's hyper parameters: Current learning rate is 3.1486146095717883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33792/60000][Iteration 3078][Wall Clock 297.594965052s] Trained 128 records in 0.087605411 seconds. Throughput is 1461.097 records/second. Loss is 1.276179. Sequential266afc8b's hyper parameters: Current learning rate is 3.147623544224111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 33920/60000][Iteration 3079][Wall Clock 297.685168606s] Trained 128 records in 0.090203554 seconds. Throughput is 1419.0128 records/second. Loss is 1.1665355. Sequential266afc8b's hyper parameters: Current learning rate is 3.1466331025802394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 34048/60000][Iteration 3080][Wall Clock 297.770532649s] Trained 128 records in 0.085364043 seconds. Throughput is 1499.4603 records/second. Loss is 1.1178483. Sequential266afc8b's hyper parameters: Current learning rate is 3.145643284051589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:16 INFO  DistriOptimizer$:408 - [Epoch 7 34176/60000][Iteration 3081][Wall Clock 297.857320863s] Trained 128 records in 0.086788214 seconds. Throughput is 1474.8546 records/second. Loss is 1.1794169. Sequential266afc8b's hyper parameters: Current learning rate is 3.1446540880503143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 34304/60000][Iteration 3082][Wall Clock 297.946633942s] Trained 128 records in 0.089313079 seconds. Throughput is 1433.1606 records/second. Loss is 1.2381792. Sequential266afc8b's hyper parameters: Current learning rate is 3.1436655139893113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 34432/60000][Iteration 3083][Wall Clock 298.042928453s] Trained 128 records in 0.096294511 seconds. Throughput is 1329.2555 records/second. Loss is 1.2745768. Sequential266afc8b's hyper parameters: Current learning rate is 3.1426775612822125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 34560/60000][Iteration 3084][Wall Clock 298.132433271s] Trained 128 records in 0.089504818 seconds. Throughput is 1430.0907 records/second. Loss is 1.1820544. Sequential266afc8b's hyper parameters: Current learning rate is 3.1416902293433867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 34688/60000][Iteration 3085][Wall Clock 298.218782966s] Trained 128 records in 0.086349695 seconds. Throughput is 1482.3445 records/second. Loss is 1.19302. Sequential266afc8b's hyper parameters: Current learning rate is 3.14070351758794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 34816/60000][Iteration 3086][Wall Clock 298.309317512s] Trained 128 records in 0.090534546 seconds. Throughput is 1413.825 records/second. Loss is 1.330251. Sequential266afc8b's hyper parameters: Current learning rate is 3.139717425431711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 34944/60000][Iteration 3087][Wall Clock 298.392537879s] Trained 128 records in 0.083220367 seconds. Throughput is 1538.085 records/second. Loss is 1.2591412. Sequential266afc8b's hyper parameters: Current learning rate is 3.1387319522912746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 35072/60000][Iteration 3088][Wall Clock 298.477984911s] Trained 128 records in 0.085447032 seconds. Throughput is 1498.0042 records/second. Loss is 1.1459215. Sequential266afc8b's hyper parameters: Current learning rate is 3.1377470975839345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 35200/60000][Iteration 3089][Wall Clock 298.55930084s] Trained 128 records in 0.081315929 seconds. Throughput is 1574.1074 records/second. Loss is 1.2067299. Sequential266afc8b's hyper parameters: Current learning rate is 3.1367628607277293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 35328/60000][Iteration 3090][Wall Clock 298.644297991s] Trained 128 records in 0.084997151 seconds. Throughput is 1505.9329 records/second. Loss is 1.1705127. Sequential266afc8b's hyper parameters: Current learning rate is 3.1357792411414236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 35456/60000][Iteration 3091][Wall Clock 298.734089136s] Trained 128 records in 0.089791145 seconds. Throughput is 1425.5304 records/second. Loss is 1.2148057. Sequential266afc8b's hyper parameters: Current learning rate is 3.134796238244514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:17 INFO  DistriOptimizer$:408 - [Epoch 7 35584/60000][Iteration 3092][Wall Clock 298.821181983s] Trained 128 records in 0.087092847 seconds. Throughput is 1469.6959 records/second. Loss is 1.1166531. Sequential266afc8b's hyper parameters: Current learning rate is 3.1338138514572234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 35712/60000][Iteration 3093][Wall Clock 298.903700971s] Trained 128 records in 0.082518988 seconds. Throughput is 1551.1582 records/second. Loss is 1.1899338. Sequential266afc8b's hyper parameters: Current learning rate is 3.132832080200501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 35840/60000][Iteration 3094][Wall Clock 298.993666661s] Trained 128 records in 0.08996569 seconds. Throughput is 1422.7645 records/second. Loss is 1.3439773. Sequential266afc8b's hyper parameters: Current learning rate is 3.1318509238960227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 35968/60000][Iteration 3095][Wall Clock 299.079655975s] Trained 128 records in 0.085989314 seconds. Throughput is 1488.5571 records/second. Loss is 1.1779755. Sequential266afc8b's hyper parameters: Current learning rate is 3.1308703819661864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36096/60000][Iteration 3096][Wall Clock 299.167711606s] Trained 128 records in 0.088055631 seconds. Throughput is 1453.6265 records/second. Loss is 1.303663. Sequential266afc8b's hyper parameters: Current learning rate is 3.129890453834116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36224/60000][Iteration 3097][Wall Clock 299.254434673s] Trained 128 records in 0.086723067 seconds. Throughput is 1475.9625 records/second. Loss is 1.2925813. Sequential266afc8b's hyper parameters: Current learning rate is 3.1289111389236547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36352/60000][Iteration 3098][Wall Clock 299.342595094s] Trained 128 records in 0.088160421 seconds. Throughput is 1451.8987 records/second. Loss is 1.3002368. Sequential266afc8b's hyper parameters: Current learning rate is 3.127932436659368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36480/60000][Iteration 3099][Wall Clock 299.42799278s] Trained 128 records in 0.085397686 seconds. Throughput is 1498.8698 records/second. Loss is 1.3627332. Sequential266afc8b's hyper parameters: Current learning rate is 3.1269543464665416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36608/60000][Iteration 3100][Wall Clock 299.512195006s] Trained 128 records in 0.084202226 seconds. Throughput is 1520.1499 records/second. Loss is 1.1558233. Sequential266afc8b's hyper parameters: Current learning rate is 3.1259768677711783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36736/60000][Iteration 3101][Wall Clock 299.597229521s] Trained 128 records in 0.085034515 seconds. Throughput is 1505.2711 records/second. Loss is 1.2895153. Sequential266afc8b's hyper parameters: Current learning rate is 3.125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36864/60000][Iteration 3102][Wall Clock 299.681265897s] Trained 128 records in 0.084036376 seconds. Throughput is 1523.15 records/second. Loss is 1.2215966. Sequential266afc8b's hyper parameters: Current learning rate is 3.124023742580443E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:18 INFO  DistriOptimizer$:408 - [Epoch 7 36992/60000][Iteration 3103][Wall Clock 299.767069346s] Trained 128 records in 0.085803449 seconds. Throughput is 1491.7815 records/second. Loss is 1.3011297. Sequential266afc8b's hyper parameters: Current learning rate is 3.1230480949406624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37120/60000][Iteration 3104][Wall Clock 299.853744831s] Trained 128 records in 0.086675485 seconds. Throughput is 1476.7728 records/second. Loss is 1.2357314. Sequential266afc8b's hyper parameters: Current learning rate is 3.1220730565095225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37248/60000][Iteration 3105][Wall Clock 299.938599155s] Trained 128 records in 0.084854324 seconds. Throughput is 1508.4675 records/second. Loss is 1.2372708. Sequential266afc8b's hyper parameters: Current learning rate is 3.1210986267166043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37376/60000][Iteration 3106][Wall Clock 300.026460206s] Trained 128 records in 0.087861051 seconds. Throughput is 1456.8457 records/second. Loss is 1.3277406. Sequential266afc8b's hyper parameters: Current learning rate is 3.1201248049922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37504/60000][Iteration 3107][Wall Clock 300.116615745s] Trained 128 records in 0.090155539 seconds. Throughput is 1419.7686 records/second. Loss is 1.312832. Sequential266afc8b's hyper parameters: Current learning rate is 3.1191515907673113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37632/60000][Iteration 3108][Wall Clock 300.202193736s] Trained 128 records in 0.085577991 seconds. Throughput is 1495.7117 records/second. Loss is 1.2040398. Sequential266afc8b's hyper parameters: Current learning rate is 3.118178983473651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37760/60000][Iteration 3109][Wall Clock 300.286045282s] Trained 128 records in 0.083851546 seconds. Throughput is 1526.5073 records/second. Loss is 1.2492828. Sequential266afc8b's hyper parameters: Current learning rate is 3.1172069825436414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 37888/60000][Iteration 3110][Wall Clock 300.37368607s] Trained 128 records in 0.087640788 seconds. Throughput is 1460.5072 records/second. Loss is 1.2043853. Sequential266afc8b's hyper parameters: Current learning rate is 3.116235587410408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 38016/60000][Iteration 3111][Wall Clock 300.474605522s] Trained 128 records in 0.100919452 seconds. Throughput is 1268.3383 records/second. Loss is 1.2318853. Sequential266afc8b's hyper parameters: Current learning rate is 3.1152647975077883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 38144/60000][Iteration 3112][Wall Clock 300.557968843s] Trained 128 records in 0.083363321 seconds. Throughput is 1535.4474 records/second. Loss is 1.3401287. Sequential266afc8b's hyper parameters: Current learning rate is 3.114294612270321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 38272/60000][Iteration 3113][Wall Clock 300.641878619s] Trained 128 records in 0.083909776 seconds. Throughput is 1525.4481 records/second. Loss is 1.2240764. Sequential266afc8b's hyper parameters: Current learning rate is 3.11332503113325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 38400/60000][Iteration 3114][Wall Clock 300.721799941s] Trained 128 records in 0.079921322 seconds. Throughput is 1601.5752 records/second. Loss is 1.233386. Sequential266afc8b's hyper parameters: Current learning rate is 3.112356053532525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:19 INFO  DistriOptimizer$:408 - [Epoch 7 38528/60000][Iteration 3115][Wall Clock 300.80729692s] Trained 128 records in 0.085496979 seconds. Throughput is 1497.1289 records/second. Loss is 1.1957483. Sequential266afc8b's hyper parameters: Current learning rate is 3.1113876789047915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 38656/60000][Iteration 3116][Wall Clock 300.897402016s] Trained 128 records in 0.090105096 seconds. Throughput is 1420.5634 records/second. Loss is 1.351086. Sequential266afc8b's hyper parameters: Current learning rate is 3.1104199066874026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 38784/60000][Iteration 3117][Wall Clock 300.98593169s] Trained 128 records in 0.088529674 seconds. Throughput is 1445.8429 records/second. Loss is 1.1910163. Sequential266afc8b's hyper parameters: Current learning rate is 3.1094527363184084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 38912/60000][Iteration 3118][Wall Clock 301.073268713s] Trained 128 records in 0.087337023 seconds. Throughput is 1465.5869 records/second. Loss is 1.2511567. Sequential266afc8b's hyper parameters: Current learning rate is 3.1084861672365556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39040/60000][Iteration 3119][Wall Clock 301.169644054s] Trained 128 records in 0.096375341 seconds. Throughput is 1328.1406 records/second. Loss is 1.26877. Sequential266afc8b's hyper parameters: Current learning rate is 3.107520198881293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39168/60000][Iteration 3120][Wall Clock 301.254636139s] Trained 128 records in 0.084992085 seconds. Throughput is 1506.0226 records/second. Loss is 1.1088558. Sequential266afc8b's hyper parameters: Current learning rate is 3.106554830692762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39296/60000][Iteration 3121][Wall Clock 301.337890653s] Trained 128 records in 0.083254514 seconds. Throughput is 1537.4541 records/second. Loss is 1.2556267. Sequential266afc8b's hyper parameters: Current learning rate is 3.105590062111801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39424/60000][Iteration 3122][Wall Clock 301.428127781s] Trained 128 records in 0.090237128 seconds. Throughput is 1418.4849 records/second. Loss is 1.2835679. Sequential266afc8b's hyper parameters: Current learning rate is 3.104625892579944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39552/60000][Iteration 3123][Wall Clock 301.51509272s] Trained 128 records in 0.086964939 seconds. Throughput is 1471.8574 records/second. Loss is 1.1150012. Sequential266afc8b's hyper parameters: Current learning rate is 3.1036623215394165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39680/60000][Iteration 3124][Wall Clock 301.600974053s] Trained 128 records in 0.085881333 seconds. Throughput is 1490.4287 records/second. Loss is 1.215359. Sequential266afc8b's hyper parameters: Current learning rate is 3.1026993484331366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39808/60000][Iteration 3125][Wall Clock 301.688104673s] Trained 128 records in 0.08713062 seconds. Throughput is 1469.0587 records/second. Loss is 1.1647561. Sequential266afc8b's hyper parameters: Current learning rate is 3.1017369727047146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:20 INFO  DistriOptimizer$:408 - [Epoch 7 39936/60000][Iteration 3126][Wall Clock 301.77594827s] Trained 128 records in 0.087843597 seconds. Throughput is 1457.1353 records/second. Loss is 1.2810583. Sequential266afc8b's hyper parameters: Current learning rate is 3.10077519379845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40064/60000][Iteration 3127][Wall Clock 301.861087314s] Trained 128 records in 0.085139044 seconds. Throughput is 1503.4231 records/second. Loss is 1.2127973. Sequential266afc8b's hyper parameters: Current learning rate is 3.09981401115933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40192/60000][Iteration 3128][Wall Clock 301.948757229s] Trained 128 records in 0.087669915 seconds. Throughput is 1460.022 records/second. Loss is 1.2603937. Sequential266afc8b's hyper parameters: Current learning rate is 3.0988534242330345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40320/60000][Iteration 3129][Wall Clock 302.036532367s] Trained 128 records in 0.087775138 seconds. Throughput is 1458.2716 records/second. Loss is 1.2559228. Sequential266afc8b's hyper parameters: Current learning rate is 3.097893432465923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40448/60000][Iteration 3130][Wall Clock 302.125133082s] Trained 128 records in 0.088600715 seconds. Throughput is 1444.6836 records/second. Loss is 1.2141097. Sequential266afc8b's hyper parameters: Current learning rate is 3.096934035305048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40576/60000][Iteration 3131][Wall Clock 302.21788059s] Trained 128 records in 0.092747508 seconds. Throughput is 1380.091 records/second. Loss is 1.2851562. Sequential266afc8b's hyper parameters: Current learning rate is 3.0959752321981426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40704/60000][Iteration 3132][Wall Clock 302.307326749s] Trained 128 records in 0.089446159 seconds. Throughput is 1431.0284 records/second. Loss is 1.1749548. Sequential266afc8b's hyper parameters: Current learning rate is 3.0950170225936243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40832/60000][Iteration 3133][Wall Clock 302.393659655s] Trained 128 records in 0.086332906 seconds. Throughput is 1482.6329 records/second. Loss is 1.2258804. Sequential266afc8b's hyper parameters: Current learning rate is 3.094059405940594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 40960/60000][Iteration 3134][Wall Clock 302.48013371s] Trained 128 records in 0.086474055 seconds. Throughput is 1480.2128 records/second. Loss is 1.175601. Sequential266afc8b's hyper parameters: Current learning rate is 3.093102381688834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 41088/60000][Iteration 3135][Wall Clock 302.573554727s] Trained 128 records in 0.093421017 seconds. Throughput is 1370.1414 records/second. Loss is 1.3164406. Sequential266afc8b's hyper parameters: Current learning rate is 3.092145949288806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 41216/60000][Iteration 3136][Wall Clock 302.662985185s] Trained 128 records in 0.089430458 seconds. Throughput is 1431.2797 records/second. Loss is 1.3407954. Sequential266afc8b's hyper parameters: Current learning rate is 3.091190108191654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:21 INFO  DistriOptimizer$:408 - [Epoch 7 41344/60000][Iteration 3137][Wall Clock 302.766352327s] Trained 128 records in 0.103367142 seconds. Throughput is 1238.3046 records/second. Loss is 1.3009683. Sequential266afc8b's hyper parameters: Current learning rate is 3.090234857849197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 41472/60000][Iteration 3138][Wall Clock 302.849940305s] Trained 128 records in 0.083587978 seconds. Throughput is 1531.3208 records/second. Loss is 1.2539303. Sequential266afc8b's hyper parameters: Current learning rate is 3.089280197713932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 41600/60000][Iteration 3139][Wall Clock 302.927892401s] Trained 128 records in 0.077952096 seconds. Throughput is 1642.0342 records/second. Loss is 1.2656178. Sequential266afc8b's hyper parameters: Current learning rate is 3.088326127239037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 41728/60000][Iteration 3140][Wall Clock 303.015952512s] Trained 128 records in 0.088060111 seconds. Throughput is 1453.5526 records/second. Loss is 1.2752433. Sequential266afc8b's hyper parameters: Current learning rate is 3.0873726458783575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 41856/60000][Iteration 3141][Wall Clock 303.104758508s] Trained 128 records in 0.088805996 seconds. Throughput is 1441.3441 records/second. Loss is 1.2339408. Sequential266afc8b's hyper parameters: Current learning rate is 3.086419753086419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 41984/60000][Iteration 3142][Wall Clock 303.188497228s] Trained 128 records in 0.08373872 seconds. Throughput is 1528.5641 records/second. Loss is 1.2050688. Sequential266afc8b's hyper parameters: Current learning rate is 3.085467448318421E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42112/60000][Iteration 3143][Wall Clock 303.276579721s] Trained 128 records in 0.088082493 seconds. Throughput is 1453.1832 records/second. Loss is 1.2657428. Sequential266afc8b's hyper parameters: Current learning rate is 3.0845157310302283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42240/60000][Iteration 3144][Wall Clock 303.35803745s] Trained 128 records in 0.081457729 seconds. Throughput is 1571.3672 records/second. Loss is 1.2016981. Sequential266afc8b's hyper parameters: Current learning rate is 3.0835646006783845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42368/60000][Iteration 3145][Wall Clock 303.454933156s] Trained 128 records in 0.096895706 seconds. Throughput is 1321.0079 records/second. Loss is 1.3056395. Sequential266afc8b's hyper parameters: Current learning rate is 3.0826140567200987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42496/60000][Iteration 3146][Wall Clock 303.539260472s] Trained 128 records in 0.084327316 seconds. Throughput is 1517.8948 records/second. Loss is 1.3282428. Sequential266afc8b's hyper parameters: Current learning rate is 3.0816640986132507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42624/60000][Iteration 3147][Wall Clock 303.624866561s] Trained 128 records in 0.085606089 seconds. Throughput is 1495.2207 records/second. Loss is 1.1266673. Sequential266afc8b's hyper parameters: Current learning rate is 3.0807147258163895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42752/60000][Iteration 3148][Wall Clock 303.711616716s] Trained 128 records in 0.086750155 seconds. Throughput is 1475.5017 records/second. Loss is 1.2266164. Sequential266afc8b's hyper parameters: Current learning rate is 3.079765937788728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:22 INFO  DistriOptimizer$:408 - [Epoch 7 42880/60000][Iteration 3149][Wall Clock 303.800192021s] Trained 128 records in 0.088575305 seconds. Throughput is 1445.098 records/second. Loss is 1.218352. Sequential266afc8b's hyper parameters: Current learning rate is 3.0788177339901473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43008/60000][Iteration 3150][Wall Clock 303.883795155s] Trained 128 records in 0.083603134 seconds. Throughput is 1531.0431 records/second. Loss is 1.3422173. Sequential266afc8b's hyper parameters: Current learning rate is 3.077870113881194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43136/60000][Iteration 3151][Wall Clock 303.96936818s] Trained 128 records in 0.085573025 seconds. Throughput is 1495.7985 records/second. Loss is 1.3004584. Sequential266afc8b's hyper parameters: Current learning rate is 3.076923076923077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43264/60000][Iteration 3152][Wall Clock 304.05606863s] Trained 128 records in 0.08670045 seconds. Throughput is 1476.3477 records/second. Loss is 1.2126803. Sequential266afc8b's hyper parameters: Current learning rate is 3.075976622577668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43392/60000][Iteration 3153][Wall Clock 304.141682746s] Trained 128 records in 0.085614116 seconds. Throughput is 1495.0806 records/second. Loss is 1.186871. Sequential266afc8b's hyper parameters: Current learning rate is 3.0750307503075037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43520/60000][Iteration 3154][Wall Clock 304.226718087s] Trained 128 records in 0.085035341 seconds. Throughput is 1505.2566 records/second. Loss is 1.2771038. Sequential266afc8b's hyper parameters: Current learning rate is 3.074085459575776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43648/60000][Iteration 3155][Wall Clock 304.309819132s] Trained 128 records in 0.083101045 seconds. Throughput is 1540.2936 records/second. Loss is 1.2302493. Sequential266afc8b's hyper parameters: Current learning rate is 3.073140749846343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43776/60000][Iteration 3156][Wall Clock 304.39299439s] Trained 128 records in 0.083175258 seconds. Throughput is 1538.9192 records/second. Loss is 1.3593682. Sequential266afc8b's hyper parameters: Current learning rate is 3.072196620583718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 43904/60000][Iteration 3157][Wall Clock 304.482998885s] Trained 128 records in 0.090004495 seconds. Throughput is 1422.1511 records/second. Loss is 1.2510487. Sequential266afc8b's hyper parameters: Current learning rate is 3.071253071253071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 44032/60000][Iteration 3158][Wall Clock 304.569986248s] Trained 128 records in 0.086987363 seconds. Throughput is 1471.4781 records/second. Loss is 1.203257. Sequential266afc8b's hyper parameters: Current learning rate is 3.0703101013202335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 44160/60000][Iteration 3159][Wall Clock 304.653335574s] Trained 128 records in 0.083349326 seconds. Throughput is 1535.7053 records/second. Loss is 1.2175112. Sequential266afc8b's hyper parameters: Current learning rate is 3.0693677102516884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:23 INFO  DistriOptimizer$:408 - [Epoch 7 44288/60000][Iteration 3160][Wall Clock 304.740356933s] Trained 128 records in 0.087021359 seconds. Throughput is 1470.9033 records/second. Loss is 1.1549973. Sequential266afc8b's hyper parameters: Current learning rate is 3.0684258975145745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 44416/60000][Iteration 3161][Wall Clock 304.828512079s] Trained 128 records in 0.088155146 seconds. Throughput is 1451.9856 records/second. Loss is 1.185877. Sequential266afc8b's hyper parameters: Current learning rate is 3.0674846625766873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 44544/60000][Iteration 3162][Wall Clock 304.92721943s] Trained 128 records in 0.098707351 seconds. Throughput is 1296.7626 records/second. Loss is 1.2251133. Sequential266afc8b's hyper parameters: Current learning rate is 3.0665440049064706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 44672/60000][Iteration 3163][Wall Clock 305.016453928s] Trained 128 records in 0.089234498 seconds. Throughput is 1434.4227 records/second. Loss is 1.1688598. Sequential266afc8b's hyper parameters: Current learning rate is 3.0656039239730225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 44800/60000][Iteration 3164][Wall Clock 305.096508699s] Trained 128 records in 0.080054771 seconds. Throughput is 1598.9054 records/second. Loss is 1.2282292. Sequential266afc8b's hyper parameters: Current learning rate is 3.064664419246093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 44928/60000][Iteration 3165][Wall Clock 305.187554951s] Trained 128 records in 0.091046252 seconds. Throughput is 1405.8789 records/second. Loss is 1.2625198. Sequential266afc8b's hyper parameters: Current learning rate is 3.0637254901960784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45056/60000][Iteration 3166][Wall Clock 305.270610642s] Trained 128 records in 0.083055691 seconds. Throughput is 1541.1346 records/second. Loss is 1.1744628. Sequential266afc8b's hyper parameters: Current learning rate is 3.062787136294027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45184/60000][Iteration 3167][Wall Clock 305.356773546s] Trained 128 records in 0.086162904 seconds. Throughput is 1485.5581 records/second. Loss is 1.2362856. Sequential266afc8b's hyper parameters: Current learning rate is 3.0618493570116356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45312/60000][Iteration 3168][Wall Clock 305.445000812s] Trained 128 records in 0.088227266 seconds. Throughput is 1450.7987 records/second. Loss is 1.222007. Sequential266afc8b's hyper parameters: Current learning rate is 3.0609121518212427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45440/60000][Iteration 3169][Wall Clock 305.534397419s] Trained 128 records in 0.089396607 seconds. Throughput is 1431.8218 records/second. Loss is 1.2233514. Sequential266afc8b's hyper parameters: Current learning rate is 3.0599755201958387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45568/60000][Iteration 3170][Wall Clock 305.621913251s] Trained 128 records in 0.087515832 seconds. Throughput is 1462.5925 records/second. Loss is 1.2266265. Sequential266afc8b's hyper parameters: Current learning rate is 3.059039461609055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45696/60000][Iteration 3171][Wall Clock 305.700481195s] Trained 128 records in 0.078567944 seconds. Throughput is 1629.1632 records/second. Loss is 1.2759937. Sequential266afc8b's hyper parameters: Current learning rate is 3.058103975535168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:24 INFO  DistriOptimizer$:408 - [Epoch 7 45824/60000][Iteration 3172][Wall Clock 305.785594442s] Trained 128 records in 0.085113247 seconds. Throughput is 1503.8787 records/second. Loss is 1.2845775. Sequential266afc8b's hyper parameters: Current learning rate is 3.057169061449098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 45952/60000][Iteration 3173][Wall Clock 305.86881292s] Trained 128 records in 0.083218478 seconds. Throughput is 1538.12 records/second. Loss is 1.2708399. Sequential266afc8b's hyper parameters: Current learning rate is 3.056234718826406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46080/60000][Iteration 3174][Wall Clock 305.954628973s] Trained 128 records in 0.085816053 seconds. Throughput is 1491.5624 records/second. Loss is 1.2489398. Sequential266afc8b's hyper parameters: Current learning rate is 3.0553009471432935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46208/60000][Iteration 3175][Wall Clock 306.040412711s] Trained 128 records in 0.085783738 seconds. Throughput is 1492.1244 records/second. Loss is 1.1711425. Sequential266afc8b's hyper parameters: Current learning rate is 3.0543677458766036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46336/60000][Iteration 3176][Wall Clock 306.137606468s] Trained 128 records in 0.097193757 seconds. Throughput is 1316.957 records/second. Loss is 1.2710718. Sequential266afc8b's hyper parameters: Current learning rate is 3.053435114503817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46464/60000][Iteration 3177][Wall Clock 306.249182737s] Trained 128 records in 0.111576269 seconds. Throughput is 1147.1974 records/second. Loss is 1.2228016. Sequential266afc8b's hyper parameters: Current learning rate is 3.052503052503052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46592/60000][Iteration 3178][Wall Clock 306.357711524s] Trained 128 records in 0.108528787 seconds. Throughput is 1179.4106 records/second. Loss is 1.3066102. Sequential266afc8b's hyper parameters: Current learning rate is 3.0515715593530673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46720/60000][Iteration 3179][Wall Clock 306.468446006s] Trained 128 records in 0.110734482 seconds. Throughput is 1155.9181 records/second. Loss is 1.2183213. Sequential266afc8b's hyper parameters: Current learning rate is 3.050640634533252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46848/60000][Iteration 3180][Wall Clock 306.580619354s] Trained 128 records in 0.112173348 seconds. Throughput is 1141.0911 records/second. Loss is 1.3076648. Sequential266afc8b's hyper parameters: Current learning rate is 3.049710277523635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 46976/60000][Iteration 3181][Wall Clock 306.666760799s] Trained 128 records in 0.086141445 seconds. Throughput is 1485.9282 records/second. Loss is 1.2355434. Sequential266afc8b's hyper parameters: Current learning rate is 3.0487804878048786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:25 INFO  DistriOptimizer$:408 - [Epoch 7 47104/60000][Iteration 3182][Wall Clock 306.764431081s] Trained 128 records in 0.097670282 seconds. Throughput is 1310.5317 records/second. Loss is 1.2413504. Sequential266afc8b's hyper parameters: Current learning rate is 3.0478512648582747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 47232/60000][Iteration 3183][Wall Clock 306.852823588s] Trained 128 records in 0.088392507 seconds. Throughput is 1448.0865 records/second. Loss is 1.1111003. Sequential266afc8b's hyper parameters: Current learning rate is 3.046922608165753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 47360/60000][Iteration 3184][Wall Clock 306.970106187s] Trained 128 records in 0.117282599 seconds. Throughput is 1091.381 records/second. Loss is 1.2699016. Sequential266afc8b's hyper parameters: Current learning rate is 3.045994517209869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 47488/60000][Iteration 3185][Wall Clock 307.08383967s] Trained 128 records in 0.113733483 seconds. Throughput is 1125.4381 records/second. Loss is 1.1920745. Sequential266afc8b's hyper parameters: Current learning rate is 3.045066991473812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 47616/60000][Iteration 3186][Wall Clock 307.191575697s] Trained 128 records in 0.107736027 seconds. Throughput is 1188.0891 records/second. Loss is 1.1810268. Sequential266afc8b's hyper parameters: Current learning rate is 3.0441400304414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 47744/60000][Iteration 3187][Wall Clock 307.304641189s] Trained 128 records in 0.113065492 seconds. Throughput is 1132.0873 records/second. Loss is 1.2781919. Sequential266afc8b's hyper parameters: Current learning rate is 3.0432136335970786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 47872/60000][Iteration 3188][Wall Clock 307.452086172s] Trained 128 records in 0.147444983 seconds. Throughput is 868.1204 records/second. Loss is 1.2174037. Sequential266afc8b's hyper parameters: Current learning rate is 3.04228780042592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 48000/60000][Iteration 3189][Wall Clock 307.564823609s] Trained 128 records in 0.112737437 seconds. Throughput is 1135.3815 records/second. Loss is 1.2381146. Sequential266afc8b's hyper parameters: Current learning rate is 3.041362530413626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 48128/60000][Iteration 3190][Wall Clock 307.679886253s] Trained 128 records in 0.115062644 seconds. Throughput is 1112.4375 records/second. Loss is 1.2457877. Sequential266afc8b's hyper parameters: Current learning rate is 3.040437823046519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:26 INFO  DistriOptimizer$:408 - [Epoch 7 48256/60000][Iteration 3191][Wall Clock 307.786492425s] Trained 128 records in 0.106606172 seconds. Throughput is 1200.6809 records/second. Loss is 1.1936947. Sequential266afc8b's hyper parameters: Current learning rate is 3.03951367781155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 48384/60000][Iteration 3192][Wall Clock 307.900451627s] Trained 128 records in 0.113959202 seconds. Throughput is 1123.209 records/second. Loss is 1.2034975. Sequential266afc8b's hyper parameters: Current learning rate is 3.038590094196293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 48512/60000][Iteration 3193][Wall Clock 308.0082758s] Trained 128 records in 0.107824173 seconds. Throughput is 1187.1178 records/second. Loss is 1.1983749. Sequential266afc8b's hyper parameters: Current learning rate is 3.0376670716889426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 48640/60000][Iteration 3194][Wall Clock 308.115967362s] Trained 128 records in 0.107691562 seconds. Throughput is 1188.5796 records/second. Loss is 1.2365494. Sequential266afc8b's hyper parameters: Current learning rate is 3.036744609778318E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 48768/60000][Iteration 3195][Wall Clock 308.223243802s] Trained 128 records in 0.10727644 seconds. Throughput is 1193.1791 records/second. Loss is 1.2021779. Sequential266afc8b's hyper parameters: Current learning rate is 3.0358227079538557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 48896/60000][Iteration 3196][Wall Clock 308.318042139s] Trained 128 records in 0.094798337 seconds. Throughput is 1350.2347 records/second. Loss is 1.221957. Sequential266afc8b's hyper parameters: Current learning rate is 3.0349013657056146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 49024/60000][Iteration 3197][Wall Clock 308.406066507s] Trained 128 records in 0.088024368 seconds. Throughput is 1454.1427 records/second. Loss is 1.2761064. Sequential266afc8b's hyper parameters: Current learning rate is 3.0339805825242716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 49152/60000][Iteration 3198][Wall Clock 308.495816441s] Trained 128 records in 0.089749934 seconds. Throughput is 1426.1849 records/second. Loss is 1.2894522. Sequential266afc8b's hyper parameters: Current learning rate is 3.0330603579011223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 49280/60000][Iteration 3199][Wall Clock 308.585889511s] Trained 128 records in 0.09007307 seconds. Throughput is 1421.0685 records/second. Loss is 1.2955047. Sequential266afc8b's hyper parameters: Current learning rate is 3.032140691328077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 49408/60000][Iteration 3200][Wall Clock 308.694013089s] Trained 128 records in 0.108123578 seconds. Throughput is 1183.8306 records/second. Loss is 1.2673919. Sequential266afc8b's hyper parameters: Current learning rate is 3.031221582297666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:27 INFO  DistriOptimizer$:408 - [Epoch 7 49536/60000][Iteration 3201][Wall Clock 308.779318894s] Trained 128 records in 0.085305805 seconds. Throughput is 1500.4841 records/second. Loss is 1.2952533. Sequential266afc8b's hyper parameters: Current learning rate is 3.0303030303030303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 49664/60000][Iteration 3202][Wall Clock 308.865786176s] Trained 128 records in 0.086467282 seconds. Throughput is 1480.3287 records/second. Loss is 1.2176267. Sequential266afc8b's hyper parameters: Current learning rate is 3.029385034837928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 49792/60000][Iteration 3203][Wall Clock 308.952255525s] Trained 128 records in 0.086469349 seconds. Throughput is 1480.2932 records/second. Loss is 1.2305804. Sequential266afc8b's hyper parameters: Current learning rate is 3.028467595396729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 49920/60000][Iteration 3204][Wall Clock 309.038171107s] Trained 128 records in 0.085915582 seconds. Throughput is 1489.8346 records/second. Loss is 1.2877188. Sequential266afc8b's hyper parameters: Current learning rate is 3.027550711474417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50048/60000][Iteration 3205][Wall Clock 309.128537204s] Trained 128 records in 0.090366097 seconds. Throughput is 1416.4604 records/second. Loss is 1.2399673. Sequential266afc8b's hyper parameters: Current learning rate is 3.026634382566586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50176/60000][Iteration 3206][Wall Clock 309.214986951s] Trained 128 records in 0.086449747 seconds. Throughput is 1480.6289 records/second. Loss is 1.2239076. Sequential266afc8b's hyper parameters: Current learning rate is 3.0257186081694405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50304/60000][Iteration 3207][Wall Clock 309.303466866s] Trained 128 records in 0.088479915 seconds. Throughput is 1446.656 records/second. Loss is 1.1613988. Sequential266afc8b's hyper parameters: Current learning rate is 3.024803387779794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50432/60000][Iteration 3208][Wall Clock 309.391875954s] Trained 128 records in 0.088409088 seconds. Throughput is 1447.815 records/second. Loss is 1.202704. Sequential266afc8b's hyper parameters: Current learning rate is 3.023888720895071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50560/60000][Iteration 3209][Wall Clock 309.478179362s] Trained 128 records in 0.086303408 seconds. Throughput is 1483.1396 records/second. Loss is 1.1656333. Sequential266afc8b's hyper parameters: Current learning rate is 3.0229746070133015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50688/60000][Iteration 3210][Wall Clock 309.564670486s] Trained 128 records in 0.086491124 seconds. Throughput is 1479.9207 records/second. Loss is 1.2240108. Sequential266afc8b's hyper parameters: Current learning rate is 3.022061045633122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50816/60000][Iteration 3211][Wall Clock 309.650037465s] Trained 128 records in 0.085366979 seconds. Throughput is 1499.4088 records/second. Loss is 1.170492. Sequential266afc8b's hyper parameters: Current learning rate is 3.0211480362537764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:28 INFO  DistriOptimizer$:408 - [Epoch 7 50944/60000][Iteration 3212][Wall Clock 309.735196794s] Trained 128 records in 0.085159329 seconds. Throughput is 1503.0648 records/second. Loss is 1.2811766. Sequential266afc8b's hyper parameters: Current learning rate is 3.020235578375113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51072/60000][Iteration 3213][Wall Clock 309.832755542s] Trained 128 records in 0.097558748 seconds. Throughput is 1312.0299 records/second. Loss is 1.2758482. Sequential266afc8b's hyper parameters: Current learning rate is 3.019323671497585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51200/60000][Iteration 3214][Wall Clock 309.916995183s] Trained 128 records in 0.084239641 seconds. Throughput is 1519.4747 records/second. Loss is 1.2385402. Sequential266afc8b's hyper parameters: Current learning rate is 3.0184123151222455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51328/60000][Iteration 3215][Wall Clock 309.99567092s] Trained 128 records in 0.078675737 seconds. Throughput is 1626.931 records/second. Loss is 1.3339204. Sequential266afc8b's hyper parameters: Current learning rate is 3.0175015087507544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51456/60000][Iteration 3216][Wall Clock 310.080941043s] Trained 128 records in 0.085270123 seconds. Throughput is 1501.1119 records/second. Loss is 1.1967258. Sequential266afc8b's hyper parameters: Current learning rate is 3.0165912518853697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51584/60000][Iteration 3217][Wall Clock 310.170449265s] Trained 128 records in 0.089508222 seconds. Throughput is 1430.0363 records/second. Loss is 1.2683367. Sequential266afc8b's hyper parameters: Current learning rate is 3.0156815440289503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51712/60000][Iteration 3218][Wall Clock 310.259527804s] Trained 128 records in 0.089078539 seconds. Throughput is 1436.9342 records/second. Loss is 1.2593046. Sequential266afc8b's hyper parameters: Current learning rate is 3.0147723846849563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51840/60000][Iteration 3219][Wall Clock 310.348835393s] Trained 128 records in 0.089307589 seconds. Throughput is 1433.2488 records/second. Loss is 1.1409874. Sequential266afc8b's hyper parameters: Current learning rate is 3.013863773357444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 51968/60000][Iteration 3220][Wall Clock 310.436089075s] Trained 128 records in 0.087253682 seconds. Throughput is 1466.9868 records/second. Loss is 1.1639413. Sequential266afc8b's hyper parameters: Current learning rate is 3.01295570955107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 52096/60000][Iteration 3221][Wall Clock 310.531600367s] Trained 128 records in 0.095511292 seconds. Throughput is 1340.1556 records/second. Loss is 1.1910563. Sequential266afc8b's hyper parameters: Current learning rate is 3.012048192771084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 52224/60000][Iteration 3222][Wall Clock 310.613856189s] Trained 128 records in 0.082255822 seconds. Throughput is 1556.1208 records/second. Loss is 1.2171333. Sequential266afc8b's hyper parameters: Current learning rate is 3.0111412225233364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:29 INFO  DistriOptimizer$:408 - [Epoch 7 52352/60000][Iteration 3223][Wall Clock 310.70597404s] Trained 128 records in 0.092117851 seconds. Throughput is 1389.5243 records/second. Loss is 1.2741017. Sequential266afc8b's hyper parameters: Current learning rate is 3.0102347983142685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 52480/60000][Iteration 3224][Wall Clock 310.793448415s] Trained 128 records in 0.087474375 seconds. Throughput is 1463.2856 records/second. Loss is 1.2464758. Sequential266afc8b's hyper parameters: Current learning rate is 3.0093289196509175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 52608/60000][Iteration 3225][Wall Clock 310.880302644s] Trained 128 records in 0.086854229 seconds. Throughput is 1473.7336 records/second. Loss is 1.3022203. Sequential266afc8b's hyper parameters: Current learning rate is 3.0084235860409147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 52736/60000][Iteration 3226][Wall Clock 310.965533194s] Trained 128 records in 0.08523055 seconds. Throughput is 1501.8088 records/second. Loss is 1.1884719. Sequential266afc8b's hyper parameters: Current learning rate is 3.007518796992481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 52864/60000][Iteration 3227][Wall Clock 311.055100351s] Trained 128 records in 0.089567157 seconds. Throughput is 1429.0953 records/second. Loss is 1.1473969. Sequential266afc8b's hyper parameters: Current learning rate is 3.006614552014432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 52992/60000][Iteration 3228][Wall Clock 311.141196712s] Trained 128 records in 0.086096361 seconds. Throughput is 1486.7063 records/second. Loss is 1.1118342. Sequential266afc8b's hyper parameters: Current learning rate is 3.0057108506161706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53120/60000][Iteration 3229][Wall Clock 311.225653786s] Trained 128 records in 0.084457074 seconds. Throughput is 1515.5627 records/second. Loss is 1.2870307. Sequential266afc8b's hyper parameters: Current learning rate is 3.0048076923076925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53248/60000][Iteration 3230][Wall Clock 311.315159676s] Trained 128 records in 0.08950589 seconds. Throughput is 1430.0735 records/second. Loss is 1.1559154. Sequential266afc8b's hyper parameters: Current learning rate is 3.0039050765995795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53376/60000][Iteration 3231][Wall Clock 311.403396684s] Trained 128 records in 0.088237008 seconds. Throughput is 1450.6384 records/second. Loss is 1.2498883. Sequential266afc8b's hyper parameters: Current learning rate is 3.0030030030030034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53504/60000][Iteration 3232][Wall Clock 311.490953373s] Trained 128 records in 0.087556689 seconds. Throughput is 1461.91 records/second. Loss is 1.3168523. Sequential266afc8b's hyper parameters: Current learning rate is 3.002101471029721E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53632/60000][Iteration 3233][Wall Clock 311.575612409s] Trained 128 records in 0.084659036 seconds. Throughput is 1511.9474 records/second. Loss is 1.3129067. Sequential266afc8b's hyper parameters: Current learning rate is 3.0012004801920766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53760/60000][Iteration 3234][Wall Clock 311.659019667s] Trained 128 records in 0.083407258 seconds. Throughput is 1534.6385 records/second. Loss is 1.3091468. Sequential266afc8b's hyper parameters: Current learning rate is 3.0003000300030005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:30 INFO  DistriOptimizer$:408 - [Epoch 7 53888/60000][Iteration 3235][Wall Clock 311.747926278s] Trained 128 records in 0.088906611 seconds. Throughput is 1439.713 records/second. Loss is 1.2457918. Sequential266afc8b's hyper parameters: Current learning rate is 2.9994001199760045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54016/60000][Iteration 3236][Wall Clock 311.837711516s] Trained 128 records in 0.089785238 seconds. Throughput is 1425.624 records/second. Loss is 1.2306184. Sequential266afc8b's hyper parameters: Current learning rate is 2.998500749625187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54144/60000][Iteration 3237][Wall Clock 311.923160966s] Trained 128 records in 0.08544945 seconds. Throughput is 1497.9617 records/second. Loss is 1.2162206. Sequential266afc8b's hyper parameters: Current learning rate is 2.997601918465228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54272/60000][Iteration 3238][Wall Clock 312.045362431s] Trained 128 records in 0.122201465 seconds. Throughput is 1047.4506 records/second. Loss is 1.2007676. Sequential266afc8b's hyper parameters: Current learning rate is 2.9967036260113877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54400/60000][Iteration 3239][Wall Clock 312.13592401s] Trained 128 records in 0.090561579 seconds. Throughput is 1413.403 records/second. Loss is 1.1135794. Sequential266afc8b's hyper parameters: Current learning rate is 2.995805871779509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54528/60000][Iteration 3240][Wall Clock 312.222471811s] Trained 128 records in 0.086547801 seconds. Throughput is 1478.9515 records/second. Loss is 1.2234428. Sequential266afc8b's hyper parameters: Current learning rate is 2.994908655286014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54656/60000][Iteration 3241][Wall Clock 312.306170315s] Trained 128 records in 0.083698504 seconds. Throughput is 1529.2986 records/second. Loss is 1.2214004. Sequential266afc8b's hyper parameters: Current learning rate is 2.994011976047904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54784/60000][Iteration 3242][Wall Clock 312.390752058s] Trained 128 records in 0.084581743 seconds. Throughput is 1513.329 records/second. Loss is 1.1692016. Sequential266afc8b's hyper parameters: Current learning rate is 2.9931158335827593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 54912/60000][Iteration 3243][Wall Clock 312.474279791s] Trained 128 records in 0.083527733 seconds. Throughput is 1532.425 records/second. Loss is 1.1908236. Sequential266afc8b's hyper parameters: Current learning rate is 2.992220227408737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 55040/60000][Iteration 3244][Wall Clock 312.560050624s] Trained 128 records in 0.085770833 seconds. Throughput is 1492.3489 records/second. Loss is 1.1475453. Sequential266afc8b's hyper parameters: Current learning rate is 2.991325157044571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 55168/60000][Iteration 3245][Wall Clock 312.644462737s] Trained 128 records in 0.084412113 seconds. Throughput is 1516.37 records/second. Loss is 1.2130961. Sequential266afc8b's hyper parameters: Current learning rate is 2.99043062200957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:31 INFO  DistriOptimizer$:408 - [Epoch 7 55296/60000][Iteration 3246][Wall Clock 312.735248028s] Trained 128 records in 0.090785291 seconds. Throughput is 1409.92 records/second. Loss is 1.2786865. Sequential266afc8b's hyper parameters: Current learning rate is 2.989536621823617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 55424/60000][Iteration 3247][Wall Clock 312.84476803s] Trained 128 records in 0.109520002 seconds. Throughput is 1168.7363 records/second. Loss is 1.1227798. Sequential266afc8b's hyper parameters: Current learning rate is 2.9886431560071725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 55552/60000][Iteration 3248][Wall Clock 312.931805227s] Trained 128 records in 0.087037197 seconds. Throughput is 1470.6356 records/second. Loss is 1.1590738. Sequential266afc8b's hyper parameters: Current learning rate is 2.987750224081267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 55680/60000][Iteration 3249][Wall Clock 313.030325942s] Trained 128 records in 0.098520715 seconds. Throughput is 1299.2191 records/second. Loss is 1.220972. Sequential266afc8b's hyper parameters: Current learning rate is 2.986857825567503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 55808/60000][Iteration 3250][Wall Clock 313.121955088s] Trained 128 records in 0.091629146 seconds. Throughput is 1396.9354 records/second. Loss is 1.26282. Sequential266afc8b's hyper parameters: Current learning rate is 2.985965959988056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 55936/60000][Iteration 3251][Wall Clock 313.21760332s] Trained 128 records in 0.095648232 seconds. Throughput is 1338.237 records/second. Loss is 1.2565551. Sequential266afc8b's hyper parameters: Current learning rate is 2.9850746268656717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 56064/60000][Iteration 3252][Wall Clock 313.313251281s] Trained 128 records in 0.095647961 seconds. Throughput is 1338.2407 records/second. Loss is 1.2944283. Sequential266afc8b's hyper parameters: Current learning rate is 2.984183825723665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 56192/60000][Iteration 3253][Wall Clock 313.415378927s] Trained 128 records in 0.102127646 seconds. Throughput is 1253.3335 records/second. Loss is 1.1756567. Sequential266afc8b's hyper parameters: Current learning rate is 2.9832935560859184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 56320/60000][Iteration 3254][Wall Clock 313.502352609s] Trained 128 records in 0.086973682 seconds. Throughput is 1471.7096 records/second. Loss is 1.2775987. Sequential266afc8b's hyper parameters: Current learning rate is 2.9824038174768865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 56448/60000][Iteration 3255][Wall Clock 313.589507133s] Trained 128 records in 0.087154524 seconds. Throughput is 1468.6559 records/second. Loss is 1.2809268. Sequential266afc8b's hyper parameters: Current learning rate is 2.9815146094215865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 56576/60000][Iteration 3256][Wall Clock 313.674827821s] Trained 128 records in 0.085320688 seconds. Throughput is 1500.2223 records/second. Loss is 1.20941. Sequential266afc8b's hyper parameters: Current learning rate is 2.980625931445604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:32 INFO  DistriOptimizer$:408 - [Epoch 7 56704/60000][Iteration 3257][Wall Clock 313.759761894s] Trained 128 records in 0.084934073 seconds. Throughput is 1507.0513 records/second. Loss is 1.2705302. Sequential266afc8b's hyper parameters: Current learning rate is 2.979737783075089E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 56832/60000][Iteration 3258][Wall Clock 313.847259166s] Trained 128 records in 0.087497272 seconds. Throughput is 1462.9027 records/second. Loss is 1.1919056. Sequential266afc8b's hyper parameters: Current learning rate is 2.978850163836759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 56960/60000][Iteration 3259][Wall Clock 313.933813729s] Trained 128 records in 0.086554563 seconds. Throughput is 1478.8359 records/second. Loss is 1.132411. Sequential266afc8b's hyper parameters: Current learning rate is 2.977963073257892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57088/60000][Iteration 3260][Wall Clock 314.019169713s] Trained 128 records in 0.085355984 seconds. Throughput is 1499.6019 records/second. Loss is 1.1439627. Sequential266afc8b's hyper parameters: Current learning rate is 2.977076510866329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57216/60000][Iteration 3261][Wall Clock 314.11173949s] Trained 128 records in 0.092569777 seconds. Throughput is 1382.7407 records/second. Loss is 1.2553678. Sequential266afc8b's hyper parameters: Current learning rate is 2.976190476190476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57344/60000][Iteration 3262][Wall Clock 314.199003072s] Trained 128 records in 0.087263582 seconds. Throughput is 1466.8203 records/second. Loss is 1.2152619. Sequential266afc8b's hyper parameters: Current learning rate is 2.975304968759298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57472/60000][Iteration 3263][Wall Clock 314.289920522s] Trained 128 records in 0.09091745 seconds. Throughput is 1407.8705 records/second. Loss is 1.2503481. Sequential266afc8b's hyper parameters: Current learning rate is 2.97441998810232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57600/60000][Iteration 3264][Wall Clock 314.378062679s] Trained 128 records in 0.088142157 seconds. Throughput is 1452.1996 records/second. Loss is 1.2469289. Sequential266afc8b's hyper parameters: Current learning rate is 2.973535533749628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57728/60000][Iteration 3265][Wall Clock 314.460457701s] Trained 128 records in 0.082395022 seconds. Throughput is 1553.4918 records/second. Loss is 1.1884162. Sequential266afc8b's hyper parameters: Current learning rate is 2.972651605231867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57856/60000][Iteration 3266][Wall Clock 314.546618859s] Trained 128 records in 0.086161158 seconds. Throughput is 1485.5881 records/second. Loss is 1.1784685. Sequential266afc8b's hyper parameters: Current learning rate is 2.971768202080238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 57984/60000][Iteration 3267][Wall Clock 314.632751583s] Trained 128 records in 0.086132724 seconds. Throughput is 1486.0786 records/second. Loss is 1.2755125. Sequential266afc8b's hyper parameters: Current learning rate is 2.9708853238265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:33 INFO  DistriOptimizer$:408 - [Epoch 7 58112/60000][Iteration 3268][Wall Clock 314.716625153s] Trained 128 records in 0.08387357 seconds. Throughput is 1526.1064 records/second. Loss is 1.1666754. Sequential266afc8b's hyper parameters: Current learning rate is 2.97000297000297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 58240/60000][Iteration 3269][Wall Clock 314.800684049s] Trained 128 records in 0.084058896 seconds. Throughput is 1522.7418 records/second. Loss is 1.2489014. Sequential266afc8b's hyper parameters: Current learning rate is 2.969121140142518E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 58368/60000][Iteration 3270][Wall Clock 314.886284599s] Trained 128 records in 0.08560055 seconds. Throughput is 1495.3175 records/second. Loss is 1.2441622. Sequential266afc8b's hyper parameters: Current learning rate is 2.9682398337785694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 58496/60000][Iteration 3271][Wall Clock 314.971263578s] Trained 128 records in 0.084978979 seconds. Throughput is 1506.2549 records/second. Loss is 1.1545513. Sequential266afc8b's hyper parameters: Current learning rate is 2.967359050445104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 58624/60000][Iteration 3272][Wall Clock 315.065685758s] Trained 128 records in 0.09442218 seconds. Throughput is 1355.6138 records/second. Loss is 1.2168239. Sequential266afc8b's hyper parameters: Current learning rate is 2.966478789676654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 58752/60000][Iteration 3273][Wall Clock 315.151663608s] Trained 128 records in 0.08597785 seconds. Throughput is 1488.7555 records/second. Loss is 1.173401. Sequential266afc8b's hyper parameters: Current learning rate is 2.965599051008304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 58880/60000][Iteration 3274][Wall Clock 315.241551826s] Trained 128 records in 0.089888218 seconds. Throughput is 1423.9908 records/second. Loss is 1.279609. Sequential266afc8b's hyper parameters: Current learning rate is 2.964719833975689E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 59008/60000][Iteration 3275][Wall Clock 315.329956744s] Trained 128 records in 0.088404918 seconds. Throughput is 1447.8833 records/second. Loss is 1.2766242. Sequential266afc8b's hyper parameters: Current learning rate is 2.963841138114997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 59136/60000][Iteration 3276][Wall Clock 315.417409876s] Trained 128 records in 0.087453132 seconds. Throughput is 1463.6411 records/second. Loss is 1.2986637. Sequential266afc8b's hyper parameters: Current learning rate is 2.962962962962963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 59264/60000][Iteration 3277][Wall Clock 315.50693542s] Trained 128 records in 0.089525544 seconds. Throughput is 1429.7595 records/second. Loss is 1.1517199. Sequential266afc8b's hyper parameters: Current learning rate is 2.962085308056872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 59392/60000][Iteration 3278][Wall Clock 315.595477006s] Trained 128 records in 0.088541586 seconds. Throughput is 1445.6483 records/second. Loss is 1.2193959. Sequential266afc8b's hyper parameters: Current learning rate is 2.961208172934557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:34 INFO  DistriOptimizer$:408 - [Epoch 7 59520/60000][Iteration 3279][Wall Clock 315.684791583s] Trained 128 records in 0.089314577 seconds. Throughput is 1433.1367 records/second. Loss is 1.1419021. Sequential266afc8b's hyper parameters: Current learning rate is 2.960331557134399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:35 INFO  DistriOptimizer$:408 - [Epoch 7 59648/60000][Iteration 3280][Wall Clock 315.771906576s] Trained 128 records in 0.087114993 seconds. Throughput is 1469.3224 records/second. Loss is 1.2028742. Sequential266afc8b's hyper parameters: Current learning rate is 2.959455460195324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:35 INFO  DistriOptimizer$:408 - [Epoch 7 59776/60000][Iteration 3281][Wall Clock 315.858076932s] Trained 128 records in 0.086170356 seconds. Throughput is 1485.4297 records/second. Loss is 1.1355059. Sequential266afc8b's hyper parameters: Current learning rate is 2.9585798816568053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:35 INFO  DistriOptimizer$:408 - [Epoch 7 59904/60000][Iteration 3282][Wall Clock 315.944874308s] Trained 128 records in 0.086797376 seconds. Throughput is 1474.6989 records/second. Loss is 1.2307975. Sequential266afc8b's hyper parameters: Current learning rate is 2.957704821058858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:35 INFO  DistriOptimizer$:408 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 316.033893886s] Trained 128 records in 0.089019578 seconds. Throughput is 1437.8859 records/second. Loss is 1.2559657. Sequential266afc8b's hyper parameters: Current learning rate is 2.9568302779420464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:35 INFO  DistriOptimizer$:452 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 316.033893886s] Epoch finished. Wall clock time is 317198.091232 ms
2019-10-15 08:23:35 INFO  DistriOptimizer$:111 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 316.033893886s] Validate model...
2019-10-15 08:23:36 INFO  DistriOptimizer$:178 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 316.033893886s] validate model throughput is 12226.389 records/second
2019-10-15 08:23:36 INFO  DistriOptimizer$:181 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 316.033893886s] Top1Accuracy is Accuracy(correct: 7383, count: 10000, accuracy: 0.7383)
2019-10-15 08:23:36 INFO  DistriOptimizer$:221 - [Wall Clock 317.198091232s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:23:36 INFO  DistriOptimizer$:226 - [Wall Clock 317.198091232s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 128/60000][Iteration 3284][Wall Clock 317.288327991s] Trained 128 records in 0.090236759 seconds. Throughput is 1418.4906 records/second. Loss is 1.1627332. Sequential266afc8b's hyper parameters: Current learning rate is 2.955956251847473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 256/60000][Iteration 3285][Wall Clock 317.366138593s] Trained 128 records in 0.077810602 seconds. Throughput is 1645.02 records/second. Loss is 1.2065468. Sequential266afc8b's hyper parameters: Current learning rate is 2.955082742316785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 384/60000][Iteration 3286][Wall Clock 317.456657655s] Trained 128 records in 0.090519062 seconds. Throughput is 1414.0668 records/second. Loss is 1.2993145. Sequential266afc8b's hyper parameters: Current learning rate is 2.954209748892171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 512/60000][Iteration 3287][Wall Clock 317.539630493s] Trained 128 records in 0.082972838 seconds. Throughput is 1542.6735 records/second. Loss is 1.2244794. Sequential266afc8b's hyper parameters: Current learning rate is 2.9533372711163615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 640/60000][Iteration 3288][Wall Clock 317.616185779s] Trained 128 records in 0.076555286 seconds. Throughput is 1671.9943 records/second. Loss is 1.2879742. Sequential266afc8b's hyper parameters: Current learning rate is 2.952465308532625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 768/60000][Iteration 3289][Wall Clock 317.70142392s] Trained 128 records in 0.085238141 seconds. Throughput is 1501.6752 records/second. Loss is 1.2267783. Sequential266afc8b's hyper parameters: Current learning rate is 2.9515938606847696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 896/60000][Iteration 3290][Wall Clock 317.790720094s] Trained 128 records in 0.089296174 seconds. Throughput is 1433.432 records/second. Loss is 1.3121688. Sequential266afc8b's hyper parameters: Current learning rate is 2.9507229271171436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 1024/60000][Iteration 3291][Wall Clock 317.876900654s] Trained 128 records in 0.08618056 seconds. Throughput is 1485.2538 records/second. Loss is 1.3544236. Sequential266afc8b's hyper parameters: Current learning rate is 2.949852507374631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:36 INFO  DistriOptimizer$:408 - [Epoch 8 1152/60000][Iteration 3292][Wall Clock 317.963208974s] Trained 128 records in 0.08630832 seconds. Throughput is 1483.0552 records/second. Loss is 1.1534327. Sequential266afc8b's hyper parameters: Current learning rate is 2.9489826010026536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 1280/60000][Iteration 3293][Wall Clock 318.048717515s] Trained 128 records in 0.085508541 seconds. Throughput is 1496.9265 records/second. Loss is 1.1991336. Sequential266afc8b's hyper parameters: Current learning rate is 2.9481132075471697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 1408/60000][Iteration 3294][Wall Clock 318.135625197s] Trained 128 records in 0.086907682 seconds. Throughput is 1472.8271 records/second. Loss is 1.1564468. Sequential266afc8b's hyper parameters: Current learning rate is 2.947244326554671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 1536/60000][Iteration 3295][Wall Clock 318.226024907s] Trained 128 records in 0.09039971 seconds. Throughput is 1415.9337 records/second. Loss is 1.2282394. Sequential266afc8b's hyper parameters: Current learning rate is 2.9463759575721867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 1664/60000][Iteration 3296][Wall Clock 318.321796958s] Trained 128 records in 0.095772051 seconds. Throughput is 1336.5068 records/second. Loss is 1.1556041. Sequential266afc8b's hyper parameters: Current learning rate is 2.945508100147275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 1792/60000][Iteration 3297][Wall Clock 318.40450665s] Trained 128 records in 0.082709692 seconds. Throughput is 1547.5817 records/second. Loss is 1.1294191. Sequential266afc8b's hyper parameters: Current learning rate is 2.944640753828033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 1920/60000][Iteration 3298][Wall Clock 318.490828465s] Trained 128 records in 0.086321815 seconds. Throughput is 1482.8232 records/second. Loss is 1.1198908. Sequential266afc8b's hyper parameters: Current learning rate is 2.9437739181630853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 2048/60000][Iteration 3299][Wall Clock 318.576629123s] Trained 128 records in 0.085800658 seconds. Throughput is 1491.8301 records/second. Loss is 1.1937025. Sequential266afc8b's hyper parameters: Current learning rate is 2.942907592701589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 2176/60000][Iteration 3300][Wall Clock 318.662062229s] Trained 128 records in 0.085433106 seconds. Throughput is 1498.2483 records/second. Loss is 1.1685959. Sequential266afc8b's hyper parameters: Current learning rate is 2.942041776993233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 2304/60000][Iteration 3301][Wall Clock 318.750382574s] Trained 128 records in 0.088320345 seconds. Throughput is 1449.2697 records/second. Loss is 1.2988313. Sequential266afc8b's hyper parameters: Current learning rate is 2.9411764705882356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 2432/60000][Iteration 3302][Wall Clock 318.836482027s] Trained 128 records in 0.086099453 seconds. Throughput is 1486.6528 records/second. Loss is 1.3283426. Sequential266afc8b's hyper parameters: Current learning rate is 2.940311673037342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:37 INFO  DistriOptimizer$:408 - [Epoch 8 2560/60000][Iteration 3303][Wall Clock 318.921728897s] Trained 128 records in 0.08524687 seconds. Throughput is 1501.5215 records/second. Loss is 1.2207599. Sequential266afc8b's hyper parameters: Current learning rate is 2.9394473838918284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 2688/60000][Iteration 3304][Wall Clock 319.013372116s] Trained 128 records in 0.091643219 seconds. Throughput is 1396.7208 records/second. Loss is 1.25477. Sequential266afc8b's hyper parameters: Current learning rate is 2.9385836027034966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 2816/60000][Iteration 3305][Wall Clock 319.098329339s] Trained 128 records in 0.084957223 seconds. Throughput is 1506.6406 records/second. Loss is 1.1960241. Sequential266afc8b's hyper parameters: Current learning rate is 2.937720329024677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 2944/60000][Iteration 3306][Wall Clock 319.182323404s] Trained 128 records in 0.083994065 seconds. Throughput is 1523.9171 records/second. Loss is 1.200384. Sequential266afc8b's hyper parameters: Current learning rate is 2.9368575624082237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3072/60000][Iteration 3307][Wall Clock 319.267258896s] Trained 128 records in 0.084935492 seconds. Throughput is 1507.026 records/second. Loss is 1.1315397. Sequential266afc8b's hyper parameters: Current learning rate is 2.935995302407516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3200/60000][Iteration 3308][Wall Clock 319.350118198s] Trained 128 records in 0.082859302 seconds. Throughput is 1544.7874 records/second. Loss is 1.2195534. Sequential266afc8b's hyper parameters: Current learning rate is 2.93513354857646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3328/60000][Iteration 3309][Wall Clock 319.437367179s] Trained 128 records in 0.087248981 seconds. Throughput is 1467.0658 records/second. Loss is 1.2260089. Sequential266afc8b's hyper parameters: Current learning rate is 2.9342723004694836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3456/60000][Iteration 3310][Wall Clock 319.523644606s] Trained 128 records in 0.086277427 seconds. Throughput is 1483.5862 records/second. Loss is 1.1237746. Sequential266afc8b's hyper parameters: Current learning rate is 2.933411557641537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3584/60000][Iteration 3311][Wall Clock 319.616395823s] Trained 128 records in 0.092751217 seconds. Throughput is 1380.0358 records/second. Loss is 1.2428036. Sequential266afc8b's hyper parameters: Current learning rate is 2.932551319648094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3712/60000][Iteration 3312][Wall Clock 319.70832924s] Trained 128 records in 0.091933417 seconds. Throughput is 1392.312 records/second. Loss is 1.1697867. Sequential266afc8b's hyper parameters: Current learning rate is 2.931691586045148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3840/60000][Iteration 3313][Wall Clock 319.824651745s] Trained 128 records in 0.116322505 seconds. Throughput is 1100.389 records/second. Loss is 1.1623665. Sequential266afc8b's hyper parameters: Current learning rate is 2.930832356389215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:38 INFO  DistriOptimizer$:408 - [Epoch 8 3968/60000][Iteration 3314][Wall Clock 319.939954412s] Trained 128 records in 0.115302667 seconds. Throughput is 1110.1217 records/second. Loss is 1.2569172. Sequential266afc8b's hyper parameters: Current learning rate is 2.929973630237328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4096/60000][Iteration 3315][Wall Clock 320.050244378s] Trained 128 records in 0.110289966 seconds. Throughput is 1160.577 records/second. Loss is 1.2104976. Sequential266afc8b's hyper parameters: Current learning rate is 2.9291154071470416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4224/60000][Iteration 3316][Wall Clock 320.138403966s] Trained 128 records in 0.088159588 seconds. Throughput is 1451.9124 records/second. Loss is 1.28997. Sequential266afc8b's hyper parameters: Current learning rate is 2.9282576866764275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4352/60000][Iteration 3317][Wall Clock 320.225200716s] Trained 128 records in 0.08679675 seconds. Throughput is 1474.7096 records/second. Loss is 1.2107065. Sequential266afc8b's hyper parameters: Current learning rate is 2.927400468384075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4480/60000][Iteration 3318][Wall Clock 320.308861668s] Trained 128 records in 0.083660952 seconds. Throughput is 1529.985 records/second. Loss is 1.2072396. Sequential266afc8b's hyper parameters: Current learning rate is 2.92654375182909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4608/60000][Iteration 3319][Wall Clock 320.395707196s] Trained 128 records in 0.086845528 seconds. Throughput is 1473.8813 records/second. Loss is 1.2839024. Sequential266afc8b's hyper parameters: Current learning rate is 2.925687536571094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4736/60000][Iteration 3320][Wall Clock 320.480916343s] Trained 128 records in 0.085209147 seconds. Throughput is 1502.1862 records/second. Loss is 1.2357358. Sequential266afc8b's hyper parameters: Current learning rate is 2.9248318221702257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4864/60000][Iteration 3321][Wall Clock 320.566305043s] Trained 128 records in 0.0853887 seconds. Throughput is 1499.0275 records/second. Loss is 1.1192299. Sequential266afc8b's hyper parameters: Current learning rate is 2.9239766081871346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 4992/60000][Iteration 3322][Wall Clock 320.667279996s] Trained 128 records in 0.100974953 seconds. Throughput is 1267.6411 records/second. Loss is 1.2809925. Sequential266afc8b's hyper parameters: Current learning rate is 2.9231218941829873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 5120/60000][Iteration 3323][Wall Clock 320.75257772s] Trained 128 records in 0.085297724 seconds. Throughput is 1500.6262 records/second. Loss is 1.2600621. Sequential266afc8b's hyper parameters: Current learning rate is 2.9222676797194627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 5248/60000][Iteration 3324][Wall Clock 320.832234167s] Trained 128 records in 0.079656447 seconds. Throughput is 1606.9008 records/second. Loss is 1.2051675. Sequential266afc8b's hyper parameters: Current learning rate is 2.9214139643587495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:39 INFO  DistriOptimizer$:408 - [Epoch 8 5376/60000][Iteration 3325][Wall Clock 320.917472478s] Trained 128 records in 0.085238311 seconds. Throughput is 1501.6722 records/second. Loss is 1.2391531. Sequential266afc8b's hyper parameters: Current learning rate is 2.920560747663551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 5504/60000][Iteration 3326][Wall Clock 321.005196796s] Trained 128 records in 0.087724318 seconds. Throughput is 1459.1165 records/second. Loss is 1.2415333. Sequential266afc8b's hyper parameters: Current learning rate is 2.9197080291970805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 5632/60000][Iteration 3327][Wall Clock 321.089560538s] Trained 128 records in 0.084363742 seconds. Throughput is 1517.2395 records/second. Loss is 1.3109902. Sequential266afc8b's hyper parameters: Current learning rate is 2.918855808523059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 5760/60000][Iteration 3328][Wall Clock 321.175939116s] Trained 128 records in 0.086378578 seconds. Throughput is 1481.849 records/second. Loss is 1.2105668. Sequential266afc8b's hyper parameters: Current learning rate is 2.918004085205719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 5888/60000][Iteration 3329][Wall Clock 321.263787439s] Trained 128 records in 0.087848323 seconds. Throughput is 1457.0569 records/second. Loss is 1.1924865. Sequential266afc8b's hyper parameters: Current learning rate is 2.9171528588098014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6016/60000][Iteration 3330][Wall Clock 321.34817597s] Trained 128 records in 0.084388531 seconds. Throughput is 1516.7938 records/second. Loss is 1.2351024. Sequential266afc8b's hyper parameters: Current learning rate is 2.9163021289005544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6144/60000][Iteration 3331][Wall Clock 321.433722315s] Trained 128 records in 0.085546345 seconds. Throughput is 1496.265 records/second. Loss is 1.2472831. Sequential266afc8b's hyper parameters: Current learning rate is 2.9154518950437323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6272/60000][Iteration 3332][Wall Clock 321.519345105s] Trained 128 records in 0.08562279 seconds. Throughput is 1494.9292 records/second. Loss is 1.2192265. Sequential266afc8b's hyper parameters: Current learning rate is 2.9146021568055957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6400/60000][Iteration 3333][Wall Clock 321.603897361s] Trained 128 records in 0.084552256 seconds. Throughput is 1513.8567 records/second. Loss is 1.2470798. Sequential266afc8b's hyper parameters: Current learning rate is 2.913752913752914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6528/60000][Iteration 3334][Wall Clock 321.689339451s] Trained 128 records in 0.08544209 seconds. Throughput is 1498.0907 records/second. Loss is 1.192632. Sequential266afc8b's hyper parameters: Current learning rate is 2.912904165452957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6656/60000][Iteration 3335][Wall Clock 321.772390777s] Trained 128 records in 0.083051326 seconds. Throughput is 1541.2157 records/second. Loss is 1.176822. Sequential266afc8b's hyper parameters: Current learning rate is 2.9120559114735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6784/60000][Iteration 3336][Wall Clock 321.864415887s] Trained 128 records in 0.09202511 seconds. Throughput is 1390.9247 records/second. Loss is 1.1126959. Sequential266afc8b's hyper parameters: Current learning rate is 2.9112081513828236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:40 INFO  DistriOptimizer$:408 - [Epoch 8 6912/60000][Iteration 3337][Wall Clock 321.952864592s] Trained 128 records in 0.088448705 seconds. Throughput is 1447.1665 records/second. Loss is 1.2161238. Sequential266afc8b's hyper parameters: Current learning rate is 2.910360884749709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7040/60000][Iteration 3338][Wall Clock 322.034662421s] Trained 128 records in 0.081797829 seconds. Throughput is 1564.8336 records/second. Loss is 1.1765099. Sequential266afc8b's hyper parameters: Current learning rate is 2.909514111143439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7168/60000][Iteration 3339][Wall Clock 322.120472361s] Trained 128 records in 0.08580994 seconds. Throughput is 1491.6687 records/second. Loss is 1.2053268. Sequential266afc8b's hyper parameters: Current learning rate is 2.9086678301337986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7296/60000][Iteration 3340][Wall Clock 322.204681353s] Trained 128 records in 0.084208992 seconds. Throughput is 1520.0276 records/second. Loss is 1.1833372. Sequential266afc8b's hyper parameters: Current learning rate is 2.907822041291073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7424/60000][Iteration 3341][Wall Clock 322.290077806s] Trained 128 records in 0.085396453 seconds. Throughput is 1498.8912 records/second. Loss is 1.3050116. Sequential266afc8b's hyper parameters: Current learning rate is 2.9069767441860465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7552/60000][Iteration 3342][Wall Clock 322.376646711s] Trained 128 records in 0.086568905 seconds. Throughput is 1478.591 records/second. Loss is 1.1692901. Sequential266afc8b's hyper parameters: Current learning rate is 2.9061319383900025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7680/60000][Iteration 3343][Wall Clock 322.462832318s] Trained 128 records in 0.086185607 seconds. Throughput is 1485.1669 records/second. Loss is 1.1989298. Sequential266afc8b's hyper parameters: Current learning rate is 2.905287623474724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7808/60000][Iteration 3344][Wall Clock 322.547913947s] Trained 128 records in 0.085081629 seconds. Throughput is 1504.4376 records/second. Loss is 1.1672043. Sequential266afc8b's hyper parameters: Current learning rate is 2.904443799012489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 7936/60000][Iteration 3345][Wall Clock 322.634178612s] Trained 128 records in 0.086264665 seconds. Throughput is 1483.8057 records/second. Loss is 1.2050126. Sequential266afc8b's hyper parameters: Current learning rate is 2.9036004645760743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 8064/60000][Iteration 3346][Wall Clock 322.721639477s] Trained 128 records in 0.087460865 seconds. Throughput is 1463.5116 records/second. Loss is 1.3044088. Sequential266afc8b's hyper parameters: Current learning rate is 2.9027576197387516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 8192/60000][Iteration 3347][Wall Clock 322.80704048s] Trained 128 records in 0.085401003 seconds. Throughput is 1498.8114 records/second. Loss is 1.1606052. Sequential266afc8b's hyper parameters: Current learning rate is 2.901915264074289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:41 INFO  DistriOptimizer$:408 - [Epoch 8 8320/60000][Iteration 3348][Wall Clock 322.90412322s] Trained 128 records in 0.09708274 seconds. Throughput is 1318.463 records/second. Loss is 1.1783925. Sequential266afc8b's hyper parameters: Current learning rate is 2.901073397156948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 8448/60000][Iteration 3349][Wall Clock 322.990776235s] Trained 128 records in 0.086653015 seconds. Throughput is 1477.1558 records/second. Loss is 1.2249115. Sequential266afc8b's hyper parameters: Current learning rate is 2.900232018561485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 8576/60000][Iteration 3350][Wall Clock 323.072836619s] Trained 128 records in 0.082060384 seconds. Throughput is 1559.827 records/second. Loss is 1.1817428. Sequential266afc8b's hyper parameters: Current learning rate is 2.8993911278631486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 8704/60000][Iteration 3351][Wall Clock 323.158607348s] Trained 128 records in 0.085770729 seconds. Throughput is 1492.3507 records/second. Loss is 1.1791524. Sequential266afc8b's hyper parameters: Current learning rate is 2.898550724637681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 8832/60000][Iteration 3352][Wall Clock 323.247532745s] Trained 128 records in 0.088925397 seconds. Throughput is 1439.4088 records/second. Loss is 1.1644622. Sequential266afc8b's hyper parameters: Current learning rate is 2.897710808461316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 8960/60000][Iteration 3353][Wall Clock 323.335986259s] Trained 128 records in 0.088453514 seconds. Throughput is 1447.0878 records/second. Loss is 1.098659. Sequential266afc8b's hyper parameters: Current learning rate is 2.8968713789107763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9088/60000][Iteration 3354][Wall Clock 323.422502536s] Trained 128 records in 0.086516277 seconds. Throughput is 1479.4904 records/second. Loss is 1.2205585. Sequential266afc8b's hyper parameters: Current learning rate is 2.896032435563278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9216/60000][Iteration 3355][Wall Clock 323.507184868s] Trained 128 records in 0.084682332 seconds. Throughput is 1511.5314 records/second. Loss is 1.231517. Sequential266afc8b's hyper parameters: Current learning rate is 2.895193977996526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9344/60000][Iteration 3356][Wall Clock 323.590224688s] Trained 128 records in 0.08303982 seconds. Throughput is 1541.4292 records/second. Loss is 1.2499837. Sequential266afc8b's hyper parameters: Current learning rate is 2.8943560057887124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9472/60000][Iteration 3357][Wall Clock 323.675157635s] Trained 128 records in 0.084932947 seconds. Throughput is 1507.0713 records/second. Loss is 1.2417318. Sequential266afc8b's hyper parameters: Current learning rate is 2.8935185185185184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9600/60000][Iteration 3358][Wall Clock 323.759294437s] Trained 128 records in 0.084136802 seconds. Throughput is 1521.3319 records/second. Loss is 1.2480011. Sequential266afc8b's hyper parameters: Current learning rate is 2.8926815157651146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9728/60000][Iteration 3359][Wall Clock 323.845832655s] Trained 128 records in 0.086538218 seconds. Throughput is 1479.1152 records/second. Loss is 1.2441927. Sequential266afc8b's hyper parameters: Current learning rate is 2.8918449971081553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:42 INFO  DistriOptimizer$:408 - [Epoch 8 9856/60000][Iteration 3360][Wall Clock 323.934458998s] Trained 128 records in 0.088626343 seconds. Throughput is 1444.2659 records/second. Loss is 1.1965635. Sequential266afc8b's hyper parameters: Current learning rate is 2.8910089621277823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 9984/60000][Iteration 3361][Wall Clock 324.039997811s] Trained 128 records in 0.105538813 seconds. Throughput is 1212.824 records/second. Loss is 1.1678015. Sequential266afc8b's hyper parameters: Current learning rate is 2.8901734104046245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10112/60000][Iteration 3362][Wall Clock 324.125915922s] Trained 128 records in 0.085918111 seconds. Throughput is 1489.7906 records/second. Loss is 1.1186552. Sequential266afc8b's hyper parameters: Current learning rate is 2.889338341519792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10240/60000][Iteration 3363][Wall Clock 324.213882612s] Trained 128 records in 0.08796669 seconds. Throughput is 1455.0963 records/second. Loss is 1.2326591. Sequential266afc8b's hyper parameters: Current learning rate is 2.888503755054882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10368/60000][Iteration 3364][Wall Clock 324.297659435s] Trained 128 records in 0.083776823 seconds. Throughput is 1527.8689 records/second. Loss is 1.1747061. Sequential266afc8b's hyper parameters: Current learning rate is 2.887669650591972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10496/60000][Iteration 3365][Wall Clock 324.38344997s] Trained 128 records in 0.085790535 seconds. Throughput is 1492.006 records/second. Loss is 1.2525935. Sequential266afc8b's hyper parameters: Current learning rate is 2.886836027713626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10624/60000][Iteration 3366][Wall Clock 324.473977531s] Trained 128 records in 0.090527561 seconds. Throughput is 1413.934 records/second. Loss is 1.1929853. Sequential266afc8b's hyper parameters: Current learning rate is 2.886002886002886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10752/60000][Iteration 3367][Wall Clock 324.561596834s] Trained 128 records in 0.087619303 seconds. Throughput is 1460.8652 records/second. Loss is 1.226196. Sequential266afc8b's hyper parameters: Current learning rate is 2.8851702250432774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 10880/60000][Iteration 3368][Wall Clock 324.649840457s] Trained 128 records in 0.088243623 seconds. Throughput is 1450.5297 records/second. Loss is 1.1878452. Sequential266afc8b's hyper parameters: Current learning rate is 2.8843380444188056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 11008/60000][Iteration 3369][Wall Clock 324.734848617s] Trained 128 records in 0.08500816 seconds. Throughput is 1505.7378 records/second. Loss is 1.2694421. Sequential266afc8b's hyper parameters: Current learning rate is 2.883506343713956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 11136/60000][Iteration 3370][Wall Clock 324.822315712s] Trained 128 records in 0.087467095 seconds. Throughput is 1463.4075 records/second. Loss is 1.2397412. Sequential266afc8b's hyper parameters: Current learning rate is 2.882675122513693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:43 INFO  DistriOptimizer$:408 - [Epoch 8 11264/60000][Iteration 3371][Wall Clock 324.909449448s] Trained 128 records in 0.087133736 seconds. Throughput is 1469.0062 records/second. Loss is 1.202923. Sequential266afc8b's hyper parameters: Current learning rate is 2.881844380403458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 11392/60000][Iteration 3372][Wall Clock 324.996774256s] Trained 128 records in 0.087324808 seconds. Throughput is 1465.792 records/second. Loss is 1.139151. Sequential266afc8b's hyper parameters: Current learning rate is 2.881014116969173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 11520/60000][Iteration 3373][Wall Clock 325.093019257s] Trained 128 records in 0.096245001 seconds. Throughput is 1329.9392 records/second. Loss is 1.2715182. Sequential266afc8b's hyper parameters: Current learning rate is 2.880184331797235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 11648/60000][Iteration 3374][Wall Clock 325.180133821s] Trained 128 records in 0.087114564 seconds. Throughput is 1469.3295 records/second. Loss is 1.2823567. Sequential266afc8b's hyper parameters: Current learning rate is 2.8793550244745177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 11776/60000][Iteration 3375][Wall Clock 325.261841479s] Trained 128 records in 0.081707658 seconds. Throughput is 1566.5607 records/second. Loss is 1.2165433. Sequential266afc8b's hyper parameters: Current learning rate is 2.8785261945883704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 11904/60000][Iteration 3376][Wall Clock 325.351675671s] Trained 128 records in 0.089834192 seconds. Throughput is 1424.8473 records/second. Loss is 1.1858826. Sequential266afc8b's hyper parameters: Current learning rate is 2.8776978417266187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12032/60000][Iteration 3377][Wall Clock 325.437869008s] Trained 128 records in 0.086193337 seconds. Throughput is 1485.0336 records/second. Loss is 1.2641904. Sequential266afc8b's hyper parameters: Current learning rate is 2.8768699654775604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12160/60000][Iteration 3378][Wall Clock 325.523857157s] Trained 128 records in 0.085988149 seconds. Throughput is 1488.5773 records/second. Loss is 1.2747791. Sequential266afc8b's hyper parameters: Current learning rate is 2.876042565429968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12288/60000][Iteration 3379][Wall Clock 325.608888745s] Trained 128 records in 0.085031588 seconds. Throughput is 1505.3229 records/second. Loss is 1.2285985. Sequential266afc8b's hyper parameters: Current learning rate is 2.875215641173088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12416/60000][Iteration 3380][Wall Clock 325.69377568s] Trained 128 records in 0.084886935 seconds. Throughput is 1507.8881 records/second. Loss is 1.0752825. Sequential266afc8b's hyper parameters: Current learning rate is 2.8743891922966374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12544/60000][Iteration 3381][Wall Clock 325.781037314s] Trained 128 records in 0.087261634 seconds. Throughput is 1466.8531 records/second. Loss is 1.233535. Sequential266afc8b's hyper parameters: Current learning rate is 2.873563218390805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12672/60000][Iteration 3382][Wall Clock 325.867886454s] Trained 128 records in 0.08684914 seconds. Throughput is 1473.8201 records/second. Loss is 1.2117022. Sequential266afc8b's hyper parameters: Current learning rate is 2.8727377190462507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:44 INFO  DistriOptimizer$:408 - [Epoch 8 12800/60000][Iteration 3383][Wall Clock 325.956464874s] Trained 128 records in 0.08857842 seconds. Throughput is 1445.0472 records/second. Loss is 1.1918265. Sequential266afc8b's hyper parameters: Current learning rate is 2.871912693854107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 12928/60000][Iteration 3384][Wall Clock 326.046491153s] Trained 128 records in 0.090026279 seconds. Throughput is 1421.807 records/second. Loss is 1.2646304. Sequential266afc8b's hyper parameters: Current learning rate is 2.871088142405972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13056/60000][Iteration 3385][Wall Clock 326.132693044s] Trained 128 records in 0.086201891 seconds. Throughput is 1484.8862 records/second. Loss is 1.1726396. Sequential266afc8b's hyper parameters: Current learning rate is 2.8702640642939146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13184/60000][Iteration 3386][Wall Clock 326.225497033s] Trained 128 records in 0.092803989 seconds. Throughput is 1379.251 records/second. Loss is 1.2306955. Sequential266afc8b's hyper parameters: Current learning rate is 2.8694404591104734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13312/60000][Iteration 3387][Wall Clock 326.307927758s] Trained 128 records in 0.082430725 seconds. Throughput is 1552.819 records/second. Loss is 1.2093604. Sequential266afc8b's hyper parameters: Current learning rate is 2.868617326448652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13440/60000][Iteration 3388][Wall Clock 326.389762213s] Trained 128 records in 0.081834455 seconds. Throughput is 1564.1333 records/second. Loss is 1.2158777. Sequential266afc8b's hyper parameters: Current learning rate is 2.867794665901922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13568/60000][Iteration 3389][Wall Clock 326.474919134s] Trained 128 records in 0.085156921 seconds. Throughput is 1503.1074 records/second. Loss is 1.230022. Sequential266afc8b's hyper parameters: Current learning rate is 2.86697247706422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13696/60000][Iteration 3390][Wall Clock 326.560184091s] Trained 128 records in 0.085264957 seconds. Throughput is 1501.2029 records/second. Loss is 1.2445294. Sequential266afc8b's hyper parameters: Current learning rate is 2.8661507595299513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13824/60000][Iteration 3391][Wall Clock 326.644860622s] Trained 128 records in 0.084676531 seconds. Throughput is 1511.6349 records/second. Loss is 1.2144325. Sequential266afc8b's hyper parameters: Current learning rate is 2.865329512893983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 13952/60000][Iteration 3392][Wall Clock 326.731284479s] Trained 128 records in 0.086423857 seconds. Throughput is 1481.0725 records/second. Loss is 1.1885687. Sequential266afc8b's hyper parameters: Current learning rate is 2.864508736751647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 14080/60000][Iteration 3393][Wall Clock 326.819898841s] Trained 128 records in 0.088614362 seconds. Throughput is 1444.4612 records/second. Loss is 1.2571983. Sequential266afc8b's hyper parameters: Current learning rate is 2.86368843069874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:45 INFO  DistriOptimizer$:408 - [Epoch 8 14208/60000][Iteration 3394][Wall Clock 326.908041048s] Trained 128 records in 0.088142207 seconds. Throughput is 1452.1987 records/second. Loss is 1.2492435. Sequential266afc8b's hyper parameters: Current learning rate is 2.8628685943315205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 14336/60000][Iteration 3395][Wall Clock 326.995232915s] Trained 128 records in 0.087191867 seconds. Throughput is 1468.0269 records/second. Loss is 1.1255659. Sequential266afc8b's hyper parameters: Current learning rate is 2.862049227246709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 14464/60000][Iteration 3396][Wall Clock 327.084407297s] Trained 128 records in 0.089174382 seconds. Throughput is 1435.3898 records/second. Loss is 1.2018225. Sequential266afc8b's hyper parameters: Current learning rate is 2.8612303290414875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 14592/60000][Iteration 3397][Wall Clock 327.172680425s] Trained 128 records in 0.088273128 seconds. Throughput is 1450.0449 records/second. Loss is 1.2467133. Sequential266afc8b's hyper parameters: Current learning rate is 2.860411899313501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 14720/60000][Iteration 3398][Wall Clock 327.258021673s] Trained 128 records in 0.085341248 seconds. Throughput is 1499.861 records/second. Loss is 1.2668505. Sequential266afc8b's hyper parameters: Current learning rate is 2.8595939376608524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 14848/60000][Iteration 3399][Wall Clock 327.351763156s] Trained 128 records in 0.093741483 seconds. Throughput is 1365.4574 records/second. Loss is 1.253368. Sequential266afc8b's hyper parameters: Current learning rate is 2.858776443682104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 14976/60000][Iteration 3400][Wall Clock 327.434379664s] Trained 128 records in 0.082616508 seconds. Throughput is 1549.3271 records/second. Loss is 1.0927643. Sequential266afc8b's hyper parameters: Current learning rate is 2.857959416976279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 15104/60000][Iteration 3401][Wall Clock 327.518601325s] Trained 128 records in 0.084221661 seconds. Throughput is 1519.7991 records/second. Loss is 1.1720597. Sequential266afc8b's hyper parameters: Current learning rate is 2.8571428571428574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 15232/60000][Iteration 3402][Wall Clock 327.600015032s] Trained 128 records in 0.081413707 seconds. Throughput is 1572.2168 records/second. Loss is 1.1893021. Sequential266afc8b's hyper parameters: Current learning rate is 2.8563267637817766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 15360/60000][Iteration 3403][Wall Clock 327.685956854s] Trained 128 records in 0.085941822 seconds. Throughput is 1489.3796 records/second. Loss is 1.0988072. Sequential266afc8b's hyper parameters: Current learning rate is 2.8555111364934324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 15488/60000][Iteration 3404][Wall Clock 327.770157363s] Trained 128 records in 0.084200509 seconds. Throughput is 1520.1808 records/second. Loss is 1.1212348. Sequential266afc8b's hyper parameters: Current learning rate is 2.8546959748786756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 15616/60000][Iteration 3405][Wall Clock 327.85588303s] Trained 128 records in 0.085725667 seconds. Throughput is 1493.1351 records/second. Loss is 1.2268027. Sequential266afc8b's hyper parameters: Current learning rate is 2.853881278538813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:46 INFO  DistriOptimizer$:408 - [Epoch 8 15744/60000][Iteration 3406][Wall Clock 327.941628639s] Trained 128 records in 0.085745609 seconds. Throughput is 1492.7878 records/second. Loss is 1.2322435. Sequential266afc8b's hyper parameters: Current learning rate is 2.853067047075607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 15872/60000][Iteration 3407][Wall Clock 328.029899303s] Trained 128 records in 0.088270664 seconds. Throughput is 1450.0853 records/second. Loss is 1.1902772. Sequential266afc8b's hyper parameters: Current learning rate is 2.852253280091272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16000/60000][Iteration 3408][Wall Clock 328.115815142s] Trained 128 records in 0.085915839 seconds. Throughput is 1489.8301 records/second. Loss is 1.1737646. Sequential266afc8b's hyper parameters: Current learning rate is 2.8514399771884804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16128/60000][Iteration 3409][Wall Clock 328.20105902s] Trained 128 records in 0.085243878 seconds. Throughput is 1501.5741 records/second. Loss is 1.1851822. Sequential266afc8b's hyper parameters: Current learning rate is 2.8506271379703536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16256/60000][Iteration 3410][Wall Clock 328.287574915s] Trained 128 records in 0.086515895 seconds. Throughput is 1479.497 records/second. Loss is 1.1565826. Sequential266afc8b's hyper parameters: Current learning rate is 2.849814762040467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16384/60000][Iteration 3411][Wall Clock 328.3871211s] Trained 128 records in 0.099546185 seconds. Throughput is 1285.8353 records/second. Loss is 1.2426188. Sequential266afc8b's hyper parameters: Current learning rate is 2.849002849002849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16512/60000][Iteration 3412][Wall Clock 328.471800349s] Trained 128 records in 0.084679249 seconds. Throughput is 1511.5864 records/second. Loss is 1.2393626. Sequential266afc8b's hyper parameters: Current learning rate is 2.848191398461977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16640/60000][Iteration 3413][Wall Clock 328.551758945s] Trained 128 records in 0.079958596 seconds. Throughput is 1600.8285 records/second. Loss is 1.1982378. Sequential266afc8b's hyper parameters: Current learning rate is 2.8473804100227795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16768/60000][Iteration 3414][Wall Clock 328.635546831s] Trained 128 records in 0.083787886 seconds. Throughput is 1527.6671 records/second. Loss is 1.2300276. Sequential266afc8b's hyper parameters: Current learning rate is 2.8465698832906344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 16896/60000][Iteration 3415][Wall Clock 328.721176422s] Trained 128 records in 0.085629591 seconds. Throughput is 1494.8104 records/second. Loss is 1.1914598. Sequential266afc8b's hyper parameters: Current learning rate is 2.845759817871372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 17024/60000][Iteration 3416][Wall Clock 328.80621518s] Trained 128 records in 0.085038758 seconds. Throughput is 1505.196 records/second. Loss is 1.2484396. Sequential266afc8b's hyper parameters: Current learning rate is 2.844950213371266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:47 INFO  DistriOptimizer$:408 - [Epoch 8 17152/60000][Iteration 3417][Wall Clock 328.891870443s] Trained 128 records in 0.085655263 seconds. Throughput is 1494.3623 records/second. Loss is 1.0991814. Sequential266afc8b's hyper parameters: Current learning rate is 2.844141069397042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 17280/60000][Iteration 3418][Wall Clock 328.977156091s] Trained 128 records in 0.085285648 seconds. Throughput is 1500.8386 records/second. Loss is 1.194975. Sequential266afc8b's hyper parameters: Current learning rate is 2.843332385555871E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 17408/60000][Iteration 3419][Wall Clock 329.063743462s] Trained 128 records in 0.086587371 seconds. Throughput is 1478.2756 records/second. Loss is 1.0869731. Sequential266afc8b's hyper parameters: Current learning rate is 2.842524161455372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 17536/60000][Iteration 3420][Wall Clock 329.14970935s] Trained 128 records in 0.085965888 seconds. Throughput is 1488.9628 records/second. Loss is 1.2603676. Sequential266afc8b's hyper parameters: Current learning rate is 2.841716396703609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 17664/60000][Iteration 3421][Wall Clock 329.235298929s] Trained 128 records in 0.085589579 seconds. Throughput is 1495.5092 records/second. Loss is 1.2011322. Sequential266afc8b's hyper parameters: Current learning rate is 2.840909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 17792/60000][Iteration 3422][Wall Clock 329.321708863s] Trained 128 records in 0.086409934 seconds. Throughput is 1481.3112 records/second. Loss is 1.2672718. Sequential266afc8b's hyper parameters: Current learning rate is 2.8401022436807724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 17920/60000][Iteration 3423][Wall Clock 329.407577626s] Trained 128 records in 0.085868763 seconds. Throughput is 1490.6469 records/second. Loss is 1.1842548. Sequential266afc8b's hyper parameters: Current learning rate is 2.8392958546280523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 18048/60000][Iteration 3424][Wall Clock 329.492282036s] Trained 128 records in 0.08470441 seconds. Throughput is 1511.1375 records/second. Loss is 1.2387567. Sequential266afc8b's hyper parameters: Current learning rate is 2.838489923360772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 18176/60000][Iteration 3425][Wall Clock 329.587380061s] Trained 128 records in 0.095098025 seconds. Throughput is 1345.9796 records/second. Loss is 1.2102022. Sequential266afc8b's hyper parameters: Current learning rate is 2.8376844494892167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 18304/60000][Iteration 3426][Wall Clock 329.666766676s] Trained 128 records in 0.079386615 seconds. Throughput is 1612.3625 records/second. Loss is 1.2775874. Sequential266afc8b's hyper parameters: Current learning rate is 2.8368794326241134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 18432/60000][Iteration 3427][Wall Clock 329.746349624s] Trained 128 records in 0.079582948 seconds. Throughput is 1608.3848 records/second. Loss is 1.2687142. Sequential266afc8b's hyper parameters: Current learning rate is 2.836074872376631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 18560/60000][Iteration 3428][Wall Clock 329.829174369s] Trained 128 records in 0.082824745 seconds. Throughput is 1545.4319 records/second. Loss is 1.2963016. Sequential266afc8b's hyper parameters: Current learning rate is 2.835270768358378E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:48 INFO  DistriOptimizer$:408 - [Epoch 8 18688/60000][Iteration 3429][Wall Clock 329.915987995s] Trained 128 records in 0.086813626 seconds. Throughput is 1474.4229 records/second. Loss is 1.2441685. Sequential266afc8b's hyper parameters: Current learning rate is 2.834467120181406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 18816/60000][Iteration 3430][Wall Clock 330.000577571s] Trained 128 records in 0.084589576 seconds. Throughput is 1513.1887 records/second. Loss is 1.240572. Sequential266afc8b's hyper parameters: Current learning rate is 2.8336639274582036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 18944/60000][Iteration 3431][Wall Clock 330.085398081s] Trained 128 records in 0.08482051 seconds. Throughput is 1509.069 records/second. Loss is 1.192613. Sequential266afc8b's hyper parameters: Current learning rate is 2.8328611898016995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19072/60000][Iteration 3432][Wall Clock 330.171742157s] Trained 128 records in 0.086344076 seconds. Throughput is 1482.441 records/second. Loss is 1.2459493. Sequential266afc8b's hyper parameters: Current learning rate is 2.832058906825262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19200/60000][Iteration 3433][Wall Clock 330.255908792s] Trained 128 records in 0.084166635 seconds. Throughput is 1520.7926 records/second. Loss is 1.2304649. Sequential266afc8b's hyper parameters: Current learning rate is 2.8312570781426955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19328/60000][Iteration 3434][Wall Clock 330.340748294s] Trained 128 records in 0.084839502 seconds. Throughput is 1508.7312 records/second. Loss is 1.166837. Sequential266afc8b's hyper parameters: Current learning rate is 2.8304557033682426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19456/60000][Iteration 3435][Wall Clock 330.42624462s] Trained 128 records in 0.085496326 seconds. Throughput is 1497.1403 records/second. Loss is 1.2087451. Sequential266afc8b's hyper parameters: Current learning rate is 2.8296547821165814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19584/60000][Iteration 3436][Wall Clock 330.523180686s] Trained 128 records in 0.096936066 seconds. Throughput is 1320.4579 records/second. Loss is 1.2076871. Sequential266afc8b's hyper parameters: Current learning rate is 2.828854314002829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19712/60000][Iteration 3437][Wall Clock 330.60500082s] Trained 128 records in 0.081820134 seconds. Throughput is 1564.4072 records/second. Loss is 1.0535183. Sequential266afc8b's hyper parameters: Current learning rate is 2.828054298642534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19840/60000][Iteration 3438][Wall Clock 330.688995948s] Trained 128 records in 0.083995128 seconds. Throughput is 1523.898 records/second. Loss is 1.1788704. Sequential266afc8b's hyper parameters: Current learning rate is 2.8272547356516825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 19968/60000][Iteration 3439][Wall Clock 330.772400989s] Trained 128 records in 0.083405041 seconds. Throughput is 1534.6794 records/second. Loss is 1.2405809. Sequential266afc8b's hyper parameters: Current learning rate is 2.826455624646693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:49 INFO  DistriOptimizer$:408 - [Epoch 8 20096/60000][Iteration 3440][Wall Clock 330.859952293s] Trained 128 records in 0.087551304 seconds. Throughput is 1462.0 records/second. Loss is 1.1947355. Sequential266afc8b's hyper parameters: Current learning rate is 2.8256569652444194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20224/60000][Iteration 3441][Wall Clock 330.945751231s] Trained 128 records in 0.085798938 seconds. Throughput is 1491.8599 records/second. Loss is 1.2032454. Sequential266afc8b's hyper parameters: Current learning rate is 2.824858757062147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20352/60000][Iteration 3442][Wall Clock 331.035506169s] Trained 128 records in 0.089754938 seconds. Throughput is 1426.1053 records/second. Loss is 1.2566475. Sequential266afc8b's hyper parameters: Current learning rate is 2.8240609997175935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20480/60000][Iteration 3443][Wall Clock 331.122644125s] Trained 128 records in 0.087137956 seconds. Throughput is 1468.9352 records/second. Loss is 1.2275363. Sequential266afc8b's hyper parameters: Current learning rate is 2.82326369282891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20608/60000][Iteration 3444][Wall Clock 331.204098235s] Trained 128 records in 0.08145411 seconds. Throughput is 1571.4369 records/second. Loss is 1.1309114. Sequential266afc8b's hyper parameters: Current learning rate is 2.822466836014677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20736/60000][Iteration 3445][Wall Clock 331.290939265s] Trained 128 records in 0.08684103 seconds. Throughput is 1473.9576 records/second. Loss is 1.2614886. Sequential266afc8b's hyper parameters: Current learning rate is 2.8216704288939055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20864/60000][Iteration 3446][Wall Clock 331.375523997s] Trained 128 records in 0.084584732 seconds. Throughput is 1513.2754 records/second. Loss is 1.2485743. Sequential266afc8b's hyper parameters: Current learning rate is 2.8208744710860365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 20992/60000][Iteration 3447][Wall Clock 331.46035694s] Trained 128 records in 0.084832943 seconds. Throughput is 1508.8478 records/second. Loss is 1.1430466. Sequential266afc8b's hyper parameters: Current learning rate is 2.820078962210942E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 21120/60000][Iteration 3448][Wall Clock 331.546483175s] Trained 128 records in 0.086126235 seconds. Throughput is 1486.1906 records/second. Loss is 1.1391358. Sequential266afc8b's hyper parameters: Current learning rate is 2.81928390188892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 21248/60000][Iteration 3449][Wall Clock 331.631386877s] Trained 128 records in 0.084903702 seconds. Throughput is 1507.5903 records/second. Loss is 1.2526243. Sequential266afc8b's hyper parameters: Current learning rate is 2.818489289740699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 21376/60000][Iteration 3450][Wall Clock 331.718308591s] Trained 128 records in 0.086921714 seconds. Throughput is 1472.5895 records/second. Loss is 1.1327559. Sequential266afc8b's hyper parameters: Current learning rate is 2.817695125387433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 21504/60000][Iteration 3451][Wall Clock 331.816427054s] Trained 128 records in 0.098118463 seconds. Throughput is 1304.5455 records/second. Loss is 1.1797193. Sequential266afc8b's hyper parameters: Current learning rate is 2.8169014084507044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:50 INFO  DistriOptimizer$:408 - [Epoch 8 21632/60000][Iteration 3452][Wall Clock 331.895904621s] Trained 128 records in 0.079477567 seconds. Throughput is 1610.5175 records/second. Loss is 1.1640486. Sequential266afc8b's hyper parameters: Current learning rate is 2.816108138552521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 21760/60000][Iteration 3453][Wall Clock 331.987629635s] Trained 128 records in 0.091725014 seconds. Throughput is 1395.4753 records/second. Loss is 1.1670433. Sequential266afc8b's hyper parameters: Current learning rate is 2.8153153153153153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 21888/60000][Iteration 3454][Wall Clock 332.074931676s] Trained 128 records in 0.087302041 seconds. Throughput is 1466.1742 records/second. Loss is 1.2155367. Sequential266afc8b's hyper parameters: Current learning rate is 2.8145229383619476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22016/60000][Iteration 3455][Wall Clock 332.163811229s] Trained 128 records in 0.088879553 seconds. Throughput is 1440.1512 records/second. Loss is 1.2123731. Sequential266afc8b's hyper parameters: Current learning rate is 2.813731007315701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22144/60000][Iteration 3456][Wall Clock 332.254127451s] Trained 128 records in 0.090316222 seconds. Throughput is 1417.2427 records/second. Loss is 1.1783948. Sequential266afc8b's hyper parameters: Current learning rate is 2.812939521800281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22272/60000][Iteration 3457][Wall Clock 332.339790003s] Trained 128 records in 0.085662552 seconds. Throughput is 1494.2352 records/second. Loss is 1.2043995. Sequential266afc8b's hyper parameters: Current learning rate is 2.81214848143982E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22400/60000][Iteration 3458][Wall Clock 332.427419064s] Trained 128 records in 0.087629061 seconds. Throughput is 1460.7026 records/second. Loss is 1.1223685. Sequential266afc8b's hyper parameters: Current learning rate is 2.81135788585887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22528/60000][Iteration 3459][Wall Clock 332.512134669s] Trained 128 records in 0.084715605 seconds. Throughput is 1510.9377 records/second. Loss is 1.1101019. Sequential266afc8b's hyper parameters: Current learning rate is 2.810567734682406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22656/60000][Iteration 3460][Wall Clock 332.597116332s] Trained 128 records in 0.084981663 seconds. Throughput is 1506.2073 records/second. Loss is 1.2754996. Sequential266afc8b's hyper parameters: Current learning rate is 2.8097780275358243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22784/60000][Iteration 3461][Wall Clock 332.681363507s] Trained 128 records in 0.084247175 seconds. Throughput is 1519.3389 records/second. Loss is 1.2435888. Sequential266afc8b's hyper parameters: Current learning rate is 2.8089887640449435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 22912/60000][Iteration 3462][Wall Clock 332.780412711s] Trained 128 records in 0.099049204 seconds. Throughput is 1292.287 records/second. Loss is 1.1896491. Sequential266afc8b's hyper parameters: Current learning rate is 2.808199943836001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:51 INFO  DistriOptimizer$:408 - [Epoch 8 23040/60000][Iteration 3463][Wall Clock 332.861364366s] Trained 128 records in 0.080951655 seconds. Throughput is 1581.1907 records/second. Loss is 1.1847221. Sequential266afc8b's hyper parameters: Current learning rate is 2.8074115665356543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23168/60000][Iteration 3464][Wall Clock 332.945578407s] Trained 128 records in 0.084214041 seconds. Throughput is 1519.9366 records/second. Loss is 1.168904. Sequential266afc8b's hyper parameters: Current learning rate is 2.806623631770979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23296/60000][Iteration 3465][Wall Clock 333.033401545s] Trained 128 records in 0.087823138 seconds. Throughput is 1457.4747 records/second. Loss is 1.2009289. Sequential266afc8b's hyper parameters: Current learning rate is 2.805836139169473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23424/60000][Iteration 3466][Wall Clock 333.122157197s] Trained 128 records in 0.088755652 seconds. Throughput is 1442.1616 records/second. Loss is 1.2181782. Sequential266afc8b's hyper parameters: Current learning rate is 2.8050490883590464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23552/60000][Iteration 3467][Wall Clock 333.208222429s] Trained 128 records in 0.086065232 seconds. Throughput is 1487.244 records/second. Loss is 1.2007998. Sequential266afc8b's hyper parameters: Current learning rate is 2.8042624789680314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23680/60000][Iteration 3468][Wall Clock 333.29369266s] Trained 128 records in 0.085470231 seconds. Throughput is 1497.5975 records/second. Loss is 1.2277935. Sequential266afc8b's hyper parameters: Current learning rate is 2.803476310625175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23808/60000][Iteration 3469][Wall Clock 333.376207599s] Trained 128 records in 0.082514939 seconds. Throughput is 1551.2343 records/second. Loss is 1.2281843. Sequential266afc8b's hyper parameters: Current learning rate is 2.802690582959641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 23936/60000][Iteration 3470][Wall Clock 333.460155051s] Trained 128 records in 0.083947452 seconds. Throughput is 1524.7634 records/second. Loss is 1.2874663. Sequential266afc8b's hyper parameters: Current learning rate is 2.801905295601009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 24064/60000][Iteration 3471][Wall Clock 333.54585329s] Trained 128 records in 0.085698239 seconds. Throughput is 1493.6129 records/second. Loss is 1.1660819. Sequential266afc8b's hyper parameters: Current learning rate is 2.8011204481792715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 24192/60000][Iteration 3472][Wall Clock 333.632338685s] Trained 128 records in 0.086485395 seconds. Throughput is 1480.0187 records/second. Loss is 1.2585047. Sequential266afc8b's hyper parameters: Current learning rate is 2.800336040324839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 24320/60000][Iteration 3473][Wall Clock 333.722357709s] Trained 128 records in 0.090019024 seconds. Throughput is 1421.9216 records/second. Loss is 1.2186795. Sequential266afc8b's hyper parameters: Current learning rate is 2.799552071668533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 24448/60000][Iteration 3474][Wall Clock 333.806488893s] Trained 128 records in 0.084131184 seconds. Throughput is 1521.4335 records/second. Loss is 1.175984. Sequential266afc8b's hyper parameters: Current learning rate is 2.798768541841589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:52 INFO  DistriOptimizer$:408 - [Epoch 8 24576/60000][Iteration 3475][Wall Clock 333.895604601s] Trained 128 records in 0.089115708 seconds. Throughput is 1436.3348 records/second. Loss is 1.291138. Sequential266afc8b's hyper parameters: Current learning rate is 2.797985450475657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 24704/60000][Iteration 3476][Wall Clock 333.984011908s] Trained 128 records in 0.088407307 seconds. Throughput is 1447.8441 records/second. Loss is 1.2244072. Sequential266afc8b's hyper parameters: Current learning rate is 2.797202797202797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 24832/60000][Iteration 3477][Wall Clock 334.08290117s] Trained 128 records in 0.098889262 seconds. Throughput is 1294.3772 records/second. Loss is 1.2161162. Sequential266afc8b's hyper parameters: Current learning rate is 2.7964205816554815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 24960/60000][Iteration 3478][Wall Clock 334.165409795s] Trained 128 records in 0.082508625 seconds. Throughput is 1551.353 records/second. Loss is 1.2039207. Sequential266afc8b's hyper parameters: Current learning rate is 2.795638803466592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25088/60000][Iteration 3479][Wall Clock 334.245308204s] Trained 128 records in 0.079898409 seconds. Throughput is 1602.0344 records/second. Loss is 1.2845125. Sequential266afc8b's hyper parameters: Current learning rate is 2.7948574622694243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25216/60000][Iteration 3480][Wall Clock 334.332905355s] Trained 128 records in 0.087597151 seconds. Throughput is 1461.2347 records/second. Loss is 1.243632. Sequential266afc8b's hyper parameters: Current learning rate is 2.794076557697681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25344/60000][Iteration 3481][Wall Clock 334.420667955s] Trained 128 records in 0.0877626 seconds. Throughput is 1458.48 records/second. Loss is 1.2347403. Sequential266afc8b's hyper parameters: Current learning rate is 2.7932960893854746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25472/60000][Iteration 3482][Wall Clock 334.505944558s] Trained 128 records in 0.085276603 seconds. Throughput is 1500.9979 records/second. Loss is 1.1583581. Sequential266afc8b's hyper parameters: Current learning rate is 2.7925160569673273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25600/60000][Iteration 3483][Wall Clock 334.593546202s] Trained 128 records in 0.087601644 seconds. Throughput is 1461.1598 records/second. Loss is 1.1472827. Sequential266afc8b's hyper parameters: Current learning rate is 2.7917364600781687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25728/60000][Iteration 3484][Wall Clock 334.682811314s] Trained 128 records in 0.089265112 seconds. Throughput is 1433.9308 records/second. Loss is 1.1994171. Sequential266afc8b's hyper parameters: Current learning rate is 2.7909572983533354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25856/60000][Iteration 3485][Wall Clock 334.770138485s] Trained 128 records in 0.087327171 seconds. Throughput is 1465.7523 records/second. Loss is 1.2112144. Sequential266afc8b's hyper parameters: Current learning rate is 2.7901785714285713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:53 INFO  DistriOptimizer$:408 - [Epoch 8 25984/60000][Iteration 3486][Wall Clock 334.854290739s] Trained 128 records in 0.084152254 seconds. Throughput is 1521.0526 records/second. Loss is 1.2144581. Sequential266afc8b's hyper parameters: Current learning rate is 2.789400278940028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26112/60000][Iteration 3487][Wall Clock 334.953248726s] Trained 128 records in 0.098957987 seconds. Throughput is 1293.4783 records/second. Loss is 1.1991951. Sequential266afc8b's hyper parameters: Current learning rate is 2.788622420524261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26240/60000][Iteration 3488][Wall Clock 335.033095556s] Trained 128 records in 0.07984683 seconds. Throughput is 1603.0693 records/second. Loss is 1.1024806. Sequential266afc8b's hyper parameters: Current learning rate is 2.7878449958182325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26368/60000][Iteration 3489][Wall Clock 335.116480875s] Trained 128 records in 0.083385319 seconds. Throughput is 1535.0424 records/second. Loss is 1.1681163. Sequential266afc8b's hyper parameters: Current learning rate is 2.787068004459309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26496/60000][Iteration 3490][Wall Clock 335.206206292s] Trained 128 records in 0.089725417 seconds. Throughput is 1426.5746 records/second. Loss is 1.2086012. Sequential266afc8b's hyper parameters: Current learning rate is 2.7862914460852607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26624/60000][Iteration 3491][Wall Clock 335.294585827s] Trained 128 records in 0.088379535 seconds. Throughput is 1448.2992 records/second. Loss is 1.2488788. Sequential266afc8b's hyper parameters: Current learning rate is 2.785515320334262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26752/60000][Iteration 3492][Wall Clock 335.379777513s] Trained 128 records in 0.085191686 seconds. Throughput is 1502.494 records/second. Loss is 1.1336913. Sequential266afc8b's hyper parameters: Current learning rate is 2.78473962684489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 26880/60000][Iteration 3493][Wall Clock 335.465381177s] Trained 128 records in 0.085603664 seconds. Throughput is 1495.2632 records/second. Loss is 1.225803. Sequential266afc8b's hyper parameters: Current learning rate is 2.7839643652561246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 27008/60000][Iteration 3494][Wall Clock 335.548640377s] Trained 128 records in 0.0832592 seconds. Throughput is 1537.3676 records/second. Loss is 1.1594296. Sequential266afc8b's hyper parameters: Current learning rate is 2.7831895352073476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 27136/60000][Iteration 3495][Wall Clock 335.634514975s] Trained 128 records in 0.085874598 seconds. Throughput is 1490.5457 records/second. Loss is 1.1648254. Sequential266afc8b's hyper parameters: Current learning rate is 2.782415136338342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 27264/60000][Iteration 3496][Wall Clock 335.719702801s] Trained 128 records in 0.085187826 seconds. Throughput is 1502.5621 records/second. Loss is 1.1914507. Sequential266afc8b's hyper parameters: Current learning rate is 2.7816411682892903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 27392/60000][Iteration 3497][Wall Clock 335.806315417s] Trained 128 records in 0.086612616 seconds. Throughput is 1477.8447 records/second. Loss is 1.092903. Sequential266afc8b's hyper parameters: Current learning rate is 2.7808676307007786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:54 INFO  DistriOptimizer$:408 - [Epoch 8 27520/60000][Iteration 3498][Wall Clock 335.893146276s] Trained 128 records in 0.086830859 seconds. Throughput is 1474.1302 records/second. Loss is 1.1805044. Sequential266afc8b's hyper parameters: Current learning rate is 2.7800945232137893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 27648/60000][Iteration 3499][Wall Clock 335.981247002s] Trained 128 records in 0.088100726 seconds. Throughput is 1452.8824 records/second. Loss is 1.1713036. Sequential266afc8b's hyper parameters: Current learning rate is 2.7793218454697053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 27776/60000][Iteration 3500][Wall Clock 336.068652416s] Trained 128 records in 0.087405414 seconds. Throughput is 1464.4402 records/second. Loss is 1.2052435. Sequential266afc8b's hyper parameters: Current learning rate is 2.778549597110308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 27904/60000][Iteration 3501][Wall Clock 336.154212046s] Trained 128 records in 0.08555963 seconds. Throughput is 1496.0327 records/second. Loss is 1.170331. Sequential266afc8b's hyper parameters: Current learning rate is 2.777777777777778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28032/60000][Iteration 3502][Wall Clock 336.241880268s] Trained 128 records in 0.087668222 seconds. Throughput is 1460.05 records/second. Loss is 1.2241628. Sequential266afc8b's hyper parameters: Current learning rate is 2.7770063871146905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28160/60000][Iteration 3503][Wall Clock 336.340267288s] Trained 128 records in 0.09838702 seconds. Throughput is 1300.9846 records/second. Loss is 1.179471. Sequential266afc8b's hyper parameters: Current learning rate is 2.7762354247640197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28288/60000][Iteration 3504][Wall Clock 336.41919645s] Trained 128 records in 0.078929162 seconds. Throughput is 1621.7073 records/second. Loss is 1.277172. Sequential266afc8b's hyper parameters: Current learning rate is 2.7754648903691365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28416/60000][Iteration 3505][Wall Clock 336.504390131s] Trained 128 records in 0.085193681 seconds. Throughput is 1502.4589 records/second. Loss is 1.1351054. Sequential266afc8b's hyper parameters: Current learning rate is 2.774694783573807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28544/60000][Iteration 3506][Wall Clock 336.587534334s] Trained 128 records in 0.083144203 seconds. Throughput is 1539.494 records/second. Loss is 1.2370518. Sequential266afc8b's hyper parameters: Current learning rate is 2.7739251040221914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28672/60000][Iteration 3507][Wall Clock 336.673404526s] Trained 128 records in 0.085870192 seconds. Throughput is 1490.6221 records/second. Loss is 1.1504949. Sequential266afc8b's hyper parameters: Current learning rate is 2.773155851358846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28800/60000][Iteration 3508][Wall Clock 336.75981002s] Trained 128 records in 0.086405494 seconds. Throughput is 1481.3873 records/second. Loss is 1.2442458. Sequential266afc8b's hyper parameters: Current learning rate is 2.772387025228722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:55 INFO  DistriOptimizer$:408 - [Epoch 8 28928/60000][Iteration 3509][Wall Clock 336.847220471s] Trained 128 records in 0.087410451 seconds. Throughput is 1464.3558 records/second. Loss is 1.1113073. Sequential266afc8b's hyper parameters: Current learning rate is 2.771618625277162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29056/60000][Iteration 3510][Wall Clock 336.932440292s] Trained 128 records in 0.085219821 seconds. Throughput is 1501.9979 records/second. Loss is 1.1949725. Sequential266afc8b's hyper parameters: Current learning rate is 2.7708506511499027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29184/60000][Iteration 3511][Wall Clock 337.018158957s] Trained 128 records in 0.085718665 seconds. Throughput is 1493.2571 records/second. Loss is 1.1766272. Sequential266afc8b's hyper parameters: Current learning rate is 2.7700831024930745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29312/60000][Iteration 3512][Wall Clock 337.101468874s] Trained 128 records in 0.083309917 seconds. Throughput is 1536.4316 records/second. Loss is 1.2585791. Sequential266afc8b's hyper parameters: Current learning rate is 2.7693159789531985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29440/60000][Iteration 3513][Wall Clock 337.184393046s] Trained 128 records in 0.082924172 seconds. Throughput is 1543.5789 records/second. Loss is 1.220035. Sequential266afc8b's hyper parameters: Current learning rate is 2.7685492801771876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29568/60000][Iteration 3514][Wall Clock 337.266298397s] Trained 128 records in 0.081905351 seconds. Throughput is 1562.7794 records/second. Loss is 1.1620337. Sequential266afc8b's hyper parameters: Current learning rate is 2.767783005812344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29696/60000][Iteration 3515][Wall Clock 337.352042828s] Trained 128 records in 0.085744431 seconds. Throughput is 1492.8082 records/second. Loss is 1.2971361. Sequential266afc8b's hyper parameters: Current learning rate is 2.767017155506364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29824/60000][Iteration 3516][Wall Clock 337.438136254s] Trained 128 records in 0.086093426 seconds. Throughput is 1486.757 records/second. Loss is 1.1155684. Sequential266afc8b's hyper parameters: Current learning rate is 2.7662517289073305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 29952/60000][Iteration 3517][Wall Clock 337.523265326s] Trained 128 records in 0.085129072 seconds. Throughput is 1503.5991 records/second. Loss is 1.1536107. Sequential266afc8b's hyper parameters: Current learning rate is 2.765486725663717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 30080/60000][Iteration 3518][Wall Clock 337.607520012s] Trained 128 records in 0.084254686 seconds. Throughput is 1519.2032 records/second. Loss is 1.1936209. Sequential266afc8b's hyper parameters: Current learning rate is 2.764722145424385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 30208/60000][Iteration 3519][Wall Clock 337.691687276s] Trained 128 records in 0.084167264 seconds. Throughput is 1520.7812 records/second. Loss is 1.2206004. Sequential266afc8b's hyper parameters: Current learning rate is 2.763957987838585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 30336/60000][Iteration 3520][Wall Clock 337.7772671s] Trained 128 records in 0.085579824 seconds. Throughput is 1495.6796 records/second. Loss is 1.1577134. Sequential266afc8b's hyper parameters: Current learning rate is 2.763194252555955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:56 INFO  DistriOptimizer$:408 - [Epoch 8 30464/60000][Iteration 3521][Wall Clock 337.863382856s] Trained 128 records in 0.086115756 seconds. Throughput is 1486.3715 records/second. Loss is 1.2083151. Sequential266afc8b's hyper parameters: Current learning rate is 2.762430939226519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 30592/60000][Iteration 3522][Wall Clock 337.947412539s] Trained 128 records in 0.084029683 seconds. Throughput is 1523.2712 records/second. Loss is 1.1297679. Sequential266afc8b's hyper parameters: Current learning rate is 2.7616680475006904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 30720/60000][Iteration 3523][Wall Clock 338.030842568s] Trained 128 records in 0.083430029 seconds. Throughput is 1534.2197 records/second. Loss is 1.2063819. Sequential266afc8b's hyper parameters: Current learning rate is 2.760905577029266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 30848/60000][Iteration 3524][Wall Clock 338.117769456s] Trained 128 records in 0.086926888 seconds. Throughput is 1472.5018 records/second. Loss is 1.2265012. Sequential266afc8b's hyper parameters: Current learning rate is 2.7601435274634276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 30976/60000][Iteration 3525][Wall Clock 338.204450552s] Trained 128 records in 0.086681096 seconds. Throughput is 1476.6772 records/second. Loss is 1.2269765. Sequential266afc8b's hyper parameters: Current learning rate is 2.759381898454746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31104/60000][Iteration 3526][Wall Clock 338.288481258s] Trained 128 records in 0.084030706 seconds. Throughput is 1523.2528 records/second. Loss is 1.1498623. Sequential266afc8b's hyper parameters: Current learning rate is 2.7586206896551725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31232/60000][Iteration 3527][Wall Clock 338.372668039s] Trained 128 records in 0.084186781 seconds. Throughput is 1520.4288 records/second. Loss is 1.2843724. Sequential266afc8b's hyper parameters: Current learning rate is 2.757859900717044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31360/60000][Iteration 3528][Wall Clock 338.457401404s] Trained 128 records in 0.084733365 seconds. Throughput is 1510.621 records/second. Loss is 1.2527853. Sequential266afc8b's hyper parameters: Current learning rate is 2.7570995312930797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31488/60000][Iteration 3529][Wall Clock 338.552673522s] Trained 128 records in 0.095272118 seconds. Throughput is 1343.52 records/second. Loss is 1.1639886. Sequential266afc8b's hyper parameters: Current learning rate is 2.756339581036384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31616/60000][Iteration 3530][Wall Clock 338.633457409s] Trained 128 records in 0.080783887 seconds. Throughput is 1584.4744 records/second. Loss is 1.2166895. Sequential266afc8b's hyper parameters: Current learning rate is 2.755580049600441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31744/60000][Iteration 3531][Wall Clock 338.715020145s] Trained 128 records in 0.081562736 seconds. Throughput is 1569.3441 records/second. Loss is 1.165535. Sequential266afc8b's hyper parameters: Current learning rate is 2.754820936639118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 31872/60000][Iteration 3532][Wall Clock 338.800635121s] Trained 128 records in 0.085614976 seconds. Throughput is 1495.0654 records/second. Loss is 1.2436326. Sequential266afc8b's hyper parameters: Current learning rate is 2.7540622418066645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:57 INFO  DistriOptimizer$:408 - [Epoch 8 32000/60000][Iteration 3533][Wall Clock 338.886366151s] Trained 128 records in 0.08573103 seconds. Throughput is 1493.0416 records/second. Loss is 1.2932279. Sequential266afc8b's hyper parameters: Current learning rate is 2.7533039647577095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32128/60000][Iteration 3534][Wall Clock 338.971122151s] Trained 128 records in 0.084756 seconds. Throughput is 1510.2175 records/second. Loss is 1.2175016. Sequential266afc8b's hyper parameters: Current learning rate is 2.752546105147261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32256/60000][Iteration 3535][Wall Clock 339.057146436s] Trained 128 records in 0.086024285 seconds. Throughput is 1487.9519 records/second. Loss is 1.2758088. Sequential266afc8b's hyper parameters: Current learning rate is 2.75178866263071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32384/60000][Iteration 3536][Wall Clock 339.143264607s] Trained 128 records in 0.086118171 seconds. Throughput is 1486.3298 records/second. Loss is 1.2079997. Sequential266afc8b's hyper parameters: Current learning rate is 2.751031636863824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32512/60000][Iteration 3537][Wall Clock 339.237653946s] Trained 128 records in 0.094389339 seconds. Throughput is 1356.0853 records/second. Loss is 1.141982. Sequential266afc8b's hyper parameters: Current learning rate is 2.75027502750275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32640/60000][Iteration 3538][Wall Clock 339.319678686s] Trained 128 records in 0.08202474 seconds. Throughput is 1560.5049 records/second. Loss is 1.1723057. Sequential266afc8b's hyper parameters: Current learning rate is 2.7495188342040145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32768/60000][Iteration 3539][Wall Clock 339.405077574s] Trained 128 records in 0.085398888 seconds. Throughput is 1498.8485 records/second. Loss is 1.237203. Sequential266afc8b's hyper parameters: Current learning rate is 2.748763056624519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 32896/60000][Iteration 3540][Wall Clock 339.490644013s] Trained 128 records in 0.085566439 seconds. Throughput is 1495.9136 records/second. Loss is 1.2747375. Sequential266afc8b's hyper parameters: Current learning rate is 2.748007694421544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 33024/60000][Iteration 3541][Wall Clock 339.574605343s] Trained 128 records in 0.08396133 seconds. Throughput is 1524.5114 records/second. Loss is 1.2482113. Sequential266afc8b's hyper parameters: Current learning rate is 2.747252747252747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 33152/60000][Iteration 3542][Wall Clock 339.657479517s] Trained 128 records in 0.082874174 seconds. Throughput is 1544.5101 records/second. Loss is 1.1859999. Sequential266afc8b's hyper parameters: Current learning rate is 2.7464982147761604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 33280/60000][Iteration 3543][Wall Clock 339.740775419s] Trained 128 records in 0.083295902 seconds. Throughput is 1536.6902 records/second. Loss is 1.219098. Sequential266afc8b's hyper parameters: Current learning rate is 2.745744096650192E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:58 INFO  DistriOptimizer$:408 - [Epoch 8 33408/60000][Iteration 3544][Wall Clock 339.82616964s] Trained 128 records in 0.085394221 seconds. Throughput is 1498.9305 records/second. Loss is 1.1722832. Sequential266afc8b's hyper parameters: Current learning rate is 2.7449903925336265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 33536/60000][Iteration 3545][Wall Clock 339.909738243s] Trained 128 records in 0.083568603 seconds. Throughput is 1531.6758 records/second. Loss is 1.2897968. Sequential266afc8b's hyper parameters: Current learning rate is 2.7442371020856203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 33664/60000][Iteration 3546][Wall Clock 339.994893385s] Trained 128 records in 0.085155142 seconds. Throughput is 1503.1388 records/second. Loss is 1.1998942. Sequential266afc8b's hyper parameters: Current learning rate is 2.743484224965706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 33792/60000][Iteration 3547][Wall Clock 340.081680991s] Trained 128 records in 0.086787606 seconds. Throughput is 1474.865 records/second. Loss is 1.2222452. Sequential266afc8b's hyper parameters: Current learning rate is 2.7427317608337906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 33920/60000][Iteration 3548][Wall Clock 340.166679221s] Trained 128 records in 0.08499823 seconds. Throughput is 1505.9137 records/second. Loss is 1.1717237. Sequential266afc8b's hyper parameters: Current learning rate is 2.741979709350151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34048/60000][Iteration 3549][Wall Clock 340.251537343s] Trained 128 records in 0.084858122 seconds. Throughput is 1508.4001 records/second. Loss is 1.189209. Sequential266afc8b's hyper parameters: Current learning rate is 2.7412280701754384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34176/60000][Iteration 3550][Wall Clock 340.337474316s] Trained 128 records in 0.085936973 seconds. Throughput is 1489.4637 records/second. Loss is 1.1837207. Sequential266afc8b's hyper parameters: Current learning rate is 2.7404768429706766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34304/60000][Iteration 3551][Wall Clock 340.423205298s] Trained 128 records in 0.085730982 seconds. Throughput is 1493.0425 records/second. Loss is 1.1587762. Sequential266afc8b's hyper parameters: Current learning rate is 2.73972602739726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34432/60000][Iteration 3552][Wall Clock 340.507280292s] Trained 128 records in 0.084074994 seconds. Throughput is 1522.4503 records/second. Loss is 1.3320659. Sequential266afc8b's hyper parameters: Current learning rate is 2.7389756231169547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34560/60000][Iteration 3553][Wall Clock 340.592478297s] Trained 128 records in 0.085198005 seconds. Throughput is 1502.3826 records/second. Loss is 1.1456158. Sequential266afc8b's hyper parameters: Current learning rate is 2.738225629791895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34688/60000][Iteration 3554][Wall Clock 340.681036629s] Trained 128 records in 0.088558332 seconds. Throughput is 1445.375 records/second. Loss is 1.0927906. Sequential266afc8b's hyper parameters: Current learning rate is 2.737476047084588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34816/60000][Iteration 3555][Wall Clock 340.779200569s] Trained 128 records in 0.09816394 seconds. Throughput is 1303.9412 records/second. Loss is 1.1637094. Sequential266afc8b's hyper parameters: Current learning rate is 2.736726874657909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:23:59 INFO  DistriOptimizer$:408 - [Epoch 8 34944/60000][Iteration 3556][Wall Clock 340.866833332s] Trained 128 records in 0.087632763 seconds. Throughput is 1460.641 records/second. Loss is 1.1921058. Sequential266afc8b's hyper parameters: Current learning rate is 2.7359781121751026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35072/60000][Iteration 3557][Wall Clock 340.955409001s] Trained 128 records in 0.088575669 seconds. Throughput is 1445.0922 records/second. Loss is 1.194357. Sequential266afc8b's hyper parameters: Current learning rate is 2.735229759299781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35200/60000][Iteration 3558][Wall Clock 341.042187635s] Trained 128 records in 0.086778634 seconds. Throughput is 1475.0175 records/second. Loss is 1.1408594. Sequential266afc8b's hyper parameters: Current learning rate is 2.7344818156959256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35328/60000][Iteration 3559][Wall Clock 341.1300703s] Trained 128 records in 0.087882665 seconds. Throughput is 1456.4874 records/second. Loss is 1.2068359. Sequential266afc8b's hyper parameters: Current learning rate is 2.7337342810278845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35456/60000][Iteration 3560][Wall Clock 341.379438173s] Trained 128 records in 0.249367873 seconds. Throughput is 513.29785 records/second. Loss is 1.1257048. Sequential266afc8b's hyper parameters: Current learning rate is 2.7329871549603714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35584/60000][Iteration 3561][Wall Clock 341.466166061s] Trained 128 records in 0.086727888 seconds. Throughput is 1475.8805 records/second. Loss is 1.1531025. Sequential266afc8b's hyper parameters: Current learning rate is 2.73224043715847E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35712/60000][Iteration 3562][Wall Clock 341.549888079s] Trained 128 records in 0.083722018 seconds. Throughput is 1528.869 records/second. Loss is 1.1639212. Sequential266afc8b's hyper parameters: Current learning rate is 2.7314941272876266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35840/60000][Iteration 3563][Wall Clock 341.636152576s] Trained 128 records in 0.086264497 seconds. Throughput is 1483.8086 records/second. Loss is 1.2293519. Sequential266afc8b's hyper parameters: Current learning rate is 2.730748225013654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 35968/60000][Iteration 3564][Wall Clock 341.71630117s] Trained 128 records in 0.080148594 seconds. Throughput is 1597.0337 records/second. Loss is 1.1841646. Sequential266afc8b's hyper parameters: Current learning rate is 2.7300027300027296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:00 INFO  DistriOptimizer$:408 - [Epoch 8 36096/60000][Iteration 3565][Wall Clock 341.802543261s] Trained 128 records in 0.086242091 seconds. Throughput is 1484.194 records/second. Loss is 1.2252939. Sequential266afc8b's hyper parameters: Current learning rate is 2.729257641921397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36224/60000][Iteration 3566][Wall Clock 341.885713757s] Trained 128 records in 0.083170496 seconds. Throughput is 1539.0073 records/second. Loss is 1.1901245. Sequential266afc8b's hyper parameters: Current learning rate is 2.7285129604365623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36352/60000][Iteration 3567][Wall Clock 341.970505196s] Trained 128 records in 0.084791439 seconds. Throughput is 1509.5864 records/second. Loss is 1.1388896. Sequential266afc8b's hyper parameters: Current learning rate is 2.7277686852154935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36480/60000][Iteration 3568][Wall Clock 342.059318292s] Trained 128 records in 0.088813096 seconds. Throughput is 1441.2289 records/second. Loss is 1.2019782. Sequential266afc8b's hyper parameters: Current learning rate is 2.727024815925825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36608/60000][Iteration 3569][Wall Clock 342.144970227s] Trained 128 records in 0.085651935 seconds. Throughput is 1494.4204 records/second. Loss is 1.1767842. Sequential266afc8b's hyper parameters: Current learning rate is 2.726281352235551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36736/60000][Iteration 3570][Wall Clock 342.229763124s] Trained 128 records in 0.084792897 seconds. Throughput is 1509.5604 records/second. Loss is 1.1569543. Sequential266afc8b's hyper parameters: Current learning rate is 2.725538293813028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36864/60000][Iteration 3571][Wall Clock 342.31421093s] Trained 128 records in 0.084447806 seconds. Throughput is 1515.7291 records/second. Loss is 1.2792189. Sequential266afc8b's hyper parameters: Current learning rate is 2.724795640326975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 36992/60000][Iteration 3572][Wall Clock 342.396877673s] Trained 128 records in 0.082666743 seconds. Throughput is 1548.3857 records/second. Loss is 1.1848323. Sequential266afc8b's hyper parameters: Current learning rate is 2.7240533914464724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 37120/60000][Iteration 3573][Wall Clock 342.480695215s] Trained 128 records in 0.083817542 seconds. Throughput is 1527.1266 records/second. Loss is 1.234065. Sequential266afc8b's hyper parameters: Current learning rate is 2.723311546840959E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 37248/60000][Iteration 3574][Wall Clock 342.563343553s] Trained 128 records in 0.082648338 seconds. Throughput is 1548.7305 records/second. Loss is 1.1857322. Sequential266afc8b's hyper parameters: Current learning rate is 2.7225701061802337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 37376/60000][Iteration 3575][Wall Clock 342.647922901s] Trained 128 records in 0.084579348 seconds. Throughput is 1513.3718 records/second. Loss is 1.1210282. Sequential266afc8b's hyper parameters: Current learning rate is 2.721829069134458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 37504/60000][Iteration 3576][Wall Clock 342.731598588s] Trained 128 records in 0.083675687 seconds. Throughput is 1529.7155 records/second. Loss is 1.2226578. Sequential266afc8b's hyper parameters: Current learning rate is 2.7210884353741496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:01 INFO  DistriOptimizer$:408 - [Epoch 8 37632/60000][Iteration 3577][Wall Clock 342.814288421s] Trained 128 records in 0.082689833 seconds. Throughput is 1547.9532 records/second. Loss is 1.1734679. Sequential266afc8b's hyper parameters: Current learning rate is 2.720348204570185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 37760/60000][Iteration 3578][Wall Clock 342.899039087s] Trained 128 records in 0.084750666 seconds. Throughput is 1510.3126 records/second. Loss is 1.1048583. Sequential266afc8b's hyper parameters: Current learning rate is 2.719608376393799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 37888/60000][Iteration 3579][Wall Clock 342.984419303s] Trained 128 records in 0.085380216 seconds. Throughput is 1499.1763 records/second. Loss is 1.1273181. Sequential266afc8b's hyper parameters: Current learning rate is 2.718868950516585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38016/60000][Iteration 3580][Wall Clock 343.078360946s] Trained 128 records in 0.093941643 seconds. Throughput is 1362.548 records/second. Loss is 1.1420132. Sequential266afc8b's hyper parameters: Current learning rate is 2.718129926610492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38144/60000][Iteration 3581][Wall Clock 343.156708063s] Trained 128 records in 0.078347117 seconds. Throughput is 1633.7551 records/second. Loss is 1.1613966. Sequential266afc8b's hyper parameters: Current learning rate is 2.7173913043478256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38272/60000][Iteration 3582][Wall Clock 343.23240188s] Trained 128 records in 0.075693817 seconds. Throughput is 1691.0232 records/second. Loss is 1.1770927. Sequential266afc8b's hyper parameters: Current learning rate is 2.7166530834012495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38400/60000][Iteration 3583][Wall Clock 343.318841018s] Trained 128 records in 0.086439138 seconds. Throughput is 1480.8107 records/second. Loss is 1.2328367. Sequential266afc8b's hyper parameters: Current learning rate is 2.715915263443781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38528/60000][Iteration 3584][Wall Clock 343.404320273s] Trained 128 records in 0.085479255 seconds. Throughput is 1497.4395 records/second. Loss is 1.1792953. Sequential266afc8b's hyper parameters: Current learning rate is 2.7151778441487917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38656/60000][Iteration 3585][Wall Clock 343.488319534s] Trained 128 records in 0.083999261 seconds. Throughput is 1523.8229 records/second. Loss is 1.168323. Sequential266afc8b's hyper parameters: Current learning rate is 2.7144408251900104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38784/60000][Iteration 3586][Wall Clock 343.573546853s] Trained 128 records in 0.085227319 seconds. Throughput is 1501.8658 records/second. Loss is 1.153564. Sequential266afc8b's hyper parameters: Current learning rate is 2.7137042062415194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 38912/60000][Iteration 3587][Wall Clock 343.656688056s] Trained 128 records in 0.083141203 seconds. Throughput is 1539.5496 records/second. Loss is 1.1467327. Sequential266afc8b's hyper parameters: Current learning rate is 2.7129679869777537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 39040/60000][Iteration 3588][Wall Clock 343.740139805s] Trained 128 records in 0.083451749 seconds. Throughput is 1533.8204 records/second. Loss is 1.1344147. Sequential266afc8b's hyper parameters: Current learning rate is 2.7122321670735016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:02 INFO  DistriOptimizer$:408 - [Epoch 8 39168/60000][Iteration 3589][Wall Clock 343.82923544s] Trained 128 records in 0.089095635 seconds. Throughput is 1436.6584 records/second. Loss is 1.2269022. Sequential266afc8b's hyper parameters: Current learning rate is 2.7114967462039046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 39296/60000][Iteration 3590][Wall Clock 343.909242485s] Trained 128 records in 0.080007045 seconds. Throughput is 1599.8591 records/second. Loss is 1.1521262. Sequential266afc8b's hyper parameters: Current learning rate is 2.710761724044457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 39424/60000][Iteration 3591][Wall Clock 343.992800944s] Trained 128 records in 0.083558459 seconds. Throughput is 1531.8616 records/second. Loss is 1.1939152. Sequential266afc8b's hyper parameters: Current learning rate is 2.7100271002710027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 39552/60000][Iteration 3592][Wall Clock 344.075389509s] Trained 128 records in 0.082588565 seconds. Throughput is 1549.8513 records/second. Loss is 1.1857771. Sequential266afc8b's hyper parameters: Current learning rate is 2.7092928745597395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 39680/60000][Iteration 3593][Wall Clock 344.157005697s] Trained 128 records in 0.081616188 seconds. Throughput is 1568.3164 records/second. Loss is 1.1887289. Sequential266afc8b's hyper parameters: Current learning rate is 2.7085590465872155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 39808/60000][Iteration 3594][Wall Clock 344.240941012s] Trained 128 records in 0.083935315 seconds. Throughput is 1524.9839 records/second. Loss is 1.1933731. Sequential266afc8b's hyper parameters: Current learning rate is 2.7078256160303275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 39936/60000][Iteration 3595][Wall Clock 344.324125847s] Trained 128 records in 0.083184835 seconds. Throughput is 1538.742 records/second. Loss is 1.2606523. Sequential266afc8b's hyper parameters: Current learning rate is 2.707092582566324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 40064/60000][Iteration 3596][Wall Clock 344.40643335s] Trained 128 records in 0.082307503 seconds. Throughput is 1555.1438 records/second. Loss is 1.2079347. Sequential266afc8b's hyper parameters: Current learning rate is 2.706359945872801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 40192/60000][Iteration 3597][Wall Clock 344.488120506s] Trained 128 records in 0.081687156 seconds. Throughput is 1566.9539 records/second. Loss is 1.1654129. Sequential266afc8b's hyper parameters: Current learning rate is 2.7056277056277056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 40320/60000][Iteration 3598][Wall Clock 344.572333152s] Trained 128 records in 0.084212646 seconds. Throughput is 1519.9618 records/second. Loss is 1.2175927. Sequential266afc8b's hyper parameters: Current learning rate is 2.704895861509332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 40448/60000][Iteration 3599][Wall Clock 344.657457436s] Trained 128 records in 0.085124284 seconds. Throughput is 1503.6837 records/second. Loss is 1.162745. Sequential266afc8b's hyper parameters: Current learning rate is 2.704164413196322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 40576/60000][Iteration 3600][Wall Clock 344.741085541s] Trained 128 records in 0.083628105 seconds. Throughput is 1530.5859 records/second. Loss is 1.1522392. Sequential266afc8b's hyper parameters: Current learning rate is 2.703433360367667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:03 INFO  DistriOptimizer$:408 - [Epoch 8 40704/60000][Iteration 3601][Wall Clock 344.824586107s] Trained 128 records in 0.083500566 seconds. Throughput is 1532.9238 records/second. Loss is 1.1740814. Sequential266afc8b's hyper parameters: Current learning rate is 2.702702702702703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 40832/60000][Iteration 3602][Wall Clock 344.90614889s] Trained 128 records in 0.081562783 seconds. Throughput is 1569.3433 records/second. Loss is 1.19569. Sequential266afc8b's hyper parameters: Current learning rate is 2.7019724398811136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 40960/60000][Iteration 3603][Wall Clock 344.99056755s] Trained 128 records in 0.08441866 seconds. Throughput is 1516.2524 records/second. Loss is 1.0861228. Sequential266afc8b's hyper parameters: Current learning rate is 2.701242571582928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41088/60000][Iteration 3604][Wall Clock 345.079208933s] Trained 128 records in 0.088641383 seconds. Throughput is 1444.0208 records/second. Loss is 1.1919022. Sequential266afc8b's hyper parameters: Current learning rate is 2.7005130974885227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41216/60000][Iteration 3605][Wall Clock 345.162031243s] Trained 128 records in 0.08282231 seconds. Throughput is 1545.4773 records/second. Loss is 1.3067018. Sequential266afc8b's hyper parameters: Current learning rate is 2.699784017278618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41344/60000][Iteration 3606][Wall Clock 345.251912256s] Trained 128 records in 0.089881013 seconds. Throughput is 1424.1051 records/second. Loss is 1.2460462. Sequential266afc8b's hyper parameters: Current learning rate is 2.699055330634278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41472/60000][Iteration 3607][Wall Clock 345.331572209s] Trained 128 records in 0.079659953 seconds. Throughput is 1606.83 records/second. Loss is 1.250113. Sequential266afc8b's hyper parameters: Current learning rate is 2.698327037236913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41600/60000][Iteration 3608][Wall Clock 345.413092503s] Trained 128 records in 0.081520294 seconds. Throughput is 1570.1611 records/second. Loss is 1.2475096. Sequential266afc8b's hyper parameters: Current learning rate is 2.697599136768276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41728/60000][Iteration 3609][Wall Clock 345.491008245s] Trained 128 records in 0.077915742 seconds. Throughput is 1642.8002 records/second. Loss is 1.2720727. Sequential266afc8b's hyper parameters: Current learning rate is 2.696871628910464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41856/60000][Iteration 3610][Wall Clock 345.580256368s] Trained 128 records in 0.089248123 seconds. Throughput is 1434.2039 records/second. Loss is 1.2088536. Sequential266afc8b's hyper parameters: Current learning rate is 2.696144513345915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 41984/60000][Iteration 3611][Wall Clock 345.665132805s] Trained 128 records in 0.084876437 seconds. Throughput is 1508.0746 records/second. Loss is 1.2429776. Sequential266afc8b's hyper parameters: Current learning rate is 2.695417789757412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 42112/60000][Iteration 3612][Wall Clock 345.750199737s] Trained 128 records in 0.085066932 seconds. Throughput is 1504.6975 records/second. Loss is 1.2359627. Sequential266afc8b's hyper parameters: Current learning rate is 2.6946914578280785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:04 INFO  DistriOptimizer$:408 - [Epoch 8 42240/60000][Iteration 3613][Wall Clock 345.835800308s] Trained 128 records in 0.085600571 seconds. Throughput is 1495.3171 records/second. Loss is 1.0967665. Sequential266afc8b's hyper parameters: Current learning rate is 2.69396551724138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 42368/60000][Iteration 3614][Wall Clock 345.926760521s] Trained 128 records in 0.090960213 seconds. Throughput is 1407.2087 records/second. Loss is 1.1262022. Sequential266afc8b's hyper parameters: Current learning rate is 2.6932399676811203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 42496/60000][Iteration 3615][Wall Clock 346.013526195s] Trained 128 records in 0.086765674 seconds. Throughput is 1475.2377 records/second. Loss is 1.1915795. Sequential266afc8b's hyper parameters: Current learning rate is 2.6925148088314486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 42624/60000][Iteration 3616][Wall Clock 346.094083688s] Trained 128 records in 0.080557493 seconds. Throughput is 1588.9272 records/second. Loss is 1.1855134. Sequential266afc8b's hyper parameters: Current learning rate is 2.691790040376851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 42752/60000][Iteration 3617][Wall Clock 346.177787011s] Trained 128 records in 0.083703323 seconds. Throughput is 1529.2104 records/second. Loss is 1.232511. Sequential266afc8b's hyper parameters: Current learning rate is 2.6910656620021526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 42880/60000][Iteration 3618][Wall Clock 346.267364498s] Trained 128 records in 0.089577487 seconds. Throughput is 1428.9304 records/second. Loss is 1.2214037. Sequential266afc8b's hyper parameters: Current learning rate is 2.690341673392521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 43008/60000][Iteration 3619][Wall Clock 346.3532378s] Trained 128 records in 0.085873302 seconds. Throughput is 1490.5681 records/second. Loss is 1.1783589. Sequential266afc8b's hyper parameters: Current learning rate is 2.689618074233459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 43136/60000][Iteration 3620][Wall Clock 346.442327945s] Trained 128 records in 0.089090145 seconds. Throughput is 1436.747 records/second. Loss is 1.2248338. Sequential266afc8b's hyper parameters: Current learning rate is 2.6888948642108095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 43264/60000][Iteration 3621][Wall Clock 346.52743659s] Trained 128 records in 0.085108645 seconds. Throughput is 1503.9601 records/second. Loss is 1.2367873. Sequential266afc8b's hyper parameters: Current learning rate is 2.6881720430107527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 43392/60000][Iteration 3622][Wall Clock 346.61371936s] Trained 128 records in 0.08628277 seconds. Throughput is 1483.4944 records/second. Loss is 1.1883703. Sequential266afc8b's hyper parameters: Current learning rate is 2.687449610319806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 43520/60000][Iteration 3623][Wall Clock 346.697581354s] Trained 128 records in 0.083861994 seconds. Throughput is 1526.3171 records/second. Loss is 1.1493167. Sequential266afc8b's hyper parameters: Current learning rate is 2.6867275658248256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:05 INFO  DistriOptimizer$:408 - [Epoch 8 43648/60000][Iteration 3624][Wall Clock 346.782519332s] Trained 128 records in 0.084937978 seconds. Throughput is 1506.982 records/second. Loss is 1.2662969. Sequential266afc8b's hyper parameters: Current learning rate is 2.686005909213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 43776/60000][Iteration 3625][Wall Clock 346.865481377s] Trained 128 records in 0.082962045 seconds. Throughput is 1542.8743 records/second. Loss is 1.1644341. Sequential266afc8b's hyper parameters: Current learning rate is 2.685284640171858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 43904/60000][Iteration 3626][Wall Clock 346.950689515s] Trained 128 records in 0.085208138 seconds. Throughput is 1502.2039 records/second. Loss is 1.2114938. Sequential266afc8b's hyper parameters: Current learning rate is 2.684563758389262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44032/60000][Iteration 3627][Wall Clock 347.036254167s] Trained 128 records in 0.085564652 seconds. Throughput is 1495.9448 records/second. Loss is 1.1498582. Sequential266afc8b's hyper parameters: Current learning rate is 2.6838432635534085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44160/60000][Iteration 3628][Wall Clock 347.123093021s] Trained 128 records in 0.086838854 seconds. Throughput is 1473.9945 records/second. Loss is 1.3459318. Sequential266afc8b's hyper parameters: Current learning rate is 2.6831231553528306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44288/60000][Iteration 3629][Wall Clock 347.208864612s] Trained 128 records in 0.085771591 seconds. Throughput is 1492.3356 records/second. Loss is 1.1779695. Sequential266afc8b's hyper parameters: Current learning rate is 2.682403433476395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44416/60000][Iteration 3630][Wall Clock 347.294635575s] Trained 128 records in 0.085770963 seconds. Throughput is 1492.3466 records/second. Loss is 1.2418925. Sequential266afc8b's hyper parameters: Current learning rate is 2.681684097613301E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44544/60000][Iteration 3631][Wall Clock 347.37982695s] Trained 128 records in 0.085191375 seconds. Throughput is 1502.4995 records/second. Loss is 1.2305089. Sequential266afc8b's hyper parameters: Current learning rate is 2.680965147453083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44672/60000][Iteration 3632][Wall Clock 347.471278715s] Trained 128 records in 0.091451765 seconds. Throughput is 1399.6449 records/second. Loss is 1.1619755. Sequential266afc8b's hyper parameters: Current learning rate is 2.680246582685607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44800/60000][Iteration 3633][Wall Clock 347.554219003s] Trained 128 records in 0.082940288 seconds. Throughput is 1543.2789 records/second. Loss is 1.2103715. Sequential266afc8b's hyper parameters: Current learning rate is 2.679528403001072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 44928/60000][Iteration 3634][Wall Clock 347.656706914s] Trained 128 records in 0.102487911 seconds. Throughput is 1248.9277 records/second. Loss is 1.2340462. Sequential266afc8b's hyper parameters: Current learning rate is 2.678810608090008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 45056/60000][Iteration 3635][Wall Clock 347.744629366s] Trained 128 records in 0.087922452 seconds. Throughput is 1455.8284 records/second. Loss is 1.1064268. Sequential266afc8b's hyper parameters: Current learning rate is 2.678093197643278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:06 INFO  DistriOptimizer$:408 - [Epoch 8 45184/60000][Iteration 3636][Wall Clock 347.827784905s] Trained 128 records in 0.083155539 seconds. Throughput is 1539.284 records/second. Loss is 1.1786554. Sequential266afc8b's hyper parameters: Current learning rate is 2.677376171352075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 45312/60000][Iteration 3637][Wall Clock 347.916214557s] Trained 128 records in 0.088429652 seconds. Throughput is 1447.4783 records/second. Loss is 1.151805. Sequential266afc8b's hyper parameters: Current learning rate is 2.676659528907923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 45440/60000][Iteration 3638][Wall Clock 348.000585331s] Trained 128 records in 0.084370774 seconds. Throughput is 1517.1129 records/second. Loss is 1.2264293. Sequential266afc8b's hyper parameters: Current learning rate is 2.6759432700026764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 45568/60000][Iteration 3639][Wall Clock 348.085111363s] Trained 128 records in 0.084526032 seconds. Throughput is 1514.3264 records/second. Loss is 1.1768789. Sequential266afc8b's hyper parameters: Current learning rate is 2.6752273943285177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 45696/60000][Iteration 3640][Wall Clock 348.180680599s] Trained 128 records in 0.095569236 seconds. Throughput is 1339.3431 records/second. Loss is 1.156519. Sequential266afc8b's hyper parameters: Current learning rate is 2.674511901577962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 45824/60000][Iteration 3641][Wall Clock 348.269338926s] Trained 128 records in 0.088658327 seconds. Throughput is 1443.7449 records/second. Loss is 1.1295469. Sequential266afc8b's hyper parameters: Current learning rate is 2.6737967914438503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 45952/60000][Iteration 3642][Wall Clock 348.353522471s] Trained 128 records in 0.084183545 seconds. Throughput is 1520.4872 records/second. Loss is 1.2289208. Sequential266afc8b's hyper parameters: Current learning rate is 2.673082063619353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 46080/60000][Iteration 3643][Wall Clock 348.438160565s] Trained 128 records in 0.084638094 seconds. Throughput is 1512.3213 records/second. Loss is 1.2084846. Sequential266afc8b's hyper parameters: Current learning rate is 2.672367717797969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 46208/60000][Iteration 3644][Wall Clock 348.524558873s] Trained 128 records in 0.086398308 seconds. Throughput is 1481.5105 records/second. Loss is 1.1320558. Sequential266afc8b's hyper parameters: Current learning rate is 2.671653753673524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 46336/60000][Iteration 3645][Wall Clock 348.609992943s] Trained 128 records in 0.08543407 seconds. Throughput is 1498.2313 records/second. Loss is 1.1473167. Sequential266afc8b's hyper parameters: Current learning rate is 2.670940170940171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 46464/60000][Iteration 3646][Wall Clock 348.693117962s] Trained 128 records in 0.083125019 seconds. Throughput is 1539.8492 records/second. Loss is 1.2960048. Sequential266afc8b's hyper parameters: Current learning rate is 2.67022696929239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:07 INFO  DistriOptimizer$:408 - [Epoch 8 46592/60000][Iteration 3647][Wall Clock 348.77547498s] Trained 128 records in 0.082357018 seconds. Throughput is 1554.2087 records/second. Loss is 1.1753974. Sequential266afc8b's hyper parameters: Current learning rate is 2.6695141484249865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 46720/60000][Iteration 3648][Wall Clock 348.858776214s] Trained 128 records in 0.083301234 seconds. Throughput is 1536.5919 records/second. Loss is 1.2131919. Sequential266afc8b's hyper parameters: Current learning rate is 2.668801708033093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 46848/60000][Iteration 3649][Wall Clock 348.940446415s] Trained 128 records in 0.081670201 seconds. Throughput is 1567.279 records/second. Loss is 1.1788328. Sequential266afc8b's hyper parameters: Current learning rate is 2.668089647812166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 46976/60000][Iteration 3650][Wall Clock 349.023553402s] Trained 128 records in 0.083106987 seconds. Throughput is 1540.1833 records/second. Loss is 1.276958. Sequential266afc8b's hyper parameters: Current learning rate is 2.6673779674579886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47104/60000][Iteration 3651][Wall Clock 349.107168701s] Trained 128 records in 0.083615299 seconds. Throughput is 1530.8204 records/second. Loss is 1.1876507. Sequential266afc8b's hyper parameters: Current learning rate is 2.666666666666667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47232/60000][Iteration 3652][Wall Clock 349.190560006s] Trained 128 records in 0.083391305 seconds. Throughput is 1534.9323 records/second. Loss is 1.1372136. Sequential266afc8b's hyper parameters: Current learning rate is 2.665955745134631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47360/60000][Iteration 3653][Wall Clock 349.277157991s] Trained 128 records in 0.086597985 seconds. Throughput is 1478.0944 records/second. Loss is 1.1300194. Sequential266afc8b's hyper parameters: Current learning rate is 2.6652452025586353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47488/60000][Iteration 3654][Wall Clock 349.362169767s] Trained 128 records in 0.085011776 seconds. Throughput is 1505.6738 records/second. Loss is 1.221792. Sequential266afc8b's hyper parameters: Current learning rate is 2.664535038635758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47616/60000][Iteration 3655][Wall Clock 349.445291548s] Trained 128 records in 0.083121781 seconds. Throughput is 1539.9092 records/second. Loss is 1.2525342. Sequential266afc8b's hyper parameters: Current learning rate is 2.6638252530633994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47744/60000][Iteration 3656][Wall Clock 349.532424934s] Trained 128 records in 0.087133386 seconds. Throughput is 1469.0121 records/second. Loss is 1.1150501. Sequential266afc8b's hyper parameters: Current learning rate is 2.663115845539281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 47872/60000][Iteration 3657][Wall Clock 349.626122587s] Trained 128 records in 0.093697653 seconds. Throughput is 1366.0961 records/second. Loss is 1.2122842. Sequential266afc8b's hyper parameters: Current learning rate is 2.662406815761448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 48000/60000][Iteration 3658][Wall Clock 349.708513974s] Trained 128 records in 0.082391387 seconds. Throughput is 1553.5604 records/second. Loss is 1.2352586. Sequential266afc8b's hyper parameters: Current learning rate is 2.6616981634282674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:08 INFO  DistriOptimizer$:408 - [Epoch 8 48128/60000][Iteration 3659][Wall Clock 349.786970951s] Trained 128 records in 0.078456977 seconds. Throughput is 1631.4674 records/second. Loss is 1.2120281. Sequential266afc8b's hyper parameters: Current learning rate is 2.660989888238425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 48256/60000][Iteration 3660][Wall Clock 349.868347896s] Trained 128 records in 0.081376945 seconds. Throughput is 1572.927 records/second. Loss is 1.2445004. Sequential266afc8b's hyper parameters: Current learning rate is 2.660281989890928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 48384/60000][Iteration 3661][Wall Clock 349.952511747s] Trained 128 records in 0.084163851 seconds. Throughput is 1520.8429 records/second. Loss is 1.1429118. Sequential266afc8b's hyper parameters: Current learning rate is 2.6595744680851064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 48512/60000][Iteration 3662][Wall Clock 350.038231878s] Trained 128 records in 0.085720131 seconds. Throughput is 1493.2316 records/second. Loss is 1.1113505. Sequential266afc8b's hyper parameters: Current learning rate is 2.6588673225206064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 48640/60000][Iteration 3663][Wall Clock 350.123064223s] Trained 128 records in 0.084832345 seconds. Throughput is 1508.8584 records/second. Loss is 1.188861. Sequential266afc8b's hyper parameters: Current learning rate is 2.658160552897395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 48768/60000][Iteration 3664][Wall Clock 350.208884568s] Trained 128 records in 0.085820345 seconds. Throughput is 1491.4878 records/second. Loss is 1.1933161. Sequential266afc8b's hyper parameters: Current learning rate is 2.6574541589157585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 48896/60000][Iteration 3665][Wall Clock 350.299171326s] Trained 128 records in 0.090286758 seconds. Throughput is 1417.7051 records/second. Loss is 1.0954881. Sequential266afc8b's hyper parameters: Current learning rate is 2.6567481402763017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 49024/60000][Iteration 3666][Wall Clock 350.371530921s] Trained 128 records in 0.072359595 seconds. Throughput is 1768.9431 records/second. Loss is 1.1599592. Sequential266afc8b's hyper parameters: Current learning rate is 2.656042496679947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 49152/60000][Iteration 3667][Wall Clock 350.450657721s] Trained 128 records in 0.0791268 seconds. Throughput is 1617.6567 records/second. Loss is 1.1408893. Sequential266afc8b's hyper parameters: Current learning rate is 2.655337227827934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 49280/60000][Iteration 3668][Wall Clock 350.53545091s] Trained 128 records in 0.084793189 seconds. Throughput is 1509.5552 records/second. Loss is 1.2041003. Sequential266afc8b's hyper parameters: Current learning rate is 2.654632333421821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 49408/60000][Iteration 3669][Wall Clock 350.618748256s] Trained 128 records in 0.083297346 seconds. Throughput is 1536.6636 records/second. Loss is 1.2107325. Sequential266afc8b's hyper parameters: Current learning rate is 2.653927813163482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 49536/60000][Iteration 3670][Wall Clock 350.70750871s] Trained 128 records in 0.088760454 seconds. Throughput is 1442.0837 records/second. Loss is 1.1358525. Sequential266afc8b's hyper parameters: Current learning rate is 2.653223666755108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:09 INFO  DistriOptimizer$:408 - [Epoch 8 49664/60000][Iteration 3671][Wall Clock 350.792310749s] Trained 128 records in 0.084802039 seconds. Throughput is 1509.3977 records/second. Loss is 1.1999551. Sequential266afc8b's hyper parameters: Current learning rate is 2.652519893899204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 49792/60000][Iteration 3672][Wall Clock 350.875791623s] Trained 128 records in 0.083480874 seconds. Throughput is 1533.2854 records/second. Loss is 1.0968543. Sequential266afc8b's hyper parameters: Current learning rate is 2.6518164942985947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 49920/60000][Iteration 3673][Wall Clock 350.958476094s] Trained 128 records in 0.082684471 seconds. Throughput is 1548.0537 records/second. Loss is 1.2249476. Sequential266afc8b's hyper parameters: Current learning rate is 2.651113467656416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50048/60000][Iteration 3674][Wall Clock 351.043233285s] Trained 128 records in 0.084757191 seconds. Throughput is 1510.1963 records/second. Loss is 1.1294067. Sequential266afc8b's hyper parameters: Current learning rate is 2.6504108136761196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50176/60000][Iteration 3675][Wall Clock 351.127691388s] Trained 128 records in 0.084458103 seconds. Throughput is 1515.5443 records/second. Loss is 1.1413432. Sequential266afc8b's hyper parameters: Current learning rate is 2.6497085320614734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50304/60000][Iteration 3676][Wall Clock 351.210397413s] Trained 128 records in 0.082706025 seconds. Throughput is 1547.6503 records/second. Loss is 1.2151698. Sequential266afc8b's hyper parameters: Current learning rate is 2.6490066225165563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50432/60000][Iteration 3677][Wall Clock 351.304294902s] Trained 128 records in 0.093897489 seconds. Throughput is 1363.1887 records/second. Loss is 1.146153. Sequential266afc8b's hyper parameters: Current learning rate is 2.6483050847457627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50560/60000][Iteration 3678][Wall Clock 351.38735016s] Trained 128 records in 0.083055258 seconds. Throughput is 1541.1427 records/second. Loss is 1.2325562. Sequential266afc8b's hyper parameters: Current learning rate is 2.6476039184537993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50688/60000][Iteration 3679][Wall Clock 351.472328399s] Trained 128 records in 0.084978239 seconds. Throughput is 1506.268 records/second. Loss is 1.1719522. Sequential266afc8b's hyper parameters: Current learning rate is 2.6469031233456857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50816/60000][Iteration 3680][Wall Clock 351.55569536s] Trained 128 records in 0.083366961 seconds. Throughput is 1535.3805 records/second. Loss is 1.2036557. Sequential266afc8b's hyper parameters: Current learning rate is 2.646202699126753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 50944/60000][Iteration 3681][Wall Clock 351.639903657s] Trained 128 records in 0.084208297 seconds. Throughput is 1520.0403 records/second. Loss is 1.1424251. Sequential266afc8b's hyper parameters: Current learning rate is 2.645502645502645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 51072/60000][Iteration 3682][Wall Clock 351.723117393s] Trained 128 records in 0.083213736 seconds. Throughput is 1538.2075 records/second. Loss is 1.2243408. Sequential266afc8b's hyper parameters: Current learning rate is 2.6448029621793174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:10 INFO  DistriOptimizer$:408 - [Epoch 8 51200/60000][Iteration 3683][Wall Clock 351.811852442s] Trained 128 records in 0.088735049 seconds. Throughput is 1442.4965 records/second. Loss is 1.2031087. Sequential266afc8b's hyper parameters: Current learning rate is 2.6441036488630354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 51328/60000][Iteration 3684][Wall Clock 351.898258905s] Trained 128 records in 0.086406463 seconds. Throughput is 1481.3707 records/second. Loss is 1.2304823. Sequential266afc8b's hyper parameters: Current learning rate is 2.643404705260376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 51456/60000][Iteration 3685][Wall Clock 351.979431718s] Trained 128 records in 0.081172813 seconds. Throughput is 1576.8826 records/second. Loss is 1.2166052. Sequential266afc8b's hyper parameters: Current learning rate is 2.6427061310782237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 51584/60000][Iteration 3686][Wall Clock 352.06168472s] Trained 128 records in 0.082253002 seconds. Throughput is 1556.1742 records/second. Loss is 1.1592098. Sequential266afc8b's hyper parameters: Current learning rate is 2.642007926023778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 51712/60000][Iteration 3687][Wall Clock 352.146234419s] Trained 128 records in 0.084549699 seconds. Throughput is 1513.9025 records/second. Loss is 1.2405107. Sequential266afc8b's hyper parameters: Current learning rate is 2.641310089804543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 51840/60000][Iteration 3688][Wall Clock 352.232643516s] Trained 128 records in 0.086409097 seconds. Throughput is 1481.3254 records/second. Loss is 1.1067091. Sequential266afc8b's hyper parameters: Current learning rate is 2.640612622128334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 51968/60000][Iteration 3689][Wall Clock 352.323003497s] Trained 128 records in 0.090359981 seconds. Throughput is 1416.5564 records/second. Loss is 1.253741. Sequential266afc8b's hyper parameters: Current learning rate is 2.6399155227032733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 52096/60000][Iteration 3690][Wall Clock 352.409463514s] Trained 128 records in 0.086460017 seconds. Throughput is 1480.4531 records/second. Loss is 1.1634294. Sequential266afc8b's hyper parameters: Current learning rate is 2.639218791237794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 52224/60000][Iteration 3691][Wall Clock 352.500809026s] Trained 128 records in 0.091345512 seconds. Throughput is 1401.2731 records/second. Loss is 1.1758772. Sequential266afc8b's hyper parameters: Current learning rate is 2.638522427440633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 52352/60000][Iteration 3692][Wall Clock 352.588816401s] Trained 128 records in 0.088007375 seconds. Throughput is 1454.4236 records/second. Loss is 1.1785295. Sequential266afc8b's hyper parameters: Current learning rate is 2.6378264310208385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 52480/60000][Iteration 3693][Wall Clock 352.673637134s] Trained 128 records in 0.084820733 seconds. Throughput is 1509.0651 records/second. Loss is 1.1636347. Sequential266afc8b's hyper parameters: Current learning rate is 2.6371308016877635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:11 INFO  DistriOptimizer$:408 - [Epoch 8 52608/60000][Iteration 3694][Wall Clock 352.787134871s] Trained 128 records in 0.113497737 seconds. Throughput is 1127.7759 records/second. Loss is 1.1708454. Sequential266afc8b's hyper parameters: Current learning rate is 2.636435539151068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 52736/60000][Iteration 3695][Wall Clock 352.894772588s] Trained 128 records in 0.107637717 seconds. Throughput is 1189.1742 records/second. Loss is 1.1958653. Sequential266afc8b's hyper parameters: Current learning rate is 2.635740643120717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 52864/60000][Iteration 3696][Wall Clock 352.987766505s] Trained 128 records in 0.092993917 seconds. Throughput is 1376.4342 records/second. Loss is 1.1288102. Sequential266afc8b's hyper parameters: Current learning rate is 2.6350461133069827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 52992/60000][Iteration 3697][Wall Clock 353.101183091s] Trained 128 records in 0.113416586 seconds. Throughput is 1128.5828 records/second. Loss is 1.1992689. Sequential266afc8b's hyper parameters: Current learning rate is 2.6343519494204424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53120/60000][Iteration 3698][Wall Clock 353.207307107s] Trained 128 records in 0.106124016 seconds. Throughput is 1206.1361 records/second. Loss is 1.283378. Sequential266afc8b's hyper parameters: Current learning rate is 2.633658151171978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53248/60000][Iteration 3699][Wall Clock 353.315977762s] Trained 128 records in 0.108670655 seconds. Throughput is 1177.871 records/second. Loss is 1.1754822. Sequential266afc8b's hyper parameters: Current learning rate is 2.632964718272775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53376/60000][Iteration 3700][Wall Clock 353.404167213s] Trained 128 records in 0.088189451 seconds. Throughput is 1451.4208 records/second. Loss is 1.1514939. Sequential266afc8b's hyper parameters: Current learning rate is 2.6322716504343247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53504/60000][Iteration 3701][Wall Clock 353.487802286s] Trained 128 records in 0.083635073 seconds. Throughput is 1530.4585 records/second. Loss is 1.0949707. Sequential266afc8b's hyper parameters: Current learning rate is 2.631578947368421E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53632/60000][Iteration 3702][Wall Clock 353.574584251s] Trained 128 records in 0.086781965 seconds. Throughput is 1474.9608 records/second. Loss is 1.2957225. Sequential266afc8b's hyper parameters: Current learning rate is 2.6308866087871614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53760/60000][Iteration 3703][Wall Clock 353.663334037s] Trained 128 records in 0.088749786 seconds. Throughput is 1442.257 records/second. Loss is 1.2066752. Sequential266afc8b's hyper parameters: Current learning rate is 2.630194634402946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:12 INFO  DistriOptimizer$:408 - [Epoch 8 53888/60000][Iteration 3704][Wall Clock 353.752020307s] Trained 128 records in 0.08868627 seconds. Throughput is 1443.2899 records/second. Loss is 1.1827688. Sequential266afc8b's hyper parameters: Current learning rate is 2.6295030239284776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54016/60000][Iteration 3705][Wall Clock 353.836225301s] Trained 128 records in 0.084204994 seconds. Throughput is 1520.0999 records/second. Loss is 1.1126782. Sequential266afc8b's hyper parameters: Current learning rate is 2.628811777076761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54144/60000][Iteration 3706][Wall Clock 353.92171285s] Trained 128 records in 0.085487549 seconds. Throughput is 1497.2941 records/second. Loss is 1.1524867. Sequential266afc8b's hyper parameters: Current learning rate is 2.6281208935611036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54272/60000][Iteration 3707][Wall Clock 354.009958754s] Trained 128 records in 0.088245904 seconds. Throughput is 1450.4922 records/second. Loss is 1.185072. Sequential266afc8b's hyper parameters: Current learning rate is 2.627430373095113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54400/60000][Iteration 3708][Wall Clock 354.102607233s] Trained 128 records in 0.092648479 seconds. Throughput is 1381.5662 records/second. Loss is 1.1423727. Sequential266afc8b's hyper parameters: Current learning rate is 2.626740215392698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54528/60000][Iteration 3709][Wall Clock 354.187587826s] Trained 128 records in 0.084980593 seconds. Throughput is 1506.2263 records/second. Loss is 1.1829865. Sequential266afc8b's hyper parameters: Current learning rate is 2.6260504201680677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54656/60000][Iteration 3710][Wall Clock 354.268733462s] Trained 128 records in 0.081145636 seconds. Throughput is 1577.4108 records/second. Loss is 1.246031. Sequential266afc8b's hyper parameters: Current learning rate is 2.625360987135731E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54784/60000][Iteration 3711][Wall Clock 354.349601242s] Trained 128 records in 0.08086778 seconds. Throughput is 1582.8306 records/second. Loss is 1.1213236. Sequential266afc8b's hyper parameters: Current learning rate is 2.6246719160104987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 54912/60000][Iteration 3712][Wall Clock 354.453569292s] Trained 128 records in 0.10396805 seconds. Throughput is 1231.1475 records/second. Loss is 1.1770486. Sequential266afc8b's hyper parameters: Current learning rate is 2.623983206507478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 55040/60000][Iteration 3713][Wall Clock 354.537671031s] Trained 128 records in 0.084101739 seconds. Throughput is 1521.9662 records/second. Loss is 1.2326103. Sequential266afc8b's hyper parameters: Current learning rate is 2.6232948583420777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 55168/60000][Iteration 3714][Wall Clock 354.623232288s] Trained 128 records in 0.085561257 seconds. Throughput is 1496.0042 records/second. Loss is 1.1840844. Sequential266afc8b's hyper parameters: Current learning rate is 2.6226068712300026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 55296/60000][Iteration 3715][Wall Clock 354.709684016s] Trained 128 records in 0.086451728 seconds. Throughput is 1480.595 records/second. Loss is 1.1802607. Sequential266afc8b's hyper parameters: Current learning rate is 2.6219192448872575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:13 INFO  DistriOptimizer$:408 - [Epoch 8 55424/60000][Iteration 3716][Wall Clock 354.799158619s] Trained 128 records in 0.089474603 seconds. Throughput is 1430.5735 records/second. Loss is 1.1310548. Sequential266afc8b's hyper parameters: Current learning rate is 2.621231979030144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 55552/60000][Iteration 3717][Wall Clock 354.876149683s] Trained 128 records in 0.076991064 seconds. Throughput is 1662.5305 records/second. Loss is 1.1805707. Sequential266afc8b's hyper parameters: Current learning rate is 2.6205450733752617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 55680/60000][Iteration 3718][Wall Clock 354.959342881s] Trained 128 records in 0.083193198 seconds. Throughput is 1538.5873 records/second. Loss is 1.2003872. Sequential266afc8b's hyper parameters: Current learning rate is 2.619858527639507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 55808/60000][Iteration 3719][Wall Clock 355.047847896s] Trained 128 records in 0.088505015 seconds. Throughput is 1446.2457 records/second. Loss is 1.2069672. Sequential266afc8b's hyper parameters: Current learning rate is 2.6191723415400735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 55936/60000][Iteration 3720][Wall Clock 355.133610446s] Trained 128 records in 0.08576255 seconds. Throughput is 1492.4929 records/second. Loss is 1.1659603. Sequential266afc8b's hyper parameters: Current learning rate is 2.618486514794449E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56064/60000][Iteration 3721][Wall Clock 355.21951741s] Trained 128 records in 0.085906964 seconds. Throughput is 1489.9839 records/second. Loss is 1.1741967. Sequential266afc8b's hyper parameters: Current learning rate is 2.6178010471204186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56192/60000][Iteration 3722][Wall Clock 355.302765384s] Trained 128 records in 0.083247974 seconds. Throughput is 1537.575 records/second. Loss is 1.2185409. Sequential266afc8b's hyper parameters: Current learning rate is 2.6171159382360636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56320/60000][Iteration 3723][Wall Clock 355.386902418s] Trained 128 records in 0.084137034 seconds. Throughput is 1521.3276 records/second. Loss is 1.2373677. Sequential266afc8b's hyper parameters: Current learning rate is 2.6164311878597594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56448/60000][Iteration 3724][Wall Clock 355.468432822s] Trained 128 records in 0.081530404 seconds. Throughput is 1569.9664 records/second. Loss is 1.1012317. Sequential266afc8b's hyper parameters: Current learning rate is 2.615746795710175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56576/60000][Iteration 3725][Wall Clock 355.552887835s] Trained 128 records in 0.084455013 seconds. Throughput is 1515.5997 records/second. Loss is 1.189181. Sequential266afc8b's hyper parameters: Current learning rate is 2.615062761506276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56704/60000][Iteration 3726][Wall Clock 355.641310213s] Trained 128 records in 0.088422378 seconds. Throughput is 1447.5973 records/second. Loss is 1.2047161. Sequential266afc8b's hyper parameters: Current learning rate is 2.6143790849673205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:14 INFO  DistriOptimizer$:408 - [Epoch 8 56832/60000][Iteration 3727][Wall Clock 355.728279536s] Trained 128 records in 0.086969323 seconds. Throughput is 1471.7833 records/second. Loss is 1.1960166. Sequential266afc8b's hyper parameters: Current learning rate is 2.61369576581286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 56960/60000][Iteration 3728][Wall Clock 355.812929745s] Trained 128 records in 0.084650209 seconds. Throughput is 1512.1049 records/second. Loss is 1.2811291. Sequential266afc8b's hyper parameters: Current learning rate is 2.613012803762738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57088/60000][Iteration 3729][Wall Clock 355.895691885s] Trained 128 records in 0.08276214 seconds. Throughput is 1546.601 records/second. Loss is 1.1307145. Sequential266afc8b's hyper parameters: Current learning rate is 2.612330198537095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57216/60000][Iteration 3730][Wall Clock 355.981411763s] Trained 128 records in 0.085719878 seconds. Throughput is 1493.236 records/second. Loss is 1.1703458. Sequential266afc8b's hyper parameters: Current learning rate is 2.6116479498563595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57344/60000][Iteration 3731][Wall Clock 356.066668776s] Trained 128 records in 0.085257013 seconds. Throughput is 1501.3428 records/second. Loss is 1.2566061. Sequential266afc8b's hyper parameters: Current learning rate is 2.610966057441253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57472/60000][Iteration 3732][Wall Clock 356.149330206s] Trained 128 records in 0.08266143 seconds. Throughput is 1548.4852 records/second. Loss is 1.1089877. Sequential266afc8b's hyper parameters: Current learning rate is 2.61028452101279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57600/60000][Iteration 3733][Wall Clock 356.241300267s] Trained 128 records in 0.091970061 seconds. Throughput is 1391.7572 records/second. Loss is 1.1470026. Sequential266afc8b's hyper parameters: Current learning rate is 2.609603340292276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57728/60000][Iteration 3734][Wall Clock 356.338569886s] Trained 128 records in 0.097269619 seconds. Throughput is 1315.9299 records/second. Loss is 1.1549418. Sequential266afc8b's hyper parameters: Current learning rate is 2.6089225150013044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57856/60000][Iteration 3735][Wall Clock 356.419490641s] Trained 128 records in 0.080920755 seconds. Throughput is 1581.7944 records/second. Loss is 1.1645378. Sequential266afc8b's hyper parameters: Current learning rate is 2.608242044861763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 57984/60000][Iteration 3736][Wall Clock 356.502272628s] Trained 128 records in 0.082781987 seconds. Throughput is 1546.2301 records/second. Loss is 1.102602. Sequential266afc8b's hyper parameters: Current learning rate is 2.607561929595828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 58112/60000][Iteration 3737][Wall Clock 356.58980703s] Trained 128 records in 0.087534402 seconds. Throughput is 1462.2822 records/second. Loss is 1.2146698. Sequential266afc8b's hyper parameters: Current learning rate is 2.6068821689259646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 58240/60000][Iteration 3738][Wall Clock 356.674430441s] Trained 128 records in 0.084623411 seconds. Throughput is 1512.5837 records/second. Loss is 1.2259783. Sequential266afc8b's hyper parameters: Current learning rate is 2.6062027625749283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:15 INFO  DistriOptimizer$:408 - [Epoch 8 58368/60000][Iteration 3739][Wall Clock 356.757474466s] Trained 128 records in 0.083044025 seconds. Throughput is 1541.3512 records/second. Loss is 1.1437948. Sequential266afc8b's hyper parameters: Current learning rate is 2.605523710265763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 58496/60000][Iteration 3740][Wall Clock 356.840849758s] Trained 128 records in 0.083375292 seconds. Throughput is 1535.227 records/second. Loss is 1.183756. Sequential266afc8b's hyper parameters: Current learning rate is 2.6048450117218026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 58624/60000][Iteration 3741][Wall Clock 356.926225779s] Trained 128 records in 0.085376021 seconds. Throughput is 1499.25 records/second. Loss is 1.2204374. Sequential266afc8b's hyper parameters: Current learning rate is 2.6041666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 58752/60000][Iteration 3742][Wall Clock 357.019139693s] Trained 128 records in 0.092913914 seconds. Throughput is 1377.6194 records/second. Loss is 1.3077085. Sequential266afc8b's hyper parameters: Current learning rate is 2.603488674824264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 58880/60000][Iteration 3743][Wall Clock 357.100537163s] Trained 128 records in 0.08139747 seconds. Throughput is 1572.5305 records/second. Loss is 1.1876197. Sequential266afc8b's hyper parameters: Current learning rate is 2.602811035918792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59008/60000][Iteration 3744][Wall Clock 357.182571332s] Trained 128 records in 0.082034169 seconds. Throughput is 1560.3254 records/second. Loss is 1.1713086. Sequential266afc8b's hyper parameters: Current learning rate is 2.6021337496747333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59136/60000][Iteration 3745][Wall Clock 357.267753325s] Trained 128 records in 0.085181993 seconds. Throughput is 1502.6649 records/second. Loss is 1.171955. Sequential266afc8b's hyper parameters: Current learning rate is 2.6014568158168577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59264/60000][Iteration 3746][Wall Clock 357.353149747s] Trained 128 records in 0.085396422 seconds. Throughput is 1498.8918 records/second. Loss is 1.1945072. Sequential266afc8b's hyper parameters: Current learning rate is 2.600780234070221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59392/60000][Iteration 3747][Wall Clock 357.437653982s] Trained 128 records in 0.084504235 seconds. Throughput is 1514.717 records/second. Loss is 1.161691. Sequential266afc8b's hyper parameters: Current learning rate is 2.600104004160166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59520/60000][Iteration 3748][Wall Clock 357.522623373s] Trained 128 records in 0.084969391 seconds. Throughput is 1506.4248 records/second. Loss is 1.1919469. Sequential266afc8b's hyper parameters: Current learning rate is 2.5994281258123216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59648/60000][Iteration 3749][Wall Clock 357.607693717s] Trained 128 records in 0.085070344 seconds. Throughput is 1504.6372 records/second. Loss is 1.2038981. Sequential266afc8b's hyper parameters: Current learning rate is 2.5987525987525984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59776/60000][Iteration 3750][Wall Clock 357.696971222s] Trained 128 records in 0.089277505 seconds. Throughput is 1433.7318 records/second. Loss is 1.1742586. Sequential266afc8b's hyper parameters: Current learning rate is 2.5980774227071964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:16 INFO  DistriOptimizer$:408 - [Epoch 8 59904/60000][Iteration 3751][Wall Clock 357.782783335s] Trained 128 records in 0.085812113 seconds. Throughput is 1491.6309 records/second. Loss is 1.2086436. Sequential266afc8b's hyper parameters: Current learning rate is 2.5974025974025974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:17 INFO  DistriOptimizer$:408 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 357.869599341s] Trained 128 records in 0.086816006 seconds. Throughput is 1474.3826 records/second. Loss is 1.2013714. Sequential266afc8b's hyper parameters: Current learning rate is 2.5967281225655674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:17 INFO  DistriOptimizer$:452 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 357.869599341s] Epoch finished. Wall clock time is 359001.717611 ms
2019-10-15 08:24:17 INFO  DistriOptimizer$:111 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 357.869599341s] Validate model...
2019-10-15 08:24:17 INFO  DistriOptimizer$:178 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 357.869599341s] validate model throughput is 12291.406 records/second
2019-10-15 08:24:17 INFO  DistriOptimizer$:181 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 357.869599341s] Top1Accuracy is Accuracy(correct: 7447, count: 10000, accuracy: 0.7447)
2019-10-15 08:24:17 INFO  DistriOptimizer$:221 - [Wall Clock 359.001717611s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:24:17 INFO  DistriOptimizer$:226 - [Wall Clock 359.001717611s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 128/60000][Iteration 3753][Wall Clock 359.089459148s] Trained 128 records in 0.087741537 seconds. Throughput is 1458.8301 records/second. Loss is 1.2257164. Sequential266afc8b's hyper parameters: Current learning rate is 2.5960539979231567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 256/60000][Iteration 3754][Wall Clock 359.169425272s] Trained 128 records in 0.079966124 seconds. Throughput is 1600.6779 records/second. Loss is 1.211988. Sequential266afc8b's hyper parameters: Current learning rate is 2.595380223202699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 384/60000][Iteration 3755][Wall Clock 359.245972305s] Trained 128 records in 0.076547033 seconds. Throughput is 1672.1746 records/second. Loss is 1.0782024. Sequential266afc8b's hyper parameters: Current learning rate is 2.594706798131811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 512/60000][Iteration 3756][Wall Clock 359.32872288s] Trained 128 records in 0.082750575 seconds. Throughput is 1546.817 records/second. Loss is 1.2363205. Sequential266afc8b's hyper parameters: Current learning rate is 2.5940337224383917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 640/60000][Iteration 3757][Wall Clock 359.40911461s] Trained 128 records in 0.08039173 seconds. Throughput is 1592.2036 records/second. Loss is 1.1261241. Sequential266afc8b's hyper parameters: Current learning rate is 2.5933609958506224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 768/60000][Iteration 3758][Wall Clock 359.503853728s] Trained 128 records in 0.094739118 seconds. Throughput is 1351.0786 records/second. Loss is 1.2164228. Sequential266afc8b's hyper parameters: Current learning rate is 2.592688618096967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 896/60000][Iteration 3759][Wall Clock 359.580162806s] Trained 128 records in 0.076309078 seconds. Throughput is 1677.3889 records/second. Loss is 1.1485649. Sequential266afc8b's hyper parameters: Current learning rate is 2.592016588906169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 1024/60000][Iteration 3760][Wall Clock 359.661312664s] Trained 128 records in 0.081149858 seconds. Throughput is 1577.3286 records/second. Loss is 1.1557115. Sequential266afc8b's hyper parameters: Current learning rate is 2.591344908007256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 1152/60000][Iteration 3761][Wall Clock 359.738297914s] Trained 128 records in 0.07698525 seconds. Throughput is 1662.6562 records/second. Loss is 1.2440612. Sequential266afc8b's hyper parameters: Current learning rate is 2.5906735751295336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 1280/60000][Iteration 3762][Wall Clock 359.822283216s] Trained 128 records in 0.083985302 seconds. Throughput is 1524.0763 records/second. Loss is 1.1176318. Sequential266afc8b's hyper parameters: Current learning rate is 2.59000259000259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 1408/60000][Iteration 3763][Wall Clock 359.908507132s] Trained 128 records in 0.086223916 seconds. Throughput is 1484.507 records/second. Loss is 1.152816. Sequential266afc8b's hyper parameters: Current learning rate is 2.5893319523562924E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:18 INFO  DistriOptimizer$:408 - [Epoch 9 1536/60000][Iteration 3764][Wall Clock 359.994201346s] Trained 128 records in 0.085694214 seconds. Throughput is 1493.6831 records/second. Loss is 1.097225. Sequential266afc8b's hyper parameters: Current learning rate is 2.5886616619207867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 1664/60000][Iteration 3765][Wall Clock 360.078280336s] Trained 128 records in 0.08407899 seconds. Throughput is 1522.3779 records/second. Loss is 1.1743883. Sequential266afc8b's hyper parameters: Current learning rate is 2.587991718426501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 1792/60000][Iteration 3766][Wall Clock 360.169186527s] Trained 128 records in 0.090906191 seconds. Throughput is 1408.0449 records/second. Loss is 1.2416439. Sequential266afc8b's hyper parameters: Current learning rate is 2.58732212160414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 1920/60000][Iteration 3767][Wall Clock 360.246043671s] Trained 128 records in 0.076857144 seconds. Throughput is 1665.4275 records/second. Loss is 1.2419814. Sequential266afc8b's hyper parameters: Current learning rate is 2.586652871184687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2048/60000][Iteration 3768][Wall Clock 360.327692514s] Trained 128 records in 0.081648843 seconds. Throughput is 1567.6891 records/second. Loss is 1.1621406. Sequential266afc8b's hyper parameters: Current learning rate is 2.585983966899405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2176/60000][Iteration 3769][Wall Clock 360.411691938s] Trained 128 records in 0.083999424 seconds. Throughput is 1523.82 records/second. Loss is 1.1798979. Sequential266afc8b's hyper parameters: Current learning rate is 2.585315408479835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2304/60000][Iteration 3770][Wall Clock 360.496918706s] Trained 128 records in 0.085226768 seconds. Throughput is 1501.8756 records/second. Loss is 1.1982094. Sequential266afc8b's hyper parameters: Current learning rate is 2.584647195657793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2432/60000][Iteration 3771][Wall Clock 360.581840557s] Trained 128 records in 0.084921851 seconds. Throughput is 1507.2681 records/second. Loss is 1.1622765. Sequential266afc8b's hyper parameters: Current learning rate is 2.5839793281653745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2560/60000][Iteration 3772][Wall Clock 360.667353627s] Trained 128 records in 0.08551307 seconds. Throughput is 1496.8472 records/second. Loss is 1.2511814. Sequential266afc8b's hyper parameters: Current learning rate is 2.583311805734952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2688/60000][Iteration 3773][Wall Clock 360.755193157s] Trained 128 records in 0.08783953 seconds. Throughput is 1457.2028 records/second. Loss is 1.1824201. Sequential266afc8b's hyper parameters: Current learning rate is 2.5826446280991736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2816/60000][Iteration 3774][Wall Clock 360.841680908s] Trained 128 records in 0.086487751 seconds. Throughput is 1479.9784 records/second. Loss is 1.1302762. Sequential266afc8b's hyper parameters: Current learning rate is 2.581977794990963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:19 INFO  DistriOptimizer$:408 - [Epoch 9 2944/60000][Iteration 3775][Wall Clock 360.928007232s] Trained 128 records in 0.086326324 seconds. Throughput is 1482.7458 records/second. Loss is 1.1993232. Sequential266afc8b's hyper parameters: Current learning rate is 2.5813113061435206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3072/60000][Iteration 3776][Wall Clock 361.013881172s] Trained 128 records in 0.08587394 seconds. Throughput is 1490.557 records/second. Loss is 1.1366795. Sequential266afc8b's hyper parameters: Current learning rate is 2.5806451612903227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3200/60000][Iteration 3777][Wall Clock 361.098660189s] Trained 128 records in 0.084779017 seconds. Throughput is 1509.8076 records/second. Loss is 1.17795. Sequential266afc8b's hyper parameters: Current learning rate is 2.579979360165119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3328/60000][Iteration 3778][Wall Clock 361.184539574s] Trained 128 records in 0.085879385 seconds. Throughput is 1490.4624 records/second. Loss is 1.2414459. Sequential266afc8b's hyper parameters: Current learning rate is 2.579313902501934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3456/60000][Iteration 3779][Wall Clock 361.2713023s] Trained 128 records in 0.086762726 seconds. Throughput is 1475.2878 records/second. Loss is 1.1802765. Sequential266afc8b's hyper parameters: Current learning rate is 2.5786487880350697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3584/60000][Iteration 3780][Wall Clock 361.353684907s] Trained 128 records in 0.082382607 seconds. Throughput is 1553.7261 records/second. Loss is 1.1191877. Sequential266afc8b's hyper parameters: Current learning rate is 2.577984016499098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3712/60000][Iteration 3781][Wall Clock 361.438500922s] Trained 128 records in 0.084816015 seconds. Throughput is 1509.1489 records/second. Loss is 1.1468992. Sequential266afc8b's hyper parameters: Current learning rate is 2.5773195876288655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3840/60000][Iteration 3782][Wall Clock 361.523077799s] Trained 128 records in 0.084576877 seconds. Throughput is 1513.416 records/second. Loss is 1.1684203. Sequential266afc8b's hyper parameters: Current learning rate is 2.576655501159495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 3968/60000][Iteration 3783][Wall Clock 361.607218516s] Trained 128 records in 0.084140717 seconds. Throughput is 1521.2611 records/second. Loss is 1.1524899. Sequential266afc8b's hyper parameters: Current learning rate is 2.5759917568263783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 4096/60000][Iteration 3784][Wall Clock 361.702135178s] Trained 128 records in 0.094916662 seconds. Throughput is 1348.5514 records/second. Loss is 1.1550666. Sequential266afc8b's hyper parameters: Current learning rate is 2.575328354365182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 4224/60000][Iteration 3785][Wall Clock 361.778607545s] Trained 128 records in 0.076472367 seconds. Throughput is 1673.8073 records/second. Loss is 1.0680467. Sequential266afc8b's hyper parameters: Current learning rate is 2.5746652935118434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 4352/60000][Iteration 3786][Wall Clock 361.859238644s] Trained 128 records in 0.080631099 seconds. Throughput is 1587.4768 records/second. Loss is 1.2056653. Sequential266afc8b's hyper parameters: Current learning rate is 2.574002574002574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:20 INFO  DistriOptimizer$:408 - [Epoch 9 4480/60000][Iteration 3787][Wall Clock 361.939686904s] Trained 128 records in 0.08044826 seconds. Throughput is 1591.0847 records/second. Loss is 1.1343703. Sequential266afc8b's hyper parameters: Current learning rate is 2.573340195573855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 4608/60000][Iteration 3788][Wall Clock 362.024130687s] Trained 128 records in 0.084443783 seconds. Throughput is 1515.8013 records/second. Loss is 1.2772086. Sequential266afc8b's hyper parameters: Current learning rate is 2.572678157962439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 4736/60000][Iteration 3789][Wall Clock 362.10737683s] Trained 128 records in 0.083246143 seconds. Throughput is 1537.6088 records/second. Loss is 1.1965553. Sequential266afc8b's hyper parameters: Current learning rate is 2.5720164609053495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 4864/60000][Iteration 3790][Wall Clock 362.193701695s] Trained 128 records in 0.086324865 seconds. Throughput is 1482.771 records/second. Loss is 1.2136664. Sequential266afc8b's hyper parameters: Current learning rate is 2.5713551041398817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 4992/60000][Iteration 3791][Wall Clock 362.279011827s] Trained 128 records in 0.085310132 seconds. Throughput is 1500.408 records/second. Loss is 1.0605059. Sequential266afc8b's hyper parameters: Current learning rate is 2.5706940874035993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5120/60000][Iteration 3792][Wall Clock 362.364677279s] Trained 128 records in 0.085665452 seconds. Throughput is 1494.1847 records/second. Loss is 1.1969467. Sequential266afc8b's hyper parameters: Current learning rate is 2.5700334104343357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5248/60000][Iteration 3793][Wall Clock 362.447660331s] Trained 128 records in 0.082983052 seconds. Throughput is 1542.4836 records/second. Loss is 1.1426432. Sequential266afc8b's hyper parameters: Current learning rate is 2.5693730729701953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5376/60000][Iteration 3794][Wall Clock 362.532949756s] Trained 128 records in 0.085289425 seconds. Throughput is 1500.7722 records/second. Loss is 1.2318375. Sequential266afc8b's hyper parameters: Current learning rate is 2.5687130747495504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5504/60000][Iteration 3795][Wall Clock 362.616869817s] Trained 128 records in 0.083920061 seconds. Throughput is 1525.261 records/second. Loss is 1.1240714. Sequential266afc8b's hyper parameters: Current learning rate is 2.5680534155110427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5632/60000][Iteration 3796][Wall Clock 362.700423279s] Trained 128 records in 0.083553462 seconds. Throughput is 1531.9532 records/second. Loss is 1.1995794. Sequential266afc8b's hyper parameters: Current learning rate is 2.567394094993581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5760/60000][Iteration 3797][Wall Clock 362.785398352s] Trained 128 records in 0.084975073 seconds. Throughput is 1506.3241 records/second. Loss is 1.147825. Sequential266afc8b's hyper parameters: Current learning rate is 2.566735112936345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 5888/60000][Iteration 3798][Wall Clock 362.875438667s] Trained 128 records in 0.090040315 seconds. Throughput is 1421.5853 records/second. Loss is 1.1328473. Sequential266afc8b's hyper parameters: Current learning rate is 2.5660764690787786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:21 INFO  DistriOptimizer$:408 - [Epoch 9 6016/60000][Iteration 3799][Wall Clock 362.959785577s] Trained 128 records in 0.08434691 seconds. Throughput is 1517.5422 records/second. Loss is 1.2158024. Sequential266afc8b's hyper parameters: Current learning rate is 2.565418163160595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6144/60000][Iteration 3800][Wall Clock 363.043718101s] Trained 128 records in 0.083932524 seconds. Throughput is 1525.0345 records/second. Loss is 1.1551404. Sequential266afc8b's hyper parameters: Current learning rate is 2.5647601949217746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6272/60000][Iteration 3801][Wall Clock 363.130852352s] Trained 128 records in 0.087134251 seconds. Throughput is 1468.9976 records/second. Loss is 1.1001854. Sequential266afc8b's hyper parameters: Current learning rate is 2.564102564102564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6400/60000][Iteration 3802][Wall Clock 363.218539014s] Trained 128 records in 0.087686662 seconds. Throughput is 1459.743 records/second. Loss is 1.2254276. Sequential266afc8b's hyper parameters: Current learning rate is 2.563445270443476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6528/60000][Iteration 3803][Wall Clock 363.302683689s] Trained 128 records in 0.084144675 seconds. Throughput is 1521.1896 records/second. Loss is 1.1653324. Sequential266afc8b's hyper parameters: Current learning rate is 2.5627883136852895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6656/60000][Iteration 3804][Wall Clock 363.388793672s] Trained 128 records in 0.086109983 seconds. Throughput is 1486.4711 records/second. Loss is 1.1754944. Sequential266afc8b's hyper parameters: Current learning rate is 2.5621316935690495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6784/60000][Iteration 3805][Wall Clock 363.472268356s] Trained 128 records in 0.083474684 seconds. Throughput is 1533.399 records/second. Loss is 1.0617893. Sequential266afc8b's hyper parameters: Current learning rate is 2.5614754098360657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 6912/60000][Iteration 3806][Wall Clock 363.558820068s] Trained 128 records in 0.086551712 seconds. Throughput is 1478.8846 records/second. Loss is 1.1463315. Sequential266afc8b's hyper parameters: Current learning rate is 2.5608194622279127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 7040/60000][Iteration 3807][Wall Clock 363.648187826s] Trained 128 records in 0.089367758 seconds. Throughput is 1432.2839 records/second. Loss is 1.1208384. Sequential266afc8b's hyper parameters: Current learning rate is 2.560163850486431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 7168/60000][Iteration 3808][Wall Clock 363.734984692s] Trained 128 records in 0.086796866 seconds. Throughput is 1474.7076 records/second. Loss is 1.2091126. Sequential266afc8b's hyper parameters: Current learning rate is 2.559508574353724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 7296/60000][Iteration 3809][Wall Clock 363.827963656s] Trained 128 records in 0.092978964 seconds. Throughput is 1376.6555 records/second. Loss is 1.1230437. Sequential266afc8b's hyper parameters: Current learning rate is 2.5588536335721597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:22 INFO  DistriOptimizer$:408 - [Epoch 9 7424/60000][Iteration 3810][Wall Clock 363.914467018s] Trained 128 records in 0.086503362 seconds. Throughput is 1479.7112 records/second. Loss is 1.2051991. Sequential266afc8b's hyper parameters: Current learning rate is 2.558199027884369E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 7552/60000][Iteration 3811][Wall Clock 364.00043452s] Trained 128 records in 0.085967502 seconds. Throughput is 1488.9347 records/second. Loss is 1.2352145. Sequential266afc8b's hyper parameters: Current learning rate is 2.557544757033248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 7680/60000][Iteration 3812][Wall Clock 364.081639689s] Trained 128 records in 0.081205169 seconds. Throughput is 1576.2544 records/second. Loss is 1.3125172. Sequential266afc8b's hyper parameters: Current learning rate is 2.5568908207619537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 7808/60000][Iteration 3813][Wall Clock 364.169467937s] Trained 128 records in 0.087828248 seconds. Throughput is 1457.3899 records/second. Loss is 1.1399164. Sequential266afc8b's hyper parameters: Current learning rate is 2.556237218813906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 7936/60000][Iteration 3814][Wall Clock 364.256765434s] Trained 128 records in 0.087297497 seconds. Throughput is 1466.2505 records/second. Loss is 1.1320854. Sequential266afc8b's hyper parameters: Current learning rate is 2.555583950932788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8064/60000][Iteration 3815][Wall Clock 364.343683024s] Trained 128 records in 0.08691759 seconds. Throughput is 1472.6594 records/second. Loss is 1.099468. Sequential266afc8b's hyper parameters: Current learning rate is 2.554931016862545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8192/60000][Iteration 3816][Wall Clock 364.427670543s] Trained 128 records in 0.083987519 seconds. Throughput is 1524.036 records/second. Loss is 1.2517474. Sequential266afc8b's hyper parameters: Current learning rate is 2.554278416347382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8320/60000][Iteration 3817][Wall Clock 364.523170964s] Trained 128 records in 0.095500421 seconds. Throughput is 1340.3082 records/second. Loss is 1.2394152. Sequential266afc8b's hyper parameters: Current learning rate is 2.553626149131767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8448/60000][Iteration 3818][Wall Clock 364.603922971s] Trained 128 records in 0.080752007 seconds. Throughput is 1585.0999 records/second. Loss is 1.1177357. Sequential266afc8b's hyper parameters: Current learning rate is 2.552974214960429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8576/60000][Iteration 3819][Wall Clock 364.691749685s] Trained 128 records in 0.087826714 seconds. Throughput is 1457.4153 records/second. Loss is 1.2424258. Sequential266afc8b's hyper parameters: Current learning rate is 2.5523226135783564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8704/60000][Iteration 3820][Wall Clock 364.779959515s] Trained 128 records in 0.08820983 seconds. Throughput is 1451.0854 records/second. Loss is 1.2384968. Sequential266afc8b's hyper parameters: Current learning rate is 2.551671344730799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8832/60000][Iteration 3821][Wall Clock 364.866930168s] Trained 128 records in 0.086970653 seconds. Throughput is 1471.7609 records/second. Loss is 1.1419499. Sequential266afc8b's hyper parameters: Current learning rate is 2.551020408163265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:23 INFO  DistriOptimizer$:408 - [Epoch 9 8960/60000][Iteration 3822][Wall Clock 364.966312141s] Trained 128 records in 0.099381973 seconds. Throughput is 1287.96 records/second. Loss is 1.206764. Sequential266afc8b's hyper parameters: Current learning rate is 2.550369803621525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9088/60000][Iteration 3823][Wall Clock 365.055472678s] Trained 128 records in 0.089160537 seconds. Throughput is 1435.6127 records/second. Loss is 1.1007186. Sequential266afc8b's hyper parameters: Current learning rate is 2.5497195308516065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9216/60000][Iteration 3824][Wall Clock 365.168064561s] Trained 128 records in 0.112591883 seconds. Throughput is 1136.8492 records/second. Loss is 1.2502735. Sequential266afc8b's hyper parameters: Current learning rate is 2.5490695895997957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9344/60000][Iteration 3825][Wall Clock 365.259717588s] Trained 128 records in 0.091653027 seconds. Throughput is 1396.5714 records/second. Loss is 1.1409478. Sequential266afc8b's hyper parameters: Current learning rate is 2.54841997961264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9472/60000][Iteration 3826][Wall Clock 365.351062873s] Trained 128 records in 0.091345285 seconds. Throughput is 1401.2765 records/second. Loss is 1.051656. Sequential266afc8b's hyper parameters: Current learning rate is 2.547770700636943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9600/60000][Iteration 3827][Wall Clock 365.440645494s] Trained 128 records in 0.089582621 seconds. Throughput is 1428.8485 records/second. Loss is 1.1930878. Sequential266afc8b's hyper parameters: Current learning rate is 2.5471217524197657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9728/60000][Iteration 3828][Wall Clock 365.529629304s] Trained 128 records in 0.08898381 seconds. Throughput is 1438.4639 records/second. Loss is 1.1113719. Sequential266afc8b's hyper parameters: Current learning rate is 2.5464731347084286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9856/60000][Iteration 3829][Wall Clock 365.618230023s] Trained 128 records in 0.088600719 seconds. Throughput is 1444.6836 records/second. Loss is 1.1836137. Sequential266afc8b's hyper parameters: Current learning rate is 2.545824847250509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 9984/60000][Iteration 3830][Wall Clock 365.708995265s] Trained 128 records in 0.090765242 seconds. Throughput is 1410.2314 records/second. Loss is 1.1368436. Sequential266afc8b's hyper parameters: Current learning rate is 2.5451768897938407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 10112/60000][Iteration 3831][Wall Clock 365.79896015s] Trained 128 records in 0.089964885 seconds. Throughput is 1422.7773 records/second. Loss is 1.1895684. Sequential266afc8b's hyper parameters: Current learning rate is 2.544529262086514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 10240/60000][Iteration 3832][Wall Clock 365.886771047s] Trained 128 records in 0.087810897 seconds. Throughput is 1457.6779 records/second. Loss is 1.3122256. Sequential266afc8b's hyper parameters: Current learning rate is 2.543881963876876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:24 INFO  DistriOptimizer$:408 - [Epoch 9 10368/60000][Iteration 3833][Wall Clock 365.97341469s] Trained 128 records in 0.086643643 seconds. Throughput is 1477.3156 records/second. Loss is 1.234261. Sequential266afc8b's hyper parameters: Current learning rate is 2.54323499491353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 10496/60000][Iteration 3834][Wall Clock 366.07019078s] Trained 128 records in 0.09677609 seconds. Throughput is 1322.6407 records/second. Loss is 1.2597564. Sequential266afc8b's hyper parameters: Current learning rate is 2.5425883549453347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 10624/60000][Iteration 3835][Wall Clock 366.15419853s] Trained 128 records in 0.08400775 seconds. Throughput is 1523.669 records/second. Loss is 1.2242168. Sequential266afc8b's hyper parameters: Current learning rate is 2.541942043721403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 10752/60000][Iteration 3836][Wall Clock 366.239547322s] Trained 128 records in 0.085348792 seconds. Throughput is 1499.7283 records/second. Loss is 1.2824. Sequential266afc8b's hyper parameters: Current learning rate is 2.5412960609911054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 10880/60000][Iteration 3837][Wall Clock 366.317927204s] Trained 128 records in 0.078379882 seconds. Throughput is 1633.072 records/second. Loss is 1.1993152. Sequential266afc8b's hyper parameters: Current learning rate is 2.5406504065040653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11008/60000][Iteration 3838][Wall Clock 366.409774861s] Trained 128 records in 0.091847657 seconds. Throughput is 1393.612 records/second. Loss is 1.3162245. Sequential266afc8b's hyper parameters: Current learning rate is 2.5400050800101603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11136/60000][Iteration 3839][Wall Clock 366.497555491s] Trained 128 records in 0.08778063 seconds. Throughput is 1458.1804 records/second. Loss is 1.140368. Sequential266afc8b's hyper parameters: Current learning rate is 2.5393600812595224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11264/60000][Iteration 3840][Wall Clock 366.588057907s] Trained 128 records in 0.090502416 seconds. Throughput is 1414.3269 records/second. Loss is 1.1660143. Sequential266afc8b's hyper parameters: Current learning rate is 2.538715410002539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11392/60000][Iteration 3841][Wall Clock 366.677166027s] Trained 128 records in 0.08910812 seconds. Throughput is 1436.4573 records/second. Loss is 1.164243. Sequential266afc8b's hyper parameters: Current learning rate is 2.538071065989848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11520/60000][Iteration 3842][Wall Clock 366.767422687s] Trained 128 records in 0.09025666 seconds. Throughput is 1418.1779 records/second. Loss is 1.1718837. Sequential266afc8b's hyper parameters: Current learning rate is 2.5374270489723417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11648/60000][Iteration 3843][Wall Clock 366.861982648s] Trained 128 records in 0.094559961 seconds. Throughput is 1353.6384 records/second. Loss is 1.2504437. Sequential266afc8b's hyper parameters: Current learning rate is 2.536783358701167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:25 INFO  DistriOptimizer$:408 - [Epoch 9 11776/60000][Iteration 3844][Wall Clock 366.945555961s] Trained 128 records in 0.083573313 seconds. Throughput is 1531.5895 records/second. Loss is 1.2126235. Sequential266afc8b's hyper parameters: Current learning rate is 2.53613999492772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 11904/60000][Iteration 3845][Wall Clock 367.032191748s] Trained 128 records in 0.086635787 seconds. Throughput is 1477.4496 records/second. Loss is 1.1481794. Sequential266afc8b's hyper parameters: Current learning rate is 2.535496957403651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12032/60000][Iteration 3846][Wall Clock 367.119980704s] Trained 128 records in 0.087788956 seconds. Throughput is 1458.0422 records/second. Loss is 1.1776273. Sequential266afc8b's hyper parameters: Current learning rate is 2.5348542458808617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12160/60000][Iteration 3847][Wall Clock 367.209960724s] Trained 128 records in 0.08998002 seconds. Throughput is 1422.538 records/second. Loss is 1.2295692. Sequential266afc8b's hyper parameters: Current learning rate is 2.5342118601115053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12288/60000][Iteration 3848][Wall Clock 367.297630758s] Trained 128 records in 0.087670034 seconds. Throughput is 1460.0199 records/second. Loss is 1.2167735. Sequential266afc8b's hyper parameters: Current learning rate is 2.533569799847986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12416/60000][Iteration 3849][Wall Clock 367.386974921s] Trained 128 records in 0.089344163 seconds. Throughput is 1432.6621 records/second. Loss is 1.1200837. Sequential266afc8b's hyper parameters: Current learning rate is 2.532928064842958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12544/60000][Iteration 3850][Wall Clock 367.476325187s] Trained 128 records in 0.089350266 seconds. Throughput is 1432.5642 records/second. Loss is 1.1502202. Sequential266afc8b's hyper parameters: Current learning rate is 2.532286654849329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12672/60000][Iteration 3851][Wall Clock 367.563097603s] Trained 128 records in 0.086772416 seconds. Throughput is 1475.123 records/second. Loss is 1.1612557. Sequential266afc8b's hyper parameters: Current learning rate is 2.5316455696202533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12800/60000][Iteration 3852][Wall Clock 367.653041961s] Trained 128 records in 0.089944358 seconds. Throughput is 1423.102 records/second. Loss is 1.2055371. Sequential266afc8b's hyper parameters: Current learning rate is 2.531004808909137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 12928/60000][Iteration 3853][Wall Clock 367.744995321s] Trained 128 records in 0.09195336 seconds. Throughput is 1392.01 records/second. Loss is 1.1819613. Sequential266afc8b's hyper parameters: Current learning rate is 2.5303643724696357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 13056/60000][Iteration 3854][Wall Clock 367.835593801s] Trained 128 records in 0.09059848 seconds. Throughput is 1412.8273 records/second. Loss is 1.1520455. Sequential266afc8b's hyper parameters: Current learning rate is 2.5297242600556537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:26 INFO  DistriOptimizer$:408 - [Epoch 9 13184/60000][Iteration 3855][Wall Clock 367.92126886s] Trained 128 records in 0.085675059 seconds. Throughput is 1494.0171 records/second. Loss is 1.1793636. Sequential266afc8b's hyper parameters: Current learning rate is 2.5290844714213456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 13312/60000][Iteration 3856][Wall Clock 368.008639949s] Trained 128 records in 0.087371089 seconds. Throughput is 1465.0155 records/second. Loss is 1.2065442. Sequential266afc8b's hyper parameters: Current learning rate is 2.5284450063211124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 13440/60000][Iteration 3857][Wall Clock 368.102435053s] Trained 128 records in 0.093795104 seconds. Throughput is 1364.6768 records/second. Loss is 1.159673. Sequential266afc8b's hyper parameters: Current learning rate is 2.527805864509606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 13568/60000][Iteration 3858][Wall Clock 368.196362684s] Trained 128 records in 0.093927631 seconds. Throughput is 1362.7513 records/second. Loss is 1.0708373. Sequential266afc8b's hyper parameters: Current learning rate is 2.5271670457417233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 13696/60000][Iteration 3859][Wall Clock 368.297031703s] Trained 128 records in 0.100669019 seconds. Throughput is 1271.4934 records/second. Loss is 1.2152935. Sequential266afc8b's hyper parameters: Current learning rate is 2.5265285497726126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 13824/60000][Iteration 3860][Wall Clock 368.385452116s] Trained 128 records in 0.088420413 seconds. Throughput is 1447.6295 records/second. Loss is 1.2345301. Sequential266afc8b's hyper parameters: Current learning rate is 2.525890376357666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 13952/60000][Iteration 3861][Wall Clock 368.47236498s] Trained 128 records in 0.086912864 seconds. Throughput is 1472.7394 records/second. Loss is 1.311064. Sequential266afc8b's hyper parameters: Current learning rate is 2.525252525252525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 14080/60000][Iteration 3862][Wall Clock 368.563498174s] Trained 128 records in 0.091133194 seconds. Throughput is 1404.5376 records/second. Loss is 1.160455. Sequential266afc8b's hyper parameters: Current learning rate is 2.5246149962130775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 14208/60000][Iteration 3863][Wall Clock 368.650065462s] Trained 128 records in 0.086567288 seconds. Throughput is 1478.6185 records/second. Loss is 1.1779277. Sequential266afc8b's hyper parameters: Current learning rate is 2.523977788995457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 14336/60000][Iteration 3864][Wall Clock 368.739960539s] Trained 128 records in 0.089895077 seconds. Throughput is 1423.8822 records/second. Loss is 1.232441. Sequential266afc8b's hyper parameters: Current learning rate is 2.5233409033560434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 14464/60000][Iteration 3865][Wall Clock 368.827497501s] Trained 128 records in 0.087536962 seconds. Throughput is 1462.2395 records/second. Loss is 1.0882765. Sequential266afc8b's hyper parameters: Current learning rate is 2.522704339051463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:27 INFO  DistriOptimizer$:408 - [Epoch 9 14592/60000][Iteration 3866][Wall Clock 368.916512772s] Trained 128 records in 0.089015271 seconds. Throughput is 1437.9556 records/second. Loss is 1.0786481. Sequential266afc8b's hyper parameters: Current learning rate is 2.5220680958385876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 14720/60000][Iteration 3867][Wall Clock 369.00451665s] Trained 128 records in 0.088003878 seconds. Throughput is 1454.4813 records/second. Loss is 1.149176. Sequential266afc8b's hyper parameters: Current learning rate is 2.521432173474533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 14848/60000][Iteration 3868][Wall Clock 369.10279604s] Trained 128 records in 0.09827939 seconds. Throughput is 1302.4094 records/second. Loss is 1.1502334. Sequential266afc8b's hyper parameters: Current learning rate is 2.5207965717166626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 14976/60000][Iteration 3869][Wall Clock 369.198572025s] Trained 128 records in 0.095775985 seconds. Throughput is 1336.4519 records/second. Loss is 1.1007078. Sequential266afc8b's hyper parameters: Current learning rate is 2.5201612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15104/60000][Iteration 3870][Wall Clock 369.297989284s] Trained 128 records in 0.099417259 seconds. Throughput is 1287.5028 records/second. Loss is 1.268166. Sequential266afc8b's hyper parameters: Current learning rate is 2.519526329050139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15232/60000][Iteration 3871][Wall Clock 369.386808722s] Trained 128 records in 0.088819438 seconds. Throughput is 1441.126 records/second. Loss is 1.1481016. Sequential266afc8b's hyper parameters: Current learning rate is 2.5188916876574307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15360/60000][Iteration 3872][Wall Clock 369.476013136s] Trained 128 records in 0.089204414 seconds. Throughput is 1434.9065 records/second. Loss is 1.1866406. Sequential266afc8b's hyper parameters: Current learning rate is 2.518257365902795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15488/60000][Iteration 3873][Wall Clock 369.566632402s] Trained 128 records in 0.090619266 seconds. Throughput is 1412.5032 records/second. Loss is 1.1782651. Sequential266afc8b's hyper parameters: Current learning rate is 2.5176233635448137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15616/60000][Iteration 3874][Wall Clock 369.655483449s] Trained 128 records in 0.088851047 seconds. Throughput is 1440.6133 records/second. Loss is 1.1920615. Sequential266afc8b's hyper parameters: Current learning rate is 2.51698968034231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15744/60000][Iteration 3875][Wall Clock 369.746268186s] Trained 128 records in 0.090784737 seconds. Throughput is 1409.9286 records/second. Loss is 1.1203624. Sequential266afc8b's hyper parameters: Current learning rate is 2.516356316054353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 15872/60000][Iteration 3876][Wall Clock 369.838491578s] Trained 128 records in 0.092223392 seconds. Throughput is 1387.9342 records/second. Loss is 1.2119102. Sequential266afc8b's hyper parameters: Current learning rate is 2.5157232704402514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:28 INFO  DistriOptimizer$:408 - [Epoch 9 16000/60000][Iteration 3877][Wall Clock 369.926004962s] Trained 128 records in 0.087513384 seconds. Throughput is 1462.6334 records/second. Loss is 1.155825. Sequential266afc8b's hyper parameters: Current learning rate is 2.5150905432595576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16128/60000][Iteration 3878][Wall Clock 370.020018014s] Trained 128 records in 0.094013052 seconds. Throughput is 1361.5131 records/second. Loss is 1.1024358. Sequential266afc8b's hyper parameters: Current learning rate is 2.5144581342720644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16256/60000][Iteration 3879][Wall Clock 370.106887872s] Trained 128 records in 0.086869858 seconds. Throughput is 1473.4685 records/second. Loss is 1.2118864. Sequential266afc8b's hyper parameters: Current learning rate is 2.5138260432378077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16384/60000][Iteration 3880][Wall Clock 370.198443427s] Trained 128 records in 0.091555555 seconds. Throughput is 1398.0582 records/second. Loss is 1.2540478. Sequential266afc8b's hyper parameters: Current learning rate is 2.513194269917065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16512/60000][Iteration 3881][Wall Clock 370.292487447s] Trained 128 records in 0.09404402 seconds. Throughput is 1361.0647 records/second. Loss is 1.0413793. Sequential266afc8b's hyper parameters: Current learning rate is 2.5125628140703515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16640/60000][Iteration 3882][Wall Clock 370.380742155s] Trained 128 records in 0.088254708 seconds. Throughput is 1450.3477 records/second. Loss is 1.1058444. Sequential266afc8b's hyper parameters: Current learning rate is 2.5119316754584274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16768/60000][Iteration 3883][Wall Clock 370.474670354s] Trained 128 records in 0.093928199 seconds. Throughput is 1362.743 records/second. Loss is 1.1962521. Sequential266afc8b's hyper parameters: Current learning rate is 2.5113008538422905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 16896/60000][Iteration 3884][Wall Clock 370.577685591s] Trained 128 records in 0.103015237 seconds. Throughput is 1242.5347 records/second. Loss is 1.1561615. Sequential266afc8b's hyper parameters: Current learning rate is 2.5106703489831785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 17024/60000][Iteration 3885][Wall Clock 370.663063809s] Trained 128 records in 0.085378218 seconds. Throughput is 1499.2114 records/second. Loss is 1.1470926. Sequential266afc8b's hyper parameters: Current learning rate is 2.51004016064257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 17152/60000][Iteration 3886][Wall Clock 370.753100862s] Trained 128 records in 0.090037053 seconds. Throughput is 1421.6368 records/second. Loss is 1.1296282. Sequential266afc8b's hyper parameters: Current learning rate is 2.509410288582183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 17280/60000][Iteration 3887][Wall Clock 370.838048682s] Trained 128 records in 0.08494782 seconds. Throughput is 1506.8074 records/second. Loss is 1.2729824. Sequential266afc8b's hyper parameters: Current learning rate is 2.508780732563974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:29 INFO  DistriOptimizer$:408 - [Epoch 9 17408/60000][Iteration 3888][Wall Clock 370.922946482s] Trained 128 records in 0.0848978 seconds. Throughput is 1507.6951 records/second. Loss is 1.1023334. Sequential266afc8b's hyper parameters: Current learning rate is 2.508151492350138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 17536/60000][Iteration 3889][Wall Clock 371.011821858s] Trained 128 records in 0.088875376 seconds. Throughput is 1440.219 records/second. Loss is 1.1925696. Sequential266afc8b's hyper parameters: Current learning rate is 2.5075225677031093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 17664/60000][Iteration 3890][Wall Clock 371.099414996s] Trained 128 records in 0.087593138 seconds. Throughput is 1461.3016 records/second. Loss is 1.160562. Sequential266afc8b's hyper parameters: Current learning rate is 2.50689395838556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 17792/60000][Iteration 3891][Wall Clock 371.188263285s] Trained 128 records in 0.088848289 seconds. Throughput is 1440.6581 records/second. Loss is 1.1319295. Sequential266afc8b's hyper parameters: Current learning rate is 2.506265664160401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 17920/60000][Iteration 3892][Wall Clock 371.275929847s] Trained 128 records in 0.087666562 seconds. Throughput is 1460.0778 records/second. Loss is 1.224514. Sequential266afc8b's hyper parameters: Current learning rate is 2.5056376847907793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18048/60000][Iteration 3893][Wall Clock 371.36938439s] Trained 128 records in 0.093454543 seconds. Throughput is 1369.6499 records/second. Loss is 1.1074125. Sequential266afc8b's hyper parameters: Current learning rate is 2.50501002004008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18176/60000][Iteration 3894][Wall Clock 371.465095457s] Trained 128 records in 0.095711067 seconds. Throughput is 1337.3584 records/second. Loss is 1.1558805. Sequential266afc8b's hyper parameters: Current learning rate is 2.504382669671926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18304/60000][Iteration 3895][Wall Clock 371.555296732s] Trained 128 records in 0.090201275 seconds. Throughput is 1419.0487 records/second. Loss is 1.0758557. Sequential266afc8b's hyper parameters: Current learning rate is 2.5037556334501755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18432/60000][Iteration 3896][Wall Clock 371.644500667s] Trained 128 records in 0.089203935 seconds. Throughput is 1434.9143 records/second. Loss is 1.1899245. Sequential266afc8b's hyper parameters: Current learning rate is 2.5031289111389235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18560/60000][Iteration 3897][Wall Clock 371.734314144s] Trained 128 records in 0.089813477 seconds. Throughput is 1425.1759 records/second. Loss is 1.0954912. Sequential266afc8b's hyper parameters: Current learning rate is 2.5025025025025025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18688/60000][Iteration 3898][Wall Clock 371.823299888s] Trained 128 records in 0.088985744 seconds. Throughput is 1438.4327 records/second. Loss is 1.1259873. Sequential266afc8b's hyper parameters: Current learning rate is 2.501876407305479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:30 INFO  DistriOptimizer$:408 - [Epoch 9 18816/60000][Iteration 3899][Wall Clock 371.914279154s] Trained 128 records in 0.090979266 seconds. Throughput is 1406.9141 records/second. Loss is 1.3048999. Sequential266afc8b's hyper parameters: Current learning rate is 2.501250625312656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 18944/60000][Iteration 3900][Wall Clock 372.001385814s] Trained 128 records in 0.08710666 seconds. Throughput is 1469.4629 records/second. Loss is 1.2014252. Sequential266afc8b's hyper parameters: Current learning rate is 2.500625156289072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19072/60000][Iteration 3901][Wall Clock 372.090455062s] Trained 128 records in 0.089069248 seconds. Throughput is 1437.0841 records/second. Loss is 1.1015446. Sequential266afc8b's hyper parameters: Current learning rate is 2.5E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19200/60000][Iteration 3902][Wall Clock 372.179211394s] Trained 128 records in 0.088756332 seconds. Throughput is 1442.1506 records/second. Loss is 1.0981103. Sequential266afc8b's hyper parameters: Current learning rate is 2.4993751562109475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19328/60000][Iteration 3903][Wall Clock 372.270675778s] Trained 128 records in 0.091464384 seconds. Throughput is 1399.4518 records/second. Loss is 1.1174234. Sequential266afc8b's hyper parameters: Current learning rate is 2.498750624687656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19456/60000][Iteration 3904][Wall Clock 372.362486091s] Trained 128 records in 0.091810313 seconds. Throughput is 1394.1788 records/second. Loss is 1.1977884. Sequential266afc8b's hyper parameters: Current learning rate is 2.498126405196103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19584/60000][Iteration 3905][Wall Clock 372.452366384s] Trained 128 records in 0.089880293 seconds. Throughput is 1424.1163 records/second. Loss is 1.1714346. Sequential266afc8b's hyper parameters: Current learning rate is 2.4975024975024975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19712/60000][Iteration 3906][Wall Clock 372.546833914s] Trained 128 records in 0.09446753 seconds. Throughput is 1354.9629 records/second. Loss is 1.1186608. Sequential266afc8b's hyper parameters: Current learning rate is 2.4968789013732833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19840/60000][Iteration 3907][Wall Clock 372.636412361s] Trained 128 records in 0.089578447 seconds. Throughput is 1428.9152 records/second. Loss is 1.1583347. Sequential266afc8b's hyper parameters: Current learning rate is 2.496255616575137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 19968/60000][Iteration 3908][Wall Clock 372.727001941s] Trained 128 records in 0.09058958 seconds. Throughput is 1412.966 records/second. Loss is 1.1556524. Sequential266afc8b's hyper parameters: Current learning rate is 2.495632642874969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 20096/60000][Iteration 3909][Wall Clock 372.814994281s] Trained 128 records in 0.08799234 seconds. Throughput is 1454.6721 records/second. Loss is 1.1254022. Sequential266afc8b's hyper parameters: Current learning rate is 2.4950099800399205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:31 INFO  DistriOptimizer$:408 - [Epoch 9 20224/60000][Iteration 3910][Wall Clock 372.913208907s] Trained 128 records in 0.098214626 seconds. Throughput is 1303.2682 records/second. Loss is 1.1303498. Sequential266afc8b's hyper parameters: Current learning rate is 2.4943876278373656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 20352/60000][Iteration 3911][Wall Clock 373.002718197s] Trained 128 records in 0.08950929 seconds. Throughput is 1430.0192 records/second. Loss is 1.1136538. Sequential266afc8b's hyper parameters: Current learning rate is 2.4937655860349125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 20480/60000][Iteration 3912][Wall Clock 373.088683477s] Trained 128 records in 0.08596528 seconds. Throughput is 1488.9731 records/second. Loss is 1.3105729. Sequential266afc8b's hyper parameters: Current learning rate is 2.493143854400399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 20608/60000][Iteration 3913][Wall Clock 373.176427146s] Trained 128 records in 0.087743669 seconds. Throughput is 1458.7947 records/second. Loss is 1.2440325. Sequential266afc8b's hyper parameters: Current learning rate is 2.4925224327018947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 20736/60000][Iteration 3914][Wall Clock 373.266088909s] Trained 128 records in 0.089661763 seconds. Throughput is 1427.5874 records/second. Loss is 1.119354. Sequential266afc8b's hyper parameters: Current learning rate is 2.4919013207077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 20864/60000][Iteration 3915][Wall Clock 373.354224321s] Trained 128 records in 0.088135412 seconds. Throughput is 1452.3107 records/second. Loss is 1.2419609. Sequential266afc8b's hyper parameters: Current learning rate is 2.4912805181863477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 20992/60000][Iteration 3916][Wall Clock 373.445977454s] Trained 128 records in 0.091753133 seconds. Throughput is 1395.0477 records/second. Loss is 1.1555755. Sequential266afc8b's hyper parameters: Current learning rate is 2.4906600249066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 21120/60000][Iteration 3917][Wall Clock 373.541347855s] Trained 128 records in 0.095370401 seconds. Throughput is 1342.1355 records/second. Loss is 1.1105039. Sequential266afc8b's hyper parameters: Current learning rate is 2.49003984063745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 21248/60000][Iteration 3918][Wall Clock 373.633209384s] Trained 128 records in 0.091861529 seconds. Throughput is 1393.4016 records/second. Loss is 1.1297246. Sequential266afc8b's hyper parameters: Current learning rate is 2.4894199651481205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 21376/60000][Iteration 3919][Wall Clock 373.732120967s] Trained 128 records in 0.098911583 seconds. Throughput is 1294.0851 records/second. Loss is 1.213788. Sequential266afc8b's hyper parameters: Current learning rate is 2.4888003982080636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 21504/60000][Iteration 3920][Wall Clock 373.822631579s] Trained 128 records in 0.090510612 seconds. Throughput is 1414.1987 records/second. Loss is 1.1486385. Sequential266afc8b's hyper parameters: Current learning rate is 2.488181139586962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:32 INFO  DistriOptimizer$:408 - [Epoch 9 21632/60000][Iteration 3921][Wall Clock 373.911001172s] Trained 128 records in 0.088369593 seconds. Throughput is 1448.462 records/second. Loss is 1.1113471. Sequential266afc8b's hyper parameters: Current learning rate is 2.487562189054726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 21760/60000][Iteration 3922][Wall Clock 373.996746395s] Trained 128 records in 0.085745223 seconds. Throughput is 1492.7946 records/second. Loss is 1.1700174. Sequential266afc8b's hyper parameters: Current learning rate is 2.486943546381497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 21888/60000][Iteration 3923][Wall Clock 374.084430295s] Trained 128 records in 0.0876839 seconds. Throughput is 1459.7891 records/second. Loss is 1.2046682. Sequential266afc8b's hyper parameters: Current learning rate is 2.4863252113376433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22016/60000][Iteration 3924][Wall Clock 374.17387839s] Trained 128 records in 0.089448095 seconds. Throughput is 1430.9976 records/second. Loss is 1.1155506. Sequential266afc8b's hyper parameters: Current learning rate is 2.4857071836937607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22144/60000][Iteration 3925][Wall Clock 374.257712729s] Trained 128 records in 0.083834339 seconds. Throughput is 1526.8206 records/second. Loss is 1.1625872. Sequential266afc8b's hyper parameters: Current learning rate is 2.4850894632206757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22272/60000][Iteration 3926][Wall Clock 374.343766533s] Trained 128 records in 0.086053804 seconds. Throughput is 1487.4415 records/second. Loss is 1.1964962. Sequential266afc8b's hyper parameters: Current learning rate is 2.484472049689441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22400/60000][Iteration 3927][Wall Clock 374.427210219s] Trained 128 records in 0.083443686 seconds. Throughput is 1533.9686 records/second. Loss is 1.1901189. Sequential266afc8b's hyper parameters: Current learning rate is 2.4838549428713363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22528/60000][Iteration 3928][Wall Clock 374.518494206s] Trained 128 records in 0.091283987 seconds. Throughput is 1402.2175 records/second. Loss is 1.1515125. Sequential266afc8b's hyper parameters: Current learning rate is 2.483238142537869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22656/60000][Iteration 3929][Wall Clock 374.606054918s] Trained 128 records in 0.087560712 seconds. Throughput is 1461.8428 records/second. Loss is 1.0313435. Sequential266afc8b's hyper parameters: Current learning rate is 2.4826216484607745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22784/60000][Iteration 3930][Wall Clock 374.691507463s] Trained 128 records in 0.085452545 seconds. Throughput is 1497.9075 records/second. Loss is 1.1135947. Sequential266afc8b's hyper parameters: Current learning rate is 2.482005460412013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 22912/60000][Iteration 3931][Wall Clock 374.77759251s] Trained 128 records in 0.086085047 seconds. Throughput is 1486.9017 records/second. Loss is 1.2708318. Sequential266afc8b's hyper parameters: Current learning rate is 2.4813895781637717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:33 INFO  DistriOptimizer$:408 - [Epoch 9 23040/60000][Iteration 3932][Wall Clock 374.866645732s] Trained 128 records in 0.089053222 seconds. Throughput is 1437.3428 records/second. Loss is 1.0665214. Sequential266afc8b's hyper parameters: Current learning rate is 2.4807740014884643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23168/60000][Iteration 3933][Wall Clock 374.951046083s] Trained 128 records in 0.084400351 seconds. Throughput is 1516.5814 records/second. Loss is 1.2217916. Sequential266afc8b's hyper parameters: Current learning rate is 2.48015873015873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23296/60000][Iteration 3934][Wall Clock 375.035346587s] Trained 128 records in 0.084300504 seconds. Throughput is 1518.3777 records/second. Loss is 1.1453227. Sequential266afc8b's hyper parameters: Current learning rate is 2.479543763947434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23424/60000][Iteration 3935][Wall Clock 375.13207384s] Trained 128 records in 0.096727253 seconds. Throughput is 1323.3086 records/second. Loss is 1.1596614. Sequential266afc8b's hyper parameters: Current learning rate is 2.4789291026276647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23552/60000][Iteration 3936][Wall Clock 375.217136597s] Trained 128 records in 0.085062757 seconds. Throughput is 1504.7714 records/second. Loss is 1.0768337. Sequential266afc8b's hyper parameters: Current learning rate is 2.4783147459727387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23680/60000][Iteration 3937][Wall Clock 375.294600728s] Trained 128 records in 0.077464131 seconds. Throughput is 1652.3776 records/second. Loss is 1.2221646. Sequential266afc8b's hyper parameters: Current learning rate is 2.477700693756194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23808/60000][Iteration 3938][Wall Clock 375.375383496s] Trained 128 records in 0.080782768 seconds. Throughput is 1584.4962 records/second. Loss is 1.2544001. Sequential266afc8b's hyper parameters: Current learning rate is 2.477086945751796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 23936/60000][Iteration 3939][Wall Clock 375.458777617s] Trained 128 records in 0.083394121 seconds. Throughput is 1534.8805 records/second. Loss is 1.1989485. Sequential266afc8b's hyper parameters: Current learning rate is 2.4764735017335313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 24064/60000][Iteration 3940][Wall Clock 375.543275044s] Trained 128 records in 0.084497427 seconds. Throughput is 1514.839 records/second. Loss is 1.1791284. Sequential266afc8b's hyper parameters: Current learning rate is 2.475860361475613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 24192/60000][Iteration 3941][Wall Clock 375.627715177s] Trained 128 records in 0.084440133 seconds. Throughput is 1515.8668 records/second. Loss is 1.2075467. Sequential266afc8b's hyper parameters: Current learning rate is 2.4752475247524753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 24320/60000][Iteration 3942][Wall Clock 375.7132514s] Trained 128 records in 0.085536223 seconds. Throughput is 1496.442 records/second. Loss is 1.148022. Sequential266afc8b's hyper parameters: Current learning rate is 2.4746349913387774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 24448/60000][Iteration 3943][Wall Clock 375.797883002s] Trained 128 records in 0.084631602 seconds. Throughput is 1512.4375 records/second. Loss is 1.1941978. Sequential266afc8b's hyper parameters: Current learning rate is 2.474022761009401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:34 INFO  DistriOptimizer$:408 - [Epoch 9 24576/60000][Iteration 3944][Wall Clock 375.88261478s] Trained 128 records in 0.084731778 seconds. Throughput is 1510.6493 records/second. Loss is 1.240628. Sequential266afc8b's hyper parameters: Current learning rate is 2.473410833539451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 24704/60000][Iteration 3945][Wall Clock 375.977067591s] Trained 128 records in 0.094452811 seconds. Throughput is 1355.1741 records/second. Loss is 1.1165669. Sequential266afc8b's hyper parameters: Current learning rate is 2.4727992087042537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 24832/60000][Iteration 3946][Wall Clock 376.056649331s] Trained 128 records in 0.07958174 seconds. Throughput is 1608.4092 records/second. Loss is 1.2228614. Sequential266afc8b's hyper parameters: Current learning rate is 2.472187886279357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 24960/60000][Iteration 3947][Wall Clock 376.14391586s] Trained 128 records in 0.087266529 seconds. Throughput is 1466.7709 records/second. Loss is 1.1570605. Sequential266afc8b's hyper parameters: Current learning rate is 2.4715768660405336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25088/60000][Iteration 3948][Wall Clock 376.231120602s] Trained 128 records in 0.087204742 seconds. Throughput is 1467.8102 records/second. Loss is 1.1370345. Sequential266afc8b's hyper parameters: Current learning rate is 2.4709661477637757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25216/60000][Iteration 3949][Wall Clock 376.319456535s] Trained 128 records in 0.088335933 seconds. Throughput is 1449.014 records/second. Loss is 1.152604. Sequential266afc8b's hyper parameters: Current learning rate is 2.4703557312252963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25344/60000][Iteration 3950][Wall Clock 376.407828325s] Trained 128 records in 0.08837179 seconds. Throughput is 1448.426 records/second. Loss is 1.1303191. Sequential266afc8b's hyper parameters: Current learning rate is 2.469745616201531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25472/60000][Iteration 3951][Wall Clock 376.492158626s] Trained 128 records in 0.084330301 seconds. Throughput is 1517.8412 records/second. Loss is 1.2610832. Sequential266afc8b's hyper parameters: Current learning rate is 2.469135802469136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25600/60000][Iteration 3952][Wall Clock 376.581632563s] Trained 128 records in 0.089473937 seconds. Throughput is 1430.5841 records/second. Loss is 1.1847034. Sequential266afc8b's hyper parameters: Current learning rate is 2.4685262898049864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25728/60000][Iteration 3953][Wall Clock 376.667038222s] Trained 128 records in 0.085405659 seconds. Throughput is 1498.7296 records/second. Loss is 1.1993351. Sequential266afc8b's hyper parameters: Current learning rate is 2.4679170779861795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25856/60000][Iteration 3954][Wall Clock 376.752777885s] Trained 128 records in 0.085739663 seconds. Throughput is 1492.8914 records/second. Loss is 1.1408594. Sequential266afc8b's hyper parameters: Current learning rate is 2.467308166790032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:35 INFO  DistriOptimizer$:408 - [Epoch 9 25984/60000][Iteration 3955][Wall Clock 376.840424279s] Trained 128 records in 0.087646394 seconds. Throughput is 1460.4137 records/second. Loss is 1.1169813. Sequential266afc8b's hyper parameters: Current learning rate is 2.46669955599408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26112/60000][Iteration 3956][Wall Clock 376.924080214s] Trained 128 records in 0.083655935 seconds. Throughput is 1530.0767 records/second. Loss is 1.2264167. Sequential266afc8b's hyper parameters: Current learning rate is 2.466091245376079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26240/60000][Iteration 3957][Wall Clock 377.007779088s] Trained 128 records in 0.083698874 seconds. Throughput is 1529.2917 records/second. Loss is 1.101688. Sequential266afc8b's hyper parameters: Current learning rate is 2.465483234714004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26368/60000][Iteration 3958][Wall Clock 377.093125363s] Trained 128 records in 0.085346275 seconds. Throughput is 1499.7726 records/second. Loss is 1.0656716. Sequential266afc8b's hyper parameters: Current learning rate is 2.4648755237860487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26496/60000][Iteration 3959][Wall Clock 377.17733434s] Trained 128 records in 0.084208977 seconds. Throughput is 1520.028 records/second. Loss is 1.1145589. Sequential266afc8b's hyper parameters: Current learning rate is 2.464268112370626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26624/60000][Iteration 3960][Wall Clock 377.276144975s] Trained 128 records in 0.098810635 seconds. Throughput is 1295.4071 records/second. Loss is 1.1427627. Sequential266afc8b's hyper parameters: Current learning rate is 2.463661000246366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26752/60000][Iteration 3961][Wall Clock 377.35566872s] Trained 128 records in 0.079523745 seconds. Throughput is 1609.5822 records/second. Loss is 1.1310976. Sequential266afc8b's hyper parameters: Current learning rate is 2.463054187192118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 26880/60000][Iteration 3962][Wall Clock 377.437403382s] Trained 128 records in 0.081734662 seconds. Throughput is 1566.043 records/second. Loss is 1.1849267. Sequential266afc8b's hyper parameters: Current learning rate is 2.462447672986949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 27008/60000][Iteration 3963][Wall Clock 377.521071659s] Trained 128 records in 0.083668277 seconds. Throughput is 1529.8511 records/second. Loss is 1.1678989. Sequential266afc8b's hyper parameters: Current learning rate is 2.461841457410143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 27136/60000][Iteration 3964][Wall Clock 377.607162916s] Trained 128 records in 0.086091257 seconds. Throughput is 1486.7944 records/second. Loss is 1.1404753. Sequential266afc8b's hyper parameters: Current learning rate is 2.461235540241201E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 27264/60000][Iteration 3965][Wall Clock 377.691477713s] Trained 128 records in 0.084314797 seconds. Throughput is 1518.1204 records/second. Loss is 1.0745459. Sequential266afc8b's hyper parameters: Current learning rate is 2.4606299212598425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 27392/60000][Iteration 3966][Wall Clock 377.777629597s] Trained 128 records in 0.086151884 seconds. Throughput is 1485.7482 records/second. Loss is 1.0915915. Sequential266afc8b's hyper parameters: Current learning rate is 2.460024600246003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:36 INFO  DistriOptimizer$:408 - [Epoch 9 27520/60000][Iteration 3967][Wall Clock 377.862840428s] Trained 128 records in 0.085210831 seconds. Throughput is 1502.1565 records/second. Loss is 1.1464778. Sequential266afc8b's hyper parameters: Current learning rate is 2.4594195769798326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 27648/60000][Iteration 3968][Wall Clock 377.948597417s] Trained 128 records in 0.085756989 seconds. Throughput is 1492.5897 records/second. Loss is 1.1654178. Sequential266afc8b's hyper parameters: Current learning rate is 2.4588148512417015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 27776/60000][Iteration 3969][Wall Clock 378.034272217s] Trained 128 records in 0.0856748 seconds. Throughput is 1494.0216 records/second. Loss is 1.0739605. Sequential266afc8b's hyper parameters: Current learning rate is 2.458210422812193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 27904/60000][Iteration 3970][Wall Clock 378.11888754s] Trained 128 records in 0.084615323 seconds. Throughput is 1512.7284 records/second. Loss is 1.202068. Sequential266afc8b's hyper parameters: Current learning rate is 2.4576062914721065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28032/60000][Iteration 3971][Wall Clock 378.204417627s] Trained 128 records in 0.085530087 seconds. Throughput is 1496.5494 records/second. Loss is 1.1100063. Sequential266afc8b's hyper parameters: Current learning rate is 2.457002457002457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28160/60000][Iteration 3972][Wall Clock 378.28175008s] Trained 128 records in 0.077332453 seconds. Throughput is 1655.1913 records/second. Loss is 1.1348157. Sequential266afc8b's hyper parameters: Current learning rate is 2.4563989191844754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28288/60000][Iteration 3973][Wall Clock 378.363128883s] Trained 128 records in 0.081378803 seconds. Throughput is 1572.8911 records/second. Loss is 1.1018032. Sequential266afc8b's hyper parameters: Current learning rate is 2.4557956777996074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28416/60000][Iteration 3974][Wall Clock 378.447977765s] Trained 128 records in 0.084848882 seconds. Throughput is 1508.5643 records/second. Loss is 1.1702687. Sequential266afc8b's hyper parameters: Current learning rate is 2.4551927326295114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28544/60000][Iteration 3975][Wall Clock 378.532637327s] Trained 128 records in 0.084659562 seconds. Throughput is 1511.9379 records/second. Loss is 1.2333329. Sequential266afc8b's hyper parameters: Current learning rate is 2.454590083456063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28672/60000][Iteration 3976][Wall Clock 378.618561275s] Trained 128 records in 0.085923948 seconds. Throughput is 1489.6895 records/second. Loss is 1.0822622. Sequential266afc8b's hyper parameters: Current learning rate is 2.45398773006135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28800/60000][Iteration 3977][Wall Clock 378.701483284s] Trained 128 records in 0.082922009 seconds. Throughput is 1543.6191 records/second. Loss is 1.1311725. Sequential266afc8b's hyper parameters: Current learning rate is 2.4533856722276746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 28928/60000][Iteration 3978][Wall Clock 378.788714459s] Trained 128 records in 0.087231175 seconds. Throughput is 1467.3654 records/second. Loss is 1.1057125. Sequential266afc8b's hyper parameters: Current learning rate is 2.452783909737552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:37 INFO  DistriOptimizer$:408 - [Epoch 9 29056/60000][Iteration 3979][Wall Clock 378.871634214s] Trained 128 records in 0.082919755 seconds. Throughput is 1543.6611 records/second. Loss is 1.2166448. Sequential266afc8b's hyper parameters: Current learning rate is 2.452182442373713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29184/60000][Iteration 3980][Wall Clock 378.956384088s] Trained 128 records in 0.084749874 seconds. Throughput is 1510.3267 records/second. Loss is 1.1703554. Sequential266afc8b's hyper parameters: Current learning rate is 2.451581269919098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29312/60000][Iteration 3981][Wall Clock 379.043962054s] Trained 128 records in 0.087577966 seconds. Throughput is 1461.5548 records/second. Loss is 1.08442. Sequential266afc8b's hyper parameters: Current learning rate is 2.4509803921568627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29440/60000][Iteration 3982][Wall Clock 379.127959746s] Trained 128 records in 0.083997692 seconds. Throughput is 1523.8514 records/second. Loss is 1.1237739. Sequential266afc8b's hyper parameters: Current learning rate is 2.450379808870375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29568/60000][Iteration 3983][Wall Clock 379.211574566s] Trained 128 records in 0.08361482 seconds. Throughput is 1530.8291 records/second. Loss is 1.1206878. Sequential266afc8b's hyper parameters: Current learning rate is 2.449779519843214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29696/60000][Iteration 3984][Wall Clock 379.296039017s] Trained 128 records in 0.084464451 seconds. Throughput is 1515.4304 records/second. Loss is 1.2604588. Sequential266afc8b's hyper parameters: Current learning rate is 2.449179524859172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29824/60000][Iteration 3985][Wall Clock 379.377765701s] Trained 128 records in 0.081726684 seconds. Throughput is 1566.1959 records/second. Loss is 1.13872. Sequential266afc8b's hyper parameters: Current learning rate is 2.448579823702253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 29952/60000][Iteration 3986][Wall Clock 379.466121058s] Trained 128 records in 0.088355357 seconds. Throughput is 1448.6954 records/second. Loss is 1.1078243. Sequential266afc8b's hyper parameters: Current learning rate is 2.447980416156671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 30080/60000][Iteration 3987][Wall Clock 379.549989307s] Trained 128 records in 0.083868249 seconds. Throughput is 1526.2032 records/second. Loss is 1.1105207. Sequential266afc8b's hyper parameters: Current learning rate is 2.447381302006853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 30208/60000][Iteration 3988][Wall Clock 379.638023233s] Trained 128 records in 0.088033926 seconds. Throughput is 1453.9849 records/second. Loss is 1.2292275. Sequential266afc8b's hyper parameters: Current learning rate is 2.446782481037436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 30336/60000][Iteration 3989][Wall Clock 379.721907478s] Trained 128 records in 0.083884245 seconds. Throughput is 1525.9122 records/second. Loss is 1.0775019. Sequential266afc8b's hyper parameters: Current learning rate is 2.446183953033268E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 30464/60000][Iteration 3990][Wall Clock 379.808054381s] Trained 128 records in 0.086146903 seconds. Throughput is 1485.834 records/second. Loss is 1.1057996. Sequential266afc8b's hyper parameters: Current learning rate is 2.4455857177794083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:38 INFO  DistriOptimizer$:408 - [Epoch 9 30592/60000][Iteration 3991][Wall Clock 379.893531033s] Trained 128 records in 0.085476652 seconds. Throughput is 1497.485 records/second. Loss is 1.2076137. Sequential266afc8b's hyper parameters: Current learning rate is 2.444987775061125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 30720/60000][Iteration 3992][Wall Clock 379.977113126s] Trained 128 records in 0.083582093 seconds. Throughput is 1531.4285 records/second. Loss is 1.111528. Sequential266afc8b's hyper parameters: Current learning rate is 2.444390124663896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 30848/60000][Iteration 3993][Wall Clock 380.062351397s] Trained 128 records in 0.085238271 seconds. Throughput is 1501.6729 records/second. Loss is 1.1533056. Sequential266afc8b's hyper parameters: Current learning rate is 2.4437927663734115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 30976/60000][Iteration 3994][Wall Clock 380.14499392s] Trained 128 records in 0.082642523 seconds. Throughput is 1548.8394 records/second. Loss is 1.1374067. Sequential266afc8b's hyper parameters: Current learning rate is 2.443195699975568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31104/60000][Iteration 3995][Wall Clock 380.228139454s] Trained 128 records in 0.083145534 seconds. Throughput is 1539.4692 records/second. Loss is 1.2085114. Sequential266afc8b's hyper parameters: Current learning rate is 2.442598925256473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31232/60000][Iteration 3996][Wall Clock 380.320170181s] Trained 128 records in 0.092030727 seconds. Throughput is 1390.8398 records/second. Loss is 1.2367545. Sequential266afc8b's hyper parameters: Current learning rate is 2.442002442002442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31360/60000][Iteration 3997][Wall Clock 380.401326308s] Trained 128 records in 0.081156127 seconds. Throughput is 1577.2069 records/second. Loss is 1.1471273. Sequential266afc8b's hyper parameters: Current learning rate is 2.44140625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31488/60000][Iteration 3998][Wall Clock 380.4834201s] Trained 128 records in 0.082093792 seconds. Throughput is 1559.1923 records/second. Loss is 1.1490984. Sequential266afc8b's hyper parameters: Current learning rate is 2.44081034903588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31616/60000][Iteration 3999][Wall Clock 380.568584442s] Trained 128 records in 0.085164342 seconds. Throughput is 1502.9766 records/second. Loss is 1.2209995. Sequential266afc8b's hyper parameters: Current learning rate is 2.4402147388970227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31744/60000][Iteration 4000][Wall Clock 380.651266582s] Trained 128 records in 0.08268214 seconds. Throughput is 1548.0973 records/second. Loss is 1.2205833. Sequential266afc8b's hyper parameters: Current learning rate is 2.4396194193705782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 31872/60000][Iteration 4001][Wall Clock 380.73809674s] Trained 128 records in 0.086830158 seconds. Throughput is 1474.1421 records/second. Loss is 1.103265. Sequential266afc8b's hyper parameters: Current learning rate is 2.4390243902439024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:39 INFO  DistriOptimizer$:408 - [Epoch 9 32000/60000][Iteration 4002][Wall Clock 380.824616582s] Trained 128 records in 0.086519842 seconds. Throughput is 1479.4293 records/second. Loss is 1.2876651. Sequential266afc8b's hyper parameters: Current learning rate is 2.43842965130456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32128/60000][Iteration 4003][Wall Clock 380.912131307s] Trained 128 records in 0.087514725 seconds. Throughput is 1462.611 records/second. Loss is 1.1269854. Sequential266afc8b's hyper parameters: Current learning rate is 2.4378352023403217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32256/60000][Iteration 4004][Wall Clock 380.991198285s] Trained 128 records in 0.079066978 seconds. Throughput is 1618.8806 records/second. Loss is 1.1897852. Sequential266afc8b's hyper parameters: Current learning rate is 2.4372410431391665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32384/60000][Iteration 4005][Wall Clock 381.08013084s] Trained 128 records in 0.088932555 seconds. Throughput is 1439.293 records/second. Loss is 1.1354702. Sequential266afc8b's hyper parameters: Current learning rate is 2.436647173489279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32512/60000][Iteration 4006][Wall Clock 381.166120333s] Trained 128 records in 0.085989493 seconds. Throughput is 1488.554 records/second. Loss is 1.1689435. Sequential266afc8b's hyper parameters: Current learning rate is 2.4360535931790498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32640/60000][Iteration 4007][Wall Clock 381.249729476s] Trained 128 records in 0.083609143 seconds. Throughput is 1530.9331 records/second. Loss is 1.1700038. Sequential266afc8b's hyper parameters: Current learning rate is 2.4354603019970773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32768/60000][Iteration 4008][Wall Clock 381.335490071s] Trained 128 records in 0.085760595 seconds. Throughput is 1492.527 records/second. Loss is 1.1251105. Sequential266afc8b's hyper parameters: Current learning rate is 2.4348672997321646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 32896/60000][Iteration 4009][Wall Clock 381.415366091s] Trained 128 records in 0.07987602 seconds. Throughput is 1602.4834 records/second. Loss is 1.1073109. Sequential266afc8b's hyper parameters: Current learning rate is 2.4342745861733204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 33024/60000][Iteration 4010][Wall Clock 381.499168546s] Trained 128 records in 0.083802455 seconds. Throughput is 1527.4016 records/second. Loss is 1.097653. Sequential266afc8b's hyper parameters: Current learning rate is 2.433682161109759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 33152/60000][Iteration 4011][Wall Clock 381.576504632s] Trained 128 records in 0.077336086 seconds. Throughput is 1655.1134 records/second. Loss is 1.1882716. Sequential266afc8b's hyper parameters: Current learning rate is 2.4330900243309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 33280/60000][Iteration 4012][Wall Clock 381.654319853s] Trained 128 records in 0.077815221 seconds. Throughput is 1644.9225 records/second. Loss is 1.1528666. Sequential266afc8b's hyper parameters: Current learning rate is 2.4324981756263683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 33408/60000][Iteration 4013][Wall Clock 381.735300421s] Trained 128 records in 0.080980568 seconds. Throughput is 1580.6261 records/second. Loss is 1.0764796. Sequential266afc8b's hyper parameters: Current learning rate is 2.4319066147859925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:40 INFO  DistriOptimizer$:408 - [Epoch 9 33536/60000][Iteration 4014][Wall Clock 381.818771229s] Trained 128 records in 0.083470808 seconds. Throughput is 1533.4702 records/second. Loss is 1.2577723. Sequential266afc8b's hyper parameters: Current learning rate is 2.4313153415998054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 33664/60000][Iteration 4015][Wall Clock 381.90704962s] Trained 128 records in 0.088278391 seconds. Throughput is 1449.9585 records/second. Loss is 1.1853622. Sequential266afc8b's hyper parameters: Current learning rate is 2.4307243558580456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 33792/60000][Iteration 4016][Wall Clock 381.987835312s] Trained 128 records in 0.080785692 seconds. Throughput is 1584.439 records/second. Loss is 1.0590123. Sequential266afc8b's hyper parameters: Current learning rate is 2.4301336573511544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 33920/60000][Iteration 4017][Wall Clock 382.070883105s] Trained 128 records in 0.083047793 seconds. Throughput is 1541.2811 records/second. Loss is 1.1219049. Sequential266afc8b's hyper parameters: Current learning rate is 2.4295432458697764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34048/60000][Iteration 4018][Wall Clock 382.156343285s] Trained 128 records in 0.08546018 seconds. Throughput is 1497.7736 records/second. Loss is 1.1752988. Sequential266afc8b's hyper parameters: Current learning rate is 2.4289531212047608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34176/60000][Iteration 4019][Wall Clock 382.240240496s] Trained 128 records in 0.083897211 seconds. Throughput is 1525.6765 records/second. Loss is 1.1603181. Sequential266afc8b's hyper parameters: Current learning rate is 2.428363283147159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34304/60000][Iteration 4020][Wall Clock 382.323199558s] Trained 128 records in 0.082959062 seconds. Throughput is 1542.9297 records/second. Loss is 1.1724886. Sequential266afc8b's hyper parameters: Current learning rate is 2.4277737314882256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34432/60000][Iteration 4021][Wall Clock 382.409367632s] Trained 128 records in 0.086168074 seconds. Throughput is 1485.469 records/second. Loss is 1.1667463. Sequential266afc8b's hyper parameters: Current learning rate is 2.4271844660194174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34560/60000][Iteration 4022][Wall Clock 382.506909869s] Trained 128 records in 0.097542237 seconds. Throughput is 1312.2521 records/second. Loss is 1.1900076. Sequential266afc8b's hyper parameters: Current learning rate is 2.426595486532395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34688/60000][Iteration 4023][Wall Clock 382.588764532s] Trained 128 records in 0.081854663 seconds. Throughput is 1563.7472 records/second. Loss is 1.1504958. Sequential266afc8b's hyper parameters: Current learning rate is 2.42600679281902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34816/60000][Iteration 4024][Wall Clock 382.672200709s] Trained 128 records in 0.083436177 seconds. Throughput is 1534.1067 records/second. Loss is 1.2376964. Sequential266afc8b's hyper parameters: Current learning rate is 2.4254183846713557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 34944/60000][Iteration 4025][Wall Clock 382.754933149s] Trained 128 records in 0.08273244 seconds. Throughput is 1547.1561 records/second. Loss is 1.055179. Sequential266afc8b's hyper parameters: Current learning rate is 2.4248302618816683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:41 INFO  DistriOptimizer$:408 - [Epoch 9 35072/60000][Iteration 4026][Wall Clock 382.841212477s] Trained 128 records in 0.086279328 seconds. Throughput is 1483.5536 records/second. Loss is 1.2546449. Sequential266afc8b's hyper parameters: Current learning rate is 2.4242424242424242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35200/60000][Iteration 4027][Wall Clock 382.925956715s] Trained 128 records in 0.084744238 seconds. Throughput is 1510.4272 records/second. Loss is 1.1413184. Sequential266afc8b's hyper parameters: Current learning rate is 2.423654871546292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35328/60000][Iteration 4028][Wall Clock 383.00963662s] Trained 128 records in 0.083679905 seconds. Throughput is 1529.6384 records/second. Loss is 1.1244093. Sequential266afc8b's hyper parameters: Current learning rate is 2.4230676035861398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35456/60000][Iteration 4029][Wall Clock 383.09674477s] Trained 128 records in 0.08710815 seconds. Throughput is 1469.4377 records/second. Loss is 1.2442609. Sequential266afc8b's hyper parameters: Current learning rate is 2.4224806201550387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35584/60000][Iteration 4030][Wall Clock 383.183243197s] Trained 128 records in 0.086498427 seconds. Throughput is 1479.7958 records/second. Loss is 1.1439677. Sequential266afc8b's hyper parameters: Current learning rate is 2.4218939210462584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35712/60000][Iteration 4031][Wall Clock 383.268340961s] Trained 128 records in 0.085097764 seconds. Throughput is 1504.1522 records/second. Loss is 1.1817685. Sequential266afc8b's hyper parameters: Current learning rate is 2.4213075060532685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35840/60000][Iteration 4032][Wall Clock 383.352115013s] Trained 128 records in 0.083774052 seconds. Throughput is 1527.9194 records/second. Loss is 1.1402911. Sequential266afc8b's hyper parameters: Current learning rate is 2.420721374969741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 35968/60000][Iteration 4033][Wall Clock 383.436207349s] Trained 128 records in 0.084092336 seconds. Throughput is 1522.1364 records/second. Loss is 1.1762906. Sequential266afc8b's hyper parameters: Current learning rate is 2.420135527589545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 36096/60000][Iteration 4034][Wall Clock 383.520173595s] Trained 128 records in 0.083966246 seconds. Throughput is 1524.422 records/second. Loss is 1.1866505. Sequential266afc8b's hyper parameters: Current learning rate is 2.4195499637067507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 36224/60000][Iteration 4035][Wall Clock 383.615649069s] Trained 128 records in 0.095475474 seconds. Throughput is 1340.6584 records/second. Loss is 1.1101716. Sequential266afc8b's hyper parameters: Current learning rate is 2.4189646831156264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 36352/60000][Iteration 4036][Wall Clock 383.699184053s] Trained 128 records in 0.083534984 seconds. Throughput is 1532.2921 records/second. Loss is 1.1987278. Sequential266afc8b's hyper parameters: Current learning rate is 2.4183796856106407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 36480/60000][Iteration 4037][Wall Clock 383.781223951s] Trained 128 records in 0.082039898 seconds. Throughput is 1560.2164 records/second. Loss is 1.0783871. Sequential266afc8b's hyper parameters: Current learning rate is 2.4177949709864604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:42 INFO  DistriOptimizer$:408 - [Epoch 9 36608/60000][Iteration 4038][Wall Clock 383.864171476s] Trained 128 records in 0.082947525 seconds. Throughput is 1543.1443 records/second. Loss is 1.2036265. Sequential266afc8b's hyper parameters: Current learning rate is 2.4172105390379503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 36736/60000][Iteration 4039][Wall Clock 383.948412738s] Trained 128 records in 0.084241262 seconds. Throughput is 1519.4454 records/second. Loss is 1.1941662. Sequential266afc8b's hyper parameters: Current learning rate is 2.416626389560174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 36864/60000][Iteration 4040][Wall Clock 384.032882953s] Trained 128 records in 0.084470215 seconds. Throughput is 1515.327 records/second. Loss is 1.0736191. Sequential266afc8b's hyper parameters: Current learning rate is 2.4160425223483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 36992/60000][Iteration 4041][Wall Clock 384.116142075s] Trained 128 records in 0.083259122 seconds. Throughput is 1537.3691 records/second. Loss is 1.0846677. Sequential266afc8b's hyper parameters: Current learning rate is 2.4154589371980678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37120/60000][Iteration 4042][Wall Clock 384.199592977s] Trained 128 records in 0.083450902 seconds. Throughput is 1533.836 records/second. Loss is 1.159023. Sequential266afc8b's hyper parameters: Current learning rate is 2.4148756339048536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37248/60000][Iteration 4043][Wall Clock 384.285107408s] Trained 128 records in 0.085514431 seconds. Throughput is 1496.8234 records/second. Loss is 1.1955462. Sequential266afc8b's hyper parameters: Current learning rate is 2.4142926122646064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37376/60000][Iteration 4044][Wall Clock 384.367387498s] Trained 128 records in 0.08228009 seconds. Throughput is 1555.6619 records/second. Loss is 1.066907. Sequential266afc8b's hyper parameters: Current learning rate is 2.413709872073377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37504/60000][Iteration 4045][Wall Clock 384.451515541s] Trained 128 records in 0.084128043 seconds. Throughput is 1521.4902 records/second. Loss is 1.1800934. Sequential266afc8b's hyper parameters: Current learning rate is 2.4131274131274132E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37632/60000][Iteration 4046][Wall Clock 384.534149294s] Trained 128 records in 0.082633753 seconds. Throughput is 1549.0038 records/second. Loss is 1.1177001. Sequential266afc8b's hyper parameters: Current learning rate is 2.4125452352231604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37760/60000][Iteration 4047][Wall Clock 384.616986121s] Trained 128 records in 0.082836827 seconds. Throughput is 1545.2064 records/second. Loss is 1.2177014. Sequential266afc8b's hyper parameters: Current learning rate is 2.41196333815726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 37888/60000][Iteration 4048][Wall Clock 384.712157326s] Trained 128 records in 0.095171205 seconds. Throughput is 1344.9446 records/second. Loss is 1.1728971. Sequential266afc8b's hyper parameters: Current learning rate is 2.4113817217265494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:43 INFO  DistriOptimizer$:408 - [Epoch 9 38016/60000][Iteration 4049][Wall Clock 384.793796553s] Trained 128 records in 0.081639227 seconds. Throughput is 1567.8737 records/second. Loss is 1.1724807. Sequential266afc8b's hyper parameters: Current learning rate is 2.4108003857280615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38144/60000][Iteration 4050][Wall Clock 384.875140489s] Trained 128 records in 0.081343936 seconds. Throughput is 1573.5654 records/second. Loss is 1.0508751. Sequential266afc8b's hyper parameters: Current learning rate is 2.4102193299590263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38272/60000][Iteration 4051][Wall Clock 384.956004472s] Trained 128 records in 0.080863983 seconds. Throughput is 1582.905 records/second. Loss is 1.0597572. Sequential266afc8b's hyper parameters: Current learning rate is 2.4096385542168676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38400/60000][Iteration 4052][Wall Clock 385.038635223s] Trained 128 records in 0.082630751 seconds. Throughput is 1549.06 records/second. Loss is 1.1577833. Sequential266afc8b's hyper parameters: Current learning rate is 2.4090580582992053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38528/60000][Iteration 4053][Wall Clock 385.128645273s] Trained 128 records in 0.09001005 seconds. Throughput is 1422.0635 records/second. Loss is 1.1676729. Sequential266afc8b's hyper parameters: Current learning rate is 2.4084778420038535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38656/60000][Iteration 4054][Wall Clock 385.214352319s] Trained 128 records in 0.085707046 seconds. Throughput is 1493.4595 records/second. Loss is 1.1327792. Sequential266afc8b's hyper parameters: Current learning rate is 2.4078979051288225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38784/60000][Iteration 4055][Wall Clock 385.296449364s] Trained 128 records in 0.082097045 seconds. Throughput is 1559.1304 records/second. Loss is 1.1737921. Sequential266afc8b's hyper parameters: Current learning rate is 2.407318247472316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 38912/60000][Iteration 4056][Wall Clock 385.378776297s] Trained 128 records in 0.082326933 seconds. Throughput is 1554.7767 records/second. Loss is 1.1387277. Sequential266afc8b's hyper parameters: Current learning rate is 2.4067388688327315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 39040/60000][Iteration 4057][Wall Clock 385.46304085s] Trained 128 records in 0.084264553 seconds. Throughput is 1519.0254 records/second. Loss is 1.2572536. Sequential266afc8b's hyper parameters: Current learning rate is 2.406159769008662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 39168/60000][Iteration 4058][Wall Clock 385.546748859s] Trained 128 records in 0.083708009 seconds. Throughput is 1529.1249 records/second. Loss is 1.2070665. Sequential266afc8b's hyper parameters: Current learning rate is 2.4055809477988935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 39296/60000][Iteration 4059][Wall Clock 385.629606037s] Trained 128 records in 0.082857178 seconds. Throughput is 1544.8269 records/second. Loss is 1.2866881. Sequential266afc8b's hyper parameters: Current learning rate is 2.405002405002405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 39424/60000][Iteration 4060][Wall Clock 385.719240142s] Trained 128 records in 0.089634105 seconds. Throughput is 1428.0278 records/second. Loss is 1.159149. Sequential266afc8b's hyper parameters: Current learning rate is 2.4044241404183698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:44 INFO  DistriOptimizer$:408 - [Epoch 9 39552/60000][Iteration 4061][Wall Clock 385.803299248s] Trained 128 records in 0.084059106 seconds. Throughput is 1522.738 records/second. Loss is 1.1647489. Sequential266afc8b's hyper parameters: Current learning rate is 2.4038461538461537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 39680/60000][Iteration 4062][Wall Clock 385.886734193s] Trained 128 records in 0.083434945 seconds. Throughput is 1534.1294 records/second. Loss is 1.13447. Sequential266afc8b's hyper parameters: Current learning rate is 2.4032684450853162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 39808/60000][Iteration 4063][Wall Clock 385.970321894s] Trained 128 records in 0.083587701 seconds. Throughput is 1531.3258 records/second. Loss is 1.1178135. Sequential266afc8b's hyper parameters: Current learning rate is 2.402691013935608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 39936/60000][Iteration 4064][Wall Clock 386.053661803s] Trained 128 records in 0.083339909 seconds. Throughput is 1535.8788 records/second. Loss is 1.2042644. Sequential266afc8b's hyper parameters: Current learning rate is 2.4021138601969732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40064/60000][Iteration 4065][Wall Clock 386.139009539s] Trained 128 records in 0.085347736 seconds. Throughput is 1499.747 records/second. Loss is 1.170713. Sequential266afc8b's hyper parameters: Current learning rate is 2.4015369836695484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40192/60000][Iteration 4066][Wall Clock 386.222872709s] Trained 128 records in 0.08386317 seconds. Throughput is 1526.2958 records/second. Loss is 1.1157761. Sequential266afc8b's hyper parameters: Current learning rate is 2.4009603841536616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40320/60000][Iteration 4067][Wall Clock 386.304826215s] Trained 128 records in 0.081953506 seconds. Throughput is 1561.8612 records/second. Loss is 1.1443533. Sequential266afc8b's hyper parameters: Current learning rate is 2.4003840614498319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40448/60000][Iteration 4068][Wall Clock 386.390096033s] Trained 128 records in 0.085269818 seconds. Throughput is 1501.1173 records/second. Loss is 1.0434121. Sequential266afc8b's hyper parameters: Current learning rate is 2.3998080153587713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40576/60000][Iteration 4069][Wall Clock 386.474189615s] Trained 128 records in 0.084093582 seconds. Throughput is 1522.1138 records/second. Loss is 1.149726. Sequential266afc8b's hyper parameters: Current learning rate is 2.3992322456813821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40704/60000][Iteration 4070][Wall Clock 386.559441836s] Trained 128 records in 0.085252221 seconds. Throughput is 1501.4272 records/second. Loss is 1.0813836. Sequential266afc8b's hyper parameters: Current learning rate is 2.3986567522187578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40832/60000][Iteration 4071][Wall Clock 386.642793204s] Trained 128 records in 0.083351368 seconds. Throughput is 1535.6677 records/second. Loss is 1.181426. Sequential266afc8b's hyper parameters: Current learning rate is 2.398081534772182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 40960/60000][Iteration 4072][Wall Clock 386.72711416s] Trained 128 records in 0.084320956 seconds. Throughput is 1518.0094 records/second. Loss is 1.1633469. Sequential266afc8b's hyper parameters: Current learning rate is 2.397506593143131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:45 INFO  DistriOptimizer$:408 - [Epoch 9 41088/60000][Iteration 4073][Wall Clock 386.81203617s] Trained 128 records in 0.08492201 seconds. Throughput is 1507.2654 records/second. Loss is 1.0934821. Sequential266afc8b's hyper parameters: Current learning rate is 2.3969319271332696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41216/60000][Iteration 4074][Wall Clock 386.906931026s] Trained 128 records in 0.094894856 seconds. Throughput is 1348.8613 records/second. Loss is 1.0868533. Sequential266afc8b's hyper parameters: Current learning rate is 2.3963575365444523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41344/60000][Iteration 4075][Wall Clock 386.992119851s] Trained 128 records in 0.085188825 seconds. Throughput is 1502.5444 records/second. Loss is 1.2192487. Sequential266afc8b's hyper parameters: Current learning rate is 2.3957834211787253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41472/60000][Iteration 4076][Wall Clock 387.08045763s] Trained 128 records in 0.088337779 seconds. Throughput is 1448.9836 records/second. Loss is 1.1565813. Sequential266afc8b's hyper parameters: Current learning rate is 2.3952095808383233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41600/60000][Iteration 4077][Wall Clock 387.164866725s] Trained 128 records in 0.084409095 seconds. Throughput is 1516.4243 records/second. Loss is 1.1463802. Sequential266afc8b's hyper parameters: Current learning rate is 2.3946360153256706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41728/60000][Iteration 4078][Wall Clock 387.250182056s] Trained 128 records in 0.085315331 seconds. Throughput is 1500.3165 records/second. Loss is 1.134887. Sequential266afc8b's hyper parameters: Current learning rate is 2.3940627244433804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41856/60000][Iteration 4079][Wall Clock 387.335181521s] Trained 128 records in 0.084999465 seconds. Throughput is 1505.8918 records/second. Loss is 1.1439348. Sequential266afc8b's hyper parameters: Current learning rate is 2.3934897079942556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 41984/60000][Iteration 4080][Wall Clock 387.420030669s] Trained 128 records in 0.084849148 seconds. Throughput is 1508.5596 records/second. Loss is 1.2020712. Sequential266afc8b's hyper parameters: Current learning rate is 2.3929169657812874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 42112/60000][Iteration 4081][Wall Clock 387.507410669s] Trained 128 records in 0.08738 seconds. Throughput is 1464.8661 records/second. Loss is 1.1569848. Sequential266afc8b's hyper parameters: Current learning rate is 2.3923444976076553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 42240/60000][Iteration 4082][Wall Clock 387.594394382s] Trained 128 records in 0.086983713 seconds. Throughput is 1471.5399 records/second. Loss is 1.166406. Sequential266afc8b's hyper parameters: Current learning rate is 2.391772303276728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 42368/60000][Iteration 4083][Wall Clock 387.680601783s] Trained 128 records in 0.086207401 seconds. Throughput is 1484.7914 records/second. Loss is 1.1646644. Sequential266afc8b's hyper parameters: Current learning rate is 2.3912003825920613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:46 INFO  DistriOptimizer$:408 - [Epoch 9 42496/60000][Iteration 4084][Wall Clock 387.765663578s] Trained 128 records in 0.085061795 seconds. Throughput is 1504.7883 records/second. Loss is 1.1593912. Sequential266afc8b's hyper parameters: Current learning rate is 2.3906287353573993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 42624/60000][Iteration 4085][Wall Clock 387.858624994s] Trained 128 records in 0.092961416 seconds. Throughput is 1376.9154 records/second. Loss is 1.1698439. Sequential266afc8b's hyper parameters: Current learning rate is 2.390057361376673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 42752/60000][Iteration 4086][Wall Clock 387.945534837s] Trained 128 records in 0.086909843 seconds. Throughput is 1472.7905 records/second. Loss is 1.167636. Sequential266afc8b's hyper parameters: Current learning rate is 2.3894862604540023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 42880/60000][Iteration 4087][Wall Clock 388.027210747s] Trained 128 records in 0.08167591 seconds. Throughput is 1567.1696 records/second. Loss is 1.1988924. Sequential266afc8b's hyper parameters: Current learning rate is 2.3889154323936934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43008/60000][Iteration 4088][Wall Clock 388.10983419s] Trained 128 records in 0.082623443 seconds. Throughput is 1549.1971 records/second. Loss is 1.182352. Sequential266afc8b's hyper parameters: Current learning rate is 2.388344877000239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43136/60000][Iteration 4089][Wall Clock 388.196126822s] Trained 128 records in 0.086292632 seconds. Throughput is 1483.3248 records/second. Loss is 1.1596963. Sequential266afc8b's hyper parameters: Current learning rate is 2.387774594078319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43264/60000][Iteration 4090][Wall Clock 388.282926453s] Trained 128 records in 0.086799631 seconds. Throughput is 1474.6606 records/second. Loss is 1.244124. Sequential266afc8b's hyper parameters: Current learning rate is 2.3872045834328001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43392/60000][Iteration 4091][Wall Clock 388.368363238s] Trained 128 records in 0.085436785 seconds. Throughput is 1498.1837 records/second. Loss is 1.1921792. Sequential266afc8b's hyper parameters: Current learning rate is 2.3866348448687351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43520/60000][Iteration 4092][Wall Clock 388.453568228s] Trained 128 records in 0.08520499 seconds. Throughput is 1502.2594 records/second. Loss is 1.2718312. Sequential266afc8b's hyper parameters: Current learning rate is 2.3860653781913622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43648/60000][Iteration 4093][Wall Clock 388.537801159s] Trained 128 records in 0.084232931 seconds. Throughput is 1519.5957 records/second. Loss is 1.0700854. Sequential266afc8b's hyper parameters: Current learning rate is 2.3854961832061068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43776/60000][Iteration 4094][Wall Clock 388.629137479s] Trained 128 records in 0.09133632 seconds. Throughput is 1401.4141 records/second. Loss is 1.1236584. Sequential266afc8b's hyper parameters: Current learning rate is 2.3849272597185786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 43904/60000][Iteration 4095][Wall Clock 388.71359022s] Trained 128 records in 0.084452741 seconds. Throughput is 1515.6406 records/second. Loss is 1.1374259. Sequential266afc8b's hyper parameters: Current learning rate is 2.3843586075345734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:47 INFO  DistriOptimizer$:408 - [Epoch 9 44032/60000][Iteration 4096][Wall Clock 388.798101474s] Trained 128 records in 0.084511254 seconds. Throughput is 1514.5911 records/second. Loss is 1.1571962. Sequential266afc8b's hyper parameters: Current learning rate is 2.3837902264600713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44160/60000][Iteration 4097][Wall Clock 388.885361274s] Trained 128 records in 0.0872598 seconds. Throughput is 1466.8839 records/second. Loss is 1.2033358. Sequential266afc8b's hyper parameters: Current learning rate is 2.3832221163012392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44288/60000][Iteration 4098][Wall Clock 388.969516494s] Trained 128 records in 0.08415522 seconds. Throughput is 1520.999 records/second. Loss is 1.2696162. Sequential266afc8b's hyper parameters: Current learning rate is 2.3826542768644272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44416/60000][Iteration 4099][Wall Clock 389.055319107s] Trained 128 records in 0.085802613 seconds. Throughput is 1491.796 records/second. Loss is 1.157233. Sequential266afc8b's hyper parameters: Current learning rate is 2.3820867079561695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44544/60000][Iteration 4100][Wall Clock 389.148358671s] Trained 128 records in 0.093039564 seconds. Throughput is 1375.7588 records/second. Loss is 1.1370904. Sequential266afc8b's hyper parameters: Current learning rate is 2.3815194093831864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44672/60000][Iteration 4101][Wall Clock 389.229598255s] Trained 128 records in 0.081239584 seconds. Throughput is 1575.5867 records/second. Loss is 1.1338699. Sequential266afc8b's hyper parameters: Current learning rate is 2.380952380952381E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44800/60000][Iteration 4102][Wall Clock 389.308227294s] Trained 128 records in 0.078629039 seconds. Throughput is 1627.8973 records/second. Loss is 1.0696265. Sequential266afc8b's hyper parameters: Current learning rate is 2.3803856224708406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 44928/60000][Iteration 4103][Wall Clock 389.394558708s] Trained 128 records in 0.086331414 seconds. Throughput is 1482.6584 records/second. Loss is 1.2051222. Sequential266afc8b's hyper parameters: Current learning rate is 2.3798191337458352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 45056/60000][Iteration 4104][Wall Clock 389.479773444s] Trained 128 records in 0.085214736 seconds. Throughput is 1502.0876 records/second. Loss is 1.1410501. Sequential266afc8b's hyper parameters: Current learning rate is 2.3792529145848205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 45184/60000][Iteration 4105][Wall Clock 389.566819156s] Trained 128 records in 0.087045712 seconds. Throughput is 1470.4917 records/second. Loss is 1.1331805. Sequential266afc8b's hyper parameters: Current learning rate is 2.378686964795433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 45312/60000][Iteration 4106][Wall Clock 389.652735996s] Trained 128 records in 0.08591684 seconds. Throughput is 1489.8127 records/second. Loss is 1.0324297. Sequential266afc8b's hyper parameters: Current learning rate is 2.3781212841854932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 45440/60000][Iteration 4107][Wall Clock 389.735849081s] Trained 128 records in 0.083113085 seconds. Throughput is 1540.0704 records/second. Loss is 1.1090447. Sequential266afc8b's hyper parameters: Current learning rate is 2.377555872563005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:48 INFO  DistriOptimizer$:408 - [Epoch 9 45568/60000][Iteration 4108][Wall Clock 389.822350996s] Trained 128 records in 0.086501915 seconds. Throughput is 1479.7361 records/second. Loss is 1.2023271. Sequential266afc8b's hyper parameters: Current learning rate is 2.376990729736154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 45696/60000][Iteration 4109][Wall Clock 389.911415309s] Trained 128 records in 0.089064313 seconds. Throughput is 1437.1637 records/second. Loss is 1.1161134. Sequential266afc8b's hyper parameters: Current learning rate is 2.3764258555133082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 45824/60000][Iteration 4110][Wall Clock 390.004334253s] Trained 128 records in 0.092918944 seconds. Throughput is 1377.5447 records/second. Loss is 1.0852444. Sequential266afc8b's hyper parameters: Current learning rate is 2.375861249703017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 45952/60000][Iteration 4111][Wall Clock 390.08798953s] Trained 128 records in 0.083655277 seconds. Throughput is 1530.0887 records/second. Loss is 1.168873. Sequential266afc8b's hyper parameters: Current learning rate is 2.3752969121140142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46080/60000][Iteration 4112][Wall Clock 390.169475336s] Trained 128 records in 0.081485806 seconds. Throughput is 1570.8257 records/second. Loss is 1.0743917. Sequential266afc8b's hyper parameters: Current learning rate is 2.3747328425552126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46208/60000][Iteration 4113][Wall Clock 390.257281726s] Trained 128 records in 0.08780639 seconds. Throughput is 1457.7527 records/second. Loss is 1.1801295. Sequential266afc8b's hyper parameters: Current learning rate is 2.3741690408357076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46336/60000][Iteration 4114][Wall Clock 390.34320362s] Trained 128 records in 0.085921894 seconds. Throughput is 1489.7251 records/second. Loss is 1.1518341. Sequential266afc8b's hyper parameters: Current learning rate is 2.3736055067647755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46464/60000][Iteration 4115][Wall Clock 390.42688686s] Trained 128 records in 0.08368324 seconds. Throughput is 1529.5775 records/second. Loss is 1.2577087. Sequential266afc8b's hyper parameters: Current learning rate is 2.3730422401518748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46592/60000][Iteration 4116][Wall Clock 390.511818287s] Trained 128 records in 0.084931427 seconds. Throughput is 1507.0983 records/second. Loss is 1.1715451. Sequential266afc8b's hyper parameters: Current learning rate is 2.372479240806643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46720/60000][Iteration 4117][Wall Clock 390.595464383s] Trained 128 records in 0.083646096 seconds. Throughput is 1530.2567 records/second. Loss is 1.0900017. Sequential266afc8b's hyper parameters: Current learning rate is 2.3719165085388992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46848/60000][Iteration 4118][Wall Clock 390.680458838s] Trained 128 records in 0.084994455 seconds. Throughput is 1505.9806 records/second. Loss is 1.1584415. Sequential266afc8b's hyper parameters: Current learning rate is 2.3713540431586434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:49 INFO  DistriOptimizer$:408 - [Epoch 9 46976/60000][Iteration 4119][Wall Clock 390.766569138s] Trained 128 records in 0.0861103 seconds. Throughput is 1486.4656 records/second. Loss is 1.167061. Sequential266afc8b's hyper parameters: Current learning rate is 2.370791844476055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47104/60000][Iteration 4120][Wall Clock 390.849842827s] Trained 128 records in 0.083273689 seconds. Throughput is 1537.1002 records/second. Loss is 1.3029425. Sequential266afc8b's hyper parameters: Current learning rate is 2.3702299123014935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47232/60000][Iteration 4121][Wall Clock 390.934895777s] Trained 128 records in 0.08505295 seconds. Throughput is 1504.9448 records/second. Loss is 1.0687208. Sequential266afc8b's hyper parameters: Current learning rate is 2.3696682464454974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47360/60000][Iteration 4122][Wall Clock 391.018612433s] Trained 128 records in 0.083716656 seconds. Throughput is 1528.967 records/second. Loss is 1.1858039. Sequential266afc8b's hyper parameters: Current learning rate is 2.3691068467187872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47488/60000][Iteration 4123][Wall Clock 391.102442134s] Trained 128 records in 0.083829701 seconds. Throughput is 1526.9052 records/second. Loss is 1.1896688. Sequential266afc8b's hyper parameters: Current learning rate is 2.3685457129322596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47616/60000][Iteration 4124][Wall Clock 391.187000074s] Trained 128 records in 0.08455794 seconds. Throughput is 1513.7549 records/second. Loss is 1.0990222. Sequential266afc8b's hyper parameters: Current learning rate is 2.3679848448969926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47744/60000][Iteration 4125][Wall Clock 391.273045484s] Trained 128 records in 0.08604541 seconds. Throughput is 1487.5867 records/second. Loss is 1.1302456. Sequential266afc8b's hyper parameters: Current learning rate is 2.3674242424242425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 47872/60000][Iteration 4126][Wall Clock 391.369373892s] Trained 128 records in 0.096328408 seconds. Throughput is 1328.7877 records/second. Loss is 1.1474912. Sequential266afc8b's hyper parameters: Current learning rate is 2.3668639053254438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 48000/60000][Iteration 4127][Wall Clock 391.452782735s] Trained 128 records in 0.083408843 seconds. Throughput is 1534.6095 records/second. Loss is 1.0974574. Sequential266afc8b's hyper parameters: Current learning rate is 2.3663038334122103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 48128/60000][Iteration 4128][Wall Clock 391.528652615s] Trained 128 records in 0.07586988 seconds. Throughput is 1687.099 records/second. Loss is 1.0896618. Sequential266afc8b's hyper parameters: Current learning rate is 2.365744026496333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 48256/60000][Iteration 4129][Wall Clock 391.611218946s] Trained 128 records in 0.082566331 seconds. Throughput is 1550.2688 records/second. Loss is 1.096501. Sequential266afc8b's hyper parameters: Current learning rate is 2.3651844843897824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 48384/60000][Iteration 4130][Wall Clock 391.694832861s] Trained 128 records in 0.083613915 seconds. Throughput is 1530.8456 records/second. Loss is 1.1677207. Sequential266afc8b's hyper parameters: Current learning rate is 2.3646252069047056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:50 INFO  DistriOptimizer$:408 - [Epoch 9 48512/60000][Iteration 4131][Wall Clock 391.778296501s] Trained 128 records in 0.08346364 seconds. Throughput is 1533.6019 records/second. Loss is 1.2532351. Sequential266afc8b's hyper parameters: Current learning rate is 2.3640661938534278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 48640/60000][Iteration 4132][Wall Clock 391.863178102s] Trained 128 records in 0.084881601 seconds. Throughput is 1507.9828 records/second. Loss is 1.1163924. Sequential266afc8b's hyper parameters: Current learning rate is 2.3635074450484517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 48768/60000][Iteration 4133][Wall Clock 391.949491939s] Trained 128 records in 0.086313837 seconds. Throughput is 1482.9603 records/second. Loss is 1.1455653. Sequential266afc8b's hyper parameters: Current learning rate is 2.3629489603024575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 48896/60000][Iteration 4134][Wall Clock 392.033964219s] Trained 128 records in 0.08447228 seconds. Throughput is 1515.2899 records/second. Loss is 1.036436. Sequential266afc8b's hyper parameters: Current learning rate is 2.3623907394283017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49024/60000][Iteration 4135][Wall Clock 392.12700203s] Trained 128 records in 0.093037811 seconds. Throughput is 1375.7847 records/second. Loss is 1.0894456. Sequential266afc8b's hyper parameters: Current learning rate is 2.3618327822390173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49152/60000][Iteration 4136][Wall Clock 392.209094944s] Trained 128 records in 0.082092914 seconds. Throughput is 1559.209 records/second. Loss is 1.0986545. Sequential266afc8b's hyper parameters: Current learning rate is 2.361275088547816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49280/60000][Iteration 4137][Wall Clock 392.290743591s] Trained 128 records in 0.081648647 seconds. Throughput is 1567.6929 records/second. Loss is 1.1668594. Sequential266afc8b's hyper parameters: Current learning rate is 2.3607176581680832E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49408/60000][Iteration 4138][Wall Clock 392.375223188s] Trained 128 records in 0.084479597 seconds. Throughput is 1515.1587 records/second. Loss is 0.97998595. Sequential266afc8b's hyper parameters: Current learning rate is 2.3601604909133822E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49536/60000][Iteration 4139][Wall Clock 392.459688342s] Trained 128 records in 0.084465154 seconds. Throughput is 1515.4178 records/second. Loss is 1.111922. Sequential266afc8b's hyper parameters: Current learning rate is 2.3596035865974514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49664/60000][Iteration 4140][Wall Clock 392.543763451s] Trained 128 records in 0.084075109 seconds. Throughput is 1522.4482 records/second. Loss is 1.1894536. Sequential266afc8b's hyper parameters: Current learning rate is 2.3590469450342062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49792/60000][Iteration 4141][Wall Clock 392.629355838s] Trained 128 records in 0.085592387 seconds. Throughput is 1495.4601 records/second. Loss is 1.1310238. Sequential266afc8b's hyper parameters: Current learning rate is 2.358490566037736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 49920/60000][Iteration 4142][Wall Clock 392.713142501s] Trained 128 records in 0.083786663 seconds. Throughput is 1527.6893 records/second. Loss is 1.0796506. Sequential266afc8b's hyper parameters: Current learning rate is 2.3579344494223059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:51 INFO  DistriOptimizer$:408 - [Epoch 9 50048/60000][Iteration 4143][Wall Clock 392.797075905s] Trained 128 records in 0.083933404 seconds. Throughput is 1525.0186 records/second. Loss is 1.1415485. Sequential266afc8b's hyper parameters: Current learning rate is 2.3573785950023574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50176/60000][Iteration 4144][Wall Clock 392.880186011s] Trained 128 records in 0.083110106 seconds. Throughput is 1540.1255 records/second. Loss is 1.1001443. Sequential266afc8b's hyper parameters: Current learning rate is 2.3568230025925054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50304/60000][Iteration 4145][Wall Clock 392.962892994s] Trained 128 records in 0.082706983 seconds. Throughput is 1547.6323 records/second. Loss is 1.1978842. Sequential266afc8b's hyper parameters: Current learning rate is 2.3562676720075403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50432/60000][Iteration 4146][Wall Clock 393.04683049s] Trained 128 records in 0.083937496 seconds. Throughput is 1524.9442 records/second. Loss is 1.1572077. Sequential266afc8b's hyper parameters: Current learning rate is 2.3557126030624264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50560/60000][Iteration 4147][Wall Clock 393.128985125s] Trained 128 records in 0.082154635 seconds. Throughput is 1558.0376 records/second. Loss is 1.1310626. Sequential266afc8b's hyper parameters: Current learning rate is 2.3551577955723034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50688/60000][Iteration 4148][Wall Clock 393.212460988s] Trained 128 records in 0.083475863 seconds. Throughput is 1533.3773 records/second. Loss is 1.068446. Sequential266afc8b's hyper parameters: Current learning rate is 2.354603249352484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50816/60000][Iteration 4149][Wall Clock 393.298653979s] Trained 128 records in 0.086192991 seconds. Throughput is 1485.0396 records/second. Loss is 1.2178214. Sequential266afc8b's hyper parameters: Current learning rate is 2.3540489642184556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 50944/60000][Iteration 4150][Wall Clock 393.382549284s] Trained 128 records in 0.083895305 seconds. Throughput is 1525.7112 records/second. Loss is 1.1147617. Sequential266afc8b's hyper parameters: Current learning rate is 2.353494939985879E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 51072/60000][Iteration 4151][Wall Clock 393.466699111s] Trained 128 records in 0.084149827 seconds. Throughput is 1521.0963 records/second. Loss is 1.0777668. Sequential266afc8b's hyper parameters: Current learning rate is 2.3529411764705883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 51200/60000][Iteration 4152][Wall Clock 393.560415953s] Trained 128 records in 0.093716842 seconds. Throughput is 1365.8164 records/second. Loss is 1.0803046. Sequential266afc8b's hyper parameters: Current learning rate is 2.352387673488591E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 51328/60000][Iteration 4153][Wall Clock 393.638770827s] Trained 128 records in 0.078354874 seconds. Throughput is 1633.5934 records/second. Loss is 1.1544524. Sequential266afc8b's hyper parameters: Current learning rate is 2.3518344308560675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 51456/60000][Iteration 4154][Wall Clock 393.720137768s] Trained 128 records in 0.081366941 seconds. Throughput is 1573.1205 records/second. Loss is 1.1003228. Sequential266afc8b's hyper parameters: Current learning rate is 2.351281448389372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:52 INFO  DistriOptimizer$:408 - [Epoch 9 51584/60000][Iteration 4155][Wall Clock 393.80148621s] Trained 128 records in 0.081348442 seconds. Throughput is 1573.4781 records/second. Loss is 1.0996462. Sequential266afc8b's hyper parameters: Current learning rate is 2.3507287259050307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 51712/60000][Iteration 4156][Wall Clock 393.883296439s] Trained 128 records in 0.081810229 seconds. Throughput is 1564.5966 records/second. Loss is 1.1244515. Sequential266afc8b's hyper parameters: Current learning rate is 2.3501762632197412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 51840/60000][Iteration 4157][Wall Clock 393.96734188s] Trained 128 records in 0.084045441 seconds. Throughput is 1522.9857 records/second. Loss is 1.237277. Sequential266afc8b's hyper parameters: Current learning rate is 2.3496240601503758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 51968/60000][Iteration 4158][Wall Clock 394.050719617s] Trained 128 records in 0.083377737 seconds. Throughput is 1535.182 records/second. Loss is 1.1524187. Sequential266afc8b's hyper parameters: Current learning rate is 2.349072116513977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52096/60000][Iteration 4159][Wall Clock 394.135527005s] Trained 128 records in 0.084807388 seconds. Throughput is 1509.3025 records/second. Loss is 1.1020201. Sequential266afc8b's hyper parameters: Current learning rate is 2.3485204321277596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52224/60000][Iteration 4160][Wall Clock 394.220067026s] Trained 128 records in 0.084540021 seconds. Throughput is 1514.0757 records/second. Loss is 1.1472783. Sequential266afc8b's hyper parameters: Current learning rate is 2.34796900680911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52352/60000][Iteration 4161][Wall Clock 394.308484097s] Trained 128 records in 0.088417071 seconds. Throughput is 1447.6843 records/second. Loss is 1.0986632. Sequential266afc8b's hyper parameters: Current learning rate is 2.3474178403755868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52480/60000][Iteration 4162][Wall Clock 394.391650507s] Trained 128 records in 0.08316641 seconds. Throughput is 1539.0829 records/second. Loss is 1.1430397. Sequential266afc8b's hyper parameters: Current learning rate is 2.346866932644919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52608/60000][Iteration 4163][Wall Clock 394.475116968s] Trained 128 records in 0.083466461 seconds. Throughput is 1533.55 records/second. Loss is 1.0695803. Sequential266afc8b's hyper parameters: Current learning rate is 2.3463162834350072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52736/60000][Iteration 4164][Wall Clock 394.560280333s] Trained 128 records in 0.085163365 seconds. Throughput is 1502.9938 records/second. Loss is 1.1420312. Sequential266afc8b's hyper parameters: Current learning rate is 2.345765892563922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52864/60000][Iteration 4165][Wall Clock 394.641971484s] Trained 128 records in 0.081691151 seconds. Throughput is 1566.8771 records/second. Loss is 1.1895789. Sequential266afc8b's hyper parameters: Current learning rate is 2.3452157598499062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:53 INFO  DistriOptimizer$:408 - [Epoch 9 52992/60000][Iteration 4166][Wall Clock 394.729970967s] Trained 128 records in 0.087999483 seconds. Throughput is 1454.554 records/second. Loss is 1.1632184. Sequential266afc8b's hyper parameters: Current learning rate is 2.3446658851113716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53120/60000][Iteration 4167][Wall Clock 394.816333021s] Trained 128 records in 0.086362054 seconds. Throughput is 1482.1323 records/second. Loss is 1.0754666. Sequential266afc8b's hyper parameters: Current learning rate is 2.344116268166901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53248/60000][Iteration 4168][Wall Clock 394.902361801s] Trained 128 records in 0.08602878 seconds. Throughput is 1487.8743 records/second. Loss is 1.1492927. Sequential266afc8b's hyper parameters: Current learning rate is 2.3435669088352472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53376/60000][Iteration 4169][Wall Clock 394.989339502s] Trained 128 records in 0.086977701 seconds. Throughput is 1471.6416 records/second. Loss is 1.0994556. Sequential266afc8b's hyper parameters: Current learning rate is 2.3430178069353328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53504/60000][Iteration 4170][Wall Clock 395.075607207s] Trained 128 records in 0.086267705 seconds. Throughput is 1483.7534 records/second. Loss is 1.1864126. Sequential266afc8b's hyper parameters: Current learning rate is 2.34246896228625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53632/60000][Iteration 4171][Wall Clock 395.160838064s] Trained 128 records in 0.085230857 seconds. Throughput is 1501.8035 records/second. Loss is 1.16491. Sequential266afc8b's hyper parameters: Current learning rate is 2.34192037470726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53760/60000][Iteration 4172][Wall Clock 395.246306632s] Trained 128 records in 0.085468568 seconds. Throughput is 1497.6266 records/second. Loss is 1.1652377. Sequential266afc8b's hyper parameters: Current learning rate is 2.3413720440177945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 53888/60000][Iteration 4173][Wall Clock 395.333102442s] Trained 128 records in 0.08679581 seconds. Throughput is 1474.7256 records/second. Loss is 1.1913189. Sequential266afc8b's hyper parameters: Current learning rate is 2.3408239700374532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 54016/60000][Iteration 4174][Wall Clock 395.415833923s] Trained 128 records in 0.082731481 seconds. Throughput is 1547.1741 records/second. Loss is 1.1680263. Sequential266afc8b's hyper parameters: Current learning rate is 2.340276152586005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 54144/60000][Iteration 4175][Wall Clock 395.49711192s] Trained 128 records in 0.081277997 seconds. Throughput is 1574.8419 records/second. Loss is 1.194582. Sequential266afc8b's hyper parameters: Current learning rate is 2.3397285914833878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 54272/60000][Iteration 4176][Wall Clock 395.586659976s] Trained 128 records in 0.089548056 seconds. Throughput is 1429.4 records/second. Loss is 1.2471962. Sequential266afc8b's hyper parameters: Current learning rate is 2.3391812865497077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 54400/60000][Iteration 4177][Wall Clock 395.674811614s] Trained 128 records in 0.088151638 seconds. Throughput is 1452.0433 records/second. Loss is 1.2338383. Sequential266afc8b's hyper parameters: Current learning rate is 2.3386342376052386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:54 INFO  DistriOptimizer$:408 - [Epoch 9 54528/60000][Iteration 4178][Wall Clock 395.767207346s] Trained 128 records in 0.092395732 seconds. Throughput is 1385.3455 records/second. Loss is 1.1272835. Sequential266afc8b's hyper parameters: Current learning rate is 2.338087444470423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 54656/60000][Iteration 4179][Wall Clock 395.854270855s] Trained 128 records in 0.087063509 seconds. Throughput is 1470.1912 records/second. Loss is 1.1899687. Sequential266afc8b's hyper parameters: Current learning rate is 2.337540906965872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 54784/60000][Iteration 4180][Wall Clock 395.938364817s] Trained 128 records in 0.084093962 seconds. Throughput is 1522.1068 records/second. Loss is 1.1852666. Sequential266afc8b's hyper parameters: Current learning rate is 2.3369946249123628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 54912/60000][Iteration 4181][Wall Clock 396.025334148s] Trained 128 records in 0.086969331 seconds. Throughput is 1471.7832 records/second. Loss is 1.1280769. Sequential266afc8b's hyper parameters: Current learning rate is 2.336448598130841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55040/60000][Iteration 4182][Wall Clock 396.105125144s] Trained 128 records in 0.079790996 seconds. Throughput is 1604.191 records/second. Loss is 1.186937. Sequential266afc8b's hyper parameters: Current learning rate is 2.33590282644242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55168/60000][Iteration 4183][Wall Clock 396.189840622s] Trained 128 records in 0.084715478 seconds. Throughput is 1510.94 records/second. Loss is 1.2308891. Sequential266afc8b's hyper parameters: Current learning rate is 2.3353573096683794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55296/60000][Iteration 4184][Wall Clock 396.276161748s] Trained 128 records in 0.086321126 seconds. Throughput is 1482.8352 records/second. Loss is 1.2163132. Sequential266afc8b's hyper parameters: Current learning rate is 2.3348120476301658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55424/60000][Iteration 4185][Wall Clock 396.358470226s] Trained 128 records in 0.082308478 seconds. Throughput is 1555.1254 records/second. Loss is 1.1376272. Sequential266afc8b's hyper parameters: Current learning rate is 2.334267040149393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55552/60000][Iteration 4186][Wall Clock 396.453234946s] Trained 128 records in 0.09476472 seconds. Throughput is 1350.7137 records/second. Loss is 1.178071. Sequential266afc8b's hyper parameters: Current learning rate is 2.3337222870478412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55680/60000][Iteration 4187][Wall Clock 396.533753252s] Trained 128 records in 0.080518306 seconds. Throughput is 1589.7006 records/second. Loss is 1.1552016. Sequential266afc8b's hyper parameters: Current learning rate is 2.333177788147457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55808/60000][Iteration 4188][Wall Clock 396.615477286s] Trained 128 records in 0.081724034 seconds. Throughput is 1566.2467 records/second. Loss is 1.1738101. Sequential266afc8b's hyper parameters: Current learning rate is 2.3326335432703523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 55936/60000][Iteration 4189][Wall Clock 396.69992174s] Trained 128 records in 0.084444454 seconds. Throughput is 1515.7893 records/second. Loss is 1.1242154. Sequential266afc8b's hyper parameters: Current learning rate is 2.332089552238806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:55 INFO  DistriOptimizer$:408 - [Epoch 9 56064/60000][Iteration 4190][Wall Clock 396.783743833s] Trained 128 records in 0.083822093 seconds. Throughput is 1527.0437 records/second. Loss is 1.1159881. Sequential266afc8b's hyper parameters: Current learning rate is 2.3315458148752622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56192/60000][Iteration 4191][Wall Clock 396.869642194s] Trained 128 records in 0.085898361 seconds. Throughput is 1490.1332 records/second. Loss is 1.1246467. Sequential266afc8b's hyper parameters: Current learning rate is 2.331002331002331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56320/60000][Iteration 4192][Wall Clock 396.953417765s] Trained 128 records in 0.083775571 seconds. Throughput is 1527.8917 records/second. Loss is 1.1475683. Sequential266afc8b's hyper parameters: Current learning rate is 2.330459100442787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56448/60000][Iteration 4193][Wall Clock 397.042994223s] Trained 128 records in 0.089576458 seconds. Throughput is 1428.9469 records/second. Loss is 1.1927786. Sequential266afc8b's hyper parameters: Current learning rate is 2.3299161230195712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56576/60000][Iteration 4194][Wall Clock 397.127773926s] Trained 128 records in 0.084779703 seconds. Throughput is 1509.7954 records/second. Loss is 1.0109885. Sequential266afc8b's hyper parameters: Current learning rate is 2.3293733985557886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56704/60000][Iteration 4195][Wall Clock 397.211665162s] Trained 128 records in 0.083891236 seconds. Throughput is 1525.7852 records/second. Loss is 1.2003373. Sequential266afc8b's hyper parameters: Current learning rate is 2.328830926874709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56832/60000][Iteration 4196][Wall Clock 397.294761652s] Trained 128 records in 0.08309649 seconds. Throughput is 1540.3779 records/second. Loss is 1.2069379. Sequential266afc8b's hyper parameters: Current learning rate is 2.3282887077997672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 56960/60000][Iteration 4197][Wall Clock 397.378717011s] Trained 128 records in 0.083955359 seconds. Throughput is 1524.6198 records/second. Loss is 1.1544557. Sequential266afc8b's hyper parameters: Current learning rate is 2.3277467411545624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 57088/60000][Iteration 4198][Wall Clock 397.46177134s] Trained 128 records in 0.083054329 seconds. Throughput is 1541.1599 records/second. Loss is 1.2293538. Sequential266afc8b's hyper parameters: Current learning rate is 2.327205026762858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 57216/60000][Iteration 4199][Wall Clock 397.549703707s] Trained 128 records in 0.087932367 seconds. Throughput is 1455.6642 records/second. Loss is 1.2431716. Sequential266afc8b's hyper parameters: Current learning rate is 2.3266635644485806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 57344/60000][Iteration 4200][Wall Clock 397.632645266s] Trained 128 records in 0.082941559 seconds. Throughput is 1543.2552 records/second. Loss is 1.1177497. Sequential266afc8b's hyper parameters: Current learning rate is 2.3261223540358222E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:56 INFO  DistriOptimizer$:408 - [Epoch 9 57472/60000][Iteration 4201][Wall Clock 397.718443312s] Trained 128 records in 0.085798046 seconds. Throughput is 1491.8755 records/second. Loss is 1.19769. Sequential266afc8b's hyper parameters: Current learning rate is 2.3255813953488373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 57600/60000][Iteration 4202][Wall Clock 397.803311066s] Trained 128 records in 0.084867754 seconds. Throughput is 1508.2289 records/second. Loss is 1.1444318. Sequential266afc8b's hyper parameters: Current learning rate is 2.325040688212044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 57728/60000][Iteration 4203][Wall Clock 397.888872715s] Trained 128 records in 0.085561649 seconds. Throughput is 1495.9973 records/second. Loss is 1.1631892. Sequential266afc8b's hyper parameters: Current learning rate is 2.3245002324500232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 57856/60000][Iteration 4204][Wall Clock 397.980860417s] Trained 128 records in 0.091987702 seconds. Throughput is 1391.4904 records/second. Loss is 1.201452. Sequential266afc8b's hyper parameters: Current learning rate is 2.3239600278875203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 57984/60000][Iteration 4205][Wall Clock 398.065886992s] Trained 128 records in 0.085026575 seconds. Throughput is 1505.4116 records/second. Loss is 1.2274528. Sequential266afc8b's hyper parameters: Current learning rate is 2.3234200743494425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 58112/60000][Iteration 4206][Wall Clock 398.156616894s] Trained 128 records in 0.090729902 seconds. Throughput is 1410.7808 records/second. Loss is 1.174372. Sequential266afc8b's hyper parameters: Current learning rate is 2.3228803716608592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 58240/60000][Iteration 4207][Wall Clock 398.241293762s] Trained 128 records in 0.084676868 seconds. Throughput is 1511.6289 records/second. Loss is 1.14158. Sequential266afc8b's hyper parameters: Current learning rate is 2.3223409196470042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 58368/60000][Iteration 4208][Wall Clock 398.355293397s] Trained 128 records in 0.113999635 seconds. Throughput is 1122.8107 records/second. Loss is 1.153349. Sequential266afc8b's hyper parameters: Current learning rate is 2.3218017181332715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 58496/60000][Iteration 4209][Wall Clock 398.460570623s] Trained 128 records in 0.105277226 seconds. Throughput is 1215.8375 records/second. Loss is 1.2250459. Sequential266afc8b's hyper parameters: Current learning rate is 2.3212627669452182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 58624/60000][Iteration 4210][Wall Clock 398.568838972s] Trained 128 records in 0.108268349 seconds. Throughput is 1182.2477 records/second. Loss is 1.1587465. Sequential266afc8b's hyper parameters: Current learning rate is 2.3207240659085633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:57 INFO  DistriOptimizer$:408 - [Epoch 9 58752/60000][Iteration 4211][Wall Clock 398.678139462s] Trained 128 records in 0.10930049 seconds. Throughput is 1171.0835 records/second. Loss is 1.126469. Sequential266afc8b's hyper parameters: Current learning rate is 2.320185614849188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 58880/60000][Iteration 4212][Wall Clock 398.8113875s] Trained 128 records in 0.133248038 seconds. Throughput is 960.61456 records/second. Loss is 1.1716454. Sequential266afc8b's hyper parameters: Current learning rate is 2.3196474135931338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59008/60000][Iteration 4213][Wall Clock 398.916418359s] Trained 128 records in 0.105030859 seconds. Throughput is 1218.6895 records/second. Loss is 1.0856092. Sequential266afc8b's hyper parameters: Current learning rate is 2.319109461966605E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59136/60000][Iteration 4214][Wall Clock 399.002740582s] Trained 128 records in 0.086322223 seconds. Throughput is 1482.8163 records/second. Loss is 1.1471648. Sequential266afc8b's hyper parameters: Current learning rate is 2.3185717597959656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59264/60000][Iteration 4215][Wall Clock 399.088736713s] Trained 128 records in 0.085996131 seconds. Throughput is 1488.4391 records/second. Loss is 1.1624756. Sequential266afc8b's hyper parameters: Current learning rate is 2.318034306907742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59392/60000][Iteration 4216][Wall Clock 399.174121314s] Trained 128 records in 0.085384601 seconds. Throughput is 1499.0994 records/second. Loss is 1.1554532. Sequential266afc8b's hyper parameters: Current learning rate is 2.317497103128621E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59520/60000][Iteration 4217][Wall Clock 399.259803531s] Trained 128 records in 0.085682217 seconds. Throughput is 1493.8923 records/second. Loss is 1.1436207. Sequential266afc8b's hyper parameters: Current learning rate is 2.3169601482854493E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59648/60000][Iteration 4218][Wall Clock 399.345820554s] Trained 128 records in 0.086017023 seconds. Throughput is 1488.0776 records/second. Loss is 1.1191564. Sequential266afc8b's hyper parameters: Current learning rate is 2.316423442205235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59776/60000][Iteration 4219][Wall Clock 399.433760605s] Trained 128 records in 0.087940051 seconds. Throughput is 1455.537 records/second. Loss is 1.129458. Sequential266afc8b's hyper parameters: Current learning rate is 2.315886984715146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 59904/60000][Iteration 4220][Wall Clock 399.518421977s] Trained 128 records in 0.084661372 seconds. Throughput is 1511.9055 records/second. Loss is 1.1105063. Sequential266afc8b's hyper parameters: Current learning rate is 2.31535077564251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:408 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 399.601232297s] Trained 128 records in 0.08281032 seconds. Throughput is 1545.701 records/second. Loss is 1.1906024. Sequential266afc8b's hyper parameters: Current learning rate is 2.3148148148148146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:58 INFO  DistriOptimizer$:452 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 399.601232297s] Epoch finished. Wall clock time is 400735.325291 ms
2019-10-15 08:24:58 INFO  DistriOptimizer$:111 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 399.601232297s] Validate model...
2019-10-15 08:24:59 INFO  DistriOptimizer$:178 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 399.601232297s] validate model throughput is 12224.033 records/second
2019-10-15 08:24:59 INFO  DistriOptimizer$:181 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 399.601232297s] Top1Accuracy is Accuracy(correct: 7538, count: 10000, accuracy: 0.7538)
2019-10-15 08:24:59 INFO  DistriOptimizer$:221 - [Wall Clock 400.735325291s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:24:59 INFO  DistriOptimizer$:226 - [Wall Clock 400.735325291s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
2019-10-15 08:24:59 INFO  DistriOptimizer$:408 - [Epoch 10 128/60000][Iteration 4222][Wall Clock 400.830612416s] Trained 128 records in 0.095287125 seconds. Throughput is 1343.3085 records/second. Loss is 1.1418233. Sequential266afc8b's hyper parameters: Current learning rate is 2.3142791020597085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:59 INFO  DistriOptimizer$:408 - [Epoch 10 256/60000][Iteration 4223][Wall Clock 400.91549864s] Trained 128 records in 0.084886224 seconds. Throughput is 1507.9008 records/second. Loss is 1.1029639. Sequential266afc8b's hyper parameters: Current learning rate is 2.3137436372049977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:24:59 INFO  DistriOptimizer$:408 - [Epoch 10 384/60000][Iteration 4224][Wall Clock 401.007986912s] Trained 128 records in 0.092488272 seconds. Throughput is 1383.9592 records/second. Loss is 1.116469. Sequential266afc8b's hyper parameters: Current learning rate is 2.3132084200786488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 512/60000][Iteration 4225][Wall Clock 401.10725073s] Trained 128 records in 0.099263818 seconds. Throughput is 1289.493 records/second. Loss is 1.0987384. Sequential266afc8b's hyper parameters: Current learning rate is 2.312673450508788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 640/60000][Iteration 4226][Wall Clock 401.192337076s] Trained 128 records in 0.085086346 seconds. Throughput is 1504.3541 records/second. Loss is 1.1103108. Sequential266afc8b's hyper parameters: Current learning rate is 2.3121387283236994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 768/60000][Iteration 4227][Wall Clock 401.280676436s] Trained 128 records in 0.08833936 seconds. Throughput is 1448.9578 records/second. Loss is 1.2260377. Sequential266afc8b's hyper parameters: Current learning rate is 2.3116042533518263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 896/60000][Iteration 4228][Wall Clock 401.384124118s] Trained 128 records in 0.103447682 seconds. Throughput is 1237.3405 records/second. Loss is 1.1417357. Sequential266afc8b's hyper parameters: Current learning rate is 2.31107002542177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1024/60000][Iteration 4229][Wall Clock 401.465783868s] Trained 128 records in 0.08165975 seconds. Throughput is 1567.4797 records/second. Loss is 1.0711999. Sequential266afc8b's hyper parameters: Current learning rate is 2.310536044362292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1152/60000][Iteration 4230][Wall Clock 401.547654146s] Trained 128 records in 0.081870278 seconds. Throughput is 1563.4489 records/second. Loss is 1.067426. Sequential266afc8b's hyper parameters: Current learning rate is 2.3100023100023102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1280/60000][Iteration 4231][Wall Clock 401.632155295s] Trained 128 records in 0.084501149 seconds. Throughput is 1514.7723 records/second. Loss is 1.1644493. Sequential266afc8b's hyper parameters: Current learning rate is 2.3094688221709004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1408/60000][Iteration 4232][Wall Clock 401.716863799s] Trained 128 records in 0.084708504 seconds. Throughput is 1511.0643 records/second. Loss is 1.1697636. Sequential266afc8b's hyper parameters: Current learning rate is 2.3089355806972986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1536/60000][Iteration 4233][Wall Clock 401.802421462s] Trained 128 records in 0.085557663 seconds. Throughput is 1496.067 records/second. Loss is 1.1437203. Sequential266afc8b's hyper parameters: Current learning rate is 2.3084025854108956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1664/60000][Iteration 4234][Wall Clock 401.885241608s] Trained 128 records in 0.082820146 seconds. Throughput is 1545.5177 records/second. Loss is 1.0977591. Sequential266afc8b's hyper parameters: Current learning rate is 2.3078698361412417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:00 INFO  DistriOptimizer$:408 - [Epoch 10 1792/60000][Iteration 4235][Wall Clock 401.969419904s] Trained 128 records in 0.084178296 seconds. Throughput is 1520.5819 records/second. Loss is 1.1155401. Sequential266afc8b's hyper parameters: Current learning rate is 2.3073373327180433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 1920/60000][Iteration 4236][Wall Clock 402.059820833s] Trained 128 records in 0.090400929 seconds. Throughput is 1415.9147 records/second. Loss is 1.2453669. Sequential266afc8b's hyper parameters: Current learning rate is 2.306805074971165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2048/60000][Iteration 4237][Wall Clock 402.137705059s] Trained 128 records in 0.077884226 seconds. Throughput is 1643.465 records/second. Loss is 1.1546501. Sequential266afc8b's hyper parameters: Current learning rate is 2.3062730627306275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2176/60000][Iteration 4238][Wall Clock 402.226390727s] Trained 128 records in 0.088685668 seconds. Throughput is 1443.2997 records/second. Loss is 1.2259108. Sequential266afc8b's hyper parameters: Current learning rate is 2.3057412958266084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2304/60000][Iteration 4239][Wall Clock 402.316521104s] Trained 128 records in 0.090130377 seconds. Throughput is 1420.1649 records/second. Loss is 1.1088963. Sequential266afc8b's hyper parameters: Current learning rate is 2.305209774089442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2432/60000][Iteration 4240][Wall Clock 402.400315123s] Trained 128 records in 0.083794019 seconds. Throughput is 1527.5553 records/second. Loss is 1.0697937. Sequential266afc8b's hyper parameters: Current learning rate is 2.30467849734962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2560/60000][Iteration 4241][Wall Clock 402.484373741s] Trained 128 records in 0.084058618 seconds. Throughput is 1522.7468 records/second. Loss is 1.1164441. Sequential266afc8b's hyper parameters: Current learning rate is 2.304147465437788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2688/60000][Iteration 4242][Wall Clock 402.568975384s] Trained 128 records in 0.084601643 seconds. Throughput is 1512.973 records/second. Loss is 1.2496653. Sequential266afc8b's hyper parameters: Current learning rate is 2.30361667818475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2816/60000][Iteration 4243][Wall Clock 402.654503779s] Trained 128 records in 0.085528395 seconds. Throughput is 1496.579 records/second. Loss is 1.1795697. Sequential266afc8b's hyper parameters: Current learning rate is 2.3030861354214648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 2944/60000][Iteration 4244][Wall Clock 402.742125844s] Trained 128 records in 0.087622065 seconds. Throughput is 1460.8193 records/second. Loss is 1.093385. Sequential266afc8b's hyper parameters: Current learning rate is 2.302555836979047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 3072/60000][Iteration 4245][Wall Clock 402.830761298s] Trained 128 records in 0.088635454 seconds. Throughput is 1444.1174 records/second. Loss is 1.092226. Sequential266afc8b's hyper parameters: Current learning rate is 2.3020257826887662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 3200/60000][Iteration 4246][Wall Clock 402.917637324s] Trained 128 records in 0.086876026 seconds. Throughput is 1473.3639 records/second. Loss is 1.1125427. Sequential266afc8b's hyper parameters: Current learning rate is 2.3014959723820482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:01 INFO  DistriOptimizer$:408 - [Epoch 10 3328/60000][Iteration 4247][Wall Clock 403.00065822s] Trained 128 records in 0.083020896 seconds. Throughput is 1541.7805 records/second. Loss is 1.1623077. Sequential266afc8b's hyper parameters: Current learning rate is 2.300966405890474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 3456/60000][Iteration 4248][Wall Clock 403.087965405s] Trained 128 records in 0.087307185 seconds. Throughput is 1466.0878 records/second. Loss is 1.1120313. Sequential266afc8b's hyper parameters: Current learning rate is 2.300437083045779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 3584/60000][Iteration 4249][Wall Clock 403.171842709s] Trained 128 records in 0.083877304 seconds. Throughput is 1526.0386 records/second. Loss is 1.107791. Sequential266afc8b's hyper parameters: Current learning rate is 2.2999080036798525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 3712/60000][Iteration 4250][Wall Clock 403.255780242s] Trained 128 records in 0.083937533 seconds. Throughput is 1524.9436 records/second. Loss is 1.1441028. Sequential266afc8b's hyper parameters: Current learning rate is 2.2993791676247414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 3840/60000][Iteration 4251][Wall Clock 403.339281644s] Trained 128 records in 0.083501402 seconds. Throughput is 1532.9084 records/second. Loss is 1.0900265. Sequential266afc8b's hyper parameters: Current learning rate is 2.2988505747126436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 3968/60000][Iteration 4252][Wall Clock 403.42693912s] Trained 128 records in 0.087657476 seconds. Throughput is 1460.2291 records/second. Loss is 1.1684735. Sequential266afc8b's hyper parameters: Current learning rate is 2.2983222247759138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 4096/60000][Iteration 4253][Wall Clock 403.509302144s] Trained 128 records in 0.082363024 seconds. Throughput is 1554.0955 records/second. Loss is 1.1707506. Sequential266afc8b's hyper parameters: Current learning rate is 2.2977941176470588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 4224/60000][Iteration 4254][Wall Clock 403.603005925s] Trained 128 records in 0.093703781 seconds. Throughput is 1366.0067 records/second. Loss is 1.1024145. Sequential266afc8b's hyper parameters: Current learning rate is 2.2972662531587412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 4352/60000][Iteration 4255][Wall Clock 403.68491295s] Trained 128 records in 0.081907025 seconds. Throughput is 1562.7474 records/second. Loss is 1.164668. Sequential266afc8b's hyper parameters: Current learning rate is 2.2967386311437759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 4480/60000][Iteration 4256][Wall Clock 403.766057314s] Trained 128 records in 0.081144364 seconds. Throughput is 1577.4355 records/second. Loss is 1.2664161. Sequential266afc8b's hyper parameters: Current learning rate is 2.2962112514351318E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 4608/60000][Iteration 4257][Wall Clock 403.848384184s] Trained 128 records in 0.08232687 seconds. Throughput is 1554.778 records/second. Loss is 1.0670019. Sequential266afc8b's hyper parameters: Current learning rate is 2.295684113865932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:02 INFO  DistriOptimizer$:408 - [Epoch 10 4736/60000][Iteration 4258][Wall Clock 403.934709678s] Trained 128 records in 0.086325494 seconds. Throughput is 1482.7601 records/second. Loss is 1.1217222. Sequential266afc8b's hyper parameters: Current learning rate is 2.2951572182694515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 4864/60000][Iteration 4259][Wall Clock 404.018730637s] Trained 128 records in 0.084020959 seconds. Throughput is 1523.4294 records/second. Loss is 1.0557584. Sequential266afc8b's hyper parameters: Current learning rate is 2.294630564479119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 4992/60000][Iteration 4260][Wall Clock 404.103083654s] Trained 128 records in 0.084353017 seconds. Throughput is 1517.4324 records/second. Loss is 1.213486. Sequential266afc8b's hyper parameters: Current learning rate is 2.2941041523285156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5120/60000][Iteration 4261][Wall Clock 404.190294225s] Trained 128 records in 0.087210571 seconds. Throughput is 1467.7119 records/second. Loss is 1.1723844. Sequential266afc8b's hyper parameters: Current learning rate is 2.293577981651376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5248/60000][Iteration 4262][Wall Clock 404.277661658s] Trained 128 records in 0.087367433 seconds. Throughput is 1465.0769 records/second. Loss is 1.1665767. Sequential266afc8b's hyper parameters: Current learning rate is 2.293052052281587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5376/60000][Iteration 4263][Wall Clock 404.36048746s] Trained 128 records in 0.082825802 seconds. Throughput is 1545.4121 records/second. Loss is 1.1106825. Sequential266afc8b's hyper parameters: Current learning rate is 2.2925263640531868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5504/60000][Iteration 4264][Wall Clock 404.445905791s] Trained 128 records in 0.085418331 seconds. Throughput is 1498.5074 records/second. Loss is 1.1227412. Sequential266afc8b's hyper parameters: Current learning rate is 2.2920009168003665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5632/60000][Iteration 4265][Wall Clock 404.528810985s] Trained 128 records in 0.082905194 seconds. Throughput is 1543.9321 records/second. Loss is 1.0874211. Sequential266afc8b's hyper parameters: Current learning rate is 2.2914757103574703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5760/60000][Iteration 4266][Wall Clock 404.613558632s] Trained 128 records in 0.084747647 seconds. Throughput is 1510.3663 records/second. Loss is 1.0889022. Sequential266afc8b's hyper parameters: Current learning rate is 2.290950744558992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 5888/60000][Iteration 4267][Wall Clock 404.699072739s] Trained 128 records in 0.085514107 seconds. Throughput is 1496.8291 records/second. Loss is 1.1422081. Sequential266afc8b's hyper parameters: Current learning rate is 2.2904260192395785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 6016/60000][Iteration 4268][Wall Clock 404.784208532s] Trained 128 records in 0.085135793 seconds. Throughput is 1503.4803 records/second. Loss is 1.0718327. Sequential266afc8b's hyper parameters: Current learning rate is 2.289901534234028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 6144/60000][Iteration 4269][Wall Clock 404.867749907s] Trained 128 records in 0.083541375 seconds. Throughput is 1532.1748 records/second. Loss is 1.0755053. Sequential266afc8b's hyper parameters: Current learning rate is 2.2893772893772894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:03 INFO  DistriOptimizer$:408 - [Epoch 10 6272/60000][Iteration 4270][Wall Clock 404.952317552s] Trained 128 records in 0.084567645 seconds. Throughput is 1513.5813 records/second. Loss is 1.1896247. Sequential266afc8b's hyper parameters: Current learning rate is 2.2888532845044635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 6400/60000][Iteration 4271][Wall Clock 405.034945295s] Trained 128 records in 0.082627743 seconds. Throughput is 1549.1165 records/second. Loss is 1.1990907. Sequential266afc8b's hyper parameters: Current learning rate is 2.2883295194508008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 6528/60000][Iteration 4272][Wall Clock 405.117448286s] Trained 128 records in 0.082502991 seconds. Throughput is 1551.4589 records/second. Loss is 1.1813787. Sequential266afc8b's hyper parameters: Current learning rate is 2.2878059940517045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 6656/60000][Iteration 4273][Wall Clock 405.203507504s] Trained 128 records in 0.086059218 seconds. Throughput is 1487.3479 records/second. Loss is 1.0901233. Sequential266afc8b's hyper parameters: Current learning rate is 2.2872827081427266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 6784/60000][Iteration 4274][Wall Clock 405.28668608s] Trained 128 records in 0.083178576 seconds. Throughput is 1538.8579 records/second. Loss is 1.1051105. Sequential266afc8b's hyper parameters: Current learning rate is 2.2867596615595698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 6912/60000][Iteration 4275][Wall Clock 405.371041646s] Trained 128 records in 0.084355566 seconds. Throughput is 1517.3866 records/second. Loss is 1.1255312. Sequential266afc8b's hyper parameters: Current learning rate is 2.2862368541380886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 7040/60000][Iteration 4276][Wall Clock 405.456488678s] Trained 128 records in 0.085447032 seconds. Throughput is 1498.0042 records/second. Loss is 1.1622851. Sequential266afc8b's hyper parameters: Current learning rate is 2.2857142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 7168/60000][Iteration 4277][Wall Clock 405.541198144s] Trained 128 records in 0.084709466 seconds. Throughput is 1511.0472 records/second. Loss is 1.1671634. Sequential266afc8b's hyper parameters: Current learning rate is 2.2851919561243147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 7296/60000][Iteration 4278][Wall Clock 405.623513021s] Trained 128 records in 0.082314877 seconds. Throughput is 1555.0044 records/second. Loss is 1.2001194. Sequential266afc8b's hyper parameters: Current learning rate is 2.2846698652044777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 7424/60000][Iteration 4279][Wall Clock 405.725636161s] Trained 128 records in 0.10212314 seconds. Throughput is 1253.3888 records/second. Loss is 1.0895644. Sequential266afc8b's hyper parameters: Current learning rate is 2.2841480127912289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 7552/60000][Iteration 4280][Wall Clock 405.834208406s] Trained 128 records in 0.108572245 seconds. Throughput is 1178.9385 records/second. Loss is 1.2075946. Sequential266afc8b's hyper parameters: Current learning rate is 2.2836263987211693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:04 INFO  DistriOptimizer$:408 - [Epoch 10 7680/60000][Iteration 4281][Wall Clock 405.938076368s] Trained 128 records in 0.103867962 seconds. Throughput is 1232.3337 records/second. Loss is 1.187236. Sequential266afc8b's hyper parameters: Current learning rate is 2.2831050228310502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 7808/60000][Iteration 4282][Wall Clock 406.049105761s] Trained 128 records in 0.111029393 seconds. Throughput is 1152.8479 records/second. Loss is 1.1985805. Sequential266afc8b's hyper parameters: Current learning rate is 2.2825838849577722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 7936/60000][Iteration 4283][Wall Clock 406.154925459s] Trained 128 records in 0.105819698 seconds. Throughput is 1209.6047 records/second. Loss is 1.213559. Sequential266afc8b's hyper parameters: Current learning rate is 2.2820629849383843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8064/60000][Iteration 4284][Wall Clock 406.262211406s] Trained 128 records in 0.107285947 seconds. Throughput is 1193.0734 records/second. Loss is 1.1229547. Sequential266afc8b's hyper parameters: Current learning rate is 2.2815423226100847E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8192/60000][Iteration 4285][Wall Clock 406.373540206s] Trained 128 records in 0.1113288 seconds. Throughput is 1149.7474 records/second. Loss is 1.1786484. Sequential266afc8b's hyper parameters: Current learning rate is 2.281021897810219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8320/60000][Iteration 4286][Wall Clock 406.480318052s] Trained 128 records in 0.106777846 seconds. Throughput is 1198.7505 records/second. Loss is 1.1226152. Sequential266afc8b's hyper parameters: Current learning rate is 2.2805017103762827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8448/60000][Iteration 4287][Wall Clock 406.57278051s] Trained 128 records in 0.092462458 seconds. Throughput is 1384.3456 records/second. Loss is 1.0985408. Sequential266afc8b's hyper parameters: Current learning rate is 2.2799817601459188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8576/60000][Iteration 4288][Wall Clock 406.649589773s] Trained 128 records in 0.076809263 seconds. Throughput is 1666.4656 records/second. Loss is 1.1836625. Sequential266afc8b's hyper parameters: Current learning rate is 2.2794620469569182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8704/60000][Iteration 4289][Wall Clock 406.729004749s] Trained 128 records in 0.079414976 seconds. Throughput is 1611.7866 records/second. Loss is 1.1407397. Sequential266afc8b's hyper parameters: Current learning rate is 2.2789425706472196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8832/60000][Iteration 4290][Wall Clock 406.811898559s] Trained 128 records in 0.08289381 seconds. Throughput is 1544.1443 records/second. Loss is 1.087066. Sequential266afc8b's hyper parameters: Current learning rate is 2.27842333105491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 8960/60000][Iteration 4291][Wall Clock 406.895224101s] Trained 128 records in 0.083325542 seconds. Throughput is 1536.1436 records/second. Loss is 1.2430762. Sequential266afc8b's hyper parameters: Current learning rate is 2.2779043280182233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:05 INFO  DistriOptimizer$:408 - [Epoch 10 9088/60000][Iteration 4292][Wall Clock 406.978354708s] Trained 128 records in 0.083130607 seconds. Throughput is 1539.7458 records/second. Loss is 1.0445476. Sequential266afc8b's hyper parameters: Current learning rate is 2.2773855613755407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9216/60000][Iteration 4293][Wall Clock 407.071123082s] Trained 128 records in 0.092768374 seconds. Throughput is 1379.7806 records/second. Loss is 1.1592946. Sequential266afc8b's hyper parameters: Current learning rate is 2.2768670309653916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9344/60000][Iteration 4294][Wall Clock 407.15536136s] Trained 128 records in 0.084238278 seconds. Throughput is 1519.4993 records/second. Loss is 1.2037015. Sequential266afc8b's hyper parameters: Current learning rate is 2.2763487366264513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9472/60000][Iteration 4295][Wall Clock 407.239391445s] Trained 128 records in 0.084030085 seconds. Throughput is 1523.2639 records/second. Loss is 1.1023809. Sequential266afc8b's hyper parameters: Current learning rate is 2.275830678197542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9600/60000][Iteration 4296][Wall Clock 407.32561589s] Trained 128 records in 0.086224445 seconds. Throughput is 1484.4978 records/second. Loss is 1.1361732. Sequential266afc8b's hyper parameters: Current learning rate is 2.2753128555176336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9728/60000][Iteration 4297][Wall Clock 407.411239651s] Trained 128 records in 0.085623761 seconds. Throughput is 1494.9121 records/second. Loss is 1.2077379. Sequential266afc8b's hyper parameters: Current learning rate is 2.2747952684258417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9856/60000][Iteration 4298][Wall Clock 407.494223862s] Trained 128 records in 0.082984211 seconds. Throughput is 1542.4622 records/second. Loss is 1.0576332. Sequential266afc8b's hyper parameters: Current learning rate is 2.2742779167614284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 9984/60000][Iteration 4299][Wall Clock 407.581327958s] Trained 128 records in 0.087104096 seconds. Throughput is 1469.5061 records/second. Loss is 1.1222776. Sequential266afc8b's hyper parameters: Current learning rate is 2.2737608003638017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 10112/60000][Iteration 4300][Wall Clock 407.666441585s] Trained 128 records in 0.085113627 seconds. Throughput is 1503.872 records/second. Loss is 1.1613762. Sequential266afc8b's hyper parameters: Current learning rate is 2.2732439190725165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 10240/60000][Iteration 4301][Wall Clock 407.75487889s] Trained 128 records in 0.088437305 seconds. Throughput is 1447.353 records/second. Loss is 1.1134175. Sequential266afc8b's hyper parameters: Current learning rate is 2.2727272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 10368/60000][Iteration 4302][Wall Clock 407.843539946s] Trained 128 records in 0.088661056 seconds. Throughput is 1443.7004 records/second. Loss is 1.1736324. Sequential266afc8b's hyper parameters: Current learning rate is 2.2722108611679165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:06 INFO  DistriOptimizer$:408 - [Epoch 10 10496/60000][Iteration 4303][Wall Clock 407.934482774s] Trained 128 records in 0.090942828 seconds. Throughput is 1407.4777 records/second. Loss is 1.0587736. Sequential266afc8b's hyper parameters: Current learning rate is 2.2716946842344388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 10624/60000][Iteration 4304][Wall Clock 408.018435153s] Trained 128 records in 0.083952379 seconds. Throughput is 1524.6738 records/second. Loss is 1.2890301. Sequential266afc8b's hyper parameters: Current learning rate is 2.271178741766977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 10752/60000][Iteration 4305][Wall Clock 408.119175583s] Trained 128 records in 0.10074043 seconds. Throughput is 1270.5922 records/second. Loss is 1.1977451. Sequential266afc8b's hyper parameters: Current learning rate is 2.270663033605813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 10880/60000][Iteration 4306][Wall Clock 408.20358623s] Trained 128 records in 0.084410647 seconds. Throughput is 1516.3964 records/second. Loss is 1.1212426. Sequential266afc8b's hyper parameters: Current learning rate is 2.2701475595913732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11008/60000][Iteration 4307][Wall Clock 408.289658487s] Trained 128 records in 0.086072257 seconds. Throughput is 1487.1226 records/second. Loss is 1.1088395. Sequential266afc8b's hyper parameters: Current learning rate is 2.2696323195642307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11136/60000][Iteration 4308][Wall Clock 408.368886698s] Trained 128 records in 0.079228211 seconds. Throughput is 1615.5862 records/second. Loss is 1.10431. Sequential266afc8b's hyper parameters: Current learning rate is 2.269117313365101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11264/60000][Iteration 4309][Wall Clock 408.460298467s] Trained 128 records in 0.091411769 seconds. Throughput is 1400.2573 records/second. Loss is 1.1538538. Sequential266afc8b's hyper parameters: Current learning rate is 2.268602540834846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11392/60000][Iteration 4310][Wall Clock 408.544320363s] Trained 128 records in 0.084021896 seconds. Throughput is 1523.4125 records/second. Loss is 1.1440636. Sequential266afc8b's hyper parameters: Current learning rate is 2.2680880018144704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11520/60000][Iteration 4311][Wall Clock 408.632446075s] Trained 128 records in 0.088125712 seconds. Throughput is 1452.4705 records/second. Loss is 1.0972128. Sequential266afc8b's hyper parameters: Current learning rate is 2.2675736961451246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11648/60000][Iteration 4312][Wall Clock 408.720341605s] Trained 128 records in 0.08789553 seconds. Throughput is 1456.2743 records/second. Loss is 1.1184682. Sequential266afc8b's hyper parameters: Current learning rate is 2.2670596236681024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11776/60000][Iteration 4313][Wall Clock 408.811630796s] Trained 128 records in 0.091289191 seconds. Throughput is 1402.1375 records/second. Loss is 1.1058676. Sequential266afc8b's hyper parameters: Current learning rate is 2.2665457842248416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:07 INFO  DistriOptimizer$:408 - [Epoch 10 11904/60000][Iteration 4314][Wall Clock 408.893238329s] Trained 128 records in 0.081607533 seconds. Throughput is 1568.4827 records/second. Loss is 1.1128192. Sequential266afc8b's hyper parameters: Current learning rate is 2.2660321776569228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12032/60000][Iteration 4315][Wall Clock 408.977094286s] Trained 128 records in 0.083855957 seconds. Throughput is 1526.427 records/second. Loss is 1.1581262. Sequential266afc8b's hyper parameters: Current learning rate is 2.2655188038060717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12160/60000][Iteration 4316][Wall Clock 409.058664955s] Trained 128 records in 0.081570669 seconds. Throughput is 1569.1915 records/second. Loss is 1.0368619. Sequential266afc8b's hyper parameters: Current learning rate is 2.2650056625141563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12288/60000][Iteration 4317][Wall Clock 409.146136324s] Trained 128 records in 0.087471369 seconds. Throughput is 1463.336 records/second. Loss is 1.1007235. Sequential266afc8b's hyper parameters: Current learning rate is 2.2644927536231882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12416/60000][Iteration 4318][Wall Clock 409.23085873s] Trained 128 records in 0.084722406 seconds. Throughput is 1510.8164 records/second. Loss is 1.1711715. Sequential266afc8b's hyper parameters: Current learning rate is 2.2639800769753225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12544/60000][Iteration 4319][Wall Clock 409.315434563s] Trained 128 records in 0.084575833 seconds. Throughput is 1513.4347 records/second. Loss is 1.2521595. Sequential266afc8b's hyper parameters: Current learning rate is 2.2634676324128565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12672/60000][Iteration 4320][Wall Clock 409.399217644s] Trained 128 records in 0.083783081 seconds. Throughput is 1527.7548 records/second. Loss is 1.169009. Sequential266afc8b's hyper parameters: Current learning rate is 2.2629554197782305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12800/60000][Iteration 4321][Wall Clock 409.483902131s] Trained 128 records in 0.084684487 seconds. Throughput is 1511.4929 records/second. Loss is 1.1551642. Sequential266afc8b's hyper parameters: Current learning rate is 2.262443438914027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 12928/60000][Iteration 4322][Wall Clock 409.566989424s] Trained 128 records in 0.083087293 seconds. Throughput is 1540.5485 records/second. Loss is 1.2317591. Sequential266afc8b's hyper parameters: Current learning rate is 2.2619316896629722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 13056/60000][Iteration 4323][Wall Clock 409.650415376s] Trained 128 records in 0.083425952 seconds. Throughput is 1534.2947 records/second. Loss is 1.2031132. Sequential266afc8b's hyper parameters: Current learning rate is 2.261420171867933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 13184/60000][Iteration 4324][Wall Clock 409.734432658s] Trained 128 records in 0.084017282 seconds. Throughput is 1523.4961 records/second. Loss is 1.1703286. Sequential266afc8b's hyper parameters: Current learning rate is 2.2609088853719193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 13312/60000][Iteration 4325][Wall Clock 409.818728708s] Trained 128 records in 0.08429605 seconds. Throughput is 1518.4579 records/second. Loss is 1.2032502. Sequential266afc8b's hyper parameters: Current learning rate is 2.260397830018083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:08 INFO  DistriOptimizer$:408 - [Epoch 10 13440/60000][Iteration 4326][Wall Clock 409.900935944s] Trained 128 records in 0.082207236 seconds. Throughput is 1557.0406 records/second. Loss is 1.1045755. Sequential266afc8b's hyper parameters: Current learning rate is 2.2598870056497175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 13568/60000][Iteration 4327][Wall Clock 409.985003585s] Trained 128 records in 0.084067641 seconds. Throughput is 1522.5834 records/second. Loss is 1.0994766. Sequential266afc8b's hyper parameters: Current learning rate is 2.2593764121102577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 13696/60000][Iteration 4328][Wall Clock 410.068349551s] Trained 128 records in 0.083345966 seconds. Throughput is 1535.7672 records/second. Loss is 1.120647. Sequential266afc8b's hyper parameters: Current learning rate is 2.2588660492432798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 13824/60000][Iteration 4329][Wall Clock 410.155218303s] Trained 128 records in 0.086868752 seconds. Throughput is 1473.4872 records/second. Loss is 1.2175199. Sequential266afc8b's hyper parameters: Current learning rate is 2.2583559168925022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 13952/60000][Iteration 4330][Wall Clock 410.251308848s] Trained 128 records in 0.096090545 seconds. Throughput is 1332.0769 records/second. Loss is 1.2043693. Sequential266afc8b's hyper parameters: Current learning rate is 2.257846014901784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14080/60000][Iteration 4331][Wall Clock 410.332968117s] Trained 128 records in 0.081659269 seconds. Throughput is 1567.4889 records/second. Loss is 1.2082491. Sequential266afc8b's hyper parameters: Current learning rate is 2.257336343115124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14208/60000][Iteration 4332][Wall Clock 410.406160885s] Trained 128 records in 0.073192768 seconds. Throughput is 1748.8066 records/second. Loss is 1.1262256. Sequential266afc8b's hyper parameters: Current learning rate is 2.2568269013766644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14336/60000][Iteration 4333][Wall Clock 410.490568478s] Trained 128 records in 0.084407593 seconds. Throughput is 1516.4513 records/second. Loss is 1.0680848. Sequential266afc8b's hyper parameters: Current learning rate is 2.256317689530686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14464/60000][Iteration 4334][Wall Clock 410.577316502s] Trained 128 records in 0.086748024 seconds. Throughput is 1475.5378 records/second. Loss is 1.094223. Sequential266afc8b's hyper parameters: Current learning rate is 2.255808707421611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14592/60000][Iteration 4335][Wall Clock 410.663720464s] Trained 128 records in 0.086403962 seconds. Throughput is 1481.4136 records/second. Loss is 1.1345735. Sequential266afc8b's hyper parameters: Current learning rate is 2.255299954894001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14720/60000][Iteration 4336][Wall Clock 410.753984611s] Trained 128 records in 0.090264147 seconds. Throughput is 1418.0602 records/second. Loss is 1.229688. Sequential266afc8b's hyper parameters: Current learning rate is 2.2547914317925591E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14848/60000][Iteration 4337][Wall Clock 410.839772383s] Trained 128 records in 0.085787772 seconds. Throughput is 1492.0541 records/second. Loss is 1.134285. Sequential266afc8b's hyper parameters: Current learning rate is 2.2542831379621282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:09 INFO  DistriOptimizer$:408 - [Epoch 10 14976/60000][Iteration 4338][Wall Clock 410.935177714s] Trained 128 records in 0.095405331 seconds. Throughput is 1341.644 records/second. Loss is 1.2153715. Sequential266afc8b's hyper parameters: Current learning rate is 2.25377507324769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15104/60000][Iteration 4339][Wall Clock 411.016923854s] Trained 128 records in 0.08174614 seconds. Throughput is 1565.8232 records/second. Loss is 1.104437. Sequential266afc8b's hyper parameters: Current learning rate is 2.253267237494367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15232/60000][Iteration 4340][Wall Clock 411.099768427s] Trained 128 records in 0.082844573 seconds. Throughput is 1545.062 records/second. Loss is 1.1744367. Sequential266afc8b's hyper parameters: Current learning rate is 2.2527596305474206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15360/60000][Iteration 4341][Wall Clock 411.184950982s] Trained 128 records in 0.085182555 seconds. Throughput is 1502.6552 records/second. Loss is 1.0539954. Sequential266afc8b's hyper parameters: Current learning rate is 2.2522522522522523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15488/60000][Iteration 4342][Wall Clock 411.270548005s] Trained 128 records in 0.085597023 seconds. Throughput is 1495.3792 records/second. Loss is 1.1738485. Sequential266afc8b's hyper parameters: Current learning rate is 2.2517451024544022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15616/60000][Iteration 4343][Wall Clock 411.35690102s] Trained 128 records in 0.086353015 seconds. Throughput is 1482.2876 records/second. Loss is 1.1076493. Sequential266afc8b's hyper parameters: Current learning rate is 2.2512381809995497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15744/60000][Iteration 4344][Wall Clock 411.44060574s] Trained 128 records in 0.08370472 seconds. Throughput is 1529.185 records/second. Loss is 1.099285. Sequential266afc8b's hyper parameters: Current learning rate is 2.2507314877335134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 15872/60000][Iteration 4345][Wall Clock 411.525449025s] Trained 128 records in 0.084843285 seconds. Throughput is 1508.6638 records/second. Loss is 1.1550682. Sequential266afc8b's hyper parameters: Current learning rate is 2.2502250225022504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 16000/60000][Iteration 4346][Wall Clock 411.608841941s] Trained 128 records in 0.083392916 seconds. Throughput is 1534.9025 records/second. Loss is 1.1316196. Sequential266afc8b's hyper parameters: Current learning rate is 2.249718785151856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 16128/60000][Iteration 4347][Wall Clock 411.692718714s] Trained 128 records in 0.083876773 seconds. Throughput is 1526.0482 records/second. Loss is 1.1759297. Sequential266afc8b's hyper parameters: Current learning rate is 2.249212775528565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 16256/60000][Iteration 4348][Wall Clock 411.778949025s] Trained 128 records in 0.086230311 seconds. Throughput is 1484.3969 records/second. Loss is 1.1256489. Sequential266afc8b's hyper parameters: Current learning rate is 2.2487069934787497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 16384/60000][Iteration 4349][Wall Clock 411.861742895s] Trained 128 records in 0.08279387 seconds. Throughput is 1546.0082 records/second. Loss is 1.1294702. Sequential266afc8b's hyper parameters: Current learning rate is 2.2482014388489207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:10 INFO  DistriOptimizer$:408 - [Epoch 10 16512/60000][Iteration 4350][Wall Clock 411.94687972s] Trained 128 records in 0.085136825 seconds. Throughput is 1503.4623 records/second. Loss is 1.0973678. Sequential266afc8b's hyper parameters: Current learning rate is 2.247696111485727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 16640/60000][Iteration 4351][Wall Clock 412.033600517s] Trained 128 records in 0.086720797 seconds. Throughput is 1476.0012 records/second. Loss is 1.2454132. Sequential266afc8b's hyper parameters: Current learning rate is 2.2471910112359551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 16768/60000][Iteration 4352][Wall Clock 412.12624577s] Trained 128 records in 0.092645253 seconds. Throughput is 1381.6143 records/second. Loss is 1.1134645. Sequential266afc8b's hyper parameters: Current learning rate is 2.246686137946529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 16896/60000][Iteration 4353][Wall Clock 412.211659295s] Trained 128 records in 0.085413525 seconds. Throughput is 1498.5918 records/second. Loss is 1.2211196. Sequential266afc8b's hyper parameters: Current learning rate is 2.2461814914645102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17024/60000][Iteration 4354][Wall Clock 412.296778094s] Trained 128 records in 0.085118799 seconds. Throughput is 1503.7806 records/second. Loss is 1.0474033. Sequential266afc8b's hyper parameters: Current learning rate is 2.2456770716370987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17152/60000][Iteration 4355][Wall Clock 412.383714368s] Trained 128 records in 0.086936274 seconds. Throughput is 1472.3429 records/second. Loss is 1.1697268. Sequential266afc8b's hyper parameters: Current learning rate is 2.2451728783116302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17280/60000][Iteration 4356][Wall Clock 412.482852726s] Trained 128 records in 0.099138358 seconds. Throughput is 1291.1249 records/second. Loss is 1.1521213. Sequential266afc8b's hyper parameters: Current learning rate is 2.2446689113355778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17408/60000][Iteration 4357][Wall Clock 412.569150178s] Trained 128 records in 0.086297452 seconds. Throughput is 1483.242 records/second. Loss is 1.0473061. Sequential266afc8b's hyper parameters: Current learning rate is 2.2441651705565528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17536/60000][Iteration 4358][Wall Clock 412.657954513s] Trained 128 records in 0.088804335 seconds. Throughput is 1441.3711 records/second. Loss is 1.1606661. Sequential266afc8b's hyper parameters: Current learning rate is 2.243661655822302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17664/60000][Iteration 4359][Wall Clock 412.751294487s] Trained 128 records in 0.093339974 seconds. Throughput is 1371.331 records/second. Loss is 1.1519122. Sequential266afc8b's hyper parameters: Current learning rate is 2.243158366980709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17792/60000][Iteration 4360][Wall Clock 412.836975354s] Trained 128 records in 0.085680867 seconds. Throughput is 1493.9158 records/second. Loss is 1.105633. Sequential266afc8b's hyper parameters: Current learning rate is 2.2426553038797935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:11 INFO  DistriOptimizer$:408 - [Epoch 10 17920/60000][Iteration 4361][Wall Clock 412.922542709s] Trained 128 records in 0.085567355 seconds. Throughput is 1495.8976 records/second. Loss is 1.197869. Sequential266afc8b's hyper parameters: Current learning rate is 2.242152466367713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18048/60000][Iteration 4362][Wall Clock 413.008483328s] Trained 128 records in 0.085940619 seconds. Throughput is 1489.4004 records/second. Loss is 1.1277772. Sequential266afc8b's hyper parameters: Current learning rate is 2.2416498542927594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18176/60000][Iteration 4363][Wall Clock 413.094397227s] Trained 128 records in 0.085913899 seconds. Throughput is 1489.8638 records/second. Loss is 1.1077806. Sequential266afc8b's hyper parameters: Current learning rate is 2.2411474675033618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18304/60000][Iteration 4364][Wall Clock 413.1847813s] Trained 128 records in 0.090384073 seconds. Throughput is 1416.1787 records/second. Loss is 1.1149589. Sequential266afc8b's hyper parameters: Current learning rate is 2.240645305848084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18432/60000][Iteration 4365][Wall Clock 413.270290586s] Trained 128 records in 0.085509286 seconds. Throughput is 1496.9135 records/second. Loss is 1.1214929. Sequential266afc8b's hyper parameters: Current learning rate is 2.2401433691756272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18560/60000][Iteration 4366][Wall Clock 413.356019464s] Trained 128 records in 0.085728878 seconds. Throughput is 1493.0792 records/second. Loss is 1.064736. Sequential266afc8b's hyper parameters: Current learning rate is 2.2396416573348266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18688/60000][Iteration 4367][Wall Clock 413.447226036s] Trained 128 records in 0.091206572 seconds. Throughput is 1403.4076 records/second. Loss is 1.1239913. Sequential266afc8b's hyper parameters: Current learning rate is 2.239140170174653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18816/60000][Iteration 4368][Wall Clock 413.531776444s] Trained 128 records in 0.084550408 seconds. Throughput is 1513.8898 records/second. Loss is 1.0986915. Sequential266afc8b's hyper parameters: Current learning rate is 2.238638907544213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 18944/60000][Iteration 4369][Wall Clock 413.61177098s] Trained 128 records in 0.079994536 seconds. Throughput is 1600.1093 records/second. Loss is 1.1245046. Sequential266afc8b's hyper parameters: Current learning rate is 2.2381378692927484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 19072/60000][Iteration 4370][Wall Clock 413.691714367s] Trained 128 records in 0.079943387 seconds. Throughput is 1601.133 records/second. Loss is 1.1863368. Sequential266afc8b's hyper parameters: Current learning rate is 2.2376370552696354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 19200/60000][Iteration 4371][Wall Clock 413.774424307s] Trained 128 records in 0.08270994 seconds. Throughput is 1547.577 records/second. Loss is 1.1597657. Sequential266afc8b's hyper parameters: Current learning rate is 2.2371364653243846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 19328/60000][Iteration 4372][Wall Clock 413.859014855s] Trained 128 records in 0.084590548 seconds. Throughput is 1513.1714 records/second. Loss is 1.1018867. Sequential266afc8b's hyper parameters: Current learning rate is 2.2366360993066427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:12 INFO  DistriOptimizer$:408 - [Epoch 10 19456/60000][Iteration 4373][Wall Clock 413.94186243s] Trained 128 records in 0.082847575 seconds. Throughput is 1545.006 records/second. Loss is 1.0723598. Sequential266afc8b's hyper parameters: Current learning rate is 2.2361359570661896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 19584/60000][Iteration 4374][Wall Clock 414.02685453s] Trained 128 records in 0.0849921 seconds. Throughput is 1506.0222 records/second. Loss is 1.090201. Sequential266afc8b's hyper parameters: Current learning rate is 2.2356360384529397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 19712/60000][Iteration 4375][Wall Clock 414.112578424s] Trained 128 records in 0.085723894 seconds. Throughput is 1493.166 records/second. Loss is 1.2419218. Sequential266afc8b's hyper parameters: Current learning rate is 2.2351363433169424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 19840/60000][Iteration 4376][Wall Clock 414.197579491s] Trained 128 records in 0.085001067 seconds. Throughput is 1505.8634 records/second. Loss is 1.1862841. Sequential266afc8b's hyper parameters: Current learning rate is 2.23463687150838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 19968/60000][Iteration 4377][Wall Clock 414.280994905s] Trained 128 records in 0.083415414 seconds. Throughput is 1534.4886 records/second. Loss is 1.1831429. Sequential266afc8b's hyper parameters: Current learning rate is 2.2341376228775695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20096/60000][Iteration 4378][Wall Clock 414.364725623s] Trained 128 records in 0.083730718 seconds. Throughput is 1528.7101 records/second. Loss is 1.1163899. Sequential266afc8b's hyper parameters: Current learning rate is 2.2336385972749609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20224/60000][Iteration 4379][Wall Clock 414.449223266s] Trained 128 records in 0.084497643 seconds. Throughput is 1514.8351 records/second. Loss is 1.1301011. Sequential266afc8b's hyper parameters: Current learning rate is 2.2331397945511388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20352/60000][Iteration 4380][Wall Clock 414.53419018s] Trained 128 records in 0.084966914 seconds. Throughput is 1506.4688 records/second. Loss is 1.0287354. Sequential266afc8b's hyper parameters: Current learning rate is 2.2326412145568208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20480/60000][Iteration 4381][Wall Clock 414.627182652s] Trained 128 records in 0.092992472 seconds. Throughput is 1376.4556 records/second. Loss is 1.1830617. Sequential266afc8b's hyper parameters: Current learning rate is 2.232142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20608/60000][Iteration 4382][Wall Clock 414.709478997s] Trained 128 records in 0.082296345 seconds. Throughput is 1555.3547 records/second. Loss is 1.1753789. Sequential266afc8b's hyper parameters: Current learning rate is 2.231644722160232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20736/60000][Iteration 4383][Wall Clock 414.79426088s] Trained 128 records in 0.084781883 seconds. Throughput is 1509.7565 records/second. Loss is 1.140984. Sequential266afc8b's hyper parameters: Current learning rate is 2.2311468094600624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:13 INFO  DistriOptimizer$:408 - [Epoch 10 20864/60000][Iteration 4384][Wall Clock 414.872322896s] Trained 128 records in 0.078062016 seconds. Throughput is 1639.722 records/second. Loss is 1.1763031. Sequential266afc8b's hyper parameters: Current learning rate is 2.2306491188935982E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 20992/60000][Iteration 4385][Wall Clock 414.950428728s] Trained 128 records in 0.078105832 seconds. Throughput is 1638.8021 records/second. Loss is 1.1140857. Sequential266afc8b's hyper parameters: Current learning rate is 2.230151650312221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21120/60000][Iteration 4386][Wall Clock 415.03485037s] Trained 128 records in 0.084421642 seconds. Throughput is 1516.1989 records/second. Loss is 1.1111066. Sequential266afc8b's hyper parameters: Current learning rate is 2.229654403567447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21248/60000][Iteration 4387][Wall Clock 415.118908596s] Trained 128 records in 0.084058226 seconds. Throughput is 1522.754 records/second. Loss is 1.1319169. Sequential266afc8b's hyper parameters: Current learning rate is 2.229157378510923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21376/60000][Iteration 4388][Wall Clock 415.202852499s] Trained 128 records in 0.083943903 seconds. Throughput is 1524.8279 records/second. Loss is 1.0665181. Sequential266afc8b's hyper parameters: Current learning rate is 2.2286605749944285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21504/60000][Iteration 4389][Wall Clock 415.293719146s] Trained 128 records in 0.090866647 seconds. Throughput is 1408.6577 records/second. Loss is 1.0671134. Sequential266afc8b's hyper parameters: Current learning rate is 2.228163992869875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21632/60000][Iteration 4390][Wall Clock 415.37692159s] Trained 128 records in 0.083202444 seconds. Throughput is 1538.4164 records/second. Loss is 1.1176932. Sequential266afc8b's hyper parameters: Current learning rate is 2.2276676319893073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21760/60000][Iteration 4391][Wall Clock 415.452245517s] Trained 128 records in 0.075323927 seconds. Throughput is 1699.3273 records/second. Loss is 1.1098362. Sequential266afc8b's hyper parameters: Current learning rate is 2.2271714922048998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 21888/60000][Iteration 4392][Wall Clock 415.535949005s] Trained 128 records in 0.083703488 seconds. Throughput is 1529.2075 records/second. Loss is 1.0927395. Sequential266afc8b's hyper parameters: Current learning rate is 2.22667557336896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 22016/60000][Iteration 4393][Wall Clock 415.618982327s] Trained 128 records in 0.083033322 seconds. Throughput is 1541.5498 records/second. Loss is 1.0578622. Sequential266afc8b's hyper parameters: Current learning rate is 2.226179875333927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 22144/60000][Iteration 4394][Wall Clock 415.702435967s] Trained 128 records in 0.08345364 seconds. Throughput is 1533.7856 records/second. Loss is 1.0997528. Sequential266afc8b's hyper parameters: Current learning rate is 2.2256843979523704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 22272/60000][Iteration 4395][Wall Clock 415.786378441s] Trained 128 records in 0.083942474 seconds. Throughput is 1524.8538 records/second. Loss is 1.119312. Sequential266afc8b's hyper parameters: Current learning rate is 2.2251891410769918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:14 INFO  DistriOptimizer$:408 - [Epoch 10 22400/60000][Iteration 4396][Wall Clock 415.870425965s] Trained 128 records in 0.084047524 seconds. Throughput is 1522.9479 records/second. Loss is 1.1417136. Sequential266afc8b's hyper parameters: Current learning rate is 2.2246941045606227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 22528/60000][Iteration 4397][Wall Clock 415.955110097s] Trained 128 records in 0.084684132 seconds. Throughput is 1511.4991 records/second. Loss is 1.0790882. Sequential266afc8b's hyper parameters: Current learning rate is 2.2241992882562276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 22656/60000][Iteration 4398][Wall Clock 416.037239718s] Trained 128 records in 0.082129621 seconds. Throughput is 1558.512 records/second. Loss is 1.1369455. Sequential266afc8b's hyper parameters: Current learning rate is 2.2237046920169003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 22784/60000][Iteration 4399][Wall Clock 416.122523339s] Trained 128 records in 0.085283621 seconds. Throughput is 1500.8744 records/second. Loss is 1.2736189. Sequential266afc8b's hyper parameters: Current learning rate is 2.2232103156958648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 22912/60000][Iteration 4400][Wall Clock 416.208566327s] Trained 128 records in 0.086042988 seconds. Throughput is 1487.6285 records/second. Loss is 1.1848311. Sequential266afc8b's hyper parameters: Current learning rate is 2.222716159146477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23040/60000][Iteration 4401][Wall Clock 416.291935424s] Trained 128 records in 0.083369097 seconds. Throughput is 1535.3411 records/second. Loss is 1.0168993. Sequential266afc8b's hyper parameters: Current learning rate is 2.2222222222222223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23168/60000][Iteration 4402][Wall Clock 416.380669948s] Trained 128 records in 0.088734524 seconds. Throughput is 1442.5051 records/second. Loss is 1.1607143. Sequential266afc8b's hyper parameters: Current learning rate is 2.2217285047767163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23296/60000][Iteration 4403][Wall Clock 416.465299763s] Trained 128 records in 0.084629815 seconds. Throughput is 1512.4694 records/second. Loss is 1.0910101. Sequential266afc8b's hyper parameters: Current learning rate is 2.221235006663705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23424/60000][Iteration 4404][Wall Clock 416.550143452s] Trained 128 records in 0.084843689 seconds. Throughput is 1508.6567 records/second. Loss is 1.0958194. Sequential266afc8b's hyper parameters: Current learning rate is 2.2207417277370642E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23552/60000][Iteration 4405][Wall Clock 416.635898249s] Trained 128 records in 0.085754797 seconds. Throughput is 1492.6279 records/second. Loss is 1.1189537. Sequential266afc8b's hyper parameters: Current learning rate is 2.2202486678507994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23680/60000][Iteration 4406][Wall Clock 416.720690463s] Trained 128 records in 0.084792214 seconds. Throughput is 1509.5726 records/second. Loss is 1.1475236. Sequential266afc8b's hyper parameters: Current learning rate is 2.2197558268590453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23808/60000][Iteration 4407][Wall Clock 416.812573339s] Trained 128 records in 0.091882876 seconds. Throughput is 1393.0779 records/second. Loss is 1.1457539. Sequential266afc8b's hyper parameters: Current learning rate is 2.2192632046160674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:15 INFO  DistriOptimizer$:408 - [Epoch 10 23936/60000][Iteration 4408][Wall Clock 416.893138783s] Trained 128 records in 0.080565444 seconds. Throughput is 1588.7705 records/second. Loss is 1.1871251. Sequential266afc8b's hyper parameters: Current learning rate is 2.2187708009762592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24064/60000][Iteration 4409][Wall Clock 416.96882504s] Trained 128 records in 0.075686257 seconds. Throughput is 1691.1921 records/second. Loss is 1.2273118. Sequential266afc8b's hyper parameters: Current learning rate is 2.2182786157941438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24192/60000][Iteration 4410][Wall Clock 417.051112495s] Trained 128 records in 0.082287455 seconds. Throughput is 1555.5227 records/second. Loss is 1.1164777. Sequential266afc8b's hyper parameters: Current learning rate is 2.2177866489243733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24320/60000][Iteration 4411][Wall Clock 417.134366921s] Trained 128 records in 0.083254426 seconds. Throughput is 1537.4558 records/second. Loss is 1.1504238. Sequential266afc8b's hyper parameters: Current learning rate is 2.2172949002217295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24448/60000][Iteration 4412][Wall Clock 417.217041755s] Trained 128 records in 0.082674834 seconds. Throughput is 1548.2341 records/second. Loss is 1.0560075. Sequential266afc8b's hyper parameters: Current learning rate is 2.216803369541122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24576/60000][Iteration 4413][Wall Clock 417.302465044s] Trained 128 records in 0.085423289 seconds. Throughput is 1498.4204 records/second. Loss is 1.093009. Sequential266afc8b's hyper parameters: Current learning rate is 2.216312056737589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24704/60000][Iteration 4414][Wall Clock 417.385750858s] Trained 128 records in 0.083285814 seconds. Throughput is 1536.8763 records/second. Loss is 0.98410076. Sequential266afc8b's hyper parameters: Current learning rate is 2.2158209616662973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24832/60000][Iteration 4415][Wall Clock 417.471611915s] Trained 128 records in 0.085861057 seconds. Throughput is 1490.7806 records/second. Loss is 1.1051439. Sequential266afc8b's hyper parameters: Current learning rate is 2.2153300841825432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 24960/60000][Iteration 4416][Wall Clock 417.551062929s] Trained 128 records in 0.079451014 seconds. Throughput is 1611.0555 records/second. Loss is 1.1600766. Sequential266afc8b's hyper parameters: Current learning rate is 2.2148394241417498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 25088/60000][Iteration 4417][Wall Clock 417.635720051s] Trained 128 records in 0.084657122 seconds. Throughput is 1511.9814 records/second. Loss is 1.1392814. Sequential266afc8b's hyper parameters: Current learning rate is 2.2143489813994684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 25216/60000][Iteration 4418][Wall Clock 417.7189864s] Trained 128 records in 0.083266349 seconds. Throughput is 1537.2357 records/second. Loss is 1.1414601. Sequential266afc8b's hyper parameters: Current learning rate is 2.2138587558113792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 25344/60000][Iteration 4419][Wall Clock 417.805852663s] Trained 128 records in 0.086866263 seconds. Throughput is 1473.5295 records/second. Loss is 1.1511724. Sequential266afc8b's hyper parameters: Current learning rate is 2.213368747233289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:16 INFO  DistriOptimizer$:408 - [Epoch 10 25472/60000][Iteration 4420][Wall Clock 417.890057121s] Trained 128 records in 0.084204458 seconds. Throughput is 1520.1095 records/second. Loss is 1.131337. Sequential266afc8b's hyper parameters: Current learning rate is 2.212878955521133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 25600/60000][Iteration 4421][Wall Clock 417.973928325s] Trained 128 records in 0.083871204 seconds. Throughput is 1526.1497 records/second. Loss is 1.0835129. Sequential266afc8b's hyper parameters: Current learning rate is 2.2123893805309734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 25728/60000][Iteration 4422][Wall Clock 418.061717061s] Trained 128 records in 0.087788736 seconds. Throughput is 1458.0458 records/second. Loss is 1.1944587. Sequential266afc8b's hyper parameters: Current learning rate is 2.2119000221190003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 25856/60000][Iteration 4423][Wall Clock 418.151363276s] Trained 128 records in 0.089646215 seconds. Throughput is 1427.835 records/second. Loss is 1.0964947. Sequential266afc8b's hyper parameters: Current learning rate is 2.2114108801415304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 25984/60000][Iteration 4424][Wall Clock 418.236273894s] Trained 128 records in 0.084910618 seconds. Throughput is 1507.4675 records/second. Loss is 1.1795775. Sequential266afc8b's hyper parameters: Current learning rate is 2.2109219544550076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26112/60000][Iteration 4425][Wall Clock 418.322465349s] Trained 128 records in 0.086191455 seconds. Throughput is 1485.066 records/second. Loss is 1.1199404. Sequential266afc8b's hyper parameters: Current learning rate is 2.2104332449160034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26240/60000][Iteration 4426][Wall Clock 418.406749234s] Trained 128 records in 0.084283885 seconds. Throughput is 1518.677 records/second. Loss is 1.240751. Sequential266afc8b's hyper parameters: Current learning rate is 2.2099447513812155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26368/60000][Iteration 4427][Wall Clock 418.488702567s] Trained 128 records in 0.081953333 seconds. Throughput is 1561.8645 records/second. Loss is 1.0748696. Sequential266afc8b's hyper parameters: Current learning rate is 2.209456473707468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26496/60000][Iteration 4428][Wall Clock 418.572023939s] Trained 128 records in 0.083321372 seconds. Throughput is 1536.2206 records/second. Loss is 1.1228113. Sequential266afc8b's hyper parameters: Current learning rate is 2.2089684117517118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26624/60000][Iteration 4429][Wall Clock 418.657790436s] Trained 128 records in 0.085766497 seconds. Throughput is 1492.4243 records/second. Loss is 1.1013119. Sequential266afc8b's hyper parameters: Current learning rate is 2.2084805653710247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26752/60000][Iteration 4430][Wall Clock 418.745504802s] Trained 128 records in 0.087714366 seconds. Throughput is 1459.282 records/second. Loss is 1.086679. Sequential266afc8b's hyper parameters: Current learning rate is 2.2079929344226098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 26880/60000][Iteration 4431][Wall Clock 418.828380875s] Trained 128 records in 0.082876073 seconds. Throughput is 1544.4747 records/second. Loss is 1.1620907. Sequential266afc8b's hyper parameters: Current learning rate is 2.2075055187637966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:17 INFO  DistriOptimizer$:408 - [Epoch 10 27008/60000][Iteration 4432][Wall Clock 418.919447632s] Trained 128 records in 0.091066757 seconds. Throughput is 1405.5624 records/second. Loss is 1.1776794. Sequential266afc8b's hyper parameters: Current learning rate is 2.2070183182520414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27136/60000][Iteration 4433][Wall Clock 418.998116861s] Trained 128 records in 0.078669229 seconds. Throughput is 1627.0657 records/second. Loss is 1.064079. Sequential266afc8b's hyper parameters: Current learning rate is 2.206531332744925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27264/60000][Iteration 4434][Wall Clock 419.082477922s] Trained 128 records in 0.084361061 seconds. Throughput is 1517.2877 records/second. Loss is 1.1065028. Sequential266afc8b's hyper parameters: Current learning rate is 2.2060445621001546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27392/60000][Iteration 4435][Wall Clock 419.166440071s] Trained 128 records in 0.083962149 seconds. Throughput is 1524.4965 records/second. Loss is 1.1893448. Sequential266afc8b's hyper parameters: Current learning rate is 2.2055580061755624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27520/60000][Iteration 4436][Wall Clock 419.249915801s] Trained 128 records in 0.08347573 seconds. Throughput is 1533.3798 records/second. Loss is 1.1661727. Sequential266afc8b's hyper parameters: Current learning rate is 2.205071664829107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27648/60000][Iteration 4437][Wall Clock 419.335119868s] Trained 128 records in 0.085204067 seconds. Throughput is 1502.2758 records/second. Loss is 1.241346. Sequential266afc8b's hyper parameters: Current learning rate is 2.2045855379188714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27776/60000][Iteration 4438][Wall Clock 419.449918517s] Trained 128 records in 0.114798649 seconds. Throughput is 1114.9957 records/second. Loss is 1.0840273. Sequential266afc8b's hyper parameters: Current learning rate is 2.2040996253030638E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 27904/60000][Iteration 4439][Wall Clock 419.533453388s] Trained 128 records in 0.083534871 seconds. Throughput is 1532.2942 records/second. Loss is 1.1070119. Sequential266afc8b's hyper parameters: Current learning rate is 2.2036139268400174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 28032/60000][Iteration 4440][Wall Clock 419.623718502s] Trained 128 records in 0.090265114 seconds. Throughput is 1418.045 records/second. Loss is 1.0974007. Sequential266afc8b's hyper parameters: Current learning rate is 2.203128442388191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 28160/60000][Iteration 4441][Wall Clock 419.698861314s] Trained 128 records in 0.075142812 seconds. Throughput is 1703.423 records/second. Loss is 1.1527792. Sequential266afc8b's hyper parameters: Current learning rate is 2.2026431718061675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 28288/60000][Iteration 4442][Wall Clock 419.779247126s] Trained 128 records in 0.080385812 seconds. Throughput is 1592.3208 records/second. Loss is 1.1940591. Sequential266afc8b's hyper parameters: Current learning rate is 2.2021581149526536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:18 INFO  DistriOptimizer$:408 - [Epoch 10 28416/60000][Iteration 4443][Wall Clock 419.8624758s] Trained 128 records in 0.083228674 seconds. Throughput is 1537.9314 records/second. Loss is 1.190441. Sequential266afc8b's hyper parameters: Current learning rate is 2.2016732716864817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 28544/60000][Iteration 4444][Wall Clock 419.947828481s] Trained 128 records in 0.085352681 seconds. Throughput is 1499.6599 records/second. Loss is 1.1578807. Sequential266afc8b's hyper parameters: Current learning rate is 2.201188641866608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 28672/60000][Iteration 4445][Wall Clock 420.03063267s] Trained 128 records in 0.082804189 seconds. Throughput is 1545.8156 records/second. Loss is 1.1263198. Sequential266afc8b's hyper parameters: Current learning rate is 2.2007042253521127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 28800/60000][Iteration 4446][Wall Clock 420.115082863s] Trained 128 records in 0.084450193 seconds. Throughput is 1515.6863 records/second. Loss is 1.1147245. Sequential266afc8b's hyper parameters: Current learning rate is 2.2002200220022002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 28928/60000][Iteration 4447][Wall Clock 420.199905751s] Trained 128 records in 0.084822888 seconds. Throughput is 1509.0267 records/second. Loss is 1.1958648. Sequential266afc8b's hyper parameters: Current learning rate is 2.199736031676199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29056/60000][Iteration 4448][Wall Clock 420.282043646s] Trained 128 records in 0.082137895 seconds. Throughput is 1558.355 records/second. Loss is 1.2189039. Sequential266afc8b's hyper parameters: Current learning rate is 2.1992522542335608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29184/60000][Iteration 4449][Wall Clock 420.365574749s] Trained 128 records in 0.083531103 seconds. Throughput is 1532.3633 records/second. Loss is 1.1586841. Sequential266afc8b's hyper parameters: Current learning rate is 2.198768689533861E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29312/60000][Iteration 4450][Wall Clock 420.449338822s] Trained 128 records in 0.083764073 seconds. Throughput is 1528.1013 records/second. Loss is 1.230825. Sequential266afc8b's hyper parameters: Current learning rate is 2.1982853374367993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29440/60000][Iteration 4451][Wall Clock 420.531979221s] Trained 128 records in 0.082640399 seconds. Throughput is 1548.8792 records/second. Loss is 1.1835701. Sequential266afc8b's hyper parameters: Current learning rate is 2.1978021978021978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29568/60000][Iteration 4452][Wall Clock 420.614968583s] Trained 128 records in 0.082989362 seconds. Throughput is 1542.3663 records/second. Loss is 1.1392658. Sequential266afc8b's hyper parameters: Current learning rate is 2.1973192704900023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29696/60000][Iteration 4453][Wall Clock 420.700279924s] Trained 128 records in 0.085311341 seconds. Throughput is 1500.3867 records/second. Loss is 1.182417. Sequential266afc8b's hyper parameters: Current learning rate is 2.196836555360281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29824/60000][Iteration 4454][Wall Clock 420.786389419s] Trained 128 records in 0.086109495 seconds. Throughput is 1486.4795 records/second. Loss is 1.1479301. Sequential266afc8b's hyper parameters: Current learning rate is 2.1963540522732265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:19 INFO  DistriOptimizer$:408 - [Epoch 10 29952/60000][Iteration 4455][Wall Clock 420.870408693s] Trained 128 records in 0.084019274 seconds. Throughput is 1523.46 records/second. Loss is 1.1126332. Sequential266afc8b's hyper parameters: Current learning rate is 2.1958717610891525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30080/60000][Iteration 4456][Wall Clock 420.958379209s] Trained 128 records in 0.087970516 seconds. Throughput is 1455.033 records/second. Loss is 1.2406509. Sequential266afc8b's hyper parameters: Current learning rate is 2.195389681668496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30208/60000][Iteration 4457][Wall Clock 421.051794595s] Trained 128 records in 0.093415386 seconds. Throughput is 1370.224 records/second. Loss is 1.0734814. Sequential266afc8b's hyper parameters: Current learning rate is 2.1949078138718174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30336/60000][Iteration 4458][Wall Clock 421.132681723s] Trained 128 records in 0.080887128 seconds. Throughput is 1582.4519 records/second. Loss is 1.206347. Sequential266afc8b's hyper parameters: Current learning rate is 2.1944261575597982E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30464/60000][Iteration 4459][Wall Clock 421.221851672s] Trained 128 records in 0.089169949 seconds. Throughput is 1435.4612 records/second. Loss is 1.0840074. Sequential266afc8b's hyper parameters: Current learning rate is 2.1939447125932427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30592/60000][Iteration 4460][Wall Clock 421.302473031s] Trained 128 records in 0.080621359 seconds. Throughput is 1587.6686 records/second. Loss is 1.1074147. Sequential266afc8b's hyper parameters: Current learning rate is 2.1934634788330773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30720/60000][Iteration 4461][Wall Clock 421.385992248s] Trained 128 records in 0.083519217 seconds. Throughput is 1532.5813 records/second. Loss is 1.2361066. Sequential266afc8b's hyper parameters: Current learning rate is 2.192982456140351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30848/60000][Iteration 4462][Wall Clock 421.474854175s] Trained 128 records in 0.088861927 seconds. Throughput is 1440.4369 records/second. Loss is 1.0600557. Sequential266afc8b's hyper parameters: Current learning rate is 2.1925016443762334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 30976/60000][Iteration 4463][Wall Clock 421.559055769s] Trained 128 records in 0.084201594 seconds. Throughput is 1520.1613 records/second. Loss is 1.0733658. Sequential266afc8b's hyper parameters: Current learning rate is 2.1920210434020167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 31104/60000][Iteration 4464][Wall Clock 421.641463496s] Trained 128 records in 0.082407727 seconds. Throughput is 1553.2524 records/second. Loss is 1.129174. Sequential266afc8b's hyper parameters: Current learning rate is 2.1915406530791145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 31232/60000][Iteration 4465][Wall Clock 421.724789654s] Trained 128 records in 0.083326158 seconds. Throughput is 1536.1322 records/second. Loss is 1.0714799. Sequential266afc8b's hyper parameters: Current learning rate is 2.1910604732690623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 31360/60000][Iteration 4466][Wall Clock 421.813030018s] Trained 128 records in 0.088240364 seconds. Throughput is 1450.5834 records/second. Loss is 1.145592. Sequential266afc8b's hyper parameters: Current learning rate is 2.190580503833516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:20 INFO  DistriOptimizer$:408 - [Epoch 10 31488/60000][Iteration 4467][Wall Clock 421.894864485s] Trained 128 records in 0.081834467 seconds. Throughput is 1564.1332 records/second. Loss is 1.1613011. Sequential266afc8b's hyper parameters: Current learning rate is 2.190100744634253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 31616/60000][Iteration 4468][Wall Clock 421.975999724s] Trained 128 records in 0.081135239 seconds. Throughput is 1577.6129 records/second. Loss is 1.085624. Sequential266afc8b's hyper parameters: Current learning rate is 2.1896211955331726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 31744/60000][Iteration 4469][Wall Clock 422.060726594s] Trained 128 records in 0.08472687 seconds. Throughput is 1510.7368 records/second. Loss is 1.0287564. Sequential266afc8b's hyper parameters: Current learning rate is 2.1891418563922942E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 31872/60000][Iteration 4470][Wall Clock 422.146119286s] Trained 128 records in 0.085392692 seconds. Throughput is 1498.9573 records/second. Loss is 1.1553613. Sequential266afc8b's hyper parameters: Current learning rate is 2.1886627270737582E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32000/60000][Iteration 4471][Wall Clock 422.229597725s] Trained 128 records in 0.083478439 seconds. Throughput is 1533.3301 records/second. Loss is 1.2635416. Sequential266afc8b's hyper parameters: Current learning rate is 2.1881838074398248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32128/60000][Iteration 4472][Wall Clock 422.313348826s] Trained 128 records in 0.083751101 seconds. Throughput is 1528.3381 records/second. Loss is 1.0940822. Sequential266afc8b's hyper parameters: Current learning rate is 2.187705097352877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32256/60000][Iteration 4473][Wall Clock 422.396965106s] Trained 128 records in 0.08361628 seconds. Throughput is 1530.8024 records/second. Loss is 1.0372307. Sequential266afc8b's hyper parameters: Current learning rate is 2.1872265966754156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32384/60000][Iteration 4474][Wall Clock 422.481930585s] Trained 128 records in 0.084965479 seconds. Throughput is 1506.4941 records/second. Loss is 1.039708. Sequential266afc8b's hyper parameters: Current learning rate is 2.1867483052700633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32512/60000][Iteration 4475][Wall Clock 422.565536309s] Trained 128 records in 0.083605724 seconds. Throughput is 1530.9957 records/second. Loss is 1.1393799. Sequential266afc8b's hyper parameters: Current learning rate is 2.1862702229995628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32640/60000][Iteration 4476][Wall Clock 422.653083257s] Trained 128 records in 0.087546948 seconds. Throughput is 1462.0728 records/second. Loss is 1.1505256. Sequential266afc8b's hyper parameters: Current learning rate is 2.185792349726776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32768/60000][Iteration 4477][Wall Clock 422.737490752s] Trained 128 records in 0.084407495 seconds. Throughput is 1516.453 records/second. Loss is 1.1854314. Sequential266afc8b's hyper parameters: Current learning rate is 2.1853146853146856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:21 INFO  DistriOptimizer$:408 - [Epoch 10 32896/60000][Iteration 4478][Wall Clock 422.825144928s] Trained 128 records in 0.087654176 seconds. Throughput is 1460.2842 records/second. Loss is 1.2110473. Sequential266afc8b's hyper parameters: Current learning rate is 2.1848372296263927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33024/60000][Iteration 4479][Wall Clock 422.910238972s] Trained 128 records in 0.085094044 seconds. Throughput is 1504.2181 records/second. Loss is 1.0702156. Sequential266afc8b's hyper parameters: Current learning rate is 2.1843599825251202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33152/60000][Iteration 4480][Wall Clock 422.997867231s] Trained 128 records in 0.087628259 seconds. Throughput is 1460.716 records/second. Loss is 1.1136249. Sequential266afc8b's hyper parameters: Current learning rate is 2.1838829438742085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33280/60000][Iteration 4481][Wall Clock 423.085737604s] Trained 128 records in 0.087870373 seconds. Throughput is 1456.6912 records/second. Loss is 1.1359783. Sequential266afc8b's hyper parameters: Current learning rate is 2.1834061135371177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33408/60000][Iteration 4482][Wall Clock 423.187575815s] Trained 128 records in 0.101838211 seconds. Throughput is 1256.8956 records/second. Loss is 1.0442034. Sequential266afc8b's hyper parameters: Current learning rate is 2.1829294913774285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33536/60000][Iteration 4483][Wall Clock 423.274161983s] Trained 128 records in 0.086586168 seconds. Throughput is 1478.2961 records/second. Loss is 1.1857033. Sequential266afc8b's hyper parameters: Current learning rate is 2.1824530772588389E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33664/60000][Iteration 4484][Wall Clock 423.355900017s] Trained 128 records in 0.081738034 seconds. Throughput is 1565.9785 records/second. Loss is 1.1134554. Sequential266afc8b's hyper parameters: Current learning rate is 2.181976871045167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33792/60000][Iteration 4485][Wall Clock 423.440493801s] Trained 128 records in 0.084593784 seconds. Throughput is 1513.1136 records/second. Loss is 1.0582762. Sequential266afc8b's hyper parameters: Current learning rate is 2.1815008726003488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 33920/60000][Iteration 4486][Wall Clock 423.524709137s] Trained 128 records in 0.084215336 seconds. Throughput is 1519.9132 records/second. Loss is 1.0685086. Sequential266afc8b's hyper parameters: Current learning rate is 2.1810250817884405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 34048/60000][Iteration 4487][Wall Clock 423.608999344s] Trained 128 records in 0.084290207 seconds. Throughput is 1518.5631 records/second. Loss is 1.0923282. Sequential266afc8b's hyper parameters: Current learning rate is 2.1805494984736154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 34176/60000][Iteration 4488][Wall Clock 423.69402134s] Trained 128 records in 0.085021996 seconds. Throughput is 1505.4928 records/second. Loss is 1.0629373. Sequential266afc8b's hyper parameters: Current learning rate is 2.1800741225201658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 34304/60000][Iteration 4489][Wall Clock 423.775493681s] Trained 128 records in 0.081472341 seconds. Throughput is 1571.0852 records/second. Loss is 1.1039633. Sequential266afc8b's hyper parameters: Current learning rate is 2.179598953792502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:22 INFO  DistriOptimizer$:408 - [Epoch 10 34432/60000][Iteration 4490][Wall Clock 423.856088059s] Trained 128 records in 0.080594378 seconds. Throughput is 1588.2002 records/second. Loss is 1.0752879. Sequential266afc8b's hyper parameters: Current learning rate is 2.1791239921551536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 34560/60000][Iteration 4491][Wall Clock 423.945972914s] Trained 128 records in 0.089884855 seconds. Throughput is 1424.0442 records/second. Loss is 1.1048422. Sequential266afc8b's hyper parameters: Current learning rate is 2.178649237472767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 34688/60000][Iteration 4492][Wall Clock 424.025709254s] Trained 128 records in 0.07973634 seconds. Throughput is 1605.2906 records/second. Loss is 1.1725093. Sequential266afc8b's hyper parameters: Current learning rate is 2.1781746896101065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 34816/60000][Iteration 4493][Wall Clock 424.106512349s] Trained 128 records in 0.080803095 seconds. Throughput is 1584.0977 records/second. Loss is 1.0970407. Sequential266afc8b's hyper parameters: Current learning rate is 2.1777003484320557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 34944/60000][Iteration 4494][Wall Clock 424.192108555s] Trained 128 records in 0.085596206 seconds. Throughput is 1495.3934 records/second. Loss is 1.0911467. Sequential266afc8b's hyper parameters: Current learning rate is 2.1772262138036142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35072/60000][Iteration 4495][Wall Clock 424.275931114s] Trained 128 records in 0.083822559 seconds. Throughput is 1527.0353 records/second. Loss is 1.0610873. Sequential266afc8b's hyper parameters: Current learning rate is 2.1767522855899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35200/60000][Iteration 4496][Wall Clock 424.359341809s] Trained 128 records in 0.083410695 seconds. Throughput is 1534.5754 records/second. Loss is 1.1279639. Sequential266afc8b's hyper parameters: Current learning rate is 2.1762785636561478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35328/60000][Iteration 4497][Wall Clock 424.442373838s] Trained 128 records in 0.083032029 seconds. Throughput is 1541.5739 records/second. Loss is 1.1588964. Sequential266afc8b's hyper parameters: Current learning rate is 2.175805047867711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35456/60000][Iteration 4498][Wall Clock 424.527913988s] Trained 128 records in 0.08554015 seconds. Throughput is 1496.3733 records/second. Loss is 1.1022356. Sequential266afc8b's hyper parameters: Current learning rate is 2.1753317380900588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35584/60000][Iteration 4499][Wall Clock 424.614676074s] Trained 128 records in 0.086762086 seconds. Throughput is 1475.2988 records/second. Loss is 1.1319654. Sequential266afc8b's hyper parameters: Current learning rate is 2.1748586341887777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35712/60000][Iteration 4500][Wall Clock 424.700423422s] Trained 128 records in 0.085747348 seconds. Throughput is 1492.7576 records/second. Loss is 1.1212589. Sequential266afc8b's hyper parameters: Current learning rate is 2.1743857360295715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35840/60000][Iteration 4501][Wall Clock 424.787690056s] Trained 128 records in 0.087266634 seconds. Throughput is 1466.7692 records/second. Loss is 1.0813729. Sequential266afc8b's hyper parameters: Current learning rate is 2.173913043478261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:23 INFO  DistriOptimizer$:408 - [Epoch 10 35968/60000][Iteration 4502][Wall Clock 424.871354462s] Trained 128 records in 0.083664406 seconds. Throughput is 1529.9219 records/second. Loss is 1.1559713. Sequential266afc8b's hyper parameters: Current learning rate is 2.1734405564007825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36096/60000][Iteration 4503][Wall Clock 424.956460589s] Trained 128 records in 0.085106127 seconds. Throughput is 1504.0045 records/second. Loss is 1.0619009. Sequential266afc8b's hyper parameters: Current learning rate is 2.1729682746631898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36224/60000][Iteration 4504][Wall Clock 425.039499762s] Trained 128 records in 0.083039173 seconds. Throughput is 1541.4412 records/second. Loss is 1.1682663. Sequential266afc8b's hyper parameters: Current learning rate is 2.1724961981316532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36352/60000][Iteration 4505][Wall Clock 425.125412966s] Trained 128 records in 0.085913204 seconds. Throughput is 1489.8757 records/second. Loss is 1.174928. Sequential266afc8b's hyper parameters: Current learning rate is 2.172024326672459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36480/60000][Iteration 4506][Wall Clock 425.213055039s] Trained 128 records in 0.087642073 seconds. Throughput is 1460.4857 records/second. Loss is 1.1031654. Sequential266afc8b's hyper parameters: Current learning rate is 2.1715526601520085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36608/60000][Iteration 4507][Wall Clock 425.300514047s] Trained 128 records in 0.087459008 seconds. Throughput is 1463.5428 records/second. Loss is 1.1547616. Sequential266afc8b's hyper parameters: Current learning rate is 2.1710811984368216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36736/60000][Iteration 4508][Wall Clock 425.39114299s] Trained 128 records in 0.090628943 seconds. Throughput is 1412.3523 records/second. Loss is 0.969029. Sequential266afc8b's hyper parameters: Current learning rate is 2.1706099413935315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36864/60000][Iteration 4509][Wall Clock 425.469045821s] Trained 128 records in 0.077902831 seconds. Throughput is 1643.0725 records/second. Loss is 1.1165402. Sequential266afc8b's hyper parameters: Current learning rate is 2.170138888888889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 36992/60000][Iteration 4510][Wall Clock 425.548127363s] Trained 128 records in 0.079081542 seconds. Throughput is 1618.5825 records/second. Loss is 1.0064806. Sequential266afc8b's hyper parameters: Current learning rate is 2.169668040789759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 37120/60000][Iteration 4511][Wall Clock 425.62900377s] Trained 128 records in 0.080876407 seconds. Throughput is 1582.6617 records/second. Loss is 1.0635003. Sequential266afc8b's hyper parameters: Current learning rate is 2.1691973969631235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 37248/60000][Iteration 4512][Wall Clock 425.713911197s] Trained 128 records in 0.084907427 seconds. Throughput is 1507.5242 records/second. Loss is 1.1174623. Sequential266afc8b's hyper parameters: Current learning rate is 2.168726957276079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 37376/60000][Iteration 4513][Wall Clock 425.79804302s] Trained 128 records in 0.084131823 seconds. Throughput is 1521.422 records/second. Loss is 1.152619. Sequential266afc8b's hyper parameters: Current learning rate is 2.1682567215958371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:24 INFO  DistriOptimizer$:408 - [Epoch 10 37504/60000][Iteration 4514][Wall Clock 425.881927141s] Trained 128 records in 0.083884121 seconds. Throughput is 1525.9146 records/second. Loss is 1.1385928. Sequential266afc8b's hyper parameters: Current learning rate is 2.1677866897897247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 37632/60000][Iteration 4515][Wall Clock 425.963726382s] Trained 128 records in 0.081799241 seconds. Throughput is 1564.8068 records/second. Loss is 1.1190711. Sequential266afc8b's hyper parameters: Current learning rate is 2.1673168617251842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 37760/60000][Iteration 4516][Wall Clock 426.046435417s] Trained 128 records in 0.082709035 seconds. Throughput is 1547.5939 records/second. Loss is 1.1266582. Sequential266afc8b's hyper parameters: Current learning rate is 2.1668472372697725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 37888/60000][Iteration 4517][Wall Clock 426.140250431s] Trained 128 records in 0.093815014 seconds. Throughput is 1364.3872 records/second. Loss is 1.1418996. Sequential266afc8b's hyper parameters: Current learning rate is 2.166377816291161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38016/60000][Iteration 4518][Wall Clock 426.222550246s] Trained 128 records in 0.082299815 seconds. Throughput is 1555.2891 records/second. Loss is 1.075393. Sequential266afc8b's hyper parameters: Current learning rate is 2.1659085986571366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38144/60000][Iteration 4519][Wall Clock 426.305698341s] Trained 128 records in 0.083148095 seconds. Throughput is 1539.422 records/second. Loss is 1.123613. Sequential266afc8b's hyper parameters: Current learning rate is 2.1654395842356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38272/60000][Iteration 4520][Wall Clock 426.388030109s] Trained 128 records in 0.082331768 seconds. Throughput is 1554.6854 records/second. Loss is 1.1446751. Sequential266afc8b's hyper parameters: Current learning rate is 2.164970772894566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38400/60000][Iteration 4521][Wall Clock 426.471531514s] Trained 128 records in 0.083501405 seconds. Throughput is 1532.9083 records/second. Loss is 1.1317995. Sequential266afc8b's hyper parameters: Current learning rate is 2.1645021645021645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38528/60000][Iteration 4522][Wall Clock 426.555595324s] Trained 128 records in 0.08406381 seconds. Throughput is 1522.6528 records/second. Loss is 1.0359259. Sequential266afc8b's hyper parameters: Current learning rate is 2.1640337589266391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38656/60000][Iteration 4523][Wall Clock 426.64019434s] Trained 128 records in 0.084599016 seconds. Throughput is 1513.0199 records/second. Loss is 1.0873448. Sequential266afc8b's hyper parameters: Current learning rate is 2.163565556036348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38784/60000][Iteration 4524][Wall Clock 426.720923756s] Trained 128 records in 0.080729416 seconds. Throughput is 1585.5435 records/second. Loss is 1.105809. Sequential266afc8b's hyper parameters: Current learning rate is 2.163097555699762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:25 INFO  DistriOptimizer$:408 - [Epoch 10 38912/60000][Iteration 4525][Wall Clock 426.803030015s] Trained 128 records in 0.082106259 seconds. Throughput is 1558.9554 records/second. Loss is 1.0569972. Sequential266afc8b's hyper parameters: Current learning rate is 2.1626297577854672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39040/60000][Iteration 4526][Wall Clock 426.884893977s] Trained 128 records in 0.081863962 seconds. Throughput is 1563.5696 records/second. Loss is 1.1823995. Sequential266afc8b's hyper parameters: Current learning rate is 2.1621621621621621E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39168/60000][Iteration 4527][Wall Clock 426.967842699s] Trained 128 records in 0.082948722 seconds. Throughput is 1543.1221 records/second. Loss is 1.122518. Sequential266afc8b's hyper parameters: Current learning rate is 2.16169476869866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39296/60000][Iteration 4528][Wall Clock 427.052652321s] Trained 128 records in 0.084809622 seconds. Throughput is 1509.2627 records/second. Loss is 1.1301765. Sequential266afc8b's hyper parameters: Current learning rate is 2.1612275772638857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39424/60000][Iteration 4529][Wall Clock 427.135707575s] Trained 128 records in 0.083055254 seconds. Throughput is 1541.1428 records/second. Loss is 1.0285687. Sequential266afc8b's hyper parameters: Current learning rate is 2.16076058772688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39552/60000][Iteration 4530][Wall Clock 427.220924977s] Trained 128 records in 0.085217402 seconds. Throughput is 1502.0406 records/second. Loss is 1.0788004. Sequential266afc8b's hyper parameters: Current learning rate is 2.1602937999567941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39680/60000][Iteration 4531][Wall Clock 427.303924663s] Trained 128 records in 0.082999686 seconds. Throughput is 1542.1746 records/second. Loss is 1.149085. Sequential266afc8b's hyper parameters: Current learning rate is 2.1598272138228941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39808/60000][Iteration 4532][Wall Clock 427.387118101s] Trained 128 records in 0.083193438 seconds. Throughput is 1538.5829 records/second. Loss is 1.145853. Sequential266afc8b's hyper parameters: Current learning rate is 2.1593608291945585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 39936/60000][Iteration 4533][Wall Clock 427.482205383s] Trained 128 records in 0.095087282 seconds. Throughput is 1346.1316 records/second. Loss is 1.1019168. Sequential266afc8b's hyper parameters: Current learning rate is 2.158894645941278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 40064/60000][Iteration 4534][Wall Clock 427.567088798s] Trained 128 records in 0.084883415 seconds. Throughput is 1507.9507 records/second. Loss is 1.1094687. Sequential266afc8b's hyper parameters: Current learning rate is 2.1584286639326572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 40192/60000][Iteration 4535][Wall Clock 427.649061156s] Trained 128 records in 0.081972358 seconds. Throughput is 1561.502 records/second. Loss is 1.1526241. Sequential266afc8b's hyper parameters: Current learning rate is 2.1579628830384117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 40320/60000][Iteration 4536][Wall Clock 427.730744637s] Trained 128 records in 0.081683481 seconds. Throughput is 1567.0243 records/second. Loss is 1.0831422. Sequential266afc8b's hyper parameters: Current learning rate is 2.157497303128371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:26 INFO  DistriOptimizer$:408 - [Epoch 10 40448/60000][Iteration 4537][Wall Clock 427.819475719s] Trained 128 records in 0.088731082 seconds. Throughput is 1442.561 records/second. Loss is 1.1789416. Sequential266afc8b's hyper parameters: Current learning rate is 2.1570319240724764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 40576/60000][Iteration 4538][Wall Clock 427.907610969s] Trained 128 records in 0.08813525 seconds. Throughput is 1452.3134 records/second. Loss is 1.0578979. Sequential266afc8b's hyper parameters: Current learning rate is 2.1565667457407807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 40704/60000][Iteration 4539][Wall Clock 427.992457349s] Trained 128 records in 0.08484638 seconds. Throughput is 1508.6089 records/second. Loss is 1.1151699. Sequential266afc8b's hyper parameters: Current learning rate is 2.1561017680034496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 40832/60000][Iteration 4540][Wall Clock 428.079428812s] Trained 128 records in 0.086971463 seconds. Throughput is 1471.7472 records/second. Loss is 1.0229384. Sequential266afc8b's hyper parameters: Current learning rate is 2.155636990730761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 40960/60000][Iteration 4541][Wall Clock 428.163250851s] Trained 128 records in 0.083822039 seconds. Throughput is 1527.0447 records/second. Loss is 1.0453963. Sequential266afc8b's hyper parameters: Current learning rate is 2.1551724137931037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41088/60000][Iteration 4542][Wall Clock 428.247821275s] Trained 128 records in 0.084570424 seconds. Throughput is 1513.5315 records/second. Loss is 1.1570383. Sequential266afc8b's hyper parameters: Current learning rate is 2.1547080370609782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41216/60000][Iteration 4543][Wall Clock 428.336699847s] Trained 128 records in 0.088878572 seconds. Throughput is 1440.1671 records/second. Loss is 1.1613598. Sequential266afc8b's hyper parameters: Current learning rate is 2.1542438604049978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41344/60000][Iteration 4544][Wall Clock 428.421037789s] Trained 128 records in 0.084337942 seconds. Throughput is 1517.7036 records/second. Loss is 1.2045523. Sequential266afc8b's hyper parameters: Current learning rate is 2.1537798836958864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41472/60000][Iteration 4545][Wall Clock 428.502067148s] Trained 128 records in 0.081029359 seconds. Throughput is 1579.6744 records/second. Loss is 1.0997273. Sequential266afc8b's hyper parameters: Current learning rate is 2.1533161068044792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41600/60000][Iteration 4546][Wall Clock 428.584531451s] Trained 128 records in 0.082464303 seconds. Throughput is 1552.1868 records/second. Loss is 1.0600393. Sequential266afc8b's hyper parameters: Current learning rate is 2.1528525296017221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41728/60000][Iteration 4547][Wall Clock 428.668550234s] Trained 128 records in 0.084018783 seconds. Throughput is 1523.4689 records/second. Loss is 1.0936998. Sequential266afc8b's hyper parameters: Current learning rate is 2.1523891519586742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41856/60000][Iteration 4548][Wall Clock 428.756756863s] Trained 128 records in 0.088206629 seconds. Throughput is 1451.1382 records/second. Loss is 1.15294. Sequential266afc8b's hyper parameters: Current learning rate is 2.1519259737465033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:27 INFO  DistriOptimizer$:408 - [Epoch 10 41984/60000][Iteration 4549][Wall Clock 428.840345514s] Trained 128 records in 0.083588651 seconds. Throughput is 1531.3083 records/second. Loss is 1.1494185. Sequential266afc8b's hyper parameters: Current learning rate is 2.1514629948364886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42112/60000][Iteration 4550][Wall Clock 428.923630381s] Trained 128 records in 0.083284867 seconds. Throughput is 1536.8938 records/second. Loss is 1.1164727. Sequential266afc8b's hyper parameters: Current learning rate is 2.1510002151000214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42240/60000][Iteration 4551][Wall Clock 429.012682957s] Trained 128 records in 0.089052576 seconds. Throughput is 1437.3531 records/second. Loss is 1.1829399. Sequential266afc8b's hyper parameters: Current learning rate is 2.1505376344086021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42368/60000][Iteration 4552][Wall Clock 429.10112417s] Trained 128 records in 0.088441213 seconds. Throughput is 1447.2891 records/second. Loss is 1.1741045. Sequential266afc8b's hyper parameters: Current learning rate is 2.1500752526338424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42496/60000][Iteration 4553][Wall Clock 429.187733534s] Trained 128 records in 0.086609364 seconds. Throughput is 1477.9003 records/second. Loss is 1.1237687. Sequential266afc8b's hyper parameters: Current learning rate is 2.1496130696474632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42624/60000][Iteration 4554][Wall Clock 429.271890216s] Trained 128 records in 0.084156682 seconds. Throughput is 1520.9724 records/second. Loss is 1.2086227. Sequential266afc8b's hyper parameters: Current learning rate is 2.149151085321298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42752/60000][Iteration 4555][Wall Clock 429.358109353s] Trained 128 records in 0.086219137 seconds. Throughput is 1484.5891 records/second. Loss is 1.1159486. Sequential266afc8b's hyper parameters: Current learning rate is 2.1486892995272884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 42880/60000][Iteration 4556][Wall Clock 429.44306904s] Trained 128 records in 0.084959687 seconds. Throughput is 1506.5969 records/second. Loss is 1.1441034. Sequential266afc8b's hyper parameters: Current learning rate is 2.1482277121374864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 43008/60000][Iteration 4557][Wall Clock 429.528619061s] Trained 128 records in 0.085550021 seconds. Throughput is 1496.2007 records/second. Loss is 1.229794. Sequential266afc8b's hyper parameters: Current learning rate is 2.147766323024055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 43136/60000][Iteration 4558][Wall Clock 429.618467854s] Trained 128 records in 0.089848793 seconds. Throughput is 1424.6157 records/second. Loss is 1.1536602. Sequential266afc8b's hyper parameters: Current learning rate is 2.1473051320592657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 43264/60000][Iteration 4559][Wall Clock 429.697132439s] Trained 128 records in 0.078664585 seconds. Throughput is 1627.1617 records/second. Loss is 1.1222016. Sequential266afc8b's hyper parameters: Current learning rate is 2.1468441391155003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 43392/60000][Iteration 4560][Wall Clock 429.777964602s] Trained 128 records in 0.080832163 seconds. Throughput is 1583.5281 records/second. Loss is 1.0435237. Sequential266afc8b's hyper parameters: Current learning rate is 2.14638334406525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:28 INFO  DistriOptimizer$:408 - [Epoch 10 43520/60000][Iteration 4561][Wall Clock 429.85902225s] Trained 128 records in 0.081057648 seconds. Throughput is 1579.123 records/second. Loss is 1.0195686. Sequential266afc8b's hyper parameters: Current learning rate is 2.1459227467811158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 43648/60000][Iteration 4562][Wall Clock 429.943207453s] Trained 128 records in 0.084185203 seconds. Throughput is 1520.4572 records/second. Loss is 1.217915. Sequential266afc8b's hyper parameters: Current learning rate is 2.145462347135808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 43776/60000][Iteration 4563][Wall Clock 430.025500436s] Trained 128 records in 0.082292983 seconds. Throughput is 1555.4182 records/second. Loss is 1.1600158. Sequential266afc8b's hyper parameters: Current learning rate is 2.1450021450021453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 43904/60000][Iteration 4564][Wall Clock 430.112050724s] Trained 128 records in 0.086550288 seconds. Throughput is 1478.909 records/second. Loss is 1.0430362. Sequential266afc8b's hyper parameters: Current learning rate is 2.1445421402530558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44032/60000][Iteration 4565][Wall Clock 430.194375127s] Trained 128 records in 0.082324403 seconds. Throughput is 1554.8246 records/second. Loss is 1.0575795. Sequential266afc8b's hyper parameters: Current learning rate is 2.144082332761578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44160/60000][Iteration 4566][Wall Clock 430.278571419s] Trained 128 records in 0.084196292 seconds. Throughput is 1520.257 records/second. Loss is 1.0401262. Sequential266afc8b's hyper parameters: Current learning rate is 2.1436227224008576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44288/60000][Iteration 4567][Wall Clock 430.362413992s] Trained 128 records in 0.083842573 seconds. Throughput is 1526.6707 records/second. Loss is 1.0545968. Sequential266afc8b's hyper parameters: Current learning rate is 2.143163309044149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44416/60000][Iteration 4568][Wall Clock 430.455035831s] Trained 128 records in 0.092621839 seconds. Throughput is 1381.9635 records/second. Loss is 1.0810695. Sequential266afc8b's hyper parameters: Current learning rate is 2.1427040925648167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44544/60000][Iteration 4569][Wall Clock 430.537955755s] Trained 128 records in 0.082919924 seconds. Throughput is 1543.658 records/second. Loss is 1.1944641. Sequential266afc8b's hyper parameters: Current learning rate is 2.1422450728363326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44672/60000][Iteration 4570][Wall Clock 430.611326391s] Trained 128 records in 0.073370636 seconds. Throughput is 1744.5671 records/second. Loss is 1.0574642. Sequential266afc8b's hyper parameters: Current learning rate is 2.141786249732277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44800/60000][Iteration 4571][Wall Clock 430.695754982s] Trained 128 records in 0.084428591 seconds. Throughput is 1516.0741 records/second. Loss is 1.1398958. Sequential266afc8b's hyper parameters: Current learning rate is 2.1413276231263382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:29 INFO  DistriOptimizer$:408 - [Epoch 10 44928/60000][Iteration 4572][Wall Clock 430.777739767s] Trained 128 records in 0.081984785 seconds. Throughput is 1561.2653 records/second. Loss is 0.98925877. Sequential266afc8b's hyper parameters: Current learning rate is 2.1408691928923143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45056/60000][Iteration 4573][Wall Clock 430.862219341s] Trained 128 records in 0.084479574 seconds. Throughput is 1515.1592 records/second. Loss is 1.0300467. Sequential266afc8b's hyper parameters: Current learning rate is 2.1404109589041097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45184/60000][Iteration 4574][Wall Clock 430.946265597s] Trained 128 records in 0.084046256 seconds. Throughput is 1522.9708 records/second. Loss is 1.1763173. Sequential266afc8b's hyper parameters: Current learning rate is 2.139952921035737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45312/60000][Iteration 4575][Wall Clock 431.03239956s] Trained 128 records in 0.086133963 seconds. Throughput is 1486.0573 records/second. Loss is 1.1078657. Sequential266afc8b's hyper parameters: Current learning rate is 2.139495079161318E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45440/60000][Iteration 4576][Wall Clock 431.118515493s] Trained 128 records in 0.086115933 seconds. Throughput is 1486.3684 records/second. Loss is 1.2534866. Sequential266afc8b's hyper parameters: Current learning rate is 2.1390374331550804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45568/60000][Iteration 4577][Wall Clock 431.205050549s] Trained 128 records in 0.086535056 seconds. Throughput is 1479.1693 records/second. Loss is 1.1289164. Sequential266afc8b's hyper parameters: Current learning rate is 2.1385799828913603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45696/60000][Iteration 4578][Wall Clock 431.290839205s] Trained 128 records in 0.085788656 seconds. Throughput is 1492.0388 records/second. Loss is 1.2092216. Sequential266afc8b's hyper parameters: Current learning rate is 2.1381227282446012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45824/60000][Iteration 4579][Wall Clock 431.379913895s] Trained 128 records in 0.08907469 seconds. Throughput is 1436.9962 records/second. Loss is 1.1210437. Sequential266afc8b's hyper parameters: Current learning rate is 2.1376656690893543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 45952/60000][Iteration 4580][Wall Clock 431.463943354s] Trained 128 records in 0.084029459 seconds. Throughput is 1523.2753 records/second. Loss is 1.1026912. Sequential266afc8b's hyper parameters: Current learning rate is 2.137208805300278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 46080/60000][Iteration 4581][Wall Clock 431.549069388s] Trained 128 records in 0.085126034 seconds. Throughput is 1503.6528 records/second. Loss is 1.1359593. Sequential266afc8b's hyper parameters: Current learning rate is 2.1367521367521365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 46208/60000][Iteration 4582][Wall Clock 431.631495321s] Trained 128 records in 0.082425933 seconds. Throughput is 1552.9094 records/second. Loss is 1.0872358. Sequential266afc8b's hyper parameters: Current learning rate is 2.1362956633198035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 46336/60000][Iteration 4583][Wall Clock 431.718076305s] Trained 128 records in 0.086580984 seconds. Throughput is 1478.3846 records/second. Loss is 1.1855224. Sequential266afc8b's hyper parameters: Current learning rate is 2.1358393848782572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:30 INFO  DistriOptimizer$:408 - [Epoch 10 46464/60000][Iteration 4584][Wall Clock 431.798645801s] Trained 128 records in 0.080569496 seconds. Throughput is 1588.6906 records/second. Loss is 1.1784421. Sequential266afc8b's hyper parameters: Current learning rate is 2.135383301302584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 46592/60000][Iteration 4585][Wall Clock 431.878751499s] Trained 128 records in 0.080105698 seconds. Throughput is 1597.8888 records/second. Loss is 1.1960609. Sequential266afc8b's hyper parameters: Current learning rate is 2.134927412467976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 46720/60000][Iteration 4586][Wall Clock 431.957831807s] Trained 128 records in 0.079080308 seconds. Throughput is 1618.6078 records/second. Loss is 1.1976438. Sequential266afc8b's hyper parameters: Current learning rate is 2.1344717182497332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 46848/60000][Iteration 4587][Wall Clock 432.043367813s] Trained 128 records in 0.085536006 seconds. Throughput is 1496.4459 records/second. Loss is 1.1186634. Sequential266afc8b's hyper parameters: Current learning rate is 2.134016218523261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 46976/60000][Iteration 4588][Wall Clock 432.12827484s] Trained 128 records in 0.084907027 seconds. Throughput is 1507.5314 records/second. Loss is 1.0844293. Sequential266afc8b's hyper parameters: Current learning rate is 2.133560913164071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47104/60000][Iteration 4589][Wall Clock 432.214920994s] Trained 128 records in 0.086646154 seconds. Throughput is 1477.2727 records/second. Loss is 1.0687162. Sequential266afc8b's hyper parameters: Current learning rate is 2.1331058020477816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47232/60000][Iteration 4590][Wall Clock 432.301501316s] Trained 128 records in 0.086580322 seconds. Throughput is 1478.396 records/second. Loss is 1.1706254. Sequential266afc8b's hyper parameters: Current learning rate is 2.1326508850501172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47360/60000][Iteration 4591][Wall Clock 432.385894566s] Trained 128 records in 0.08439325 seconds. Throughput is 1516.709 records/second. Loss is 1.1357899. Sequential266afc8b's hyper parameters: Current learning rate is 2.1321961620469085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47488/60000][Iteration 4592][Wall Clock 432.470609074s] Trained 128 records in 0.084714508 seconds. Throughput is 1510.9573 records/second. Loss is 1.0962629. Sequential266afc8b's hyper parameters: Current learning rate is 2.1317416329140907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47616/60000][Iteration 4593][Wall Clock 432.553905291s] Trained 128 records in 0.083296217 seconds. Throughput is 1536.6844 records/second. Loss is 1.1452295. Sequential266afc8b's hyper parameters: Current learning rate is 2.1312872975277067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47744/60000][Iteration 4594][Wall Clock 432.643511966s] Trained 128 records in 0.089606675 seconds. Throughput is 1428.4651 records/second. Loss is 1.1777675. Sequential266afc8b's hyper parameters: Current learning rate is 2.1308331557639038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 47872/60000][Iteration 4595][Wall Clock 432.72540191s] Trained 128 records in 0.081889944 seconds. Throughput is 1563.0735 records/second. Loss is 1.2195884. Sequential266afc8b's hyper parameters: Current learning rate is 2.130379207498935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:31 INFO  DistriOptimizer$:408 - [Epoch 10 48000/60000][Iteration 4596][Wall Clock 432.801587705s] Trained 128 records in 0.076185795 seconds. Throughput is 1680.1033 records/second. Loss is 1.1227952. Sequential266afc8b's hyper parameters: Current learning rate is 2.1299254526091586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48128/60000][Iteration 4597][Wall Clock 432.886763228s] Trained 128 records in 0.085175523 seconds. Throughput is 1502.7792 records/second. Loss is 1.0064886. Sequential266afc8b's hyper parameters: Current learning rate is 2.1294718909710392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48256/60000][Iteration 4598][Wall Clock 432.971823197s] Trained 128 records in 0.085059969 seconds. Throughput is 1504.8207 records/second. Loss is 1.1121255. Sequential266afc8b's hyper parameters: Current learning rate is 2.1290185224611454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48384/60000][Iteration 4599][Wall Clock 433.054208893s] Trained 128 records in 0.082385696 seconds. Throughput is 1553.6677 records/second. Loss is 1.0361121. Sequential266afc8b's hyper parameters: Current learning rate is 2.1285653469561513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48512/60000][Iteration 4600][Wall Clock 433.138127184s] Trained 128 records in 0.083918291 seconds. Throughput is 1525.2932 records/second. Loss is 1.1794258. Sequential266afc8b's hyper parameters: Current learning rate is 2.1281123643328368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48640/60000][Iteration 4601][Wall Clock 433.22251817s] Trained 128 records in 0.084390986 seconds. Throughput is 1516.7498 records/second. Loss is 1.1674296. Sequential266afc8b's hyper parameters: Current learning rate is 2.127659574468085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48768/60000][Iteration 4602][Wall Clock 433.30578149s] Trained 128 records in 0.08326332 seconds. Throughput is 1537.2915 records/second. Loss is 1.0907158. Sequential266afc8b's hyper parameters: Current learning rate is 2.1272069772388855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 48896/60000][Iteration 4603][Wall Clock 433.38800485s] Trained 128 records in 0.08222336 seconds. Throughput is 1556.7351 records/second. Loss is 1.1510845. Sequential266afc8b's hyper parameters: Current learning rate is 2.1267545725223307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 49024/60000][Iteration 4604][Wall Clock 433.472576891s] Trained 128 records in 0.084572041 seconds. Throughput is 1513.5026 records/second. Loss is 1.155732. Sequential266afc8b's hyper parameters: Current learning rate is 2.1263023601956197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 49152/60000][Iteration 4605][Wall Clock 433.555620833s] Trained 128 records in 0.083043942 seconds. Throughput is 1541.3527 records/second. Loss is 1.2273141. Sequential266afc8b's hyper parameters: Current learning rate is 2.1258503401360546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 49280/60000][Iteration 4606][Wall Clock 433.639235466s] Trained 128 records in 0.083614633 seconds. Throughput is 1530.8325 records/second. Loss is 1.1546226. Sequential266afc8b's hyper parameters: Current learning rate is 2.1253985122210412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 49408/60000][Iteration 4607][Wall Clock 433.721916131s] Trained 128 records in 0.082680665 seconds. Throughput is 1548.125 records/second. Loss is 1.0723445. Sequential266afc8b's hyper parameters: Current learning rate is 2.1249468763280918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:32 INFO  DistriOptimizer$:408 - [Epoch 10 49536/60000][Iteration 4608][Wall Clock 433.808840503s] Trained 128 records in 0.086924372 seconds. Throughput is 1472.5444 records/second. Loss is 1.1835074. Sequential266afc8b's hyper parameters: Current learning rate is 2.1244954323348204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 49664/60000][Iteration 4609][Wall Clock 433.891587849s] Trained 128 records in 0.082747346 seconds. Throughput is 1546.8773 records/second. Loss is 1.257906. Sequential266afc8b's hyper parameters: Current learning rate is 2.1240441801189465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 49792/60000][Iteration 4610][Wall Clock 433.969654536s] Trained 128 records in 0.078066687 seconds. Throughput is 1639.6239 records/second. Loss is 1.1528652. Sequential266afc8b's hyper parameters: Current learning rate is 2.1235931195582924E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 49920/60000][Iteration 4611][Wall Clock 434.049991656s] Trained 128 records in 0.08033712 seconds. Throughput is 1593.2859 records/second. Loss is 1.136453. Sequential266afc8b's hyper parameters: Current learning rate is 2.1231422505307856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50048/60000][Iteration 4612][Wall Clock 434.136622448s] Trained 128 records in 0.086630792 seconds. Throughput is 1477.5347 records/second. Loss is 1.1422676. Sequential266afc8b's hyper parameters: Current learning rate is 2.1226915729144556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50176/60000][Iteration 4613][Wall Clock 434.224136701s] Trained 128 records in 0.087514253 seconds. Throughput is 1462.6189 records/second. Loss is 1.226425. Sequential266afc8b's hyper parameters: Current learning rate is 2.1222410865874366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50304/60000][Iteration 4614][Wall Clock 434.307080899s] Trained 128 records in 0.082944198 seconds. Throughput is 1543.2062 records/second. Loss is 1.1948686. Sequential266afc8b's hyper parameters: Current learning rate is 2.121790791427965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50432/60000][Iteration 4615][Wall Clock 434.393727874s] Trained 128 records in 0.086646975 seconds. Throughput is 1477.2588 records/second. Loss is 1.005415. Sequential266afc8b's hyper parameters: Current learning rate is 2.1213406873143826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50560/60000][Iteration 4616][Wall Clock 434.479805559s] Trained 128 records in 0.086077685 seconds. Throughput is 1487.0289 records/second. Loss is 1.0897514. Sequential266afc8b's hyper parameters: Current learning rate is 2.1208907741251327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50688/60000][Iteration 4617][Wall Clock 434.564664849s] Trained 128 records in 0.08485929 seconds. Throughput is 1508.3794 records/second. Loss is 1.2101012. Sequential266afc8b's hyper parameters: Current learning rate is 2.1204410517387616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50816/60000][Iteration 4618][Wall Clock 434.650973862s] Trained 128 records in 0.086309013 seconds. Throughput is 1483.0432 records/second. Loss is 1.0936661. Sequential266afc8b's hyper parameters: Current learning rate is 2.1199915200339198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 50944/60000][Iteration 4619][Wall Clock 434.734338324s] Trained 128 records in 0.083364462 seconds. Throughput is 1535.4264 records/second. Loss is 1.1427519. Sequential266afc8b's hyper parameters: Current learning rate is 2.11954217888936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:33 INFO  DistriOptimizer$:408 - [Epoch 10 51072/60000][Iteration 4620][Wall Clock 434.826518558s] Trained 128 records in 0.092180234 seconds. Throughput is 1388.584 records/second. Loss is 1.1886753. Sequential266afc8b's hyper parameters: Current learning rate is 2.1190930281839374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51200/60000][Iteration 4621][Wall Clock 434.904568121s] Trained 128 records in 0.078049563 seconds. Throughput is 1639.9835 records/second. Loss is 1.1677865. Sequential266afc8b's hyper parameters: Current learning rate is 2.11864406779661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51328/60000][Iteration 4622][Wall Clock 434.987143779s] Trained 128 records in 0.082575658 seconds. Throughput is 1550.0936 records/second. Loss is 1.2108831. Sequential266afc8b's hyper parameters: Current learning rate is 2.1181952976064393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51456/60000][Iteration 4623][Wall Clock 435.073242049s] Trained 128 records in 0.08609827 seconds. Throughput is 1486.6733 records/second. Loss is 1.0864142. Sequential266afc8b's hyper parameters: Current learning rate is 2.117746717492588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51584/60000][Iteration 4624][Wall Clock 435.155324189s] Trained 128 records in 0.08208214 seconds. Throughput is 1559.4136 records/second. Loss is 1.1087352. Sequential266afc8b's hyper parameters: Current learning rate is 2.1172983273343211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51712/60000][Iteration 4625][Wall Clock 435.240045068s] Trained 128 records in 0.084720879 seconds. Throughput is 1510.8436 records/second. Loss is 1.0736922. Sequential266afc8b's hyper parameters: Current learning rate is 2.1168501270110075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51840/60000][Iteration 4626][Wall Clock 435.323292655s] Trained 128 records in 0.083247587 seconds. Throughput is 1537.5822 records/second. Loss is 1.104405. Sequential266afc8b's hyper parameters: Current learning rate is 2.1164021164021165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 51968/60000][Iteration 4627][Wall Clock 435.405618612s] Trained 128 records in 0.082325957 seconds. Throughput is 1554.7952 records/second. Loss is 1.1198965. Sequential266afc8b's hyper parameters: Current learning rate is 2.1159542953872197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 52096/60000][Iteration 4628][Wall Clock 435.489757326s] Trained 128 records in 0.084138714 seconds. Throughput is 1521.2974 records/second. Loss is 1.1666033. Sequential266afc8b's hyper parameters: Current learning rate is 2.115506663845991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 52224/60000][Iteration 4629][Wall Clock 435.574093632s] Trained 128 records in 0.084336306 seconds. Throughput is 1517.7332 records/second. Loss is 1.115297. Sequential266afc8b's hyper parameters: Current learning rate is 2.1150592216582064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 52352/60000][Iteration 4630][Wall Clock 435.659665583s] Trained 128 records in 0.085571951 seconds. Throughput is 1495.8173 records/second. Loss is 1.1039592. Sequential266afc8b's hyper parameters: Current learning rate is 2.114611968703743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:34 INFO  DistriOptimizer$:408 - [Epoch 10 52480/60000][Iteration 4631][Wall Clock 435.745558088s] Trained 128 records in 0.085892505 seconds. Throughput is 1490.2347 records/second. Loss is 1.0452812. Sequential266afc8b's hyper parameters: Current learning rate is 2.1141649048625792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 52608/60000][Iteration 4632][Wall Clock 435.8372741s] Trained 128 records in 0.091716012 seconds. Throughput is 1395.6123 records/second. Loss is 1.1463021. Sequential266afc8b's hyper parameters: Current learning rate is 2.113718030014796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 52736/60000][Iteration 4633][Wall Clock 435.924452413s] Trained 128 records in 0.087178313 seconds. Throughput is 1468.2551 records/second. Loss is 1.2027518. Sequential266afc8b's hyper parameters: Current learning rate is 2.113271344040575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 52864/60000][Iteration 4634][Wall Clock 436.009046124s] Trained 128 records in 0.084593711 seconds. Throughput is 1513.1147 records/second. Loss is 1.0653971. Sequential266afc8b's hyper parameters: Current learning rate is 2.1128248468201986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 52992/60000][Iteration 4635][Wall Clock 436.089042558s] Trained 128 records in 0.079996434 seconds. Throughput is 1600.0713 records/second. Loss is 1.0435102. Sequential266afc8b's hyper parameters: Current learning rate is 2.1123785382340515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53120/60000][Iteration 4636][Wall Clock 436.175263949s] Trained 128 records in 0.086221391 seconds. Throughput is 1484.5504 records/second. Loss is 1.0215122. Sequential266afc8b's hyper parameters: Current learning rate is 2.1119324181626187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53248/60000][Iteration 4637][Wall Clock 436.261391759s] Trained 128 records in 0.08612781 seconds. Throughput is 1486.1635 records/second. Loss is 1.1321193. Sequential266afc8b's hyper parameters: Current learning rate is 2.1114864864864866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53376/60000][Iteration 4638][Wall Clock 436.34395707s] Trained 128 records in 0.082565311 seconds. Throughput is 1550.288 records/second. Loss is 1.2132199. Sequential266afc8b's hyper parameters: Current learning rate is 2.1110407430863416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53504/60000][Iteration 4639][Wall Clock 436.425999659s] Trained 128 records in 0.082042589 seconds. Throughput is 1560.1653 records/second. Loss is 1.1190367. Sequential266afc8b's hyper parameters: Current learning rate is 2.1105951878429716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53632/60000][Iteration 4640][Wall Clock 436.51452876s] Trained 128 records in 0.088529101 seconds. Throughput is 1445.8522 records/second. Loss is 1.174252. Sequential266afc8b's hyper parameters: Current learning rate is 2.1101498206372652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53760/60000][Iteration 4641][Wall Clock 436.596572803s] Trained 128 records in 0.082044043 seconds. Throughput is 1560.1377 records/second. Loss is 1.048507. Sequential266afc8b's hyper parameters: Current learning rate is 2.109704641350211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 53888/60000][Iteration 4642][Wall Clock 436.680902959s] Trained 128 records in 0.084330156 seconds. Throughput is 1517.8438 records/second. Loss is 1.1388708. Sequential266afc8b's hyper parameters: Current learning rate is 2.109259649862898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:35 INFO  DistriOptimizer$:408 - [Epoch 10 54016/60000][Iteration 4643][Wall Clock 436.768910415s] Trained 128 records in 0.088007456 seconds. Throughput is 1454.4222 records/second. Loss is 1.0719141. Sequential266afc8b's hyper parameters: Current learning rate is 2.1088148460565162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54144/60000][Iteration 4644][Wall Clock 436.85825618s] Trained 128 records in 0.089345765 seconds. Throughput is 1432.6364 records/second. Loss is 1.0682498. Sequential266afc8b's hyper parameters: Current learning rate is 2.108370229812355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54272/60000][Iteration 4645][Wall Clock 436.944556726s] Trained 128 records in 0.086300546 seconds. Throughput is 1483.1888 records/second. Loss is 1.1402032. Sequential266afc8b's hyper parameters: Current learning rate is 2.1079258010118045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54400/60000][Iteration 4646][Wall Clock 437.035869488s] Trained 128 records in 0.091312762 seconds. Throughput is 1401.7756 records/second. Loss is 1.0244907. Sequential266afc8b's hyper parameters: Current learning rate is 2.107481559536354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54528/60000][Iteration 4647][Wall Clock 437.114858186s] Trained 128 records in 0.078988698 seconds. Throughput is 1620.485 records/second. Loss is 1.129039. Sequential266afc8b's hyper parameters: Current learning rate is 2.1070375052675939E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54656/60000][Iteration 4648][Wall Clock 437.190550339s] Trained 128 records in 0.075692153 seconds. Throughput is 1691.0603 records/second. Loss is 1.1481689. Sequential266afc8b's hyper parameters: Current learning rate is 2.106593638087213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54784/60000][Iteration 4649][Wall Clock 437.275325717s] Trained 128 records in 0.084775378 seconds. Throughput is 1509.8723 records/second. Loss is 1.1981938. Sequential266afc8b's hyper parameters: Current learning rate is 2.1061499578770007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 54912/60000][Iteration 4650][Wall Clock 437.359769082s] Trained 128 records in 0.084443365 seconds. Throughput is 1515.8088 records/second. Loss is 1.1410036. Sequential266afc8b's hyper parameters: Current learning rate is 2.105706464518846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 55040/60000][Iteration 4651][Wall Clock 437.446504115s] Trained 128 records in 0.086735033 seconds. Throughput is 1475.7589 records/second. Loss is 1.1891283. Sequential266afc8b's hyper parameters: Current learning rate is 2.105263157894737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 55168/60000][Iteration 4652][Wall Clock 437.52909349s] Trained 128 records in 0.082589375 seconds. Throughput is 1549.8362 records/second. Loss is 1.0501525. Sequential266afc8b's hyper parameters: Current learning rate is 2.104820037886761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 55296/60000][Iteration 4653][Wall Clock 437.613805059s] Trained 128 records in 0.084711569 seconds. Throughput is 1511.0098 records/second. Loss is 1.1855174. Sequential266afc8b's hyper parameters: Current learning rate is 2.1043771043771043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 55424/60000][Iteration 4654][Wall Clock 437.701289718s] Trained 128 records in 0.087484659 seconds. Throughput is 1463.1136 records/second. Loss is 1.1982863. Sequential266afc8b's hyper parameters: Current learning rate is 2.1039343572480537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:36 INFO  DistriOptimizer$:408 - [Epoch 10 55552/60000][Iteration 4655][Wall Clock 437.784020318s] Trained 128 records in 0.0827306 seconds. Throughput is 1547.1906 records/second. Loss is 1.1149904. Sequential266afc8b's hyper parameters: Current learning rate is 2.1034917963819942E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 55680/60000][Iteration 4656][Wall Clock 437.867601619s] Trained 128 records in 0.083581301 seconds. Throughput is 1531.4431 records/second. Loss is 1.0274795. Sequential266afc8b's hyper parameters: Current learning rate is 2.103049421661409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 55808/60000][Iteration 4657][Wall Clock 437.951835823s] Trained 128 records in 0.084234204 seconds. Throughput is 1519.5728 records/second. Loss is 1.2388082. Sequential266afc8b's hyper parameters: Current learning rate is 2.1026072329688813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 55936/60000][Iteration 4658][Wall Clock 438.034370839s] Trained 128 records in 0.082535016 seconds. Throughput is 1550.8569 records/second. Loss is 1.2370834. Sequential266afc8b's hyper parameters: Current learning rate is 2.1021652301870928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56064/60000][Iteration 4659][Wall Clock 438.118041719s] Trained 128 records in 0.08367088 seconds. Throughput is 1529.8035 records/second. Loss is 1.1617885. Sequential266afc8b's hyper parameters: Current learning rate is 2.101723413198823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56192/60000][Iteration 4660][Wall Clock 438.197884989s] Trained 128 records in 0.07984327 seconds. Throughput is 1603.1407 records/second. Loss is 1.0282108. Sequential266afc8b's hyper parameters: Current learning rate is 2.101281781886951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56320/60000][Iteration 4661][Wall Clock 438.286270428s] Trained 128 records in 0.088385439 seconds. Throughput is 1448.2023 records/second. Loss is 1.1312104. Sequential266afc8b's hyper parameters: Current learning rate is 2.1008403361344536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56448/60000][Iteration 4662][Wall Clock 438.373646658s] Trained 128 records in 0.08737623 seconds. Throughput is 1464.9293 records/second. Loss is 1.1052989. Sequential266afc8b's hyper parameters: Current learning rate is 2.1003990758244068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56576/60000][Iteration 4663][Wall Clock 438.46651285s] Trained 128 records in 0.092866192 seconds. Throughput is 1378.3273 records/second. Loss is 1.0085995. Sequential266afc8b's hyper parameters: Current learning rate is 2.0999580008399833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56704/60000][Iteration 4664][Wall Clock 438.550626062s] Trained 128 records in 0.084113212 seconds. Throughput is 1521.7585 records/second. Loss is 1.1173751. Sequential266afc8b's hyper parameters: Current learning rate is 2.099517111064455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56832/60000][Iteration 4665][Wall Clock 438.637213731s] Trained 128 records in 0.086587669 seconds. Throughput is 1478.2705 records/second. Loss is 1.0295111. Sequential266afc8b's hyper parameters: Current learning rate is 2.0990764063811922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 56960/60000][Iteration 4666][Wall Clock 438.720687803s] Trained 128 records in 0.083474072 seconds. Throughput is 1533.4103 records/second. Loss is 1.1011599. Sequential266afc8b's hyper parameters: Current learning rate is 2.0986358866736623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:37 INFO  DistriOptimizer$:408 - [Epoch 10 57088/60000][Iteration 4667][Wall Clock 438.805184375s] Trained 128 records in 0.084496572 seconds. Throughput is 1514.8544 records/second. Loss is 1.2238457. Sequential266afc8b's hyper parameters: Current learning rate is 2.09819555182543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57216/60000][Iteration 4668][Wall Clock 438.892275628s] Trained 128 records in 0.087091253 seconds. Throughput is 1469.7228 records/second. Loss is 1.0981196. Sequential266afc8b's hyper parameters: Current learning rate is 2.0977554017201594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57344/60000][Iteration 4669][Wall Clock 438.980454816s] Trained 128 records in 0.088179188 seconds. Throughput is 1451.5897 records/second. Loss is 0.96028113. Sequential266afc8b's hyper parameters: Current learning rate is 2.0973154362416107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57472/60000][Iteration 4670][Wall Clock 439.06660472s] Trained 128 records in 0.086149904 seconds. Throughput is 1485.7823 records/second. Loss is 1.1106158. Sequential266afc8b's hyper parameters: Current learning rate is 2.0968756552736424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57600/60000][Iteration 4671][Wall Clock 439.153507618s] Trained 128 records in 0.086902898 seconds. Throughput is 1472.9082 records/second. Loss is 1.1213957. Sequential266afc8b's hyper parameters: Current learning rate is 2.0964360587002095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57728/60000][Iteration 4672][Wall Clock 439.244286795s] Trained 128 records in 0.090779177 seconds. Throughput is 1410.015 records/second. Loss is 1.1555414. Sequential266afc8b's hyper parameters: Current learning rate is 2.0959966464053657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57856/60000][Iteration 4673][Wall Clock 439.326319768s] Trained 128 records in 0.082032973 seconds. Throughput is 1560.3483 records/second. Loss is 1.1431402. Sequential266afc8b's hyper parameters: Current learning rate is 2.0955574182732607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 57984/60000][Iteration 4674][Wall Clock 439.412171737s] Trained 128 records in 0.085851969 seconds. Throughput is 1490.9385 records/second. Loss is 1.0702031. Sequential266afc8b's hyper parameters: Current learning rate is 2.0951183741881415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 58112/60000][Iteration 4675][Wall Clock 439.497056632s] Trained 128 records in 0.084884895 seconds. Throughput is 1507.9243 records/second. Loss is 1.1952955. Sequential266afc8b's hyper parameters: Current learning rate is 2.0946795140343527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 58240/60000][Iteration 4676][Wall Clock 439.580954081s] Trained 128 records in 0.083897449 seconds. Throughput is 1525.6721 records/second. Loss is 1.0791063. Sequential266afc8b's hyper parameters: Current learning rate is 2.094240837696335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 58368/60000][Iteration 4677][Wall Clock 439.667312403s] Trained 128 records in 0.086358322 seconds. Throughput is 1482.1964 records/second. Loss is 1.1402476. Sequential266afc8b's hyper parameters: Current learning rate is 2.0938023450586265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:38 INFO  DistriOptimizer$:408 - [Epoch 10 58496/60000][Iteration 4678][Wall Clock 439.755972268s] Trained 128 records in 0.088659865 seconds. Throughput is 1443.7197 records/second. Loss is 1.1407382. Sequential266afc8b's hyper parameters: Current learning rate is 2.0933640360058613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 58624/60000][Iteration 4679][Wall Clock 439.84385082s] Trained 128 records in 0.087878552 seconds. Throughput is 1456.5555 records/second. Loss is 1.0682259. Sequential266afc8b's hyper parameters: Current learning rate is 2.092925910422771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 58752/60000][Iteration 4680][Wall Clock 439.931482875s] Trained 128 records in 0.087632055 seconds. Throughput is 1460.6527 records/second. Loss is 1.1526304. Sequential266afc8b's hyper parameters: Current learning rate is 2.092487968194183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 58880/60000][Iteration 4681][Wall Clock 440.019653875s] Trained 128 records in 0.088171 seconds. Throughput is 1451.7245 records/second. Loss is 1.0193752. Sequential266afc8b's hyper parameters: Current learning rate is 2.0920502092050208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59008/60000][Iteration 4682][Wall Clock 440.105274212s] Trained 128 records in 0.085620337 seconds. Throughput is 1494.9719 records/second. Loss is 1.0952963. Sequential266afc8b's hyper parameters: Current learning rate is 2.0916126333403052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59136/60000][Iteration 4683][Wall Clock 440.204417403s] Trained 128 records in 0.099143191 seconds. Throughput is 1291.0619 records/second. Loss is 1.2169085. Sequential266afc8b's hyper parameters: Current learning rate is 2.0911752404851526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59264/60000][Iteration 4684][Wall Clock 440.289635434s] Trained 128 records in 0.085218031 seconds. Throughput is 1502.0294 records/second. Loss is 1.0851792. Sequential266afc8b's hyper parameters: Current learning rate is 2.0907380305247754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59392/60000][Iteration 4685][Wall Clock 440.369188664s] Trained 128 records in 0.07955323 seconds. Throughput is 1608.9856 records/second. Loss is 1.0988731. Sequential266afc8b's hyper parameters: Current learning rate is 2.0903010033444816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59520/60000][Iteration 4686][Wall Clock 440.45407438s] Trained 128 records in 0.084885716 seconds. Throughput is 1507.9098 records/second. Loss is 1.2371417. Sequential266afc8b's hyper parameters: Current learning rate is 2.089864158829676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59648/60000][Iteration 4687][Wall Clock 440.538741597s] Trained 128 records in 0.084667217 seconds. Throughput is 1511.8011 records/second. Loss is 1.0994517. Sequential266afc8b's hyper parameters: Current learning rate is 2.089427496865859E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59776/60000][Iteration 4688][Wall Clock 440.623384588s] Trained 128 records in 0.084642991 seconds. Throughput is 1512.2339 records/second. Loss is 1.1492333. Sequential266afc8b's hyper parameters: Current learning rate is 2.0889910173386257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 59904/60000][Iteration 4689][Wall Clock 440.709263035s] Trained 128 records in 0.085878447 seconds. Throughput is 1490.4788 records/second. Loss is 1.0567211. Sequential266afc8b's hyper parameters: Current learning rate is 2.0885547201336674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:408 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 440.790874517s] Trained 128 records in 0.081611482 seconds. Throughput is 1568.4067 records/second. Loss is 1.1026897. Sequential266afc8b's hyper parameters: Current learning rate is 2.0881186051367718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 08:25:39 INFO  DistriOptimizer$:452 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 440.790874517s] Epoch finished. Wall clock time is 441914.230537 ms
2019-10-15 08:25:40 INFO  DistriOptimizer$:111 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 440.790874517s] Validate model...
2019-10-15 08:25:40 INFO  DistriOptimizer$:178 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 440.790874517s] validate model throughput is 12290.534 records/second
2019-10-15 08:25:40 INFO  DistriOptimizer$:181 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 440.790874517s] Top1Accuracy is Accuracy(correct: 7585, count: 10000, accuracy: 0.7585)
2019-10-15 08:25:40 INFO  DistriOptimizer$:221 - [Wall Clock 441.914230537s] Save model to /tmp/lenet5/20191015_081817
2019-10-15 08:25:40 INFO  DistriOptimizer$:226 - [Wall Clock 441.914230537s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@396d26c1 to /tmp/lenet5/20191015_081817
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.75830000639, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.97990000248, total_num: 10000, method: Top5Accuracy
Evaluated result: 1.09394180775, total_num: 157, method: Loss
