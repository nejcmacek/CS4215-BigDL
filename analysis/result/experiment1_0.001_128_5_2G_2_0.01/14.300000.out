2019-10-15 20:04:12 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-15 20:04:13 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-15 20:04:13 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-15 20:04:13 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-15 20:04:13 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-15 20:04:13 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-15 20:04:13 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-15 20:04:13 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-15 20:04:14 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 33713.
2019-10-15 20:04:14 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-15 20:04:14 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-15 20:04:14 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-15 20:04:14 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-15 20:04:14 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-b5281edb-35a0-45f6-947c-55c5d31f1977
2019-10-15 20:04:14 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-15 20:04:14 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-15 20:04:14 INFO  log:192 - Logging initialized @3742ms
2019-10-15 20:04:14 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-15 20:04:14 INFO  Server:414 - Started @3882ms
2019-10-15 20:04:14 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-10-15 20:04:14 INFO  AbstractConnector:278 - Started ServerConnector@681c4ccb{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2019-10-15 20:04:14 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@670dad52{/jobs,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7902b1ec{/jobs/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53611a85{/jobs/job,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@166a542c{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a8b1adc{/stages,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21e5823a{/stages/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63778768{/stages/stage,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@87e710f{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@576debaf{/stages/pool,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@33d13dc8{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@8d3fd1a{/storage,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@735e1306{/storage/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4bd6ae51{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7153e59e{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@667fed83{/environment,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65ba1469{/environment/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1be08aa9{/executors,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75f1e35e{/executors/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cfb0b96{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59d7433c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@467d3f6d{/static,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f54d849{/,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5adace8f{/api,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65c0cde9{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22e54949{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-15 20:04:14 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4041
2019-10-15 20:04:14 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:33713/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571169854845
2019-10-15 20:04:14 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:33713/files/lenet5.py with timestamp 1571169854902
2019-10-15 20:04:14 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-c09fc66f-dc67-456c-bbde-a4e5be42a743/userFiles-d9034a1a-24f1-4f8d-a3dc-ed2eed191f63/lenet5.py
2019-10-15 20:04:14 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:33713/files/bigdl-0.8.0-python-api.zip with timestamp 1571169854924
2019-10-15 20:04:14 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-c09fc66f-dc67-456c-bbde-a4e5be42a743/userFiles-d9034a1a-24f1-4f8d-a3dc-ed2eed191f63/bigdl-0.8.0-python-api.zip
2019-10-15 20:04:15 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-15 20:04:15 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 80 ms (0 ms spent in bootstraps)
2019-10-15 20:04:15 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191015200415-0275
2019-10-15 20:04:15 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191015200415-0275/0 on worker-20191014155222-10.164.0.6-44093 (10.164.0.6:44093) with 1 core(s)
2019-10-15 20:04:15 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37321.
2019-10-15 20:04:15 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:37321
2019-10-15 20:04:15 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-15 20:04:15 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191015200415-0275/0 on hostPort 10.164.0.6:44093 with 1 core(s), 2.0 GB RAM
2019-10-15 20:04:15 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191015200415-0275/0 is now RUNNING
2019-10-15 20:04:15 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 37321, None)
2019-10-15 20:04:15 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:37321 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 37321, None)
2019-10-15 20:04:15 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 37321, None)
2019-10-15 20:04:15 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 37321, None)
2019-10-15 20:04:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3578d60b{/metrics/json,null,AVAILABLE,@Spark}
2019-10-15 20:04:18 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.6:35352) with ID 0
2019-10-15 20:04:18 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-15 20:04:18 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.6:35691 with 1007.8 MB RAM, BlockManagerId(0, 10.164.0.6, 35691, None)
2019-10-15 20:04:19 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-15 20:04:19 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-15 20:04:19 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 18
2019-10-15 20:04:19 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.001
('Extracting', '/tmp/mnist/train-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-15 20:04:21 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-15 20:04:40 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-15 20:04:41 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-15 20:04:41 INFO  DistriOptimizer$:154 - Count dataset
2019-10-15 20:04:41 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.757946356s
2019-10-15 20:04:42 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-15 20:04:42 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-15 20:04:42 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.059010599s
2019-10-15 20:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 128/60000][Iteration 1][Wall Clock 1.059966307s] Trained 128 records in 1.059966307 seconds. Throughput is 120.75855 records/second. Loss is 2.3052406. Sequentiale465b572's hyper parameters: Current learning rate is 0.001. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 2][Wall Clock 1.443699239s] Trained 128 records in 0.383732932 seconds. Throughput is 333.5653 records/second. Loss is 2.3246264. Sequentiale465b572's hyper parameters: Current learning rate is 9.990009990009992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:43 INFO  DistriOptimizer$:408 - [Epoch 1 384/60000][Iteration 3][Wall Clock 1.806604822s] Trained 128 records in 0.362905583 seconds. Throughput is 352.7088 records/second. Loss is 2.3065028. Sequentiale465b572's hyper parameters: Current learning rate is 9.98003992015968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:44 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 4][Wall Clock 2.146113187s] Trained 128 records in 0.339508365 seconds. Throughput is 377.01575 records/second. Loss is 2.331341. Sequentiale465b572's hyper parameters: Current learning rate is 9.970089730807579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:44 INFO  DistriOptimizer$:408 - [Epoch 1 640/60000][Iteration 5][Wall Clock 2.423585958s] Trained 128 records in 0.277472771 seconds. Throughput is 461.30655 records/second. Loss is 2.3149314. Sequentiale465b572's hyper parameters: Current learning rate is 9.9601593625498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:44 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 6][Wall Clock 2.680416457s] Trained 128 records in 0.256830499 seconds. Throughput is 498.38315 records/second. Loss is 2.3274257. Sequentiale465b572's hyper parameters: Current learning rate is 9.950248756218907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:45 INFO  DistriOptimizer$:408 - [Epoch 1 896/60000][Iteration 7][Wall Clock 2.894620198s] Trained 128 records in 0.214203741 seconds. Throughput is 597.5619 records/second. Loss is 2.320594. Sequentiale465b572's hyper parameters: Current learning rate is 9.940357852882705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:45 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 8][Wall Clock 3.13316774s] Trained 128 records in 0.238547542 seconds. Throughput is 536.5806 records/second. Loss is 2.3276463. Sequentiale465b572's hyper parameters: Current learning rate is 9.9304865938431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:45 INFO  DistriOptimizer$:408 - [Epoch 1 1152/60000][Iteration 9][Wall Clock 3.475601219s] Trained 128 records in 0.342433479 seconds. Throughput is 373.79523 records/second. Loss is 2.3096952. Sequentiale465b572's hyper parameters: Current learning rate is 9.92063492063492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:45 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 10][Wall Clock 3.687225966s] Trained 128 records in 0.211624747 seconds. Throughput is 604.84424 records/second. Loss is 2.3264563. Sequentiale465b572's hyper parameters: Current learning rate is 9.91080277502478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:46 INFO  DistriOptimizer$:408 - [Epoch 1 1408/60000][Iteration 11][Wall Clock 3.871372839s] Trained 128 records in 0.184146873 seconds. Throughput is 695.09735 records/second. Loss is 2.3171778. Sequentiale465b572's hyper parameters: Current learning rate is 9.900990099009901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:46 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 12][Wall Clock 4.048894944s] Trained 128 records in 0.177522105 seconds. Throughput is 721.0369 records/second. Loss is 2.3331127. Sequentiale465b572's hyper parameters: Current learning rate is 9.891196834817015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:46 INFO  DistriOptimizer$:408 - [Epoch 1 1664/60000][Iteration 13][Wall Clock 4.227219981s] Trained 128 records in 0.178325037 seconds. Throughput is 717.7904 records/second. Loss is 2.3187897. Sequentiale465b572's hyper parameters: Current learning rate is 9.881422924901185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:46 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 14][Wall Clock 4.437942802s] Trained 128 records in 0.210722821 seconds. Throughput is 607.43304 records/second. Loss is 2.3116398. Sequentiale465b572's hyper parameters: Current learning rate is 9.87166831194472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:46 INFO  DistriOptimizer$:408 - [Epoch 1 1920/60000][Iteration 15][Wall Clock 4.714389718s] Trained 128 records in 0.276446916 seconds. Throughput is 463.01837 records/second. Loss is 2.3037877. Sequentiale465b572's hyper parameters: Current learning rate is 9.861932938856016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:47 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 16][Wall Clock 4.927412645s] Trained 128 records in 0.213022927 seconds. Throughput is 600.87427 records/second. Loss is 2.3143876. Sequentiale465b572's hyper parameters: Current learning rate is 9.852216748768474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:47 INFO  DistriOptimizer$:408 - [Epoch 1 2176/60000][Iteration 17][Wall Clock 5.118174812s] Trained 128 records in 0.190762167 seconds. Throughput is 670.9926 records/second. Loss is 2.3314567. Sequentiale465b572's hyper parameters: Current learning rate is 9.84251968503937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:47 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 18][Wall Clock 5.316227195s] Trained 128 records in 0.198052383 seconds. Throughput is 646.2937 records/second. Loss is 2.3313222. Sequentiale465b572's hyper parameters: Current learning rate is 9.832841691248771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:47 INFO  DistriOptimizer$:408 - [Epoch 1 2432/60000][Iteration 19][Wall Clock 5.499035375s] Trained 128 records in 0.18280818 seconds. Throughput is 700.1875 records/second. Loss is 2.3248951. Sequentiale465b572's hyper parameters: Current learning rate is 9.823182711198428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:47 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 20][Wall Clock 5.688781082s] Trained 128 records in 0.189745707 seconds. Throughput is 674.58704 records/second. Loss is 2.3267193. Sequentiale465b572's hyper parameters: Current learning rate is 9.813542688910698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:48 INFO  DistriOptimizer$:408 - [Epoch 1 2688/60000][Iteration 21][Wall Clock 5.96428364s] Trained 128 records in 0.275502558 seconds. Throughput is 464.60547 records/second. Loss is 2.312506. Sequentiale465b572's hyper parameters: Current learning rate is 9.80392156862745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:48 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 22][Wall Clock 6.172391725s] Trained 128 records in 0.208108085 seconds. Throughput is 615.065 records/second. Loss is 2.3284233. Sequentiale465b572's hyper parameters: Current learning rate is 9.794319294809011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:48 INFO  DistriOptimizer$:408 - [Epoch 1 2944/60000][Iteration 23][Wall Clock 6.331402677s] Trained 128 records in 0.159010952 seconds. Throughput is 804.976 records/second. Loss is 2.3287878. Sequentiale465b572's hyper parameters: Current learning rate is 9.784735812133072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:48 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 24][Wall Clock 6.497866145s] Trained 128 records in 0.166463468 seconds. Throughput is 768.9375 records/second. Loss is 2.321995. Sequentiale465b572's hyper parameters: Current learning rate is 9.775171065493646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:48 INFO  DistriOptimizer$:408 - [Epoch 1 3200/60000][Iteration 25][Wall Clock 6.652722739s] Trained 128 records in 0.154856594 seconds. Throughput is 826.5712 records/second. Loss is 2.3163319. Sequentiale465b572's hyper parameters: Current learning rate is 9.765625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:48 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 26][Wall Clock 6.811193861s] Trained 128 records in 0.158471122 seconds. Throughput is 807.71814 records/second. Loss is 2.3009171. Sequentiale465b572's hyper parameters: Current learning rate is 9.756097560975611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:49 INFO  DistriOptimizer$:408 - [Epoch 1 3456/60000][Iteration 27][Wall Clock 7.181032932s] Trained 128 records in 0.369839071 seconds. Throughput is 346.09647 records/second. Loss is 2.3217943. Sequentiale465b572's hyper parameters: Current learning rate is 9.746588693957114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:49 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 28][Wall Clock 7.358466407s] Trained 128 records in 0.177433475 seconds. Throughput is 721.39716 records/second. Loss is 2.3167887. Sequentiale465b572's hyper parameters: Current learning rate is 9.737098344693283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:49 INFO  DistriOptimizer$:408 - [Epoch 1 3712/60000][Iteration 29][Wall Clock 7.521018798s] Trained 128 records in 0.162552391 seconds. Throughput is 787.4385 records/second. Loss is 2.3187466. Sequentiale465b572's hyper parameters: Current learning rate is 9.727626459143969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:49 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 30][Wall Clock 7.676141967s] Trained 128 records in 0.155123169 seconds. Throughput is 825.15076 records/second. Loss is 2.3129706. Sequentiale465b572's hyper parameters: Current learning rate is 9.718172983479106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:50 INFO  DistriOptimizer$:408 - [Epoch 1 3968/60000][Iteration 31][Wall Clock 7.853404197s] Trained 128 records in 0.17726223 seconds. Throughput is 722.09406 records/second. Loss is 2.3133426. Sequentiale465b572's hyper parameters: Current learning rate is 9.70873786407767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:50 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 32][Wall Clock 8.034914046s] Trained 128 records in 0.181509849 seconds. Throughput is 705.19586 records/second. Loss is 2.3236039. Sequentiale465b572's hyper parameters: Current learning rate is 9.699321047526674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:50 INFO  DistriOptimizer$:408 - [Epoch 1 4224/60000][Iteration 33][Wall Clock 8.242803789s] Trained 128 records in 0.207889743 seconds. Throughput is 615.711 records/second. Loss is 2.3212354. Sequentiale465b572's hyper parameters: Current learning rate is 9.689922480620155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:50 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 34][Wall Clock 8.396164334s] Trained 128 records in 0.153360545 seconds. Throughput is 834.63446 records/second. Loss is 2.3033226. Sequentiale465b572's hyper parameters: Current learning rate is 9.680542110358181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:50 INFO  DistriOptimizer$:408 - [Epoch 1 4480/60000][Iteration 35][Wall Clock 8.603296022s] Trained 128 records in 0.207131688 seconds. Throughput is 617.96436 records/second. Loss is 2.3133106. Sequentiale465b572's hyper parameters: Current learning rate is 9.671179883945841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:50 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 36][Wall Clock 8.773801366s] Trained 128 records in 0.170505344 seconds. Throughput is 750.7096 records/second. Loss is 2.3083696. Sequentiale465b572's hyper parameters: Current learning rate is 9.661835748792271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:51 INFO  DistriOptimizer$:408 - [Epoch 1 4736/60000][Iteration 37][Wall Clock 8.927309714s] Trained 128 records in 0.153508348 seconds. Throughput is 833.8309 records/second. Loss is 2.2998648. Sequentiale465b572's hyper parameters: Current learning rate is 9.652509652509653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:51 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 38][Wall Clock 9.089824328s] Trained 128 records in 0.162514614 seconds. Throughput is 787.62146 records/second. Loss is 2.3185294. Sequentiale465b572's hyper parameters: Current learning rate is 9.643201542912248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:51 INFO  DistriOptimizer$:408 - [Epoch 1 4992/60000][Iteration 39][Wall Clock 9.310362582s] Trained 128 records in 0.220538254 seconds. Throughput is 580.39813 records/second. Loss is 2.3141818. Sequentiale465b572's hyper parameters: Current learning rate is 9.633911368015414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:51 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 40][Wall Clock 9.47892161s] Trained 128 records in 0.168559028 seconds. Throughput is 759.37787 records/second. Loss is 2.3306987. Sequentiale465b572's hyper parameters: Current learning rate is 9.624639076034649E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:51 INFO  DistriOptimizer$:408 - [Epoch 1 5248/60000][Iteration 41][Wall Clock 9.640773351s] Trained 128 records in 0.161851741 seconds. Throughput is 790.8472 records/second. Loss is 2.3140204. Sequentiale465b572's hyper parameters: Current learning rate is 9.615384615384615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 42][Wall Clock 9.830898747s] Trained 128 records in 0.190125396 seconds. Throughput is 673.2399 records/second. Loss is 2.3147862. Sequentiale465b572's hyper parameters: Current learning rate is 9.606147934678195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 5504/60000][Iteration 43][Wall Clock 9.98099063s] Trained 128 records in 0.150091883 seconds. Throughput is 852.8109 records/second. Loss is 2.3203418. Sequentiale465b572's hyper parameters: Current learning rate is 9.596928982725527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 44][Wall Clock 10.147258033s] Trained 128 records in 0.166267403 seconds. Throughput is 769.8442 records/second. Loss is 2.3233657. Sequentiale465b572's hyper parameters: Current learning rate is 9.587727708533078E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 5760/60000][Iteration 45][Wall Clock 10.322820185s] Trained 128 records in 0.175562152 seconds. Throughput is 729.0865 records/second. Loss is 2.3103657. Sequentiale465b572's hyper parameters: Current learning rate is 9.578544061302681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 46][Wall Clock 10.461258431s] Trained 128 records in 0.138438246 seconds. Throughput is 924.60004 records/second. Loss is 2.3070118. Sequentiale465b572's hyper parameters: Current learning rate is 9.569377990430623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 6016/60000][Iteration 47][Wall Clock 10.586277426s] Trained 128 records in 0.125018995 seconds. Throughput is 1023.84436 records/second. Loss is 2.3024585. Sequentiale465b572's hyper parameters: Current learning rate is 9.560229445506692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:52 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 48][Wall Clock 10.74827865s] Trained 128 records in 0.162001224 seconds. Throughput is 790.1175 records/second. Loss is 2.3196502. Sequentiale465b572's hyper parameters: Current learning rate is 9.551098376313277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:53 INFO  DistriOptimizer$:408 - [Epoch 1 6272/60000][Iteration 49][Wall Clock 10.899372162s] Trained 128 records in 0.151093512 seconds. Throughput is 847.1575 records/second. Loss is 2.3110259. Sequentiale465b572's hyper parameters: Current learning rate is 9.541984732824427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:53 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 50][Wall Clock 11.030533683s] Trained 128 records in 0.131161521 seconds. Throughput is 975.89594 records/second. Loss is 2.3227365. Sequentiale465b572's hyper parameters: Current learning rate is 9.532888465204958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:53 INFO  DistriOptimizer$:408 - [Epoch 1 6528/60000][Iteration 51][Wall Clock 11.228366946s] Trained 128 records in 0.197833263 seconds. Throughput is 647.00946 records/second. Loss is 2.310606. Sequentiale465b572's hyper parameters: Current learning rate is 9.523809523809524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:53 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 52][Wall Clock 11.417834175s] Trained 128 records in 0.189467229 seconds. Throughput is 675.57855 records/second. Loss is 2.307084. Sequentiale465b572's hyper parameters: Current learning rate is 9.514747859181732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:53 INFO  DistriOptimizer$:408 - [Epoch 1 6784/60000][Iteration 53][Wall Clock 11.56670561s] Trained 128 records in 0.148871435 seconds. Throughput is 859.80225 records/second. Loss is 2.3000708. Sequentiale465b572's hyper parameters: Current learning rate is 9.505703422053232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:53 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 54][Wall Clock 11.715626108s] Trained 128 records in 0.148920498 seconds. Throughput is 859.51904 records/second. Loss is 2.3075464. Sequentiale465b572's hyper parameters: Current learning rate is 9.49667616334283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7040/60000][Iteration 55][Wall Clock 11.867843041s] Trained 128 records in 0.152216933 seconds. Throughput is 840.90515 records/second. Loss is 2.3112974. Sequentiale465b572's hyper parameters: Current learning rate is 9.487666034155598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 56][Wall Clock 12.02171668s] Trained 128 records in 0.153873639 seconds. Throughput is 831.8514 records/second. Loss is 2.316435. Sequentiale465b572's hyper parameters: Current learning rate is 9.478672985781991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7296/60000][Iteration 57][Wall Clock 12.199639756s] Trained 128 records in 0.177923076 seconds. Throughput is 719.412 records/second. Loss is 2.3269923. Sequentiale465b572's hyper parameters: Current learning rate is 9.46969696969697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 58][Wall Clock 12.332499157s] Trained 128 records in 0.132859401 seconds. Throughput is 963.42456 records/second. Loss is 2.309895. Sequentiale465b572's hyper parameters: Current learning rate is 9.460737937559131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7552/60000][Iteration 59][Wall Clock 12.465490231s] Trained 128 records in 0.132991074 seconds. Throughput is 962.4706 records/second. Loss is 2.301062. Sequentiale465b572's hyper parameters: Current learning rate is 9.45179584120983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 60][Wall Clock 12.632078577s] Trained 128 records in 0.166588346 seconds. Throughput is 768.361 records/second. Loss is 2.3071532. Sequentiale465b572's hyper parameters: Current learning rate is 9.442870632672333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:54 INFO  DistriOptimizer$:408 - [Epoch 1 7808/60000][Iteration 61][Wall Clock 12.793053761s] Trained 128 records in 0.160975184 seconds. Throughput is 795.1536 records/second. Loss is 2.3116367. Sequentiale465b572's hyper parameters: Current learning rate is 9.433962264150943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 62][Wall Clock 12.923923062s] Trained 128 records in 0.130869301 seconds. Throughput is 978.0751 records/second. Loss is 2.3060951. Sequentiale465b572's hyper parameters: Current learning rate is 9.425070688030161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 8064/60000][Iteration 63][Wall Clock 13.063144006s] Trained 128 records in 0.139220944 seconds. Throughput is 919.4019 records/second. Loss is 2.322703. Sequentiale465b572's hyper parameters: Current learning rate is 9.416195856873823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 64][Wall Clock 13.228958215s] Trained 128 records in 0.165814209 seconds. Throughput is 771.9483 records/second. Loss is 2.3169627. Sequentiale465b572's hyper parameters: Current learning rate is 9.407337723424271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 8320/60000][Iteration 65][Wall Clock 13.385221972s] Trained 128 records in 0.156263757 seconds. Throughput is 819.12787 records/second. Loss is 2.313001. Sequentiale465b572's hyper parameters: Current learning rate is 9.398496240601503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 66][Wall Clock 13.505561994s] Trained 128 records in 0.120340022 seconds. Throughput is 1063.6528 records/second. Loss is 2.333073. Sequentiale465b572's hyper parameters: Current learning rate is 9.389671361502348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 8576/60000][Iteration 67][Wall Clock 13.630891711s] Trained 128 records in 0.125329717 seconds. Throughput is 1021.306 records/second. Loss is 2.3000543. Sequentiale465b572's hyper parameters: Current learning rate is 9.380863039399625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:55 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 68][Wall Clock 13.780589922s] Trained 128 records in 0.149698211 seconds. Throughput is 855.05365 records/second. Loss is 2.3062816. Sequentiale465b572's hyper parameters: Current learning rate is 9.372071227741331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 8832/60000][Iteration 69][Wall Clock 13.918828596s] Trained 128 records in 0.138238674 seconds. Throughput is 925.9348 records/second. Loss is 2.3107722. Sequentiale465b572's hyper parameters: Current learning rate is 9.363295880149813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 70][Wall Clock 14.067768317s] Trained 128 records in 0.148939721 seconds. Throughput is 859.40814 records/second. Loss is 2.3113117. Sequentiale465b572's hyper parameters: Current learning rate is 9.354536950420954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 9088/60000][Iteration 71][Wall Clock 14.203248649s] Trained 128 records in 0.135480332 seconds. Throughput is 944.7866 records/second. Loss is 2.31078. Sequentiale465b572's hyper parameters: Current learning rate is 9.345794392523364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 72][Wall Clock 14.350928486s] Trained 128 records in 0.147679837 seconds. Throughput is 866.73987 records/second. Loss is 2.3052316. Sequentiale465b572's hyper parameters: Current learning rate is 9.337068160597573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 9344/60000][Iteration 73][Wall Clock 14.509212993s] Trained 128 records in 0.158284507 seconds. Throughput is 808.6705 records/second. Loss is 2.3108006. Sequentiale465b572's hyper parameters: Current learning rate is 9.328358208955224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 74][Wall Clock 14.653208035s] Trained 128 records in 0.143995042 seconds. Throughput is 888.9195 records/second. Loss is 2.3098376. Sequentiale465b572's hyper parameters: Current learning rate is 9.319664492078286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:56 INFO  DistriOptimizer$:408 - [Epoch 1 9600/60000][Iteration 75][Wall Clock 14.780598689s] Trained 128 records in 0.127390654 seconds. Throughput is 1004.7833 records/second. Loss is 2.3131702. Sequentiale465b572's hyper parameters: Current learning rate is 9.31098696461825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:57 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 76][Wall Clock 14.932664021s] Trained 128 records in 0.152065332 seconds. Throughput is 841.74347 records/second. Loss is 2.311551. Sequentiale465b572's hyper parameters: Current learning rate is 9.302325581395349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:57 INFO  DistriOptimizer$:408 - [Epoch 1 9856/60000][Iteration 77][Wall Clock 15.095392709s] Trained 128 records in 0.162728688 seconds. Throughput is 786.5854 records/second. Loss is 2.313856. Sequentiale465b572's hyper parameters: Current learning rate is 9.293680297397769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:57 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 78][Wall Clock 15.230309673s] Trained 128 records in 0.134916964 seconds. Throughput is 948.7317 records/second. Loss is 2.2940383. Sequentiale465b572's hyper parameters: Current learning rate is 9.285051067780873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:57 INFO  DistriOptimizer$:408 - [Epoch 1 10112/60000][Iteration 79][Wall Clock 15.358180012s] Trained 128 records in 0.127870339 seconds. Throughput is 1001.01404 records/second. Loss is 2.2970538. Sequentiale465b572's hyper parameters: Current learning rate is 9.276437847866418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:57 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 80][Wall Clock 15.518681898s] Trained 128 records in 0.160501886 seconds. Throughput is 797.4984 records/second. Loss is 2.3160837. Sequentiale465b572's hyper parameters: Current learning rate is 9.267840593141798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:57 INFO  DistriOptimizer$:408 - [Epoch 1 10368/60000][Iteration 81][Wall Clock 15.65867447s] Trained 128 records in 0.139992572 seconds. Throughput is 914.3343 records/second. Loss is 2.305535. Sequentiale465b572's hyper parameters: Current learning rate is 9.259259259259259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 82][Wall Clock 15.793875319s] Trained 128 records in 0.135200849 seconds. Throughput is 946.7397 records/second. Loss is 2.2920585. Sequentiale465b572's hyper parameters: Current learning rate is 9.250693802035153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 10624/60000][Iteration 83][Wall Clock 15.958184006s] Trained 128 records in 0.164308687 seconds. Throughput is 779.02155 records/second. Loss is 2.310913. Sequentiale465b572's hyper parameters: Current learning rate is 9.242144177449168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 84][Wall Clock 16.14061749s] Trained 128 records in 0.182433484 seconds. Throughput is 701.62555 records/second. Loss is 2.2921436. Sequentiale465b572's hyper parameters: Current learning rate is 9.233610341643583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 10880/60000][Iteration 85][Wall Clock 16.292806069s] Trained 128 records in 0.152188579 seconds. Throughput is 841.06177 records/second. Loss is 2.3169084. Sequentiale465b572's hyper parameters: Current learning rate is 9.225092250922509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 86][Wall Clock 16.478650777s] Trained 128 records in 0.185844708 seconds. Throughput is 688.7471 records/second. Loss is 2.3092935. Sequentiale465b572's hyper parameters: Current learning rate is 9.216589861751152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 11136/60000][Iteration 87][Wall Clock 16.632677162s] Trained 128 records in 0.154026385 seconds. Throughput is 831.0264 records/second. Loss is 2.3086536. Sequentiale465b572's hyper parameters: Current learning rate is 9.208103130755064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:58 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 88][Wall Clock 16.764182224s] Trained 128 records in 0.131505062 seconds. Throughput is 973.3466 records/second. Loss is 2.3171182. Sequentiale465b572's hyper parameters: Current learning rate is 9.199632014719412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 11392/60000][Iteration 89][Wall Clock 16.899582968s] Trained 128 records in 0.135400744 seconds. Throughput is 945.3419 records/second. Loss is 2.3070555. Sequentiale465b572's hyper parameters: Current learning rate is 9.191176470588235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 90][Wall Clock 17.030139004s] Trained 128 records in 0.130556036 seconds. Throughput is 980.42194 records/second. Loss is 2.3151927. Sequentiale465b572's hyper parameters: Current learning rate is 9.182736455463729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 11648/60000][Iteration 91][Wall Clock 17.18352323s] Trained 128 records in 0.153384226 seconds. Throughput is 834.5056 records/second. Loss is 2.309977. Sequentiale465b572's hyper parameters: Current learning rate is 9.174311926605504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 92][Wall Clock 17.338221864s] Trained 128 records in 0.154698634 seconds. Throughput is 827.41516 records/second. Loss is 2.3238056. Sequentiale465b572's hyper parameters: Current learning rate is 9.165902841429881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 11904/60000][Iteration 93][Wall Clock 17.478161332s] Trained 128 records in 0.139939468 seconds. Throughput is 914.68115 records/second. Loss is 2.3029568. Sequentiale465b572's hyper parameters: Current learning rate is 9.157509157509158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 94][Wall Clock 17.627198405s] Trained 128 records in 0.149037073 seconds. Throughput is 858.8467 records/second. Loss is 2.2949545. Sequentiale465b572's hyper parameters: Current learning rate is 9.149130832570906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:04:59 INFO  DistriOptimizer$:408 - [Epoch 1 12160/60000][Iteration 95][Wall Clock 17.754879196s] Trained 128 records in 0.127680791 seconds. Throughput is 1002.50006 records/second. Loss is 2.298413. Sequentiale465b572's hyper parameters: Current learning rate is 9.140767824497258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 96][Wall Clock 17.906226649s] Trained 128 records in 0.151347453 seconds. Throughput is 845.736 records/second. Loss is 2.2998087. Sequentiale465b572's hyper parameters: Current learning rate is 9.132420091324202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 12416/60000][Iteration 97][Wall Clock 18.067819694s] Trained 128 records in 0.161593045 seconds. Throughput is 792.1133 records/second. Loss is 2.305199. Sequentiale465b572's hyper parameters: Current learning rate is 9.124087591240876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 98][Wall Clock 18.206298696s] Trained 128 records in 0.138479002 seconds. Throughput is 924.3278 records/second. Loss is 2.2906716. Sequentiale465b572's hyper parameters: Current learning rate is 9.11577028258888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 12672/60000][Iteration 99][Wall Clock 18.354488296s] Trained 128 records in 0.1481896 seconds. Throughput is 863.7583 records/second. Loss is 2.3187706. Sequentiale465b572's hyper parameters: Current learning rate is 9.107468123861566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 100][Wall Clock 18.496304644s] Trained 128 records in 0.141816348 seconds. Throughput is 902.57574 records/second. Loss is 2.3051963. Sequentiale465b572's hyper parameters: Current learning rate is 9.099181073703367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 12928/60000][Iteration 101][Wall Clock 18.626649847s] Trained 128 records in 0.130345203 seconds. Throughput is 982.0077 records/second. Loss is 2.2989674. Sequentiale465b572's hyper parameters: Current learning rate is 9.090909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:00 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 102][Wall Clock 18.756522413s] Trained 128 records in 0.129872566 seconds. Throughput is 985.58154 records/second. Loss is 2.2948387. Sequentiale465b572's hyper parameters: Current learning rate is 9.082652134423252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13184/60000][Iteration 103][Wall Clock 18.891858896s] Trained 128 records in 0.135336483 seconds. Throughput is 945.7908 records/second. Loss is 2.307096. Sequentiale465b572's hyper parameters: Current learning rate is 9.074410163339383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 104][Wall Clock 19.027251022s] Trained 128 records in 0.135392126 seconds. Throughput is 945.4021 records/second. Loss is 2.3199384. Sequentiale465b572's hyper parameters: Current learning rate is 9.066183136899365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13440/60000][Iteration 105][Wall Clock 19.163902732s] Trained 128 records in 0.13665171 seconds. Throughput is 936.68787 records/second. Loss is 2.3204997. Sequentiale465b572's hyper parameters: Current learning rate is 9.057971014492753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 106][Wall Clock 19.293380891s] Trained 128 records in 0.129478159 seconds. Throughput is 988.58374 records/second. Loss is 2.303712. Sequentiale465b572's hyper parameters: Current learning rate is 9.049773755656109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13696/60000][Iteration 107][Wall Clock 19.413923332s] Trained 128 records in 0.120542441 seconds. Throughput is 1061.8666 records/second. Loss is 2.3037567. Sequentiale465b572's hyper parameters: Current learning rate is 9.041591320072332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 108][Wall Clock 19.574775855s] Trained 128 records in 0.160852523 seconds. Throughput is 795.76 records/second. Loss is 2.2950926. Sequentiale465b572's hyper parameters: Current learning rate is 9.03342366757001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:01 INFO  DistriOptimizer$:408 - [Epoch 1 13952/60000][Iteration 109][Wall Clock 19.706165418s] Trained 128 records in 0.131389563 seconds. Throughput is 974.2022 records/second. Loss is 2.308492. Sequentiale465b572's hyper parameters: Current learning rate is 9.025270758122743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 110][Wall Clock 19.827590268s] Trained 128 records in 0.12142485 seconds. Throughput is 1054.15 records/second. Loss is 2.3021653. Sequentiale465b572's hyper parameters: Current learning rate is 9.017132551848513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14208/60000][Iteration 111][Wall Clock 19.953280864s] Trained 128 records in 0.125690596 seconds. Throughput is 1018.3737 records/second. Loss is 2.3040962. Sequentiale465b572's hyper parameters: Current learning rate is 9.009009009009008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 112][Wall Clock 20.086193694s] Trained 128 records in 0.13291283 seconds. Throughput is 963.03723 records/second. Loss is 2.3032186. Sequentiale465b572's hyper parameters: Current learning rate is 9.000900090009002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14464/60000][Iteration 113][Wall Clock 20.209315493s] Trained 128 records in 0.123121799 seconds. Throughput is 1039.621 records/second. Loss is 2.3044174. Sequentiale465b572's hyper parameters: Current learning rate is 8.992805755395683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 114][Wall Clock 20.333540481s] Trained 128 records in 0.124224988 seconds. Throughput is 1030.3884 records/second. Loss is 2.2911932. Sequentiale465b572's hyper parameters: Current learning rate is 8.984725965858042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14720/60000][Iteration 115][Wall Clock 20.451765743s] Trained 128 records in 0.118225262 seconds. Throughput is 1082.679 records/second. Loss is 2.3079474. Sequentiale465b572's hyper parameters: Current learning rate is 8.976660682226211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:02 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 116][Wall Clock 20.593998043s] Trained 128 records in 0.1422323 seconds. Throughput is 899.9362 records/second. Loss is 2.2935948. Sequentiale465b572's hyper parameters: Current learning rate is 8.968609865470852E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 14976/60000][Iteration 117][Wall Clock 20.789133688s] Trained 128 records in 0.195135645 seconds. Throughput is 655.954 records/second. Loss is 2.311966. Sequentiale465b572's hyper parameters: Current learning rate is 8.960573476702508E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 118][Wall Clock 20.917618553s] Trained 128 records in 0.128484865 seconds. Throughput is 996.2263 records/second. Loss is 2.2900329. Sequentiale465b572's hyper parameters: Current learning rate is 8.952551477170994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15232/60000][Iteration 119][Wall Clock 21.057304067s] Trained 128 records in 0.139685514 seconds. Throughput is 916.3441 records/second. Loss is 2.3060777. Sequentiale465b572's hyper parameters: Current learning rate is 8.944543828264757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 120][Wall Clock 21.184411615s] Trained 128 records in 0.127107548 seconds. Throughput is 1007.02124 records/second. Loss is 2.301926. Sequentiale465b572's hyper parameters: Current learning rate is 8.936550491510277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15488/60000][Iteration 121][Wall Clock 21.317044537s] Trained 128 records in 0.132632922 seconds. Throughput is 965.0696 records/second. Loss is 2.3015976. Sequentiale465b572's hyper parameters: Current learning rate is 8.928571428571428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 122][Wall Clock 21.450846295s] Trained 128 records in 0.133801758 seconds. Throughput is 956.63916 records/second. Loss is 2.2994173. Sequentiale465b572's hyper parameters: Current learning rate is 8.920606601248885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15744/60000][Iteration 123][Wall Clock 21.585206642s] Trained 128 records in 0.134360347 seconds. Throughput is 952.66205 records/second. Loss is 2.3043535. Sequentiale465b572's hyper parameters: Current learning rate is 8.912655971479501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:03 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 124][Wall Clock 21.744243918s] Trained 128 records in 0.159037276 seconds. Throughput is 804.8428 records/second. Loss is 2.3113086. Sequentiale465b572's hyper parameters: Current learning rate is 8.904719501335708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16000/60000][Iteration 125][Wall Clock 21.888179096s] Trained 128 records in 0.143935178 seconds. Throughput is 889.28925 records/second. Loss is 2.3006883. Sequentiale465b572's hyper parameters: Current learning rate is 8.896797153024911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 126][Wall Clock 22.055945318s] Trained 128 records in 0.167766222 seconds. Throughput is 762.96643 records/second. Loss is 2.3085065. Sequentiale465b572's hyper parameters: Current learning rate is 8.888888888888889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16256/60000][Iteration 127][Wall Clock 22.192043636s] Trained 128 records in 0.136098318 seconds. Throughput is 940.4965 records/second. Loss is 2.2938695. Sequentiale465b572's hyper parameters: Current learning rate is 8.880994671403199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 128][Wall Clock 22.350628281s] Trained 128 records in 0.158584645 seconds. Throughput is 807.13995 records/second. Loss is 2.3051555. Sequentiale465b572's hyper parameters: Current learning rate is 8.873114463176575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16512/60000][Iteration 129][Wall Clock 22.467650872s] Trained 128 records in 0.117022591 seconds. Throughput is 1093.8059 records/second. Loss is 2.3081977. Sequentiale465b572's hyper parameters: Current learning rate is 8.865248226950354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 130][Wall Clock 22.589449408s] Trained 128 records in 0.121798536 seconds. Throughput is 1050.9158 records/second. Loss is 2.2902408. Sequentiale465b572's hyper parameters: Current learning rate is 8.857395925597874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:04 INFO  DistriOptimizer$:408 - [Epoch 1 16768/60000][Iteration 131][Wall Clock 22.698874302s] Trained 128 records in 0.109424894 seconds. Throughput is 1169.7521 records/second. Loss is 2.3063717. Sequentiale465b572's hyper parameters: Current learning rate is 8.849557522123895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 132][Wall Clock 22.805373812s] Trained 128 records in 0.10649951 seconds. Throughput is 1201.8835 records/second. Loss is 2.298401. Sequentiale465b572's hyper parameters: Current learning rate is 8.841732979664015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17024/60000][Iteration 133][Wall Clock 22.915459801s] Trained 128 records in 0.110085989 seconds. Throughput is 1162.7274 records/second. Loss is 2.3057704. Sequentiale465b572's hyper parameters: Current learning rate is 8.833922261484098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 134][Wall Clock 23.044298262s] Trained 128 records in 0.128838461 seconds. Throughput is 993.4921 records/second. Loss is 2.3043275. Sequentiale465b572's hyper parameters: Current learning rate is 8.8261253309797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17280/60000][Iteration 135][Wall Clock 23.161488616s] Trained 128 records in 0.117190354 seconds. Throughput is 1092.2401 records/second. Loss is 2.2982912. Sequentiale465b572's hyper parameters: Current learning rate is 8.818342151675486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 136][Wall Clock 23.282246129s] Trained 128 records in 0.120757513 seconds. Throughput is 1059.9755 records/second. Loss is 2.3022265. Sequentiale465b572's hyper parameters: Current learning rate is 8.81057268722467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17536/60000][Iteration 137][Wall Clock 23.415324458s] Trained 128 records in 0.133078329 seconds. Throughput is 961.8396 records/second. Loss is 2.316622. Sequentiale465b572's hyper parameters: Current learning rate is 8.80281690140845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 138][Wall Clock 23.533951917s] Trained 128 records in 0.118627459 seconds. Throughput is 1079.0082 records/second. Loss is 2.281053. Sequentiale465b572's hyper parameters: Current learning rate is 8.795074758135445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:05 INFO  DistriOptimizer$:408 - [Epoch 1 17792/60000][Iteration 139][Wall Clock 23.650385299s] Trained 128 records in 0.116433382 seconds. Throughput is 1099.3411 records/second. Loss is 2.300516. Sequentiale465b572's hyper parameters: Current learning rate is 8.787346221441125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 140][Wall Clock 23.773012933s] Trained 128 records in 0.122627634 seconds. Throughput is 1043.8104 records/second. Loss is 2.3164592. Sequentiale465b572's hyper parameters: Current learning rate is 8.77963125548727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18048/60000][Iteration 141][Wall Clock 23.90234119s] Trained 128 records in 0.129328257 seconds. Throughput is 989.7296 records/second. Loss is 2.301879. Sequentiale465b572's hyper parameters: Current learning rate is 8.771929824561403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 142][Wall Clock 24.018577282s] Trained 128 records in 0.116236092 seconds. Throughput is 1101.207 records/second. Loss is 2.300809. Sequentiale465b572's hyper parameters: Current learning rate is 8.764241893076249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18304/60000][Iteration 143][Wall Clock 24.135658444s] Trained 128 records in 0.117081162 seconds. Throughput is 1093.2587 records/second. Loss is 2.2856016. Sequentiale465b572's hyper parameters: Current learning rate is 8.756567425569178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 144][Wall Clock 24.248022037s] Trained 128 records in 0.112363593 seconds. Throughput is 1139.159 records/second. Loss is 2.3026495. Sequentiale465b572's hyper parameters: Current learning rate is 8.748906386701663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18560/60000][Iteration 145][Wall Clock 24.354115489s] Trained 128 records in 0.106093452 seconds. Throughput is 1206.4835 records/second. Loss is 2.3020654. Sequentiale465b572's hyper parameters: Current learning rate is 8.74125874125874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 146][Wall Clock 24.464183364s] Trained 128 records in 0.110067875 seconds. Throughput is 1162.9188 records/second. Loss is 2.3186426. Sequentiale465b572's hyper parameters: Current learning rate is 8.733624454148472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18816/60000][Iteration 147][Wall Clock 24.5990348s] Trained 128 records in 0.134851436 seconds. Throughput is 949.1927 records/second. Loss is 2.3053634. Sequentiale465b572's hyper parameters: Current learning rate is 8.726003490401397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:06 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 148][Wall Clock 24.715323063s] Trained 128 records in 0.116288263 seconds. Throughput is 1100.713 records/second. Loss is 2.3121781. Sequentiale465b572's hyper parameters: Current learning rate is 8.718395815170009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19072/60000][Iteration 149][Wall Clock 24.829225294s] Trained 128 records in 0.113902231 seconds. Throughput is 1123.7708 records/second. Loss is 2.291549. Sequentiale465b572's hyper parameters: Current learning rate is 8.710801393728224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 150][Wall Clock 24.94511284s] Trained 128 records in 0.115887546 seconds. Throughput is 1104.519 records/second. Loss is 2.2912962. Sequentiale465b572's hyper parameters: Current learning rate is 8.703220191470844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19328/60000][Iteration 151][Wall Clock 25.073621203s] Trained 128 records in 0.128508363 seconds. Throughput is 996.0441 records/second. Loss is 2.2911978. Sequentiale465b572's hyper parameters: Current learning rate is 8.695652173913044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 152][Wall Clock 25.186612977s] Trained 128 records in 0.112991774 seconds. Throughput is 1132.8258 records/second. Loss is 2.3044548. Sequentiale465b572's hyper parameters: Current learning rate is 8.688097306689834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19584/60000][Iteration 153][Wall Clock 25.294362317s] Trained 128 records in 0.10774934 seconds. Throughput is 1187.9423 records/second. Loss is 2.3238702. Sequentiale465b572's hyper parameters: Current learning rate is 8.680555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 154][Wall Clock 25.409306233s] Trained 128 records in 0.114943916 seconds. Throughput is 1113.5865 records/second. Loss is 2.3078015. Sequentiale465b572's hyper parameters: Current learning rate is 8.673026886383347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19840/60000][Iteration 155][Wall Clock 25.535378476s] Trained 128 records in 0.126072243 seconds. Throughput is 1015.2909 records/second. Loss is 2.298051. Sequentiale465b572's hyper parameters: Current learning rate is 8.665511265164645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:07 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 156][Wall Clock 25.648590095s] Trained 128 records in 0.113211619 seconds. Throughput is 1130.626 records/second. Loss is 2.2934067. Sequentiale465b572's hyper parameters: Current learning rate is 8.658008658008658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20096/60000][Iteration 157][Wall Clock 25.761597979s] Trained 128 records in 0.113007884 seconds. Throughput is 1132.6644 records/second. Loss is 2.2969813. Sequentiale465b572's hyper parameters: Current learning rate is 8.65051903114187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 158][Wall Clock 25.915407866s] Trained 128 records in 0.153809887 seconds. Throughput is 832.19617 records/second. Loss is 2.3093424. Sequentiale465b572's hyper parameters: Current learning rate is 8.64304235090752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20352/60000][Iteration 159][Wall Clock 26.051435001s] Trained 128 records in 0.136027135 seconds. Throughput is 940.98865 records/second. Loss is 2.2954042. Sequentiale465b572's hyper parameters: Current learning rate is 8.635578583765113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 160][Wall Clock 26.169937088s] Trained 128 records in 0.118502087 seconds. Throughput is 1080.1498 records/second. Loss is 2.3023062. Sequentiale465b572's hyper parameters: Current learning rate is 8.628127696289905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20608/60000][Iteration 161][Wall Clock 26.285809983s] Trained 128 records in 0.115872895 seconds. Throughput is 1104.6587 records/second. Loss is 2.2937534. Sequentiale465b572's hyper parameters: Current learning rate is 8.620689655172415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 162][Wall Clock 26.389912818s] Trained 128 records in 0.104102835 seconds. Throughput is 1229.5535 records/second. Loss is 2.306589. Sequentiale465b572's hyper parameters: Current learning rate is 8.613264427217916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20864/60000][Iteration 163][Wall Clock 26.517572634s] Trained 128 records in 0.127659816 seconds. Throughput is 1002.6648 records/second. Loss is 2.3109071. Sequentiale465b572's hyper parameters: Current learning rate is 8.605851979345956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:08 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 164][Wall Clock 26.620239171s] Trained 128 records in 0.102666537 seconds. Throughput is 1246.7549 records/second. Loss is 2.3022676. Sequentiale465b572's hyper parameters: Current learning rate is 8.598452278589854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21120/60000][Iteration 165][Wall Clock 26.727174218s] Trained 128 records in 0.106935047 seconds. Throughput is 1196.9883 records/second. Loss is 2.3019123. Sequentiale465b572's hyper parameters: Current learning rate is 8.591065292096221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 166][Wall Clock 26.831484992s] Trained 128 records in 0.104310774 seconds. Throughput is 1227.1024 records/second. Loss is 2.2941313. Sequentiale465b572's hyper parameters: Current learning rate is 8.583690987124463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21376/60000][Iteration 167][Wall Clock 26.937716191s] Trained 128 records in 0.106231199 seconds. Throughput is 1204.9191 records/second. Loss is 2.3005416. Sequentiale465b572's hyper parameters: Current learning rate is 8.576329331046313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 168][Wall Clock 27.049378616s] Trained 128 records in 0.111662425 seconds. Throughput is 1146.3123 records/second. Loss is 2.2975774. Sequentiale465b572's hyper parameters: Current learning rate is 8.568980291345329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21632/60000][Iteration 169][Wall Clock 27.172299493s] Trained 128 records in 0.122920877 seconds. Throughput is 1041.3203 records/second. Loss is 2.286757. Sequentiale465b572's hyper parameters: Current learning rate is 8.561643835616439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 170][Wall Clock 27.309987602s] Trained 128 records in 0.137688109 seconds. Throughput is 929.63727 records/second. Loss is 2.3038666. Sequentiale465b572's hyper parameters: Current learning rate is 8.55431993156544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 21888/60000][Iteration 171][Wall Clock 27.430660008s] Trained 128 records in 0.120672406 seconds. Throughput is 1060.723 records/second. Loss is 2.301665. Sequentiale465b572's hyper parameters: Current learning rate is 8.547008547008548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 172][Wall Clock 27.537841155s] Trained 128 records in 0.107181147 seconds. Throughput is 1194.2399 records/second. Loss is 2.3002124. Sequentiale465b572's hyper parameters: Current learning rate is 8.539709649871904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:09 INFO  DistriOptimizer$:408 - [Epoch 1 22144/60000][Iteration 173][Wall Clock 27.655670438s] Trained 128 records in 0.117829283 seconds. Throughput is 1086.3174 records/second. Loss is 2.2850122. Sequentiale465b572's hyper parameters: Current learning rate is 8.532423208191127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 174][Wall Clock 27.775877821s] Trained 128 records in 0.120207383 seconds. Throughput is 1064.8264 records/second. Loss is 2.2935112. Sequentiale465b572's hyper parameters: Current learning rate is 8.525149190110827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 22400/60000][Iteration 175][Wall Clock 27.898610579s] Trained 128 records in 0.122732758 seconds. Throughput is 1042.9164 records/second. Loss is 2.308309. Sequentiale465b572's hyper parameters: Current learning rate is 8.517887563884158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 176][Wall Clock 28.013763198s] Trained 128 records in 0.115152619 seconds. Throughput is 1111.5682 records/second. Loss is 2.297879. Sequentiale465b572's hyper parameters: Current learning rate is 8.51063829787234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 22656/60000][Iteration 177][Wall Clock 28.14269625s] Trained 128 records in 0.128933052 seconds. Throughput is 992.76324 records/second. Loss is 2.3019412. Sequentiale465b572's hyper parameters: Current learning rate is 8.503401360544218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 178][Wall Clock 28.250010142s] Trained 128 records in 0.107313892 seconds. Throughput is 1192.7626 records/second. Loss is 2.3043141. Sequentiale465b572's hyper parameters: Current learning rate is 8.496176720475786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 22912/60000][Iteration 179][Wall Clock 28.381785648s] Trained 128 records in 0.131775506 seconds. Throughput is 971.3489 records/second. Loss is 2.2920866. Sequentiale465b572's hyper parameters: Current learning rate is 8.488964346349746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:10 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 180][Wall Clock 28.571784435s] Trained 128 records in 0.189998787 seconds. Throughput is 673.6885 records/second. Loss is 2.2964525. Sequentiale465b572's hyper parameters: Current learning rate is 8.481764206955047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23168/60000][Iteration 181][Wall Clock 28.741773538s] Trained 128 records in 0.169989103 seconds. Throughput is 752.98944 records/second. Loss is 2.2942474. Sequentiale465b572's hyper parameters: Current learning rate is 8.474576271186442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 182][Wall Clock 28.874720929s] Trained 128 records in 0.132947391 seconds. Throughput is 962.78687 records/second. Loss is 2.3081036. Sequentiale465b572's hyper parameters: Current learning rate is 8.46740050804403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23424/60000][Iteration 183][Wall Clock 29.008753139s] Trained 128 records in 0.13403221 seconds. Throughput is 954.9944 records/second. Loss is 2.3069735. Sequentiale465b572's hyper parameters: Current learning rate is 8.460236886632827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 184][Wall Clock 29.134102022s] Trained 128 records in 0.125348883 seconds. Throughput is 1021.1499 records/second. Loss is 2.3001688. Sequentiale465b572's hyper parameters: Current learning rate is 8.453085376162299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23680/60000][Iteration 185][Wall Clock 29.238420143s] Trained 128 records in 0.104318121 seconds. Throughput is 1227.016 records/second. Loss is 2.3088531. Sequentiale465b572's hyper parameters: Current learning rate is 8.445945945945946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 186][Wall Clock 29.349527843s] Trained 128 records in 0.1111077 seconds. Throughput is 1152.0354 records/second. Loss is 2.3022108. Sequentiale465b572's hyper parameters: Current learning rate is 8.438818565400844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 23936/60000][Iteration 187][Wall Clock 29.462582343s] Trained 128 records in 0.1130545 seconds. Throughput is 1132.1973 records/second. Loss is 2.2985306. Sequentiale465b572's hyper parameters: Current learning rate is 8.431703204047218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 188][Wall Clock 29.597309469s] Trained 128 records in 0.134727126 seconds. Throughput is 950.06854 records/second. Loss is 2.3185544. Sequentiale465b572's hyper parameters: Current learning rate is 8.424599831508003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:11 INFO  DistriOptimizer$:408 - [Epoch 1 24192/60000][Iteration 189][Wall Clock 29.706894827s] Trained 128 records in 0.109585358 seconds. Throughput is 1168.0392 records/second. Loss is 2.2969332. Sequentiale465b572's hyper parameters: Current learning rate is 8.417508417508418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 190][Wall Clock 29.824334709s] Trained 128 records in 0.117439882 seconds. Throughput is 1089.9193 records/second. Loss is 2.2891152. Sequentiale465b572's hyper parameters: Current learning rate is 8.410428931875525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 24448/60000][Iteration 191][Wall Clock 29.954270286s] Trained 128 records in 0.129935577 seconds. Throughput is 985.1036 records/second. Loss is 2.2841794. Sequentiale465b572's hyper parameters: Current learning rate is 8.403361344537816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 192][Wall Clock 30.092829774s] Trained 128 records in 0.138559488 seconds. Throughput is 923.79095 records/second. Loss is 2.2965276. Sequentiale465b572's hyper parameters: Current learning rate is 8.396305625524769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 24704/60000][Iteration 193][Wall Clock 30.203382883s] Trained 128 records in 0.110553109 seconds. Throughput is 1157.8146 records/second. Loss is 2.3081732. Sequentiale465b572's hyper parameters: Current learning rate is 8.389261744966444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 194][Wall Clock 30.35041977s] Trained 128 records in 0.147036887 seconds. Throughput is 870.5299 records/second. Loss is 2.29084. Sequentiale465b572's hyper parameters: Current learning rate is 8.382229673093043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 24960/60000][Iteration 195][Wall Clock 30.479705359s] Trained 128 records in 0.129285589 seconds. Throughput is 990.0562 records/second. Loss is 2.301971. Sequentiale465b572's hyper parameters: Current learning rate is 8.375209380234506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:12 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 196][Wall Clock 30.605710401s] Trained 128 records in 0.126005042 seconds. Throughput is 1015.8324 records/second. Loss is 2.2806249. Sequentiale465b572's hyper parameters: Current learning rate is 8.368200836820083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25216/60000][Iteration 197][Wall Clock 30.712493393s] Trained 128 records in 0.106782992 seconds. Throughput is 1198.6927 records/second. Loss is 2.2963068. Sequentiale465b572's hyper parameters: Current learning rate is 8.361204013377927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 198][Wall Clock 30.823102961s] Trained 128 records in 0.110609568 seconds. Throughput is 1157.2235 records/second. Loss is 2.3030255. Sequentiale465b572's hyper parameters: Current learning rate is 8.35421888053467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25472/60000][Iteration 199][Wall Clock 30.933566472s] Trained 128 records in 0.110463511 seconds. Throughput is 1158.7537 records/second. Loss is 2.2853453. Sequentiale465b572's hyper parameters: Current learning rate is 8.347245409015025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 200][Wall Clock 31.044654099s] Trained 128 records in 0.111087627 seconds. Throughput is 1152.2435 records/second. Loss is 2.2958987. Sequentiale465b572's hyper parameters: Current learning rate is 8.340283569641367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25728/60000][Iteration 201][Wall Clock 31.163651008s] Trained 128 records in 0.118996909 seconds. Throughput is 1075.6582 records/second. Loss is 2.2883606. Sequentiale465b572's hyper parameters: Current learning rate is 8.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 202][Wall Clock 31.287145906s] Trained 128 records in 0.123494898 seconds. Throughput is 1036.4801 records/second. Loss is 2.2986841. Sequentiale465b572's hyper parameters: Current learning rate is 8.326394671107411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 25984/60000][Iteration 203][Wall Clock 31.392164375s] Trained 128 records in 0.105018469 seconds. Throughput is 1218.8333 records/second. Loss is 2.2928689. Sequentiale465b572's hyper parameters: Current learning rate is 8.319467554076539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 204][Wall Clock 31.493102376s] Trained 128 records in 0.100938001 seconds. Throughput is 1268.1052 records/second. Loss is 2.2909117. Sequentiale465b572's hyper parameters: Current learning rate is 8.312551953449709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:13 INFO  DistriOptimizer$:408 - [Epoch 1 26240/60000][Iteration 205][Wall Clock 31.604637633s] Trained 128 records in 0.111535257 seconds. Throughput is 1147.6191 records/second. Loss is 2.289399. Sequentiale465b572's hyper parameters: Current learning rate is 8.305647840531562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 206][Wall Clock 31.73083759s] Trained 128 records in 0.126199957 seconds. Throughput is 1014.26337 records/second. Loss is 2.299939. Sequentiale465b572's hyper parameters: Current learning rate is 8.298755186721991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 26496/60000][Iteration 207][Wall Clock 31.84543609s] Trained 128 records in 0.1145985 seconds. Throughput is 1116.9431 records/second. Loss is 2.290184. Sequentiale465b572's hyper parameters: Current learning rate is 8.291873963515755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 208][Wall Clock 31.970888235s] Trained 128 records in 0.125452145 seconds. Throughput is 1020.3094 records/second. Loss is 2.2967832. Sequentiale465b572's hyper parameters: Current learning rate is 8.285004142502071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 26752/60000][Iteration 209][Wall Clock 32.089258325s] Trained 128 records in 0.11837009 seconds. Throughput is 1081.3542 records/second. Loss is 2.3096213. Sequentiale465b572's hyper parameters: Current learning rate is 8.278145695364238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 210][Wall Clock 32.197411059s] Trained 128 records in 0.108152734 seconds. Throughput is 1183.5115 records/second. Loss is 2.3116693. Sequentiale465b572's hyper parameters: Current learning rate is 8.271298593879239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 27008/60000][Iteration 211][Wall Clock 32.302069618s] Trained 128 records in 0.104658559 seconds. Throughput is 1223.0247 records/second. Loss is 2.2869253. Sequentiale465b572's hyper parameters: Current learning rate is 8.264462809917356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 212][Wall Clock 32.435226809s] Trained 128 records in 0.133157191 seconds. Throughput is 961.2699 records/second. Loss is 2.288974. Sequentiale465b572's hyper parameters: Current learning rate is 8.257638315441783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 27264/60000][Iteration 213][Wall Clock 32.540562197s] Trained 128 records in 0.105335388 seconds. Throughput is 1215.1663 records/second. Loss is 2.295935. Sequentiale465b572's hyper parameters: Current learning rate is 8.250825082508251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:14 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 214][Wall Clock 32.65384312s] Trained 128 records in 0.113280923 seconds. Throughput is 1129.9343 records/second. Loss is 2.301609. Sequentiale465b572's hyper parameters: Current learning rate is 8.244023083264633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 27520/60000][Iteration 215][Wall Clock 32.761944886s] Trained 128 records in 0.108101766 seconds. Throughput is 1184.0695 records/second. Loss is 2.291334. Sequentiale465b572's hyper parameters: Current learning rate is 8.237232289950577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 216][Wall Clock 32.886997016s] Trained 128 records in 0.12505213 seconds. Throughput is 1023.5732 records/second. Loss is 2.3061721. Sequentiale465b572's hyper parameters: Current learning rate is 8.230452674897119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 27776/60000][Iteration 217][Wall Clock 33.003226215s] Trained 128 records in 0.116229199 seconds. Throughput is 1101.2723 records/second. Loss is 2.3000395. Sequentiale465b572's hyper parameters: Current learning rate is 8.223684210526316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 218][Wall Clock 33.115999575s] Trained 128 records in 0.11277336 seconds. Throughput is 1135.0199 records/second. Loss is 2.2882738. Sequentiale465b572's hyper parameters: Current learning rate is 8.216926869350862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 28032/60000][Iteration 219][Wall Clock 33.259892031s] Trained 128 records in 0.143892456 seconds. Throughput is 889.5533 records/second. Loss is 2.2843187. Sequentiale465b572's hyper parameters: Current learning rate is 8.210180623973728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 220][Wall Clock 33.386574191s] Trained 128 records in 0.12668216 seconds. Throughput is 1010.4027 records/second. Loss is 2.295243. Sequentiale465b572's hyper parameters: Current learning rate is 8.203445447087776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 28288/60000][Iteration 221][Wall Clock 33.510211545s] Trained 128 records in 0.123637354 seconds. Throughput is 1035.2858 records/second. Loss is 2.3166978. Sequentiale465b572's hyper parameters: Current learning rate is 8.19672131147541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:15 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 222][Wall Clock 33.619854918s] Trained 128 records in 0.109643373 seconds. Throughput is 1167.4213 records/second. Loss is 2.3030014. Sequentiale465b572's hyper parameters: Current learning rate is 8.190008190008189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 28544/60000][Iteration 223][Wall Clock 33.730475964s] Trained 128 records in 0.110621046 seconds. Throughput is 1157.1035 records/second. Loss is 2.306643. Sequentiale465b572's hyper parameters: Current learning rate is 8.183306055646482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 224][Wall Clock 33.83244371s] Trained 128 records in 0.101967746 seconds. Throughput is 1255.299 records/second. Loss is 2.2884753. Sequentiale465b572's hyper parameters: Current learning rate is 8.176614881439083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 28800/60000][Iteration 225][Wall Clock 33.942808934s] Trained 128 records in 0.110365224 seconds. Throughput is 1159.7856 records/second. Loss is 2.3049033. Sequentiale465b572's hyper parameters: Current learning rate is 8.169934640522876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 226][Wall Clock 34.084789716s] Trained 128 records in 0.141980782 seconds. Throughput is 901.53046 records/second. Loss is 2.2862484. Sequentiale465b572's hyper parameters: Current learning rate is 8.163265306122448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 29056/60000][Iteration 227][Wall Clock 34.190808029s] Trained 128 records in 0.106018313 seconds. Throughput is 1207.3386 records/second. Loss is 2.2961318. Sequentiale465b572's hyper parameters: Current learning rate is 8.156606851549756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 228][Wall Clock 34.292830981s] Trained 128 records in 0.102022952 seconds. Throughput is 1254.6196 records/second. Loss is 2.2870724. Sequentiale465b572's hyper parameters: Current learning rate is 8.149959250203749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 29312/60000][Iteration 229][Wall Clock 34.403251491s] Trained 128 records in 0.11042051 seconds. Throughput is 1159.205 records/second. Loss is 2.2960045. Sequentiale465b572's hyper parameters: Current learning rate is 8.143322475570033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 230][Wall Clock 34.513079591s] Trained 128 records in 0.1098281 seconds. Throughput is 1165.4576 records/second. Loss is 2.2854764. Sequentiale465b572's hyper parameters: Current learning rate is 8.136696501220504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:16 INFO  DistriOptimizer$:408 - [Epoch 1 29568/60000][Iteration 231][Wall Clock 34.617855953s] Trained 128 records in 0.104776362 seconds. Throughput is 1221.6497 records/second. Loss is 2.31193. Sequentiale465b572's hyper parameters: Current learning rate is 8.130081300813008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 232][Wall Clock 34.747475761s] Trained 128 records in 0.129619808 seconds. Throughput is 987.5034 records/second. Loss is 2.2919953. Sequentiale465b572's hyper parameters: Current learning rate is 8.123476848090983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 29824/60000][Iteration 233][Wall Clock 34.884268205s] Trained 128 records in 0.136792444 seconds. Throughput is 935.7241 records/second. Loss is 2.2947528. Sequentiale465b572's hyper parameters: Current learning rate is 8.116883116883117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 234][Wall Clock 35.036119505s] Trained 128 records in 0.1518513 seconds. Throughput is 842.92993 records/second. Loss is 2.292807. Sequentiale465b572's hyper parameters: Current learning rate is 8.110300081103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 30080/60000][Iteration 235][Wall Clock 35.156876022s] Trained 128 records in 0.120756517 seconds. Throughput is 1059.9843 records/second. Loss is 2.2821774. Sequentiale465b572's hyper parameters: Current learning rate is 8.103727714748785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 236][Wall Clock 35.282304251s] Trained 128 records in 0.125428229 seconds. Throughput is 1020.5039 records/second. Loss is 2.293353. Sequentiale465b572's hyper parameters: Current learning rate is 8.097165991902834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 30336/60000][Iteration 237][Wall Clock 35.38468513s] Trained 128 records in 0.102380879 seconds. Throughput is 1250.2334 records/second. Loss is 2.2876332. Sequentiale465b572's hyper parameters: Current learning rate is 8.090614886731392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 238][Wall Clock 35.487524666s] Trained 128 records in 0.102839536 seconds. Throughput is 1244.6575 records/second. Loss is 2.2990308. Sequentiale465b572's hyper parameters: Current learning rate is 8.084074373484236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:17 INFO  DistriOptimizer$:408 - [Epoch 1 30592/60000][Iteration 239][Wall Clock 35.603818646s] Trained 128 records in 0.11629398 seconds. Throughput is 1100.6588 records/second. Loss is 2.2862668. Sequentiale465b572's hyper parameters: Current learning rate is 8.077544426494346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 240][Wall Clock 35.704379686s] Trained 128 records in 0.10056104 seconds. Throughput is 1272.8588 records/second. Loss is 2.2860754. Sequentiale465b572's hyper parameters: Current learning rate is 8.071025020177562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 30848/60000][Iteration 241][Wall Clock 35.838973338s] Trained 128 records in 0.134593652 seconds. Throughput is 951.0107 records/second. Loss is 2.2964132. Sequentiale465b572's hyper parameters: Current learning rate is 8.064516129032258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 242][Wall Clock 35.977093855s] Trained 128 records in 0.138120517 seconds. Throughput is 926.7269 records/second. Loss is 2.2958214. Sequentiale465b572's hyper parameters: Current learning rate is 8.058017727639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 31104/60000][Iteration 243][Wall Clock 36.092968311s] Trained 128 records in 0.115874456 seconds. Throughput is 1104.6438 records/second. Loss is 2.2881618. Sequentiale465b572's hyper parameters: Current learning rate is 8.051529790660225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 244][Wall Clock 36.230916402s] Trained 128 records in 0.137948091 seconds. Throughput is 927.88525 records/second. Loss is 2.2762218. Sequentiale465b572's hyper parameters: Current learning rate is 8.045052292839904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 31360/60000][Iteration 245][Wall Clock 36.380951937s] Trained 128 records in 0.150035535 seconds. Throughput is 853.1312 records/second. Loss is 2.3001862. Sequentiale465b572's hyper parameters: Current learning rate is 8.038585209003215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 246][Wall Clock 36.501057343s] Trained 128 records in 0.120105406 seconds. Throughput is 1065.7305 records/second. Loss is 2.2823653. Sequentiale465b572's hyper parameters: Current learning rate is 8.032128514056224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:18 INFO  DistriOptimizer$:408 - [Epoch 1 31616/60000][Iteration 247][Wall Clock 36.637723814s] Trained 128 records in 0.136666471 seconds. Throughput is 936.5867 records/second. Loss is 2.293669. Sequentiale465b572's hyper parameters: Current learning rate is 8.025682182985554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 248][Wall Clock 36.810665681s] Trained 128 records in 0.172941867 seconds. Throughput is 740.1331 records/second. Loss is 2.2857976. Sequentiale465b572's hyper parameters: Current learning rate is 8.01924619085806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 31872/60000][Iteration 249][Wall Clock 36.961109929s] Trained 128 records in 0.150444248 seconds. Throughput is 850.8135 records/second. Loss is 2.2926424. Sequentiale465b572's hyper parameters: Current learning rate is 8.012820512820513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 250][Wall Clock 37.09423612s] Trained 128 records in 0.133126191 seconds. Throughput is 961.4938 records/second. Loss is 2.2963467. Sequentiale465b572's hyper parameters: Current learning rate is 8.006405124099279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 32128/60000][Iteration 251][Wall Clock 37.213944798s] Trained 128 records in 0.119708678 seconds. Throughput is 1069.2625 records/second. Loss is 2.2914057. Sequentiale465b572's hyper parameters: Current learning rate is 8.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 252][Wall Clock 37.362850601s] Trained 128 records in 0.148905803 seconds. Throughput is 859.6039 records/second. Loss is 2.2888625. Sequentiale465b572's hyper parameters: Current learning rate is 7.993605115907275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 32384/60000][Iteration 253][Wall Clock 37.490247213s] Trained 128 records in 0.127396612 seconds. Throughput is 1004.73627 records/second. Loss is 2.305012. Sequentiale465b572's hyper parameters: Current learning rate is 7.987220447284345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:19 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 254][Wall Clock 37.632813478s] Trained 128 records in 0.142566265 seconds. Throughput is 897.8281 records/second. Loss is 2.2926273. Sequentiale465b572's hyper parameters: Current learning rate is 7.980845969672785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 32640/60000][Iteration 255][Wall Clock 37.76542126s] Trained 128 records in 0.132607782 seconds. Throughput is 965.2525 records/second. Loss is 2.2891054. Sequentiale465b572's hyper parameters: Current learning rate is 7.974481658692185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 256][Wall Clock 37.901697306s] Trained 128 records in 0.136276046 seconds. Throughput is 939.26996 records/second. Loss is 2.2811668. Sequentiale465b572's hyper parameters: Current learning rate is 7.968127490039842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 32896/60000][Iteration 257][Wall Clock 38.007297312s] Trained 128 records in 0.105600006 seconds. Throughput is 1212.1211 records/second. Loss is 2.2888892. Sequentiale465b572's hyper parameters: Current learning rate is 7.961783439490446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 258][Wall Clock 38.107158737s] Trained 128 records in 0.099861425 seconds. Throughput is 1281.7761 records/second. Loss is 2.305524. Sequentiale465b572's hyper parameters: Current learning rate is 7.955449482895783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 33152/60000][Iteration 259][Wall Clock 38.207430993s] Trained 128 records in 0.100272256 seconds. Throughput is 1276.5247 records/second. Loss is 2.2934234. Sequentiale465b572's hyper parameters: Current learning rate is 7.94912559618442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 260][Wall Clock 38.307375126s] Trained 128 records in 0.099944133 seconds. Throughput is 1280.7156 records/second. Loss is 2.2829719. Sequentiale465b572's hyper parameters: Current learning rate is 7.942811755361399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 33408/60000][Iteration 261][Wall Clock 38.416342585s] Trained 128 records in 0.108967459 seconds. Throughput is 1174.6626 records/second. Loss is 2.2901611. Sequentiale465b572's hyper parameters: Current learning rate is 7.936507936507937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 262][Wall Clock 38.519927808s] Trained 128 records in 0.103585223 seconds. Throughput is 1235.6975 records/second. Loss is 2.297492. Sequentiale465b572's hyper parameters: Current learning rate is 7.930214115781125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:20 INFO  DistriOptimizer$:408 - [Epoch 1 33664/60000][Iteration 263][Wall Clock 38.623687407s] Trained 128 records in 0.103759599 seconds. Throughput is 1233.6207 records/second. Loss is 2.2890873. Sequentiale465b572's hyper parameters: Current learning rate is 7.92393026941363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 264][Wall Clock 38.74070661s] Trained 128 records in 0.117019203 seconds. Throughput is 1093.8375 records/second. Loss is 2.2970781. Sequentiale465b572's hyper parameters: Current learning rate is 7.917656373713382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 33920/60000][Iteration 265][Wall Clock 38.870839061s] Trained 128 records in 0.130132451 seconds. Throughput is 983.6132 records/second. Loss is 2.2981417. Sequentiale465b572's hyper parameters: Current learning rate is 7.911392405063291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 266][Wall Clock 38.969717174s] Trained 128 records in 0.098878113 seconds. Throughput is 1294.5231 records/second. Loss is 2.2959263. Sequentiale465b572's hyper parameters: Current learning rate is 7.905138339920949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 34176/60000][Iteration 267][Wall Clock 39.077651014s] Trained 128 records in 0.10793384 seconds. Throughput is 1185.9116 records/second. Loss is 2.2951717. Sequentiale465b572's hyper parameters: Current learning rate is 7.898894154818325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 268][Wall Clock 39.197162405s] Trained 128 records in 0.119511391 seconds. Throughput is 1071.0276 records/second. Loss is 2.3074627. Sequentiale465b572's hyper parameters: Current learning rate is 7.892659826361485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 34432/60000][Iteration 269][Wall Clock 39.316359034s] Trained 128 records in 0.119196629 seconds. Throughput is 1073.8558 records/second. Loss is 2.2691333. Sequentiale465b572's hyper parameters: Current learning rate is 7.886435331230284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 270][Wall Clock 39.429032389s] Trained 128 records in 0.112673355 seconds. Throughput is 1136.0272 records/second. Loss is 2.2868347. Sequentiale465b572's hyper parameters: Current learning rate is 7.880220646178092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:21 INFO  DistriOptimizer$:408 - [Epoch 1 34688/60000][Iteration 271][Wall Clock 39.53587509s] Trained 128 records in 0.106842701 seconds. Throughput is 1198.0228 records/second. Loss is 2.2808177. Sequentiale465b572's hyper parameters: Current learning rate is 7.874015748031496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 272][Wall Clock 39.646084817s] Trained 128 records in 0.110209727 seconds. Throughput is 1161.422 records/second. Loss is 2.2838593. Sequentiale465b572's hyper parameters: Current learning rate is 7.867820613690009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 34944/60000][Iteration 273][Wall Clock 39.759037123s] Trained 128 records in 0.112952306 seconds. Throughput is 1133.2217 records/second. Loss is 2.293175. Sequentiale465b572's hyper parameters: Current learning rate is 7.861635220125787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 274][Wall Clock 39.869479221s] Trained 128 records in 0.110442098 seconds. Throughput is 1158.9784 records/second. Loss is 2.2852285. Sequentiale465b572's hyper parameters: Current learning rate is 7.855459544383346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35200/60000][Iteration 275][Wall Clock 39.978112563s] Trained 128 records in 0.108633342 seconds. Throughput is 1178.2755 records/second. Loss is 2.279893. Sequentiale465b572's hyper parameters: Current learning rate is 7.849293563579278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 276][Wall Clock 40.08230854s] Trained 128 records in 0.104195977 seconds. Throughput is 1228.4543 records/second. Loss is 2.2912958. Sequentiale465b572's hyper parameters: Current learning rate is 7.843137254901962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35456/60000][Iteration 277][Wall Clock 40.215382057s] Trained 128 records in 0.133073517 seconds. Throughput is 961.87427 records/second. Loss is 2.297895. Sequentiale465b572's hyper parameters: Current learning rate is 7.836990595611285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 278][Wall Clock 40.322542474s] Trained 128 records in 0.107160417 seconds. Throughput is 1194.4708 records/second. Loss is 2.2876072. Sequentiale465b572's hyper parameters: Current learning rate is 7.83085356303837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35712/60000][Iteration 279][Wall Clock 40.431636691s] Trained 128 records in 0.109094217 seconds. Throughput is 1173.2977 records/second. Loss is 2.3020308. Sequentiale465b572's hyper parameters: Current learning rate is 7.82472613458529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 280][Wall Clock 40.532071248s] Trained 128 records in 0.100434557 seconds. Throughput is 1274.4618 records/second. Loss is 2.282364. Sequentiale465b572's hyper parameters: Current learning rate is 7.818608287724786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:22 INFO  DistriOptimizer$:408 - [Epoch 1 35968/60000][Iteration 281][Wall Clock 40.629271392s] Trained 128 records in 0.097200144 seconds. Throughput is 1316.8705 records/second. Loss is 2.2731102. Sequentiale465b572's hyper parameters: Current learning rate is 7.8125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 282][Wall Clock 40.725033181s] Trained 128 records in 0.095761789 seconds. Throughput is 1336.65 records/second. Loss is 2.287902. Sequentiale465b572's hyper parameters: Current learning rate is 7.806401249024199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36224/60000][Iteration 283][Wall Clock 40.821264442s] Trained 128 records in 0.096231261 seconds. Throughput is 1330.1292 records/second. Loss is 2.2913046. Sequentiale465b572's hyper parameters: Current learning rate is 7.8003120124805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 284][Wall Clock 40.922241509s] Trained 128 records in 0.100977067 seconds. Throughput is 1267.6145 records/second. Loss is 2.2965689. Sequentiale465b572's hyper parameters: Current learning rate is 7.79423226812159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36480/60000][Iteration 285][Wall Clock 41.023970418s] Trained 128 records in 0.101728909 seconds. Throughput is 1258.2461 records/second. Loss is 2.2865512. Sequentiale465b572's hyper parameters: Current learning rate is 7.78816199376947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 286][Wall Clock 41.125967716s] Trained 128 records in 0.101997298 seconds. Throughput is 1254.9352 records/second. Loss is 2.2878935. Sequentiale465b572's hyper parameters: Current learning rate is 7.782101167315175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36736/60000][Iteration 287][Wall Clock 41.229450051s] Trained 128 records in 0.103482335 seconds. Throughput is 1236.926 records/second. Loss is 2.2770658. Sequentiale465b572's hyper parameters: Current learning rate is 7.776049766718507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 288][Wall Clock 41.332492099s] Trained 128 records in 0.103042048 seconds. Throughput is 1242.2113 records/second. Loss is 2.2911172. Sequentiale465b572's hyper parameters: Current learning rate is 7.770007770007771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 36992/60000][Iteration 289][Wall Clock 41.471036717s] Trained 128 records in 0.138544618 seconds. Throughput is 923.8901 records/second. Loss is 2.2844431. Sequentiale465b572's hyper parameters: Current learning rate is 7.763975155279503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:23 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 290][Wall Clock 41.570409443s] Trained 128 records in 0.099372726 seconds. Throughput is 1288.0797 records/second. Loss is 2.2798767. Sequentiale465b572's hyper parameters: Current learning rate is 7.757951900698217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 37248/60000][Iteration 291][Wall Clock 41.680253213s] Trained 128 records in 0.10984377 seconds. Throughput is 1165.2914 records/second. Loss is 2.2865329. Sequentiale465b572's hyper parameters: Current learning rate is 7.751937984496124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 292][Wall Clock 41.795526734s] Trained 128 records in 0.115273521 seconds. Throughput is 1110.4025 records/second. Loss is 2.3021836. Sequentiale465b572's hyper parameters: Current learning rate is 7.74593338497289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 37504/60000][Iteration 293][Wall Clock 41.913580665s] Trained 128 records in 0.118053931 seconds. Throughput is 1084.2502 records/second. Loss is 2.2958615. Sequentiale465b572's hyper parameters: Current learning rate is 7.739938080495357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 294][Wall Clock 42.031679109s] Trained 128 records in 0.118098444 seconds. Throughput is 1083.8416 records/second. Loss is 2.2951283. Sequentiale465b572's hyper parameters: Current learning rate is 7.733952049497294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 37760/60000][Iteration 295][Wall Clock 42.149853949s] Trained 128 records in 0.11817484 seconds. Throughput is 1083.1409 records/second. Loss is 2.2953942. Sequentiale465b572's hyper parameters: Current learning rate is 7.727975270479134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 296][Wall Clock 42.277431941s] Trained 128 records in 0.127577992 seconds. Throughput is 1003.30786 records/second. Loss is 2.2790112. Sequentiale465b572's hyper parameters: Current learning rate is 7.722007722007723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 38016/60000][Iteration 297][Wall Clock 42.383263444s] Trained 128 records in 0.105831503 seconds. Throughput is 1209.4697 records/second. Loss is 2.290545. Sequentiale465b572's hyper parameters: Current learning rate is 7.716049382716049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 298][Wall Clock 42.491019413s] Trained 128 records in 0.107755969 seconds. Throughput is 1187.8693 records/second. Loss is 2.2808414. Sequentiale465b572's hyper parameters: Current learning rate is 7.710100231303008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:24 INFO  DistriOptimizer$:408 - [Epoch 1 38272/60000][Iteration 299][Wall Clock 42.593961633s] Trained 128 records in 0.10294222 seconds. Throughput is 1243.416 records/second. Loss is 2.2883236. Sequentiale465b572's hyper parameters: Current learning rate is 7.704160246533128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 300][Wall Clock 42.700397902s] Trained 128 records in 0.106436269 seconds. Throughput is 1202.5977 records/second. Loss is 2.2780333. Sequentiale465b572's hyper parameters: Current learning rate is 7.698229407236336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 38528/60000][Iteration 301][Wall Clock 42.853752645s] Trained 128 records in 0.153354743 seconds. Throughput is 834.666 records/second. Loss is 2.2919502. Sequentiale465b572's hyper parameters: Current learning rate is 7.692307692307692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 302][Wall Clock 42.951541756s] Trained 128 records in 0.097789111 seconds. Throughput is 1308.9392 records/second. Loss is 2.2963023. Sequentiale465b572's hyper parameters: Current learning rate is 7.686395080707148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 38784/60000][Iteration 303][Wall Clock 43.056243392s] Trained 128 records in 0.104701636 seconds. Throughput is 1222.5215 records/second. Loss is 2.283236. Sequentiale465b572's hyper parameters: Current learning rate is 7.680491551459293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 304][Wall Clock 43.157036462s] Trained 128 records in 0.10079307 seconds. Throughput is 1269.9286 records/second. Loss is 2.285605. Sequentiale465b572's hyper parameters: Current learning rate is 7.674597083653109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 39040/60000][Iteration 305][Wall Clock 43.258763157s] Trained 128 records in 0.101726695 seconds. Throughput is 1258.2734 records/second. Loss is 2.290109. Sequentiale465b572's hyper parameters: Current learning rate is 7.668711656441718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 306][Wall Clock 43.35720432s] Trained 128 records in 0.098441163 seconds. Throughput is 1300.269 records/second. Loss is 2.2890768. Sequentiale465b572's hyper parameters: Current learning rate is 7.662835249042146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 39296/60000][Iteration 307][Wall Clock 43.455979519s] Trained 128 records in 0.098775199 seconds. Throughput is 1295.8718 records/second. Loss is 2.288548. Sequentiale465b572's hyper parameters: Current learning rate is 7.656967840735069E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:25 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 308][Wall Clock 43.562263518s] Trained 128 records in 0.106283999 seconds. Throughput is 1204.3206 records/second. Loss is 2.2983642. Sequentiale465b572's hyper parameters: Current learning rate is 7.651109410864576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 39552/60000][Iteration 309][Wall Clock 43.689197395s] Trained 128 records in 0.126933877 seconds. Throughput is 1008.39905 records/second. Loss is 2.2925494. Sequentiale465b572's hyper parameters: Current learning rate is 7.645259938837921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 310][Wall Clock 43.810383333s] Trained 128 records in 0.121185938 seconds. Throughput is 1056.2281 records/second. Loss is 2.2916658. Sequentiale465b572's hyper parameters: Current learning rate is 7.639419404125287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 39808/60000][Iteration 311][Wall Clock 43.912649081s] Trained 128 records in 0.102265748 seconds. Throughput is 1251.641 records/second. Loss is 2.2805684. Sequentiale465b572's hyper parameters: Current learning rate is 7.633587786259542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 312][Wall Clock 44.029022275s] Trained 128 records in 0.116373194 seconds. Throughput is 1099.9097 records/second. Loss is 2.2925735. Sequentiale465b572's hyper parameters: Current learning rate is 7.627765064836003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 40064/60000][Iteration 313][Wall Clock 44.146347194s] Trained 128 records in 0.117324919 seconds. Throughput is 1090.9873 records/second. Loss is 2.2809234. Sequentiale465b572's hyper parameters: Current learning rate is 7.621951219512195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 314][Wall Clock 44.297628845s] Trained 128 records in 0.151281651 seconds. Throughput is 846.1039 records/second. Loss is 2.276186. Sequentiale465b572's hyper parameters: Current learning rate is 7.616146230007616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:26 INFO  DistriOptimizer$:408 - [Epoch 1 40320/60000][Iteration 315][Wall Clock 44.439344902s] Trained 128 records in 0.141716057 seconds. Throughput is 903.2145 records/second. Loss is 2.2879953. Sequentiale465b572's hyper parameters: Current learning rate is 7.6103500761035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 316][Wall Clock 44.636553023s] Trained 128 records in 0.197208121 seconds. Throughput is 649.0605 records/second. Loss is 2.271941. Sequentiale465b572's hyper parameters: Current learning rate is 7.604562737642586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 40576/60000][Iteration 317][Wall Clock 44.759247028s] Trained 128 records in 0.122694005 seconds. Throughput is 1043.2457 records/second. Loss is 2.273337. Sequentiale465b572's hyper parameters: Current learning rate is 7.598784194528875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 318][Wall Clock 44.868609258s] Trained 128 records in 0.10936223 seconds. Throughput is 1170.4224 records/second. Loss is 2.2832837. Sequentiale465b572's hyper parameters: Current learning rate is 7.593014426727411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 40832/60000][Iteration 319][Wall Clock 44.971243722s] Trained 128 records in 0.102634464 seconds. Throughput is 1247.1444 records/second. Loss is 2.287583. Sequentiale465b572's hyper parameters: Current learning rate is 7.587253414264037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 320][Wall Clock 45.073867979s] Trained 128 records in 0.102624257 seconds. Throughput is 1247.2684 records/second. Loss is 2.2885776. Sequentiale465b572's hyper parameters: Current learning rate is 7.58150113722517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 41088/60000][Iteration 321][Wall Clock 45.189223549s] Trained 128 records in 0.11535557 seconds. Throughput is 1109.6127 records/second. Loss is 2.27725. Sequentiale465b572's hyper parameters: Current learning rate is 7.575757575757576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 322][Wall Clock 45.297466419s] Trained 128 records in 0.10824287 seconds. Throughput is 1182.5259 records/second. Loss is 2.292026. Sequentiale465b572's hyper parameters: Current learning rate is 7.57002271006813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 41344/60000][Iteration 323][Wall Clock 45.403662589s] Trained 128 records in 0.10619617 seconds. Throughput is 1205.3165 records/second. Loss is 2.3011348. Sequentiale465b572's hyper parameters: Current learning rate is 7.564296520423601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:27 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 324][Wall Clock 45.518023359s] Trained 128 records in 0.11436077 seconds. Throughput is 1119.2649 records/second. Loss is 2.2755795. Sequentiale465b572's hyper parameters: Current learning rate is 7.558578987150416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 41600/60000][Iteration 325][Wall Clock 45.628929754s] Trained 128 records in 0.110906395 seconds. Throughput is 1154.1265 records/second. Loss is 2.2824001. Sequentiale465b572's hyper parameters: Current learning rate is 7.552870090634441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 326][Wall Clock 45.735212931s] Trained 128 records in 0.106283177 seconds. Throughput is 1204.3298 records/second. Loss is 2.2760732. Sequentiale465b572's hyper parameters: Current learning rate is 7.547169811320755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 41856/60000][Iteration 327][Wall Clock 45.837407258s] Trained 128 records in 0.102194327 seconds. Throughput is 1252.5157 records/second. Loss is 2.280634. Sequentiale465b572's hyper parameters: Current learning rate is 7.541478129713424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 328][Wall Clock 45.941915699s] Trained 128 records in 0.104508441 seconds. Throughput is 1224.7814 records/second. Loss is 2.3023791. Sequentiale465b572's hyper parameters: Current learning rate is 7.535795026375283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 42112/60000][Iteration 329][Wall Clock 46.051391723s] Trained 128 records in 0.109476024 seconds. Throughput is 1169.2058 records/second. Loss is 2.2879362. Sequentiale465b572's hyper parameters: Current learning rate is 7.53012048192771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 330][Wall Clock 46.146973531s] Trained 128 records in 0.095581808 seconds. Throughput is 1339.167 records/second. Loss is 2.2917826. Sequentiale465b572's hyper parameters: Current learning rate is 7.524454477050415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 42368/60000][Iteration 331][Wall Clock 46.244177883s] Trained 128 records in 0.097204352 seconds. Throughput is 1316.8135 records/second. Loss is 2.2724347. Sequentiale465b572's hyper parameters: Current learning rate is 7.518796992481202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 332][Wall Clock 46.374122215s] Trained 128 records in 0.129944332 seconds. Throughput is 985.0371 records/second. Loss is 2.3031867. Sequentiale465b572's hyper parameters: Current learning rate is 7.513148009015778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 42624/60000][Iteration 333][Wall Clock 46.476234074s] Trained 128 records in 0.102111859 seconds. Throughput is 1253.5272 records/second. Loss is 2.287232. Sequentiale465b572's hyper parameters: Current learning rate is 7.507507507507507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:28 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 334][Wall Clock 46.575960583s] Trained 128 records in 0.099726509 seconds. Throughput is 1283.5104 records/second. Loss is 2.283935. Sequentiale465b572's hyper parameters: Current learning rate is 7.501875468867217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 42880/60000][Iteration 335][Wall Clock 46.69800751s] Trained 128 records in 0.122046927 seconds. Throughput is 1048.777 records/second. Loss is 2.3024569. Sequentiale465b572's hyper parameters: Current learning rate is 7.496251874062968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 336][Wall Clock 46.831641233s] Trained 128 records in 0.133633723 seconds. Throughput is 957.8421 records/second. Loss is 2.2970152. Sequentiale465b572's hyper parameters: Current learning rate is 7.49063670411985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43136/60000][Iteration 337][Wall Clock 46.93372506s] Trained 128 records in 0.102083827 seconds. Throughput is 1253.8715 records/second. Loss is 2.2984374. Sequentiale465b572's hyper parameters: Current learning rate is 7.48502994011976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 338][Wall Clock 47.033460085s] Trained 128 records in 0.099735025 seconds. Throughput is 1283.4008 records/second. Loss is 2.2807503. Sequentiale465b572's hyper parameters: Current learning rate is 7.479431563201197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43392/60000][Iteration 339][Wall Clock 47.134007515s] Trained 128 records in 0.10054743 seconds. Throughput is 1273.031 records/second. Loss is 2.2739816. Sequentiale465b572's hyper parameters: Current learning rate is 7.473841554559044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 340][Wall Clock 47.251857218s] Trained 128 records in 0.117849703 seconds. Throughput is 1086.1292 records/second. Loss is 2.2804537. Sequentiale465b572's hyper parameters: Current learning rate is 7.468259895444362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43648/60000][Iteration 341][Wall Clock 47.381951753s] Trained 128 records in 0.130094535 seconds. Throughput is 983.89996 records/second. Loss is 2.2888436. Sequentiale465b572's hyper parameters: Current learning rate is 7.462686567164179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:29 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 342][Wall Clock 47.498085774s] Trained 128 records in 0.116134021 seconds. Throughput is 1102.1749 records/second. Loss is 2.2937865. Sequentiale465b572's hyper parameters: Current learning rate is 7.457121551081283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 43904/60000][Iteration 343][Wall Clock 47.62189289s] Trained 128 records in 0.123807116 seconds. Throughput is 1033.8662 records/second. Loss is 2.2851377. Sequentiale465b572's hyper parameters: Current learning rate is 7.451564828614009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 344][Wall Clock 47.724355849s] Trained 128 records in 0.102462959 seconds. Throughput is 1249.2319 records/second. Loss is 2.2851284. Sequentiale465b572's hyper parameters: Current learning rate is 7.446016381236039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44160/60000][Iteration 345][Wall Clock 47.82912718s] Trained 128 records in 0.104771331 seconds. Throughput is 1221.7083 records/second. Loss is 2.269506. Sequentiale465b572's hyper parameters: Current learning rate is 7.44047619047619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 346][Wall Clock 47.929575105s] Trained 128 records in 0.100447925 seconds. Throughput is 1274.2921 records/second. Loss is 2.29017. Sequentiale465b572's hyper parameters: Current learning rate is 7.434944237918215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44416/60000][Iteration 347][Wall Clock 48.032653916s] Trained 128 records in 0.103078811 seconds. Throughput is 1241.7683 records/second. Loss is 2.2921016. Sequentiale465b572's hyper parameters: Current learning rate is 7.429420505200594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 348][Wall Clock 48.137288259s] Trained 128 records in 0.104634343 seconds. Throughput is 1223.3077 records/second. Loss is 2.2844105. Sequentiale465b572's hyper parameters: Current learning rate is 7.423904974016333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44672/60000][Iteration 349][Wall Clock 48.257821737s] Trained 128 records in 0.120533478 seconds. Throughput is 1061.9456 records/second. Loss is 2.2887743. Sequentiale465b572's hyper parameters: Current learning rate is 7.418397626112759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 350][Wall Clock 48.370414828s] Trained 128 records in 0.112593091 seconds. Throughput is 1136.837 records/second. Loss is 2.294114. Sequentiale465b572's hyper parameters: Current learning rate is 7.412898443291328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:30 INFO  DistriOptimizer$:408 - [Epoch 1 44928/60000][Iteration 351][Wall Clock 48.469890361s] Trained 128 records in 0.099475533 seconds. Throughput is 1286.7485 records/second. Loss is 2.2858121. Sequentiale465b572's hyper parameters: Current learning rate is 7.407407407407407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 352][Wall Clock 48.605427871s] Trained 128 records in 0.13553751 seconds. Throughput is 944.38806 records/second. Loss is 2.2942104. Sequentiale465b572's hyper parameters: Current learning rate is 7.401924500370097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45184/60000][Iteration 353][Wall Clock 48.709976483s] Trained 128 records in 0.104548612 seconds. Throughput is 1224.3109 records/second. Loss is 2.2749546. Sequentiale465b572's hyper parameters: Current learning rate is 7.396449704142013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 354][Wall Clock 48.811395167s] Trained 128 records in 0.101418684 seconds. Throughput is 1262.0948 records/second. Loss is 2.269799. Sequentiale465b572's hyper parameters: Current learning rate is 7.390983000739098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45440/60000][Iteration 355][Wall Clock 48.912316203s] Trained 128 records in 0.100921036 seconds. Throughput is 1268.3184 records/second. Loss is 2.2980225. Sequentiale465b572's hyper parameters: Current learning rate is 7.385524372230428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 356][Wall Clock 49.022500643s] Trained 128 records in 0.11018444 seconds. Throughput is 1161.6886 records/second. Loss is 2.2819154. Sequentiale465b572's hyper parameters: Current learning rate is 7.380073800738007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45696/60000][Iteration 357][Wall Clock 49.123963119s] Trained 128 records in 0.101462476 seconds. Throughput is 1261.5502 records/second. Loss is 2.2912233. Sequentiale465b572's hyper parameters: Current learning rate is 7.374631268436579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 358][Wall Clock 49.239742902s] Trained 128 records in 0.115779783 seconds. Throughput is 1105.5471 records/second. Loss is 2.287705. Sequentiale465b572's hyper parameters: Current learning rate is 7.369196757553427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 45952/60000][Iteration 359][Wall Clock 49.34718937s] Trained 128 records in 0.107446468 seconds. Throughput is 1191.2909 records/second. Loss is 2.289471. Sequentiale465b572's hyper parameters: Current learning rate is 7.363770250368188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 360][Wall Clock 49.449024261s] Trained 128 records in 0.101834891 seconds. Throughput is 1256.9365 records/second. Loss is 2.2938683. Sequentiale465b572's hyper parameters: Current learning rate is 7.358351729212656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:31 INFO  DistriOptimizer$:408 - [Epoch 1 46208/60000][Iteration 361][Wall Clock 49.550862734s] Trained 128 records in 0.101838473 seconds. Throughput is 1256.8925 records/second. Loss is 2.2857594. Sequentiale465b572's hyper parameters: Current learning rate is 7.352941176470589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 362][Wall Clock 49.65298385s] Trained 128 records in 0.102121116 seconds. Throughput is 1253.4137 records/second. Loss is 2.2882845. Sequentiale465b572's hyper parameters: Current learning rate is 7.347538574577517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 46464/60000][Iteration 363][Wall Clock 49.763238214s] Trained 128 records in 0.110254364 seconds. Throughput is 1160.9518 records/second. Loss is 2.294728. Sequentiale465b572's hyper parameters: Current learning rate is 7.342143906020558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 364][Wall Clock 49.865894391s] Trained 128 records in 0.102656177 seconds. Throughput is 1246.8806 records/second. Loss is 2.2819433. Sequentiale465b572's hyper parameters: Current learning rate is 7.336757153338225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 46720/60000][Iteration 365][Wall Clock 49.986849605s] Trained 128 records in 0.120955214 seconds. Throughput is 1058.2429 records/second. Loss is 2.2852488. Sequentiale465b572's hyper parameters: Current learning rate is 7.331378299120236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 366][Wall Clock 50.100944814s] Trained 128 records in 0.114095209 seconds. Throughput is 1121.87 records/second. Loss is 2.286163. Sequentiale465b572's hyper parameters: Current learning rate is 7.326007326007326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 46976/60000][Iteration 367][Wall Clock 50.204850883s] Trained 128 records in 0.103906069 seconds. Throughput is 1231.8818 records/second. Loss is 2.2833827. Sequentiale465b572's hyper parameters: Current learning rate is 7.320644216691068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 368][Wall Clock 50.315876906s] Trained 128 records in 0.111026023 seconds. Throughput is 1152.8828 records/second. Loss is 2.2889574. Sequentiale465b572's hyper parameters: Current learning rate is 7.31528895391368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 47232/60000][Iteration 369][Wall Clock 50.431369906s] Trained 128 records in 0.115493 seconds. Throughput is 1108.2922 records/second. Loss is 2.2908528. Sequentiale465b572's hyper parameters: Current learning rate is 7.309941520467837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:32 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 370][Wall Clock 50.528658247s] Trained 128 records in 0.097288341 seconds. Throughput is 1315.6766 records/second. Loss is 2.2922192. Sequentiale465b572's hyper parameters: Current learning rate is 7.304601899196494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 47488/60000][Iteration 371][Wall Clock 50.628250343s] Trained 128 records in 0.099592096 seconds. Throughput is 1285.2426 records/second. Loss is 2.2948968. Sequentiale465b572's hyper parameters: Current learning rate is 7.2992700729927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 372][Wall Clock 50.725488417s] Trained 128 records in 0.097238074 seconds. Throughput is 1316.3568 records/second. Loss is 2.2715118. Sequentiale465b572's hyper parameters: Current learning rate is 7.293946024799417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 47744/60000][Iteration 373][Wall Clock 50.826419961s] Trained 128 records in 0.100931544 seconds. Throughput is 1268.1863 records/second. Loss is 2.2851305. Sequentiale465b572's hyper parameters: Current learning rate is 7.28862973760933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 374][Wall Clock 50.967227735s] Trained 128 records in 0.140807774 seconds. Throughput is 909.0407 records/second. Loss is 2.268999. Sequentiale465b572's hyper parameters: Current learning rate is 7.283321194464676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 48000/60000][Iteration 375][Wall Clock 51.06497767s] Trained 128 records in 0.097749935 seconds. Throughput is 1309.4637 records/second. Loss is 2.2749681. Sequentiale465b572's hyper parameters: Current learning rate is 7.278020378457059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 376][Wall Clock 51.184810153s] Trained 128 records in 0.119832483 seconds. Throughput is 1068.1577 records/second. Loss is 2.282508. Sequentiale465b572's hyper parameters: Current learning rate is 7.272727272727273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 48256/60000][Iteration 377][Wall Clock 51.282741037s] Trained 128 records in 0.097930884 seconds. Throughput is 1307.0442 records/second. Loss is 2.2788491. Sequentiale465b572's hyper parameters: Current learning rate is 7.267441860465117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 378][Wall Clock 51.400449388s] Trained 128 records in 0.117708351 seconds. Throughput is 1087.4335 records/second. Loss is 2.2832153. Sequentiale465b572's hyper parameters: Current learning rate is 7.262164124909223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:33 INFO  DistriOptimizer$:408 - [Epoch 1 48512/60000][Iteration 379][Wall Clock 51.507623099s] Trained 128 records in 0.107173711 seconds. Throughput is 1194.3228 records/second. Loss is 2.294226. Sequentiale465b572's hyper parameters: Current learning rate is 7.25689404934688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 380][Wall Clock 51.62497973s] Trained 128 records in 0.117356631 seconds. Throughput is 1090.6925 records/second. Loss is 2.2759402. Sequentiale465b572's hyper parameters: Current learning rate is 7.251631617113851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 48768/60000][Iteration 381][Wall Clock 51.7239258s] Trained 128 records in 0.09894607 seconds. Throughput is 1293.6339 records/second. Loss is 2.2767074. Sequentiale465b572's hyper parameters: Current learning rate is 7.246376811594204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 382][Wall Clock 51.823245638s] Trained 128 records in 0.099319838 seconds. Throughput is 1288.7657 records/second. Loss is 2.2867277. Sequentiale465b572's hyper parameters: Current learning rate is 7.241129616220131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49024/60000][Iteration 383][Wall Clock 51.923879108s] Trained 128 records in 0.10063347 seconds. Throughput is 1271.9426 records/second. Loss is 2.2817929. Sequentiale465b572's hyper parameters: Current learning rate is 7.23589001447178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 384][Wall Clock 52.034247119s] Trained 128 records in 0.110368011 seconds. Throughput is 1159.7563 records/second. Loss is 2.2879357. Sequentiale465b572's hyper parameters: Current learning rate is 7.230657989877079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49280/60000][Iteration 385][Wall Clock 52.138119408s] Trained 128 records in 0.103872289 seconds. Throughput is 1232.2825 records/second. Loss is 2.2895715. Sequentiale465b572's hyper parameters: Current learning rate is 7.225433526011561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 386][Wall Clock 52.234023367s] Trained 128 records in 0.095903959 seconds. Throughput is 1334.6686 records/second. Loss is 2.2819493. Sequentiale465b572's hyper parameters: Current learning rate is 7.220216606498195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49536/60000][Iteration 387][Wall Clock 52.329037612s] Trained 128 records in 0.095014245 seconds. Throughput is 1347.1664 records/second. Loss is 2.2770493. Sequentiale465b572's hyper parameters: Current learning rate is 7.215007215007215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 388][Wall Clock 52.423864247s] Trained 128 records in 0.094826635 seconds. Throughput is 1349.8317 records/second. Loss is 2.2727323. Sequentiale465b572's hyper parameters: Current learning rate is 7.209805335255948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:34 INFO  DistriOptimizer$:408 - [Epoch 1 49792/60000][Iteration 389][Wall Clock 52.527626992s] Trained 128 records in 0.103762745 seconds. Throughput is 1233.5834 records/second. Loss is 2.2836316. Sequentiale465b572's hyper parameters: Current learning rate is 7.204610951008646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 390][Wall Clock 52.638252311s] Trained 128 records in 0.110625319 seconds. Throughput is 1157.0588 records/second. Loss is 2.2878187. Sequentiale465b572's hyper parameters: Current learning rate is 7.199424046076314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50048/60000][Iteration 391][Wall Clock 52.731959281s] Trained 128 records in 0.09370697 seconds. Throughput is 1365.9602 records/second. Loss is 2.268954. Sequentiale465b572's hyper parameters: Current learning rate is 7.194244604316546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 392][Wall Clock 52.830492777s] Trained 128 records in 0.098533496 seconds. Throughput is 1299.0507 records/second. Loss is 2.277633. Sequentiale465b572's hyper parameters: Current learning rate is 7.189072609633358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50304/60000][Iteration 393][Wall Clock 52.931281636s] Trained 128 records in 0.100788859 seconds. Throughput is 1269.9816 records/second. Loss is 2.265293. Sequentiale465b572's hyper parameters: Current learning rate is 7.183908045977012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 394][Wall Clock 53.030104345s] Trained 128 records in 0.098822709 seconds. Throughput is 1295.2489 records/second. Loss is 2.2815673. Sequentiale465b572's hyper parameters: Current learning rate is 7.178750897343862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50560/60000][Iteration 395][Wall Clock 53.124816807s] Trained 128 records in 0.094712462 seconds. Throughput is 1351.459 records/second. Loss is 2.2826912. Sequentiale465b572's hyper parameters: Current learning rate is 7.173601147776183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 396][Wall Clock 53.224594899s] Trained 128 records in 0.099778092 seconds. Throughput is 1282.8467 records/second. Loss is 2.27851. Sequentiale465b572's hyper parameters: Current learning rate is 7.168458781362007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50816/60000][Iteration 397][Wall Clock 53.326549711s] Trained 128 records in 0.101954812 seconds. Throughput is 1255.4581 records/second. Loss is 2.2818618. Sequentiale465b572's hyper parameters: Current learning rate is 7.163323782234958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:35 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 398][Wall Clock 53.457018689s] Trained 128 records in 0.130468978 seconds. Throughput is 981.0761 records/second. Loss is 2.27857. Sequentiale465b572's hyper parameters: Current learning rate is 7.158196134574087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51072/60000][Iteration 399][Wall Clock 53.566813128s] Trained 128 records in 0.109794439 seconds. Throughput is 1165.815 records/second. Loss is 2.2868185. Sequentiale465b572's hyper parameters: Current learning rate is 7.15307582260372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 400][Wall Clock 53.666754408s] Trained 128 records in 0.09994128 seconds. Throughput is 1280.752 records/second. Loss is 2.2873762. Sequentiale465b572's hyper parameters: Current learning rate is 7.147962830593281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51328/60000][Iteration 401][Wall Clock 53.766656531s] Trained 128 records in 0.099902123 seconds. Throughput is 1281.254 records/second. Loss is 2.2772985. Sequentiale465b572's hyper parameters: Current learning rate is 7.142857142857144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 402][Wall Clock 53.864376544s] Trained 128 records in 0.097720013 seconds. Throughput is 1309.8647 records/second. Loss is 2.2822897. Sequentiale465b572's hyper parameters: Current learning rate is 7.137758743754461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51584/60000][Iteration 403][Wall Clock 53.970061999s] Trained 128 records in 0.105685455 seconds. Throughput is 1211.1411 records/second. Loss is 2.2796628. Sequentiale465b572's hyper parameters: Current learning rate is 7.132667617689015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 404][Wall Clock 54.072299238s] Trained 128 records in 0.102237239 seconds. Throughput is 1251.99 records/second. Loss is 2.2815711. Sequentiale465b572's hyper parameters: Current learning rate is 7.127583749109052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51840/60000][Iteration 405][Wall Clock 54.170387963s] Trained 128 records in 0.098088725 seconds. Throughput is 1304.941 records/second. Loss is 2.272992. Sequentiale465b572's hyper parameters: Current learning rate is 7.122507122507123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 406][Wall Clock 54.269643049s] Trained 128 records in 0.099255086 seconds. Throughput is 1289.6064 records/second. Loss is 2.2749412. Sequentiale465b572's hyper parameters: Current learning rate is 7.117437722419929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 52096/60000][Iteration 407][Wall Clock 54.369432944s] Trained 128 records in 0.099789895 seconds. Throughput is 1282.695 records/second. Loss is 2.286349. Sequentiale465b572's hyper parameters: Current learning rate is 7.112375533428164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:36 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 408][Wall Clock 54.479798123s] Trained 128 records in 0.110365179 seconds. Throughput is 1159.786 records/second. Loss is 2.2785015. Sequentiale465b572's hyper parameters: Current learning rate is 7.107320540156361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 52352/60000][Iteration 409][Wall Clock 54.584798035s] Trained 128 records in 0.104999912 seconds. Throughput is 1219.0486 records/second. Loss is 2.2861195. Sequentiale465b572's hyper parameters: Current learning rate is 7.102272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 410][Wall Clock 54.689008189s] Trained 128 records in 0.104210154 seconds. Throughput is 1228.2872 records/second. Loss is 2.2768903. Sequentiale465b572's hyper parameters: Current learning rate is 7.097232079489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 52608/60000][Iteration 411][Wall Clock 54.788466257s] Trained 128 records in 0.099458068 seconds. Throughput is 1286.9745 records/second. Loss is 2.2831333. Sequentiale465b572's hyper parameters: Current learning rate is 7.092198581560283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 412][Wall Clock 54.921007778s] Trained 128 records in 0.132541521 seconds. Throughput is 965.7351 records/second. Loss is 2.2798102. Sequentiale465b572's hyper parameters: Current learning rate is 7.087172218284905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 52864/60000][Iteration 413][Wall Clock 55.01945193s] Trained 128 records in 0.098444152 seconds. Throughput is 1300.2296 records/second. Loss is 2.2720828. Sequentiale465b572's hyper parameters: Current learning rate is 7.08215297450425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 414][Wall Clock 55.128588887s] Trained 128 records in 0.109136957 seconds. Throughput is 1172.8383 records/second. Loss is 2.2761307. Sequentiale465b572's hyper parameters: Current learning rate is 7.077140835102619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 53120/60000][Iteration 415][Wall Clock 55.262975094s] Trained 128 records in 0.134386207 seconds. Throughput is 952.4787 records/second. Loss is 2.270651. Sequentiale465b572's hyper parameters: Current learning rate is 7.072135785007071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 416][Wall Clock 55.389937001s] Trained 128 records in 0.126961907 seconds. Throughput is 1008.17645 records/second. Loss is 2.2765677. Sequentiale465b572's hyper parameters: Current learning rate is 7.067137809187279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:37 INFO  DistriOptimizer$:408 - [Epoch 1 53376/60000][Iteration 417][Wall Clock 55.52446331s] Trained 128 records in 0.134526309 seconds. Throughput is 951.4867 records/second. Loss is 2.282033. Sequentiale465b572's hyper parameters: Current learning rate is 7.062146892655368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 418][Wall Clock 55.650055351s] Trained 128 records in 0.125592041 seconds. Throughput is 1019.1729 records/second. Loss is 2.2638738. Sequentiale465b572's hyper parameters: Current learning rate is 7.057163020465773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 53632/60000][Iteration 419][Wall Clock 55.750514447s] Trained 128 records in 0.100459096 seconds. Throughput is 1274.1504 records/second. Loss is 2.2826557. Sequentiale465b572's hyper parameters: Current learning rate is 7.052186177715093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 420][Wall Clock 55.852471466s] Trained 128 records in 0.101957019 seconds. Throughput is 1255.431 records/second. Loss is 2.27587. Sequentiale465b572's hyper parameters: Current learning rate is 7.047216349541931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 53888/60000][Iteration 421][Wall Clock 55.955020754s] Trained 128 records in 0.102549288 seconds. Throughput is 1248.1803 records/second. Loss is 2.2794645. Sequentiale465b572's hyper parameters: Current learning rate is 7.042253521126761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 422][Wall Clock 56.053546263s] Trained 128 records in 0.098525509 seconds. Throughput is 1299.1559 records/second. Loss is 2.2687001. Sequentiale465b572's hyper parameters: Current learning rate is 7.037297677691766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 54144/60000][Iteration 423][Wall Clock 56.154834149s] Trained 128 records in 0.101287886 seconds. Throughput is 1263.7246 records/second. Loss is 2.2793028. Sequentiale465b572's hyper parameters: Current learning rate is 7.032348804500703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 424][Wall Clock 56.291952581s] Trained 128 records in 0.137118432 seconds. Throughput is 933.49963 records/second. Loss is 2.274579. Sequentiale465b572's hyper parameters: Current learning rate is 7.027406886858749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 54400/60000][Iteration 425][Wall Clock 56.396473507s] Trained 128 records in 0.104520926 seconds. Throughput is 1224.6351 records/second. Loss is 2.273798. Sequentiale465b572's hyper parameters: Current learning rate is 7.02247191011236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:38 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 426][Wall Clock 56.494647688s] Trained 128 records in 0.098174181 seconds. Throughput is 1303.805 records/second. Loss is 2.278633. Sequentiale465b572's hyper parameters: Current learning rate is 7.017543859649122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 54656/60000][Iteration 427][Wall Clock 56.595746248s] Trained 128 records in 0.10109856 seconds. Throughput is 1266.0912 records/second. Loss is 2.2729344. Sequentiale465b572's hyper parameters: Current learning rate is 7.012622720897617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 428][Wall Clock 56.698771642s] Trained 128 records in 0.103025394 seconds. Throughput is 1242.4121 records/second. Loss is 2.27891. Sequentiale465b572's hyper parameters: Current learning rate is 7.00770847932726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 54912/60000][Iteration 429][Wall Clock 56.800151021s] Trained 128 records in 0.101379379 seconds. Throughput is 1262.5842 records/second. Loss is 2.2844157. Sequentiale465b572's hyper parameters: Current learning rate is 7.002801120448179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 430][Wall Clock 56.900204419s] Trained 128 records in 0.100053398 seconds. Throughput is 1279.3169 records/second. Loss is 2.2738569. Sequentiale465b572's hyper parameters: Current learning rate is 6.997900629811056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55168/60000][Iteration 431][Wall Clock 56.996763687s] Trained 128 records in 0.096559268 seconds. Throughput is 1325.6107 records/second. Loss is 2.2680676. Sequentiale465b572's hyper parameters: Current learning rate is 6.993006993006993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 432][Wall Clock 57.105249948s] Trained 128 records in 0.108486261 seconds. Throughput is 1179.8729 records/second. Loss is 2.276127. Sequentiale465b572's hyper parameters: Current learning rate is 6.988120195667365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55424/60000][Iteration 433][Wall Clock 57.20497366s] Trained 128 records in 0.099723712 seconds. Throughput is 1283.5463 records/second. Loss is 2.2674494. Sequentiale465b572's hyper parameters: Current learning rate is 6.983240223463687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 434][Wall Clock 57.301812901s] Trained 128 records in 0.096839241 seconds. Throughput is 1321.7782 records/second. Loss is 2.2732494. Sequentiale465b572's hyper parameters: Current learning rate is 6.978367062107466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55680/60000][Iteration 435][Wall Clock 57.398381083s] Trained 128 records in 0.096568182 seconds. Throughput is 1325.4884 records/second. Loss is 2.2806094. Sequentiale465b572's hyper parameters: Current learning rate is 6.973500697350071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:39 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 436][Wall Clock 57.496648582s] Trained 128 records in 0.098267499 seconds. Throughput is 1302.567 records/second. Loss is 2.274745. Sequentiale465b572's hyper parameters: Current learning rate is 6.968641114982578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 55936/60000][Iteration 437][Wall Clock 57.589156894s] Trained 128 records in 0.092508312 seconds. Throughput is 1383.6595 records/second. Loss is 2.2761886. Sequentiale465b572's hyper parameters: Current learning rate is 6.963788300835655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 438][Wall Clock 57.700956746s] Trained 128 records in 0.111799852 seconds. Throughput is 1144.9031 records/second. Loss is 2.2763572. Sequentiale465b572's hyper parameters: Current learning rate is 6.958942240779402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56192/60000][Iteration 439][Wall Clock 57.799491626s] Trained 128 records in 0.09853488 seconds. Throughput is 1299.0323 records/second. Loss is 2.282409. Sequentiale465b572's hyper parameters: Current learning rate is 6.954102920723227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 440][Wall Clock 57.920113397s] Trained 128 records in 0.120621771 seconds. Throughput is 1061.1683 records/second. Loss is 2.291079. Sequentiale465b572's hyper parameters: Current learning rate is 6.949270326615705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56448/60000][Iteration 441][Wall Clock 58.020156181s] Trained 128 records in 0.100042784 seconds. Throughput is 1279.4526 records/second. Loss is 2.2787411. Sequentiale465b572's hyper parameters: Current learning rate is 6.944444444444445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 442][Wall Clock 58.1319331s] Trained 128 records in 0.111776919 seconds. Throughput is 1145.1381 records/second. Loss is 2.2699466. Sequentiale465b572's hyper parameters: Current learning rate is 6.939625260235947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56704/60000][Iteration 443][Wall Clock 58.240099327s] Trained 128 records in 0.108166227 seconds. Throughput is 1183.3639 records/second. Loss is 2.2754307. Sequentiale465b572's hyper parameters: Current learning rate is 6.934812760055479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 444][Wall Clock 58.338845057s] Trained 128 records in 0.09874573 seconds. Throughput is 1296.2585 records/second. Loss is 2.27765. Sequentiale465b572's hyper parameters: Current learning rate is 6.93000693000693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:40 INFO  DistriOptimizer$:408 - [Epoch 1 56960/60000][Iteration 445][Wall Clock 58.432514739s] Trained 128 records in 0.093669682 seconds. Throughput is 1366.504 records/second. Loss is 2.2686152. Sequentiale465b572's hyper parameters: Current learning rate is 6.925207756232687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 446][Wall Clock 58.536787799s] Trained 128 records in 0.10427306 seconds. Throughput is 1227.5463 records/second. Loss is 2.266542. Sequentiale465b572's hyper parameters: Current learning rate is 6.920415224913495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57216/60000][Iteration 447][Wall Clock 58.630889176s] Trained 128 records in 0.094101377 seconds. Throughput is 1360.2351 records/second. Loss is 2.2778506. Sequentiale465b572's hyper parameters: Current learning rate is 6.915629322268327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 448][Wall Clock 58.741132916s] Trained 128 records in 0.11024374 seconds. Throughput is 1161.0637 records/second. Loss is 2.2633584. Sequentiale465b572's hyper parameters: Current learning rate is 6.91085003455425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57472/60000][Iteration 449][Wall Clock 58.841682065s] Trained 128 records in 0.100549149 seconds. Throughput is 1273.0093 records/second. Loss is 2.2784636. Sequentiale465b572's hyper parameters: Current learning rate is 6.906077348066299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 450][Wall Clock 59.010665591s] Trained 128 records in 0.168983526 seconds. Throughput is 757.47034 records/second. Loss is 2.260537. Sequentiale465b572's hyper parameters: Current learning rate is 6.901311249137336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57728/60000][Iteration 451][Wall Clock 59.125327875s] Trained 128 records in 0.114662284 seconds. Throughput is 1116.3218 records/second. Loss is 2.2815876. Sequentiale465b572's hyper parameters: Current learning rate is 6.896551724137932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 452][Wall Clock 59.224301666s] Trained 128 records in 0.098973791 seconds. Throughput is 1293.2717 records/second. Loss is 2.2868829. Sequentiale465b572's hyper parameters: Current learning rate is 6.891798759476223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 57984/60000][Iteration 453][Wall Clock 59.32506545s] Trained 128 records in 0.100763784 seconds. Throughput is 1270.2977 records/second. Loss is 2.2662954. Sequentiale465b572's hyper parameters: Current learning rate is 6.887052341597796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:41 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 454][Wall Clock 59.42888177s] Trained 128 records in 0.10381632 seconds. Throughput is 1232.9468 records/second. Loss is 2.282102. Sequentiale465b572's hyper parameters: Current learning rate is 6.882312456985547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 58240/60000][Iteration 455][Wall Clock 59.530055438s] Trained 128 records in 0.101173668 seconds. Throughput is 1265.1514 records/second. Loss is 2.276793. Sequentiale465b572's hyper parameters: Current learning rate is 6.87757909215956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 456][Wall Clock 59.636518074s] Trained 128 records in 0.106462636 seconds. Throughput is 1202.2998 records/second. Loss is 2.2898445. Sequentiale465b572's hyper parameters: Current learning rate is 6.872852233676975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 58496/60000][Iteration 457][Wall Clock 59.735944982s] Trained 128 records in 0.099426908 seconds. Throughput is 1287.3778 records/second. Loss is 2.2775488. Sequentiale465b572's hyper parameters: Current learning rate is 6.868131868131869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 458][Wall Clock 59.837484079s] Trained 128 records in 0.101539097 seconds. Throughput is 1260.5981 records/second. Loss is 2.2735522. Sequentiale465b572's hyper parameters: Current learning rate is 6.863417982155113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 58752/60000][Iteration 459][Wall Clock 59.934401598s] Trained 128 records in 0.096917519 seconds. Throughput is 1320.7107 records/second. Loss is 2.276036. Sequentiale465b572's hyper parameters: Current learning rate is 6.858710562414267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 460][Wall Clock 60.031486309s] Trained 128 records in 0.097084711 seconds. Throughput is 1318.4363 records/second. Loss is 2.2602258. Sequentiale465b572's hyper parameters: Current learning rate is 6.854009595613433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 59008/60000][Iteration 461][Wall Clock 60.126243321s] Trained 128 records in 0.094757012 seconds. Throughput is 1350.8235 records/second. Loss is 2.263602. Sequentiale465b572's hyper parameters: Current learning rate is 6.849315068493151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 462][Wall Clock 60.222478004s] Trained 128 records in 0.096234683 seconds. Throughput is 1330.0818 records/second. Loss is 2.268399. Sequentiale465b572's hyper parameters: Current learning rate is 6.844626967830253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 59264/60000][Iteration 463][Wall Clock 60.317714293s] Trained 128 records in 0.095236289 seconds. Throughput is 1344.0255 records/second. Loss is 2.2871275. Sequentiale465b572's hyper parameters: Current learning rate is 6.839945280437756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:42 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 464][Wall Clock 60.411660871s] Trained 128 records in 0.093946578 seconds. Throughput is 1362.4764 records/second. Loss is 2.2810633. Sequentiale465b572's hyper parameters: Current learning rate is 6.835269993164729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:43 INFO  DistriOptimizer$:408 - [Epoch 1 59520/60000][Iteration 465][Wall Clock 60.545772551s] Trained 128 records in 0.13411168 seconds. Throughput is 954.42847 records/second. Loss is 2.2817664. Sequentiale465b572's hyper parameters: Current learning rate is 6.830601092896175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:43 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 466][Wall Clock 60.652296717s] Trained 128 records in 0.106524166 seconds. Throughput is 1201.6052 records/second. Loss is 2.2650347. Sequentiale465b572's hyper parameters: Current learning rate is 6.825938566552901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:43 INFO  DistriOptimizer$:408 - [Epoch 1 59776/60000][Iteration 467][Wall Clock 60.750570063s] Trained 128 records in 0.098273346 seconds. Throughput is 1302.4895 records/second. Loss is 2.277702. Sequentiale465b572's hyper parameters: Current learning rate is 6.821282401091405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:43 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 468][Wall Clock 60.855282619s] Trained 128 records in 0.104712556 seconds. Throughput is 1222.394 records/second. Loss is 2.2830846. Sequentiale465b572's hyper parameters: Current learning rate is 6.816632583503749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:43 INFO  DistriOptimizer$:408 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 60.980295621s] Trained 128 records in 0.125013002 seconds. Throughput is 1023.89343 records/second. Loss is 2.2646482. Sequentiale465b572's hyper parameters: Current learning rate is 6.811989100817438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:43 INFO  DistriOptimizer$:452 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 60.980295621s] Epoch finished. Wall clock time is 61355.82734 ms
2019-10-15 20:05:43 INFO  DistriOptimizer$:111 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 60.980295621s] Validate model...
2019-10-15 20:05:44 INFO  DistriOptimizer$:178 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 60.980295621s] validate model throughput is 8593.945 records/second
2019-10-15 20:05:44 INFO  DistriOptimizer$:181 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 60.980295621s] Top1Accuracy is Accuracy(correct: 1302, count: 10000, accuracy: 0.1302)
2019-10-15 20:05:44 INFO  DistriOptimizer$:221 - [Wall Clock 61.35582734s] Save model to /tmp/lenet5/20191015_200441
2019-10-15 20:05:44 INFO  DistriOptimizer$:226 - [Wall Clock 61.35582734s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@c83982c to /tmp/lenet5/20191015_200441
2019-10-15 20:05:44 INFO  DistriOptimizer$:408 - [Epoch 2 128/60000][Iteration 470][Wall Clock 61.520992s] Trained 128 records in 0.16516466 seconds. Throughput is 774.9842 records/second. Loss is 2.2816603. Sequentiale465b572's hyper parameters: Current learning rate is 6.807351940095302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 471][Wall Clock 61.624253063s] Trained 128 records in 0.103261063 seconds. Throughput is 1239.5767 records/second. Loss is 2.2679548. Sequentiale465b572's hyper parameters: Current learning rate is 6.802721088435375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 384/60000][Iteration 472][Wall Clock 61.732599286s] Trained 128 records in 0.108346223 seconds. Throughput is 1181.3978 records/second. Loss is 2.273329. Sequentiale465b572's hyper parameters: Current learning rate is 6.798096532970768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 473][Wall Clock 61.872001136s] Trained 128 records in 0.13940185 seconds. Throughput is 918.20874 records/second. Loss is 2.2795596. Sequentiale465b572's hyper parameters: Current learning rate is 6.793478260869565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 640/60000][Iteration 474][Wall Clock 61.996182372s] Trained 128 records in 0.124181236 seconds. Throughput is 1030.7516 records/second. Loss is 2.2745616. Sequentiale465b572's hyper parameters: Current learning rate is 6.788866259334691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 475][Wall Clock 62.098959457s] Trained 128 records in 0.102777085 seconds. Throughput is 1245.4138 records/second. Loss is 2.2626414. Sequentiale465b572's hyper parameters: Current learning rate is 6.7842605156038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 896/60000][Iteration 476][Wall Clock 62.205608568s] Trained 128 records in 0.106649111 seconds. Throughput is 1200.1975 records/second. Loss is 2.2790234. Sequentiale465b572's hyper parameters: Current learning rate is 6.779661016949152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 477][Wall Clock 62.313380711s] Trained 128 records in 0.107772143 seconds. Throughput is 1187.6909 records/second. Loss is 2.2728217. Sequentiale465b572's hyper parameters: Current learning rate is 6.775067750677507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 1152/60000][Iteration 478][Wall Clock 62.415269491s] Trained 128 records in 0.10188878 seconds. Throughput is 1256.2717 records/second. Loss is 2.272619. Sequentiale465b572's hyper parameters: Current learning rate is 6.770480704129993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:45 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 479][Wall Clock 62.516568503s] Trained 128 records in 0.101299012 seconds. Throughput is 1263.5859 records/second. Loss is 2.2745152. Sequentiale465b572's hyper parameters: Current learning rate is 6.765899864682003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 1408/60000][Iteration 480][Wall Clock 62.635958248s] Trained 128 records in 0.119389745 seconds. Throughput is 1072.1189 records/second. Loss is 2.2494707. Sequentiale465b572's hyper parameters: Current learning rate is 6.76132521974307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 481][Wall Clock 62.736300433s] Trained 128 records in 0.100342185 seconds. Throughput is 1275.635 records/second. Loss is 2.2673697. Sequentiale465b572's hyper parameters: Current learning rate is 6.756756756756757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 1664/60000][Iteration 482][Wall Clock 62.835366456s] Trained 128 records in 0.099066023 seconds. Throughput is 1292.0676 records/second. Loss is 2.2643325. Sequentiale465b572's hyper parameters: Current learning rate is 6.752194463200541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 483][Wall Clock 62.935559369s] Trained 128 records in 0.100192913 seconds. Throughput is 1277.5355 records/second. Loss is 2.2663932. Sequentiale465b572's hyper parameters: Current learning rate is 6.747638326585695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 1920/60000][Iteration 484][Wall Clock 63.035870638s] Trained 128 records in 0.100311269 seconds. Throughput is 1276.0281 records/second. Loss is 2.2814312. Sequentiale465b572's hyper parameters: Current learning rate is 6.743088334457181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 485][Wall Clock 63.135689648s] Trained 128 records in 0.09981901 seconds. Throughput is 1282.3208 records/second. Loss is 2.2711413. Sequentiale465b572's hyper parameters: Current learning rate is 6.738544474393531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 2176/60000][Iteration 486][Wall Clock 63.247267078s] Trained 128 records in 0.11157743 seconds. Throughput is 1147.1854 records/second. Loss is 2.2760282. Sequentiale465b572's hyper parameters: Current learning rate is 6.734006734006734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 487][Wall Clock 63.344456065s] Trained 128 records in 0.097188987 seconds. Throughput is 1317.0216 records/second. Loss is 2.2700949. Sequentiale465b572's hyper parameters: Current learning rate is 6.729475100942127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:46 INFO  DistriOptimizer$:408 - [Epoch 2 2432/60000][Iteration 488][Wall Clock 63.457799747s] Trained 128 records in 0.113343682 seconds. Throughput is 1129.3087 records/second. Loss is 2.2654204. Sequentiale465b572's hyper parameters: Current learning rate is 6.724949562878278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 489][Wall Clock 63.555956126s] Trained 128 records in 0.098156379 seconds. Throughput is 1304.0416 records/second. Loss is 2.2748797. Sequentiale465b572's hyper parameters: Current learning rate is 6.720430107526882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 2688/60000][Iteration 490][Wall Clock 63.663631896s] Trained 128 records in 0.10767577 seconds. Throughput is 1188.754 records/second. Loss is 2.261298. Sequentiale465b572's hyper parameters: Current learning rate is 6.71591672263264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 491][Wall Clock 63.768203754s] Trained 128 records in 0.104571858 seconds. Throughput is 1224.0387 records/second. Loss is 2.265618. Sequentiale465b572's hyper parameters: Current learning rate is 6.711409395973154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 2944/60000][Iteration 492][Wall Clock 63.866412227s] Trained 128 records in 0.098208473 seconds. Throughput is 1303.3499 records/second. Loss is 2.2626116. Sequentiale465b572's hyper parameters: Current learning rate is 6.706908115358819E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 493][Wall Clock 63.972882365s] Trained 128 records in 0.106470138 seconds. Throughput is 1202.2151 records/second. Loss is 2.2743626. Sequentiale465b572's hyper parameters: Current learning rate is 6.702412868632708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 3200/60000][Iteration 494][Wall Clock 64.074003785s] Trained 128 records in 0.10112142 seconds. Throughput is 1265.805 records/second. Loss is 2.2716146. Sequentiale465b572's hyper parameters: Current learning rate is 6.697923643670463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 495][Wall Clock 64.1721466s] Trained 128 records in 0.098142815 seconds. Throughput is 1304.2218 records/second. Loss is 2.2704859. Sequentiale465b572's hyper parameters: Current learning rate is 6.693440428380187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 3456/60000][Iteration 496][Wall Clock 64.304918645s] Trained 128 records in 0.132772045 seconds. Throughput is 964.05835 records/second. Loss is 2.2731788. Sequentiale465b572's hyper parameters: Current learning rate is 6.688963210702341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:47 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 497][Wall Clock 64.450782254s] Trained 128 records in 0.145863609 seconds. Throughput is 877.5321 records/second. Loss is 2.270297. Sequentiale465b572's hyper parameters: Current learning rate is 6.684491978609626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 3712/60000][Iteration 498][Wall Clock 64.549897119s] Trained 128 records in 0.099114865 seconds. Throughput is 1291.4309 records/second. Loss is 2.2622712. Sequentiale465b572's hyper parameters: Current learning rate is 6.680026720106881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 499][Wall Clock 64.654635567s] Trained 128 records in 0.104738448 seconds. Throughput is 1222.0918 records/second. Loss is 2.2602723. Sequentiale465b572's hyper parameters: Current learning rate is 6.675567423230974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 3968/60000][Iteration 500][Wall Clock 64.761255473s] Trained 128 records in 0.106619906 seconds. Throughput is 1200.5262 records/second. Loss is 2.2779324. Sequentiale465b572's hyper parameters: Current learning rate is 6.6711140760507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 501][Wall Clock 64.873384978s] Trained 128 records in 0.112129505 seconds. Throughput is 1141.5372 records/second. Loss is 2.2782967. Sequentiale465b572's hyper parameters: Current learning rate is 6.666666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4224/60000][Iteration 502][Wall Clock 64.975591649s] Trained 128 records in 0.102206671 seconds. Throughput is 1252.3645 records/second. Loss is 2.2676067. Sequentiale465b572's hyper parameters: Current learning rate is 6.662225183211193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 503][Wall Clock 65.086266885s] Trained 128 records in 0.110675236 seconds. Throughput is 1156.537 records/second. Loss is 2.2709186. Sequentiale465b572's hyper parameters: Current learning rate is 6.657789613848203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4480/60000][Iteration 504][Wall Clock 65.190526167s] Trained 128 records in 0.104259282 seconds. Throughput is 1227.7084 records/second. Loss is 2.2744308. Sequentiale465b572's hyper parameters: Current learning rate is 6.653359946773121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 505][Wall Clock 65.29551754s] Trained 128 records in 0.104991373 seconds. Throughput is 1219.1477 records/second. Loss is 2.2729278. Sequentiale465b572's hyper parameters: Current learning rate is 6.648936170212766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4736/60000][Iteration 506][Wall Clock 65.397909283s] Trained 128 records in 0.102391743 seconds. Throughput is 1250.1008 records/second. Loss is 2.2644274. Sequentiale465b572's hyper parameters: Current learning rate is 6.64451827242525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:48 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 507][Wall Clock 65.50102552s] Trained 128 records in 0.103116237 seconds. Throughput is 1241.3176 records/second. Loss is 2.2657118. Sequentiale465b572's hyper parameters: Current learning rate is 6.640106241699868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 4992/60000][Iteration 508][Wall Clock 65.597445366s] Trained 128 records in 0.096419846 seconds. Throughput is 1327.5275 records/second. Loss is 2.2872813. Sequentiale465b572's hyper parameters: Current learning rate is 6.635700066357001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 509][Wall Clock 65.697651152s] Trained 128 records in 0.100205786 seconds. Throughput is 1277.3713 records/second. Loss is 2.2779412. Sequentiale465b572's hyper parameters: Current learning rate is 6.63129973474801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5248/60000][Iteration 510][Wall Clock 65.796741658s] Trained 128 records in 0.099090506 seconds. Throughput is 1291.7483 records/second. Loss is 2.2700107. Sequentiale465b572's hyper parameters: Current learning rate is 6.626905235255137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 511][Wall Clock 65.908686531s] Trained 128 records in 0.111944873 seconds. Throughput is 1143.4199 records/second. Loss is 2.2636452. Sequentiale465b572's hyper parameters: Current learning rate is 6.622516556291391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5504/60000][Iteration 512][Wall Clock 66.015138846s] Trained 128 records in 0.106452315 seconds. Throughput is 1202.4163 records/second. Loss is 2.2801738. Sequentiale465b572's hyper parameters: Current learning rate is 6.618133686300463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 513][Wall Clock 66.118122599s] Trained 128 records in 0.102983753 seconds. Throughput is 1242.9146 records/second. Loss is 2.2604012. Sequentiale465b572's hyper parameters: Current learning rate is 6.613756613756613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5760/60000][Iteration 514][Wall Clock 66.220912915s] Trained 128 records in 0.102790316 seconds. Throughput is 1245.2534 records/second. Loss is 2.2760396. Sequentiale465b572's hyper parameters: Current learning rate is 6.609385327164574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 515][Wall Clock 66.32223795s] Trained 128 records in 0.101325035 seconds. Throughput is 1263.2614 records/second. Loss is 2.266895. Sequentiale465b572's hyper parameters: Current learning rate is 6.605019815059445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 6016/60000][Iteration 516][Wall Clock 66.421545072s] Trained 128 records in 0.099307122 seconds. Throughput is 1288.9308 records/second. Loss is 2.2613065. Sequentiale465b572's hyper parameters: Current learning rate is 6.600660066006601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:49 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 517][Wall Clock 66.522464893s] Trained 128 records in 0.100919821 seconds. Throughput is 1268.3336 records/second. Loss is 2.2560105. Sequentiale465b572's hyper parameters: Current learning rate is 6.596306068601583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 6272/60000][Iteration 518][Wall Clock 66.615307454s] Trained 128 records in 0.092842561 seconds. Throughput is 1378.678 records/second. Loss is 2.2648852. Sequentiale465b572's hyper parameters: Current learning rate is 6.591957811470007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 519][Wall Clock 66.709031817s] Trained 128 records in 0.093724363 seconds. Throughput is 1365.7068 records/second. Loss is 2.2579396. Sequentiale465b572's hyper parameters: Current learning rate is 6.587615283267457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 6528/60000][Iteration 520][Wall Clock 66.803248237s] Trained 128 records in 0.09421642 seconds. Throughput is 1358.5742 records/second. Loss is 2.2724817. Sequentiale465b572's hyper parameters: Current learning rate is 6.583278472679394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 521][Wall Clock 66.901552883s] Trained 128 records in 0.098304646 seconds. Throughput is 1302.0748 records/second. Loss is 2.2795105. Sequentiale465b572's hyper parameters: Current learning rate is 6.578947368421052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 6784/60000][Iteration 522][Wall Clock 67.039948454s] Trained 128 records in 0.138395571 seconds. Throughput is 924.8851 records/second. Loss is 2.259957. Sequentiale465b572's hyper parameters: Current learning rate is 6.574621959237344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 523][Wall Clock 67.165356157s] Trained 128 records in 0.125407703 seconds. Throughput is 1020.671 records/second. Loss is 2.2783859. Sequentiale465b572's hyper parameters: Current learning rate is 6.57030223390276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 7040/60000][Iteration 524][Wall Clock 67.275691047s] Trained 128 records in 0.11033489 seconds. Throughput is 1160.1045 records/second. Loss is 2.2690196. Sequentiale465b572's hyper parameters: Current learning rate is 6.565988181221273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 525][Wall Clock 67.377078496s] Trained 128 records in 0.101387449 seconds. Throughput is 1262.4836 records/second. Loss is 2.275706. Sequentiale465b572's hyper parameters: Current learning rate is 6.561679790026247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:50 INFO  DistriOptimizer$:408 - [Epoch 2 7296/60000][Iteration 526][Wall Clock 67.478863698s] Trained 128 records in 0.101785202 seconds. Throughput is 1257.5502 records/second. Loss is 2.2643569. Sequentiale465b572's hyper parameters: Current learning rate is 6.557377049180328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 527][Wall Clock 67.580976468s] Trained 128 records in 0.10211277 seconds. Throughput is 1253.5161 records/second. Loss is 2.2633295. Sequentiale465b572's hyper parameters: Current learning rate is 6.55307994757536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 7552/60000][Iteration 528][Wall Clock 67.710709748s] Trained 128 records in 0.12973328 seconds. Throughput is 986.63965 records/second. Loss is 2.2619524. Sequentiale465b572's hyper parameters: Current learning rate is 6.548788474132285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 529][Wall Clock 67.844441527s] Trained 128 records in 0.133731779 seconds. Throughput is 957.1397 records/second. Loss is 2.2724814. Sequentiale465b572's hyper parameters: Current learning rate is 6.544502617801048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 7808/60000][Iteration 530][Wall Clock 67.980932308s] Trained 128 records in 0.136490781 seconds. Throughput is 937.7923 records/second. Loss is 2.2650945. Sequentiale465b572's hyper parameters: Current learning rate is 6.540222367560497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 531][Wall Clock 68.101896424s] Trained 128 records in 0.120964116 seconds. Throughput is 1058.165 records/second. Loss is 2.2760377. Sequentiale465b572's hyper parameters: Current learning rate is 6.5359477124183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 8064/60000][Iteration 532][Wall Clock 68.22943316s] Trained 128 records in 0.127536736 seconds. Throughput is 1003.63245 records/second. Loss is 2.2520142. Sequentiale465b572's hyper parameters: Current learning rate is 6.531678641410842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 533][Wall Clock 68.346787308s] Trained 128 records in 0.117354148 seconds. Throughput is 1090.7156 records/second. Loss is 2.262249. Sequentiale465b572's hyper parameters: Current learning rate is 6.527415143603133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:51 INFO  DistriOptimizer$:408 - [Epoch 2 8320/60000][Iteration 534][Wall Clock 68.478387042s] Trained 128 records in 0.131599734 seconds. Throughput is 972.6463 records/second. Loss is 2.2739463. Sequentiale465b572's hyper parameters: Current learning rate is 6.523157208088716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 535][Wall Clock 68.579172567s] Trained 128 records in 0.100785525 seconds. Throughput is 1270.0237 records/second. Loss is 2.265054. Sequentiale465b572's hyper parameters: Current learning rate is 6.51890482398957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 8576/60000][Iteration 536][Wall Clock 68.684448732s] Trained 128 records in 0.105276165 seconds. Throughput is 1215.8497 records/second. Loss is 2.2610438. Sequentiale465b572's hyper parameters: Current learning rate is 6.514657980456025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 537][Wall Clock 68.807488313s] Trained 128 records in 0.123039581 seconds. Throughput is 1040.3157 records/second. Loss is 2.2616482. Sequentiale465b572's hyper parameters: Current learning rate is 6.510416666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 8832/60000][Iteration 538][Wall Clock 68.932214512s] Trained 128 records in 0.124726199 seconds. Throughput is 1026.2479 records/second. Loss is 2.2630239. Sequentiale465b572's hyper parameters: Current learning rate is 6.506180871828237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 539][Wall Clock 69.037577149s] Trained 128 records in 0.105362637 seconds. Throughput is 1214.8519 records/second. Loss is 2.2711635. Sequentiale465b572's hyper parameters: Current learning rate is 6.501950585175553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 9088/60000][Iteration 540][Wall Clock 69.152780636s] Trained 128 records in 0.115203487 seconds. Throughput is 1111.0775 records/second. Loss is 2.2715683. Sequentiale465b572's hyper parameters: Current learning rate is 6.49772579597141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 541][Wall Clock 69.261819533s] Trained 128 records in 0.109038897 seconds. Throughput is 1173.8931 records/second. Loss is 2.2807274. Sequentiale465b572's hyper parameters: Current learning rate is 6.493506493506494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 9344/60000][Iteration 542][Wall Clock 69.36312896s] Trained 128 records in 0.101309427 seconds. Throughput is 1263.4559 records/second. Loss is 2.2651982. Sequentiale465b572's hyper parameters: Current learning rate is 6.489292667099287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:52 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 543][Wall Clock 69.475577332s] Trained 128 records in 0.112448372 seconds. Throughput is 1138.3002 records/second. Loss is 2.2631946. Sequentiale465b572's hyper parameters: Current learning rate is 6.485084306095979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 9600/60000][Iteration 544][Wall Clock 69.587573388s] Trained 128 records in 0.111996056 seconds. Throughput is 1142.8975 records/second. Loss is 2.256552. Sequentiale465b572's hyper parameters: Current learning rate is 6.480881399870381E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 545][Wall Clock 69.688863611s] Trained 128 records in 0.101290223 seconds. Throughput is 1263.6954 records/second. Loss is 2.2557576. Sequentiale465b572's hyper parameters: Current learning rate is 6.476683937823834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 9856/60000][Iteration 546][Wall Clock 69.781011076s] Trained 128 records in 0.092147465 seconds. Throughput is 1389.0779 records/second. Loss is 2.2553458. Sequentiale465b572's hyper parameters: Current learning rate is 6.472491909385113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 547][Wall Clock 69.879343727s] Trained 128 records in 0.098332651 seconds. Throughput is 1301.704 records/second. Loss is 2.2632504. Sequentiale465b572's hyper parameters: Current learning rate is 6.468305304010349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 10112/60000][Iteration 548][Wall Clock 69.987395252s] Trained 128 records in 0.108051525 seconds. Throughput is 1184.62 records/second. Loss is 2.2631533. Sequentiale465b572's hyper parameters: Current learning rate is 6.464124111182935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 549][Wall Clock 70.087980578s] Trained 128 records in 0.100585326 seconds. Throughput is 1272.5514 records/second. Loss is 2.2802896. Sequentiale465b572's hyper parameters: Current learning rate is 6.459948320413437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 10368/60000][Iteration 550][Wall Clock 70.18448719s] Trained 128 records in 0.096506612 seconds. Throughput is 1326.334 records/second. Loss is 2.2635918. Sequentiale465b572's hyper parameters: Current learning rate is 6.45577792123951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 551][Wall Clock 70.281542776s] Trained 128 records in 0.097055586 seconds. Throughput is 1318.8319 records/second. Loss is 2.2562432. Sequentiale465b572's hyper parameters: Current learning rate is 6.451612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 10624/60000][Iteration 552][Wall Clock 70.376916352s] Trained 128 records in 0.095373576 seconds. Throughput is 1342.0908 records/second. Loss is 2.262263. Sequentiale465b572's hyper parameters: Current learning rate is 6.447453255963893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:53 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 553][Wall Clock 70.472530151s] Trained 128 records in 0.095613799 seconds. Throughput is 1338.7189 records/second. Loss is 2.2730808. Sequentiale465b572's hyper parameters: Current learning rate is 6.443298969072165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 10880/60000][Iteration 554][Wall Clock 70.568228026s] Trained 128 records in 0.095697875 seconds. Throughput is 1337.5428 records/second. Loss is 2.271199. Sequentiale465b572's hyper parameters: Current learning rate is 6.439150032195751E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 555][Wall Clock 70.661362715s] Trained 128 records in 0.093134689 seconds. Throughput is 1374.3536 records/second. Loss is 2.2663908. Sequentiale465b572's hyper parameters: Current learning rate is 6.435006435006435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11136/60000][Iteration 556][Wall Clock 70.757543219s] Trained 128 records in 0.096180504 seconds. Throughput is 1330.831 records/second. Loss is 2.2719564. Sequentiale465b572's hyper parameters: Current learning rate is 6.430868167202571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 557][Wall Clock 70.849927195s] Trained 128 records in 0.092383976 seconds. Throughput is 1385.5217 records/second. Loss is 2.2620397. Sequentiale465b572's hyper parameters: Current learning rate is 6.426735218508997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11392/60000][Iteration 558][Wall Clock 70.950386284s] Trained 128 records in 0.100459089 seconds. Throughput is 1274.1505 records/second. Loss is 2.271934. Sequentiale465b572's hyper parameters: Current learning rate is 6.422607578676943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 559][Wall Clock 71.048948243s] Trained 128 records in 0.098561959 seconds. Throughput is 1298.6755 records/second. Loss is 2.27071. Sequentiale465b572's hyper parameters: Current learning rate is 6.418485237483953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11648/60000][Iteration 560][Wall Clock 71.155123864s] Trained 128 records in 0.106175621 seconds. Throughput is 1205.5498 records/second. Loss is 2.2717652. Sequentiale465b572's hyper parameters: Current learning rate is 6.414368184733803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 561][Wall Clock 71.255904559s] Trained 128 records in 0.100780695 seconds. Throughput is 1270.0845 records/second. Loss is 2.264052. Sequentiale465b572's hyper parameters: Current learning rate is 6.41025641025641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 11904/60000][Iteration 562][Wall Clock 71.360282588s] Trained 128 records in 0.104378029 seconds. Throughput is 1226.3118 records/second. Loss is 2.2637515. Sequentiale465b572's hyper parameters: Current learning rate is 6.406149903907752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:54 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 563][Wall Clock 71.472943165s] Trained 128 records in 0.112660577 seconds. Throughput is 1136.156 records/second. Loss is 2.2533967. Sequentiale465b572's hyper parameters: Current learning rate is 6.402048655569782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12160/60000][Iteration 564][Wall Clock 71.577516997s] Trained 128 records in 0.104573832 seconds. Throughput is 1224.0156 records/second. Loss is 2.2697628. Sequentiale465b572's hyper parameters: Current learning rate is 6.397952655150352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 565][Wall Clock 71.685381615s] Trained 128 records in 0.107864618 seconds. Throughput is 1186.6727 records/second. Loss is 2.2777226. Sequentiale465b572's hyper parameters: Current learning rate is 6.39386189258312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12416/60000][Iteration 566][Wall Clock 71.794445289s] Trained 128 records in 0.109063674 seconds. Throughput is 1173.6263 records/second. Loss is 2.2699847. Sequentiale465b572's hyper parameters: Current learning rate is 6.389776357827476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 567][Wall Clock 71.895865936s] Trained 128 records in 0.101420647 seconds. Throughput is 1262.0704 records/second. Loss is 2.265679. Sequentiale465b572's hyper parameters: Current learning rate is 6.385696040868455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12672/60000][Iteration 568][Wall Clock 71.99252839s] Trained 128 records in 0.096662454 seconds. Throughput is 1324.1957 records/second. Loss is 2.265781. Sequentiale465b572's hyper parameters: Current learning rate is 6.381620931716655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 569][Wall Clock 72.086502196s] Trained 128 records in 0.093973806 seconds. Throughput is 1362.0817 records/second. Loss is 2.2709568. Sequentiale465b572's hyper parameters: Current learning rate is 6.377551020408163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 12928/60000][Iteration 570][Wall Clock 72.189029608s] Trained 128 records in 0.102527412 seconds. Throughput is 1248.4467 records/second. Loss is 2.2706306. Sequentiale465b572's hyper parameters: Current learning rate is 6.373486297004462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 571][Wall Clock 72.284930682s] Trained 128 records in 0.095901074 seconds. Throughput is 1334.7087 records/second. Loss is 2.2699497. Sequentiale465b572's hyper parameters: Current learning rate is 6.369426751592356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:55 INFO  DistriOptimizer$:408 - [Epoch 2 13184/60000][Iteration 572][Wall Clock 72.380860031s] Trained 128 records in 0.095929349 seconds. Throughput is 1334.3153 records/second. Loss is 2.259633. Sequentiale465b572's hyper parameters: Current learning rate is 6.365372374283895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 573][Wall Clock 72.508008073s] Trained 128 records in 0.127148042 seconds. Throughput is 1006.7005 records/second. Loss is 2.26165. Sequentiale465b572's hyper parameters: Current learning rate is 6.361323155216284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 13440/60000][Iteration 574][Wall Clock 72.605650027s] Trained 128 records in 0.097641954 seconds. Throughput is 1310.912 records/second. Loss is 2.2530963. Sequentiale465b572's hyper parameters: Current learning rate is 6.357279084551812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 575][Wall Clock 72.702654269s] Trained 128 records in 0.097004242 seconds. Throughput is 1319.5299 records/second. Loss is 2.263718. Sequentiale465b572's hyper parameters: Current learning rate is 6.353240152477764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 13696/60000][Iteration 576][Wall Clock 72.800040408s] Trained 128 records in 0.097386139 seconds. Throughput is 1314.3555 records/second. Loss is 2.270728. Sequentiale465b572's hyper parameters: Current learning rate is 6.349206349206348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 577][Wall Clock 72.900058392s] Trained 128 records in 0.100017984 seconds. Throughput is 1279.7698 records/second. Loss is 2.2719064. Sequentiale465b572's hyper parameters: Current learning rate is 6.345177664974619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 13952/60000][Iteration 578][Wall Clock 73.004171739s] Trained 128 records in 0.104113347 seconds. Throughput is 1229.4293 records/second. Loss is 2.265942. Sequentiale465b572's hyper parameters: Current learning rate is 6.341154090044388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 579][Wall Clock 73.100940132s] Trained 128 records in 0.096768393 seconds. Throughput is 1322.746 records/second. Loss is 2.2729623. Sequentiale465b572's hyper parameters: Current learning rate is 6.337135614702155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 14208/60000][Iteration 580][Wall Clock 73.195177798s] Trained 128 records in 0.094237666 seconds. Throughput is 1358.268 records/second. Loss is 2.2698634. Sequentiale465b572's hyper parameters: Current learning rate is 6.333122229259025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 581][Wall Clock 73.292130645s] Trained 128 records in 0.096952847 seconds. Throughput is 1320.2294 records/second. Loss is 2.2740703. Sequentiale465b572's hyper parameters: Current learning rate is 6.329113924050633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 14464/60000][Iteration 582][Wall Clock 73.388533795s] Trained 128 records in 0.09640315 seconds. Throughput is 1327.7574 records/second. Loss is 2.2682045. Sequentiale465b572's hyper parameters: Current learning rate is 6.325110689437065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:56 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 583][Wall Clock 73.483814191s] Trained 128 records in 0.095280396 seconds. Throughput is 1343.4033 records/second. Loss is 2.2726054. Sequentiale465b572's hyper parameters: Current learning rate is 6.321112515802782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 14720/60000][Iteration 584][Wall Clock 73.578180601s] Trained 128 records in 0.09436641 seconds. Throughput is 1356.4149 records/second. Loss is 2.25657. Sequentiale465b572's hyper parameters: Current learning rate is 6.317119393556539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 585][Wall Clock 73.6779266s] Trained 128 records in 0.099745999 seconds. Throughput is 1283.2595 records/second. Loss is 2.2500215. Sequentiale465b572's hyper parameters: Current learning rate is 6.313131313131313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 14976/60000][Iteration 586][Wall Clock 73.77366108s] Trained 128 records in 0.09573448 seconds. Throughput is 1337.0314 records/second. Loss is 2.2603652. Sequentiale465b572's hyper parameters: Current learning rate is 6.309148264984228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 587][Wall Clock 73.865909628s] Trained 128 records in 0.092248548 seconds. Throughput is 1387.5557 records/second. Loss is 2.2579615. Sequentiale465b572's hyper parameters: Current learning rate is 6.30517023959647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 15232/60000][Iteration 588][Wall Clock 73.982866569s] Trained 128 records in 0.116956941 seconds. Throughput is 1094.4199 records/second. Loss is 2.2583125. Sequentiale465b572's hyper parameters: Current learning rate is 6.30119722747322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 589][Wall Clock 74.08950685s] Trained 128 records in 0.106640281 seconds. Throughput is 1200.2969 records/second. Loss is 2.264996. Sequentiale465b572's hyper parameters: Current learning rate is 6.297229219143577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 15488/60000][Iteration 590][Wall Clock 74.191787517s] Trained 128 records in 0.102280667 seconds. Throughput is 1251.4584 records/second. Loss is 2.2595794. Sequentiale465b572's hyper parameters: Current learning rate is 6.293266205160479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 591][Wall Clock 74.326838042s] Trained 128 records in 0.135050525 seconds. Throughput is 947.79346 records/second. Loss is 2.2702317. Sequentiale465b572's hyper parameters: Current learning rate is 6.28930817610063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:57 INFO  DistriOptimizer$:408 - [Epoch 2 15744/60000][Iteration 592][Wall Clock 74.42506815s] Trained 128 records in 0.098230108 seconds. Throughput is 1303.0627 records/second. Loss is 2.2654958. Sequentiale465b572's hyper parameters: Current learning rate is 6.285355122564425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 593][Wall Clock 74.518576986s] Trained 128 records in 0.093508836 seconds. Throughput is 1368.8545 records/second. Loss is 2.2589376. Sequentiale465b572's hyper parameters: Current learning rate is 6.28140703517588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16000/60000][Iteration 594][Wall Clock 74.617371124s] Trained 128 records in 0.098794138 seconds. Throughput is 1295.6234 records/second. Loss is 2.2614527. Sequentiale465b572's hyper parameters: Current learning rate is 6.277463904582549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 595][Wall Clock 74.712077852s] Trained 128 records in 0.094706728 seconds. Throughput is 1351.5408 records/second. Loss is 2.2767603. Sequentiale465b572's hyper parameters: Current learning rate is 6.273525721455459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16256/60000][Iteration 596][Wall Clock 74.808052724s] Trained 128 records in 0.095974872 seconds. Throughput is 1333.6825 records/second. Loss is 2.2504163. Sequentiale465b572's hyper parameters: Current learning rate is 6.269592476489029E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 597][Wall Clock 74.906159044s] Trained 128 records in 0.09810632 seconds. Throughput is 1304.707 records/second. Loss is 2.2613108. Sequentiale465b572's hyper parameters: Current learning rate is 6.265664160401002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16512/60000][Iteration 598][Wall Clock 75.018660337s] Trained 128 records in 0.112501293 seconds. Throughput is 1137.7646 records/second. Loss is 2.2622063. Sequentiale465b572's hyper parameters: Current learning rate is 6.261740763932373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 599][Wall Clock 75.115149154s] Trained 128 records in 0.096488817 seconds. Throughput is 1326.5786 records/second. Loss is 2.2584689. Sequentiale465b572's hyper parameters: Current learning rate is 6.257822277847309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16768/60000][Iteration 600][Wall Clock 75.212164269s] Trained 128 records in 0.097015115 seconds. Throughput is 1319.3821 records/second. Loss is 2.262752. Sequentiale465b572's hyper parameters: Current learning rate is 6.253908692933083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 601][Wall Clock 75.309708552s] Trained 128 records in 0.097544283 seconds. Throughput is 1312.2245 records/second. Loss is 2.272913. Sequentiale465b572's hyper parameters: Current learning rate is 6.25E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:58 INFO  DistriOptimizer$:408 - [Epoch 2 17024/60000][Iteration 602][Wall Clock 75.407952077s] Trained 128 records in 0.098243525 seconds. Throughput is 1302.8848 records/second. Loss is 2.2719998. Sequentiale465b572's hyper parameters: Current learning rate is 6.246096189881325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 603][Wall Clock 75.503885796s] Trained 128 records in 0.095933719 seconds. Throughput is 1334.2545 records/second. Loss is 2.2683954. Sequentiale465b572's hyper parameters: Current learning rate is 6.24219725343321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17280/60000][Iteration 604][Wall Clock 75.597750658s] Trained 128 records in 0.093864862 seconds. Throughput is 1363.6625 records/second. Loss is 2.2703638. Sequentiale465b572's hyper parameters: Current learning rate is 6.238303181534623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 605][Wall Clock 75.689127609s] Trained 128 records in 0.091376951 seconds. Throughput is 1400.7909 records/second. Loss is 2.2546387. Sequentiale465b572's hyper parameters: Current learning rate is 6.234413965087282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17536/60000][Iteration 606][Wall Clock 75.788498395s] Trained 128 records in 0.099370786 seconds. Throughput is 1288.105 records/second. Loss is 2.2721746. Sequentiale465b572's hyper parameters: Current learning rate is 6.230529595015577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 607][Wall Clock 75.8937339s] Trained 128 records in 0.105235505 seconds. Throughput is 1216.3196 records/second. Loss is 2.261076. Sequentiale465b572's hyper parameters: Current learning rate is 6.226650062266502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17792/60000][Iteration 608][Wall Clock 75.994382882s] Trained 128 records in 0.100648982 seconds. Throughput is 1271.7466 records/second. Loss is 2.256796. Sequentiale465b572's hyper parameters: Current learning rate is 6.222775357809583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 609][Wall Clock 76.09023945s] Trained 128 records in 0.095856568 seconds. Throughput is 1335.3284 records/second. Loss is 2.2551074. Sequentiale465b572's hyper parameters: Current learning rate is 6.218905472636816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 18048/60000][Iteration 610][Wall Clock 76.187229535s] Trained 128 records in 0.096990085 seconds. Throughput is 1319.7225 records/second. Loss is 2.2598574. Sequentiale465b572's hyper parameters: Current learning rate is 6.215040397762586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 611][Wall Clock 76.284402419s] Trained 128 records in 0.097172884 seconds. Throughput is 1317.2399 records/second. Loss is 2.2625818. Sequentiale465b572's hyper parameters: Current learning rate is 6.211180124223603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:05:59 INFO  DistriOptimizer$:408 - [Epoch 2 18304/60000][Iteration 612][Wall Clock 76.390505221s] Trained 128 records in 0.106102802 seconds. Throughput is 1206.3772 records/second. Loss is 2.258914. Sequentiale465b572's hyper parameters: Current learning rate is 6.207324643078833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 613][Wall Clock 76.489585496s] Trained 128 records in 0.099080275 seconds. Throughput is 1291.8818 records/second. Loss is 2.2475202. Sequentiale465b572's hyper parameters: Current learning rate is 6.203473945409429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 18560/60000][Iteration 614][Wall Clock 76.610237286s] Trained 128 records in 0.12065179 seconds. Throughput is 1060.9043 records/second. Loss is 2.2655084. Sequentiale465b572's hyper parameters: Current learning rate is 6.199628022318661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 615][Wall Clock 76.714669013s] Trained 128 records in 0.104431727 seconds. Throughput is 1225.6812 records/second. Loss is 2.24358. Sequentiale465b572's hyper parameters: Current learning rate is 6.195786864931846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 18816/60000][Iteration 616][Wall Clock 76.817572718s] Trained 128 records in 0.102903705 seconds. Throughput is 1243.8813 records/second. Loss is 2.247472. Sequentiale465b572's hyper parameters: Current learning rate is 6.191950464396285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 617][Wall Clock 76.920841086s] Trained 128 records in 0.103268368 seconds. Throughput is 1239.4889 records/second. Loss is 2.264128. Sequentiale465b572's hyper parameters: Current learning rate is 6.188118811881188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 19072/60000][Iteration 618][Wall Clock 77.014571397s] Trained 128 records in 0.093730311 seconds. Throughput is 1365.6201 records/second. Loss is 2.2651877. Sequentiale465b572's hyper parameters: Current learning rate is 6.184291898577613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 619][Wall Clock 77.107160046s] Trained 128 records in 0.092588649 seconds. Throughput is 1382.4589 records/second. Loss is 2.2654297. Sequentiale465b572's hyper parameters: Current learning rate is 6.180469715698394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 19328/60000][Iteration 620][Wall Clock 77.224449317s] Trained 128 records in 0.117289271 seconds. Throughput is 1091.319 records/second. Loss is 2.245674. Sequentiale465b572's hyper parameters: Current learning rate is 6.176652254478073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 621][Wall Clock 77.325413043s] Trained 128 records in 0.100963726 seconds. Throughput is 1267.7821 records/second. Loss is 2.2478483. Sequentiale465b572's hyper parameters: Current learning rate is 6.172839506172839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:00 INFO  DistriOptimizer$:408 - [Epoch 2 19584/60000][Iteration 622][Wall Clock 77.457980375s] Trained 128 records in 0.132567332 seconds. Throughput is 965.54706 records/second. Loss is 2.264976. Sequentiale465b572's hyper parameters: Current learning rate is 6.169031462060457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 623][Wall Clock 77.556630511s] Trained 128 records in 0.098650136 seconds. Throughput is 1297.5146 records/second. Loss is 2.2693608. Sequentiale465b572's hyper parameters: Current learning rate is 6.165228113440197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 19840/60000][Iteration 624][Wall Clock 77.65894538s] Trained 128 records in 0.102314869 seconds. Throughput is 1251.04 records/second. Loss is 2.257622. Sequentiale465b572's hyper parameters: Current learning rate is 6.161429451632779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 625][Wall Clock 77.756094213s] Trained 128 records in 0.097148833 seconds. Throughput is 1317.5659 records/second. Loss is 2.2505572. Sequentiale465b572's hyper parameters: Current learning rate is 6.157635467980296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 20096/60000][Iteration 626][Wall Clock 77.850266352s] Trained 128 records in 0.094172139 seconds. Throughput is 1359.213 records/second. Loss is 2.266738. Sequentiale465b572's hyper parameters: Current learning rate is 6.153846153846154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 627][Wall Clock 77.950119414s] Trained 128 records in 0.099853062 seconds. Throughput is 1281.8835 records/second. Loss is 2.251599. Sequentiale465b572's hyper parameters: Current learning rate is 6.150061500615006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 20352/60000][Iteration 628][Wall Clock 78.068928091s] Trained 128 records in 0.118808677 seconds. Throughput is 1077.3624 records/second. Loss is 2.2594154. Sequentiale465b572's hyper parameters: Current learning rate is 6.146281499692687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 629][Wall Clock 78.183778203s] Trained 128 records in 0.114850112 seconds. Throughput is 1114.4961 records/second. Loss is 2.2613828. Sequentiale465b572's hyper parameters: Current learning rate is 6.142506142506142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 20608/60000][Iteration 630][Wall Clock 78.2830084s] Trained 128 records in 0.099230197 seconds. Throughput is 1289.9299 records/second. Loss is 2.2543197. Sequentiale465b572's hyper parameters: Current learning rate is 6.138735420503377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:01 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 631][Wall Clock 78.383320428s] Trained 128 records in 0.100312028 seconds. Throughput is 1276.0186 records/second. Loss is 2.2723005. Sequentiale465b572's hyper parameters: Current learning rate is 6.134969325153375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 20864/60000][Iteration 632][Wall Clock 78.482075356s] Trained 128 records in 0.098754928 seconds. Throughput is 1296.1378 records/second. Loss is 2.282957. Sequentiale465b572's hyper parameters: Current learning rate is 6.131207847946045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 633][Wall Clock 78.584259924s] Trained 128 records in 0.102184568 seconds. Throughput is 1252.6353 records/second. Loss is 2.2666473. Sequentiale465b572's hyper parameters: Current learning rate is 6.127450980392157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21120/60000][Iteration 634][Wall Clock 78.688122223s] Trained 128 records in 0.103862299 seconds. Throughput is 1232.401 records/second. Loss is 2.2627916. Sequentiale465b572's hyper parameters: Current learning rate is 6.12369871402327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 635][Wall Clock 78.80210417s] Trained 128 records in 0.113981947 seconds. Throughput is 1122.9849 records/second. Loss is 2.2521255. Sequentiale465b572's hyper parameters: Current learning rate is 6.119951040391677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21376/60000][Iteration 636][Wall Clock 78.904869305s] Trained 128 records in 0.102765135 seconds. Throughput is 1245.5586 records/second. Loss is 2.2552884. Sequentiale465b572's hyper parameters: Current learning rate is 6.116207951070336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 637][Wall Clock 79.014749452s] Trained 128 records in 0.109880147 seconds. Throughput is 1164.9056 records/second. Loss is 2.2481558. Sequentiale465b572's hyper parameters: Current learning rate is 6.112469437652812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21632/60000][Iteration 638][Wall Clock 79.139173213s] Trained 128 records in 0.124423761 seconds. Throughput is 1028.7424 records/second. Loss is 2.2494214. Sequentiale465b572's hyper parameters: Current learning rate is 6.108735491753207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 639][Wall Clock 79.277066439s] Trained 128 records in 0.137893226 seconds. Throughput is 928.2544 records/second. Loss is 2.268484. Sequentiale465b572's hyper parameters: Current learning rate is 6.105006105006105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:02 INFO  DistriOptimizer$:408 - [Epoch 2 21888/60000][Iteration 640][Wall Clock 79.411427698s] Trained 128 records in 0.134361259 seconds. Throughput is 952.6556 records/second. Loss is 2.251109. Sequentiale465b572's hyper parameters: Current learning rate is 6.101281269066504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 641][Wall Clock 79.53587228s] Trained 128 records in 0.124444582 seconds. Throughput is 1028.5703 records/second. Loss is 2.2565258. Sequentiale465b572's hyper parameters: Current learning rate is 6.097560975609756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22144/60000][Iteration 642][Wall Clock 79.634901151s] Trained 128 records in 0.099028871 seconds. Throughput is 1292.5524 records/second. Loss is 2.24888. Sequentiale465b572's hyper parameters: Current learning rate is 6.093845216331506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 643][Wall Clock 79.769109568s] Trained 128 records in 0.134208417 seconds. Throughput is 953.74054 records/second. Loss is 2.2550025. Sequentiale465b572's hyper parameters: Current learning rate is 6.090133982947626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22400/60000][Iteration 644][Wall Clock 79.867953925s] Trained 128 records in 0.098844357 seconds. Throughput is 1294.9652 records/second. Loss is 2.2594938. Sequentiale465b572's hyper parameters: Current learning rate is 6.086427267194157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 645][Wall Clock 79.973818318s] Trained 128 records in 0.105864393 seconds. Throughput is 1209.094 records/second. Loss is 2.2710938. Sequentiale465b572's hyper parameters: Current learning rate is 6.082725060827251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22656/60000][Iteration 646][Wall Clock 80.069424189s] Trained 128 records in 0.095605871 seconds. Throughput is 1338.8298 records/second. Loss is 2.2660432. Sequentiale465b572's hyper parameters: Current learning rate is 6.079027355623101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 647][Wall Clock 80.173573391s] Trained 128 records in 0.104149202 seconds. Throughput is 1229.0061 records/second. Loss is 2.2464032. Sequentiale465b572's hyper parameters: Current learning rate is 6.075334143377886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 22912/60000][Iteration 648][Wall Clock 80.276150718s] Trained 128 records in 0.102577327 seconds. Throughput is 1247.8391 records/second. Loss is 2.2614374. Sequentiale465b572's hyper parameters: Current learning rate is 6.071645415907711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:03 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 649][Wall Clock 80.374020594s] Trained 128 records in 0.097869876 seconds. Throughput is 1307.859 records/second. Loss is 2.255948. Sequentiale465b572's hyper parameters: Current learning rate is 6.067961165048543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23168/60000][Iteration 650][Wall Clock 80.46893448s] Trained 128 records in 0.094913886 seconds. Throughput is 1348.591 records/second. Loss is 2.2571812. Sequentiale465b572's hyper parameters: Current learning rate is 6.064281382656155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 651][Wall Clock 80.569275612s] Trained 128 records in 0.100341132 seconds. Throughput is 1275.6483 records/second. Loss is 2.2485795. Sequentiale465b572's hyper parameters: Current learning rate is 6.060606060606061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23424/60000][Iteration 652][Wall Clock 80.662943292s] Trained 128 records in 0.09366768 seconds. Throughput is 1366.5333 records/second. Loss is 2.250861. Sequentiale465b572's hyper parameters: Current learning rate is 6.056935190793458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 653][Wall Clock 80.760917842s] Trained 128 records in 0.09797455 seconds. Throughput is 1306.4617 records/second. Loss is 2.2701976. Sequentiale465b572's hyper parameters: Current learning rate is 6.053268765133171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23680/60000][Iteration 654][Wall Clock 80.854184432s] Trained 128 records in 0.09326659 seconds. Throughput is 1372.4099 records/second. Loss is 2.2448394. Sequentiale465b572's hyper parameters: Current learning rate is 6.049606775559589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 655][Wall Clock 80.961517292s] Trained 128 records in 0.10733286 seconds. Throughput is 1192.5518 records/second. Loss is 2.2582638. Sequentiale465b572's hyper parameters: Current learning rate is 6.045949214026603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 23936/60000][Iteration 656][Wall Clock 81.064762917s] Trained 128 records in 0.103245625 seconds. Throughput is 1239.762 records/second. Loss is 2.2629545. Sequentiale465b572's hyper parameters: Current learning rate is 6.042296072507553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 657][Wall Clock 81.162774293s] Trained 128 records in 0.098011376 seconds. Throughput is 1305.9708 records/second. Loss is 2.2536693. Sequentiale465b572's hyper parameters: Current learning rate is 6.038647342995169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 24192/60000][Iteration 658][Wall Clock 81.268821227s] Trained 128 records in 0.106046934 seconds. Throughput is 1207.0127 records/second. Loss is 2.2583144. Sequentiale465b572's hyper parameters: Current learning rate is 6.035003017501509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:04 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 659][Wall Clock 81.363912747s] Trained 128 records in 0.09509152 seconds. Throughput is 1346.0717 records/second. Loss is 2.2572026. Sequentiale465b572's hyper parameters: Current learning rate is 6.031363088057902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 24448/60000][Iteration 660][Wall Clock 81.463002434s] Trained 128 records in 0.099089687 seconds. Throughput is 1291.759 records/second. Loss is 2.2572327. Sequentiale465b572's hyper parameters: Current learning rate is 6.027727546714888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 661][Wall Clock 81.564412775s] Trained 128 records in 0.101410341 seconds. Throughput is 1262.1986 records/second. Loss is 2.2437935. Sequentiale465b572's hyper parameters: Current learning rate is 6.024096385542168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 24704/60000][Iteration 662][Wall Clock 81.671123811s] Trained 128 records in 0.106711036 seconds. Throughput is 1199.501 records/second. Loss is 2.2549818. Sequentiale465b572's hyper parameters: Current learning rate is 6.020469596628537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 663][Wall Clock 81.802577473s] Trained 128 records in 0.131453662 seconds. Throughput is 973.7272 records/second. Loss is 2.2521338. Sequentiale465b572's hyper parameters: Current learning rate is 6.016847172081829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 24960/60000][Iteration 664][Wall Clock 81.927284287s] Trained 128 records in 0.124706814 seconds. Throughput is 1026.4075 records/second. Loss is 2.2648296. Sequentiale465b572's hyper parameters: Current learning rate is 6.013229104028864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 665][Wall Clock 82.061180749s] Trained 128 records in 0.133896462 seconds. Throughput is 955.9626 records/second. Loss is 2.2507088. Sequentiale465b572's hyper parameters: Current learning rate is 6.009615384615384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 25216/60000][Iteration 666][Wall Clock 82.162405664s] Trained 128 records in 0.101224915 seconds. Throughput is 1264.5109 records/second. Loss is 2.2632694. Sequentiale465b572's hyper parameters: Current learning rate is 6.006006006006006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 667][Wall Clock 82.278587405s] Trained 128 records in 0.116181741 seconds. Throughput is 1101.7222 records/second. Loss is 2.2550633. Sequentiale465b572's hyper parameters: Current learning rate is 6.002400960384154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:05 INFO  DistriOptimizer$:408 - [Epoch 2 25472/60000][Iteration 668][Wall Clock 82.404112876s] Trained 128 records in 0.125525471 seconds. Throughput is 1019.7133 records/second. Loss is 2.2642317. Sequentiale465b572's hyper parameters: Current learning rate is 5.998800239952009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 669][Wall Clock 82.530780571s] Trained 128 records in 0.126667695 seconds. Throughput is 1010.5181 records/second. Loss is 2.2446766. Sequentiale465b572's hyper parameters: Current learning rate is 5.995203836930455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 25728/60000][Iteration 670][Wall Clock 82.637748528s] Trained 128 records in 0.106967957 seconds. Throughput is 1196.62 records/second. Loss is 2.255614. Sequentiale465b572's hyper parameters: Current learning rate is 5.991611743559018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 671][Wall Clock 82.773475548s] Trained 128 records in 0.13572702 seconds. Throughput is 943.0694 records/second. Loss is 2.2553656. Sequentiale465b572's hyper parameters: Current learning rate is 5.988023952095808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 25984/60000][Iteration 672][Wall Clock 82.915991455s] Trained 128 records in 0.142515907 seconds. Throughput is 898.1453 records/second. Loss is 2.249827. Sequentiale465b572's hyper parameters: Current learning rate is 5.984440454817474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 673][Wall Clock 83.070635016s] Trained 128 records in 0.154643561 seconds. Throughput is 827.70984 records/second. Loss is 2.253516. Sequentiale465b572's hyper parameters: Current learning rate is 5.980861244019139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 26240/60000][Iteration 674][Wall Clock 83.199611175s] Trained 128 records in 0.128976159 seconds. Throughput is 992.4314 records/second. Loss is 2.268402. Sequentiale465b572's hyper parameters: Current learning rate is 5.977286312014345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 675][Wall Clock 83.297216783s] Trained 128 records in 0.097605608 seconds. Throughput is 1311.4 records/second. Loss is 2.241335. Sequentiale465b572's hyper parameters: Current learning rate is 5.973715651135007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:06 INFO  DistriOptimizer$:408 - [Epoch 2 26496/60000][Iteration 676][Wall Clock 83.393841078s] Trained 128 records in 0.096624295 seconds. Throughput is 1324.7186 records/second. Loss is 2.2608411. Sequentiale465b572's hyper parameters: Current learning rate is 5.970149253731343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 677][Wall Clock 83.499170748s] Trained 128 records in 0.10532967 seconds. Throughput is 1215.2322 records/second. Loss is 2.248643. Sequentiale465b572's hyper parameters: Current learning rate is 5.966587112171837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 26752/60000][Iteration 678][Wall Clock 83.599511382s] Trained 128 records in 0.100340634 seconds. Throughput is 1275.6547 records/second. Loss is 2.2516494. Sequentiale465b572's hyper parameters: Current learning rate is 5.963029218843172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 679][Wall Clock 83.70392455s] Trained 128 records in 0.104413168 seconds. Throughput is 1225.899 records/second. Loss is 2.256272. Sequentiale465b572's hyper parameters: Current learning rate is 5.95947556615018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 27008/60000][Iteration 680][Wall Clock 83.79876892s] Trained 128 records in 0.09484437 seconds. Throughput is 1349.5793 records/second. Loss is 2.2557855. Sequentiale465b572's hyper parameters: Current learning rate is 5.955926146515783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 681][Wall Clock 83.898291364s] Trained 128 records in 0.099522444 seconds. Throughput is 1286.1421 records/second. Loss is 2.2511766. Sequentiale465b572's hyper parameters: Current learning rate is 5.952380952380952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 27264/60000][Iteration 682][Wall Clock 83.999917981s] Trained 128 records in 0.101626617 seconds. Throughput is 1259.5126 records/second. Loss is 2.2659547. Sequentiale465b572's hyper parameters: Current learning rate is 5.94883997620464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 683][Wall Clock 84.126144328s] Trained 128 records in 0.126226347 seconds. Throughput is 1014.05133 records/second. Loss is 2.2439742. Sequentiale465b572's hyper parameters: Current learning rate is 5.945303210463734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 27520/60000][Iteration 684][Wall Clock 84.227004373s] Trained 128 records in 0.100860045 seconds. Throughput is 1269.0853 records/second. Loss is 2.2593446. Sequentiale465b572's hyper parameters: Current learning rate is 5.941770647653001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:07 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 685][Wall Clock 84.353634985s] Trained 128 records in 0.126630612 seconds. Throughput is 1010.81396 records/second. Loss is 2.2436314. Sequentiale465b572's hyper parameters: Current learning rate is 5.938242280285035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 27776/60000][Iteration 686][Wall Clock 84.474197379s] Trained 128 records in 0.120562394 seconds. Throughput is 1061.6909 records/second. Loss is 2.254779. Sequentiale465b572's hyper parameters: Current learning rate is 5.934718100890207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 687][Wall Clock 84.5790894s] Trained 128 records in 0.104892021 seconds. Throughput is 1220.3025 records/second. Loss is 2.2537024. Sequentiale465b572's hyper parameters: Current learning rate is 5.931198102016608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28032/60000][Iteration 688][Wall Clock 84.709795798s] Trained 128 records in 0.130706398 seconds. Throughput is 979.29407 records/second. Loss is 2.2419567. Sequentiale465b572's hyper parameters: Current learning rate is 5.927682276229994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 689][Wall Clock 84.805052107s] Trained 128 records in 0.095256309 seconds. Throughput is 1343.743 records/second. Loss is 2.2586806. Sequentiale465b572's hyper parameters: Current learning rate is 5.924170616113743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28288/60000][Iteration 690][Wall Clock 84.912109332s] Trained 128 records in 0.107057225 seconds. Throughput is 1195.6222 records/second. Loss is 2.2594023. Sequentiale465b572's hyper parameters: Current learning rate is 5.920663114268798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 691][Wall Clock 85.013307134s] Trained 128 records in 0.101197802 seconds. Throughput is 1264.8496 records/second. Loss is 2.2593627. Sequentiale465b572's hyper parameters: Current learning rate is 5.91715976331361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28544/60000][Iteration 692][Wall Clock 85.122116276s] Trained 128 records in 0.108809142 seconds. Throughput is 1176.3717 records/second. Loss is 2.264551. Sequentiale465b572's hyper parameters: Current learning rate is 5.913660555884092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 693][Wall Clock 85.23453153s] Trained 128 records in 0.112415254 seconds. Throughput is 1138.6355 records/second. Loss is 2.2613852. Sequentiale465b572's hyper parameters: Current learning rate is 5.91016548463357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:08 INFO  DistriOptimizer$:408 - [Epoch 2 28800/60000][Iteration 694][Wall Clock 85.358781077s] Trained 128 records in 0.124249547 seconds. Throughput is 1030.1848 records/second. Loss is 2.2497017. Sequentiale465b572's hyper parameters: Current learning rate is 5.906674542232723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 695][Wall Clock 85.473149212s] Trained 128 records in 0.114368135 seconds. Throughput is 1119.1929 records/second. Loss is 2.269965. Sequentiale465b572's hyper parameters: Current learning rate is 5.90318772136954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29056/60000][Iteration 696][Wall Clock 85.562691672s] Trained 128 records in 0.08954246 seconds. Throughput is 1429.4894 records/second. Loss is 2.2654827. Sequentiale465b572's hyper parameters: Current learning rate is 5.899705014749262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 697][Wall Clock 85.657261062s] Trained 128 records in 0.09456939 seconds. Throughput is 1353.5034 records/second. Loss is 2.2554226. Sequentiale465b572's hyper parameters: Current learning rate is 5.896226415094339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29312/60000][Iteration 698][Wall Clock 85.791627094s] Trained 128 records in 0.134366032 seconds. Throughput is 952.6217 records/second. Loss is 2.2498362. Sequentiale465b572's hyper parameters: Current learning rate is 5.892751915144372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 699][Wall Clock 85.888331414s] Trained 128 records in 0.09670432 seconds. Throughput is 1323.6223 records/second. Loss is 2.2494788. Sequentiale465b572's hyper parameters: Current learning rate is 5.889281507656067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29568/60000][Iteration 700][Wall Clock 85.980762387s] Trained 128 records in 0.092430973 seconds. Throughput is 1384.8173 records/second. Loss is 2.2414725. Sequentiale465b572's hyper parameters: Current learning rate is 5.885815185403178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 701][Wall Clock 86.074200011s] Trained 128 records in 0.093437624 seconds. Throughput is 1369.8978 records/second. Loss is 2.2511864. Sequentiale465b572's hyper parameters: Current learning rate is 5.88235294117647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29824/60000][Iteration 702][Wall Clock 86.167346574s] Trained 128 records in 0.093146563 seconds. Throughput is 1374.1785 records/second. Loss is 2.258124. Sequentiale465b572's hyper parameters: Current learning rate is 5.878894767783657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 703][Wall Clock 86.262224571s] Trained 128 records in 0.094877997 seconds. Throughput is 1349.1011 records/second. Loss is 2.2495747. Sequentiale465b572's hyper parameters: Current learning rate is 5.875440658049354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:09 INFO  DistriOptimizer$:408 - [Epoch 2 30080/60000][Iteration 704][Wall Clock 86.356941114s] Trained 128 records in 0.094716543 seconds. Throughput is 1351.4006 records/second. Loss is 2.2579517. Sequentiale465b572's hyper parameters: Current learning rate is 5.871990604815032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 705][Wall Clock 86.452461363s] Trained 128 records in 0.095520249 seconds. Throughput is 1340.03 records/second. Loss is 2.2568216. Sequentiale465b572's hyper parameters: Current learning rate is 5.868544600938967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30336/60000][Iteration 706][Wall Clock 86.548333662s] Trained 128 records in 0.095872299 seconds. Throughput is 1335.1094 records/second. Loss is 2.246244. Sequentiale465b572's hyper parameters: Current learning rate is 5.865102639296188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 707][Wall Clock 86.643442068s] Trained 128 records in 0.095108406 seconds. Throughput is 1345.8326 records/second. Loss is 2.2521772. Sequentiale465b572's hyper parameters: Current learning rate is 5.86166471277843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30592/60000][Iteration 708][Wall Clock 86.744207935s] Trained 128 records in 0.100765867 seconds. Throughput is 1270.2714 records/second. Loss is 2.2598155. Sequentiale465b572's hyper parameters: Current learning rate is 5.858230814294084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 709][Wall Clock 86.837086098s] Trained 128 records in 0.092878163 seconds. Throughput is 1378.1495 records/second. Loss is 2.2540455. Sequentiale465b572's hyper parameters: Current learning rate is 5.85480093676815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30848/60000][Iteration 710][Wall Clock 86.930323869s] Trained 128 records in 0.093237771 seconds. Throughput is 1372.8342 records/second. Loss is 2.2586021. Sequentiale465b572's hyper parameters: Current learning rate is 5.851375073142189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 711][Wall Clock 87.021144429s] Trained 128 records in 0.09082056 seconds. Throughput is 1409.3726 records/second. Loss is 2.2482169. Sequentiale465b572's hyper parameters: Current learning rate is 5.847953216374269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 31104/60000][Iteration 712][Wall Clock 87.115194827s] Trained 128 records in 0.094050398 seconds. Throughput is 1360.9724 records/second. Loss is 2.258014. Sequentiale465b572's hyper parameters: Current learning rate is 5.844535359438925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 713][Wall Clock 87.210043922s] Trained 128 records in 0.094849095 seconds. Throughput is 1349.5121 records/second. Loss is 2.2513063. Sequentiale465b572's hyper parameters: Current learning rate is 5.841121495327103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 31360/60000][Iteration 714][Wall Clock 87.312002662s] Trained 128 records in 0.10195874 seconds. Throughput is 1255.4098 records/second. Loss is 2.2456272. Sequentiale465b572's hyper parameters: Current learning rate is 5.837711617046118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:10 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 715][Wall Clock 87.406093959s] Trained 128 records in 0.094091297 seconds. Throughput is 1360.3809 records/second. Loss is 2.2490008. Sequentiale465b572's hyper parameters: Current learning rate is 5.834305717619604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 31616/60000][Iteration 716][Wall Clock 87.512694599s] Trained 128 records in 0.10660064 seconds. Throughput is 1200.7433 records/second. Loss is 2.2636302. Sequentiale465b572's hyper parameters: Current learning rate is 5.830903790087465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 717][Wall Clock 87.618626179s] Trained 128 records in 0.10593158 seconds. Throughput is 1208.3271 records/second. Loss is 2.239268. Sequentiale465b572's hyper parameters: Current learning rate is 5.827505827505828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 31872/60000][Iteration 718][Wall Clock 87.714450265s] Trained 128 records in 0.095824086 seconds. Throughput is 1335.7811 records/second. Loss is 2.248853. Sequentiale465b572's hyper parameters: Current learning rate is 5.824111822947001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 719][Wall Clock 87.811705435s] Trained 128 records in 0.09725517 seconds. Throughput is 1316.1254 records/second. Loss is 2.2578976. Sequentiale465b572's hyper parameters: Current learning rate is 5.820721769499418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 32128/60000][Iteration 720][Wall Clock 87.908714889s] Trained 128 records in 0.097009454 seconds. Throughput is 1319.459 records/second. Loss is 2.2582264. Sequentiale465b572's hyper parameters: Current learning rate is 5.817335660267598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 721][Wall Clock 88.007991945s] Trained 128 records in 0.099277056 seconds. Throughput is 1289.321 records/second. Loss is 2.242741. Sequentiale465b572's hyper parameters: Current learning rate is 5.813953488372093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 32384/60000][Iteration 722][Wall Clock 88.127073293s] Trained 128 records in 0.119081348 seconds. Throughput is 1074.8955 records/second. Loss is 2.2513456. Sequentiale465b572's hyper parameters: Current learning rate is 5.810575246949448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 723][Wall Clock 88.226901337s] Trained 128 records in 0.099828044 seconds. Throughput is 1282.2048 records/second. Loss is 2.2481635. Sequentiale465b572's hyper parameters: Current learning rate is 5.807200929152149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:11 INFO  DistriOptimizer$:408 - [Epoch 2 32640/60000][Iteration 724][Wall Clock 88.334096211s] Trained 128 records in 0.107194874 seconds. Throughput is 1194.087 records/second. Loss is 2.2537751. Sequentiale465b572's hyper parameters: Current learning rate is 5.803830528148578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 725][Wall Clock 88.435517248s] Trained 128 records in 0.101421037 seconds. Throughput is 1262.0656 records/second. Loss is 2.256368. Sequentiale465b572's hyper parameters: Current learning rate is 5.80046403712297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 32896/60000][Iteration 726][Wall Clock 88.535341862s] Trained 128 records in 0.099824614 seconds. Throughput is 1282.2489 records/second. Loss is 2.2362208. Sequentiale465b572's hyper parameters: Current learning rate is 5.797101449275362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 727][Wall Clock 88.633316386s] Trained 128 records in 0.097974524 seconds. Throughput is 1306.462 records/second. Loss is 2.23728. Sequentiale465b572's hyper parameters: Current learning rate is 5.793742757821553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33152/60000][Iteration 728][Wall Clock 88.733564661s] Trained 128 records in 0.100248275 seconds. Throughput is 1276.83 records/second. Loss is 2.2462938. Sequentiale465b572's hyper parameters: Current learning rate is 5.790387955993052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 729][Wall Clock 88.831386257s] Trained 128 records in 0.097821596 seconds. Throughput is 1308.5045 records/second. Loss is 2.2597225. Sequentiale465b572's hyper parameters: Current learning rate is 5.787037037037037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33408/60000][Iteration 730][Wall Clock 88.927522542s] Trained 128 records in 0.096136285 seconds. Throughput is 1331.4431 records/second. Loss is 2.2512445. Sequentiale465b572's hyper parameters: Current learning rate is 5.78368999421631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 731][Wall Clock 89.026818394s] Trained 128 records in 0.099295852 seconds. Throughput is 1289.077 records/second. Loss is 2.2443783. Sequentiale465b572's hyper parameters: Current learning rate is 5.780346820809249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33664/60000][Iteration 732][Wall Clock 89.123507672s] Trained 128 records in 0.096689278 seconds. Throughput is 1323.8282 records/second. Loss is 2.2487454. Sequentiale465b572's hyper parameters: Current learning rate is 5.777007510109764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 733][Wall Clock 89.226848516s] Trained 128 records in 0.103340844 seconds. Throughput is 1238.6196 records/second. Loss is 2.251167. Sequentiale465b572's hyper parameters: Current learning rate is 5.773672055427252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:12 INFO  DistriOptimizer$:408 - [Epoch 2 33920/60000][Iteration 734][Wall Clock 89.326567454s] Trained 128 records in 0.099718938 seconds. Throughput is 1283.6078 records/second. Loss is 2.2576623. Sequentiale465b572's hyper parameters: Current learning rate is 5.770340450086555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 735][Wall Clock 89.422506999s] Trained 128 records in 0.095939545 seconds. Throughput is 1334.1735 records/second. Loss is 2.2484062. Sequentiale465b572's hyper parameters: Current learning rate is 5.767012687427913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34176/60000][Iteration 736][Wall Clock 89.51865364s] Trained 128 records in 0.096146641 seconds. Throughput is 1331.2997 records/second. Loss is 2.2513015. Sequentiale465b572's hyper parameters: Current learning rate is 5.763688760806917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 737][Wall Clock 89.617374176s] Trained 128 records in 0.098720536 seconds. Throughput is 1296.5894 records/second. Loss is 2.2594461. Sequentiale465b572's hyper parameters: Current learning rate is 5.76036866359447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34432/60000][Iteration 738][Wall Clock 89.732113534s] Trained 128 records in 0.114739358 seconds. Throughput is 1115.5719 records/second. Loss is 2.2474852. Sequentiale465b572's hyper parameters: Current learning rate is 5.757052389176741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 739][Wall Clock 89.830124945s] Trained 128 records in 0.098011411 seconds. Throughput is 1305.9703 records/second. Loss is 2.2533875. Sequentiale465b572's hyper parameters: Current learning rate is 5.753739930955121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34688/60000][Iteration 740][Wall Clock 89.929606871s] Trained 128 records in 0.099481926 seconds. Throughput is 1286.6659 records/second. Loss is 2.2580256. Sequentiale465b572's hyper parameters: Current learning rate is 5.750431282346176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 741][Wall Clock 90.068419674s] Trained 128 records in 0.138812803 seconds. Throughput is 922.1051 records/second. Loss is 2.2510247. Sequentiale465b572's hyper parameters: Current learning rate is 5.747126436781609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 34944/60000][Iteration 742][Wall Clock 90.161133117s] Trained 128 records in 0.092713443 seconds. Throughput is 1380.598 records/second. Loss is 2.2432735. Sequentiale465b572's hyper parameters: Current learning rate is 5.743825387708214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 743][Wall Clock 90.283408387s] Trained 128 records in 0.12227527 seconds. Throughput is 1046.8184 records/second. Loss is 2.2577748. Sequentiale465b572's hyper parameters: Current learning rate is 5.74052812858783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:13 INFO  DistriOptimizer$:408 - [Epoch 2 35200/60000][Iteration 744][Wall Clock 90.379183107s] Trained 128 records in 0.09577472 seconds. Throughput is 1336.4696 records/second. Loss is 2.2636092. Sequentiale465b572's hyper parameters: Current learning rate is 5.737234652897304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 745][Wall Clock 90.475287976s] Trained 128 records in 0.096104869 seconds. Throughput is 1331.8784 records/second. Loss is 2.231924. Sequentiale465b572's hyper parameters: Current learning rate is 5.733944954128441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 35456/60000][Iteration 746][Wall Clock 90.568039142s] Trained 128 records in 0.092751166 seconds. Throughput is 1380.0365 records/second. Loss is 2.2470157. Sequentiale465b572's hyper parameters: Current learning rate is 5.730659025787965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 747][Wall Clock 90.660736795s] Trained 128 records in 0.092697653 seconds. Throughput is 1380.8333 records/second. Loss is 2.2474637. Sequentiale465b572's hyper parameters: Current learning rate is 5.72737686139748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 35712/60000][Iteration 748][Wall Clock 90.753952989s] Trained 128 records in 0.093216194 seconds. Throughput is 1373.152 records/second. Loss is 2.2599468. Sequentiale465b572's hyper parameters: Current learning rate is 5.724098454493418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 749][Wall Clock 90.850341387s] Trained 128 records in 0.096388398 seconds. Throughput is 1327.9606 records/second. Loss is 2.2474358. Sequentiale465b572's hyper parameters: Current learning rate is 5.720823798627002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 35968/60000][Iteration 750][Wall Clock 90.955293365s] Trained 128 records in 0.104951978 seconds. Throughput is 1219.6055 records/second. Loss is 2.2444823. Sequentiale465b572's hyper parameters: Current learning rate is 5.717552887364208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 751][Wall Clock 91.050581236s] Trained 128 records in 0.095287871 seconds. Throughput is 1343.2979 records/second. Loss is 2.2449484. Sequentiale465b572's hyper parameters: Current learning rate is 5.714285714285715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 36224/60000][Iteration 752][Wall Clock 91.150079933s] Trained 128 records in 0.099498697 seconds. Throughput is 1286.449 records/second. Loss is 2.259696. Sequentiale465b572's hyper parameters: Current learning rate is 5.711022272986865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 753][Wall Clock 91.243458248s] Trained 128 records in 0.093378315 seconds. Throughput is 1370.768 records/second. Loss is 2.2528672. Sequentiale465b572's hyper parameters: Current learning rate is 5.707762557077625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:14 INFO  DistriOptimizer$:408 - [Epoch 2 36480/60000][Iteration 754][Wall Clock 91.338747163s] Trained 128 records in 0.095288915 seconds. Throughput is 1343.2832 records/second. Loss is 2.2514982. Sequentiale465b572's hyper parameters: Current learning rate is 5.704506560182544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 755][Wall Clock 91.432101484s] Trained 128 records in 0.093354321 seconds. Throughput is 1371.1202 records/second. Loss is 2.2454498. Sequentiale465b572's hyper parameters: Current learning rate is 5.701254275940707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 36736/60000][Iteration 756][Wall Clock 91.525601195s] Trained 128 records in 0.093499711 seconds. Throughput is 1368.9882 records/second. Loss is 2.251691. Sequentiale465b572's hyper parameters: Current learning rate is 5.698005698005699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 757][Wall Clock 91.62063167s] Trained 128 records in 0.095030475 seconds. Throughput is 1346.9364 records/second. Loss is 2.2511952. Sequentiale465b572's hyper parameters: Current learning rate is 5.694760820045558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 36992/60000][Iteration 758][Wall Clock 91.717962746s] Trained 128 records in 0.097331076 seconds. Throughput is 1315.099 records/second. Loss is 2.255154. Sequentiale465b572's hyper parameters: Current learning rate is 5.691519635742744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 759][Wall Clock 91.814501136s] Trained 128 records in 0.09653839 seconds. Throughput is 1325.8975 records/second. Loss is 2.252497. Sequentiale465b572's hyper parameters: Current learning rate is 5.688282138794084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 37248/60000][Iteration 760][Wall Clock 91.919067322s] Trained 128 records in 0.104566186 seconds. Throughput is 1224.1051 records/second. Loss is 2.2413878. Sequentiale465b572's hyper parameters: Current learning rate is 5.685048322910746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 761][Wall Clock 92.025153862s] Trained 128 records in 0.10608654 seconds. Throughput is 1206.5621 records/second. Loss is 2.2558446. Sequentiale465b572's hyper parameters: Current learning rate is 5.681818181818182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 37504/60000][Iteration 762][Wall Clock 92.127066199s] Trained 128 records in 0.101912337 seconds. Throughput is 1255.9814 records/second. Loss is 2.2360606. Sequentiale465b572's hyper parameters: Current learning rate is 5.678591709256105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 763][Wall Clock 92.228615473s] Trained 128 records in 0.101549274 seconds. Throughput is 1260.4718 records/second. Loss is 2.2530963. Sequentiale465b572's hyper parameters: Current learning rate is 5.675368898978433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:15 INFO  DistriOptimizer$:408 - [Epoch 2 37760/60000][Iteration 764][Wall Clock 92.326919983s] Trained 128 records in 0.09830451 seconds. Throughput is 1302.0765 records/second. Loss is 2.2407181. Sequentiale465b572's hyper parameters: Current learning rate is 5.672149744753262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 765][Wall Clock 92.429646837s] Trained 128 records in 0.102726854 seconds. Throughput is 1246.0228 records/second. Loss is 2.239942. Sequentiale465b572's hyper parameters: Current learning rate is 5.668934240362812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38016/60000][Iteration 766][Wall Clock 92.539316186s] Trained 128 records in 0.109669349 seconds. Throughput is 1167.1447 records/second. Loss is 2.2412543. Sequentiale465b572's hyper parameters: Current learning rate is 5.665722379603399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 767][Wall Clock 92.644233424s] Trained 128 records in 0.104917238 seconds. Throughput is 1220.0093 records/second. Loss is 2.2480826. Sequentiale465b572's hyper parameters: Current learning rate is 5.662514156285391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38272/60000][Iteration 768][Wall Clock 92.770084659s] Trained 128 records in 0.125851235 seconds. Throughput is 1017.0739 records/second. Loss is 2.2411802. Sequentiale465b572's hyper parameters: Current learning rate is 5.659309564233164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 769][Wall Clock 92.867423629s] Trained 128 records in 0.09733897 seconds. Throughput is 1314.9924 records/second. Loss is 2.24233. Sequentiale465b572's hyper parameters: Current learning rate is 5.656108597285068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38528/60000][Iteration 770][Wall Clock 92.973257732s] Trained 128 records in 0.105834103 seconds. Throughput is 1209.4401 records/second. Loss is 2.2454758. Sequentiale465b572's hyper parameters: Current learning rate is 5.652911249293386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 771][Wall Clock 93.072286451s] Trained 128 records in 0.099028719 seconds. Throughput is 1292.5543 records/second. Loss is 2.2407222. Sequentiale465b572's hyper parameters: Current learning rate is 5.649717514124294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38784/60000][Iteration 772][Wall Clock 93.177870829s] Trained 128 records in 0.105584378 seconds. Throughput is 1212.3005 records/second. Loss is 2.2446914. Sequentiale465b572's hyper parameters: Current learning rate is 5.646527385657821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:16 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 773][Wall Clock 93.276807184s] Trained 128 records in 0.098936355 seconds. Throughput is 1293.761 records/second. Loss is 2.2349143. Sequentiale465b572's hyper parameters: Current learning rate is 5.64334085778781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39040/60000][Iteration 774][Wall Clock 93.400881143s] Trained 128 records in 0.124073959 seconds. Throughput is 1031.6427 records/second. Loss is 2.236053. Sequentiale465b572's hyper parameters: Current learning rate is 5.640157924421883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 775][Wall Clock 93.497190006s] Trained 128 records in 0.096308863 seconds. Throughput is 1329.0573 records/second. Loss is 2.251928. Sequentiale465b572's hyper parameters: Current learning rate is 5.636978579481398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39296/60000][Iteration 776][Wall Clock 93.596326439s] Trained 128 records in 0.099136433 seconds. Throughput is 1291.1499 records/second. Loss is 2.2419064. Sequentiale465b572's hyper parameters: Current learning rate is 5.633802816901409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 777][Wall Clock 93.695278667s] Trained 128 records in 0.098952228 seconds. Throughput is 1293.5535 records/second. Loss is 2.2385187. Sequentiale465b572's hyper parameters: Current learning rate is 5.630630630630631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39552/60000][Iteration 778][Wall Clock 93.79078923s] Trained 128 records in 0.095510563 seconds. Throughput is 1340.1659 records/second. Loss is 2.2458553. Sequentiale465b572's hyper parameters: Current learning rate is 5.6274620146314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 779][Wall Clock 93.88450743s] Trained 128 records in 0.0937182 seconds. Throughput is 1365.7966 records/second. Loss is 2.2464697. Sequentiale465b572's hyper parameters: Current learning rate is 5.624296962879641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39808/60000][Iteration 780][Wall Clock 93.978573745s] Trained 128 records in 0.094066315 seconds. Throughput is 1360.7422 records/second. Loss is 2.2497869. Sequentiale465b572's hyper parameters: Current learning rate is 5.621135469364812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 781][Wall Clock 94.072570579s] Trained 128 records in 0.093996834 seconds. Throughput is 1361.748 records/second. Loss is 2.2347486. Sequentiale465b572's hyper parameters: Current learning rate is 5.617977528089888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 40064/60000][Iteration 782][Wall Clock 94.176493557s] Trained 128 records in 0.103922978 seconds. Throughput is 1231.6814 records/second. Loss is 2.2387893. Sequentiale465b572's hyper parameters: Current learning rate is 5.614823133071308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 783][Wall Clock 94.272995575s] Trained 128 records in 0.096502018 seconds. Throughput is 1326.3971 records/second. Loss is 2.2428966. Sequentiale465b572's hyper parameters: Current learning rate is 5.611672278338945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:17 INFO  DistriOptimizer$:408 - [Epoch 2 40320/60000][Iteration 784][Wall Clock 94.366943751s] Trained 128 records in 0.093948176 seconds. Throughput is 1362.4532 records/second. Loss is 2.257804. Sequentiale465b572's hyper parameters: Current learning rate is 5.608524957936063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 785][Wall Clock 94.463939255s] Trained 128 records in 0.096995504 seconds. Throughput is 1319.6488 records/second. Loss is 2.237706. Sequentiale465b572's hyper parameters: Current learning rate is 5.605381165919282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 40576/60000][Iteration 786][Wall Clock 94.557529319s] Trained 128 records in 0.093590064 seconds. Throughput is 1367.6665 records/second. Loss is 2.238853. Sequentiale465b572's hyper parameters: Current learning rate is 5.602240896358543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 787][Wall Clock 94.650276496s] Trained 128 records in 0.092747177 seconds. Throughput is 1380.096 records/second. Loss is 2.2444053. Sequentiale465b572's hyper parameters: Current learning rate is 5.599104143337066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 40832/60000][Iteration 788][Wall Clock 94.745357196s] Trained 128 records in 0.0950807 seconds. Throughput is 1346.2247 records/second. Loss is 2.238177. Sequentiale465b572's hyper parameters: Current learning rate is 5.595970900951316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 789][Wall Clock 94.842768144s] Trained 128 records in 0.097410948 seconds. Throughput is 1314.0208 records/second. Loss is 2.232985. Sequentiale465b572's hyper parameters: Current learning rate is 5.592841163310962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 41088/60000][Iteration 790][Wall Clock 94.941553932s] Trained 128 records in 0.098785788 seconds. Throughput is 1295.7329 records/second. Loss is 2.2548559. Sequentiale465b572's hyper parameters: Current learning rate is 5.589714924538849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 791][Wall Clock 95.045016112s] Trained 128 records in 0.10346218 seconds. Throughput is 1237.167 records/second. Loss is 2.2427967. Sequentiale465b572's hyper parameters: Current learning rate is 5.586592178770949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 41344/60000][Iteration 792][Wall Clock 95.140853347s] Trained 128 records in 0.095837235 seconds. Throughput is 1335.5978 records/second. Loss is 2.2544227. Sequentiale465b572's hyper parameters: Current learning rate is 5.583472920156337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 793][Wall Clock 95.236032586s] Trained 128 records in 0.095179239 seconds. Throughput is 1344.831 records/second. Loss is 2.245752. Sequentiale465b572's hyper parameters: Current learning rate is 5.580357142857143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:18 INFO  DistriOptimizer$:408 - [Epoch 2 41600/60000][Iteration 794][Wall Clock 95.34133454s] Trained 128 records in 0.105301954 seconds. Throughput is 1215.552 records/second. Loss is 2.2409415. Sequentiale465b572's hyper parameters: Current learning rate is 5.577244841048521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 795][Wall Clock 95.440254265s] Trained 128 records in 0.098919725 seconds. Throughput is 1293.9785 records/second. Loss is 2.2430615. Sequentiale465b572's hyper parameters: Current learning rate is 5.574136008918618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 41856/60000][Iteration 796][Wall Clock 95.539785835s] Trained 128 records in 0.09953157 seconds. Throughput is 1286.0242 records/second. Loss is 2.241375. Sequentiale465b572's hyper parameters: Current learning rate is 5.571030640668524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 797][Wall Clock 95.644584639s] Trained 128 records in 0.104798804 seconds. Throughput is 1221.3881 records/second. Loss is 2.2435625. Sequentiale465b572's hyper parameters: Current learning rate is 5.567928730512249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 42112/60000][Iteration 798][Wall Clock 95.754022295s] Trained 128 records in 0.109437656 seconds. Throughput is 1169.6156 records/second. Loss is 2.2537043. Sequentiale465b572's hyper parameters: Current learning rate is 5.564830272676684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 799][Wall Clock 95.852937204s] Trained 128 records in 0.098914909 seconds. Throughput is 1294.0415 records/second. Loss is 2.2363605. Sequentiale465b572's hyper parameters: Current learning rate is 5.561735261401557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 42368/60000][Iteration 800][Wall Clock 95.966600676s] Trained 128 records in 0.113663472 seconds. Throughput is 1126.1313 records/second. Loss is 2.2474499. Sequentiale465b572's hyper parameters: Current learning rate is 5.558643690939412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 801][Wall Clock 96.070532275s] Trained 128 records in 0.103931599 seconds. Throughput is 1231.5792 records/second. Loss is 2.2466476. Sequentiale465b572's hyper parameters: Current learning rate is 5.555555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 42624/60000][Iteration 802][Wall Clock 96.177440472s] Trained 128 records in 0.106908197 seconds. Throughput is 1197.289 records/second. Loss is 2.2491326. Sequentiale465b572's hyper parameters: Current learning rate is 5.552470849528039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:19 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 803][Wall Clock 96.277858411s] Trained 128 records in 0.100417939 seconds. Throughput is 1274.6726 records/second. Loss is 2.2414455. Sequentiale465b572's hyper parameters: Current learning rate is 5.549389567147614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 42880/60000][Iteration 804][Wall Clock 96.374529005s] Trained 128 records in 0.096670594 seconds. Throughput is 1324.0842 records/second. Loss is 2.2412136. Sequentiale465b572's hyper parameters: Current learning rate is 5.546311702717693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 805][Wall Clock 96.486561879s] Trained 128 records in 0.112032874 seconds. Throughput is 1142.5217 records/second. Loss is 2.2466056. Sequentiale465b572's hyper parameters: Current learning rate is 5.543237250554324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43136/60000][Iteration 806][Wall Clock 96.583896592s] Trained 128 records in 0.097334713 seconds. Throughput is 1315.0498 records/second. Loss is 2.2490423. Sequentiale465b572's hyper parameters: Current learning rate is 5.540166204986149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 807][Wall Clock 96.681798189s] Trained 128 records in 0.097901597 seconds. Throughput is 1307.4353 records/second. Loss is 2.233809. Sequentiale465b572's hyper parameters: Current learning rate is 5.537098560354374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43392/60000][Iteration 808][Wall Clock 96.779765345s] Trained 128 records in 0.097967156 seconds. Throughput is 1306.5603 records/second. Loss is 2.2481914. Sequentiale465b572's hyper parameters: Current learning rate is 5.534034311012729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 809][Wall Clock 96.876813593s] Trained 128 records in 0.097048248 seconds. Throughput is 1318.9316 records/second. Loss is 2.2493377. Sequentiale465b572's hyper parameters: Current learning rate is 5.530973451327434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43648/60000][Iteration 810][Wall Clock 96.975158971s] Trained 128 records in 0.098345378 seconds. Throughput is 1301.5355 records/second. Loss is 2.2415848. Sequentiale465b572's hyper parameters: Current learning rate is 5.52791597567717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 811][Wall Clock 97.071793104s] Trained 128 records in 0.096634133 seconds. Throughput is 1324.5837 records/second. Loss is 2.2434895. Sequentiale465b572's hyper parameters: Current learning rate is 5.524861878453039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 43904/60000][Iteration 812][Wall Clock 97.169181435s] Trained 128 records in 0.097388331 seconds. Throughput is 1314.3258 records/second. Loss is 2.2450426. Sequentiale465b572's hyper parameters: Current learning rate is 5.521811154058532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:20 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 813][Wall Clock 97.264714374s] Trained 128 records in 0.095532939 seconds. Throughput is 1339.852 records/second. Loss is 2.236598. Sequentiale465b572's hyper parameters: Current learning rate is 5.518763796909492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44160/60000][Iteration 814][Wall Clock 97.359791453s] Trained 128 records in 0.095077079 seconds. Throughput is 1346.276 records/second. Loss is 2.2516391. Sequentiale465b572's hyper parameters: Current learning rate is 5.515719801434087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 815][Wall Clock 97.458031192s] Trained 128 records in 0.098239739 seconds. Throughput is 1302.935 records/second. Loss is 2.2480323. Sequentiale465b572's hyper parameters: Current learning rate is 5.512679162072767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44416/60000][Iteration 816][Wall Clock 97.553870202s] Trained 128 records in 0.09583901 seconds. Throughput is 1335.5731 records/second. Loss is 2.236131. Sequentiale465b572's hyper parameters: Current learning rate is 5.509641873278238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 817][Wall Clock 97.661327919s] Trained 128 records in 0.107457717 seconds. Throughput is 1191.1661 records/second. Loss is 2.2527435. Sequentiale465b572's hyper parameters: Current learning rate is 5.506607929515418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44672/60000][Iteration 818][Wall Clock 97.76624754s] Trained 128 records in 0.104919621 seconds. Throughput is 1219.9816 records/second. Loss is 2.23688. Sequentiale465b572's hyper parameters: Current learning rate is 5.50357732526142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 819][Wall Clock 97.863071097s] Trained 128 records in 0.096823557 seconds. Throughput is 1321.9923 records/second. Loss is 2.2536163. Sequentiale465b572's hyper parameters: Current learning rate is 5.5005500550055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 44928/60000][Iteration 820][Wall Clock 97.95555607s] Trained 128 records in 0.092484973 seconds. Throughput is 1384.0087 records/second. Loss is 2.2417681. Sequentiale465b572's hyper parameters: Current learning rate is 5.497526113249038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 821][Wall Clock 98.052227308s] Trained 128 records in 0.096671238 seconds. Throughput is 1324.0753 records/second. Loss is 2.2433617. Sequentiale465b572's hyper parameters: Current learning rate is 5.494505494505495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 45184/60000][Iteration 822][Wall Clock 98.145883525s] Trained 128 records in 0.093656217 seconds. Throughput is 1366.7004 records/second. Loss is 2.2378886. Sequentiale465b572's hyper parameters: Current learning rate is 5.491488193300384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 823][Wall Clock 98.246285196s] Trained 128 records in 0.100401671 seconds. Throughput is 1274.8792 records/second. Loss is 2.2464068. Sequentiale465b572's hyper parameters: Current learning rate is 5.488474204171241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:21 INFO  DistriOptimizer$:408 - [Epoch 2 45440/60000][Iteration 824][Wall Clock 98.341580132s] Trained 128 records in 0.095294936 seconds. Throughput is 1343.1984 records/second. Loss is 2.2420459. Sequentiale465b572's hyper parameters: Current learning rate is 5.485463521667581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 825][Wall Clock 98.451153279s] Trained 128 records in 0.109573147 seconds. Throughput is 1168.1694 records/second. Loss is 2.2674143. Sequentiale465b572's hyper parameters: Current learning rate is 5.482456140350877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 45696/60000][Iteration 826][Wall Clock 98.546725183s] Trained 128 records in 0.095571904 seconds. Throughput is 1339.3057 records/second. Loss is 2.231779. Sequentiale465b572's hyper parameters: Current learning rate is 5.47945205479452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 827][Wall Clock 98.645829234s] Trained 128 records in 0.099104051 seconds. Throughput is 1291.5718 records/second. Loss is 2.2445135. Sequentiale465b572's hyper parameters: Current learning rate is 5.47645125958379E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 45952/60000][Iteration 828][Wall Clock 98.742196294s] Trained 128 records in 0.09636706 seconds. Throughput is 1328.2546 records/second. Loss is 2.2460968. Sequentiale465b572's hyper parameters: Current learning rate is 5.473453749315818E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 829][Wall Clock 98.854902841s] Trained 128 records in 0.112706547 seconds. Throughput is 1135.6926 records/second. Loss is 2.2352855. Sequentiale465b572's hyper parameters: Current learning rate is 5.470459518599562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 46208/60000][Iteration 830][Wall Clock 98.95154135s] Trained 128 records in 0.096638509 seconds. Throughput is 1324.5238 records/second. Loss is 2.249927. Sequentiale465b572's hyper parameters: Current learning rate is 5.467468562055768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 831][Wall Clock 99.050622287s] Trained 128 records in 0.099080937 seconds. Throughput is 1291.8732 records/second. Loss is 2.250028. Sequentiale465b572's hyper parameters: Current learning rate is 5.46448087431694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 46464/60000][Iteration 832][Wall Clock 99.150382615s] Trained 128 records in 0.099760328 seconds. Throughput is 1283.0751 records/second. Loss is 2.2446249. Sequentiale465b572's hyper parameters: Current learning rate is 5.461496450027308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:22 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 833][Wall Clock 99.250695027s] Trained 128 records in 0.100312412 seconds. Throughput is 1276.0135 records/second. Loss is 2.2376564. Sequentiale465b572's hyper parameters: Current learning rate is 5.458515283842794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 46720/60000][Iteration 834][Wall Clock 99.348693602s] Trained 128 records in 0.097998575 seconds. Throughput is 1306.1415 records/second. Loss is 2.248195. Sequentiale465b572's hyper parameters: Current learning rate is 5.455537370430988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 835][Wall Clock 99.453646501s] Trained 128 records in 0.104952899 seconds. Throughput is 1219.5947 records/second. Loss is 2.2519302. Sequentiale465b572's hyper parameters: Current learning rate is 5.452562704471102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 46976/60000][Iteration 836][Wall Clock 99.553730465s] Trained 128 records in 0.100083964 seconds. Throughput is 1278.9261 records/second. Loss is 2.2572486. Sequentiale465b572's hyper parameters: Current learning rate is 5.449591280653951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 837][Wall Clock 99.676673549s] Trained 128 records in 0.122943084 seconds. Throughput is 1041.1322 records/second. Loss is 2.25288. Sequentiale465b572's hyper parameters: Current learning rate is 5.446623093681918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47232/60000][Iteration 838][Wall Clock 99.79369131s] Trained 128 records in 0.117017761 seconds. Throughput is 1093.8511 records/second. Loss is 2.240567. Sequentiale465b572's hyper parameters: Current learning rate is 5.443658138268917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 839][Wall Clock 99.886014274s] Trained 128 records in 0.092322964 seconds. Throughput is 1386.4374 records/second. Loss is 2.2400503. Sequentiale465b572's hyper parameters: Current learning rate is 5.44069640914037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47488/60000][Iteration 840][Wall Clock 99.976380143s] Trained 128 records in 0.090365869 seconds. Throughput is 1416.464 records/second. Loss is 2.230688. Sequentiale465b572's hyper parameters: Current learning rate is 5.437737901033171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 841][Wall Clock 100.090798019s] Trained 128 records in 0.114417876 seconds. Throughput is 1118.7063 records/second. Loss is 2.2427692. Sequentiale465b572's hyper parameters: Current learning rate is 5.434782608695652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47744/60000][Iteration 842][Wall Clock 100.219880747s] Trained 128 records in 0.129082728 seconds. Throughput is 991.6122 records/second. Loss is 2.2530904. Sequentiale465b572's hyper parameters: Current learning rate is 5.431830526887562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:23 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 843][Wall Clock 100.319061843s] Trained 128 records in 0.099181096 seconds. Throughput is 1290.5686 records/second. Loss is 2.2326114. Sequentiale465b572's hyper parameters: Current learning rate is 5.428881650380022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48000/60000][Iteration 844][Wall Clock 100.427466963s] Trained 128 records in 0.10840512 seconds. Throughput is 1180.756 records/second. Loss is 2.230409. Sequentiale465b572's hyper parameters: Current learning rate is 5.425935973955507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 845][Wall Clock 100.543195557s] Trained 128 records in 0.115728594 seconds. Throughput is 1106.0361 records/second. Loss is 2.2353103. Sequentiale465b572's hyper parameters: Current learning rate is 5.422993492407809E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48256/60000][Iteration 846][Wall Clock 100.652935315s] Trained 128 records in 0.109739758 seconds. Throughput is 1166.3959 records/second. Loss is 2.2404795. Sequentiale465b572's hyper parameters: Current learning rate is 5.420054200542005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 847][Wall Clock 100.75923295s] Trained 128 records in 0.106297635 seconds. Throughput is 1204.166 records/second. Loss is 2.2501175. Sequentiale465b572's hyper parameters: Current learning rate is 5.417118093174431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48512/60000][Iteration 848][Wall Clock 100.859367286s] Trained 128 records in 0.100134336 seconds. Throughput is 1278.2828 records/second. Loss is 2.2335973. Sequentiale465b572's hyper parameters: Current learning rate is 5.414185165132648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 849][Wall Clock 100.964065057s] Trained 128 records in 0.104697771 seconds. Throughput is 1222.5667 records/second. Loss is 2.2442007. Sequentiale465b572's hyper parameters: Current learning rate is 5.411255411255411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48768/60000][Iteration 850][Wall Clock 101.073790482s] Trained 128 records in 0.109725425 seconds. Throughput is 1166.5482 records/second. Loss is 2.2347496. Sequentiale465b572's hyper parameters: Current learning rate is 5.408328826392645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 851][Wall Clock 101.17268989s] Trained 128 records in 0.098899408 seconds. Throughput is 1294.2444 records/second. Loss is 2.2286625. Sequentiale465b572's hyper parameters: Current learning rate is 5.405405405405405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:24 INFO  DistriOptimizer$:408 - [Epoch 2 49024/60000][Iteration 852][Wall Clock 101.272767772s] Trained 128 records in 0.100077882 seconds. Throughput is 1279.0039 records/second. Loss is 2.2380533. Sequentiale465b572's hyper parameters: Current learning rate is 5.402485143165856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 853][Wall Clock 101.390448595s] Trained 128 records in 0.117680823 seconds. Throughput is 1087.6879 records/second. Loss is 2.2470982. Sequentiale465b572's hyper parameters: Current learning rate is 5.399568034557236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49280/60000][Iteration 854][Wall Clock 101.486306383s] Trained 128 records in 0.095857788 seconds. Throughput is 1335.3114 records/second. Loss is 2.2342696. Sequentiale465b572's hyper parameters: Current learning rate is 5.396654074473826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 855][Wall Clock 101.583875288s] Trained 128 records in 0.097568905 seconds. Throughput is 1311.8933 records/second. Loss is 2.2393243. Sequentiale465b572's hyper parameters: Current learning rate is 5.393743257820927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49536/60000][Iteration 856][Wall Clock 101.684695942s] Trained 128 records in 0.100820654 seconds. Throughput is 1269.5812 records/second. Loss is 2.2507067. Sequentiale465b572's hyper parameters: Current learning rate is 5.390835579514825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 857][Wall Clock 101.78553688s] Trained 128 records in 0.100840938 seconds. Throughput is 1269.3257 records/second. Loss is 2.2402215. Sequentiale465b572's hyper parameters: Current learning rate is 5.38793103448276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49792/60000][Iteration 858][Wall Clock 101.884675519s] Trained 128 records in 0.099138639 seconds. Throughput is 1291.1212 records/second. Loss is 2.2539768. Sequentiale465b572's hyper parameters: Current learning rate is 5.385029617662897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 859][Wall Clock 101.981284234s] Trained 128 records in 0.096608715 seconds. Throughput is 1324.9323 records/second. Loss is 2.2331502. Sequentiale465b572's hyper parameters: Current learning rate is 5.382131324004305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 50048/60000][Iteration 860][Wall Clock 102.076707404s] Trained 128 records in 0.09542317 seconds. Throughput is 1341.3933 records/second. Loss is 2.2459679. Sequentiale465b572's hyper parameters: Current learning rate is 5.379236148466918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 861][Wall Clock 102.190891253s] Trained 128 records in 0.114183849 seconds. Throughput is 1120.9991 records/second. Loss is 2.2403858. Sequentiale465b572's hyper parameters: Current learning rate is 5.376344086021505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:25 INFO  DistriOptimizer$:408 - [Epoch 2 50304/60000][Iteration 862][Wall Clock 102.285678274s] Trained 128 records in 0.094787021 seconds. Throughput is 1350.3958 records/second. Loss is 2.241861. Sequentiale465b572's hyper parameters: Current learning rate is 5.373455131649651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 863][Wall Clock 102.387887704s] Trained 128 records in 0.10220943 seconds. Throughput is 1252.3307 records/second. Loss is 2.2294762. Sequentiale465b572's hyper parameters: Current learning rate is 5.370569280343716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 50560/60000][Iteration 864][Wall Clock 102.484199183s] Trained 128 records in 0.096311479 seconds. Throughput is 1329.0212 records/second. Loss is 2.236999. Sequentiale465b572's hyper parameters: Current learning rate is 5.367686527106817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 865][Wall Clock 102.578044187s] Trained 128 records in 0.093845004 seconds. Throughput is 1363.9512 records/second. Loss is 2.2468305. Sequentiale465b572's hyper parameters: Current learning rate is 5.36480686695279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 50816/60000][Iteration 866][Wall Clock 102.678698437s] Trained 128 records in 0.10065425 seconds. Throughput is 1271.68 records/second. Loss is 2.233254. Sequentiale465b572's hyper parameters: Current learning rate is 5.361930294906167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 867][Wall Clock 102.779719268s] Trained 128 records in 0.101020831 seconds. Throughput is 1267.0654 records/second. Loss is 2.2352319. Sequentiale465b572's hyper parameters: Current learning rate is 5.359056806002144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 51072/60000][Iteration 868][Wall Clock 102.896398018s] Trained 128 records in 0.11667875 seconds. Throughput is 1097.0292 records/second. Loss is 2.23837. Sequentiale465b572's hyper parameters: Current learning rate is 5.356186395286556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 869][Wall Clock 102.999632108s] Trained 128 records in 0.10323409 seconds. Throughput is 1239.9005 records/second. Loss is 2.2342968. Sequentiale465b572's hyper parameters: Current learning rate is 5.353319057815846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 51328/60000][Iteration 870][Wall Clock 103.095746894s] Trained 128 records in 0.096114786 seconds. Throughput is 1331.741 records/second. Loss is 2.2463598. Sequentiale465b572's hyper parameters: Current learning rate is 5.350454788657035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:26 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 871][Wall Clock 103.207972361s] Trained 128 records in 0.112225467 seconds. Throughput is 1140.5612 records/second. Loss is 2.2409043. Sequentiale465b572's hyper parameters: Current learning rate is 5.347593582887701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 51584/60000][Iteration 872][Wall Clock 103.322502032s] Trained 128 records in 0.114529671 seconds. Throughput is 1117.6144 records/second. Loss is 2.2360625. Sequentiale465b572's hyper parameters: Current learning rate is 5.344735435595939E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 873][Wall Clock 103.424434025s] Trained 128 records in 0.101931993 seconds. Throughput is 1255.7391 records/second. Loss is 2.2513025. Sequentiale465b572's hyper parameters: Current learning rate is 5.341880341880342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 51840/60000][Iteration 874][Wall Clock 103.519261661s] Trained 128 records in 0.094827636 seconds. Throughput is 1349.8175 records/second. Loss is 2.2353427. Sequentiale465b572's hyper parameters: Current learning rate is 5.339028296849973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 875][Wall Clock 103.617157922s] Trained 128 records in 0.097896261 seconds. Throughput is 1307.5065 records/second. Loss is 2.2421288. Sequentiale465b572's hyper parameters: Current learning rate is 5.336179295624333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 52096/60000][Iteration 876][Wall Clock 103.773908455s] Trained 128 records in 0.156750533 seconds. Throughput is 816.58417 records/second. Loss is 2.2326016. Sequentiale465b572's hyper parameters: Current learning rate is 5.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 877][Wall Clock 103.883612391s] Trained 128 records in 0.109703936 seconds. Throughput is 1166.7767 records/second. Loss is 2.2490513. Sequentiale465b572's hyper parameters: Current learning rate is 5.330490405117271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 52352/60000][Iteration 878][Wall Clock 103.989040034s] Trained 128 records in 0.105427643 seconds. Throughput is 1214.1028 records/second. Loss is 2.248965. Sequentiale465b572's hyper parameters: Current learning rate is 5.327650506126798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 879][Wall Clock 104.091026645s] Trained 128 records in 0.101986611 seconds. Throughput is 1255.0668 records/second. Loss is 2.2438498. Sequentiale465b572's hyper parameters: Current learning rate is 5.324813631522896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 52608/60000][Iteration 880][Wall Clock 104.200040462s] Trained 128 records in 0.109013817 seconds. Throughput is 1174.1631 records/second. Loss is 2.2346117. Sequentiale465b572's hyper parameters: Current learning rate is 5.321979776476849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:27 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 881][Wall Clock 104.313265484s] Trained 128 records in 0.113225022 seconds. Throughput is 1130.4922 records/second. Loss is 2.2471704. Sequentiale465b572's hyper parameters: Current learning rate is 5.319148936170213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 52864/60000][Iteration 882][Wall Clock 104.417358539s] Trained 128 records in 0.104093055 seconds. Throughput is 1229.669 records/second. Loss is 2.229443. Sequentiale465b572's hyper parameters: Current learning rate is 5.31632110579479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 883][Wall Clock 104.517190177s] Trained 128 records in 0.099831638 seconds. Throughput is 1282.1587 records/second. Loss is 2.2355301. Sequentiale465b572's hyper parameters: Current learning rate is 5.313496280552603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 53120/60000][Iteration 884][Wall Clock 104.623706472s] Trained 128 records in 0.106516295 seconds. Throughput is 1201.6941 records/second. Loss is 2.2501502. Sequentiale465b572's hyper parameters: Current learning rate is 5.310674455655868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 885][Wall Clock 104.744745962s] Trained 128 records in 0.12103949 seconds. Throughput is 1057.5061 records/second. Loss is 2.2272031. Sequentiale465b572's hyper parameters: Current learning rate is 5.307855626326964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 53376/60000][Iteration 886][Wall Clock 104.884927288s] Trained 128 records in 0.140181326 seconds. Throughput is 913.103 records/second. Loss is 2.2358358. Sequentiale465b572's hyper parameters: Current learning rate is 5.305039787798409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 887][Wall Clock 105.011262103s] Trained 128 records in 0.126334815 seconds. Throughput is 1013.1807 records/second. Loss is 2.2292924. Sequentiale465b572's hyper parameters: Current learning rate is 5.302226935312831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 53632/60000][Iteration 888][Wall Clock 105.139190216s] Trained 128 records in 0.127928113 seconds. Throughput is 1000.56195 records/second. Loss is 2.2401288. Sequentiale465b572's hyper parameters: Current learning rate is 5.299417064122947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:28 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 889][Wall Clock 105.255711284s] Trained 128 records in 0.116521068 seconds. Throughput is 1098.5138 records/second. Loss is 2.235068. Sequentiale465b572's hyper parameters: Current learning rate is 5.296610169491525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 53888/60000][Iteration 890][Wall Clock 105.3807771s] Trained 128 records in 0.125065816 seconds. Throughput is 1023.4611 records/second. Loss is 2.24527. Sequentiale465b572's hyper parameters: Current learning rate is 5.293806246691371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 891][Wall Clock 105.493477336s] Trained 128 records in 0.112700236 seconds. Throughput is 1135.7562 records/second. Loss is 2.2320468. Sequentiale465b572's hyper parameters: Current learning rate is 5.29100529100529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54144/60000][Iteration 892][Wall Clock 105.589497713s] Trained 128 records in 0.096020377 seconds. Throughput is 1333.0504 records/second. Loss is 2.2445848. Sequentiale465b572's hyper parameters: Current learning rate is 5.288207297726071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 893][Wall Clock 105.763786823s] Trained 128 records in 0.17428911 seconds. Throughput is 734.4119 records/second. Loss is 2.236461. Sequentiale465b572's hyper parameters: Current learning rate is 5.285412262156448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54400/60000][Iteration 894][Wall Clock 105.911865822s] Trained 128 records in 0.148078999 seconds. Throughput is 864.4035 records/second. Loss is 2.2413888. Sequentiale465b572's hyper parameters: Current learning rate is 5.282620179609086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 895][Wall Clock 106.014911364s] Trained 128 records in 0.103045542 seconds. Throughput is 1242.1692 records/second. Loss is 2.2404087. Sequentiale465b572's hyper parameters: Current learning rate is 5.279831045406547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54656/60000][Iteration 896][Wall Clock 106.110834222s] Trained 128 records in 0.095922858 seconds. Throughput is 1334.4056 records/second. Loss is 2.2396333. Sequentiale465b572's hyper parameters: Current learning rate is 5.277044854881266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:29 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 897][Wall Clock 106.207428242s] Trained 128 records in 0.09659402 seconds. Throughput is 1325.1338 records/second. Loss is 2.239139. Sequentiale465b572's hyper parameters: Current learning rate is 5.274261603375528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 54912/60000][Iteration 898][Wall Clock 106.305221719s] Trained 128 records in 0.097793477 seconds. Throughput is 1308.8807 records/second. Loss is 2.2349708. Sequentiale465b572's hyper parameters: Current learning rate is 5.271481286241434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 899][Wall Clock 106.408828426s] Trained 128 records in 0.103606707 seconds. Throughput is 1235.4413 records/second. Loss is 2.2317457. Sequentiale465b572's hyper parameters: Current learning rate is 5.268703898840885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55168/60000][Iteration 900][Wall Clock 106.50461888s] Trained 128 records in 0.095790454 seconds. Throughput is 1336.2501 records/second. Loss is 2.240499. Sequentiale465b572's hyper parameters: Current learning rate is 5.26592943654555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 901][Wall Clock 106.619530339s] Trained 128 records in 0.114911459 seconds. Throughput is 1113.9011 records/second. Loss is 2.2351842. Sequentiale465b572's hyper parameters: Current learning rate is 5.263157894736842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55424/60000][Iteration 902][Wall Clock 106.71360009s] Trained 128 records in 0.094069751 seconds. Throughput is 1360.6925 records/second. Loss is 2.2463431. Sequentiale465b572's hyper parameters: Current learning rate is 5.260389268805891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 903][Wall Clock 106.805497468s] Trained 128 records in 0.091897378 seconds. Throughput is 1392.858 records/second. Loss is 2.231282. Sequentiale465b572's hyper parameters: Current learning rate is 5.257623554153522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55680/60000][Iteration 904][Wall Clock 106.901595289s] Trained 128 records in 0.096097821 seconds. Throughput is 1331.9761 records/second. Loss is 2.233654. Sequentiale465b572's hyper parameters: Current learning rate is 5.254860746190226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 905][Wall Clock 106.996506105s] Trained 128 records in 0.094910816 seconds. Throughput is 1348.6345 records/second. Loss is 2.2336974. Sequentiale465b572's hyper parameters: Current learning rate is 5.252100840336135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 55936/60000][Iteration 906][Wall Clock 107.085098255s] Trained 128 records in 0.08859215 seconds. Throughput is 1444.8232 records/second. Loss is 2.2291524. Sequentiale465b572's hyper parameters: Current learning rate is 5.249343832020997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 907][Wall Clock 107.187979447s] Trained 128 records in 0.102881192 seconds. Throughput is 1244.1536 records/second. Loss is 2.2263224. Sequentiale465b572's hyper parameters: Current learning rate is 5.246589716684155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:30 INFO  DistriOptimizer$:408 - [Epoch 2 56192/60000][Iteration 908][Wall Clock 107.278920588s] Trained 128 records in 0.090941141 seconds. Throughput is 1407.5038 records/second. Loss is 2.245913. Sequentiale465b572's hyper parameters: Current learning rate is 5.243838489774515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 909][Wall Clock 107.374974002s] Trained 128 records in 0.096053414 seconds. Throughput is 1332.5919 records/second. Loss is 2.2425575. Sequentiale465b572's hyper parameters: Current learning rate is 5.241090146750524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 56448/60000][Iteration 910][Wall Clock 107.467789638s] Trained 128 records in 0.092815636 seconds. Throughput is 1379.078 records/second. Loss is 2.2259223. Sequentiale465b572's hyper parameters: Current learning rate is 5.238344683080147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 911][Wall Clock 107.569260455s] Trained 128 records in 0.101470817 seconds. Throughput is 1261.4464 records/second. Loss is 2.2390065. Sequentiale465b572's hyper parameters: Current learning rate is 5.235602094240837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 56704/60000][Iteration 912][Wall Clock 107.685692521s] Trained 128 records in 0.116432066 seconds. Throughput is 1099.3535 records/second. Loss is 2.23675. Sequentiale465b572's hyper parameters: Current learning rate is 5.232862375719519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 913][Wall Clock 107.797193223s] Trained 128 records in 0.111500702 seconds. Throughput is 1147.9749 records/second. Loss is 2.242083. Sequentiale465b572's hyper parameters: Current learning rate is 5.230125523012553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 56960/60000][Iteration 914][Wall Clock 107.899220394s] Trained 128 records in 0.102027171 seconds. Throughput is 1254.5677 records/second. Loss is 2.2289085. Sequentiale465b572's hyper parameters: Current learning rate is 5.227391531625719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 915][Wall Clock 107.998044256s] Trained 128 records in 0.098823862 seconds. Throughput is 1295.2338 records/second. Loss is 2.2247458. Sequentiale465b572's hyper parameters: Current learning rate is 5.22466039707419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 57216/60000][Iteration 916][Wall Clock 108.094073769s] Trained 128 records in 0.096029513 seconds. Throughput is 1332.9236 records/second. Loss is 2.2386076. Sequentiale465b572's hyper parameters: Current learning rate is 5.221932114882506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 917][Wall Clock 108.189353201s] Trained 128 records in 0.095279432 seconds. Throughput is 1343.4169 records/second. Loss is 2.2376053. Sequentiale465b572's hyper parameters: Current learning rate is 5.219206680584552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:31 INFO  DistriOptimizer$:408 - [Epoch 2 57472/60000][Iteration 918][Wall Clock 108.287475824s] Trained 128 records in 0.098122623 seconds. Throughput is 1304.4901 records/second. Loss is 2.240626. Sequentiale465b572's hyper parameters: Current learning rate is 5.216484089723526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 919][Wall Clock 108.401732822s] Trained 128 records in 0.114256998 seconds. Throughput is 1120.2815 records/second. Loss is 2.2353888. Sequentiale465b572's hyper parameters: Current learning rate is 5.213764337851929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 57728/60000][Iteration 920][Wall Clock 108.509509477s] Trained 128 records in 0.107776655 seconds. Throughput is 1187.6412 records/second. Loss is 2.2415233. Sequentiale465b572's hyper parameters: Current learning rate is 5.211047420531526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 921][Wall Clock 108.625036672s] Trained 128 records in 0.115527195 seconds. Throughput is 1107.9642 records/second. Loss is 2.2394025. Sequentiale465b572's hyper parameters: Current learning rate is 5.208333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 57984/60000][Iteration 922][Wall Clock 108.727094198s] Trained 128 records in 0.102057526 seconds. Throughput is 1254.1947 records/second. Loss is 2.2253606. Sequentiale465b572's hyper parameters: Current learning rate is 5.205622071837585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 923][Wall Clock 108.825335656s] Trained 128 records in 0.098241458 seconds. Throughput is 1302.9122 records/second. Loss is 2.2395446. Sequentiale465b572's hyper parameters: Current learning rate is 5.202913631633714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 58240/60000][Iteration 924][Wall Clock 108.92313629s] Trained 128 records in 0.097800634 seconds. Throughput is 1308.7849 records/second. Loss is 2.2259448. Sequentiale465b572's hyper parameters: Current learning rate is 5.200208008320332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 925][Wall Clock 109.01899331s] Trained 128 records in 0.09585702 seconds. Throughput is 1335.3221 records/second. Loss is 2.2376583. Sequentiale465b572's hyper parameters: Current learning rate is 5.197505197505198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 58496/60000][Iteration 926][Wall Clock 109.121483806s] Trained 128 records in 0.102490496 seconds. Throughput is 1248.8962 records/second. Loss is 2.2336388. Sequentiale465b572's hyper parameters: Current learning rate is 5.194805194805195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:32 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 927][Wall Clock 109.246168451s] Trained 128 records in 0.124684645 seconds. Throughput is 1026.59 records/second. Loss is 2.2335706. Sequentiale465b572's hyper parameters: Current learning rate is 5.192107995846313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 58752/60000][Iteration 928][Wall Clock 109.356639417s] Trained 128 records in 0.110470966 seconds. Throughput is 1158.6755 records/second. Loss is 2.2495973. Sequentiale465b572's hyper parameters: Current learning rate is 5.189413596263622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 929][Wall Clock 109.458952395s] Trained 128 records in 0.102312978 seconds. Throughput is 1251.0632 records/second. Loss is 2.2346647. Sequentiale465b572's hyper parameters: Current learning rate is 5.186721991701245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59008/60000][Iteration 930][Wall Clock 109.554986902s] Trained 128 records in 0.096034507 seconds. Throughput is 1332.8542 records/second. Loss is 2.232795. Sequentiale465b572's hyper parameters: Current learning rate is 5.184033177812338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 931][Wall Clock 109.654843765s] Trained 128 records in 0.099856863 seconds. Throughput is 1281.8348 records/second. Loss is 2.2383263. Sequentiale465b572's hyper parameters: Current learning rate is 5.181347150259067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59264/60000][Iteration 932][Wall Clock 109.748935315s] Trained 128 records in 0.09409155 seconds. Throughput is 1360.3772 records/second. Loss is 2.2357795. Sequentiale465b572's hyper parameters: Current learning rate is 5.178663904712584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 933][Wall Clock 109.843725106s] Trained 128 records in 0.094789791 seconds. Throughput is 1350.3564 records/second. Loss is 2.238298. Sequentiale465b572's hyper parameters: Current learning rate is 5.175983436853002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59520/60000][Iteration 934][Wall Clock 109.941366552s] Trained 128 records in 0.097641446 seconds. Throughput is 1310.9187 records/second. Loss is 2.2428274. Sequentiale465b572's hyper parameters: Current learning rate is 5.173305742369374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 935][Wall Clock 110.04245964s] Trained 128 records in 0.101093088 seconds. Throughput is 1266.1597 records/second. Loss is 2.23507. Sequentiale465b572's hyper parameters: Current learning rate is 5.170630816959668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59776/60000][Iteration 936][Wall Clock 110.140991754s] Trained 128 records in 0.098532114 seconds. Throughput is 1299.0688 records/second. Loss is 2.2217689. Sequentiale465b572's hyper parameters: Current learning rate is 5.167958656330749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:33 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 937][Wall Clock 110.238614447s] Trained 128 records in 0.097622693 seconds. Throughput is 1311.1705 records/second. Loss is 2.24461. Sequentiale465b572's hyper parameters: Current learning rate is 5.165289256198347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:34 INFO  DistriOptimizer$:408 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 110.330089499s] Trained 128 records in 0.091475052 seconds. Throughput is 1399.2886 records/second. Loss is 2.2289245. Sequentiale465b572's hyper parameters: Current learning rate is 5.162622612287042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:34 INFO  DistriOptimizer$:452 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 110.330089499s] Epoch finished. Wall clock time is 111939.300625 ms
2019-10-15 20:06:34 INFO  DistriOptimizer$:111 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 110.330089499s] Validate model...
2019-10-15 20:06:34 INFO  DistriOptimizer$:178 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 110.330089499s] validate model throughput is 11038.693 records/second
2019-10-15 20:06:34 INFO  DistriOptimizer$:181 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 110.330089499s] Top1Accuracy is Accuracy(correct: 2431, count: 10000, accuracy: 0.2431)
2019-10-15 20:06:35 INFO  DistriOptimizer$:221 - [Wall Clock 111.939300625s] Save model to /tmp/lenet5/20191015_200441
2019-10-15 20:06:35 INFO  DistriOptimizer$:226 - [Wall Clock 111.939300625s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@c83982c to /tmp/lenet5/20191015_200441
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 128/60000][Iteration 939][Wall Clock 112.078289275s] Trained 128 records in 0.13898865 seconds. Throughput is 920.93854 records/second. Loss is 2.2331772. Sequentiale465b572's hyper parameters: Current learning rate is 5.159958720330237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 940][Wall Clock 112.172924076s] Trained 128 records in 0.094634801 seconds. Throughput is 1352.568 records/second. Loss is 2.2385035. Sequentiale465b572's hyper parameters: Current learning rate is 5.157297576070139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 384/60000][Iteration 941][Wall Clock 112.267772289s] Trained 128 records in 0.094848213 seconds. Throughput is 1349.5247 records/second. Loss is 2.2206998. Sequentiale465b572's hyper parameters: Current learning rate is 5.154639175257732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 942][Wall Clock 112.359849167s] Trained 128 records in 0.092076878 seconds. Throughput is 1390.1427 records/second. Loss is 2.2409904. Sequentiale465b572's hyper parameters: Current learning rate is 5.151983513652757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 640/60000][Iteration 943][Wall Clock 112.478991135s] Trained 128 records in 0.119141968 seconds. Throughput is 1074.3485 records/second. Loss is 2.2361774. Sequentiale465b572's hyper parameters: Current learning rate is 5.149330587023687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 944][Wall Clock 112.592418215s] Trained 128 records in 0.11342708 seconds. Throughput is 1128.4783 records/second. Loss is 2.2552278. Sequentiale465b572's hyper parameters: Current learning rate is 5.14668039114771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 896/60000][Iteration 945][Wall Clock 112.699775512s] Trained 128 records in 0.107357297 seconds. Throughput is 1192.2804 records/second. Loss is 2.2264326. Sequentiale465b572's hyper parameters: Current learning rate is 5.1440329218107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:35 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 946][Wall Clock 112.800049751s] Trained 128 records in 0.100274239 seconds. Throughput is 1276.4993 records/second. Loss is 2.235264. Sequentiale465b572's hyper parameters: Current learning rate is 5.141388174807198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1152/60000][Iteration 947][Wall Clock 112.903207299s] Trained 128 records in 0.103157548 seconds. Throughput is 1240.8204 records/second. Loss is 2.221588. Sequentiale465b572's hyper parameters: Current learning rate is 5.138746145940391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 948][Wall Clock 113.002938001s] Trained 128 records in 0.099730702 seconds. Throughput is 1283.4563 records/second. Loss is 2.2274559. Sequentiale465b572's hyper parameters: Current learning rate is 5.136106831022085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1408/60000][Iteration 949][Wall Clock 113.103275577s] Trained 128 records in 0.100337576 seconds. Throughput is 1275.6936 records/second. Loss is 2.2300494. Sequentiale465b572's hyper parameters: Current learning rate is 5.13347022587269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 950][Wall Clock 113.200594923s] Trained 128 records in 0.097319346 seconds. Throughput is 1315.2574 records/second. Loss is 2.2262142. Sequentiale465b572's hyper parameters: Current learning rate is 5.13083632632119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1664/60000][Iteration 951][Wall Clock 113.305248011s] Trained 128 records in 0.104653088 seconds. Throughput is 1223.0886 records/second. Loss is 2.2319865. Sequentiale465b572's hyper parameters: Current learning rate is 5.128205128205128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 952][Wall Clock 113.394424719s] Trained 128 records in 0.089176708 seconds. Throughput is 1435.3524 records/second. Loss is 2.2395906. Sequentiale465b572's hyper parameters: Current learning rate is 5.125576627370579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 1920/60000][Iteration 953][Wall Clock 113.484646138s] Trained 128 records in 0.090221419 seconds. Throughput is 1418.7318 records/second. Loss is 2.236243. Sequentiale465b572's hyper parameters: Current learning rate is 5.122950819672131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 954][Wall Clock 113.577247967s] Trained 128 records in 0.092601829 seconds. Throughput is 1382.2621 records/second. Loss is 2.2198794. Sequentiale465b572's hyper parameters: Current learning rate is 5.120327700972862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 2176/60000][Iteration 955][Wall Clock 113.671195642s] Trained 128 records in 0.093947675 seconds. Throughput is 1362.4606 records/second. Loss is 2.2310734. Sequentiale465b572's hyper parameters: Current learning rate is 5.117707267144319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 956][Wall Clock 113.764785366s] Trained 128 records in 0.093589724 seconds. Throughput is 1367.6715 records/second. Loss is 2.2334285. Sequentiale465b572's hyper parameters: Current learning rate is 5.115089514066496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:36 INFO  DistriOptimizer$:408 - [Epoch 3 2432/60000][Iteration 957][Wall Clock 113.862768536s] Trained 128 records in 0.09798317 seconds. Throughput is 1306.3468 records/second. Loss is 2.2461193. Sequentiale465b572's hyper parameters: Current learning rate is 5.112474437627812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 958][Wall Clock 113.955251485s] Trained 128 records in 0.092482949 seconds. Throughput is 1384.039 records/second. Loss is 2.2351723. Sequentiale465b572's hyper parameters: Current learning rate is 5.109862033725089E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 2688/60000][Iteration 959][Wall Clock 114.0479863s] Trained 128 records in 0.092734815 seconds. Throughput is 1380.2799 records/second. Loss is 2.2316368. Sequentiale465b572's hyper parameters: Current learning rate is 5.107252298263534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 960][Wall Clock 114.140866316s] Trained 128 records in 0.092880016 seconds. Throughput is 1378.1221 records/second. Loss is 2.2407947. Sequentiale465b572's hyper parameters: Current learning rate is 5.104645227156713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 2944/60000][Iteration 961][Wall Clock 114.236165429s] Trained 128 records in 0.095299113 seconds. Throughput is 1343.1395 records/second. Loss is 2.232111. Sequentiale465b572's hyper parameters: Current learning rate is 5.102040816326531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 962][Wall Clock 114.33265922s] Trained 128 records in 0.096493791 seconds. Throughput is 1326.5103 records/second. Loss is 2.2308075. Sequentiale465b572's hyper parameters: Current learning rate is 5.099439061703213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 3200/60000][Iteration 963][Wall Clock 114.429095496s] Trained 128 records in 0.096436276 seconds. Throughput is 1327.3014 records/second. Loss is 2.2358022. Sequentiale465b572's hyper parameters: Current learning rate is 5.096839959225281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 964][Wall Clock 114.53414402s] Trained 128 records in 0.105048524 seconds. Throughput is 1218.4845 records/second. Loss is 2.2429984. Sequentiale465b572's hyper parameters: Current learning rate is 5.094243504839531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 3456/60000][Iteration 965][Wall Clock 114.628325849s] Trained 128 records in 0.094181829 seconds. Throughput is 1359.0732 records/second. Loss is 2.233711. Sequentiale465b572's hyper parameters: Current learning rate is 5.091649694501019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 966][Wall Clock 114.721086492s] Trained 128 records in 0.092760643 seconds. Throughput is 1379.8955 records/second. Loss is 2.2290492. Sequentiale465b572's hyper parameters: Current learning rate is 5.089058524173028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:37 INFO  DistriOptimizer$:408 - [Epoch 3 3712/60000][Iteration 967][Wall Clock 114.821021431s] Trained 128 records in 0.099934939 seconds. Throughput is 1280.8334 records/second. Loss is 2.2319202. Sequentiale465b572's hyper parameters: Current learning rate is 5.08646998982706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 968][Wall Clock 114.909195578s] Trained 128 records in 0.088174147 seconds. Throughput is 1451.6726 records/second. Loss is 2.2426147. Sequentiale465b572's hyper parameters: Current learning rate is 5.083884087442806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 3968/60000][Iteration 969][Wall Clock 115.014597391s] Trained 128 records in 0.105401813 seconds. Throughput is 1214.4004 records/second. Loss is 2.2324033. Sequentiale465b572's hyper parameters: Current learning rate is 5.081300813008131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 970][Wall Clock 115.109797996s] Trained 128 records in 0.095200605 seconds. Throughput is 1344.5293 records/second. Loss is 2.2502837. Sequentiale465b572's hyper parameters: Current learning rate is 5.078720162519046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4224/60000][Iteration 971][Wall Clock 115.212066928s] Trained 128 records in 0.102268932 seconds. Throughput is 1251.6019 records/second. Loss is 2.2274115. Sequentiale465b572's hyper parameters: Current learning rate is 5.076142131979696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 972][Wall Clock 115.312245131s] Trained 128 records in 0.100178203 seconds. Throughput is 1277.723 records/second. Loss is 2.2367532. Sequentiale465b572's hyper parameters: Current learning rate is 5.073566717402334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4480/60000][Iteration 973][Wall Clock 115.407707995s] Trained 128 records in 0.095462864 seconds. Throughput is 1340.8354 records/second. Loss is 2.2272577. Sequentiale465b572's hyper parameters: Current learning rate is 5.070993914807302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 974][Wall Clock 115.502914589s] Trained 128 records in 0.095206594 seconds. Throughput is 1344.4447 records/second. Loss is 2.2253904. Sequentiale465b572's hyper parameters: Current learning rate is 5.068423720223011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4736/60000][Iteration 975][Wall Clock 115.598196819s] Trained 128 records in 0.09528223 seconds. Throughput is 1343.3776 records/second. Loss is 2.2219033. Sequentiale465b572's hyper parameters: Current learning rate is 5.065856129685917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 976][Wall Clock 115.691175321s] Trained 128 records in 0.092978502 seconds. Throughput is 1376.6624 records/second. Loss is 2.225835. Sequentiale465b572's hyper parameters: Current learning rate is 5.063291139240507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:38 INFO  DistriOptimizer$:408 - [Epoch 3 4992/60000][Iteration 977][Wall Clock 115.792080223s] Trained 128 records in 0.100904902 seconds. Throughput is 1268.5211 records/second. Loss is 2.2402167. Sequentiale465b572's hyper parameters: Current learning rate is 5.060728744939271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 978][Wall Clock 115.891068776s] Trained 128 records in 0.098988553 seconds. Throughput is 1293.0787 records/second. Loss is 2.2256522. Sequentiale465b572's hyper parameters: Current learning rate is 5.058168942842691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5248/60000][Iteration 979][Wall Clock 115.986541009s] Trained 128 records in 0.095472233 seconds. Throughput is 1340.704 records/second. Loss is 2.2374885. Sequentiale465b572's hyper parameters: Current learning rate is 5.055611729019212E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 980][Wall Clock 116.082663713s] Trained 128 records in 0.096122704 seconds. Throughput is 1331.6312 records/second. Loss is 2.2341194. Sequentiale465b572's hyper parameters: Current learning rate is 5.053057099545225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5504/60000][Iteration 981][Wall Clock 116.176544066s] Trained 128 records in 0.093880353 seconds. Throughput is 1363.4375 records/second. Loss is 2.2270856. Sequentiale465b572's hyper parameters: Current learning rate is 5.05050505050505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 982][Wall Clock 116.268834542s] Trained 128 records in 0.092290476 seconds. Throughput is 1386.9253 records/second. Loss is 2.2263129. Sequentiale465b572's hyper parameters: Current learning rate is 5.047955577990914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5760/60000][Iteration 983][Wall Clock 116.366482735s] Trained 128 records in 0.097648193 seconds. Throughput is 1310.8281 records/second. Loss is 2.2373378. Sequentiale465b572's hyper parameters: Current learning rate is 5.045408678102926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 984][Wall Clock 116.463800827s] Trained 128 records in 0.097318092 seconds. Throughput is 1315.2744 records/second. Loss is 2.2405646. Sequentiale465b572's hyper parameters: Current learning rate is 5.042864346949066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 6016/60000][Iteration 985][Wall Clock 116.558743734s] Trained 128 records in 0.094942907 seconds. Throughput is 1348.1787 records/second. Loss is 2.2214544. Sequentiale465b572's hyper parameters: Current learning rate is 5.040322580645161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 986][Wall Clock 116.654014823s] Trained 128 records in 0.095271089 seconds. Throughput is 1343.5345 records/second. Loss is 2.2271264. Sequentiale465b572's hyper parameters: Current learning rate is 5.037783375314862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 6272/60000][Iteration 987][Wall Clock 116.748708419s] Trained 128 records in 0.094693596 seconds. Throughput is 1351.7281 records/second. Loss is 2.2395551. Sequentiale465b572's hyper parameters: Current learning rate is 5.035246727089627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:39 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 988][Wall Clock 116.844618332s] Trained 128 records in 0.095909913 seconds. Throughput is 1334.5857 records/second. Loss is 2.2193263. Sequentiale465b572's hyper parameters: Current learning rate is 5.032712632108706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 6528/60000][Iteration 989][Wall Clock 116.940383944s] Trained 128 records in 0.095765612 seconds. Throughput is 1336.5967 records/second. Loss is 2.2374995. Sequentiale465b572's hyper parameters: Current learning rate is 5.030181086519115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 990][Wall Clock 117.035302069s] Trained 128 records in 0.094918125 seconds. Throughput is 1348.5306 records/second. Loss is 2.2306361. Sequentiale465b572's hyper parameters: Current learning rate is 5.027652086475616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 6784/60000][Iteration 991][Wall Clock 117.1283728s] Trained 128 records in 0.093070731 seconds. Throughput is 1375.2981 records/second. Loss is 2.2167234. Sequentiale465b572's hyper parameters: Current learning rate is 5.025125628140704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 992][Wall Clock 117.222777307s] Trained 128 records in 0.094404507 seconds. Throughput is 1355.8676 records/second. Loss is 2.2188468. Sequentiale465b572's hyper parameters: Current learning rate is 5.02260170768458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 7040/60000][Iteration 993][Wall Clock 117.319408922s] Trained 128 records in 0.096631615 seconds. Throughput is 1324.6182 records/second. Loss is 2.2381818. Sequentiale465b572's hyper parameters: Current learning rate is 5.020080321285141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 994][Wall Clock 117.427401526s] Trained 128 records in 0.107992604 seconds. Throughput is 1185.2664 records/second. Loss is 2.2227256. Sequentiale465b572's hyper parameters: Current learning rate is 5.017561465127949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 7296/60000][Iteration 995][Wall Clock 117.525912173s] Trained 128 records in 0.098510647 seconds. Throughput is 1299.3519 records/second. Loss is 2.232331. Sequentiale465b572's hyper parameters: Current learning rate is 5.015045135406219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 996][Wall Clock 117.633064092s] Trained 128 records in 0.107151919 seconds. Throughput is 1194.5657 records/second. Loss is 2.220084. Sequentiale465b572's hyper parameters: Current learning rate is 5.012531328320802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 7552/60000][Iteration 997][Wall Clock 117.729478844s] Trained 128 records in 0.096414752 seconds. Throughput is 1327.5977 records/second. Loss is 2.2300308. Sequentiale465b572's hyper parameters: Current learning rate is 5.01002004008016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:40 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 998][Wall Clock 117.830377275s] Trained 128 records in 0.100898431 seconds. Throughput is 1268.6025 records/second. Loss is 2.2263453. Sequentiale465b572's hyper parameters: Current learning rate is 5.007511266900351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 7808/60000][Iteration 999][Wall Clock 117.928640669s] Trained 128 records in 0.098263394 seconds. Throughput is 1302.6215 records/second. Loss is 2.2171328. Sequentiale465b572's hyper parameters: Current learning rate is 5.005005005005005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 1000][Wall Clock 118.030743186s] Trained 128 records in 0.102102517 seconds. Throughput is 1253.642 records/second. Loss is 2.2435837. Sequentiale465b572's hyper parameters: Current learning rate is 5.002501250625312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8064/60000][Iteration 1001][Wall Clock 118.133218926s] Trained 128 records in 0.10247574 seconds. Throughput is 1249.0762 records/second. Loss is 2.2298684. Sequentiale465b572's hyper parameters: Current learning rate is 5.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 1002][Wall Clock 118.238805552s] Trained 128 records in 0.105586626 seconds. Throughput is 1212.2748 records/second. Loss is 2.2238088. Sequentiale465b572's hyper parameters: Current learning rate is 4.997501249375311E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8320/60000][Iteration 1003][Wall Clock 118.33695833s] Trained 128 records in 0.098152778 seconds. Throughput is 1304.0894 records/second. Loss is 2.232861. Sequentiale465b572's hyper parameters: Current learning rate is 4.995004995004996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 1004][Wall Clock 118.432475209s] Trained 128 records in 0.095516879 seconds. Throughput is 1340.0774 records/second. Loss is 2.2234738. Sequentiale465b572's hyper parameters: Current learning rate is 4.992511233150274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8576/60000][Iteration 1005][Wall Clock 118.526386676s] Trained 128 records in 0.093911467 seconds. Throughput is 1362.9858 records/second. Loss is 2.2347243. Sequentiale465b572's hyper parameters: Current learning rate is 4.99001996007984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 1006][Wall Clock 118.623227777s] Trained 128 records in 0.096841101 seconds. Throughput is 1321.7528 records/second. Loss is 2.2391586. Sequentiale465b572's hyper parameters: Current learning rate is 4.987531172069826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8832/60000][Iteration 1007][Wall Clock 118.719345491s] Trained 128 records in 0.096117714 seconds. Throughput is 1331.7004 records/second. Loss is 2.2255363. Sequentiale465b572's hyper parameters: Current learning rate is 4.985044865403788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:41 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 1008][Wall Clock 118.817496815s] Trained 128 records in 0.098151324 seconds. Throughput is 1304.1088 records/second. Loss is 2.2313492. Sequentiale465b572's hyper parameters: Current learning rate is 4.982561036372695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9088/60000][Iteration 1009][Wall Clock 118.918900134s] Trained 128 records in 0.101403319 seconds. Throughput is 1262.2861 records/second. Loss is 2.2189062. Sequentiale465b572's hyper parameters: Current learning rate is 4.9800796812749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 1010][Wall Clock 119.020411556s] Trained 128 records in 0.101511422 seconds. Throughput is 1260.9419 records/second. Loss is 2.23061. Sequentiale465b572's hyper parameters: Current learning rate is 4.977600796416126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9344/60000][Iteration 1011][Wall Clock 119.123989025s] Trained 128 records in 0.103577469 seconds. Throughput is 1235.7899 records/second. Loss is 2.230004. Sequentiale465b572's hyper parameters: Current learning rate is 4.975124378109454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 1012][Wall Clock 119.22243559s] Trained 128 records in 0.098446565 seconds. Throughput is 1300.1978 records/second. Loss is 2.2168486. Sequentiale465b572's hyper parameters: Current learning rate is 4.972650422675286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9600/60000][Iteration 1013][Wall Clock 119.323119578s] Trained 128 records in 0.100683988 seconds. Throughput is 1271.3044 records/second. Loss is 2.230741. Sequentiale465b572's hyper parameters: Current learning rate is 4.970178926441352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 1014][Wall Clock 119.422533979s] Trained 128 records in 0.099414401 seconds. Throughput is 1287.5398 records/second. Loss is 2.217636. Sequentiale465b572's hyper parameters: Current learning rate is 4.967709885742673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9856/60000][Iteration 1015][Wall Clock 119.520398219s] Trained 128 records in 0.09786424 seconds. Throughput is 1307.9343 records/second. Loss is 2.2267356. Sequentiale465b572's hyper parameters: Current learning rate is 4.965243296921549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 1016][Wall Clock 119.616860138s] Trained 128 records in 0.096461919 seconds. Throughput is 1326.9485 records/second. Loss is 2.2341201. Sequentiale465b572's hyper parameters: Current learning rate is 4.962779156327543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 10112/60000][Iteration 1017][Wall Clock 119.71340964s] Trained 128 records in 0.096549502 seconds. Throughput is 1325.7448 records/second. Loss is 2.2336648. Sequentiale465b572's hyper parameters: Current learning rate is 4.96031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:42 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 1018][Wall Clock 119.809967816s] Trained 128 records in 0.096558176 seconds. Throughput is 1325.6257 records/second. Loss is 2.2332766. Sequentiale465b572's hyper parameters: Current learning rate is 4.957858205255329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 10368/60000][Iteration 1019][Wall Clock 119.90767139s] Trained 128 records in 0.097703574 seconds. Throughput is 1310.0851 records/second. Loss is 2.2406905. Sequentiale465b572's hyper parameters: Current learning rate is 4.95540138751239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 1020][Wall Clock 120.02248513s] Trained 128 records in 0.11481374 seconds. Throughput is 1114.8491 records/second. Loss is 2.235906. Sequentiale465b572's hyper parameters: Current learning rate is 4.952947003467063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 10624/60000][Iteration 1021][Wall Clock 120.117720008s] Trained 128 records in 0.095234878 seconds. Throughput is 1344.0454 records/second. Loss is 2.2249353. Sequentiale465b572's hyper parameters: Current learning rate is 4.950495049504951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 1022][Wall Clock 120.218658314s] Trained 128 records in 0.100938306 seconds. Throughput is 1268.1013 records/second. Loss is 2.2304947. Sequentiale465b572's hyper parameters: Current learning rate is 4.948045522018803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 10880/60000][Iteration 1023][Wall Clock 120.313199667s] Trained 128 records in 0.094541353 seconds. Throughput is 1353.9048 records/second. Loss is 2.2221339. Sequentiale465b572's hyper parameters: Current learning rate is 4.945598417408506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 1024][Wall Clock 120.407928471s] Trained 128 records in 0.094728804 seconds. Throughput is 1351.2257 records/second. Loss is 2.2231035. Sequentiale465b572's hyper parameters: Current learning rate is 4.943153732081067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 11136/60000][Iteration 1025][Wall Clock 120.500521648s] Trained 128 records in 0.092593177 seconds. Throughput is 1382.3912 records/second. Loss is 2.2317314. Sequentiale465b572's hyper parameters: Current learning rate is 4.940711462450593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 1026][Wall Clock 120.594970109s] Trained 128 records in 0.094448461 seconds. Throughput is 1355.2365 records/second. Loss is 2.2278268. Sequentiale465b572's hyper parameters: Current learning rate is 4.938271604938272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 11392/60000][Iteration 1027][Wall Clock 120.687787933s] Trained 128 records in 0.092817824 seconds. Throughput is 1379.0455 records/second. Loss is 2.2376559. Sequentiale465b572's hyper parameters: Current learning rate is 4.93583415597236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:43 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 1028][Wall Clock 120.794123779s] Trained 128 records in 0.106335846 seconds. Throughput is 1203.7333 records/second. Loss is 2.2254553. Sequentiale465b572's hyper parameters: Current learning rate is 4.933399111988159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 11648/60000][Iteration 1029][Wall Clock 120.891502259s] Trained 128 records in 0.09737848 seconds. Throughput is 1314.4589 records/second. Loss is 2.2297976. Sequentiale465b572's hyper parameters: Current learning rate is 4.930966469428008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 1030][Wall Clock 120.986086556s] Trained 128 records in 0.094584297 seconds. Throughput is 1353.2903 records/second. Loss is 2.2358944. Sequentiale465b572's hyper parameters: Current learning rate is 4.928536224741252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 11904/60000][Iteration 1031][Wall Clock 121.095707407s] Trained 128 records in 0.109620851 seconds. Throughput is 1167.661 records/second. Loss is 2.2173617. Sequentiale465b572's hyper parameters: Current learning rate is 4.926108374384236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 1032][Wall Clock 121.210912305s] Trained 128 records in 0.115204898 seconds. Throughput is 1111.0638 records/second. Loss is 2.2317207. Sequentiale465b572's hyper parameters: Current learning rate is 4.923682914820286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12160/60000][Iteration 1033][Wall Clock 121.31319031s] Trained 128 records in 0.102278005 seconds. Throughput is 1251.491 records/second. Loss is 2.2327774. Sequentiale465b572's hyper parameters: Current learning rate is 4.921259842519685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 1034][Wall Clock 121.406644409s] Trained 128 records in 0.093454099 seconds. Throughput is 1369.6564 records/second. Loss is 2.2364302. Sequentiale465b572's hyper parameters: Current learning rate is 4.918839153959666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12416/60000][Iteration 1035][Wall Clock 121.500623351s] Trained 128 records in 0.093978942 seconds. Throughput is 1362.0072 records/second. Loss is 2.2221982. Sequentiale465b572's hyper parameters: Current learning rate is 4.916420845624386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 1036][Wall Clock 121.590727247s] Trained 128 records in 0.090103896 seconds. Throughput is 1420.5823 records/second. Loss is 2.2043586. Sequentiale465b572's hyper parameters: Current learning rate is 4.914004914004914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12672/60000][Iteration 1037][Wall Clock 121.680263456s] Trained 128 records in 0.089536209 seconds. Throughput is 1429.5892 records/second. Loss is 2.2292008. Sequentiale465b572's hyper parameters: Current learning rate is 4.911591355599214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:44 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 1038][Wall Clock 121.770449409s] Trained 128 records in 0.090185953 seconds. Throughput is 1419.2897 records/second. Loss is 2.230861. Sequentiale465b572's hyper parameters: Current learning rate is 4.909180166912126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 12928/60000][Iteration 1039][Wall Clock 121.862744983s] Trained 128 records in 0.092295574 seconds. Throughput is 1386.8488 records/second. Loss is 2.2155874. Sequentiale465b572's hyper parameters: Current learning rate is 4.906771344455348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 1040][Wall Clock 121.953928395s] Trained 128 records in 0.091183412 seconds. Throughput is 1403.7642 records/second. Loss is 2.2369843. Sequentiale465b572's hyper parameters: Current learning rate is 4.904364884747426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13184/60000][Iteration 1041][Wall Clock 122.04960703s] Trained 128 records in 0.095678635 seconds. Throughput is 1337.8118 records/second. Loss is 2.2303371. Sequentiale465b572's hyper parameters: Current learning rate is 4.901960784313725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 1042][Wall Clock 122.14355186s] Trained 128 records in 0.09394483 seconds. Throughput is 1362.5017 records/second. Loss is 2.2365196. Sequentiale465b572's hyper parameters: Current learning rate is 4.899559039686428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13440/60000][Iteration 1043][Wall Clock 122.237357692s] Trained 128 records in 0.093805832 seconds. Throughput is 1364.5206 records/second. Loss is 2.2440007. Sequentiale465b572's hyper parameters: Current learning rate is 4.897159647404506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 1044][Wall Clock 122.331108701s] Trained 128 records in 0.093751009 seconds. Throughput is 1365.3187 records/second. Loss is 2.226644. Sequentiale465b572's hyper parameters: Current learning rate is 4.894762604013705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13696/60000][Iteration 1045][Wall Clock 122.436562011s] Trained 128 records in 0.10545331 seconds. Throughput is 1213.8073 records/second. Loss is 2.2293456. Sequentiale465b572's hyper parameters: Current learning rate is 4.892367906066536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 1046][Wall Clock 122.53175564s] Trained 128 records in 0.095193629 seconds. Throughput is 1344.6278 records/second. Loss is 2.2244022. Sequentiale465b572's hyper parameters: Current learning rate is 4.88997555012225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 13952/60000][Iteration 1047][Wall Clock 122.628776734s] Trained 128 records in 0.097021094 seconds. Throughput is 1319.3007 records/second. Loss is 2.2319758. Sequentiale465b572's hyper parameters: Current learning rate is 4.887585532746823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:45 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 1048][Wall Clock 122.730214706s] Trained 128 records in 0.101437972 seconds. Throughput is 1261.8549 records/second. Loss is 2.2242558. Sequentiale465b572's hyper parameters: Current learning rate is 4.885197850512947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14208/60000][Iteration 1049][Wall Clock 122.827995599s] Trained 128 records in 0.097780893 seconds. Throughput is 1309.0492 records/second. Loss is 2.230331. Sequentiale465b572's hyper parameters: Current learning rate is 4.8828125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 1050][Wall Clock 122.92063095s] Trained 128 records in 0.092635351 seconds. Throughput is 1381.762 records/second. Loss is 2.2315538. Sequentiale465b572's hyper parameters: Current learning rate is 4.880429477794046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14464/60000][Iteration 1051][Wall Clock 123.011415194s] Trained 128 records in 0.090784244 seconds. Throughput is 1409.9363 records/second. Loss is 2.227845. Sequentiale465b572's hyper parameters: Current learning rate is 4.8780487804878054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 1052][Wall Clock 123.108579014s] Trained 128 records in 0.09716382 seconds. Throughput is 1317.3628 records/second. Loss is 2.2251816. Sequentiale465b572's hyper parameters: Current learning rate is 4.8756704046806434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14720/60000][Iteration 1053][Wall Clock 123.221738989s] Trained 128 records in 0.113159975 seconds. Throughput is 1131.142 records/second. Loss is 2.2234044. Sequentiale465b572's hyper parameters: Current learning rate is 4.873294346978557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 1054][Wall Clock 123.320995033s] Trained 128 records in 0.099256044 seconds. Throughput is 1289.594 records/second. Loss is 2.225556. Sequentiale465b572's hyper parameters: Current learning rate is 4.870920603994155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 14976/60000][Iteration 1055][Wall Clock 123.416616488s] Trained 128 records in 0.095621455 seconds. Throughput is 1338.6118 records/second. Loss is 2.2332268. Sequentiale465b572's hyper parameters: Current learning rate is 4.8685491723466403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 1056][Wall Clock 123.51228738s] Trained 128 records in 0.095670892 seconds. Throughput is 1337.9199 records/second. Loss is 2.2284658. Sequentiale465b572's hyper parameters: Current learning rate is 4.866180048661801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 15232/60000][Iteration 1057][Wall Clock 123.608682146s] Trained 128 records in 0.096394766 seconds. Throughput is 1327.8729 records/second. Loss is 2.217911. Sequentiale465b572's hyper parameters: Current learning rate is 4.8638132295719845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 1058][Wall Clock 123.702421411s] Trained 128 records in 0.093739265 seconds. Throughput is 1365.4897 records/second. Loss is 2.2419333. Sequentiale465b572's hyper parameters: Current learning rate is 4.861448711716092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:46 INFO  DistriOptimizer$:408 - [Epoch 3 15488/60000][Iteration 1059][Wall Clock 123.796828853s] Trained 128 records in 0.094407442 seconds. Throughput is 1355.8253 records/second. Loss is 2.2267518. Sequentiale465b572's hyper parameters: Current learning rate is 4.859086491739553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 1060][Wall Clock 123.907848394s] Trained 128 records in 0.111019541 seconds. Throughput is 1152.9502 records/second. Loss is 2.222976. Sequentiale465b572's hyper parameters: Current learning rate is 4.8567265662943174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 15744/60000][Iteration 1061][Wall Clock 124.004205605s] Trained 128 records in 0.096357211 seconds. Throughput is 1328.3905 records/second. Loss is 2.232077. Sequentiale465b572's hyper parameters: Current learning rate is 4.854368932038835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 1062][Wall Clock 124.097382664s] Trained 128 records in 0.093177059 seconds. Throughput is 1373.7288 records/second. Loss is 2.2317276. Sequentiale465b572's hyper parameters: Current learning rate is 4.85201358563804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16000/60000][Iteration 1063][Wall Clock 124.190202903s] Trained 128 records in 0.092820239 seconds. Throughput is 1379.0095 records/second. Loss is 2.2275064. Sequentiale465b572's hyper parameters: Current learning rate is 4.849660523763336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 1064][Wall Clock 124.286203326s] Trained 128 records in 0.096000423 seconds. Throughput is 1333.3274 records/second. Loss is 2.2276058. Sequentiale465b572's hyper parameters: Current learning rate is 4.8473097430925844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16256/60000][Iteration 1065][Wall Clock 124.382282178s] Trained 128 records in 0.096078852 seconds. Throughput is 1332.2391 records/second. Loss is 2.2198536. Sequentiale465b572's hyper parameters: Current learning rate is 4.8449612403100775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 1066][Wall Clock 124.479693034s] Trained 128 records in 0.097410856 seconds. Throughput is 1314.0219 records/second. Loss is 2.2252743. Sequentiale465b572's hyper parameters: Current learning rate is 4.8426150121065375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16512/60000][Iteration 1067][Wall Clock 124.578567992s] Trained 128 records in 0.098874958 seconds. Throughput is 1294.5645 records/second. Loss is 2.230075. Sequentiale465b572's hyper parameters: Current learning rate is 4.8402710551790907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 1068][Wall Clock 124.672864811s] Trained 128 records in 0.094296819 seconds. Throughput is 1357.4159 records/second. Loss is 2.2269852. Sequentiale465b572's hyper parameters: Current learning rate is 4.837929366231253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:47 INFO  DistriOptimizer$:408 - [Epoch 3 16768/60000][Iteration 1069][Wall Clock 124.765415739s] Trained 128 records in 0.092550928 seconds. Throughput is 1383.0223 records/second. Loss is 2.216585. Sequentiale465b572's hyper parameters: Current learning rate is 4.8355899419729207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 1070][Wall Clock 124.87499842s] Trained 128 records in 0.109582681 seconds. Throughput is 1168.0679 records/second. Loss is 2.2287862. Sequentiale465b572's hyper parameters: Current learning rate is 4.833252779120348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17024/60000][Iteration 1071][Wall Clock 124.969482521s] Trained 128 records in 0.094484101 seconds. Throughput is 1354.7253 records/second. Loss is 2.2304692. Sequentiale465b572's hyper parameters: Current learning rate is 4.8309178743961346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 1072][Wall Clock 125.06776123s] Trained 128 records in 0.098278709 seconds. Throughput is 1302.4185 records/second. Loss is 2.2155406. Sequentiale465b572's hyper parameters: Current learning rate is 4.828585224529214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17280/60000][Iteration 1073][Wall Clock 125.161657933s] Trained 128 records in 0.093896703 seconds. Throughput is 1363.2002 records/second. Loss is 2.2380714. Sequentiale465b572's hyper parameters: Current learning rate is 4.8262548262548264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 1074][Wall Clock 125.254567325s] Trained 128 records in 0.092909392 seconds. Throughput is 1377.6863 records/second. Loss is 2.2257829. Sequentiale465b572's hyper parameters: Current learning rate is 4.82392667631452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17536/60000][Iteration 1075][Wall Clock 125.349660335s] Trained 128 records in 0.09509301 seconds. Throughput is 1346.0505 records/second. Loss is 2.2151344. Sequentiale465b572's hyper parameters: Current learning rate is 4.821600771456124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 1076][Wall Clock 125.443661032s] Trained 128 records in 0.094000697 seconds. Throughput is 1361.692 records/second. Loss is 2.218782. Sequentiale465b572's hyper parameters: Current learning rate is 4.8192771084337347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17792/60000][Iteration 1077][Wall Clock 125.535017766s] Trained 128 records in 0.091356734 seconds. Throughput is 1401.101 records/second. Loss is 2.228724. Sequentiale465b572's hyper parameters: Current learning rate is 4.816955684007707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 1078][Wall Clock 125.628511702s] Trained 128 records in 0.093493936 seconds. Throughput is 1369.0728 records/second. Loss is 2.2143316. Sequentiale465b572's hyper parameters: Current learning rate is 4.814636494944632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:48 INFO  DistriOptimizer$:408 - [Epoch 3 18048/60000][Iteration 1079][Wall Clock 125.732463839s] Trained 128 records in 0.103952137 seconds. Throughput is 1231.3359 records/second. Loss is 2.2436032. Sequentiale465b572's hyper parameters: Current learning rate is 4.8123195380173235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 1080][Wall Clock 125.828867569s] Trained 128 records in 0.09640373 seconds. Throughput is 1327.7494 records/second. Loss is 2.240201. Sequentiale465b572's hyper parameters: Current learning rate is 4.8100048100048107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18304/60000][Iteration 1081][Wall Clock 125.919715803s] Trained 128 records in 0.090848234 seconds. Throughput is 1408.9431 records/second. Loss is 2.2260768. Sequentiale465b572's hyper parameters: Current learning rate is 4.8076923076923074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 1082][Wall Clock 126.017012441s] Trained 128 records in 0.097296638 seconds. Throughput is 1315.5645 records/second. Loss is 2.2126846. Sequentiale465b572's hyper parameters: Current learning rate is 4.805382027871216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18560/60000][Iteration 1083][Wall Clock 126.108710079s] Trained 128 records in 0.091697638 seconds. Throughput is 1395.892 records/second. Loss is 2.2232292. Sequentiale465b572's hyper parameters: Current learning rate is 4.8030739673390974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 1084][Wall Clock 126.203039537s] Trained 128 records in 0.094329458 seconds. Throughput is 1356.9462 records/second. Loss is 2.2255957. Sequentiale465b572's hyper parameters: Current learning rate is 4.8007681228996637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18816/60000][Iteration 1085][Wall Clock 126.299622527s] Trained 128 records in 0.09658299 seconds. Throughput is 1325.2852 records/second. Loss is 2.2328339. Sequentiale465b572's hyper parameters: Current learning rate is 4.798464491362764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 1086][Wall Clock 126.4000665s] Trained 128 records in 0.100443973 seconds. Throughput is 1274.3423 records/second. Loss is 2.226028. Sequentiale465b572's hyper parameters: Current learning rate is 4.7961630695443646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 19072/60000][Iteration 1087][Wall Clock 126.498367934s] Trained 128 records in 0.098301434 seconds. Throughput is 1302.1173 records/second. Loss is 2.221341. Sequentiale465b572's hyper parameters: Current learning rate is 4.793863854266538E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 1088][Wall Clock 126.602831817s] Trained 128 records in 0.104463883 seconds. Throughput is 1225.3038 records/second. Loss is 2.2223613. Sequentiale465b572's hyper parameters: Current learning rate is 4.7915668423574516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:49 INFO  DistriOptimizer$:408 - [Epoch 3 19328/60000][Iteration 1089][Wall Clock 126.699672794s] Trained 128 records in 0.096840977 seconds. Throughput is 1321.7545 records/second. Loss is 2.225548. Sequentiale465b572's hyper parameters: Current learning rate is 4.789272030651341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 1090][Wall Clock 126.796858896s] Trained 128 records in 0.097186102 seconds. Throughput is 1317.0607 records/second. Loss is 2.226414. Sequentiale465b572's hyper parameters: Current learning rate is 4.786979415988511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 19584/60000][Iteration 1091][Wall Clock 126.894442666s] Trained 128 records in 0.09758377 seconds. Throughput is 1311.6935 records/second. Loss is 2.2250917. Sequentiale465b572's hyper parameters: Current learning rate is 4.7846889952153117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 1092][Wall Clock 126.988157477s] Trained 128 records in 0.093714811 seconds. Throughput is 1365.846 records/second. Loss is 2.2178261. Sequentiale465b572's hyper parameters: Current learning rate is 4.782400765184122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 19840/60000][Iteration 1093][Wall Clock 127.086252245s] Trained 128 records in 0.098094768 seconds. Throughput is 1304.8606 records/second. Loss is 2.2093277. Sequentiale465b572's hyper parameters: Current learning rate is 4.780114722753346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 1094][Wall Clock 127.183055191s] Trained 128 records in 0.096802946 seconds. Throughput is 1322.2738 records/second. Loss is 2.2142346. Sequentiale465b572's hyper parameters: Current learning rate is 4.777830864787387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 20096/60000][Iteration 1095][Wall Clock 127.292551343s] Trained 128 records in 0.109496152 seconds. Throughput is 1168.9908 records/second. Loss is 2.225514. Sequentiale465b572's hyper parameters: Current learning rate is 4.7755491881566373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 1096][Wall Clock 127.396816847s] Trained 128 records in 0.104265504 seconds. Throughput is 1227.6351 records/second. Loss is 2.2388763. Sequentiale465b572's hyper parameters: Current learning rate is 4.773269689737471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 20352/60000][Iteration 1097][Wall Clock 127.501404544s] Trained 128 records in 0.104587697 seconds. Throughput is 1223.8533 records/second. Loss is 2.2195075. Sequentiale465b572's hyper parameters: Current learning rate is 4.7709923664122136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 1098][Wall Clock 127.608638265s] Trained 128 records in 0.107233721 seconds. Throughput is 1193.6544 records/second. Loss is 2.2229557. Sequentiale465b572's hyper parameters: Current learning rate is 4.768717215069147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:50 INFO  DistriOptimizer$:408 - [Epoch 3 20608/60000][Iteration 1099][Wall Clock 127.709105991s] Trained 128 records in 0.100467726 seconds. Throughput is 1274.041 records/second. Loss is 2.223584. Sequentiale465b572's hyper parameters: Current learning rate is 4.766444232602479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 1100][Wall Clock 127.810762876s] Trained 128 records in 0.101656885 seconds. Throughput is 1259.1376 records/second. Loss is 2.224316. Sequentiale465b572's hyper parameters: Current learning rate is 4.764173415912339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 20864/60000][Iteration 1101][Wall Clock 127.908992071s] Trained 128 records in 0.098229195 seconds. Throughput is 1303.075 records/second. Loss is 2.2252471. Sequentiale465b572's hyper parameters: Current learning rate is 4.761904761904762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 1102][Wall Clock 128.008307865s] Trained 128 records in 0.099315794 seconds. Throughput is 1288.8182 records/second. Loss is 2.2097275. Sequentiale465b572's hyper parameters: Current learning rate is 4.759638267491671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21120/60000][Iteration 1103][Wall Clock 128.106452602s] Trained 128 records in 0.098144737 seconds. Throughput is 1304.1963 records/second. Loss is 2.2173588. Sequentiale465b572's hyper parameters: Current learning rate is 4.757373929590865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 1104][Wall Clock 128.211990175s] Trained 128 records in 0.105537573 seconds. Throughput is 1212.8383 records/second. Loss is 2.2250795. Sequentiale465b572's hyper parameters: Current learning rate is 4.755111745126011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21376/60000][Iteration 1105][Wall Clock 128.307467218s] Trained 128 records in 0.095477043 seconds. Throughput is 1340.6364 records/second. Loss is 2.2218084. Sequentiale465b572's hyper parameters: Current learning rate is 4.752851711026616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 1106][Wall Clock 128.402490401s] Trained 128 records in 0.095023183 seconds. Throughput is 1347.0397 records/second. Loss is 2.237165. Sequentiale465b572's hyper parameters: Current learning rate is 4.7505938242280285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21632/60000][Iteration 1107][Wall Clock 128.497623757s] Trained 128 records in 0.095133356 seconds. Throughput is 1345.4797 records/second. Loss is 2.2257512. Sequentiale465b572's hyper parameters: Current learning rate is 4.748338081671415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 1108][Wall Clock 128.598551473s] Trained 128 records in 0.100927716 seconds. Throughput is 1268.2344 records/second. Loss is 2.2181144. Sequentiale465b572's hyper parameters: Current learning rate is 4.746084480303749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:51 INFO  DistriOptimizer$:408 - [Epoch 3 21888/60000][Iteration 1109][Wall Clock 128.69732824s] Trained 128 records in 0.098776767 seconds. Throughput is 1295.8513 records/second. Loss is 2.2000914. Sequentiale465b572's hyper parameters: Current learning rate is 4.743833017077799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 1110][Wall Clock 128.79667376s] Trained 128 records in 0.09934552 seconds. Throughput is 1288.4325 records/second. Loss is 2.210595. Sequentiale465b572's hyper parameters: Current learning rate is 4.74158368895211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22144/60000][Iteration 1111][Wall Clock 128.889014577s] Trained 128 records in 0.092340817 seconds. Throughput is 1386.1692 records/second. Loss is 2.2184227. Sequentiale465b572's hyper parameters: Current learning rate is 4.739336492890995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 1112][Wall Clock 128.982006097s] Trained 128 records in 0.09299152 seconds. Throughput is 1376.4696 records/second. Loss is 2.204179. Sequentiale465b572's hyper parameters: Current learning rate is 4.73709142586452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22400/60000][Iteration 1113][Wall Clock 129.073516831s] Trained 128 records in 0.091510734 seconds. Throughput is 1398.743 records/second. Loss is 2.220809. Sequentiale465b572's hyper parameters: Current learning rate is 4.734848484848485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 1114][Wall Clock 129.170111653s] Trained 128 records in 0.096594822 seconds. Throughput is 1325.1228 records/second. Loss is 2.210893. Sequentiale465b572's hyper parameters: Current learning rate is 4.73260766682442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22656/60000][Iteration 1115][Wall Clock 129.263986605s] Trained 128 records in 0.093874952 seconds. Throughput is 1363.516 records/second. Loss is 2.219404. Sequentiale465b572's hyper parameters: Current learning rate is 4.7303689687795653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 1116][Wall Clock 129.362669449s] Trained 128 records in 0.098682844 seconds. Throughput is 1297.0846 records/second. Loss is 2.2126274. Sequentiale465b572's hyper parameters: Current learning rate is 4.7281323877068556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 22912/60000][Iteration 1117][Wall Clock 129.458811977s] Trained 128 records in 0.096142528 seconds. Throughput is 1331.3567 records/second. Loss is 2.2181866. Sequentiale465b572's hyper parameters: Current learning rate is 4.725897920604915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 1118][Wall Clock 129.559977722s] Trained 128 records in 0.101165745 seconds. Throughput is 1265.2505 records/second. Loss is 2.211594. Sequentiale465b572's hyper parameters: Current learning rate is 4.723665564478035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 23168/60000][Iteration 1119][Wall Clock 129.660723525s] Trained 128 records in 0.100745803 seconds. Throughput is 1270.5244 records/second. Loss is 2.2371132. Sequentiale465b572's hyper parameters: Current learning rate is 4.7214353163361653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:52 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 1120][Wall Clock 129.767143299s] Trained 128 records in 0.106419774 seconds. Throughput is 1202.784 records/second. Loss is 2.2230825. Sequentiale465b572's hyper parameters: Current learning rate is 4.719207173194904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 23424/60000][Iteration 1121][Wall Clock 129.876440386s] Trained 128 records in 0.109297087 seconds. Throughput is 1171.12 records/second. Loss is 2.2207985. Sequentiale465b572's hyper parameters: Current learning rate is 4.716981132075472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 1122][Wall Clock 129.986729823s] Trained 128 records in 0.110289437 seconds. Throughput is 1160.5825 records/second. Loss is 2.2183924. Sequentiale465b572's hyper parameters: Current learning rate is 4.714757190004715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 23680/60000][Iteration 1123][Wall Clock 130.08441496s] Trained 128 records in 0.097685137 seconds. Throughput is 1310.3324 records/second. Loss is 2.2294347. Sequentiale465b572's hyper parameters: Current learning rate is 4.7125353440150805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 1124][Wall Clock 130.180721397s] Trained 128 records in 0.096306437 seconds. Throughput is 1329.0908 records/second. Loss is 2.2191844. Sequentiale465b572's hyper parameters: Current learning rate is 4.7103155911446063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 23936/60000][Iteration 1125][Wall Clock 130.281481926s] Trained 128 records in 0.100760529 seconds. Throughput is 1270.3387 records/second. Loss is 2.2200394. Sequentiale465b572's hyper parameters: Current learning rate is 4.7080979284369113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 1126][Wall Clock 130.380082771s] Trained 128 records in 0.098600845 seconds. Throughput is 1298.1633 records/second. Loss is 2.222395. Sequentiale465b572's hyper parameters: Current learning rate is 4.7058823529411766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 24192/60000][Iteration 1127][Wall Clock 130.469849757s] Trained 128 records in 0.089766986 seconds. Throughput is 1425.914 records/second. Loss is 2.2180269. Sequentiale465b572's hyper parameters: Current learning rate is 4.703668861712135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 1128][Wall Clock 130.564012413s] Trained 128 records in 0.094162656 seconds. Throughput is 1359.3499 records/second. Loss is 2.2170987. Sequentiale465b572's hyper parameters: Current learning rate is 4.701457451810062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:53 INFO  DistriOptimizer$:408 - [Epoch 3 24448/60000][Iteration 1129][Wall Clock 130.661270848s] Trained 128 records in 0.097258435 seconds. Throughput is 1316.0813 records/second. Loss is 2.225513. Sequentiale465b572's hyper parameters: Current learning rate is 4.6992481203007516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 1130][Wall Clock 130.776706915s] Trained 128 records in 0.115436067 seconds. Throughput is 1108.8389 records/second. Loss is 2.214688. Sequentiale465b572's hyper parameters: Current learning rate is 4.697040864255519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 24704/60000][Iteration 1131][Wall Clock 130.8657593s] Trained 128 records in 0.089052385 seconds. Throughput is 1437.3562 records/second. Loss is 2.2071066. Sequentiale465b572's hyper parameters: Current learning rate is 4.694835680751174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 1132][Wall Clock 130.960454461s] Trained 128 records in 0.094695161 seconds. Throughput is 1351.7058 records/second. Loss is 2.2227411. Sequentiale465b572's hyper parameters: Current learning rate is 4.692632566870014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 24960/60000][Iteration 1133][Wall Clock 131.057016378s] Trained 128 records in 0.096561917 seconds. Throughput is 1325.5743 records/second. Loss is 2.2275918. Sequentiale465b572's hyper parameters: Current learning rate is 4.6904315196998124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 1134][Wall Clock 131.151431391s] Trained 128 records in 0.094415013 seconds. Throughput is 1355.7166 records/second. Loss is 2.2234373. Sequentiale465b572's hyper parameters: Current learning rate is 4.6882325363338024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 25216/60000][Iteration 1135][Wall Clock 131.250676158s] Trained 128 records in 0.099244767 seconds. Throughput is 1289.7406 records/second. Loss is 2.2145815. Sequentiale465b572's hyper parameters: Current learning rate is 4.686035613870665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 1136][Wall Clock 131.357785331s] Trained 128 records in 0.107109173 seconds. Throughput is 1195.0424 records/second. Loss is 2.2195194. Sequentiale465b572's hyper parameters: Current learning rate is 4.6838407494145204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 25472/60000][Iteration 1137][Wall Clock 131.45925097s] Trained 128 records in 0.101465639 seconds. Throughput is 1261.5107 records/second. Loss is 2.2302077. Sequentiale465b572's hyper parameters: Current learning rate is 4.6816479400749064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 1138][Wall Clock 131.565898013s] Trained 128 records in 0.106647043 seconds. Throughput is 1200.2208 records/second. Loss is 2.2261205. Sequentiale465b572's hyper parameters: Current learning rate is 4.679457182966776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:54 INFO  DistriOptimizer$:408 - [Epoch 3 25728/60000][Iteration 1139][Wall Clock 131.677950415s] Trained 128 records in 0.112052402 seconds. Throughput is 1142.3226 records/second. Loss is 2.2292964. Sequentiale465b572's hyper parameters: Current learning rate is 4.677268475210477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 1140][Wall Clock 131.780091153s] Trained 128 records in 0.102140738 seconds. Throughput is 1253.1729 records/second. Loss is 2.215891. Sequentiale465b572's hyper parameters: Current learning rate is 4.6750818139317435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 25984/60000][Iteration 1141][Wall Clock 131.894324181s] Trained 128 records in 0.114233028 seconds. Throughput is 1120.5166 records/second. Loss is 2.2303963. Sequentiale465b572's hyper parameters: Current learning rate is 4.672897196261682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 1142][Wall Clock 132.003495674s] Trained 128 records in 0.109171493 seconds. Throughput is 1172.4673 records/second. Loss is 2.2205873. Sequentiale465b572's hyper parameters: Current learning rate is 4.670714619336759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26240/60000][Iteration 1143][Wall Clock 132.104000722s] Trained 128 records in 0.100505048 seconds. Throughput is 1273.5679 records/second. Loss is 2.241182. Sequentiale465b572's hyper parameters: Current learning rate is 4.6685340802987853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 1144][Wall Clock 132.199726685s] Trained 128 records in 0.095725963 seconds. Throughput is 1337.1503 records/second. Loss is 2.2275739. Sequentiale465b572's hyper parameters: Current learning rate is 4.6663555762949143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26496/60000][Iteration 1145][Wall Clock 132.321201768s] Trained 128 records in 0.121475083 seconds. Throughput is 1053.714 records/second. Loss is 2.2245839. Sequentiale465b572's hyper parameters: Current learning rate is 4.664179104477612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 1146][Wall Clock 132.438968038s] Trained 128 records in 0.11776627 seconds. Throughput is 1086.8987 records/second. Loss is 2.2073739. Sequentiale465b572's hyper parameters: Current learning rate is 4.662004662004662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26752/60000][Iteration 1147][Wall Clock 132.539702217s] Trained 128 records in 0.100734179 seconds. Throughput is 1270.671 records/second. Loss is 2.2228467. Sequentiale465b572's hyper parameters: Current learning rate is 4.659832246039143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:55 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 1148][Wall Clock 132.650487068s] Trained 128 records in 0.110784851 seconds. Throughput is 1155.3926 records/second. Loss is 2.2259123. Sequentiale465b572's hyper parameters: Current learning rate is 4.6576618537494174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27008/60000][Iteration 1149][Wall Clock 132.751662224s] Trained 128 records in 0.101175156 seconds. Throughput is 1265.1327 records/second. Loss is 2.2254329. Sequentiale465b572's hyper parameters: Current learning rate is 4.655493482309125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 1150][Wall Clock 132.855153986s] Trained 128 records in 0.103491762 seconds. Throughput is 1236.8135 records/second. Loss is 2.2230504. Sequentiale465b572's hyper parameters: Current learning rate is 4.6533271288971617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27264/60000][Iteration 1151][Wall Clock 132.953078718s] Trained 128 records in 0.097924732 seconds. Throughput is 1307.1263 records/second. Loss is 2.2104378. Sequentiale465b572's hyper parameters: Current learning rate is 4.6511627906976736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 1152][Wall Clock 133.054451601s] Trained 128 records in 0.101372883 seconds. Throughput is 1262.665 records/second. Loss is 2.2110224. Sequentiale465b572's hyper parameters: Current learning rate is 4.649000464900047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27520/60000][Iteration 1153][Wall Clock 133.166571015s] Trained 128 records in 0.112119414 seconds. Throughput is 1141.6399 records/second. Loss is 2.218937. Sequentiale465b572's hyper parameters: Current learning rate is 4.6468401486988845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 1154][Wall Clock 133.269982908s] Trained 128 records in 0.103411893 seconds. Throughput is 1237.7687 records/second. Loss is 2.2250237. Sequentiale465b572's hyper parameters: Current learning rate is 4.6446818392940084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27776/60000][Iteration 1155][Wall Clock 133.415132417s] Trained 128 records in 0.145149509 seconds. Throughput is 881.8493 records/second. Loss is 2.2224104. Sequentiale465b572's hyper parameters: Current learning rate is 4.6425255338904364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 1156][Wall Clock 133.546951117s] Trained 128 records in 0.1318187 seconds. Throughput is 971.0307 records/second. Loss is 2.224453. Sequentiale465b572's hyper parameters: Current learning rate is 4.6403712296983754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:56 INFO  DistriOptimizer$:408 - [Epoch 3 28032/60000][Iteration 1157][Wall Clock 133.65014587s] Trained 128 records in 0.103194753 seconds. Throughput is 1240.3732 records/second. Loss is 2.2153409. Sequentiale465b572's hyper parameters: Current learning rate is 4.63821892393321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 1158][Wall Clock 133.747186295s] Trained 128 records in 0.097040425 seconds. Throughput is 1319.038 records/second. Loss is 2.2184734. Sequentiale465b572's hyper parameters: Current learning rate is 4.636068613815484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28288/60000][Iteration 1159][Wall Clock 133.853239359s] Trained 128 records in 0.106053064 seconds. Throughput is 1206.943 records/second. Loss is 2.2024913. Sequentiale465b572's hyper parameters: Current learning rate is 4.633920296570899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 1160][Wall Clock 133.946105999s] Trained 128 records in 0.09286664 seconds. Throughput is 1378.3206 records/second. Loss is 2.2078855. Sequentiale465b572's hyper parameters: Current learning rate is 4.6317739694302923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28544/60000][Iteration 1161][Wall Clock 134.041616791s] Trained 128 records in 0.095510792 seconds. Throughput is 1340.1626 records/second. Loss is 2.230339. Sequentiale465b572's hyper parameters: Current learning rate is 4.629629629629629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 1162][Wall Clock 134.155171372s] Trained 128 records in 0.113554581 seconds. Throughput is 1127.2112 records/second. Loss is 2.22522. Sequentiale465b572's hyper parameters: Current learning rate is 4.6274872744099955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28800/60000][Iteration 1163][Wall Clock 134.26551601s] Trained 128 records in 0.110344638 seconds. Throughput is 1160.002 records/second. Loss is 2.2243764. Sequentiale465b572's hyper parameters: Current learning rate is 4.6253469010175765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 1164][Wall Clock 134.375877363s] Trained 128 records in 0.110361353 seconds. Throughput is 1159.8263 records/second. Loss is 2.2250617. Sequentiale465b572's hyper parameters: Current learning rate is 4.623208506703652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 29056/60000][Iteration 1165][Wall Clock 134.477790576s] Trained 128 records in 0.101913213 seconds. Throughput is 1255.9706 records/second. Loss is 2.2295353. Sequentiale465b572's hyper parameters: Current learning rate is 4.6210720887245846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 1166][Wall Clock 134.576429869s] Trained 128 records in 0.098639293 seconds. Throughput is 1297.6573 records/second. Loss is 2.2121744. Sequentiale465b572's hyper parameters: Current learning rate is 4.6189376443418013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:57 INFO  DistriOptimizer$:408 - [Epoch 3 29312/60000][Iteration 1167][Wall Clock 134.675577543s] Trained 128 records in 0.099147674 seconds. Throughput is 1291.0035 records/second. Loss is 2.2250333. Sequentiale465b572's hyper parameters: Current learning rate is 4.6168051708217917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 1168][Wall Clock 134.774682719s] Trained 128 records in 0.099105176 seconds. Throughput is 1291.5571 records/second. Loss is 2.2027009. Sequentiale465b572's hyper parameters: Current learning rate is 4.614674665436087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 29568/60000][Iteration 1169][Wall Clock 134.872356235s] Trained 128 records in 0.097673516 seconds. Throughput is 1310.4883 records/second. Loss is 2.2136059. Sequentiale465b572's hyper parameters: Current learning rate is 4.6125461254612545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 1170][Wall Clock 135.008778039s] Trained 128 records in 0.136421804 seconds. Throughput is 938.2665 records/second. Loss is 2.2139075. Sequentiale465b572's hyper parameters: Current learning rate is 4.610419548178884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 29824/60000][Iteration 1171][Wall Clock 135.127198813s] Trained 128 records in 0.118420774 seconds. Throughput is 1080.8915 records/second. Loss is 2.210078. Sequentiale465b572's hyper parameters: Current learning rate is 4.608294930875576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 1172][Wall Clock 135.22418952s] Trained 128 records in 0.096990707 seconds. Throughput is 1319.7141 records/second. Loss is 2.2209876. Sequentiale465b572's hyper parameters: Current learning rate is 4.606172270842929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 30080/60000][Iteration 1173][Wall Clock 135.328533589s] Trained 128 records in 0.104344069 seconds. Throughput is 1226.7108 records/second. Loss is 2.2134104. Sequentiale465b572's hyper parameters: Current learning rate is 4.604051565377533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 1174][Wall Clock 135.454746036s] Trained 128 records in 0.126212447 seconds. Throughput is 1014.163 records/second. Loss is 2.2174177. Sequentiale465b572's hyper parameters: Current learning rate is 4.601932811780948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 30336/60000][Iteration 1175][Wall Clock 135.547976213s] Trained 128 records in 0.093230177 seconds. Throughput is 1372.9459 records/second. Loss is 2.2249417. Sequentiale465b572's hyper parameters: Current learning rate is 4.599816007359706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:58 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 1176][Wall Clock 135.644085428s] Trained 128 records in 0.096109215 seconds. Throughput is 1331.8182 records/second. Loss is 2.2158532. Sequentiale465b572's hyper parameters: Current learning rate is 4.5977011494252877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 30592/60000][Iteration 1177][Wall Clock 135.739023562s] Trained 128 records in 0.094938134 seconds. Throughput is 1348.2463 records/second. Loss is 2.1971362. Sequentiale465b572's hyper parameters: Current learning rate is 4.5955882352941176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 1178][Wall Clock 135.840793181s] Trained 128 records in 0.101769619 seconds. Throughput is 1257.7428 records/second. Loss is 2.213629. Sequentiale465b572's hyper parameters: Current learning rate is 4.5934772622875517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 30848/60000][Iteration 1179][Wall Clock 135.943320984s] Trained 128 records in 0.102527803 seconds. Throughput is 1248.4418 records/second. Loss is 2.214065. Sequentiale465b572's hyper parameters: Current learning rate is 4.5913682277318646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 1180][Wall Clock 136.036740004s] Trained 128 records in 0.09341902 seconds. Throughput is 1370.1707 records/second. Loss is 2.212325. Sequentiale465b572's hyper parameters: Current learning rate is 4.5892611289582373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 31104/60000][Iteration 1181][Wall Clock 136.159491821s] Trained 128 records in 0.122751817 seconds. Throughput is 1042.7544 records/second. Loss is 2.2238703. Sequentiale465b572's hyper parameters: Current learning rate is 4.587155963302753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 1182][Wall Clock 136.252342363s] Trained 128 records in 0.092850542 seconds. Throughput is 1378.5596 records/second. Loss is 2.2159111. Sequentiale465b572's hyper parameters: Current learning rate is 4.585052728106373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 31360/60000][Iteration 1183][Wall Clock 136.35553873s] Trained 128 records in 0.103196367 seconds. Throughput is 1240.3538 records/second. Loss is 2.2081883. Sequentiale465b572's hyper parameters: Current learning rate is 4.5829514207149406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 1184][Wall Clock 136.454312435s] Trained 128 records in 0.098773705 seconds. Throughput is 1295.8915 records/second. Loss is 2.213755. Sequentiale465b572's hyper parameters: Current learning rate is 4.5808520384791576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 31616/60000][Iteration 1185][Wall Clock 136.556564249s] Trained 128 records in 0.102251814 seconds. Throughput is 1251.8115 records/second. Loss is 2.2084506. Sequentiale465b572's hyper parameters: Current learning rate is 4.578754578754579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:06:59 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 1186][Wall Clock 136.652711008s] Trained 128 records in 0.096146759 seconds. Throughput is 1331.2981 records/second. Loss is 2.1919377. Sequentiale465b572's hyper parameters: Current learning rate is 4.576659038901602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 31872/60000][Iteration 1187][Wall Clock 136.752413334s] Trained 128 records in 0.099702326 seconds. Throughput is 1283.8215 records/second. Loss is 2.2076764. Sequentiale465b572's hyper parameters: Current learning rate is 4.574565416285453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 1188][Wall Clock 136.85057879s] Trained 128 records in 0.098165456 seconds. Throughput is 1303.921 records/second. Loss is 2.205864. Sequentiale465b572's hyper parameters: Current learning rate is 4.5724737082761767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32128/60000][Iteration 1189][Wall Clock 136.945481983s] Trained 128 records in 0.094903193 seconds. Throughput is 1348.7428 records/second. Loss is 2.213447. Sequentiale465b572's hyper parameters: Current learning rate is 4.5703839122486294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 1190][Wall Clock 137.047321153s] Trained 128 records in 0.10183917 seconds. Throughput is 1256.8838 records/second. Loss is 2.2204235. Sequentiale465b572's hyper parameters: Current learning rate is 4.5682960255824577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32384/60000][Iteration 1191][Wall Clock 137.148885683s] Trained 128 records in 0.10156453 seconds. Throughput is 1260.2826 records/second. Loss is 2.227352. Sequentiale465b572's hyper parameters: Current learning rate is 4.566210045662101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 1192][Wall Clock 137.250777907s] Trained 128 records in 0.101892224 seconds. Throughput is 1256.2294 records/second. Loss is 2.2162306. Sequentiale465b572's hyper parameters: Current learning rate is 4.564125969876769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32640/60000][Iteration 1193][Wall Clock 137.347498418s] Trained 128 records in 0.096720511 seconds. Throughput is 1323.4008 records/second. Loss is 2.1984556. Sequentiale465b572's hyper parameters: Current learning rate is 4.562043795620438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 1194][Wall Clock 137.443267075s] Trained 128 records in 0.095768657 seconds. Throughput is 1336.5542 records/second. Loss is 2.222156. Sequentiale465b572's hyper parameters: Current learning rate is 4.5599635202918376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 32896/60000][Iteration 1195][Wall Clock 137.582065184s] Trained 128 records in 0.138798109 seconds. Throughput is 922.2028 records/second. Loss is 2.1950362. Sequentiale465b572's hyper parameters: Current learning rate is 4.55788514129444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:00 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 1196][Wall Clock 137.68017659s] Trained 128 records in 0.098111406 seconds. Throughput is 1304.6393 records/second. Loss is 2.2088308. Sequentiale465b572's hyper parameters: Current learning rate is 4.555808656036446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33152/60000][Iteration 1197][Wall Clock 137.791180948s] Trained 128 records in 0.111004358 seconds. Throughput is 1153.1079 records/second. Loss is 2.1993277. Sequentiale465b572's hyper parameters: Current learning rate is 4.553734061930784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 1198][Wall Clock 137.885556244s] Trained 128 records in 0.094375296 seconds. Throughput is 1356.2871 records/second. Loss is 2.2004783. Sequentiale465b572's hyper parameters: Current learning rate is 4.551661356395084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33408/60000][Iteration 1199][Wall Clock 137.989808741s] Trained 128 records in 0.104252497 seconds. Throughput is 1227.7883 records/second. Loss is 2.2079847. Sequentiale465b572's hyper parameters: Current learning rate is 4.5495905368516835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 1200][Wall Clock 138.098325392s] Trained 128 records in 0.108516651 seconds. Throughput is 1179.5425 records/second. Loss is 2.209643. Sequentiale465b572's hyper parameters: Current learning rate is 4.547521600727604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33664/60000][Iteration 1201][Wall Clock 138.194711937s] Trained 128 records in 0.096386545 seconds. Throughput is 1327.9862 records/second. Loss is 2.2053525. Sequentiale465b572's hyper parameters: Current learning rate is 4.5454545454545455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 1202][Wall Clock 138.293074501s] Trained 128 records in 0.098362564 seconds. Throughput is 1301.3081 records/second. Loss is 2.217795. Sequentiale465b572's hyper parameters: Current learning rate is 4.5433893684688776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 33920/60000][Iteration 1203][Wall Clock 138.395003667s] Trained 128 records in 0.101929166 seconds. Throughput is 1255.774 records/second. Loss is 2.2266722. Sequentiale465b572's hyper parameters: Current learning rate is 4.541326067211626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 1204][Wall Clock 138.497846657s] Trained 128 records in 0.10284299 seconds. Throughput is 1244.6157 records/second. Loss is 2.219272. Sequentiale465b572's hyper parameters: Current learning rate is 4.539264639128461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:01 INFO  DistriOptimizer$:408 - [Epoch 3 34176/60000][Iteration 1205][Wall Clock 138.596666209s] Trained 128 records in 0.098819552 seconds. Throughput is 1295.2902 records/second. Loss is 2.2153697. Sequentiale465b572's hyper parameters: Current learning rate is 4.537205081669692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 1206][Wall Clock 138.706658326s] Trained 128 records in 0.109992117 seconds. Throughput is 1163.7197 records/second. Loss is 2.2096891. Sequentiale465b572's hyper parameters: Current learning rate is 4.535147392290249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 34432/60000][Iteration 1207][Wall Clock 138.804421096s] Trained 128 records in 0.09776277 seconds. Throughput is 1309.2919 records/second. Loss is 2.223391. Sequentiale465b572's hyper parameters: Current learning rate is 4.5330915684496827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 1208][Wall Clock 138.91514032s] Trained 128 records in 0.110719224 seconds. Throughput is 1156.0774 records/second. Loss is 2.232086. Sequentiale465b572's hyper parameters: Current learning rate is 4.5310376076121433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 34688/60000][Iteration 1209][Wall Clock 139.019051068s] Trained 128 records in 0.103910748 seconds. Throughput is 1231.8263 records/second. Loss is 2.213627. Sequentiale465b572's hyper parameters: Current learning rate is 4.5289855072463763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 1210][Wall Clock 139.116935178s] Trained 128 records in 0.09788411 seconds. Throughput is 1307.6688 records/second. Loss is 2.2112129. Sequentiale465b572's hyper parameters: Current learning rate is 4.526935264825713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 34944/60000][Iteration 1211][Wall Clock 139.217546638s] Trained 128 records in 0.10061146 seconds. Throughput is 1272.2208 records/second. Loss is 2.2098353. Sequentiale465b572's hyper parameters: Current learning rate is 4.5248868778280545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 1212][Wall Clock 139.31652751s] Trained 128 records in 0.098980872 seconds. Throughput is 1293.1791 records/second. Loss is 2.2168899. Sequentiale465b572's hyper parameters: Current learning rate is 4.5228403437358656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 35200/60000][Iteration 1213][Wall Clock 139.424266624s] Trained 128 records in 0.107739114 seconds. Throughput is 1188.055 records/second. Loss is 2.205519. Sequentiale465b572's hyper parameters: Current learning rate is 4.520795660036167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 1214][Wall Clock 139.522092183s] Trained 128 records in 0.097825559 seconds. Throughput is 1308.4515 records/second. Loss is 2.1982214. Sequentiale465b572's hyper parameters: Current learning rate is 4.5187528242205153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:02 INFO  DistriOptimizer$:408 - [Epoch 3 35456/60000][Iteration 1215][Wall Clock 139.621493285s] Trained 128 records in 0.099401102 seconds. Throughput is 1287.712 records/second. Loss is 2.2099755. Sequentiale465b572's hyper parameters: Current learning rate is 4.516711833785005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 1216][Wall Clock 139.719090581s] Trained 128 records in 0.097597296 seconds. Throughput is 1311.5117 records/second. Loss is 2.2059934. Sequentiale465b572's hyper parameters: Current learning rate is 4.5146726862302486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 35712/60000][Iteration 1217][Wall Clock 139.816517884s] Trained 128 records in 0.097427303 seconds. Throughput is 1313.8002 records/second. Loss is 2.1908493. Sequentiale465b572's hyper parameters: Current learning rate is 4.5126353790613715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 1218][Wall Clock 139.915449196s] Trained 128 records in 0.098931312 seconds. Throughput is 1293.827 records/second. Loss is 2.2138724. Sequentiale465b572's hyper parameters: Current learning rate is 4.510599909788002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 35968/60000][Iteration 1219][Wall Clock 140.015867178s] Trained 128 records in 0.100417982 seconds. Throughput is 1274.6721 records/second. Loss is 2.2066445. Sequentiale465b572's hyper parameters: Current learning rate is 4.5085662759242564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 1220][Wall Clock 140.143095532s] Trained 128 records in 0.127228354 seconds. Throughput is 1006.06506 records/second. Loss is 2.2166653. Sequentiale465b572's hyper parameters: Current learning rate is 4.506534474988733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 36224/60000][Iteration 1221][Wall Clock 140.259157434s] Trained 128 records in 0.116061902 seconds. Throughput is 1102.8597 records/second. Loss is 2.2251823. Sequentiale465b572's hyper parameters: Current learning rate is 4.504504504504505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 1222][Wall Clock 140.375679618s] Trained 128 records in 0.116522184 seconds. Throughput is 1098.5033 records/second. Loss is 2.216015. Sequentiale465b572's hyper parameters: Current learning rate is 4.5024763619990995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 36480/60000][Iteration 1223][Wall Clock 140.475467742s] Trained 128 records in 0.099788124 seconds. Throughput is 1282.7178 records/second. Loss is 2.2121592. Sequentiale465b572's hyper parameters: Current learning rate is 4.500450045004501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 1224][Wall Clock 140.580385025s] Trained 128 records in 0.104917283 seconds. Throughput is 1220.0088 records/second. Loss is 2.2039855. Sequentiale465b572's hyper parameters: Current learning rate is 4.49842555105713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:03 INFO  DistriOptimizer$:408 - [Epoch 3 36736/60000][Iteration 1225][Wall Clock 140.681805594s] Trained 128 records in 0.101420569 seconds. Throughput is 1262.0714 records/second. Loss is 2.1952043. Sequentiale465b572's hyper parameters: Current learning rate is 4.4964028776978414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 1226][Wall Clock 140.77998147s] Trained 128 records in 0.098175876 seconds. Throughput is 1303.7826 records/second. Loss is 2.2174942. Sequentiale465b572's hyper parameters: Current learning rate is 4.4943820224719103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 36992/60000][Iteration 1227][Wall Clock 140.87818826s] Trained 128 records in 0.09820679 seconds. Throughput is 1303.3722 records/second. Loss is 2.2285457. Sequentiale465b572's hyper parameters: Current learning rate is 4.492362982929021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 1228][Wall Clock 140.974942293s] Trained 128 records in 0.096754033 seconds. Throughput is 1322.9423 records/second. Loss is 2.216189. Sequentiale465b572's hyper parameters: Current learning rate is 4.490345756623259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37248/60000][Iteration 1229][Wall Clock 141.08080856s] Trained 128 records in 0.105866267 seconds. Throughput is 1209.0725 records/second. Loss is 2.218802. Sequentiale465b572's hyper parameters: Current learning rate is 4.4883303411131066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 1230][Wall Clock 141.180907463s] Trained 128 records in 0.100098903 seconds. Throughput is 1278.7354 records/second. Loss is 2.2183588. Sequentiale465b572's hyper parameters: Current learning rate is 4.4863167339614175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37504/60000][Iteration 1231][Wall Clock 141.2799069s] Trained 128 records in 0.098999437 seconds. Throughput is 1292.9366 records/second. Loss is 2.2073278. Sequentiale465b572's hyper parameters: Current learning rate is 4.484304932735426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 1232][Wall Clock 141.386422301s] Trained 128 records in 0.106515401 seconds. Throughput is 1201.7042 records/second. Loss is 2.2192848. Sequentiale465b572's hyper parameters: Current learning rate is 4.4822949350067237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37760/60000][Iteration 1233][Wall Clock 141.479468613s] Trained 128 records in 0.093046312 seconds. Throughput is 1375.6589 records/second. Loss is 2.1893241. Sequentiale465b572's hyper parameters: Current learning rate is 4.480286738351254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:04 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 1234][Wall Clock 141.583975282s] Trained 128 records in 0.104506669 seconds. Throughput is 1224.8022 records/second. Loss is 2.2149312. Sequentiale465b572's hyper parameters: Current learning rate is 4.478280340349306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38016/60000][Iteration 1235][Wall Clock 141.677948819s] Trained 128 records in 0.093973537 seconds. Throughput is 1362.0856 records/second. Loss is 2.2137175. Sequentiale465b572's hyper parameters: Current learning rate is 4.476275738585497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 1236][Wall Clock 141.77459156s] Trained 128 records in 0.096642741 seconds. Throughput is 1324.4657 records/second. Loss is 2.2225797. Sequentiale465b572's hyper parameters: Current learning rate is 4.474272930648769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38272/60000][Iteration 1237][Wall Clock 141.868709701s] Trained 128 records in 0.094118141 seconds. Throughput is 1359.9929 records/second. Loss is 2.2256181. Sequentiale465b572's hyper parameters: Current learning rate is 4.47227191413238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 1238][Wall Clock 141.974169947s] Trained 128 records in 0.105460246 seconds. Throughput is 1213.7274 records/second. Loss is 2.2110333. Sequentiale465b572's hyper parameters: Current learning rate is 4.470272686633885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38528/60000][Iteration 1239][Wall Clock 142.070281977s] Trained 128 records in 0.09611203 seconds. Throughput is 1331.7792 records/second. Loss is 2.2095695. Sequentiale465b572's hyper parameters: Current learning rate is 4.4682752457551384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 1240][Wall Clock 142.163442476s] Trained 128 records in 0.093160499 seconds. Throughput is 1373.9728 records/second. Loss is 2.2166104. Sequentiale465b572's hyper parameters: Current learning rate is 4.466279589102278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38784/60000][Iteration 1241][Wall Clock 142.256790974s] Trained 128 records in 0.093348498 seconds. Throughput is 1371.2058 records/second. Loss is 2.2143195. Sequentiale465b572's hyper parameters: Current learning rate is 4.464285714285714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 1242][Wall Clock 142.349238129s] Trained 128 records in 0.092447155 seconds. Throughput is 1384.5748 records/second. Loss is 2.216495. Sequentiale465b572's hyper parameters: Current learning rate is 4.462293618920125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 39040/60000][Iteration 1243][Wall Clock 142.440620879s] Trained 128 records in 0.09138275 seconds. Throughput is 1400.702 records/second. Loss is 2.206443. Sequentiale465b572's hyper parameters: Current learning rate is 4.4603033006244426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 1244][Wall Clock 142.536000176s] Trained 128 records in 0.095379297 seconds. Throughput is 1342.0103 records/second. Loss is 2.216621. Sequentiale465b572's hyper parameters: Current learning rate is 4.458314757021845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:05 INFO  DistriOptimizer$:408 - [Epoch 3 39296/60000][Iteration 1245][Wall Clock 142.637943339s] Trained 128 records in 0.101943163 seconds. Throughput is 1255.6016 records/second. Loss is 2.2006092. Sequentiale465b572's hyper parameters: Current learning rate is 4.4563279857397507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 1246][Wall Clock 142.743450888s] Trained 128 records in 0.105507549 seconds. Throughput is 1213.1833 records/second. Loss is 2.2145312. Sequentiale465b572's hyper parameters: Current learning rate is 4.4543429844097997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 39552/60000][Iteration 1247][Wall Clock 142.844040976s] Trained 128 records in 0.100590088 seconds. Throughput is 1272.4912 records/second. Loss is 2.212597. Sequentiale465b572's hyper parameters: Current learning rate is 4.452359750667854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 1248][Wall Clock 142.947433893s] Trained 128 records in 0.103392917 seconds. Throughput is 1237.9958 records/second. Loss is 2.1991417. Sequentiale465b572's hyper parameters: Current learning rate is 4.4503782821539835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 39808/60000][Iteration 1249][Wall Clock 143.044777773s] Trained 128 records in 0.09734388 seconds. Throughput is 1314.926 records/second. Loss is 2.20156. Sequentiale465b572's hyper parameters: Current learning rate is 4.4483985765124553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 1250][Wall Clock 143.139258569s] Trained 128 records in 0.094480796 seconds. Throughput is 1354.7726 records/second. Loss is 2.2087188. Sequentiale465b572's hyper parameters: Current learning rate is 4.4464206313917296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 40064/60000][Iteration 1251][Wall Clock 143.242975358s] Trained 128 records in 0.103716789 seconds. Throughput is 1234.13 records/second. Loss is 2.2095413. Sequentiale465b572's hyper parameters: Current learning rate is 4.4444444444444447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 1252][Wall Clock 143.345454089s] Trained 128 records in 0.102478731 seconds. Throughput is 1249.0397 records/second. Loss is 2.2016714. Sequentiale465b572's hyper parameters: Current learning rate is 4.4424700133274093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 40320/60000][Iteration 1253][Wall Clock 143.443352499s] Trained 128 records in 0.09789841 seconds. Throughput is 1307.4778 records/second. Loss is 2.203596. Sequentiale465b572's hyper parameters: Current learning rate is 4.4404973357015993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 1254][Wall Clock 143.554670789s] Trained 128 records in 0.11131829 seconds. Throughput is 1149.856 records/second. Loss is 2.2067797. Sequentiale465b572's hyper parameters: Current learning rate is 4.438526409232135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:06 INFO  DistriOptimizer$:408 - [Epoch 3 40576/60000][Iteration 1255][Wall Clock 143.655241648s] Trained 128 records in 0.100570859 seconds. Throughput is 1272.7345 records/second. Loss is 2.2114506. Sequentiale465b572's hyper parameters: Current learning rate is 4.4365572315882877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 1256][Wall Clock 143.751601551s] Trained 128 records in 0.096359903 seconds. Throughput is 1328.3534 records/second. Loss is 2.208626. Sequentiale465b572's hyper parameters: Current learning rate is 4.4345898004434595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 40832/60000][Iteration 1257][Wall Clock 143.845094083s] Trained 128 records in 0.093492532 seconds. Throughput is 1369.0934 records/second. Loss is 2.2202973. Sequentiale465b572's hyper parameters: Current learning rate is 4.432624113475177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 1258][Wall Clock 143.951459014s] Trained 128 records in 0.106364931 seconds. Throughput is 1203.4042 records/second. Loss is 2.2125058. Sequentiale465b572's hyper parameters: Current learning rate is 4.4306601683650863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 41088/60000][Iteration 1259][Wall Clock 144.062198447s] Trained 128 records in 0.110739433 seconds. Throughput is 1155.8665 records/second. Loss is 2.216594. Sequentiale465b572's hyper parameters: Current learning rate is 4.428697962798937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 1260][Wall Clock 144.1693673s] Trained 128 records in 0.107168853 seconds. Throughput is 1194.3768 records/second. Loss is 2.2145522. Sequentiale465b572's hyper parameters: Current learning rate is 4.4267374944665776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 41344/60000][Iteration 1261][Wall Clock 144.271904756s] Trained 128 records in 0.102537456 seconds. Throughput is 1248.3243 records/second. Loss is 2.226837. Sequentiale465b572's hyper parameters: Current learning rate is 4.4247787610619474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 1262][Wall Clock 144.375529929s] Trained 128 records in 0.103625173 seconds. Throughput is 1235.2211 records/second. Loss is 2.1938877. Sequentiale465b572's hyper parameters: Current learning rate is 4.4228217602830603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 41600/60000][Iteration 1263][Wall Clock 144.479889775s] Trained 128 records in 0.104359846 seconds. Throughput is 1226.5254 records/second. Loss is 2.2209938. Sequentiale465b572's hyper parameters: Current learning rate is 4.4208664898320074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:07 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 1264][Wall Clock 144.581947413s] Trained 128 records in 0.102057638 seconds. Throughput is 1254.1932 records/second. Loss is 2.2084663. Sequentiale465b572's hyper parameters: Current learning rate is 4.418912947414936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 41856/60000][Iteration 1265][Wall Clock 144.688880706s] Trained 128 records in 0.106933293 seconds. Throughput is 1197.0079 records/second. Loss is 2.2025175. Sequentiale465b572's hyper parameters: Current learning rate is 4.416961130742049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 1266][Wall Clock 144.787751784s] Trained 128 records in 0.098871078 seconds. Throughput is 1294.6152 records/second. Loss is 2.2054682. Sequentiale465b572's hyper parameters: Current learning rate is 4.415011037527594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42112/60000][Iteration 1267][Wall Clock 144.88766078s] Trained 128 records in 0.099908996 seconds. Throughput is 1281.166 records/second. Loss is 2.2126083. Sequentiale465b572's hyper parameters: Current learning rate is 4.41306266548985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 1268][Wall Clock 144.986038346s] Trained 128 records in 0.098377566 seconds. Throughput is 1301.1097 records/second. Loss is 2.2043965. Sequentiale465b572's hyper parameters: Current learning rate is 4.411116012351124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42368/60000][Iteration 1269][Wall Clock 145.084872686s] Trained 128 records in 0.09883434 seconds. Throughput is 1295.0964 records/second. Loss is 2.2166002. Sequentiale465b572's hyper parameters: Current learning rate is 4.409171075837743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 1270][Wall Clock 145.192903008s] Trained 128 records in 0.108030322 seconds. Throughput is 1184.8525 records/second. Loss is 2.2040863. Sequentiale465b572's hyper parameters: Current learning rate is 4.407227853680035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42624/60000][Iteration 1271][Wall Clock 145.301509963s] Trained 128 records in 0.108606955 seconds. Throughput is 1178.5616 records/second. Loss is 2.2020864. Sequentiale465b572's hyper parameters: Current learning rate is 4.405286343612335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 1272][Wall Clock 145.397856759s] Trained 128 records in 0.096346796 seconds. Throughput is 1328.534 records/second. Loss is 2.1908815. Sequentiale465b572's hyper parameters: Current learning rate is 4.403346543372964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 42880/60000][Iteration 1273][Wall Clock 145.498993908s] Trained 128 records in 0.101137149 seconds. Throughput is 1265.6082 records/second. Loss is 2.2195091. Sequentiale465b572's hyper parameters: Current learning rate is 4.401408450704225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:08 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 1274][Wall Clock 145.608146531s] Trained 128 records in 0.109152623 seconds. Throughput is 1172.6699 records/second. Loss is 2.2039175. Sequentiale465b572's hyper parameters: Current learning rate is 4.3994720633523974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43136/60000][Iteration 1275][Wall Clock 145.710333789s] Trained 128 records in 0.102187258 seconds. Throughput is 1252.6023 records/second. Loss is 2.2233126. Sequentiale465b572's hyper parameters: Current learning rate is 4.3975373790677223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 1276][Wall Clock 145.819411769s] Trained 128 records in 0.10907798 seconds. Throughput is 1173.4724 records/second. Loss is 2.196162. Sequentiale465b572's hyper parameters: Current learning rate is 4.395604395604395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43392/60000][Iteration 1277][Wall Clock 145.923749815s] Trained 128 records in 0.104338046 seconds. Throughput is 1226.7817 records/second. Loss is 2.2151434. Sequentiale465b572's hyper parameters: Current learning rate is 4.3936731107205627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 1278][Wall Clock 146.029348151s] Trained 128 records in 0.105598336 seconds. Throughput is 1212.1403 records/second. Loss is 2.2242486. Sequentiale465b572's hyper parameters: Current learning rate is 4.3917435221783044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43648/60000][Iteration 1279][Wall Clock 146.145875302s] Trained 128 records in 0.116527151 seconds. Throughput is 1098.4564 records/second. Loss is 2.1984305. Sequentiale465b572's hyper parameters: Current learning rate is 4.389815627743635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 1280][Wall Clock 146.279877406s] Trained 128 records in 0.134002104 seconds. Throughput is 955.20886 records/second. Loss is 2.2281137. Sequentiale465b572's hyper parameters: Current learning rate is 4.3878894251864854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 43904/60000][Iteration 1281][Wall Clock 146.382940758s] Trained 128 records in 0.103063352 seconds. Throughput is 1241.9546 records/second. Loss is 2.2104607. Sequentiale465b572's hyper parameters: Current learning rate is 4.3859649122807013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 1282][Wall Clock 146.483649571s] Trained 128 records in 0.100708813 seconds. Throughput is 1270.9911 records/second. Loss is 2.1915755. Sequentiale465b572's hyper parameters: Current learning rate is 4.384042086804034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:09 INFO  DistriOptimizer$:408 - [Epoch 3 44160/60000][Iteration 1283][Wall Clock 146.581714336s] Trained 128 records in 0.098064765 seconds. Throughput is 1305.2599 records/second. Loss is 2.2038288. Sequentiale465b572's hyper parameters: Current learning rate is 4.3821209465381246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 1284][Wall Clock 146.712806214s] Trained 128 records in 0.131091878 seconds. Throughput is 976.4144 records/second. Loss is 2.2104573. Sequentiale465b572's hyper parameters: Current learning rate is 4.380201489268507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 44416/60000][Iteration 1285][Wall Clock 146.810133588s] Trained 128 records in 0.097327374 seconds. Throughput is 1315.149 records/second. Loss is 2.2059882. Sequentiale465b572's hyper parameters: Current learning rate is 4.378283712784589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 1286][Wall Clock 146.909432904s] Trained 128 records in 0.099299316 seconds. Throughput is 1289.032 records/second. Loss is 2.2032623. Sequentiale465b572's hyper parameters: Current learning rate is 4.3763676148796495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 44672/60000][Iteration 1287][Wall Clock 147.00617122s] Trained 128 records in 0.096738316 seconds. Throughput is 1323.1572 records/second. Loss is 2.2134666. Sequentiale465b572's hyper parameters: Current learning rate is 4.374453193350831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 1288][Wall Clock 147.112844855s] Trained 128 records in 0.106673635 seconds. Throughput is 1199.9216 records/second. Loss is 2.2103343. Sequentiale465b572's hyper parameters: Current learning rate is 4.3725404459991256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 44928/60000][Iteration 1289][Wall Clock 147.212980737s] Trained 128 records in 0.100135882 seconds. Throughput is 1278.2631 records/second. Loss is 2.2113664. Sequentiale465b572's hyper parameters: Current learning rate is 4.37062937062937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 1290][Wall Clock 147.307284771s] Trained 128 records in 0.094304034 seconds. Throughput is 1357.312 records/second. Loss is 2.2123046. Sequentiale465b572's hyper parameters: Current learning rate is 4.368719965050241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 45184/60000][Iteration 1291][Wall Clock 147.399492077s] Trained 128 records in 0.092207306 seconds. Throughput is 1388.1764 records/second. Loss is 2.2080529. Sequentiale465b572's hyper parameters: Current learning rate is 4.366812227074236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 1292][Wall Clock 147.49174666s] Trained 128 records in 0.092254583 seconds. Throughput is 1387.4648 records/second. Loss is 2.222476. Sequentiale465b572's hyper parameters: Current learning rate is 4.364906154517678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:10 INFO  DistriOptimizer$:408 - [Epoch 3 45440/60000][Iteration 1293][Wall Clock 147.588291196s] Trained 128 records in 0.096544536 seconds. Throughput is 1325.813 records/second. Loss is 2.212624. Sequentiale465b572's hyper parameters: Current learning rate is 4.3630017452006987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 1294][Wall Clock 147.676942865s] Trained 128 records in 0.088651669 seconds. Throughput is 1443.8531 records/second. Loss is 2.1884432. Sequentiale465b572's hyper parameters: Current learning rate is 4.3610989969472303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 45696/60000][Iteration 1295][Wall Clock 147.769037114s] Trained 128 records in 0.092094249 seconds. Throughput is 1389.8805 records/second. Loss is 2.202933. Sequentiale465b572's hyper parameters: Current learning rate is 4.3591979075850045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 1296][Wall Clock 147.889714669s] Trained 128 records in 0.120677555 seconds. Throughput is 1060.6777 records/second. Loss is 2.214927. Sequentiale465b572's hyper parameters: Current learning rate is 4.357298474945534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 45952/60000][Iteration 1297][Wall Clock 147.983529995s] Trained 128 records in 0.093815326 seconds. Throughput is 1364.3826 records/second. Loss is 2.2059588. Sequentiale465b572's hyper parameters: Current learning rate is 4.355400696864111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 1298][Wall Clock 148.086195998s] Trained 128 records in 0.102666003 seconds. Throughput is 1246.7612 records/second. Loss is 2.205441. Sequentiale465b572's hyper parameters: Current learning rate is 4.3535045711798006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 46208/60000][Iteration 1299][Wall Clock 148.181521571s] Trained 128 records in 0.095325573 seconds. Throughput is 1342.7666 records/second. Loss is 2.207548. Sequentiale465b572's hyper parameters: Current learning rate is 4.351610095735422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 1300][Wall Clock 148.284345457s] Trained 128 records in 0.102823886 seconds. Throughput is 1244.8469 records/second. Loss is 2.222105. Sequentiale465b572's hyper parameters: Current learning rate is 4.3497172683775554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 46464/60000][Iteration 1301][Wall Clock 148.407834792s] Trained 128 records in 0.123489335 seconds. Throughput is 1036.5267 records/second. Loss is 2.2042594. Sequentiale465b572's hyper parameters: Current learning rate is 4.347826086956522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 1302][Wall Clock 148.511696698s] Trained 128 records in 0.103861906 seconds. Throughput is 1232.4056 records/second. Loss is 2.2220778. Sequentiale465b572's hyper parameters: Current learning rate is 4.3459365493263795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:11 INFO  DistriOptimizer$:408 - [Epoch 3 46720/60000][Iteration 1303][Wall Clock 148.608901868s] Trained 128 records in 0.09720517 seconds. Throughput is 1316.8024 records/second. Loss is 2.20516. Sequentiale465b572's hyper parameters: Current learning rate is 4.344048653344917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 1304][Wall Clock 148.705069916s] Trained 128 records in 0.096168048 seconds. Throughput is 1331.0034 records/second. Loss is 2.2170389. Sequentiale465b572's hyper parameters: Current learning rate is 4.342162396873643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 46976/60000][Iteration 1305][Wall Clock 148.803960571s] Trained 128 records in 0.098890655 seconds. Throughput is 1294.3589 records/second. Loss is 2.2174788. Sequentiale465b572's hyper parameters: Current learning rate is 4.3402777777777775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 1306][Wall Clock 148.90611962s] Trained 128 records in 0.102159049 seconds. Throughput is 1252.9482 records/second. Loss is 2.2035956. Sequentiale465b572's hyper parameters: Current learning rate is 4.338394793926248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47232/60000][Iteration 1307][Wall Clock 149.009988201s] Trained 128 records in 0.103868581 seconds. Throughput is 1232.3264 records/second. Loss is 2.206839. Sequentiale465b572's hyper parameters: Current learning rate is 4.336513443191674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 1308][Wall Clock 149.120284163s] Trained 128 records in 0.110295962 seconds. Throughput is 1160.5139 records/second. Loss is 2.1906142. Sequentiale465b572's hyper parameters: Current learning rate is 4.334633723450369E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47488/60000][Iteration 1309][Wall Clock 149.22578539s] Trained 128 records in 0.105501227 seconds. Throughput is 1213.256 records/second. Loss is 2.2084465. Sequentiale465b572's hyper parameters: Current learning rate is 4.3327556325823227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 1310][Wall Clock 149.349604741s] Trained 128 records in 0.123819351 seconds. Throughput is 1033.764 records/second. Loss is 2.2030175. Sequentiale465b572's hyper parameters: Current learning rate is 4.3308791684711995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47744/60000][Iteration 1311][Wall Clock 149.46229128s] Trained 128 records in 0.112686539 seconds. Throughput is 1135.8943 records/second. Loss is 2.2022297. Sequentiale465b572's hyper parameters: Current learning rate is 4.329004329004329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:12 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 1312][Wall Clock 149.550658596s] Trained 128 records in 0.088367316 seconds. Throughput is 1448.4994 records/second. Loss is 2.209739. Sequentiale465b572's hyper parameters: Current learning rate is 4.327131112072696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48000/60000][Iteration 1313][Wall Clock 149.663997889s] Trained 128 records in 0.113339293 seconds. Throughput is 1129.3524 records/second. Loss is 2.2030313. Sequentiale465b572's hyper parameters: Current learning rate is 4.325259515570934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 1314][Wall Clock 149.758285355s] Trained 128 records in 0.094287466 seconds. Throughput is 1357.5505 records/second. Loss is 2.200602. Sequentiale465b572's hyper parameters: Current learning rate is 4.32338953739732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48256/60000][Iteration 1315][Wall Clock 149.856096184s] Trained 128 records in 0.097810829 seconds. Throughput is 1308.6486 records/second. Loss is 2.2014887. Sequentiale465b572's hyper parameters: Current learning rate is 4.32152117545376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 1316][Wall Clock 149.952040159s] Trained 128 records in 0.095943975 seconds. Throughput is 1334.1119 records/second. Loss is 2.1965008. Sequentiale465b572's hyper parameters: Current learning rate is 4.3196544276457883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48512/60000][Iteration 1317][Wall Clock 150.046351707s] Trained 128 records in 0.094311548 seconds. Throughput is 1357.2039 records/second. Loss is 2.2088127. Sequentiale465b572's hyper parameters: Current learning rate is 4.3177892918825565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 1318][Wall Clock 150.141653478s] Trained 128 records in 0.095301771 seconds. Throughput is 1343.102 records/second. Loss is 2.193157. Sequentiale465b572's hyper parameters: Current learning rate is 4.3159257660768235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48768/60000][Iteration 1319][Wall Clock 150.241992841s] Trained 128 records in 0.100339363 seconds. Throughput is 1275.6709 records/second. Loss is 2.206846. Sequentiale465b572's hyper parameters: Current learning rate is 4.314063848144953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 1320][Wall Clock 150.34248281s] Trained 128 records in 0.100489969 seconds. Throughput is 1273.759 records/second. Loss is 2.2076318. Sequentiale465b572's hyper parameters: Current learning rate is 4.3122035360068997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 49024/60000][Iteration 1321][Wall Clock 150.466633147s] Trained 128 records in 0.124150337 seconds. Throughput is 1031.008 records/second. Loss is 2.2088661. Sequentiale465b572's hyper parameters: Current learning rate is 4.3103448275862063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:13 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 1322][Wall Clock 150.568443662s] Trained 128 records in 0.101810515 seconds. Throughput is 1257.2375 records/second. Loss is 2.2139795. Sequentiale465b572's hyper parameters: Current learning rate is 4.308487720809996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 49280/60000][Iteration 1323][Wall Clock 150.664998333s] Trained 128 records in 0.096554671 seconds. Throughput is 1325.6738 records/second. Loss is 2.2247877. Sequentiale465b572's hyper parameters: Current learning rate is 4.306632213608958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 1324][Wall Clock 150.763486559s] Trained 128 records in 0.098488226 seconds. Throughput is 1299.6477 records/second. Loss is 2.1904778. Sequentiale465b572's hyper parameters: Current learning rate is 4.3047783039173483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 49536/60000][Iteration 1325][Wall Clock 150.858644733s] Trained 128 records in 0.095158174 seconds. Throughput is 1345.1288 records/second. Loss is 2.2085133. Sequentiale465b572's hyper parameters: Current learning rate is 4.302925989672978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 1326][Wall Clock 150.971570387s] Trained 128 records in 0.112925654 seconds. Throughput is 1133.4891 records/second. Loss is 2.1953614. Sequentiale465b572's hyper parameters: Current learning rate is 4.3010752688172043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 49792/60000][Iteration 1327][Wall Clock 151.069706108s] Trained 128 records in 0.098135721 seconds. Throughput is 1304.316 records/second. Loss is 2.2096384. Sequentiale465b572's hyper parameters: Current learning rate is 4.299226139294927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 1328][Wall Clock 151.166802194s] Trained 128 records in 0.097096086 seconds. Throughput is 1318.2817 records/second. Loss is 2.219052. Sequentiale465b572's hyper parameters: Current learning rate is 4.297378599054577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 50048/60000][Iteration 1329][Wall Clock 151.264804896s] Trained 128 records in 0.098002702 seconds. Throughput is 1306.0864 records/second. Loss is 2.2092078. Sequentiale465b572's hyper parameters: Current learning rate is 4.2955326460481093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 1330][Wall Clock 151.35901134s] Trained 128 records in 0.094206444 seconds. Throughput is 1358.7181 records/second. Loss is 2.1852114. Sequentiale465b572's hyper parameters: Current learning rate is 4.293688278231001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 50304/60000][Iteration 1331][Wall Clock 151.456590977s] Trained 128 records in 0.097579637 seconds. Throughput is 1311.7491 records/second. Loss is 2.202984. Sequentiale465b572's hyper parameters: Current learning rate is 4.2918454935622315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:14 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 1332][Wall Clock 151.554535115s] Trained 128 records in 0.097944138 seconds. Throughput is 1306.8673 records/second. Loss is 2.212632. Sequentiale465b572's hyper parameters: Current learning rate is 4.29000429000429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 50560/60000][Iteration 1333][Wall Clock 151.652209904s] Trained 128 records in 0.097674789 seconds. Throughput is 1310.4712 records/second. Loss is 2.2112143. Sequentiale465b572's hyper parameters: Current learning rate is 4.2881646655231566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 1334][Wall Clock 151.751343639s] Trained 128 records in 0.099133735 seconds. Throughput is 1291.185 records/second. Loss is 2.1912181. Sequentiale465b572's hyper parameters: Current learning rate is 4.286326618088298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 50816/60000][Iteration 1335][Wall Clock 151.861429377s] Trained 128 records in 0.110085738 seconds. Throughput is 1162.7301 records/second. Loss is 2.1915116. Sequentiale465b572's hyper parameters: Current learning rate is 4.2844901456726646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 1336][Wall Clock 151.994882127s] Trained 128 records in 0.13345275 seconds. Throughput is 959.141 records/second. Loss is 2.2088165. Sequentiale465b572's hyper parameters: Current learning rate is 4.282655246252677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 51072/60000][Iteration 1337][Wall Clock 152.130920256s] Trained 128 records in 0.136038129 seconds. Throughput is 940.9127 records/second. Loss is 2.211086. Sequentiale465b572's hyper parameters: Current learning rate is 4.280821917808219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 1338][Wall Clock 152.228905506s] Trained 128 records in 0.09798525 seconds. Throughput is 1306.319 records/second. Loss is 2.204734. Sequentiale465b572's hyper parameters: Current learning rate is 4.2789901583226365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 51328/60000][Iteration 1339][Wall Clock 152.327370082s] Trained 128 records in 0.098464576 seconds. Throughput is 1299.9598 records/second. Loss is 2.2137494. Sequentiale465b572's hyper parameters: Current learning rate is 4.27715996578272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 1340][Wall Clock 152.425005569s] Trained 128 records in 0.097635487 seconds. Throughput is 1310.9988 records/second. Loss is 2.2066362. Sequentiale465b572's hyper parameters: Current learning rate is 4.275331338178709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:15 INFO  DistriOptimizer$:408 - [Epoch 3 51584/60000][Iteration 1341][Wall Clock 152.524994945s] Trained 128 records in 0.099989376 seconds. Throughput is 1280.136 records/second. Loss is 2.2149193. Sequentiale465b572's hyper parameters: Current learning rate is 4.273504273504274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 1342][Wall Clock 152.61740127s] Trained 128 records in 0.092406325 seconds. Throughput is 1385.1865 records/second. Loss is 2.1973145. Sequentiale465b572's hyper parameters: Current learning rate is 4.271678769756514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 51840/60000][Iteration 1343][Wall Clock 152.718072654s] Trained 128 records in 0.100671384 seconds. Throughput is 1271.4636 records/second. Loss is 2.189488. Sequentiale465b572's hyper parameters: Current learning rate is 4.269854824935952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 1344][Wall Clock 152.823346726s] Trained 128 records in 0.105274072 seconds. Throughput is 1215.8739 records/second. Loss is 2.2025275. Sequentiale465b572's hyper parameters: Current learning rate is 4.268032437046522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52096/60000][Iteration 1345][Wall Clock 152.916420071s] Trained 128 records in 0.093073345 seconds. Throughput is 1375.2595 records/second. Loss is 2.1945233. Sequentiale465b572's hyper parameters: Current learning rate is 4.2662116040955626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 1346][Wall Clock 153.006485744s] Trained 128 records in 0.090065673 seconds. Throughput is 1421.1852 records/second. Loss is 2.2024765. Sequentiale465b572's hyper parameters: Current learning rate is 4.264392324093817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52352/60000][Iteration 1347][Wall Clock 153.140042152s] Trained 128 records in 0.133556408 seconds. Throughput is 958.39655 records/second. Loss is 2.2123272. Sequentiale465b572's hyper parameters: Current learning rate is 4.2625745950554135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 1348][Wall Clock 153.274534197s] Trained 128 records in 0.134492045 seconds. Throughput is 951.7292 records/second. Loss is 2.2148976. Sequentiale465b572's hyper parameters: Current learning rate is 4.26075841499787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52608/60000][Iteration 1349][Wall Clock 153.39100212s] Trained 128 records in 0.116467923 seconds. Throughput is 1099.015 records/second. Loss is 2.18934. Sequentiale465b572's hyper parameters: Current learning rate is 4.258943781942079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 1350][Wall Clock 153.485364027s] Trained 128 records in 0.094361907 seconds. Throughput is 1356.4796 records/second. Loss is 2.1891496. Sequentiale465b572's hyper parameters: Current learning rate is 4.2571306939123026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:16 INFO  DistriOptimizer$:408 - [Epoch 3 52864/60000][Iteration 1351][Wall Clock 153.58001896s] Trained 128 records in 0.094654933 seconds. Throughput is 1352.2803 records/second. Loss is 2.2211256. Sequentiale465b572's hyper parameters: Current learning rate is 4.25531914893617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 1352][Wall Clock 153.67518972s] Trained 128 records in 0.09517076 seconds. Throughput is 1344.9509 records/second. Loss is 2.2143977. Sequentiale465b572's hyper parameters: Current learning rate is 4.253509145044662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53120/60000][Iteration 1353][Wall Clock 153.771583015s] Trained 128 records in 0.096393295 seconds. Throughput is 1327.8932 records/second. Loss is 2.2028556. Sequentiale465b572's hyper parameters: Current learning rate is 4.251700680272108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 1354][Wall Clock 153.86771999s] Trained 128 records in 0.096136975 seconds. Throughput is 1331.4336 records/second. Loss is 2.200664. Sequentiale465b572's hyper parameters: Current learning rate is 4.249893752656184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53376/60000][Iteration 1355][Wall Clock 153.96321719s] Trained 128 records in 0.0954972 seconds. Throughput is 1340.3535 records/second. Loss is 2.2113898. Sequentiale465b572's hyper parameters: Current learning rate is 4.248088360237893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 1356][Wall Clock 154.058932823s] Trained 128 records in 0.095715633 seconds. Throughput is 1337.2946 records/second. Loss is 2.179254. Sequentiale465b572's hyper parameters: Current learning rate is 4.246284501061571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53632/60000][Iteration 1357][Wall Clock 154.153004908s] Trained 128 records in 0.094072085 seconds. Throughput is 1360.6587 records/second. Loss is 2.2014956. Sequentiale465b572's hyper parameters: Current learning rate is 4.244482173174873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 1358][Wall Clock 154.262266942s] Trained 128 records in 0.109262034 seconds. Throughput is 1171.4957 records/second. Loss is 2.198162. Sequentiale465b572's hyper parameters: Current learning rate is 4.2426813746287653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 53888/60000][Iteration 1359][Wall Clock 154.364254609s] Trained 128 records in 0.101987667 seconds. Throughput is 1255.0537 records/second. Loss is 2.1857257. Sequentiale465b572's hyper parameters: Current learning rate is 4.2408821034775233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:17 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 1360][Wall Clock 154.482541323s] Trained 128 records in 0.118286714 seconds. Throughput is 1082.1165 records/second. Loss is 2.1986291. Sequentiale465b572's hyper parameters: Current learning rate is 4.23908435777872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54144/60000][Iteration 1361][Wall Clock 154.615985351s] Trained 128 records in 0.133444028 seconds. Throughput is 959.2037 records/second. Loss is 2.2194784. Sequentiale465b572's hyper parameters: Current learning rate is 4.2372881355932197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 1362][Wall Clock 154.742997169s] Trained 128 records in 0.127011818 seconds. Throughput is 1007.7802 records/second. Loss is 2.1965501. Sequentiale465b572's hyper parameters: Current learning rate is 4.235493434985176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54400/60000][Iteration 1363][Wall Clock 154.849016695s] Trained 128 records in 0.106019526 seconds. Throughput is 1207.3247 records/second. Loss is 2.216989. Sequentiale465b572's hyper parameters: Current learning rate is 4.233700254022015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 1364][Wall Clock 154.991067857s] Trained 128 records in 0.142051162 seconds. Throughput is 901.0838 records/second. Loss is 2.2020996. Sequentiale465b572's hyper parameters: Current learning rate is 4.2319085907744394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54656/60000][Iteration 1365][Wall Clock 155.103618402s] Trained 128 records in 0.112550545 seconds. Throughput is 1137.2668 records/second. Loss is 2.2102048. Sequentiale465b572's hyper parameters: Current learning rate is 4.230118443316413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 1366][Wall Clock 155.228546527s] Trained 128 records in 0.124928125 seconds. Throughput is 1024.5891 records/second. Loss is 2.207745. Sequentiale465b572's hyper parameters: Current learning rate is 4.2283298097251583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 54912/60000][Iteration 1367][Wall Clock 155.327179884s] Trained 128 records in 0.098633357 seconds. Throughput is 1297.7355 records/second. Loss is 2.202948. Sequentiale465b572's hyper parameters: Current learning rate is 4.2265426880811494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 1368][Wall Clock 155.438999782s] Trained 128 records in 0.111819898 seconds. Throughput is 1144.6979 records/second. Loss is 2.1899598. Sequentiale465b572's hyper parameters: Current learning rate is 4.224757076468103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:18 INFO  DistriOptimizer$:408 - [Epoch 3 55168/60000][Iteration 1369][Wall Clock 155.547907953s] Trained 128 records in 0.108908171 seconds. Throughput is 1175.3021 records/second. Loss is 2.198238. Sequentiale465b572's hyper parameters: Current learning rate is 4.2229729729729727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 1370][Wall Clock 155.680632317s] Trained 128 records in 0.132724364 seconds. Throughput is 964.4047 records/second. Loss is 2.2010188. Sequentiale465b572's hyper parameters: Current learning rate is 4.221190375685944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 55424/60000][Iteration 1371][Wall Clock 155.794072002s] Trained 128 records in 0.113439685 seconds. Throughput is 1128.3529 records/second. Loss is 2.2073178. Sequentiale465b572's hyper parameters: Current learning rate is 4.219409282700422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 1372][Wall Clock 155.896362504s] Trained 128 records in 0.102290502 seconds. Throughput is 1251.338 records/second. Loss is 2.1942651. Sequentiale465b572's hyper parameters: Current learning rate is 4.2176296921130323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 55680/60000][Iteration 1373][Wall Clock 156.002340703s] Trained 128 records in 0.105978199 seconds. Throughput is 1207.7955 records/second. Loss is 2.2025788. Sequentiale465b572's hyper parameters: Current learning rate is 4.215851602023609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 1374][Wall Clock 156.106570524s] Trained 128 records in 0.104229821 seconds. Throughput is 1228.0554 records/second. Loss is 2.2039027. Sequentiale465b572's hyper parameters: Current learning rate is 4.214075010535187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 55936/60000][Iteration 1375][Wall Clock 156.20558854s] Trained 128 records in 0.099018016 seconds. Throughput is 1292.6941 records/second. Loss is 2.1921744. Sequentiale465b572's hyper parameters: Current learning rate is 4.2122999157540015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 1376][Wall Clock 156.311523787s] Trained 128 records in 0.105935247 seconds. Throughput is 1208.2853 records/second. Loss is 2.204404. Sequentiale465b572's hyper parameters: Current learning rate is 4.210526315789474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 56192/60000][Iteration 1377][Wall Clock 156.410652617s] Trained 128 records in 0.09912883 seconds. Throughput is 1291.249 records/second. Loss is 2.2022927. Sequentiale465b572's hyper parameters: Current learning rate is 4.208754208754208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:19 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 1378][Wall Clock 156.511039814s] Trained 128 records in 0.100387197 seconds. Throughput is 1275.063 records/second. Loss is 2.204693. Sequentiale465b572's hyper parameters: Current learning rate is 4.206983592763989E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 56448/60000][Iteration 1379][Wall Clock 156.606527005s] Trained 128 records in 0.095487191 seconds. Throughput is 1340.4939 records/second. Loss is 2.2037115. Sequentiale465b572's hyper parameters: Current learning rate is 4.2052144659377626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 1380][Wall Clock 156.70481612s] Trained 128 records in 0.098289115 seconds. Throughput is 1302.2805 records/second. Loss is 2.1850097. Sequentiale465b572's hyper parameters: Current learning rate is 4.203446826397646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 56704/60000][Iteration 1381][Wall Clock 156.803106552s] Trained 128 records in 0.098290432 seconds. Throughput is 1302.2631 records/second. Loss is 2.1990955. Sequentiale465b572's hyper parameters: Current learning rate is 4.201680672268908E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 1382][Wall Clock 156.911103142s] Trained 128 records in 0.10799659 seconds. Throughput is 1185.2227 records/second. Loss is 2.1867795. Sequentiale465b572's hyper parameters: Current learning rate is 4.199916001679966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 56960/60000][Iteration 1383][Wall Clock 157.034031885s] Trained 128 records in 0.122928743 seconds. Throughput is 1041.2537 records/second. Loss is 2.2014933. Sequentiale465b572's hyper parameters: Current learning rate is 4.1981528127623844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 1384][Wall Clock 157.135373154s] Trained 128 records in 0.101341269 seconds. Throughput is 1263.059 records/second. Loss is 2.1869678. Sequentiale465b572's hyper parameters: Current learning rate is 4.19639110365086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 57216/60000][Iteration 1385][Wall Clock 157.228831808s] Trained 128 records in 0.093458654 seconds. Throughput is 1369.5896 records/second. Loss is 2.1995566. Sequentiale465b572's hyper parameters: Current learning rate is 4.194630872483221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 1386][Wall Clock 157.323234535s] Trained 128 records in 0.094402727 seconds. Throughput is 1355.893 records/second. Loss is 2.2067041. Sequentiale465b572's hyper parameters: Current learning rate is 4.1928721174004196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 57472/60000][Iteration 1387][Wall Clock 157.415887675s] Trained 128 records in 0.09265314 seconds. Throughput is 1381.4966 records/second. Loss is 2.1979208. Sequentiale465b572's hyper parameters: Current learning rate is 4.1911148365465214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:20 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 1388][Wall Clock 157.518251499s] Trained 128 records in 0.102363824 seconds. Throughput is 1250.4418 records/second. Loss is 2.194837. Sequentiale465b572's hyper parameters: Current learning rate is 4.1893590280687055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 57728/60000][Iteration 1389][Wall Clock 157.624569175s] Trained 128 records in 0.106317676 seconds. Throughput is 1203.939 records/second. Loss is 2.194543. Sequentiale465b572's hyper parameters: Current learning rate is 4.187604690117253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 1390][Wall Clock 157.718418824s] Trained 128 records in 0.093849649 seconds. Throughput is 1363.8835 records/second. Loss is 2.1927574. Sequentiale465b572's hyper parameters: Current learning rate is 4.1858518208455416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 57984/60000][Iteration 1391][Wall Clock 157.816230264s] Trained 128 records in 0.09781144 seconds. Throughput is 1308.6404 records/second. Loss is 2.1979938. Sequentiale465b572's hyper parameters: Current learning rate is 4.1841004184100416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 1392][Wall Clock 157.908606765s] Trained 128 records in 0.092376501 seconds. Throughput is 1385.6338 records/second. Loss is 2.1973524. Sequentiale465b572's hyper parameters: Current learning rate is 4.182350480970305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58240/60000][Iteration 1393][Wall Clock 158.000853317s] Trained 128 records in 0.092246552 seconds. Throughput is 1387.5857 records/second. Loss is 2.2007043. Sequentiale465b572's hyper parameters: Current learning rate is 4.1806020066889626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 1394][Wall Clock 158.095876819s] Trained 128 records in 0.095023502 seconds. Throughput is 1347.0352 records/second. Loss is 2.1992664. Sequentiale465b572's hyper parameters: Current learning rate is 4.178854993731718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58496/60000][Iteration 1395][Wall Clock 158.192426528s] Trained 128 records in 0.096549709 seconds. Throughput is 1325.742 records/second. Loss is 2.2058876. Sequentiale465b572's hyper parameters: Current learning rate is 4.177109440267335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 1396][Wall Clock 158.300607654s] Trained 128 records in 0.108181126 seconds. Throughput is 1183.2008 records/second. Loss is 2.2051704. Sequentiale465b572's hyper parameters: Current learning rate is 4.175365344467641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58752/60000][Iteration 1397][Wall Clock 158.411353682s] Trained 128 records in 0.110746028 seconds. Throughput is 1155.7977 records/second. Loss is 2.1997116. Sequentiale465b572's hyper parameters: Current learning rate is 4.1736227045075126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:21 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 1398][Wall Clock 158.507061381s] Trained 128 records in 0.095707699 seconds. Throughput is 1337.4055 records/second. Loss is 2.1919873. Sequentiale465b572's hyper parameters: Current learning rate is 4.1718815185648727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59008/60000][Iteration 1399][Wall Clock 158.599350817s] Trained 128 records in 0.092289436 seconds. Throughput is 1386.941 records/second. Loss is 2.1971955. Sequentiale465b572's hyper parameters: Current learning rate is 4.170141784820684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 1400][Wall Clock 158.694478554s] Trained 128 records in 0.095127737 seconds. Throughput is 1345.5592 records/second. Loss is 2.2067735. Sequentiale465b572's hyper parameters: Current learning rate is 4.1684035014589413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59264/60000][Iteration 1401][Wall Clock 158.786772176s] Trained 128 records in 0.092293622 seconds. Throughput is 1386.878 records/second. Loss is 2.1978621. Sequentiale465b572's hyper parameters: Current learning rate is 4.1666666666666664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 1402][Wall Clock 158.883921303s] Trained 128 records in 0.097149127 seconds. Throughput is 1317.562 records/second. Loss is 2.2036867. Sequentiale465b572's hyper parameters: Current learning rate is 4.1649312786339027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59520/60000][Iteration 1403][Wall Clock 158.977977012s] Trained 128 records in 0.094055709 seconds. Throughput is 1360.8955 records/second. Loss is 2.1809254. Sequentiale465b572's hyper parameters: Current learning rate is 4.1631973355537054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 1404][Wall Clock 159.072587296s] Trained 128 records in 0.094610284 seconds. Throughput is 1352.9185 records/second. Loss is 2.1990855. Sequentiale465b572's hyper parameters: Current learning rate is 4.161464835622139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59776/60000][Iteration 1405][Wall Clock 159.165505978s] Trained 128 records in 0.092918682 seconds. Throughput is 1377.5486 records/second. Loss is 2.1978652. Sequentiale465b572's hyper parameters: Current learning rate is 4.1597337770382697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 1406][Wall Clock 159.265797243s] Trained 128 records in 0.100291265 seconds. Throughput is 1276.2826 records/second. Loss is 2.197972. Sequentiale465b572's hyper parameters: Current learning rate is 4.1580041580041577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:408 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 159.363926335s] Trained 128 records in 0.098129092 seconds. Throughput is 1304.4042 records/second. Loss is 2.2024376. Sequentiale465b572's hyper parameters: Current learning rate is 4.1562759767248546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:22 INFO  DistriOptimizer$:452 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 159.363926335s] Epoch finished. Wall clock time is 160679.380337 ms
2019-10-15 20:07:22 INFO  DistriOptimizer$:111 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 159.363926335s] Validate model...
2019-10-15 20:07:23 INFO  DistriOptimizer$:178 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 159.363926335s] validate model throughput is 9441.964 records/second
2019-10-15 20:07:23 INFO  DistriOptimizer$:181 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 159.363926335s] Top1Accuracy is Accuracy(correct: 3467, count: 10000, accuracy: 0.3467)
2019-10-15 20:07:23 INFO  DistriOptimizer$:221 - [Wall Clock 160.679380337s] Save model to /tmp/lenet5/20191015_200441
2019-10-15 20:07:23 INFO  DistriOptimizer$:226 - [Wall Clock 160.679380337s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@c83982c to /tmp/lenet5/20191015_200441
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 128/60000][Iteration 1408][Wall Clock 160.78644362s] Trained 128 records in 0.107063283 seconds. Throughput is 1195.5546 records/second. Loss is 2.2030265. Sequentiale465b572's hyper parameters: Current learning rate is 4.154549231408392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 1409][Wall Clock 160.885219566s] Trained 128 records in 0.098775946 seconds. Throughput is 1295.862 records/second. Loss is 2.1847296. Sequentiale465b572's hyper parameters: Current learning rate is 4.152823920265781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 384/60000][Iteration 1410][Wall Clock 160.983465855s] Trained 128 records in 0.098246289 seconds. Throughput is 1302.8481 records/second. Loss is 2.1929064. Sequentiale465b572's hyper parameters: Current learning rate is 4.151100041511001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 1411][Wall Clock 161.07422274s] Trained 128 records in 0.090756885 seconds. Throughput is 1410.3613 records/second. Loss is 2.1861584. Sequentiale465b572's hyper parameters: Current learning rate is 4.149377593360996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 640/60000][Iteration 1412][Wall Clock 161.177804609s] Trained 128 records in 0.103581869 seconds. Throughput is 1235.7375 records/second. Loss is 2.2072628. Sequentiale465b572's hyper parameters: Current learning rate is 4.14765657403567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 1413][Wall Clock 161.286105066s] Trained 128 records in 0.108300457 seconds. Throughput is 1181.8972 records/second. Loss is 2.1935513. Sequentiale465b572's hyper parameters: Current learning rate is 4.1459369817578774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 896/60000][Iteration 1414][Wall Clock 161.420190883s] Trained 128 records in 0.134085817 seconds. Throughput is 954.6125 records/second. Loss is 2.200184. Sequentiale465b572's hyper parameters: Current learning rate is 4.144218814753419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 1415][Wall Clock 161.514304007s] Trained 128 records in 0.094113124 seconds. Throughput is 1360.0653 records/second. Loss is 2.212187. Sequentiale465b572's hyper parameters: Current learning rate is 4.1425020712510365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 1152/60000][Iteration 1416][Wall Clock 161.612147375s] Trained 128 records in 0.097843368 seconds. Throughput is 1308.2133 records/second. Loss is 2.200163. Sequentiale465b572's hyper parameters: Current learning rate is 4.1407867494824016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:24 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 1417][Wall Clock 161.705501884s] Trained 128 records in 0.093354509 seconds. Throughput is 1371.1176 records/second. Loss is 2.1896372. Sequentiale465b572's hyper parameters: Current learning rate is 4.139072847682119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 1408/60000][Iteration 1418][Wall Clock 161.804646225s] Trained 128 records in 0.099144341 seconds. Throughput is 1291.047 records/second. Loss is 2.1939876. Sequentiale465b572's hyper parameters: Current learning rate is 4.1373603640877123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 1419][Wall Clock 161.902912322s] Trained 128 records in 0.098266097 seconds. Throughput is 1302.5856 records/second. Loss is 2.1877. Sequentiale465b572's hyper parameters: Current learning rate is 4.1356492969396195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 1664/60000][Iteration 1420][Wall Clock 162.007057345s] Trained 128 records in 0.104145023 seconds. Throughput is 1229.0554 records/second. Loss is 2.1971874. Sequentiale465b572's hyper parameters: Current learning rate is 4.1339396444811904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 1421][Wall Clock 162.093572515s] Trained 128 records in 0.08651517 seconds. Throughput is 1479.5093 records/second. Loss is 2.1953187. Sequentiale465b572's hyper parameters: Current learning rate is 4.132231404958678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 1920/60000][Iteration 1422][Wall Clock 162.18474829s] Trained 128 records in 0.091175775 seconds. Throughput is 1403.8817 records/second. Loss is 2.1966963. Sequentiale465b572's hyper parameters: Current learning rate is 4.1305245766212306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 1423][Wall Clock 162.279908516s] Trained 128 records in 0.095160226 seconds. Throughput is 1345.0999 records/second. Loss is 2.1905136. Sequentiale465b572's hyper parameters: Current learning rate is 4.128819157720892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 2176/60000][Iteration 1424][Wall Clock 162.375970457s] Trained 128 records in 0.096061941 seconds. Throughput is 1332.4736 records/second. Loss is 2.1963356. Sequentiale465b572's hyper parameters: Current learning rate is 4.127115146512588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 1425][Wall Clock 162.465563165s] Trained 128 records in 0.089592708 seconds. Throughput is 1428.6876 records/second. Loss is 2.191397. Sequentiale465b572's hyper parameters: Current learning rate is 4.1254125412541255E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 2432/60000][Iteration 1426][Wall Clock 162.562713124s] Trained 128 records in 0.097149959 seconds. Throughput is 1317.5507 records/second. Loss is 2.1913342. Sequentiale465b572's hyper parameters: Current learning rate is 4.123711340206186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:25 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 1427][Wall Clock 162.659533513s] Trained 128 records in 0.096820389 seconds. Throughput is 1322.0355 records/second. Loss is 2.1997347. Sequentiale465b572's hyper parameters: Current learning rate is 4.1220115416323167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 2688/60000][Iteration 1428][Wall Clock 162.75065935s] Trained 128 records in 0.091125837 seconds. Throughput is 1404.651 records/second. Loss is 2.1930985. Sequentiale465b572's hyper parameters: Current learning rate is 4.1203131437989287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 1429][Wall Clock 162.842710848s] Trained 128 records in 0.092051498 seconds. Throughput is 1390.526 records/second. Loss is 2.1972291. Sequentiale465b572's hyper parameters: Current learning rate is 4.1186161449752884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 2944/60000][Iteration 1430][Wall Clock 162.935654752s] Trained 128 records in 0.092943904 seconds. Throughput is 1377.1747 records/second. Loss is 2.2033367. Sequentiale465b572's hyper parameters: Current learning rate is 4.116920543433511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 1431][Wall Clock 163.031653872s] Trained 128 records in 0.09599912 seconds. Throughput is 1333.3456 records/second. Loss is 2.210047. Sequentiale465b572's hyper parameters: Current learning rate is 4.11522633744856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3200/60000][Iteration 1432][Wall Clock 163.127866982s] Trained 128 records in 0.09621311 seconds. Throughput is 1330.38 records/second. Loss is 2.203028. Sequentiale465b572's hyper parameters: Current learning rate is 4.1135335252982314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 1433][Wall Clock 163.223030599s] Trained 128 records in 0.095163617 seconds. Throughput is 1345.0519 records/second. Loss is 2.2125604. Sequentiale465b572's hyper parameters: Current learning rate is 4.111842105263158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3456/60000][Iteration 1434][Wall Clock 163.316482554s] Trained 128 records in 0.093451955 seconds. Throughput is 1369.6877 records/second. Loss is 2.204361. Sequentiale465b572's hyper parameters: Current learning rate is 4.1101520756267986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 1435][Wall Clock 163.420241206s] Trained 128 records in 0.103758652 seconds. Throughput is 1233.6321 records/second. Loss is 2.1948755. Sequentiale465b572's hyper parameters: Current learning rate is 4.108463434675431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3712/60000][Iteration 1436][Wall Clock 163.551198462s] Trained 128 records in 0.130957256 seconds. Throughput is 977.41815 records/second. Loss is 2.1889253. Sequentiale465b572's hyper parameters: Current learning rate is 4.106776180698152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:26 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 1437][Wall Clock 163.676378851s] Trained 128 records in 0.125180389 seconds. Throughput is 1022.52435 records/second. Loss is 2.205327. Sequentiale465b572's hyper parameters: Current learning rate is 4.105090311986864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 3968/60000][Iteration 1438][Wall Clock 163.82144813s] Trained 128 records in 0.145069279 seconds. Throughput is 882.33704 records/second. Loss is 2.1925082. Sequentiale465b572's hyper parameters: Current learning rate is 4.1034058268362735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 1439][Wall Clock 163.924715121s] Trained 128 records in 0.103266991 seconds. Throughput is 1239.5055 records/second. Loss is 2.2092073. Sequentiale465b572's hyper parameters: Current learning rate is 4.101722723543889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4224/60000][Iteration 1440][Wall Clock 164.022602855s] Trained 128 records in 0.097887734 seconds. Throughput is 1307.6205 records/second. Loss is 2.1853168. Sequentiale465b572's hyper parameters: Current learning rate is 4.100041000410004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 1441][Wall Clock 164.121902331s] Trained 128 records in 0.099299476 seconds. Throughput is 1289.03 records/second. Loss is 2.1862712. Sequentiale465b572's hyper parameters: Current learning rate is 4.098360655737705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4480/60000][Iteration 1442][Wall Clock 164.219000034s] Trained 128 records in 0.097097703 seconds. Throughput is 1318.2598 records/second. Loss is 2.1909087. Sequentiale465b572's hyper parameters: Current learning rate is 4.096681687832856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 1443][Wall Clock 164.320464369s] Trained 128 records in 0.101464335 seconds. Throughput is 1261.527 records/second. Loss is 2.1885421. Sequentiale465b572's hyper parameters: Current learning rate is 4.0950040950040947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4736/60000][Iteration 1444][Wall Clock 164.416353324s] Trained 128 records in 0.095888955 seconds. Throughput is 1334.8773 records/second. Loss is 2.1935213. Sequentiale465b572's hyper parameters: Current learning rate is 4.0933278755628325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 1445][Wall Clock 164.513977025s] Trained 128 records in 0.097623701 seconds. Throughput is 1311.1571 records/second. Loss is 2.2047796. Sequentiale465b572's hyper parameters: Current learning rate is 4.091653027823241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:27 INFO  DistriOptimizer$:408 - [Epoch 4 4992/60000][Iteration 1446][Wall Clock 164.637846592s] Trained 128 records in 0.123869567 seconds. Throughput is 1033.345 records/second. Loss is 2.1925066. Sequentiale465b572's hyper parameters: Current learning rate is 4.089979550102249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 1447][Wall Clock 164.729883574s] Trained 128 records in 0.092036982 seconds. Throughput is 1390.7452 records/second. Loss is 2.1951113. Sequentiale465b572's hyper parameters: Current learning rate is 4.088307440719543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5248/60000][Iteration 1448][Wall Clock 164.83320075s] Trained 128 records in 0.103317176 seconds. Throughput is 1238.9033 records/second. Loss is 2.2018843. Sequentiale465b572's hyper parameters: Current learning rate is 4.086636697997548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 1449][Wall Clock 164.932957748s] Trained 128 records in 0.099756998 seconds. Throughput is 1283.1179 records/second. Loss is 2.2156258. Sequentiale465b572's hyper parameters: Current learning rate is 4.084967320261438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5504/60000][Iteration 1450][Wall Clock 165.03315286s] Trained 128 records in 0.100195112 seconds. Throughput is 1277.5074 records/second. Loss is 2.1772509. Sequentiale465b572's hyper parameters: Current learning rate is 4.083299305839118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 1451][Wall Clock 165.13887302s] Trained 128 records in 0.10572016 seconds. Throughput is 1210.7435 records/second. Loss is 2.1922123. Sequentiale465b572's hyper parameters: Current learning rate is 4.081632653061224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5760/60000][Iteration 1452][Wall Clock 165.233865827s] Trained 128 records in 0.094992807 seconds. Throughput is 1347.4705 records/second. Loss is 2.1914396. Sequentiale465b572's hyper parameters: Current learning rate is 4.079967360261118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 1453][Wall Clock 165.33243223s] Trained 128 records in 0.098566403 seconds. Throughput is 1298.617 records/second. Loss is 2.1725414. Sequentiale465b572's hyper parameters: Current learning rate is 4.078303425774878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 6016/60000][Iteration 1454][Wall Clock 165.425675362s] Trained 128 records in 0.093243132 seconds. Throughput is 1372.7552 records/second. Loss is 2.208256. Sequentiale465b572's hyper parameters: Current learning rate is 4.076640847941296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 1455][Wall Clock 165.522506512s] Trained 128 records in 0.09683115 seconds. Throughput is 1321.8887 records/second. Loss is 2.1911306. Sequentiale465b572's hyper parameters: Current learning rate is 4.074979625101875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:28 INFO  DistriOptimizer$:408 - [Epoch 4 6272/60000][Iteration 1456][Wall Clock 165.620015119s] Trained 128 records in 0.097508607 seconds. Throughput is 1312.7046 records/second. Loss is 2.192423. Sequentiale465b572's hyper parameters: Current learning rate is 4.073319755600815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 1457][Wall Clock 165.719470266s] Trained 128 records in 0.099455147 seconds. Throughput is 1287.0123 records/second. Loss is 2.1860263. Sequentiale465b572's hyper parameters: Current learning rate is 4.0716612377850165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 6528/60000][Iteration 1458][Wall Clock 165.816700275s] Trained 128 records in 0.097230009 seconds. Throughput is 1316.466 records/second. Loss is 2.1996055. Sequentiale465b572's hyper parameters: Current learning rate is 4.0700040700040704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 1459][Wall Clock 165.91221798s] Trained 128 records in 0.095517705 seconds. Throughput is 1340.0657 records/second. Loss is 2.2065587. Sequentiale465b572's hyper parameters: Current learning rate is 4.068348250610252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 6784/60000][Iteration 1460][Wall Clock 166.008025378s] Trained 128 records in 0.095807398 seconds. Throughput is 1336.0138 records/second. Loss is 2.204308. Sequentiale465b572's hyper parameters: Current learning rate is 4.0666937779585197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 1461][Wall Clock 166.103404687s] Trained 128 records in 0.095379309 seconds. Throughput is 1342.0101 records/second. Loss is 2.1909194. Sequentiale465b572's hyper parameters: Current learning rate is 4.065040650406504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 7040/60000][Iteration 1462][Wall Clock 166.202569913s] Trained 128 records in 0.099165226 seconds. Throughput is 1290.7751 records/second. Loss is 2.1979237. Sequentiale465b572's hyper parameters: Current learning rate is 4.063388866314506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 1463][Wall Clock 166.309500156s] Trained 128 records in 0.106930243 seconds. Throughput is 1197.0421 records/second. Loss is 2.2055. Sequentiale465b572's hyper parameters: Current learning rate is 4.061738424045492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 7296/60000][Iteration 1464][Wall Clock 166.437091381s] Trained 128 records in 0.127591225 seconds. Throughput is 1003.2038 records/second. Loss is 2.192803. Sequentiale465b572's hyper parameters: Current learning rate is 4.060089321965083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 1465][Wall Clock 166.542556059s] Trained 128 records in 0.105464678 seconds. Throughput is 1213.6765 records/second. Loss is 2.1842713. Sequentiale465b572's hyper parameters: Current learning rate is 4.0584415584415587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:29 INFO  DistriOptimizer$:408 - [Epoch 4 7552/60000][Iteration 1466][Wall Clock 166.640937877s] Trained 128 records in 0.098381818 seconds. Throughput is 1301.0535 records/second. Loss is 2.2001677. Sequentiale465b572's hyper parameters: Current learning rate is 4.056795131845842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 1467][Wall Clock 166.74351493s] Trained 128 records in 0.102577053 seconds. Throughput is 1247.8424 records/second. Loss is 2.1919286. Sequentiale465b572's hyper parameters: Current learning rate is 4.0551500405515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 7808/60000][Iteration 1468][Wall Clock 166.837467397s] Trained 128 records in 0.093952467 seconds. Throughput is 1362.391 records/second. Loss is 2.2082477. Sequentiale465b572's hyper parameters: Current learning rate is 4.0535062829347385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 1469][Wall Clock 166.934346988s] Trained 128 records in 0.096879591 seconds. Throughput is 1321.2277 records/second. Loss is 2.2083092. Sequentiale465b572's hyper parameters: Current learning rate is 4.0518638573743926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8064/60000][Iteration 1470][Wall Clock 167.031370542s] Trained 128 records in 0.097023554 seconds. Throughput is 1319.2673 records/second. Loss is 2.20161. Sequentiale465b572's hyper parameters: Current learning rate is 4.0502227622519235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 1471][Wall Clock 167.133863784s] Trained 128 records in 0.102493242 seconds. Throughput is 1248.8628 records/second. Loss is 2.1833165. Sequentiale465b572's hyper parameters: Current learning rate is 4.0485829959514174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8320/60000][Iteration 1472][Wall Clock 167.245716187s] Trained 128 records in 0.111852403 seconds. Throughput is 1144.3652 records/second. Loss is 2.189959. Sequentiale465b572's hyper parameters: Current learning rate is 4.046944556859571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 1473][Wall Clock 167.345184748s] Trained 128 records in 0.099468561 seconds. Throughput is 1286.8387 records/second. Loss is 2.2034166. Sequentiale465b572's hyper parameters: Current learning rate is 4.045307443365696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8576/60000][Iteration 1474][Wall Clock 167.445272549s] Trained 128 records in 0.100087801 seconds. Throughput is 1278.8772 records/second. Loss is 2.1901786. Sequentiale465b572's hyper parameters: Current learning rate is 4.043671653861707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 1475][Wall Clock 167.538320881s] Trained 128 records in 0.093048332 seconds. Throughput is 1375.6292 records/second. Loss is 2.1870804. Sequentiale465b572's hyper parameters: Current learning rate is 4.042037186742118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:30 INFO  DistriOptimizer$:408 - [Epoch 4 8832/60000][Iteration 1476][Wall Clock 167.628829765s] Trained 128 records in 0.090508884 seconds. Throughput is 1414.2258 records/second. Loss is 2.1880379. Sequentiale465b572's hyper parameters: Current learning rate is 4.0404040404040404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 1477][Wall Clock 167.720656086s] Trained 128 records in 0.091826321 seconds. Throughput is 1393.9359 records/second. Loss is 2.2003014. Sequentiale465b572's hyper parameters: Current learning rate is 4.038772213247173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9088/60000][Iteration 1478][Wall Clock 167.811056252s] Trained 128 records in 0.090400166 seconds. Throughput is 1415.9266 records/second. Loss is 2.2039795. Sequentiale465b572's hyper parameters: Current learning rate is 4.037141703673799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 1479][Wall Clock 167.903383902s] Trained 128 records in 0.09232765 seconds. Throughput is 1386.367 records/second. Loss is 2.1785617. Sequentiale465b572's hyper parameters: Current learning rate is 4.0355125100887816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9344/60000][Iteration 1480][Wall Clock 167.997265224s] Trained 128 records in 0.093881322 seconds. Throughput is 1363.4235 records/second. Loss is 2.2026076. Sequentiale465b572's hyper parameters: Current learning rate is 4.033884630899556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 1481][Wall Clock 168.091796218s] Trained 128 records in 0.094530994 seconds. Throughput is 1354.0532 records/second. Loss is 2.2069693. Sequentiale465b572's hyper parameters: Current learning rate is 4.032258064516129E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9600/60000][Iteration 1482][Wall Clock 168.18174023s] Trained 128 records in 0.089944012 seconds. Throughput is 1423.1075 records/second. Loss is 2.186784. Sequentiale465b572's hyper parameters: Current learning rate is 4.0306328093510683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 1483][Wall Clock 168.278525317s] Trained 128 records in 0.096785087 seconds. Throughput is 1322.5178 records/second. Loss is 2.2014534. Sequentiale465b572's hyper parameters: Current learning rate is 4.0290088638195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9856/60000][Iteration 1484][Wall Clock 168.385923683s] Trained 128 records in 0.107398366 seconds. Throughput is 1191.8245 records/second. Loss is 2.1981514. Sequentiale465b572's hyper parameters: Current learning rate is 4.027386226339106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 1485][Wall Clock 168.484119486s] Trained 128 records in 0.098195803 seconds. Throughput is 1303.518 records/second. Loss is 2.2020326. Sequentiale465b572's hyper parameters: Current learning rate is 4.0257648953301127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 10112/60000][Iteration 1486][Wall Clock 168.58227894s] Trained 128 records in 0.098159454 seconds. Throughput is 1304.0007 records/second. Loss is 2.2100203. Sequentiale465b572's hyper parameters: Current learning rate is 4.024144869215291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:31 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 1487][Wall Clock 168.677995773s] Trained 128 records in 0.095716833 seconds. Throughput is 1337.2778 records/second. Loss is 2.2044058. Sequentiale465b572's hyper parameters: Current learning rate is 4.022526146419952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 10368/60000][Iteration 1488][Wall Clock 168.774549768s] Trained 128 records in 0.096553995 seconds. Throughput is 1325.6831 records/second. Loss is 2.1965158. Sequentiale465b572's hyper parameters: Current learning rate is 4.020908725371934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 1489][Wall Clock 168.891740876s] Trained 128 records in 0.117191108 seconds. Throughput is 1092.233 records/second. Loss is 2.217791. Sequentiale465b572's hyper parameters: Current learning rate is 4.0192926045016077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 10624/60000][Iteration 1490][Wall Clock 169.025847178s] Trained 128 records in 0.134106302 seconds. Throughput is 954.4667 records/second. Loss is 2.180619. Sequentiale465b572's hyper parameters: Current learning rate is 4.0176777822418646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 1491][Wall Clock 169.11934268s] Trained 128 records in 0.093495502 seconds. Throughput is 1369.0498 records/second. Loss is 2.209727. Sequentiale465b572's hyper parameters: Current learning rate is 4.016064257028112E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 10880/60000][Iteration 1492][Wall Clock 169.215460513s] Trained 128 records in 0.096117833 seconds. Throughput is 1331.6987 records/second. Loss is 2.1889906. Sequentiale465b572's hyper parameters: Current learning rate is 4.014452027298274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 1493][Wall Clock 169.31266501s] Trained 128 records in 0.097204497 seconds. Throughput is 1316.8115 records/second. Loss is 2.191712. Sequentiale465b572's hyper parameters: Current learning rate is 4.012841091492777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 11136/60000][Iteration 1494][Wall Clock 169.411893312s] Trained 128 records in 0.099228302 seconds. Throughput is 1289.9546 records/second. Loss is 2.2047534. Sequentiale465b572's hyper parameters: Current learning rate is 4.0112314480545525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 1495][Wall Clock 169.506184213s] Trained 128 records in 0.094290901 seconds. Throughput is 1357.501 records/second. Loss is 2.1937528. Sequentiale465b572's hyper parameters: Current learning rate is 4.00962309542903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:32 INFO  DistriOptimizer$:408 - [Epoch 4 11392/60000][Iteration 1496][Wall Clock 169.60130667s] Trained 128 records in 0.095122457 seconds. Throughput is 1345.6339 records/second. Loss is 2.1934023. Sequentiale465b572's hyper parameters: Current learning rate is 4.008016032064128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 1497][Wall Clock 169.706570745s] Trained 128 records in 0.105264075 seconds. Throughput is 1215.9894 records/second. Loss is 2.1902094. Sequentiale465b572's hyper parameters: Current learning rate is 4.0064102564102563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 11648/60000][Iteration 1498][Wall Clock 169.803627835s] Trained 128 records in 0.09705709 seconds. Throughput is 1318.8114 records/second. Loss is 2.1888154. Sequentiale465b572's hyper parameters: Current learning rate is 4.004805766920305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 1499][Wall Clock 169.903995519s] Trained 128 records in 0.100367684 seconds. Throughput is 1275.3108 records/second. Loss is 2.1863554. Sequentiale465b572's hyper parameters: Current learning rate is 4.0032025620496394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 11904/60000][Iteration 1500][Wall Clock 170.005070632s] Trained 128 records in 0.101075113 seconds. Throughput is 1266.3849 records/second. Loss is 2.1851065. Sequentiale465b572's hyper parameters: Current learning rate is 4.001600640256102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 1501][Wall Clock 170.102889031s] Trained 128 records in 0.097818399 seconds. Throughput is 1308.5474 records/second. Loss is 2.1806324. Sequentiale465b572's hyper parameters: Current learning rate is 4.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 12160/60000][Iteration 1502][Wall Clock 170.203099156s] Trained 128 records in 0.100210125 seconds. Throughput is 1277.316 records/second. Loss is 2.1985526. Sequentiale465b572's hyper parameters: Current learning rate is 3.998400639744102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 1503][Wall Clock 170.30800038s] Trained 128 records in 0.104901224 seconds. Throughput is 1220.1954 records/second. Loss is 2.1932447. Sequentiale465b572's hyper parameters: Current learning rate is 3.9968025579536375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 12416/60000][Iteration 1504][Wall Clock 170.408868211s] Trained 128 records in 0.100867831 seconds. Throughput is 1268.9873 records/second. Loss is 2.1910837. Sequentiale465b572's hyper parameters: Current learning rate is 3.9952057530962844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 1505][Wall Clock 170.506161771s] Trained 128 records in 0.09729356 seconds. Throughput is 1315.6061 records/second. Loss is 2.182783. Sequentiale465b572's hyper parameters: Current learning rate is 3.9936102236421724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:33 INFO  DistriOptimizer$:408 - [Epoch 4 12672/60000][Iteration 1506][Wall Clock 170.601487363s] Trained 128 records in 0.095325592 seconds. Throughput is 1342.7665 records/second. Loss is 2.1921291. Sequentiale465b572's hyper parameters: Current learning rate is 3.9920159680638726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 1507][Wall Clock 170.704577795s] Trained 128 records in 0.103090432 seconds. Throughput is 1241.6283 records/second. Loss is 2.1841867. Sequentiale465b572's hyper parameters: Current learning rate is 3.9904229848363923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 12928/60000][Iteration 1508][Wall Clock 170.801396028s] Trained 128 records in 0.096818233 seconds. Throughput is 1322.0651 records/second. Loss is 2.190598. Sequentiale465b572's hyper parameters: Current learning rate is 3.9888312724371757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 1509][Wall Clock 170.901660505s] Trained 128 records in 0.100264477 seconds. Throughput is 1276.6237 records/second. Loss is 2.188211. Sequentiale465b572's hyper parameters: Current learning rate is 3.9872408293460925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13184/60000][Iteration 1510][Wall Clock 170.993843037s] Trained 128 records in 0.092182532 seconds. Throughput is 1388.5494 records/second. Loss is 2.1860785. Sequentiale465b572's hyper parameters: Current learning rate is 3.985651654045436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 1511][Wall Clock 171.087844071s] Trained 128 records in 0.094001034 seconds. Throughput is 1361.6871 records/second. Loss is 2.2021215. Sequentiale465b572's hyper parameters: Current learning rate is 3.984063745019921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13440/60000][Iteration 1512][Wall Clock 171.189529347s] Trained 128 records in 0.101685276 seconds. Throughput is 1258.786 records/second. Loss is 2.1889932. Sequentiale465b572's hyper parameters: Current learning rate is 3.9824771007566706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 1513][Wall Clock 171.290337007s] Trained 128 records in 0.10080766 seconds. Throughput is 1269.7448 records/second. Loss is 2.1987436. Sequentiale465b572's hyper parameters: Current learning rate is 3.980891719745223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13696/60000][Iteration 1514][Wall Clock 171.390485825s] Trained 128 records in 0.100148818 seconds. Throughput is 1278.0979 records/second. Loss is 2.195729. Sequentiale465b572's hyper parameters: Current learning rate is 3.9793076004775174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 1515][Wall Clock 171.51184298s] Trained 128 records in 0.121357155 seconds. Throughput is 1054.7379 records/second. Loss is 2.2019436. Sequentiale465b572's hyper parameters: Current learning rate is 3.9777247414478914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:34 INFO  DistriOptimizer$:408 - [Epoch 4 13952/60000][Iteration 1516][Wall Clock 171.612291932s] Trained 128 records in 0.100448952 seconds. Throughput is 1274.279 records/second. Loss is 2.2050414. Sequentiale465b572's hyper parameters: Current learning rate is 3.9761431411530816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 1517][Wall Clock 171.714400531s] Trained 128 records in 0.102108599 seconds. Throughput is 1253.5673 records/second. Loss is 2.2018416. Sequentiale465b572's hyper parameters: Current learning rate is 3.97456279809221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14208/60000][Iteration 1518][Wall Clock 171.821199352s] Trained 128 records in 0.106798821 seconds. Throughput is 1198.5151 records/second. Loss is 2.1855514. Sequentiale465b572's hyper parameters: Current learning rate is 3.9729837107667853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 1519][Wall Clock 171.919871117s] Trained 128 records in 0.098671765 seconds. Throughput is 1297.2302 records/second. Loss is 2.1925118. Sequentiale465b572's hyper parameters: Current learning rate is 3.9714058776806993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14464/60000][Iteration 1520][Wall Clock 172.030884032s] Trained 128 records in 0.111012915 seconds. Throughput is 1153.019 records/second. Loss is 2.1825855. Sequentiale465b572's hyper parameters: Current learning rate is 3.969829297340214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 1521][Wall Clock 172.126140725s] Trained 128 records in 0.095256693 seconds. Throughput is 1343.7375 records/second. Loss is 2.196952. Sequentiale465b572's hyper parameters: Current learning rate is 3.968253968253968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14720/60000][Iteration 1522][Wall Clock 172.221131009s] Trained 128 records in 0.094990284 seconds. Throughput is 1347.5062 records/second. Loss is 2.187084. Sequentiale465b572's hyper parameters: Current learning rate is 3.966679888932963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 1523][Wall Clock 172.342272305s] Trained 128 records in 0.121141296 seconds. Throughput is 1056.6173 records/second. Loss is 2.1852567. Sequentiale465b572's hyper parameters: Current learning rate is 3.9651070578905625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 14976/60000][Iteration 1524][Wall Clock 172.435973317s] Trained 128 records in 0.093701012 seconds. Throughput is 1366.0471 records/second. Loss is 2.194255. Sequentiale465b572's hyper parameters: Current learning rate is 3.963535473642489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 1525][Wall Clock 172.529847532s] Trained 128 records in 0.093874215 seconds. Throughput is 1363.5267 records/second. Loss is 2.2117486. Sequentiale465b572's hyper parameters: Current learning rate is 3.961965134706815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:35 INFO  DistriOptimizer$:408 - [Epoch 4 15232/60000][Iteration 1526][Wall Clock 172.623377434s] Trained 128 records in 0.093529902 seconds. Throughput is 1368.5463 records/second. Loss is 2.183902. Sequentiale465b572's hyper parameters: Current learning rate is 3.96039603960396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 1527][Wall Clock 172.71488407s] Trained 128 records in 0.091506636 seconds. Throughput is 1398.8057 records/second. Loss is 2.1716537. Sequentiale465b572's hyper parameters: Current learning rate is 3.958828186856691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 15488/60000][Iteration 1528][Wall Clock 172.805695416s] Trained 128 records in 0.090811346 seconds. Throughput is 1409.5155 records/second. Loss is 2.1862774. Sequentiale465b572's hyper parameters: Current learning rate is 3.957261574990107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 1529][Wall Clock 172.900366976s] Trained 128 records in 0.09467156 seconds. Throughput is 1352.0427 records/second. Loss is 2.2063167. Sequentiale465b572's hyper parameters: Current learning rate is 3.9556962025316455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 15744/60000][Iteration 1530][Wall Clock 172.996031057s] Trained 128 records in 0.095664081 seconds. Throughput is 1338.0153 records/second. Loss is 2.1783414. Sequentiale465b572's hyper parameters: Current learning rate is 3.9541320680110717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 1531][Wall Clock 173.095682295s] Trained 128 records in 0.099651238 seconds. Throughput is 1284.4797 records/second. Loss is 2.1966. Sequentiale465b572's hyper parameters: Current learning rate is 3.952569169960474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 16000/60000][Iteration 1532][Wall Clock 173.190109121s] Trained 128 records in 0.094426826 seconds. Throughput is 1355.547 records/second. Loss is 2.198746. Sequentiale465b572's hyper parameters: Current learning rate is 3.951007506914263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 1533][Wall Clock 173.284499044s] Trained 128 records in 0.094389923 seconds. Throughput is 1356.0769 records/second. Loss is 2.1944668. Sequentiale465b572's hyper parameters: Current learning rate is 3.9494470774091627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 16256/60000][Iteration 1534][Wall Clock 173.384046486s] Trained 128 records in 0.099547442 seconds. Throughput is 1285.8191 records/second. Loss is 2.1899366. Sequentiale465b572's hyper parameters: Current learning rate is 3.947887879984208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 1535][Wall Clock 173.481143255s] Trained 128 records in 0.097096769 seconds. Throughput is 1318.2725 records/second. Loss is 2.200227. Sequentiale465b572's hyper parameters: Current learning rate is 3.9463299131807424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:36 INFO  DistriOptimizer$:408 - [Epoch 4 16512/60000][Iteration 1536][Wall Clock 173.575065648s] Trained 128 records in 0.093922393 seconds. Throughput is 1362.8273 records/second. Loss is 2.2011323. Sequentiale465b572's hyper parameters: Current learning rate is 3.944773175542406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 1537][Wall Clock 173.671198964s] Trained 128 records in 0.096133316 seconds. Throughput is 1331.4844 records/second. Loss is 2.1780615. Sequentiale465b572's hyper parameters: Current learning rate is 3.943217665615142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 16768/60000][Iteration 1538][Wall Clock 173.763067803s] Trained 128 records in 0.091868839 seconds. Throughput is 1393.2906 records/second. Loss is 2.1844218. Sequentiale465b572's hyper parameters: Current learning rate is 3.941663381947182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 1539][Wall Clock 173.862261359s] Trained 128 records in 0.099193556 seconds. Throughput is 1290.4064 records/second. Loss is 2.1823332. Sequentiale465b572's hyper parameters: Current learning rate is 3.940110323089046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17024/60000][Iteration 1540][Wall Clock 173.980136536s] Trained 128 records in 0.117875177 seconds. Throughput is 1085.8945 records/second. Loss is 2.1807165. Sequentiale465b572's hyper parameters: Current learning rate is 3.938558487593541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 1541][Wall Clock 174.087762299s] Trained 128 records in 0.107625763 seconds. Throughput is 1189.3064 records/second. Loss is 2.2083204. Sequentiale465b572's hyper parameters: Current learning rate is 3.937007874015748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17280/60000][Iteration 1542][Wall Clock 174.191345829s] Trained 128 records in 0.10358353 seconds. Throughput is 1235.7177 records/second. Loss is 2.1984725. Sequentiale465b572's hyper parameters: Current learning rate is 3.9354584809130267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 1543][Wall Clock 174.29198158s] Trained 128 records in 0.100635751 seconds. Throughput is 1271.9138 records/second. Loss is 2.1910834. Sequentiale465b572's hyper parameters: Current learning rate is 3.9339103068450045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17536/60000][Iteration 1544][Wall Clock 174.394320876s] Trained 128 records in 0.102339296 seconds. Throughput is 1250.7415 records/second. Loss is 2.172576. Sequentiale465b572's hyper parameters: Current learning rate is 3.9323633503735744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 1545][Wall Clock 174.491168959s] Trained 128 records in 0.096848083 seconds. Throughput is 1321.6575 records/second. Loss is 2.2022014. Sequentiale465b572's hyper parameters: Current learning rate is 3.9308176100628933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:37 INFO  DistriOptimizer$:408 - [Epoch 4 17792/60000][Iteration 1546][Wall Clock 174.587495784s] Trained 128 records in 0.096326825 seconds. Throughput is 1328.8094 records/second. Loss is 2.2062526. Sequentiale465b572's hyper parameters: Current learning rate is 3.9292730844793717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 1547][Wall Clock 174.683916361s] Trained 128 records in 0.096420577 seconds. Throughput is 1327.5175 records/second. Loss is 2.1934884. Sequentiale465b572's hyper parameters: Current learning rate is 3.927729772191673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18048/60000][Iteration 1548][Wall Clock 174.789599774s] Trained 128 records in 0.105683413 seconds. Throughput is 1211.1644 records/second. Loss is 2.1938329. Sequentiale465b572's hyper parameters: Current learning rate is 3.926187671770711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 1549][Wall Clock 174.883833974s] Trained 128 records in 0.0942342 seconds. Throughput is 1358.3179 records/second. Loss is 2.1717434. Sequentiale465b572's hyper parameters: Current learning rate is 3.924646781789639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18304/60000][Iteration 1550][Wall Clock 174.976834421s] Trained 128 records in 0.093000447 seconds. Throughput is 1376.3374 records/second. Loss is 2.1793556. Sequentiale465b572's hyper parameters: Current learning rate is 3.9231071008238524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 1551][Wall Clock 175.068892567s] Trained 128 records in 0.092058146 seconds. Throughput is 1390.4255 records/second. Loss is 2.1855881. Sequentiale465b572's hyper parameters: Current learning rate is 3.921568627450981E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18560/60000][Iteration 1552][Wall Clock 175.165753015s] Trained 128 records in 0.096860448 seconds. Throughput is 1321.4889 records/second. Loss is 2.1957803. Sequentiale465b572's hyper parameters: Current learning rate is 3.920031360250882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 1553][Wall Clock 175.263184096s] Trained 128 records in 0.097431081 seconds. Throughput is 1313.7491 records/second. Loss is 2.1885827. Sequentiale465b572's hyper parameters: Current learning rate is 3.9184952978056425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18816/60000][Iteration 1554][Wall Clock 175.358893898s] Trained 128 records in 0.095709802 seconds. Throughput is 1337.3761 records/second. Loss is 2.1898634. Sequentiale465b572's hyper parameters: Current learning rate is 3.9169604386995695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 1555][Wall Clock 175.478744388s] Trained 128 records in 0.11985049 seconds. Throughput is 1067.9973 records/second. Loss is 2.195452. Sequentiale465b572's hyper parameters: Current learning rate is 3.915426781519185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:38 INFO  DistriOptimizer$:408 - [Epoch 4 19072/60000][Iteration 1556][Wall Clock 175.573973336s] Trained 128 records in 0.095228948 seconds. Throughput is 1344.1292 records/second. Loss is 2.1847327. Sequentiale465b572's hyper parameters: Current learning rate is 3.9138943248532296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 1557][Wall Clock 175.672242181s] Trained 128 records in 0.098268845 seconds. Throughput is 1302.5492 records/second. Loss is 2.188247. Sequentiale465b572's hyper parameters: Current learning rate is 3.912363067292645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19328/60000][Iteration 1558][Wall Clock 175.770210156s] Trained 128 records in 0.097967975 seconds. Throughput is 1306.5494 records/second. Loss is 2.1844049. Sequentiale465b572's hyper parameters: Current learning rate is 3.910833007430583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 1559][Wall Clock 175.864728993s] Trained 128 records in 0.094518837 seconds. Throughput is 1354.2274 records/second. Loss is 2.1703835. Sequentiale465b572's hyper parameters: Current learning rate is 3.909304143862393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19584/60000][Iteration 1560][Wall Clock 175.965659567s] Trained 128 records in 0.100930574 seconds. Throughput is 1268.1985 records/second. Loss is 2.1785574. Sequentiale465b572's hyper parameters: Current learning rate is 3.907776475185619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 1561][Wall Clock 176.06326318s] Trained 128 records in 0.097603613 seconds. Throughput is 1311.4269 records/second. Loss is 2.196092. Sequentiale465b572's hyper parameters: Current learning rate is 3.90625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19840/60000][Iteration 1562][Wall Clock 176.157756578s] Trained 128 records in 0.094493398 seconds. Throughput is 1354.592 records/second. Loss is 2.1862502. Sequentiale465b572's hyper parameters: Current learning rate is 3.904724716907458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 1563][Wall Clock 176.25337789s] Trained 128 records in 0.095621312 seconds. Throughput is 1338.6138 records/second. Loss is 2.1749086. Sequentiale465b572's hyper parameters: Current learning rate is 3.9032006245120994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 20096/60000][Iteration 1564][Wall Clock 176.350479401s] Trained 128 records in 0.097101511 seconds. Throughput is 1318.2081 records/second. Loss is 2.2093625. Sequentiale465b572's hyper parameters: Current learning rate is 3.9016777214202113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 1565][Wall Clock 176.444756058s] Trained 128 records in 0.094276657 seconds. Throughput is 1357.7062 records/second. Loss is 2.186222. Sequentiale465b572's hyper parameters: Current learning rate is 3.90015600624025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:39 INFO  DistriOptimizer$:408 - [Epoch 4 20352/60000][Iteration 1566][Wall Clock 176.554057898s] Trained 128 records in 0.10930184 seconds. Throughput is 1171.069 records/second. Loss is 2.2005033. Sequentiale465b572's hyper parameters: Current learning rate is 3.898635477582846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 1567][Wall Clock 176.659492144s] Trained 128 records in 0.105434246 seconds. Throughput is 1214.0267 records/second. Loss is 2.1906962. Sequentiale465b572's hyper parameters: Current learning rate is 3.897116134060795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 20608/60000][Iteration 1568][Wall Clock 176.759744711s] Trained 128 records in 0.100252567 seconds. Throughput is 1276.7753 records/second. Loss is 2.185245. Sequentiale465b572's hyper parameters: Current learning rate is 3.8955979742890534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 1569][Wall Clock 176.866208499s] Trained 128 records in 0.106463788 seconds. Throughput is 1202.2867 records/second. Loss is 2.2039905. Sequentiale465b572's hyper parameters: Current learning rate is 3.894080996884735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 20864/60000][Iteration 1570][Wall Clock 176.963641969s] Trained 128 records in 0.09743347 seconds. Throughput is 1313.7169 records/second. Loss is 2.1871474. Sequentiale465b572's hyper parameters: Current learning rate is 3.892565200467108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 1571][Wall Clock 177.059094784s] Trained 128 records in 0.095452815 seconds. Throughput is 1340.9767 records/second. Loss is 2.1854205. Sequentiale465b572's hyper parameters: Current learning rate is 3.8910505836575873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 21120/60000][Iteration 1572][Wall Clock 177.153438783s] Trained 128 records in 0.094343999 seconds. Throughput is 1356.737 records/second. Loss is 2.1933484. Sequentiale465b572's hyper parameters: Current learning rate is 3.889537145079736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 1573][Wall Clock 177.252704964s] Trained 128 records in 0.099266181 seconds. Throughput is 1289.4624 records/second. Loss is 2.1829567. Sequentiale465b572's hyper parameters: Current learning rate is 3.8880248833592535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 21376/60000][Iteration 1574][Wall Clock 177.363231954s] Trained 128 records in 0.11052699 seconds. Throughput is 1158.0883 records/second. Loss is 2.1736705. Sequentiale465b572's hyper parameters: Current learning rate is 3.88651379712398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 1575][Wall Clock 177.46861617s] Trained 128 records in 0.105384216 seconds. Throughput is 1214.6031 records/second. Loss is 2.1860907. Sequentiale465b572's hyper parameters: Current learning rate is 3.8850038850038855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:40 INFO  DistriOptimizer$:408 - [Epoch 4 21632/60000][Iteration 1576][Wall Clock 177.563488008s] Trained 128 records in 0.094871838 seconds. Throughput is 1349.1885 records/second. Loss is 2.201076. Sequentiale465b572's hyper parameters: Current learning rate is 3.8834951456310677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 1577][Wall Clock 177.657110078s] Trained 128 records in 0.09362207 seconds. Throughput is 1367.199 records/second. Loss is 2.1984363. Sequentiale465b572's hyper parameters: Current learning rate is 3.8819875776397513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 21888/60000][Iteration 1578][Wall Clock 177.753857447s] Trained 128 records in 0.096747369 seconds. Throughput is 1323.0334 records/second. Loss is 2.1772943. Sequentiale465b572's hyper parameters: Current learning rate is 3.880481179666279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 1579][Wall Clock 177.848935036s] Trained 128 records in 0.095077589 seconds. Throughput is 1346.2689 records/second. Loss is 2.1880789. Sequentiale465b572's hyper parameters: Current learning rate is 3.878975950349107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22144/60000][Iteration 1580][Wall Clock 177.946894628s] Trained 128 records in 0.097959592 seconds. Throughput is 1306.6613 records/second. Loss is 2.1849718. Sequentiale465b572's hyper parameters: Current learning rate is 3.87747188832881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 1581][Wall Clock 178.040534009s] Trained 128 records in 0.093639381 seconds. Throughput is 1366.9463 records/second. Loss is 2.1768835. Sequentiale465b572's hyper parameters: Current learning rate is 3.875968992248062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22400/60000][Iteration 1582][Wall Clock 178.134674639s] Trained 128 records in 0.09414063 seconds. Throughput is 1359.668 records/second. Loss is 2.1817825. Sequentiale465b572's hyper parameters: Current learning rate is 3.874467260751647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 1583][Wall Clock 178.229239722s] Trained 128 records in 0.094565083 seconds. Throughput is 1353.5651 records/second. Loss is 2.1825948. Sequentiale465b572's hyper parameters: Current learning rate is 3.872966692486445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22656/60000][Iteration 1584][Wall Clock 178.323334052s] Trained 128 records in 0.09409433 seconds. Throughput is 1360.337 records/second. Loss is 2.187312. Sequentiale465b572's hyper parameters: Current learning rate is 3.8714672861014324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 1585][Wall Clock 178.417890137s] Trained 128 records in 0.094556085 seconds. Throughput is 1353.694 records/second. Loss is 2.1833794. Sequentiale465b572's hyper parameters: Current learning rate is 3.869969040247678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 22912/60000][Iteration 1586][Wall Clock 178.507301741s] Trained 128 records in 0.089411604 seconds. Throughput is 1431.5815 records/second. Loss is 2.1901503. Sequentiale465b572's hyper parameters: Current learning rate is 3.8684719535783365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:41 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 1587][Wall Clock 178.609164975s] Trained 128 records in 0.101863234 seconds. Throughput is 1256.5868 records/second. Loss is 2.1890206. Sequentiale465b572's hyper parameters: Current learning rate is 3.866976024748646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23168/60000][Iteration 1588][Wall Clock 178.699672843s] Trained 128 records in 0.090507868 seconds. Throughput is 1414.2417 records/second. Loss is 2.1803954. Sequentiale465b572's hyper parameters: Current learning rate is 3.865481252415926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 1589][Wall Clock 178.793795801s] Trained 128 records in 0.094122958 seconds. Throughput is 1359.9232 records/second. Loss is 2.2013228. Sequentiale465b572's hyper parameters: Current learning rate is 3.863987635239567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23424/60000][Iteration 1590][Wall Clock 178.891452315s] Trained 128 records in 0.097656514 seconds. Throughput is 1310.7166 records/second. Loss is 2.176278. Sequentiale465b572's hyper parameters: Current learning rate is 3.862495171881035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 1591][Wall Clock 179.001839772s] Trained 128 records in 0.110387457 seconds. Throughput is 1159.552 records/second. Loss is 2.182801. Sequentiale465b572's hyper parameters: Current learning rate is 3.8610038610038615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23680/60000][Iteration 1592][Wall Clock 179.101482087s] Trained 128 records in 0.099642315 seconds. Throughput is 1284.5948 records/second. Loss is 2.1676543. Sequentiale465b572's hyper parameters: Current learning rate is 3.859513701273639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 1593][Wall Clock 179.19708592s] Trained 128 records in 0.095603833 seconds. Throughput is 1338.8585 records/second. Loss is 2.1837833. Sequentiale465b572's hyper parameters: Current learning rate is 3.8580246913580245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 23936/60000][Iteration 1594][Wall Clock 179.296512325s] Trained 128 records in 0.099426405 seconds. Throughput is 1287.3844 records/second. Loss is 2.1884558. Sequentiale465b572's hyper parameters: Current learning rate is 3.856536829926726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 1595][Wall Clock 179.396000726s] Trained 128 records in 0.099488401 seconds. Throughput is 1286.5822 records/second. Loss is 2.1825137. Sequentiale465b572's hyper parameters: Current learning rate is 3.8550501156515033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 24192/60000][Iteration 1596][Wall Clock 179.493954307s] Trained 128 records in 0.097953581 seconds. Throughput is 1306.7415 records/second. Loss is 2.1734817. Sequentiale465b572's hyper parameters: Current learning rate is 3.8535645472061663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:42 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 1597][Wall Clock 179.589853021s] Trained 128 records in 0.095898714 seconds. Throughput is 1334.7416 records/second. Loss is 2.169829. Sequentiale465b572's hyper parameters: Current learning rate is 3.852080123266564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 24448/60000][Iteration 1598][Wall Clock 179.689439423s] Trained 128 records in 0.099586402 seconds. Throughput is 1285.316 records/second. Loss is 2.1941993. Sequentiale465b572's hyper parameters: Current learning rate is 3.850596842510589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 1599][Wall Clock 179.796429482s] Trained 128 records in 0.106990059 seconds. Throughput is 1196.3728 records/second. Loss is 2.1671083. Sequentiale465b572's hyper parameters: Current learning rate is 3.849114703618168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 24704/60000][Iteration 1600][Wall Clock 179.887828866s] Trained 128 records in 0.091399384 seconds. Throughput is 1400.447 records/second. Loss is 2.1772428. Sequentiale465b572's hyper parameters: Current learning rate is 3.847633705271258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 1601][Wall Clock 179.980557251s] Trained 128 records in 0.092728385 seconds. Throughput is 1380.3756 records/second. Loss is 2.19237. Sequentiale465b572's hyper parameters: Current learning rate is 3.846153846153846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 24960/60000][Iteration 1602][Wall Clock 180.076545117s] Trained 128 records in 0.095987866 seconds. Throughput is 1333.502 records/second. Loss is 2.1920764. Sequentiale465b572's hyper parameters: Current learning rate is 3.8446751249519417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 1603][Wall Clock 180.16772707s] Trained 128 records in 0.091181953 seconds. Throughput is 1403.7865 records/second. Loss is 2.1885095. Sequentiale465b572's hyper parameters: Current learning rate is 3.8431975403535736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 25216/60000][Iteration 1604][Wall Clock 180.268082849s] Trained 128 records in 0.100355779 seconds. Throughput is 1275.4622 records/second. Loss is 2.1821415. Sequentiale465b572's hyper parameters: Current learning rate is 3.8417210910487906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 1605][Wall Clock 180.362031358s] Trained 128 records in 0.093948509 seconds. Throughput is 1362.4485 records/second. Loss is 2.181869. Sequentiale465b572's hyper parameters: Current learning rate is 3.8402457757296467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 25472/60000][Iteration 1606][Wall Clock 180.452775272s] Trained 128 records in 0.090743914 seconds. Throughput is 1410.5629 records/second. Loss is 2.1869977. Sequentiale465b572's hyper parameters: Current learning rate is 3.8387715930902113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:43 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 1607][Wall Clock 180.545716863s] Trained 128 records in 0.092941591 seconds. Throughput is 1377.2091 records/second. Loss is 2.197894. Sequentiale465b572's hyper parameters: Current learning rate is 3.8372985418265546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 25728/60000][Iteration 1608][Wall Clock 180.640250119s] Trained 128 records in 0.094533256 seconds. Throughput is 1354.0209 records/second. Loss is 2.1823764. Sequentiale465b572's hyper parameters: Current learning rate is 3.835826620636747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 1609][Wall Clock 180.734154522s] Trained 128 records in 0.093904403 seconds. Throughput is 1363.0884 records/second. Loss is 2.1861107. Sequentiale465b572's hyper parameters: Current learning rate is 3.834355828220859E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 25984/60000][Iteration 1610][Wall Clock 180.829450654s] Trained 128 records in 0.095296132 seconds. Throughput is 1343.1815 records/second. Loss is 2.1910222. Sequentiale465b572's hyper parameters: Current learning rate is 3.832886163280951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 1611][Wall Clock 180.922482194s] Trained 128 records in 0.09303154 seconds. Throughput is 1375.8774 records/second. Loss is 2.1838517. Sequentiale465b572's hyper parameters: Current learning rate is 3.8314176245210724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26240/60000][Iteration 1612][Wall Clock 181.017208298s] Trained 128 records in 0.094726104 seconds. Throughput is 1351.2643 records/second. Loss is 2.1768713. Sequentiale465b572's hyper parameters: Current learning rate is 3.829950210647262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 1613][Wall Clock 181.10821036s] Trained 128 records in 0.091002062 seconds. Throughput is 1406.5615 records/second. Loss is 2.1787562. Sequentiale465b572's hyper parameters: Current learning rate is 3.8284839203675346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26496/60000][Iteration 1614][Wall Clock 181.199102696s] Trained 128 records in 0.090892336 seconds. Throughput is 1408.2595 records/second. Loss is 2.1798806. Sequentiale465b572's hyper parameters: Current learning rate is 3.827018752391887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 1615][Wall Clock 181.290915669s] Trained 128 records in 0.091812973 seconds. Throughput is 1394.1384 records/second. Loss is 2.1743684. Sequentiale465b572's hyper parameters: Current learning rate is 3.825554705432288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26752/60000][Iteration 1616][Wall Clock 181.387979727s] Trained 128 records in 0.097064058 seconds. Throughput is 1318.7168 records/second. Loss is 2.1887324. Sequentiale465b572's hyper parameters: Current learning rate is 3.824091778202677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:44 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 1617][Wall Clock 181.508395459s] Trained 128 records in 0.120415732 seconds. Throughput is 1062.984 records/second. Loss is 2.1885605. Sequentiale465b572's hyper parameters: Current learning rate is 3.8226299694189603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27008/60000][Iteration 1618][Wall Clock 181.615582856s] Trained 128 records in 0.107187397 seconds. Throughput is 1194.1703 records/second. Loss is 2.1845546. Sequentiale465b572's hyper parameters: Current learning rate is 3.8211692777990065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 1619][Wall Clock 181.714599675s] Trained 128 records in 0.099016819 seconds. Throughput is 1292.7097 records/second. Loss is 2.166654. Sequentiale465b572's hyper parameters: Current learning rate is 3.8197097020626426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27264/60000][Iteration 1620][Wall Clock 181.809910068s] Trained 128 records in 0.095310393 seconds. Throughput is 1342.9806 records/second. Loss is 2.1640978. Sequentiale465b572's hyper parameters: Current learning rate is 3.8182512409316535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 1621][Wall Clock 181.901862287s] Trained 128 records in 0.091952219 seconds. Throughput is 1392.0273 records/second. Loss is 2.1698616. Sequentiale465b572's hyper parameters: Current learning rate is 3.816793893129771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27520/60000][Iteration 1622][Wall Clock 181.999206683s] Trained 128 records in 0.097344396 seconds. Throughput is 1314.9191 records/second. Loss is 2.1739044. Sequentiale465b572's hyper parameters: Current learning rate is 3.8153376573826786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 1623][Wall Clock 182.099643642s] Trained 128 records in 0.100436959 seconds. Throughput is 1274.4313 records/second. Loss is 2.1818087. Sequentiale465b572's hyper parameters: Current learning rate is 3.8138825324180017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27776/60000][Iteration 1624][Wall Clock 182.195645004s] Trained 128 records in 0.096001362 seconds. Throughput is 1333.3143 records/second. Loss is 2.1782405. Sequentiale465b572's hyper parameters: Current learning rate is 3.812428516965307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 1625][Wall Clock 182.297462705s] Trained 128 records in 0.101817701 seconds. Throughput is 1257.1488 records/second. Loss is 2.1720617. Sequentiale465b572's hyper parameters: Current learning rate is 3.8109756097560977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 28032/60000][Iteration 1626][Wall Clock 182.4107624s] Trained 128 records in 0.113299695 seconds. Throughput is 1129.7471 records/second. Loss is 2.16995. Sequentiale465b572's hyper parameters: Current learning rate is 3.8095238095238096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 1627][Wall Clock 182.500248016s] Trained 128 records in 0.089485616 seconds. Throughput is 1430.3975 records/second. Loss is 2.168745. Sequentiale465b572's hyper parameters: Current learning rate is 3.8080731150038076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:45 INFO  DistriOptimizer$:408 - [Epoch 4 28288/60000][Iteration 1628][Wall Clock 182.593415256s] Trained 128 records in 0.09316724 seconds. Throughput is 1373.8735 records/second. Loss is 2.1913753. Sequentiale465b572's hyper parameters: Current learning rate is 3.8066235249333843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 1629][Wall Clock 182.682550752s] Trained 128 records in 0.089135496 seconds. Throughput is 1436.016 records/second. Loss is 2.1773648. Sequentiale465b572's hyper parameters: Current learning rate is 3.80517503805175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 28544/60000][Iteration 1630][Wall Clock 182.771992243s] Trained 128 records in 0.089441491 seconds. Throughput is 1431.1031 records/second. Loss is 2.1860268. Sequentiale465b572's hyper parameters: Current learning rate is 3.803727653100038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 1631][Wall Clock 182.862972308s] Trained 128 records in 0.090980065 seconds. Throughput is 1406.9016 records/second. Loss is 2.1794913. Sequentiale465b572's hyper parameters: Current learning rate is 3.802281368821293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 28800/60000][Iteration 1632][Wall Clock 182.959791414s] Trained 128 records in 0.096819106 seconds. Throughput is 1322.0531 records/second. Loss is 2.1756544. Sequentiale465b572's hyper parameters: Current learning rate is 3.800836183960471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 1633][Wall Clock 183.051646507s] Trained 128 records in 0.091855093 seconds. Throughput is 1393.4991 records/second. Loss is 2.181308. Sequentiale465b572's hyper parameters: Current learning rate is 3.7993920972644377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 29056/60000][Iteration 1634][Wall Clock 183.143123611s] Trained 128 records in 0.091477104 seconds. Throughput is 1399.2572 records/second. Loss is 2.1808617. Sequentiale465b572's hyper parameters: Current learning rate is 3.7979491074819596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 1635][Wall Clock 183.238328379s] Trained 128 records in 0.095204768 seconds. Throughput is 1344.4705 records/second. Loss is 2.1738334. Sequentiale465b572's hyper parameters: Current learning rate is 3.796507213363705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 29312/60000][Iteration 1636][Wall Clock 183.337000435s] Trained 128 records in 0.098672056 seconds. Throughput is 1297.2264 records/second. Loss is 2.1810992. Sequentiale465b572's hyper parameters: Current learning rate is 3.7950664136622396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 1637][Wall Clock 183.439096751s] Trained 128 records in 0.102096316 seconds. Throughput is 1253.718 records/second. Loss is 2.1809072. Sequentiale465b572's hyper parameters: Current learning rate is 3.7936267071320183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:46 INFO  DistriOptimizer$:408 - [Epoch 4 29568/60000][Iteration 1638][Wall Clock 183.533098121s] Trained 128 records in 0.09400137 seconds. Throughput is 1361.6824 records/second. Loss is 2.1713667. Sequentiale465b572's hyper parameters: Current learning rate is 3.792188092529389E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 1639][Wall Clock 183.631232454s] Trained 128 records in 0.098134333 seconds. Throughput is 1304.3346 records/second. Loss is 2.188715. Sequentiale465b572's hyper parameters: Current learning rate is 3.790750568612585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 29824/60000][Iteration 1640][Wall Clock 183.734322074s] Trained 128 records in 0.10308962 seconds. Throughput is 1241.6381 records/second. Loss is 2.1799579. Sequentiale465b572's hyper parameters: Current learning rate is 3.7893141341417203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 1641][Wall Clock 183.832989823s] Trained 128 records in 0.098667749 seconds. Throughput is 1297.2831 records/second. Loss is 2.1728756. Sequentiale465b572's hyper parameters: Current learning rate is 3.787878787878788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 30080/60000][Iteration 1642][Wall Clock 183.957129808s] Trained 128 records in 0.124139985 seconds. Throughput is 1031.094 records/second. Loss is 2.181679. Sequentiale465b572's hyper parameters: Current learning rate is 3.786444528587656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 1643][Wall Clock 184.060623538s] Trained 128 records in 0.10349373 seconds. Throughput is 1236.7899 records/second. Loss is 2.160586. Sequentiale465b572's hyper parameters: Current learning rate is 3.7850113550340646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 30336/60000][Iteration 1644][Wall Clock 184.166484067s] Trained 128 records in 0.105860529 seconds. Throughput is 1209.1381 records/second. Loss is 2.1704278. Sequentiale465b572's hyper parameters: Current learning rate is 3.7835792659856227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 1645][Wall Clock 184.259528175s] Trained 128 records in 0.093044108 seconds. Throughput is 1375.6917 records/second. Loss is 2.1844947. Sequentiale465b572's hyper parameters: Current learning rate is 3.7821482602118004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 30592/60000][Iteration 1646][Wall Clock 184.354712613s] Trained 128 records in 0.095184438 seconds. Throughput is 1344.7577 records/second. Loss is 2.1773393. Sequentiale465b572's hyper parameters: Current learning rate is 3.780718336483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:47 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 1647][Wall Clock 184.450538531s] Trained 128 records in 0.095825918 seconds. Throughput is 1335.7555 records/second. Loss is 2.1917725. Sequentiale465b572's hyper parameters: Current learning rate is 3.779289493575208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 30848/60000][Iteration 1648][Wall Clock 184.590771734s] Trained 128 records in 0.140233203 seconds. Throughput is 912.76526 records/second. Loss is 2.1799066. Sequentiale465b572's hyper parameters: Current learning rate is 3.7778617302606723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 1649][Wall Clock 184.686521198s] Trained 128 records in 0.095749464 seconds. Throughput is 1336.822 records/second. Loss is 2.1918583. Sequentiale465b572's hyper parameters: Current learning rate is 3.7764350453172205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31104/60000][Iteration 1650][Wall Clock 184.800409533s] Trained 128 records in 0.113888335 seconds. Throughput is 1123.9078 records/second. Loss is 2.1916664. Sequentiale465b572's hyper parameters: Current learning rate is 3.7750094375235937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 1651][Wall Clock 184.898037404s] Trained 128 records in 0.097627871 seconds. Throughput is 1311.101 records/second. Loss is 2.1648571. Sequentiale465b572's hyper parameters: Current learning rate is 3.773584905660377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31360/60000][Iteration 1652][Wall Clock 184.996518613s] Trained 128 records in 0.098481209 seconds. Throughput is 1299.7404 records/second. Loss is 2.1722817. Sequentiale465b572's hyper parameters: Current learning rate is 3.7721614485099967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 1653][Wall Clock 185.092071718s] Trained 128 records in 0.095553105 seconds. Throughput is 1339.5692 records/second. Loss is 2.177822. Sequentiale465b572's hyper parameters: Current learning rate is 3.770739064856712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31616/60000][Iteration 1654][Wall Clock 185.190262877s] Trained 128 records in 0.098191159 seconds. Throughput is 1303.5797 records/second. Loss is 2.180488. Sequentiale465b572's hyper parameters: Current learning rate is 3.769317753486619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 1655][Wall Clock 185.282035249s] Trained 128 records in 0.091772372 seconds. Throughput is 1394.7552 records/second. Loss is 2.1824236. Sequentiale465b572's hyper parameters: Current learning rate is 3.7678975131876413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 31872/60000][Iteration 1656][Wall Clock 185.374565055s] Trained 128 records in 0.092529806 seconds. Throughput is 1383.338 records/second. Loss is 2.1810474. Sequentiale465b572's hyper parameters: Current learning rate is 3.766478342749529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 1657][Wall Clock 185.481178421s] Trained 128 records in 0.106613366 seconds. Throughput is 1200.5999 records/second. Loss is 2.1656609. Sequentiale465b572's hyper parameters: Current learning rate is 3.765060240963855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:48 INFO  DistriOptimizer$:408 - [Epoch 4 32128/60000][Iteration 1658][Wall Clock 185.573459103s] Trained 128 records in 0.092280682 seconds. Throughput is 1387.0726 records/second. Loss is 2.1789374. Sequentiale465b572's hyper parameters: Current learning rate is 3.763643206624012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 1659][Wall Clock 185.665307309s] Trained 128 records in 0.091848206 seconds. Throughput is 1393.6036 records/second. Loss is 2.1850631. Sequentiale465b572's hyper parameters: Current learning rate is 3.762227238525206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 32384/60000][Iteration 1660][Wall Clock 185.758283618s] Trained 128 records in 0.092976309 seconds. Throughput is 1376.6948 records/second. Loss is 2.179942. Sequentiale465b572's hyper parameters: Current learning rate is 3.760812335464461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 1661][Wall Clock 185.852441493s] Trained 128 records in 0.094157875 seconds. Throughput is 1359.419 records/second. Loss is 2.1782413. Sequentiale465b572's hyper parameters: Current learning rate is 3.759398496240601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 32640/60000][Iteration 1662][Wall Clock 185.947474657s] Trained 128 records in 0.095033164 seconds. Throughput is 1346.8983 records/second. Loss is 2.1931925. Sequentiale465b572's hyper parameters: Current learning rate is 3.757985719654265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 1663][Wall Clock 186.042290588s] Trained 128 records in 0.094815931 seconds. Throughput is 1349.9841 records/second. Loss is 2.1940544. Sequentiale465b572's hyper parameters: Current learning rate is 3.756574004507889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 32896/60000][Iteration 1664][Wall Clock 186.132796834s] Trained 128 records in 0.090506246 seconds. Throughput is 1414.267 records/second. Loss is 2.182498. Sequentiale465b572's hyper parameters: Current learning rate is 3.755163349605708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 1665][Wall Clock 186.228283445s] Trained 128 records in 0.095486611 seconds. Throughput is 1340.5021 records/second. Loss is 2.172418. Sequentiale465b572's hyper parameters: Current learning rate is 3.7537537537537537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 33152/60000][Iteration 1666][Wall Clock 186.319545374s] Trained 128 records in 0.091261929 seconds. Throughput is 1402.5564 records/second. Loss is 2.1823666. Sequentiale465b572's hyper parameters: Current learning rate is 3.75234521575985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 1667][Wall Clock 186.416619936s] Trained 128 records in 0.097074562 seconds. Throughput is 1318.5741 records/second. Loss is 2.1843653. Sequentiale465b572's hyper parameters: Current learning rate is 3.7509377344336085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:49 INFO  DistriOptimizer$:408 - [Epoch 4 33408/60000][Iteration 1668][Wall Clock 186.527160561s] Trained 128 records in 0.110540625 seconds. Throughput is 1157.9453 records/second. Loss is 2.1776257. Sequentiale465b572's hyper parameters: Current learning rate is 3.749531308586427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 1669][Wall Clock 186.623234838s] Trained 128 records in 0.096074277 seconds. Throughput is 1332.3025 records/second. Loss is 2.1860113. Sequentiale465b572's hyper parameters: Current learning rate is 3.748125937031484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 33664/60000][Iteration 1670][Wall Clock 186.718134019s] Trained 128 records in 0.094899181 seconds. Throughput is 1348.7999 records/second. Loss is 2.1799815. Sequentiale465b572's hyper parameters: Current learning rate is 3.746721618583739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 1671][Wall Clock 186.812254708s] Trained 128 records in 0.094120689 seconds. Throughput is 1359.956 records/second. Loss is 2.1810381. Sequentiale465b572's hyper parameters: Current learning rate is 3.745318352059925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 33920/60000][Iteration 1672][Wall Clock 186.90872197s] Trained 128 records in 0.096467262 seconds. Throughput is 1326.875 records/second. Loss is 2.1829412. Sequentiale465b572's hyper parameters: Current learning rate is 3.743916136278547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 1673][Wall Clock 187.00587943s] Trained 128 records in 0.09715746 seconds. Throughput is 1317.449 records/second. Loss is 2.1997814. Sequentiale465b572's hyper parameters: Current learning rate is 3.7425149700598805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 34176/60000][Iteration 1674][Wall Clock 187.099558753s] Trained 128 records in 0.093679323 seconds. Throughput is 1366.3634 records/second. Loss is 2.1583114. Sequentiale465b572's hyper parameters: Current learning rate is 3.741114852225963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 1675][Wall Clock 187.195705766s] Trained 128 records in 0.096147013 seconds. Throughput is 1331.2946 records/second. Loss is 2.1869462. Sequentiale465b572's hyper parameters: Current learning rate is 3.7397157816005983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 34432/60000][Iteration 1676][Wall Clock 187.327449449s] Trained 128 records in 0.131743683 seconds. Throughput is 971.58356 records/second. Loss is 2.153562. Sequentiale465b572's hyper parameters: Current learning rate is 3.738317757009346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 1677][Wall Clock 187.433832988s] Trained 128 records in 0.106383539 seconds. Throughput is 1203.1936 records/second. Loss is 2.1883378. Sequentiale465b572's hyper parameters: Current learning rate is 3.736920777279522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:50 INFO  DistriOptimizer$:408 - [Epoch 4 34688/60000][Iteration 1678][Wall Clock 187.55039021s] Trained 128 records in 0.116557222 seconds. Throughput is 1098.173 records/second. Loss is 2.1728377. Sequentiale465b572's hyper parameters: Current learning rate is 3.7355248412401944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 1679][Wall Clock 187.658998318s] Trained 128 records in 0.108608108 seconds. Throughput is 1178.5492 records/second. Loss is 2.2031753. Sequentiale465b572's hyper parameters: Current learning rate is 3.734129947722181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 34944/60000][Iteration 1680][Wall Clock 187.755062332s] Trained 128 records in 0.096064014 seconds. Throughput is 1332.4448 records/second. Loss is 2.176803. Sequentiale465b572's hyper parameters: Current learning rate is 3.7327360955580435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 1681][Wall Clock 187.850196349s] Trained 128 records in 0.095134017 seconds. Throughput is 1345.4703 records/second. Loss is 2.1813722. Sequentiale465b572's hyper parameters: Current learning rate is 3.73134328358209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35200/60000][Iteration 1682][Wall Clock 187.946190131s] Trained 128 records in 0.095993782 seconds. Throughput is 1333.4197 records/second. Loss is 2.1796966. Sequentiale465b572's hyper parameters: Current learning rate is 3.729951510630362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 1683][Wall Clock 188.042595702s] Trained 128 records in 0.096405571 seconds. Throughput is 1327.7241 records/second. Loss is 2.1656446. Sequentiale465b572's hyper parameters: Current learning rate is 3.7285607755406416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35456/60000][Iteration 1684][Wall Clock 188.140370072s] Trained 128 records in 0.09777437 seconds. Throughput is 1309.1365 records/second. Loss is 2.184723. Sequentiale465b572's hyper parameters: Current learning rate is 3.7271710771524417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 1685][Wall Clock 188.2386267s] Trained 128 records in 0.098256628 seconds. Throughput is 1302.7112 records/second. Loss is 2.1725109. Sequentiale465b572's hyper parameters: Current learning rate is 3.7257824143070045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35712/60000][Iteration 1686][Wall Clock 188.332872741s] Trained 128 records in 0.094246041 seconds. Throughput is 1358.1473 records/second. Loss is 2.1783423. Sequentiale465b572's hyper parameters: Current learning rate is 3.7243947858472997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 1687][Wall Clock 188.428026016s] Trained 128 records in 0.095153275 seconds. Throughput is 1345.1981 records/second. Loss is 2.1799476. Sequentiale465b572's hyper parameters: Current learning rate is 3.7230081906180194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:51 INFO  DistriOptimizer$:408 - [Epoch 4 35968/60000][Iteration 1688][Wall Clock 188.520663542s] Trained 128 records in 0.092637526 seconds. Throughput is 1381.7295 records/second. Loss is 2.1730464. Sequentiale465b572's hyper parameters: Current learning rate is 3.7216226274655747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 1689][Wall Clock 188.619268943s] Trained 128 records in 0.098605401 seconds. Throughput is 1298.1033 records/second. Loss is 2.1770363. Sequentiale465b572's hyper parameters: Current learning rate is 3.7202380952380956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36224/60000][Iteration 1690][Wall Clock 188.712457233s] Trained 128 records in 0.09318829 seconds. Throughput is 1373.5631 records/second. Loss is 2.1746452. Sequentiale465b572's hyper parameters: Current learning rate is 3.718854592785422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 1691][Wall Clock 188.80280843s] Trained 128 records in 0.090351197 seconds. Throughput is 1416.6941 records/second. Loss is 2.1931553. Sequentiale465b572's hyper parameters: Current learning rate is 3.717472118959108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36480/60000][Iteration 1692][Wall Clock 188.897600274s] Trained 128 records in 0.094791844 seconds. Throughput is 1350.3271 records/second. Loss is 2.1798759. Sequentiale465b572's hyper parameters: Current learning rate is 3.716090672612412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 1693][Wall Clock 189.008151406s] Trained 128 records in 0.110551132 seconds. Throughput is 1157.8352 records/second. Loss is 2.1716087. Sequentiale465b572's hyper parameters: Current learning rate is 3.714710252600297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36736/60000][Iteration 1694][Wall Clock 189.102722479s] Trained 128 records in 0.094571073 seconds. Throughput is 1353.4794 records/second. Loss is 2.1769092. Sequentiale465b572's hyper parameters: Current learning rate is 3.713330857779428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 1695][Wall Clock 189.196790382s] Trained 128 records in 0.094067903 seconds. Throughput is 1360.7192 records/second. Loss is 2.180676. Sequentiale465b572's hyper parameters: Current learning rate is 3.7119524870081667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 36992/60000][Iteration 1696][Wall Clock 189.292636812s] Trained 128 records in 0.09584643 seconds. Throughput is 1335.4697 records/second. Loss is 2.1789243. Sequentiale465b572's hyper parameters: Current learning rate is 3.7105751391465676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 1697][Wall Clock 189.391037523s] Trained 128 records in 0.098400711 seconds. Throughput is 1300.8036 records/second. Loss is 2.1724489. Sequentiale465b572's hyper parameters: Current learning rate is 3.7091988130563805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:52 INFO  DistriOptimizer$:408 - [Epoch 4 37248/60000][Iteration 1698][Wall Clock 189.487706481s] Trained 128 records in 0.096668958 seconds. Throughput is 1324.1066 records/second. Loss is 2.160208. Sequentiale465b572's hyper parameters: Current learning rate is 3.707823507601038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 1699][Wall Clock 189.584326872s] Trained 128 records in 0.096620391 seconds. Throughput is 1324.7721 records/second. Loss is 2.1723602. Sequentiale465b572's hyper parameters: Current learning rate is 3.706449221645664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 37504/60000][Iteration 1700][Wall Clock 189.678457378s] Trained 128 records in 0.094130506 seconds. Throughput is 1359.8142 records/second. Loss is 2.1684165. Sequentiale465b572's hyper parameters: Current learning rate is 3.7050759540570587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 1701][Wall Clock 189.785189587s] Trained 128 records in 0.106732209 seconds. Throughput is 1199.2631 records/second. Loss is 2.1773167. Sequentiale465b572's hyper parameters: Current learning rate is 3.7037037037037035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 37760/60000][Iteration 1702][Wall Clock 189.889306755s] Trained 128 records in 0.104117168 seconds. Throughput is 1229.3842 records/second. Loss is 2.1790566. Sequentiale465b572's hyper parameters: Current learning rate is 3.7023324694557573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 1703][Wall Clock 189.990526099s] Trained 128 records in 0.101219344 seconds. Throughput is 1264.5804 records/second. Loss is 2.17438. Sequentiale465b572's hyper parameters: Current learning rate is 3.7009622501850485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 38016/60000][Iteration 1704][Wall Clock 190.090913141s] Trained 128 records in 0.100387042 seconds. Throughput is 1275.065 records/second. Loss is 2.1612384. Sequentiale465b572's hyper parameters: Current learning rate is 3.6995930447650754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 1705][Wall Clock 190.191307743s] Trained 128 records in 0.100394602 seconds. Throughput is 1274.969 records/second. Loss is 2.1865122. Sequentiale465b572's hyper parameters: Current learning rate is 3.6982248520710064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 38272/60000][Iteration 1706][Wall Clock 190.285467251s] Trained 128 records in 0.094159508 seconds. Throughput is 1359.3954 records/second. Loss is 2.1656199. Sequentiale465b572's hyper parameters: Current learning rate is 3.696857670979667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 1707][Wall Clock 190.379818567s] Trained 128 records in 0.094351316 seconds. Throughput is 1356.6318 records/second. Loss is 2.1950486. Sequentiale465b572's hyper parameters: Current learning rate is 3.695491500369549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:53 INFO  DistriOptimizer$:408 - [Epoch 4 38528/60000][Iteration 1708][Wall Clock 190.474058468s] Trained 128 records in 0.094239901 seconds. Throughput is 1358.2357 records/second. Loss is 2.1637132. Sequentiale465b572's hyper parameters: Current learning rate is 3.6941263391207984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 1709][Wall Clock 190.567030366s] Trained 128 records in 0.092971898 seconds. Throughput is 1376.7601 records/second. Loss is 2.169515. Sequentiale465b572's hyper parameters: Current learning rate is 3.692762186115214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 38784/60000][Iteration 1710][Wall Clock 190.665049125s] Trained 128 records in 0.098018759 seconds. Throughput is 1305.8724 records/second. Loss is 2.1807015. Sequentiale465b572's hyper parameters: Current learning rate is 3.6913990402362494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 1711][Wall Clock 190.758878173s] Trained 128 records in 0.093829048 seconds. Throughput is 1364.1831 records/second. Loss is 2.1545546. Sequentiale465b572's hyper parameters: Current learning rate is 3.6900369003690036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39040/60000][Iteration 1712][Wall Clock 190.848931269s] Trained 128 records in 0.090053096 seconds. Throughput is 1421.3837 records/second. Loss is 2.1800053. Sequentiale465b572's hyper parameters: Current learning rate is 3.688675765400221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 1713][Wall Clock 190.941737895s] Trained 128 records in 0.092806626 seconds. Throughput is 1379.2119 records/second. Loss is 2.1852074. Sequentiale465b572's hyper parameters: Current learning rate is 3.6873156342182896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39296/60000][Iteration 1714][Wall Clock 191.033501648s] Trained 128 records in 0.091763753 seconds. Throughput is 1394.8864 records/second. Loss is 2.1790469. Sequentiale465b572's hyper parameters: Current learning rate is 3.6859565057132326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 1715][Wall Clock 191.125733025s] Trained 128 records in 0.092231377 seconds. Throughput is 1387.8141 records/second. Loss is 2.162355. Sequentiale465b572's hyper parameters: Current learning rate is 3.6845983787767134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39552/60000][Iteration 1716][Wall Clock 191.223069953s] Trained 128 records in 0.097336928 seconds. Throughput is 1315.02 records/second. Loss is 2.160301. Sequentiale465b572's hyper parameters: Current learning rate is 3.683241252302026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 1717][Wall Clock 191.318086255s] Trained 128 records in 0.095016302 seconds. Throughput is 1347.1373 records/second. Loss is 2.1831439. Sequentiale465b572's hyper parameters: Current learning rate is 3.681885125184094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39808/60000][Iteration 1718][Wall Clock 191.419038937s] Trained 128 records in 0.100952682 seconds. Throughput is 1267.9207 records/second. Loss is 2.1769214. Sequentiale465b572's hyper parameters: Current learning rate is 3.68052999631947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:54 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 1719][Wall Clock 191.518823673s] Trained 128 records in 0.099784736 seconds. Throughput is 1282.7612 records/second. Loss is 2.1840317. Sequentiale465b572's hyper parameters: Current learning rate is 3.679175864606328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40064/60000][Iteration 1720][Wall Clock 191.61960681s] Trained 128 records in 0.100783137 seconds. Throughput is 1270.0537 records/second. Loss is 2.1690576. Sequentiale465b572's hyper parameters: Current learning rate is 3.6778227289444644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 1721][Wall Clock 191.716262057s] Trained 128 records in 0.096655247 seconds. Throughput is 1324.2943 records/second. Loss is 2.169634. Sequentiale465b572's hyper parameters: Current learning rate is 3.6764705882352946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40320/60000][Iteration 1722][Wall Clock 191.813950507s] Trained 128 records in 0.09768845 seconds. Throughput is 1310.288 records/second. Loss is 2.1656199. Sequentiale465b572's hyper parameters: Current learning rate is 3.6751194413818446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 1723][Wall Clock 191.915288809s] Trained 128 records in 0.101338302 seconds. Throughput is 1263.096 records/second. Loss is 2.1613843. Sequentiale465b572's hyper parameters: Current learning rate is 3.6737692872887586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40576/60000][Iteration 1724][Wall Clock 192.018495829s] Trained 128 records in 0.10320702 seconds. Throughput is 1240.2257 records/second. Loss is 2.1760378. Sequentiale465b572's hyper parameters: Current learning rate is 3.6724201248622846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 1725][Wall Clock 192.113532509s] Trained 128 records in 0.09503668 seconds. Throughput is 1346.8484 records/second. Loss is 2.1584165. Sequentiale465b572's hyper parameters: Current learning rate is 3.671071953010279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40832/60000][Iteration 1726][Wall Clock 192.213453904s] Trained 128 records in 0.099921395 seconds. Throughput is 1281.007 records/second. Loss is 2.1654394. Sequentiale465b572's hyper parameters: Current learning rate is 3.669724770642202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 1727][Wall Clock 192.329070466s] Trained 128 records in 0.115616562 seconds. Throughput is 1107.1078 records/second. Loss is 2.174847. Sequentiale465b572's hyper parameters: Current learning rate is 3.6683785766691124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 41088/60000][Iteration 1728][Wall Clock 192.426678522s] Trained 128 records in 0.097608056 seconds. Throughput is 1311.3671 records/second. Loss is 2.1896849. Sequentiale465b572's hyper parameters: Current learning rate is 3.6670333700036665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:55 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 1729][Wall Clock 192.524008664s] Trained 128 records in 0.097330142 seconds. Throughput is 1315.1116 records/second. Loss is 2.1763844. Sequentiale465b572's hyper parameters: Current learning rate is 3.665689149560118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 41344/60000][Iteration 1730][Wall Clock 192.627938043s] Trained 128 records in 0.103929379 seconds. Throughput is 1231.6056 records/second. Loss is 2.1723735. Sequentiale465b572's hyper parameters: Current learning rate is 3.6643459142543056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 1731][Wall Clock 192.72785957s] Trained 128 records in 0.099921527 seconds. Throughput is 1281.0052 records/second. Loss is 2.172934. Sequentiale465b572's hyper parameters: Current learning rate is 3.663003663003663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 41600/60000][Iteration 1732][Wall Clock 192.823221494s] Trained 128 records in 0.095361924 seconds. Throughput is 1342.2548 records/second. Loss is 2.1780686. Sequentiale465b572's hyper parameters: Current learning rate is 3.6616623947272064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 1733][Wall Clock 192.915451221s] Trained 128 records in 0.092229727 seconds. Throughput is 1387.8389 records/second. Loss is 2.1891227. Sequentiale465b572's hyper parameters: Current learning rate is 3.660322108345534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 41856/60000][Iteration 1734][Wall Clock 193.01350934s] Trained 128 records in 0.098058119 seconds. Throughput is 1305.3483 records/second. Loss is 2.16628. Sequentiale465b572's hyper parameters: Current learning rate is 3.6589828027808267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 1735][Wall Clock 193.106289667s] Trained 128 records in 0.092780327 seconds. Throughput is 1379.6028 records/second. Loss is 2.1840293. Sequentiale465b572's hyper parameters: Current learning rate is 3.65764447695684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 42112/60000][Iteration 1736][Wall Clock 193.201475232s] Trained 128 records in 0.095185565 seconds. Throughput is 1344.7417 records/second. Loss is 2.169377. Sequentiale465b572's hyper parameters: Current learning rate is 3.656307129798903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 1737][Wall Clock 193.294768433s] Trained 128 records in 0.093293201 seconds. Throughput is 1372.0186 records/second. Loss is 2.159779. Sequentiale465b572's hyper parameters: Current learning rate is 3.6549707602339185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 42368/60000][Iteration 1738][Wall Clock 193.390139292s] Trained 128 records in 0.095370859 seconds. Throughput is 1342.129 records/second. Loss is 2.175391. Sequentiale465b572's hyper parameters: Current learning rate is 3.6536353671903543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:56 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 1739][Wall Clock 193.495320337s] Trained 128 records in 0.105181045 seconds. Throughput is 1216.9493 records/second. Loss is 2.162781. Sequentiale465b572's hyper parameters: Current learning rate is 3.652300949598247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 42624/60000][Iteration 1740][Wall Clock 193.588138775s] Trained 128 records in 0.092818438 seconds. Throughput is 1379.0364 records/second. Loss is 2.1642497. Sequentiale465b572's hyper parameters: Current learning rate is 3.650967506389193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 1741][Wall Clock 193.681371265s] Trained 128 records in 0.09323249 seconds. Throughput is 1372.912 records/second. Loss is 2.1735175. Sequentiale465b572's hyper parameters: Current learning rate is 3.64963503649635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 42880/60000][Iteration 1742][Wall Clock 193.772052905s] Trained 128 records in 0.09068164 seconds. Throughput is 1411.5316 records/second. Loss is 2.1707964. Sequentiale465b572's hyper parameters: Current learning rate is 3.6483035388544326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 1743][Wall Clock 193.871007566s] Trained 128 records in 0.098954661 seconds. Throughput is 1293.5216 records/second. Loss is 2.16777. Sequentiale465b572's hyper parameters: Current learning rate is 3.6469730123997083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43136/60000][Iteration 1744][Wall Clock 193.984513584s] Trained 128 records in 0.113506018 seconds. Throughput is 1127.6935 records/second. Loss is 2.1654477. Sequentiale465b572's hyper parameters: Current learning rate is 3.645643456069996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 1745][Wall Clock 194.081456817s] Trained 128 records in 0.096943233 seconds. Throughput is 1320.3604 records/second. Loss is 2.183674. Sequentiale465b572's hyper parameters: Current learning rate is 3.644314868804665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43392/60000][Iteration 1746][Wall Clock 194.175494204s] Trained 128 records in 0.094037387 seconds. Throughput is 1361.1608 records/second. Loss is 2.1723738. Sequentiale465b572's hyper parameters: Current learning rate is 3.6429872495446266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 1747][Wall Clock 194.272050813s] Trained 128 records in 0.096556609 seconds. Throughput is 1325.6472 records/second. Loss is 2.1668177. Sequentiale465b572's hyper parameters: Current learning rate is 3.641660597232338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43648/60000][Iteration 1748][Wall Clock 194.373806637s] Trained 128 records in 0.101755824 seconds. Throughput is 1257.9132 records/second. Loss is 2.16047. Sequentiale465b572's hyper parameters: Current learning rate is 3.640334910811795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:57 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 1749][Wall Clock 194.46988547s] Trained 128 records in 0.096078833 seconds. Throughput is 1332.2393 records/second. Loss is 2.1513834. Sequentiale465b572's hyper parameters: Current learning rate is 3.6390101892285295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 43904/60000][Iteration 1750][Wall Clock 194.560719042s] Trained 128 records in 0.090833572 seconds. Throughput is 1409.1705 records/second. Loss is 2.158666. Sequentiale465b572's hyper parameters: Current learning rate is 3.637686431429611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 1751][Wall Clock 194.658061972s] Trained 128 records in 0.09734293 seconds. Throughput is 1314.9388 records/second. Loss is 2.1808155. Sequentiale465b572's hyper parameters: Current learning rate is 3.6363636363636367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44160/60000][Iteration 1752][Wall Clock 194.772586956s] Trained 128 records in 0.114524984 seconds. Throughput is 1117.66 records/second. Loss is 2.1828747. Sequentiale465b572's hyper parameters: Current learning rate is 3.635041802980734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 1753][Wall Clock 194.87598257s] Trained 128 records in 0.103395614 seconds. Throughput is 1237.9636 records/second. Loss is 2.1929278. Sequentiale465b572's hyper parameters: Current learning rate is 3.6337209302325586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44416/60000][Iteration 1754][Wall Clock 194.981448945s] Trained 128 records in 0.105466375 seconds. Throughput is 1213.657 records/second. Loss is 2.161683. Sequentiale465b572's hyper parameters: Current learning rate is 3.632401017072285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 1755][Wall Clock 195.081077846s] Trained 128 records in 0.099628901 seconds. Throughput is 1284.7677 records/second. Loss is 2.1547387. Sequentiale465b572's hyper parameters: Current learning rate is 3.6310820624546115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44672/60000][Iteration 1756][Wall Clock 195.178376331s] Trained 128 records in 0.097298485 seconds. Throughput is 1315.5394 records/second. Loss is 2.1652064. Sequentiale465b572's hyper parameters: Current learning rate is 3.6297640653357535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 1757][Wall Clock 195.276212854s] Trained 128 records in 0.097836523 seconds. Throughput is 1308.3048 records/second. Loss is 2.1727896. Sequentiale465b572's hyper parameters: Current learning rate is 3.62844702467344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 44928/60000][Iteration 1758][Wall Clock 195.366175549s] Trained 128 records in 0.089962695 seconds. Throughput is 1422.8119 records/second. Loss is 2.1776593. Sequentiale465b572's hyper parameters: Current learning rate is 3.627130939426913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:58 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 1759][Wall Clock 195.459418827s] Trained 128 records in 0.093243278 seconds. Throughput is 1372.753 records/second. Loss is 2.1711173. Sequentiale465b572's hyper parameters: Current learning rate is 3.6258158085569254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45184/60000][Iteration 1760][Wall Clock 195.552535375s] Trained 128 records in 0.093116548 seconds. Throughput is 1374.6213 records/second. Loss is 2.1722298. Sequentiale465b572's hyper parameters: Current learning rate is 3.6245016310257333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 1761][Wall Clock 195.653672073s] Trained 128 records in 0.101136698 seconds. Throughput is 1265.6138 records/second. Loss is 2.168105. Sequentiale465b572's hyper parameters: Current learning rate is 3.623188405797102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45440/60000][Iteration 1762][Wall Clock 195.74841179s] Trained 128 records in 0.094739717 seconds. Throughput is 1351.0701 records/second. Loss is 2.175719. Sequentiale465b572's hyper parameters: Current learning rate is 3.621876131836291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 1763][Wall Clock 195.846270524s] Trained 128 records in 0.097858734 seconds. Throughput is 1308.0079 records/second. Loss is 2.1712675. Sequentiale465b572's hyper parameters: Current learning rate is 3.6205648081100655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45696/60000][Iteration 1764][Wall Clock 195.939847414s] Trained 128 records in 0.09357689 seconds. Throughput is 1367.859 records/second. Loss is 2.1861405. Sequentiale465b572's hyper parameters: Current learning rate is 3.619254433586681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 1765][Wall Clock 196.030088797s] Trained 128 records in 0.090241383 seconds. Throughput is 1418.418 records/second. Loss is 2.16789. Sequentiale465b572's hyper parameters: Current learning rate is 3.61794500723589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 45952/60000][Iteration 1766][Wall Clock 196.121108148s] Trained 128 records in 0.091019351 seconds. Throughput is 1406.2944 records/second. Loss is 2.1687415. Sequentiale465b572's hyper parameters: Current learning rate is 3.616636528028933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 1767][Wall Clock 196.212356097s] Trained 128 records in 0.091247949 seconds. Throughput is 1402.7714 records/second. Loss is 2.168281. Sequentiale465b572's hyper parameters: Current learning rate is 3.6153289949385393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 46208/60000][Iteration 1768][Wall Clock 196.306874799s] Trained 128 records in 0.094518702 seconds. Throughput is 1354.2294 records/second. Loss is 2.174745. Sequentiale465b572's hyper parameters: Current learning rate is 3.6140224069389226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 1769][Wall Clock 196.401946153s] Trained 128 records in 0.095071354 seconds. Throughput is 1346.3572 records/second. Loss is 2.1594315. Sequentiale465b572's hyper parameters: Current learning rate is 3.6127167630057807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:07:59 INFO  DistriOptimizer$:408 - [Epoch 4 46464/60000][Iteration 1770][Wall Clock 196.5013602s] Trained 128 records in 0.099414047 seconds. Throughput is 1287.5443 records/second. Loss is 2.1681683. Sequentiale465b572's hyper parameters: Current learning rate is 3.6114120621162876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 1771][Wall Clock 196.601727055s] Trained 128 records in 0.100366855 seconds. Throughput is 1275.3214 records/second. Loss is 2.1640892. Sequentiale465b572's hyper parameters: Current learning rate is 3.6101083032490973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 46720/60000][Iteration 1772][Wall Clock 196.692856435s] Trained 128 records in 0.09112938 seconds. Throughput is 1404.5964 records/second. Loss is 2.170029. Sequentiale465b572's hyper parameters: Current learning rate is 3.608805485384338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 1773][Wall Clock 196.791496037s] Trained 128 records in 0.098639602 seconds. Throughput is 1297.6533 records/second. Loss is 2.194298. Sequentiale465b572's hyper parameters: Current learning rate is 3.6075036075036075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 46976/60000][Iteration 1774][Wall Clock 196.889815069s] Trained 128 records in 0.098319032 seconds. Throughput is 1301.8843 records/second. Loss is 2.182784. Sequentiale465b572's hyper parameters: Current learning rate is 3.606202668589975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 1775][Wall Clock 196.981744086s] Trained 128 records in 0.091929017 seconds. Throughput is 1392.3787 records/second. Loss is 2.1699076. Sequentiale465b572's hyper parameters: Current learning rate is 3.604902667627974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 47232/60000][Iteration 1776][Wall Clock 197.07404979s] Trained 128 records in 0.092305704 seconds. Throughput is 1386.6965 records/second. Loss is 2.1721733. Sequentiale465b572's hyper parameters: Current learning rate is 3.603603603603603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 1777][Wall Clock 197.165776834s] Trained 128 records in 0.091727044 seconds. Throughput is 1395.4446 records/second. Loss is 2.1604779. Sequentiale465b572's hyper parameters: Current learning rate is 3.602305475504323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 47488/60000][Iteration 1778][Wall Clock 197.269935045s] Trained 128 records in 0.104158211 seconds. Throughput is 1228.8998 records/second. Loss is 2.1605103. Sequentiale465b572's hyper parameters: Current learning rate is 3.601008282319049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 1779][Wall Clock 197.374752103s] Trained 128 records in 0.104817058 seconds. Throughput is 1221.1753 records/second. Loss is 2.1719048. Sequentiale465b572's hyper parameters: Current learning rate is 3.599712023038157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:00 INFO  DistriOptimizer$:408 - [Epoch 4 47744/60000][Iteration 1780][Wall Clock 197.469115944s] Trained 128 records in 0.094363841 seconds. Throughput is 1356.4518 records/second. Loss is 2.1577017. Sequentiale465b572's hyper parameters: Current learning rate is 3.598416696653473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 1781][Wall Clock 197.563897163s] Trained 128 records in 0.094781219 seconds. Throughput is 1350.4785 records/second. Loss is 2.163308. Sequentiale465b572's hyper parameters: Current learning rate is 3.597122302158273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48000/60000][Iteration 1782][Wall Clock 197.657876804s] Trained 128 records in 0.093979641 seconds. Throughput is 1361.9971 records/second. Loss is 2.1664684. Sequentiale465b572's hyper parameters: Current learning rate is 3.595828838547285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 1783][Wall Clock 197.762381756s] Trained 128 records in 0.104504952 seconds. Throughput is 1224.8224 records/second. Loss is 2.1546302. Sequentiale465b572's hyper parameters: Current learning rate is 3.594536304816679E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48256/60000][Iteration 1784][Wall Clock 197.862994974s] Trained 128 records in 0.100613218 seconds. Throughput is 1272.1986 records/second. Loss is 2.1545982. Sequentiale465b572's hyper parameters: Current learning rate is 3.593244699964067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 1785][Wall Clock 197.953592011s] Trained 128 records in 0.090597037 seconds. Throughput is 1412.8499 records/second. Loss is 2.1901824. Sequentiale465b572's hyper parameters: Current learning rate is 3.591954022988506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48512/60000][Iteration 1786][Wall Clock 198.051235497s] Trained 128 records in 0.097643486 seconds. Throughput is 1310.8914 records/second. Loss is 2.1701844. Sequentiale465b572's hyper parameters: Current learning rate is 3.5906642728904844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 1787][Wall Clock 198.165199085s] Trained 128 records in 0.113963588 seconds. Throughput is 1123.1658 records/second. Loss is 2.1702163. Sequentiale465b572's hyper parameters: Current learning rate is 3.589375448671931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48768/60000][Iteration 1788][Wall Clock 198.269898764s] Trained 128 records in 0.104699679 seconds. Throughput is 1222.5443 records/second. Loss is 2.150946. Sequentiale465b572's hyper parameters: Current learning rate is 3.588087549336204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 1789][Wall Clock 198.36573232s] Trained 128 records in 0.095833556 seconds. Throughput is 1335.649 records/second. Loss is 2.1841352. Sequentiale465b572's hyper parameters: Current learning rate is 3.5868005738880915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:01 INFO  DistriOptimizer$:408 - [Epoch 4 49024/60000][Iteration 1790][Wall Clock 198.460234191s] Trained 128 records in 0.094501871 seconds. Throughput is 1354.4706 records/second. Loss is 2.170537. Sequentiale465b572's hyper parameters: Current learning rate is 3.585514521333811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 1791][Wall Clock 198.563043843s] Trained 128 records in 0.102809652 seconds. Throughput is 1245.0193 records/second. Loss is 2.161751. Sequentiale465b572's hyper parameters: Current learning rate is 3.5842293906810036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49280/60000][Iteration 1792][Wall Clock 198.678751076s] Trained 128 records in 0.115707233 seconds. Throughput is 1106.2402 records/second. Loss is 2.1602182. Sequentiale465b572's hyper parameters: Current learning rate is 3.5829451809387314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 1793][Wall Clock 198.825873348s] Trained 128 records in 0.147122272 seconds. Throughput is 870.0246 records/second. Loss is 2.143238. Sequentiale465b572's hyper parameters: Current learning rate is 3.581661891117479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49536/60000][Iteration 1794][Wall Clock 198.93391954s] Trained 128 records in 0.108046192 seconds. Throughput is 1184.6785 records/second. Loss is 2.1607397. Sequentiale465b572's hyper parameters: Current learning rate is 3.580379520229144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 1795][Wall Clock 199.030258114s] Trained 128 records in 0.096338574 seconds. Throughput is 1328.6473 records/second. Loss is 2.1574998. Sequentiale465b572's hyper parameters: Current learning rate is 3.5790980672870435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49792/60000][Iteration 1796][Wall Clock 199.131921105s] Trained 128 records in 0.101662991 seconds. Throughput is 1259.0619 records/second. Loss is 2.179684. Sequentiale465b572's hyper parameters: Current learning rate is 3.5778175313059033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 1797][Wall Clock 199.226380303s] Trained 128 records in 0.094459198 seconds. Throughput is 1355.0824 records/second. Loss is 2.1840465. Sequentiale465b572's hyper parameters: Current learning rate is 3.57653791130186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 50048/60000][Iteration 1798][Wall Clock 199.323859448s] Trained 128 records in 0.097479145 seconds. Throughput is 1313.1014 records/second. Loss is 2.1803222. Sequentiale465b572's hyper parameters: Current learning rate is 3.5752592062924567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:02 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 1799][Wall Clock 199.424163826s] Trained 128 records in 0.100304378 seconds. Throughput is 1276.1157 records/second. Loss is 2.1510832. Sequentiale465b572's hyper parameters: Current learning rate is 3.5739814152966406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 50304/60000][Iteration 1800][Wall Clock 199.51934744s] Trained 128 records in 0.095183614 seconds. Throughput is 1344.7693 records/second. Loss is 2.1795769. Sequentiale465b572's hyper parameters: Current learning rate is 3.572704537334763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 1801][Wall Clock 199.615464708s] Trained 128 records in 0.096117268 seconds. Throughput is 1331.7067 records/second. Loss is 2.1491003. Sequentiale465b572's hyper parameters: Current learning rate is 3.571428571428572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 50560/60000][Iteration 1802][Wall Clock 199.710124498s] Trained 128 records in 0.09465979 seconds. Throughput is 1352.2109 records/second. Loss is 2.1671665. Sequentiale465b572's hyper parameters: Current learning rate is 3.5701535166012135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 1803][Wall Clock 199.818458955s] Trained 128 records in 0.108334457 seconds. Throughput is 1181.5261 records/second. Loss is 2.1678178. Sequentiale465b572's hyper parameters: Current learning rate is 3.5688793718772306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 50816/60000][Iteration 1804][Wall Clock 199.907978093s] Trained 128 records in 0.089519138 seconds. Throughput is 1429.8619 records/second. Loss is 2.1639774. Sequentiale465b572's hyper parameters: Current learning rate is 3.5676061362825543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 1805][Wall Clock 200.004036874s] Trained 128 records in 0.096058781 seconds. Throughput is 1332.5175 records/second. Loss is 2.1507454. Sequentiale465b572's hyper parameters: Current learning rate is 3.5663338088445074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 51072/60000][Iteration 1806][Wall Clock 200.103851023s] Trained 128 records in 0.099814149 seconds. Throughput is 1282.3833 records/second. Loss is 2.15302. Sequentiale465b572's hyper parameters: Current learning rate is 3.565062388591801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 1807][Wall Clock 200.202089023s] Trained 128 records in 0.098238 seconds. Throughput is 1302.9581 records/second. Loss is 2.1678574. Sequentiale465b572's hyper parameters: Current learning rate is 3.563791874554526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 51328/60000][Iteration 1808][Wall Clock 200.290283565s] Trained 128 records in 0.088194542 seconds. Throughput is 1451.337 records/second. Loss is 2.163751. Sequentiale465b572's hyper parameters: Current learning rate is 3.562522265764161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 1809][Wall Clock 200.378951409s] Trained 128 records in 0.088667844 seconds. Throughput is 1443.5898 records/second. Loss is 2.1516292. Sequentiale465b572's hyper parameters: Current learning rate is 3.5612535612535614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:03 INFO  DistriOptimizer$:408 - [Epoch 4 51584/60000][Iteration 1810][Wall Clock 200.470382922s] Trained 128 records in 0.091431513 seconds. Throughput is 1399.955 records/second. Loss is 2.1581862. Sequentiale465b572's hyper parameters: Current learning rate is 3.5599857600569594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 1811][Wall Clock 200.563676971s] Trained 128 records in 0.093294049 seconds. Throughput is 1372.0061 records/second. Loss is 2.181544. Sequentiale465b572's hyper parameters: Current learning rate is 3.5587188612099647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 51840/60000][Iteration 1812][Wall Clock 200.652375771s] Trained 128 records in 0.0886988 seconds. Throughput is 1443.086 records/second. Loss is 2.171669. Sequentiale465b572's hyper parameters: Current learning rate is 3.5574528637495557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 1813][Wall Clock 200.744700503s] Trained 128 records in 0.092324732 seconds. Throughput is 1386.4108 records/second. Loss is 2.1772277. Sequentiale465b572's hyper parameters: Current learning rate is 3.556187766714082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52096/60000][Iteration 1814][Wall Clock 200.837177015s] Trained 128 records in 0.092476512 seconds. Throughput is 1384.1353 records/second. Loss is 2.166468. Sequentiale465b572's hyper parameters: Current learning rate is 3.554923569143264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 1815][Wall Clock 200.92998826s] Trained 128 records in 0.092811245 seconds. Throughput is 1379.1433 records/second. Loss is 2.1646147. Sequentiale465b572's hyper parameters: Current learning rate is 3.5536602700781805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52352/60000][Iteration 1816][Wall Clock 201.021313929s] Trained 128 records in 0.091325669 seconds. Throughput is 1401.5774 records/second. Loss is 2.155163. Sequentiale465b572's hyper parameters: Current learning rate is 3.552397868561279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 1817][Wall Clock 201.112932265s] Trained 128 records in 0.091618336 seconds. Throughput is 1397.1002 records/second. Loss is 2.1602547. Sequentiale465b572's hyper parameters: Current learning rate is 3.551136363636364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52608/60000][Iteration 1818][Wall Clock 201.211464945s] Trained 128 records in 0.09853268 seconds. Throughput is 1299.0614 records/second. Loss is 2.1749473. Sequentiale465b572's hyper parameters: Current learning rate is 3.549875754348598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 1819][Wall Clock 201.303575413s] Trained 128 records in 0.092110468 seconds. Throughput is 1389.6357 records/second. Loss is 2.1564097. Sequentiale465b572's hyper parameters: Current learning rate is 3.5486160397445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:04 INFO  DistriOptimizer$:408 - [Epoch 4 52864/60000][Iteration 1820][Wall Clock 201.402920397s] Trained 128 records in 0.099344984 seconds. Throughput is 1288.4395 records/second. Loss is 2.1540916. Sequentiale465b572's hyper parameters: Current learning rate is 3.547357218871941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 1821][Wall Clock 201.49335712s] Trained 128 records in 0.090436723 seconds. Throughput is 1415.3542 records/second. Loss is 2.1484563. Sequentiale465b572's hyper parameters: Current learning rate is 3.5460992907801415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53120/60000][Iteration 1822][Wall Clock 201.585633338s] Trained 128 records in 0.092276218 seconds. Throughput is 1387.1396 records/second. Loss is 2.1435142. Sequentiale465b572's hyper parameters: Current learning rate is 3.5448422545196744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 1823][Wall Clock 201.674643054s] Trained 128 records in 0.089009716 seconds. Throughput is 1438.0453 records/second. Loss is 2.1738083. Sequentiale465b572's hyper parameters: Current learning rate is 3.5435861091424523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53376/60000][Iteration 1824][Wall Clock 201.767401451s] Trained 128 records in 0.092758397 seconds. Throughput is 1379.929 records/second. Loss is 2.182079. Sequentiale465b572's hyper parameters: Current learning rate is 3.5423308537017357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 1825][Wall Clock 201.86031466s] Trained 128 records in 0.092913209 seconds. Throughput is 1377.6298 records/second. Loss is 2.15789. Sequentiale465b572's hyper parameters: Current learning rate is 3.541076487252125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53632/60000][Iteration 1826][Wall Clock 201.960212028s] Trained 128 records in 0.099897368 seconds. Throughput is 1281.3151 records/second. Loss is 2.1764777. Sequentiale465b572's hyper parameters: Current learning rate is 3.5398230088495576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 1827][Wall Clock 202.053762586s] Trained 128 records in 0.093550558 seconds. Throughput is 1368.2441 records/second. Loss is 2.159418. Sequentiale465b572's hyper parameters: Current learning rate is 3.5385704175513094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 53888/60000][Iteration 1828][Wall Clock 202.151475555s] Trained 128 records in 0.097712969 seconds. Throughput is 1309.9591 records/second. Loss is 2.1659958. Sequentiale465b572's hyper parameters: Current learning rate is 3.5373187124159886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 1829][Wall Clock 202.25402772s] Trained 128 records in 0.102552165 seconds. Throughput is 1248.1453 records/second. Loss is 2.167204. Sequentiale465b572's hyper parameters: Current learning rate is 3.5360678925035356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 54144/60000][Iteration 1830][Wall Clock 202.345680985s] Trained 128 records in 0.091653265 seconds. Throughput is 1396.5679 records/second. Loss is 2.1445496. Sequentiale465b572's hyper parameters: Current learning rate is 3.534817956875221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:05 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 1831][Wall Clock 202.456860289s] Trained 128 records in 0.111179304 seconds. Throughput is 1151.2933 records/second. Loss is 2.1744184. Sequentiale465b572's hyper parameters: Current learning rate is 3.5335689045936394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 54400/60000][Iteration 1832][Wall Clock 202.553962596s] Trained 128 records in 0.097102307 seconds. Throughput is 1318.1973 records/second. Loss is 2.1614687. Sequentiale465b572's hyper parameters: Current learning rate is 3.5323207347227127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 1833][Wall Clock 202.643663245s] Trained 128 records in 0.089700649 seconds. Throughput is 1426.9685 records/second. Loss is 2.1780348. Sequentiale465b572's hyper parameters: Current learning rate is 3.531073446327684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 54656/60000][Iteration 1834][Wall Clock 202.740184827s] Trained 128 records in 0.096521582 seconds. Throughput is 1326.1283 records/second. Loss is 2.1710153. Sequentiale465b572's hyper parameters: Current learning rate is 3.5298270384751147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 1835][Wall Clock 202.84781769s] Trained 128 records in 0.107632863 seconds. Throughput is 1189.2279 records/second. Loss is 2.1514995. Sequentiale465b572's hyper parameters: Current learning rate is 3.5285815102328866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 54912/60000][Iteration 1836][Wall Clock 202.945934829s] Trained 128 records in 0.098117139 seconds. Throughput is 1304.5631 records/second. Loss is 2.153069. Sequentiale465b572's hyper parameters: Current learning rate is 3.527336860670194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 1837][Wall Clock 203.041099537s] Trained 128 records in 0.095164708 seconds. Throughput is 1345.0364 records/second. Loss is 2.1671152. Sequentiale465b572's hyper parameters: Current learning rate is 3.526093088857546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 55168/60000][Iteration 1838][Wall Clock 203.132877965s] Trained 128 records in 0.091778428 seconds. Throughput is 1394.6632 records/second. Loss is 2.1715865. Sequentiale465b572's hyper parameters: Current learning rate is 3.524850193866761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 1839][Wall Clock 203.223585173s] Trained 128 records in 0.090707208 seconds. Throughput is 1411.1338 records/second. Loss is 2.1628668. Sequentiale465b572's hyper parameters: Current learning rate is 3.5236081747709656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 55424/60000][Iteration 1840][Wall Clock 203.317701732s] Trained 128 records in 0.094116559 seconds. Throughput is 1360.0157 records/second. Loss is 2.1640327. Sequentiale465b572's hyper parameters: Current learning rate is 3.522367030644593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:06 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 1841][Wall Clock 203.414932861s] Trained 128 records in 0.097231129 seconds. Throughput is 1316.4508 records/second. Loss is 2.173169. Sequentiale465b572's hyper parameters: Current learning rate is 3.5211267605633805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 55680/60000][Iteration 1842][Wall Clock 203.515222379s] Trained 128 records in 0.100289518 seconds. Throughput is 1276.3049 records/second. Loss is 2.1599889. Sequentiale465b572's hyper parameters: Current learning rate is 3.5198873636043646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 1843][Wall Clock 203.621286133s] Trained 128 records in 0.106063754 seconds. Throughput is 1206.8213 records/second. Loss is 2.1603892. Sequentiale465b572's hyper parameters: Current learning rate is 3.518648838845883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 55936/60000][Iteration 1844][Wall Clock 203.718818485s] Trained 128 records in 0.097532352 seconds. Throughput is 1312.385 records/second. Loss is 2.1716504. Sequentiale465b572's hyper parameters: Current learning rate is 3.5174111853675694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 1845][Wall Clock 203.842069457s] Trained 128 records in 0.123250972 seconds. Throughput is 1038.5314 records/second. Loss is 2.1749449. Sequentiale465b572's hyper parameters: Current learning rate is 3.516174402250351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56192/60000][Iteration 1846][Wall Clock 203.93163626s] Trained 128 records in 0.089566803 seconds. Throughput is 1429.1008 records/second. Loss is 2.1635633. Sequentiale465b572's hyper parameters: Current learning rate is 3.51493848857645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 1847][Wall Clock 204.024149286s] Trained 128 records in 0.092513026 seconds. Throughput is 1383.589 records/second. Loss is 2.1650581. Sequentiale465b572's hyper parameters: Current learning rate is 3.5137034434293746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56448/60000][Iteration 1848][Wall Clock 204.115788664s] Trained 128 records in 0.091639378 seconds. Throughput is 1396.7794 records/second. Loss is 2.163766. Sequentiale465b572's hyper parameters: Current learning rate is 3.5124692658939234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 1849][Wall Clock 204.206899941s] Trained 128 records in 0.091111277 seconds. Throughput is 1404.8755 records/second. Loss is 2.1573281. Sequentiale465b572's hyper parameters: Current learning rate is 3.51123595505618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56704/60000][Iteration 1850][Wall Clock 204.29550325s] Trained 128 records in 0.088603309 seconds. Throughput is 1444.6412 records/second. Loss is 2.1690598. Sequentiale465b572's hyper parameters: Current learning rate is 3.51000351000351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:07 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 1851][Wall Clock 204.387466996s] Trained 128 records in 0.091963746 seconds. Throughput is 1391.8528 records/second. Loss is 2.1714218. Sequentiale465b572's hyper parameters: Current learning rate is 3.508771929824561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 56960/60000][Iteration 1852][Wall Clock 204.476896947s] Trained 128 records in 0.089429951 seconds. Throughput is 1431.2878 records/second. Loss is 2.1797922. Sequentiale465b572's hyper parameters: Current learning rate is 3.50754121360926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 1853][Wall Clock 204.568810719s] Trained 128 records in 0.091913772 seconds. Throughput is 1392.6095 records/second. Loss is 2.1671424. Sequentiale465b572's hyper parameters: Current learning rate is 3.506311360448808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57216/60000][Iteration 1854][Wall Clock 204.664167429s] Trained 128 records in 0.09535671 seconds. Throughput is 1342.3282 records/second. Loss is 2.1559095. Sequentiale465b572's hyper parameters: Current learning rate is 3.505082369435682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 1855][Wall Clock 204.783842336s] Trained 128 records in 0.119674907 seconds. Throughput is 1069.5642 records/second. Loss is 2.1617045. Sequentiale465b572's hyper parameters: Current learning rate is 3.50385423966363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57472/60000][Iteration 1856][Wall Clock 204.880749252s] Trained 128 records in 0.096906916 seconds. Throughput is 1320.8552 records/second. Loss is 2.147972. Sequentiale465b572's hyper parameters: Current learning rate is 3.502626970227671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 1857][Wall Clock 204.971868391s] Trained 128 records in 0.091119139 seconds. Throughput is 1404.7543 records/second. Loss is 2.1574657. Sequentiale465b572's hyper parameters: Current learning rate is 3.5014005602240897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57728/60000][Iteration 1858][Wall Clock 205.067521389s] Trained 128 records in 0.095652998 seconds. Throughput is 1338.1703 records/second. Loss is 2.1814995. Sequentiale465b572's hyper parameters: Current learning rate is 3.5001750087504374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 1859][Wall Clock 205.158852684s] Trained 128 records in 0.091331295 seconds. Throughput is 1401.4911 records/second. Loss is 2.1612349. Sequentiale465b572's hyper parameters: Current learning rate is 3.498950314905528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 57984/60000][Iteration 1860][Wall Clock 205.253791803s] Trained 128 records in 0.094939119 seconds. Throughput is 1348.2324 records/second. Loss is 2.165528. Sequentiale465b572's hyper parameters: Current learning rate is 3.497726477789437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 1861][Wall Clock 205.349480928s] Trained 128 records in 0.095689125 seconds. Throughput is 1337.665 records/second. Loss is 2.1607342. Sequentiale465b572's hyper parameters: Current learning rate is 3.496503496503496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:08 INFO  DistriOptimizer$:408 - [Epoch 4 58240/60000][Iteration 1862][Wall Clock 205.44751414s] Trained 128 records in 0.098033212 seconds. Throughput is 1305.6799 records/second. Loss is 2.170929. Sequentiale465b572's hyper parameters: Current learning rate is 3.4952813701502974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 1863][Wall Clock 205.53952332s] Trained 128 records in 0.09200918 seconds. Throughput is 1391.1655 records/second. Loss is 2.1689208. Sequentiale465b572's hyper parameters: Current learning rate is 3.4940600978336826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 58496/60000][Iteration 1864][Wall Clock 205.633230098s] Trained 128 records in 0.093706778 seconds. Throughput is 1365.963 records/second. Loss is 2.156794. Sequentiale465b572's hyper parameters: Current learning rate is 3.4928396786587494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 1865][Wall Clock 205.727230764s] Trained 128 records in 0.094000666 seconds. Throughput is 1361.6925 records/second. Loss is 2.191247. Sequentiale465b572's hyper parameters: Current learning rate is 3.4916201117318437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 58752/60000][Iteration 1866][Wall Clock 205.820885461s] Trained 128 records in 0.093654697 seconds. Throughput is 1366.7227 records/second. Loss is 2.1706166. Sequentiale465b572's hyper parameters: Current learning rate is 3.490401396160558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 1867][Wall Clock 205.913169339s] Trained 128 records in 0.092283878 seconds. Throughput is 1387.0245 records/second. Loss is 2.148862. Sequentiale465b572's hyper parameters: Current learning rate is 3.489183531053733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 59008/60000][Iteration 1868][Wall Clock 206.015799757s] Trained 128 records in 0.102630418 seconds. Throughput is 1247.1936 records/second. Loss is 2.164492. Sequentiale465b572's hyper parameters: Current learning rate is 3.487966515521451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 1869][Wall Clock 206.109674022s] Trained 128 records in 0.093874265 seconds. Throughput is 1363.526 records/second. Loss is 2.1614296. Sequentiale465b572's hyper parameters: Current learning rate is 3.486750348675035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 59264/60000][Iteration 1870][Wall Clock 206.220902868s] Trained 128 records in 0.111228846 seconds. Throughput is 1150.7806 records/second. Loss is 2.1803758. Sequentiale465b572's hyper parameters: Current learning rate is 3.4855350296270483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 1871][Wall Clock 206.321080702s] Trained 128 records in 0.100177834 seconds. Throughput is 1277.7278 records/second. Loss is 2.1583326. Sequentiale465b572's hyper parameters: Current learning rate is 3.484320557491289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:09 INFO  DistriOptimizer$:408 - [Epoch 4 59520/60000][Iteration 1872][Wall Clock 206.411717821s] Trained 128 records in 0.090637119 seconds. Throughput is 1412.225 records/second. Loss is 2.1412308. Sequentiale465b572's hyper parameters: Current learning rate is 3.4831069313827936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:10 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 1873][Wall Clock 206.503516331s] Trained 128 records in 0.09179851 seconds. Throughput is 1394.3582 records/second. Loss is 2.1696858. Sequentiale465b572's hyper parameters: Current learning rate is 3.4818941504178273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:10 INFO  DistriOptimizer$:408 - [Epoch 4 59776/60000][Iteration 1874][Wall Clock 206.597464275s] Trained 128 records in 0.093947944 seconds. Throughput is 1362.4565 records/second. Loss is 2.1664555. Sequentiale465b572's hyper parameters: Current learning rate is 3.4806822137138876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:10 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 1875][Wall Clock 206.68908002s] Trained 128 records in 0.091615745 seconds. Throughput is 1397.1398 records/second. Loss is 2.1429396. Sequentiale465b572's hyper parameters: Current learning rate is 3.479471120389701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:10 INFO  DistriOptimizer$:408 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 206.786083098s] Trained 128 records in 0.097003078 seconds. Throughput is 1319.5458 records/second. Loss is 2.1524749. Sequentiale465b572's hyper parameters: Current learning rate is 3.4782608695652176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:10 INFO  DistriOptimizer$:452 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 206.786083098s] Epoch finished. Wall clock time is 208228.462303 ms
2019-10-15 20:08:10 INFO  DistriOptimizer$:111 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 206.786083098s] Validate model...
2019-10-15 20:08:11 INFO  DistriOptimizer$:178 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 206.786083098s] validate model throughput is 11313.549 records/second
2019-10-15 20:08:11 INFO  DistriOptimizer$:181 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 206.786083098s] Top1Accuracy is Accuracy(correct: 4295, count: 10000, accuracy: 0.4295)
2019-10-15 20:08:11 INFO  DistriOptimizer$:221 - [Wall Clock 208.228462303s] Save model to /tmp/lenet5/20191015_200441
2019-10-15 20:08:11 INFO  DistriOptimizer$:226 - [Wall Clock 208.228462303s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@c83982c to /tmp/lenet5/20191015_200441
2019-10-15 20:08:11 INFO  DistriOptimizer$:408 - [Epoch 5 128/60000][Iteration 1877][Wall Clock 208.332068567s] Trained 128 records in 0.103606264 seconds. Throughput is 1235.4465 records/second. Loss is 2.1759505. Sequentiale465b572's hyper parameters: Current learning rate is 3.477051460361613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:11 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 1878][Wall Clock 208.435614442s] Trained 128 records in 0.103545875 seconds. Throughput is 1236.1671 records/second. Loss is 2.164833. Sequentiale465b572's hyper parameters: Current learning rate is 3.475842891901286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:11 INFO  DistriOptimizer$:408 - [Epoch 5 384/60000][Iteration 1879][Wall Clock 208.548564506s] Trained 128 records in 0.112950064 seconds. Throughput is 1133.2441 records/second. Loss is 2.1623638. Sequentiale465b572's hyper parameters: Current learning rate is 3.4746351633078526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:11 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 1880][Wall Clock 208.647351127s] Trained 128 records in 0.098786621 seconds. Throughput is 1295.722 records/second. Loss is 2.173254. Sequentiale465b572's hyper parameters: Current learning rate is 3.473428273706148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:11 INFO  DistriOptimizer$:408 - [Epoch 5 640/60000][Iteration 1881][Wall Clock 208.748295615s] Trained 128 records in 0.100944488 seconds. Throughput is 1268.0237 records/second. Loss is 2.1597447. Sequentiale465b572's hyper parameters: Current learning rate is 3.4722222222222224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:11 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 1882][Wall Clock 208.852695783s] Trained 128 records in 0.104400168 seconds. Throughput is 1226.0518 records/second. Loss is 2.150153. Sequentiale465b572's hyper parameters: Current learning rate is 3.471017007983339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 896/60000][Iteration 1883][Wall Clock 208.949948718s] Trained 128 records in 0.097252935 seconds. Throughput is 1316.1556 records/second. Loss is 2.1688335. Sequentiale465b572's hyper parameters: Current learning rate is 3.4698126301179735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 1884][Wall Clock 209.047629312s] Trained 128 records in 0.097680594 seconds. Throughput is 1310.3934 records/second. Loss is 2.138599. Sequentiale465b572's hyper parameters: Current learning rate is 3.46860908775581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1152/60000][Iteration 1885][Wall Clock 209.144808248s] Trained 128 records in 0.097178936 seconds. Throughput is 1317.1578 records/second. Loss is 2.1566935. Sequentiale465b572's hyper parameters: Current learning rate is 3.467406380027739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 1886][Wall Clock 209.241073371s] Trained 128 records in 0.096265123 seconds. Throughput is 1329.6613 records/second. Loss is 2.149329. Sequentiale465b572's hyper parameters: Current learning rate is 3.466204506065858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1408/60000][Iteration 1887][Wall Clock 209.335426643s] Trained 128 records in 0.094353272 seconds. Throughput is 1356.6038 records/second. Loss is 2.1501467. Sequentiale465b572's hyper parameters: Current learning rate is 3.465003465003465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 1888][Wall Clock 209.431170014s] Trained 128 records in 0.095743371 seconds. Throughput is 1336.9071 records/second. Loss is 2.1707954. Sequentiale465b572's hyper parameters: Current learning rate is 3.4638032559750607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1664/60000][Iteration 1889][Wall Clock 209.528400493s] Trained 128 records in 0.097230479 seconds. Throughput is 1316.4596 records/second. Loss is 2.15289. Sequentiale465b572's hyper parameters: Current learning rate is 3.4626038781163435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 1890][Wall Clock 209.623382182s] Trained 128 records in 0.094981689 seconds. Throughput is 1347.6282 records/second. Loss is 2.1612442. Sequentiale465b572's hyper parameters: Current learning rate is 3.461405330564209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 1920/60000][Iteration 1891][Wall Clock 209.719804937s] Trained 128 records in 0.096422755 seconds. Throughput is 1327.4875 records/second. Loss is 2.1683064. Sequentiale465b572's hyper parameters: Current learning rate is 3.4602076124567473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:12 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 1892][Wall Clock 209.834640192s] Trained 128 records in 0.114835255 seconds. Throughput is 1114.6403 records/second. Loss is 2.1317534. Sequentiale465b572's hyper parameters: Current learning rate is 3.459010722933241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2176/60000][Iteration 1893][Wall Clock 209.928625211s] Trained 128 records in 0.093985019 seconds. Throughput is 1361.9192 records/second. Loss is 2.1335387. Sequentiale465b572's hyper parameters: Current learning rate is 3.457814661134163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 1894][Wall Clock 210.024715719s] Trained 128 records in 0.096090508 seconds. Throughput is 1332.0774 records/second. Loss is 2.1563463. Sequentiale465b572's hyper parameters: Current learning rate is 3.456619426201176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2432/60000][Iteration 1895][Wall Clock 210.11850924s] Trained 128 records in 0.093793521 seconds. Throughput is 1364.6998 records/second. Loss is 2.1608052. Sequentiale465b572's hyper parameters: Current learning rate is 3.455425017277125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 1896][Wall Clock 210.220412771s] Trained 128 records in 0.101903531 seconds. Throughput is 1256.09 records/second. Loss is 2.146675. Sequentiale465b572's hyper parameters: Current learning rate is 3.454231433506045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2688/60000][Iteration 1897][Wall Clock 210.322789295s] Trained 128 records in 0.102376524 seconds. Throughput is 1250.2866 records/second. Loss is 2.1838226. Sequentiale465b572's hyper parameters: Current learning rate is 3.4530386740331496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 1898][Wall Clock 210.421403119s] Trained 128 records in 0.098613824 seconds. Throughput is 1297.9926 records/second. Loss is 2.1424515. Sequentiale465b572's hyper parameters: Current learning rate is 3.4518467380048324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 2944/60000][Iteration 1899][Wall Clock 210.514922673s] Trained 128 records in 0.093519554 seconds. Throughput is 1368.6978 records/second. Loss is 2.1854217. Sequentiale465b572's hyper parameters: Current learning rate is 3.450655624568668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 1900][Wall Clock 210.611020771s] Trained 128 records in 0.096098098 seconds. Throughput is 1331.9723 records/second. Loss is 2.168272. Sequentiale465b572's hyper parameters: Current learning rate is 3.4494653328734045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 3200/60000][Iteration 1901][Wall Clock 210.707808993s] Trained 128 records in 0.096788222 seconds. Throughput is 1322.475 records/second. Loss is 2.1683953. Sequentiale465b572's hyper parameters: Current learning rate is 3.448275862068965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:13 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 1902][Wall Clock 210.803069148s] Trained 128 records in 0.095260155 seconds. Throughput is 1343.6887 records/second. Loss is 2.1591883. Sequentiale465b572's hyper parameters: Current learning rate is 3.447087211306446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 3456/60000][Iteration 1903][Wall Clock 210.89757225s] Trained 128 records in 0.094503102 seconds. Throughput is 1354.4529 records/second. Loss is 2.1793907. Sequentiale465b572's hyper parameters: Current learning rate is 3.4458993797381116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 1904][Wall Clock 210.997702305s] Trained 128 records in 0.100130055 seconds. Throughput is 1278.3375 records/second. Loss is 2.1679633. Sequentiale465b572's hyper parameters: Current learning rate is 3.444712366517396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 3712/60000][Iteration 1905][Wall Clock 211.106401518s] Trained 128 records in 0.108699213 seconds. Throughput is 1177.5614 records/second. Loss is 2.137434. Sequentiale465b572's hyper parameters: Current learning rate is 3.443526170798898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 1906][Wall Clock 211.210361685s] Trained 128 records in 0.103960167 seconds. Throughput is 1231.2408 records/second. Loss is 2.1654325. Sequentiale465b572's hyper parameters: Current learning rate is 3.442340791738382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 3968/60000][Iteration 1907][Wall Clock 211.307691674s] Trained 128 records in 0.097329989 seconds. Throughput is 1315.1136 records/second. Loss is 2.1605368. Sequentiale465b572's hyper parameters: Current learning rate is 3.4411562284927734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 1908][Wall Clock 211.396992005s] Trained 128 records in 0.089300331 seconds. Throughput is 1433.3652 records/second. Loss is 2.1551013. Sequentiale465b572's hyper parameters: Current learning rate is 3.439972480220158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 4224/60000][Iteration 1909][Wall Clock 211.492431227s] Trained 128 records in 0.095439222 seconds. Throughput is 1341.1676 records/second. Loss is 2.1491716. Sequentiale465b572's hyper parameters: Current learning rate is 3.4387895460797794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 1910][Wall Clock 211.587044466s] Trained 128 records in 0.094613239 seconds. Throughput is 1352.8762 records/second. Loss is 2.1535828. Sequentiale465b572's hyper parameters: Current learning rate is 3.4376074252320387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 4480/60000][Iteration 1911][Wall Clock 211.683601677s] Trained 128 records in 0.096557211 seconds. Throughput is 1325.639 records/second. Loss is 2.1611784. Sequentiale465b572's hyper parameters: Current learning rate is 3.4364261168384877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 1912][Wall Clock 211.777595534s] Trained 128 records in 0.093993857 seconds. Throughput is 1361.7911 records/second. Loss is 2.1519868. Sequentiale465b572's hyper parameters: Current learning rate is 3.4352456200618345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:14 INFO  DistriOptimizer$:408 - [Epoch 5 4736/60000][Iteration 1913][Wall Clock 211.869452664s] Trained 128 records in 0.09185713 seconds. Throughput is 1393.4684 records/second. Loss is 2.1547148. Sequentiale465b572's hyper parameters: Current learning rate is 3.4340659340659343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 1914][Wall Clock 211.957917451s] Trained 128 records in 0.088464787 seconds. Throughput is 1446.9033 records/second. Loss is 2.1529114. Sequentiale465b572's hyper parameters: Current learning rate is 3.432887058015791E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 4992/60000][Iteration 1915][Wall Clock 212.052586418s] Trained 128 records in 0.094668967 seconds. Throughput is 1352.0798 records/second. Loss is 2.1533005. Sequentiale465b572's hyper parameters: Current learning rate is 3.4317089910775565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 1916][Wall Clock 212.143993458s] Trained 128 records in 0.09140704 seconds. Throughput is 1400.3298 records/second. Loss is 2.1506295. Sequentiale465b572's hyper parameters: Current learning rate is 3.430531732418525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5248/60000][Iteration 1917][Wall Clock 212.251711589s] Trained 128 records in 0.107718131 seconds. Throughput is 1188.2865 records/second. Loss is 2.138317. Sequentiale465b572's hyper parameters: Current learning rate is 3.429355281207133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 1918][Wall Clock 212.343585663s] Trained 128 records in 0.091874074 seconds. Throughput is 1393.2114 records/second. Loss is 2.1578267. Sequentiale465b572's hyper parameters: Current learning rate is 3.4281796366129587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5504/60000][Iteration 1919][Wall Clock 212.449540338s] Trained 128 records in 0.105954675 seconds. Throughput is 1208.0637 records/second. Loss is 2.1638849. Sequentiale465b572's hyper parameters: Current learning rate is 3.4270047978067166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 1920][Wall Clock 212.540392626s] Trained 128 records in 0.090852288 seconds. Throughput is 1408.8802 records/second. Loss is 2.1480958. Sequentiale465b572's hyper parameters: Current learning rate is 3.4258307639602604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5760/60000][Iteration 1921][Wall Clock 212.638957952s] Trained 128 records in 0.098565326 seconds. Throughput is 1298.6311 records/second. Loss is 2.1722686. Sequentiale465b572's hyper parameters: Current learning rate is 3.4246575342465754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 1922][Wall Clock 212.734452433s] Trained 128 records in 0.095494481 seconds. Throughput is 1340.3916 records/second. Loss is 2.1509206. Sequentiale465b572's hyper parameters: Current learning rate is 3.4234851078397807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:15 INFO  DistriOptimizer$:408 - [Epoch 5 6016/60000][Iteration 1923][Wall Clock 212.826016571s] Trained 128 records in 0.091564138 seconds. Throughput is 1397.9271 records/second. Loss is 2.1506112. Sequentiale465b572's hyper parameters: Current learning rate is 3.422313483915127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 1924][Wall Clock 212.91976704s] Trained 128 records in 0.093750469 seconds. Throughput is 1365.3265 records/second. Loss is 2.1524816. Sequentiale465b572's hyper parameters: Current learning rate is 3.4211426616489907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6272/60000][Iteration 1925][Wall Clock 213.014275689s] Trained 128 records in 0.094508649 seconds. Throughput is 1354.3734 records/second. Loss is 2.1565983. Sequentiale465b572's hyper parameters: Current learning rate is 3.419972640218878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 1926][Wall Clock 213.112210546s] Trained 128 records in 0.097934857 seconds. Throughput is 1306.9912 records/second. Loss is 2.1646855. Sequentiale465b572's hyper parameters: Current learning rate is 3.4188034188034193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6528/60000][Iteration 1927][Wall Clock 213.207168788s] Trained 128 records in 0.094958242 seconds. Throughput is 1347.9609 records/second. Loss is 2.155333. Sequentiale465b572's hyper parameters: Current learning rate is 3.4176349965823647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 1928][Wall Clock 213.29741334s] Trained 128 records in 0.090244552 seconds. Throughput is 1418.3682 records/second. Loss is 2.1604643. Sequentiale465b572's hyper parameters: Current learning rate is 3.4164673727365904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6784/60000][Iteration 1929][Wall Clock 213.411532948s] Trained 128 records in 0.114119608 seconds. Throughput is 1121.6301 records/second. Loss is 2.1593208. Sequentiale465b572's hyper parameters: Current learning rate is 3.4153005464480874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 1930][Wall Clock 213.505349684s] Trained 128 records in 0.093816736 seconds. Throughput is 1364.3622 records/second. Loss is 2.161479. Sequentiale465b572's hyper parameters: Current learning rate is 3.4141345168999654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 7040/60000][Iteration 1931][Wall Clock 213.607448258s] Trained 128 records in 0.102098574 seconds. Throughput is 1253.6903 records/second. Loss is 2.1351938. Sequentiale465b572's hyper parameters: Current learning rate is 3.412969283276451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 1932][Wall Clock 213.708533808s] Trained 128 records in 0.10108555 seconds. Throughput is 1266.2542 records/second. Loss is 2.1522577. Sequentiale465b572's hyper parameters: Current learning rate is 3.41180484476288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:16 INFO  DistriOptimizer$:408 - [Epoch 5 7296/60000][Iteration 1933][Wall Clock 213.798529381s] Trained 128 records in 0.089995573 seconds. Throughput is 1422.2922 records/second. Loss is 2.1529357. Sequentiale465b572's hyper parameters: Current learning rate is 3.4106412005457026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 1934][Wall Clock 213.895680486s] Trained 128 records in 0.097151105 seconds. Throughput is 1317.5352 records/second. Loss is 2.1577158. Sequentiale465b572's hyper parameters: Current learning rate is 3.409478349812479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 7552/60000][Iteration 1935][Wall Clock 213.992088431s] Trained 128 records in 0.096407945 seconds. Throughput is 1327.6914 records/second. Loss is 2.1820035. Sequentiale465b572's hyper parameters: Current learning rate is 3.4083162917518747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 1936][Wall Clock 214.086133853s] Trained 128 records in 0.094045422 seconds. Throughput is 1361.0444 records/second. Loss is 2.1655927. Sequentiale465b572's hyper parameters: Current learning rate is 3.4071550255536625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 7808/60000][Iteration 1937][Wall Clock 214.178927234s] Trained 128 records in 0.092793381 seconds. Throughput is 1379.4087 records/second. Loss is 2.1637821. Sequentiale465b572's hyper parameters: Current learning rate is 3.405994550408719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 1938][Wall Clock 214.271817654s] Trained 128 records in 0.09289042 seconds. Throughput is 1377.9678 records/second. Loss is 2.160857. Sequentiale465b572's hyper parameters: Current learning rate is 3.4048348655090226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 8064/60000][Iteration 1939][Wall Clock 214.366081712s] Trained 128 records in 0.094264058 seconds. Throughput is 1357.8876 records/second. Loss is 2.164215. Sequentiale465b572's hyper parameters: Current learning rate is 3.403675970047652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 1940][Wall Clock 214.461193465s] Trained 128 records in 0.095111753 seconds. Throughput is 1345.7854 records/second. Loss is 2.1515937. Sequentiale465b572's hyper parameters: Current learning rate is 3.402517863218782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 8320/60000][Iteration 1941][Wall Clock 214.556336866s] Trained 128 records in 0.095143401 seconds. Throughput is 1345.3376 records/second. Loss is 2.1621559. Sequentiale465b572's hyper parameters: Current learning rate is 3.4013605442176874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 1942][Wall Clock 214.671343083s] Trained 128 records in 0.115006217 seconds. Throughput is 1112.9833 records/second. Loss is 2.132214. Sequentiale465b572's hyper parameters: Current learning rate is 3.4002040122407346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:17 INFO  DistriOptimizer$:408 - [Epoch 5 8576/60000][Iteration 1943][Wall Clock 214.769859323s] Trained 128 records in 0.09851624 seconds. Throughput is 1299.2782 records/second. Loss is 2.1601212. Sequentiale465b572's hyper parameters: Current learning rate is 3.399048266485384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 1944][Wall Clock 214.866248674s] Trained 128 records in 0.096389351 seconds. Throughput is 1327.9475 records/second. Loss is 2.1683354. Sequentiale465b572's hyper parameters: Current learning rate is 3.397893306150187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 8832/60000][Iteration 1945][Wall Clock 214.969640211s] Trained 128 records in 0.103391537 seconds. Throughput is 1238.0123 records/second. Loss is 2.1536527. Sequentiale465b572's hyper parameters: Current learning rate is 3.3967391304347825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 1946][Wall Clock 215.067308397s] Trained 128 records in 0.097668186 seconds. Throughput is 1310.5598 records/second. Loss is 2.1570609. Sequentiale465b572's hyper parameters: Current learning rate is 3.395585738539898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9088/60000][Iteration 1947][Wall Clock 215.16536631s] Trained 128 records in 0.098057913 seconds. Throughput is 1305.3511 records/second. Loss is 2.1683779. Sequentiale465b572's hyper parameters: Current learning rate is 3.394433129667346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 1948][Wall Clock 215.265007811s] Trained 128 records in 0.099641501 seconds. Throughput is 1284.6052 records/second. Loss is 2.159041. Sequentiale465b572's hyper parameters: Current learning rate is 3.3932813030200206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9344/60000][Iteration 1949][Wall Clock 215.359937753s] Trained 128 records in 0.094929942 seconds. Throughput is 1348.3628 records/second. Loss is 2.1674194. Sequentiale465b572's hyper parameters: Current learning rate is 3.3921302578019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 1950][Wall Clock 215.455199034s] Trained 128 records in 0.095261281 seconds. Throughput is 1343.6729 records/second. Loss is 2.1625433. Sequentiale465b572's hyper parameters: Current learning rate is 3.3909799932180403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9600/60000][Iteration 1951][Wall Clock 215.552928666s] Trained 128 records in 0.097729632 seconds. Throughput is 1309.7358 records/second. Loss is 2.1633816. Sequentiale465b572's hyper parameters: Current learning rate is 3.389830508474576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 1952][Wall Clock 215.64318995s] Trained 128 records in 0.090261284 seconds. Throughput is 1418.1053 records/second. Loss is 2.147785. Sequentiale465b572's hyper parameters: Current learning rate is 3.3886818027787193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9856/60000][Iteration 1953][Wall Clock 215.739992831s] Trained 128 records in 0.096802881 seconds. Throughput is 1322.2747 records/second. Loss is 2.1535347. Sequentiale465b572's hyper parameters: Current learning rate is 3.3875338753387534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:18 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 1954][Wall Clock 215.833938234s] Trained 128 records in 0.093945403 seconds. Throughput is 1362.4934 records/second. Loss is 2.1660929. Sequentiale465b572's hyper parameters: Current learning rate is 3.386386725364036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10112/60000][Iteration 1955][Wall Clock 215.927759627s] Trained 128 records in 0.093821393 seconds. Throughput is 1364.2944 records/second. Loss is 2.147471. Sequentiale465b572's hyper parameters: Current learning rate is 3.385240352064997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 1956][Wall Clock 216.025178577s] Trained 128 records in 0.09741895 seconds. Throughput is 1313.9127 records/second. Loss is 2.1299915. Sequentiale465b572's hyper parameters: Current learning rate is 3.3840947546531303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10368/60000][Iteration 1957][Wall Clock 216.131774132s] Trained 128 records in 0.106595555 seconds. Throughput is 1200.8005 records/second. Loss is 2.17807. Sequentiale465b572's hyper parameters: Current learning rate is 3.3829499323410016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 1958][Wall Clock 216.225262279s] Trained 128 records in 0.093488147 seconds. Throughput is 1369.1575 records/second. Loss is 2.172827. Sequentiale465b572's hyper parameters: Current learning rate is 3.381805884342239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10624/60000][Iteration 1959][Wall Clock 216.324340512s] Trained 128 records in 0.099078233 seconds. Throughput is 1291.9084 records/second. Loss is 2.1385238. Sequentiale465b572's hyper parameters: Current learning rate is 3.380662609871535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 1960][Wall Clock 216.42079747s] Trained 128 records in 0.096456958 seconds. Throughput is 1327.0167 records/second. Loss is 2.1510975. Sequentiale465b572's hyper parameters: Current learning rate is 3.379520108144643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 10880/60000][Iteration 1961][Wall Clock 216.516248432s] Trained 128 records in 0.095450962 seconds. Throughput is 1341.0028 records/second. Loss is 2.1427948. Sequentiale465b572's hyper parameters: Current learning rate is 3.3783783783783786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 1962][Wall Clock 216.6145533s] Trained 128 records in 0.098304868 seconds. Throughput is 1302.0719 records/second. Loss is 2.1647418. Sequentiale465b572's hyper parameters: Current learning rate is 3.377237419790611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 11136/60000][Iteration 1963][Wall Clock 216.714582151s] Trained 128 records in 0.100028851 seconds. Throughput is 1279.6309 records/second. Loss is 2.1517498. Sequentiale465b572's hyper parameters: Current learning rate is 3.3760972316002703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:19 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 1964][Wall Clock 216.818428068s] Trained 128 records in 0.103845917 seconds. Throughput is 1232.5955 records/second. Loss is 2.1573415. Sequentiale465b572's hyper parameters: Current learning rate is 3.374957813027337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 11392/60000][Iteration 1965][Wall Clock 216.922395384s] Trained 128 records in 0.103967316 seconds. Throughput is 1231.1561 records/second. Loss is 2.1714003. Sequentiale465b572's hyper parameters: Current learning rate is 3.3738191632928474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 1966][Wall Clock 217.021217063s] Trained 128 records in 0.098821679 seconds. Throughput is 1295.2623 records/second. Loss is 2.1674945. Sequentiale465b572's hyper parameters: Current learning rate is 3.372681281618887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 11648/60000][Iteration 1967][Wall Clock 217.122762721s] Trained 128 records in 0.101545658 seconds. Throughput is 1260.5167 records/second. Loss is 2.1493108. Sequentiale465b572's hyper parameters: Current learning rate is 3.3715441672285906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 1968][Wall Clock 217.241167259s] Trained 128 records in 0.118404538 seconds. Throughput is 1081.0397 records/second. Loss is 2.1459365. Sequentiale465b572's hyper parameters: Current learning rate is 3.370407819346141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 11904/60000][Iteration 1969][Wall Clock 217.347208928s] Trained 128 records in 0.106041669 seconds. Throughput is 1207.0726 records/second. Loss is 2.14174. Sequentiale465b572's hyper parameters: Current learning rate is 3.3692722371967657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 1970][Wall Clock 217.452759103s] Trained 128 records in 0.105550175 seconds. Throughput is 1212.6934 records/second. Loss is 2.1708066. Sequentiale465b572's hyper parameters: Current learning rate is 3.368137420006736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 12160/60000][Iteration 1971][Wall Clock 217.553016133s] Trained 128 records in 0.10025703 seconds. Throughput is 1276.7184 records/second. Loss is 2.1441896. Sequentiale465b572's hyper parameters: Current learning rate is 3.367003367003367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 1972][Wall Clock 217.64642691s] Trained 128 records in 0.093410777 seconds. Throughput is 1370.2916 records/second. Loss is 2.180624. Sequentiale465b572's hyper parameters: Current learning rate is 3.365870077415012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 12416/60000][Iteration 1973][Wall Clock 217.741742206s] Trained 128 records in 0.095315296 seconds. Throughput is 1342.9115 records/second. Loss is 2.1461098. Sequentiale465b572's hyper parameters: Current learning rate is 3.3647375504710633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:20 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 1974][Wall Clock 217.842897225s] Trained 128 records in 0.101155019 seconds. Throughput is 1265.3845 records/second. Loss is 2.1567793. Sequentiale465b572's hyper parameters: Current learning rate is 3.363605785401951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 12672/60000][Iteration 1975][Wall Clock 217.939325006s] Trained 128 records in 0.096427781 seconds. Throughput is 1327.4182 records/second. Loss is 2.1432972. Sequentiale465b572's hyper parameters: Current learning rate is 3.362474781439139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 1976][Wall Clock 218.034203002s] Trained 128 records in 0.094877996 seconds. Throughput is 1349.1011 records/second. Loss is 2.156682. Sequentiale465b572's hyper parameters: Current learning rate is 3.361344537815126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 12928/60000][Iteration 1977][Wall Clock 218.12863498s] Trained 128 records in 0.094431978 seconds. Throughput is 1355.473 records/second. Loss is 2.1483204. Sequentiale465b572's hyper parameters: Current learning rate is 3.360215053763441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 1978][Wall Clock 218.22745493s] Trained 128 records in 0.09881995 seconds. Throughput is 1295.285 records/second. Loss is 2.1491015. Sequentiale465b572's hyper parameters: Current learning rate is 3.359086328518643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13184/60000][Iteration 1979][Wall Clock 218.325863415s] Trained 128 records in 0.098408485 seconds. Throughput is 1300.7009 records/second. Loss is 2.1469278. Sequentiale465b572's hyper parameters: Current learning rate is 3.35795836131632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 1980][Wall Clock 218.422382332s] Trained 128 records in 0.096518917 seconds. Throughput is 1326.1649 records/second. Loss is 2.1447542. Sequentiale465b572's hyper parameters: Current learning rate is 3.356831151393085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13440/60000][Iteration 1981][Wall Clock 218.520678886s] Trained 128 records in 0.098296554 seconds. Throughput is 1302.182 records/second. Loss is 2.1719022. Sequentiale465b572's hyper parameters: Current learning rate is 3.355704697986577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 1982][Wall Clock 218.616044134s] Trained 128 records in 0.095365248 seconds. Throughput is 1342.208 records/second. Loss is 2.1416626. Sequentiale465b572's hyper parameters: Current learning rate is 3.354579000335458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13696/60000][Iteration 1983][Wall Clock 218.726760926s] Trained 128 records in 0.110716792 seconds. Throughput is 1156.1029 records/second. Loss is 2.1613986. Sequentiale465b572's hyper parameters: Current learning rate is 3.3534540576794097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:21 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 1984][Wall Clock 218.8280985s] Trained 128 records in 0.101337574 seconds. Throughput is 1263.105 records/second. Loss is 2.1552298. Sequentiale465b572's hyper parameters: Current learning rate is 3.3523298692591353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 13952/60000][Iteration 1985][Wall Clock 218.926400899s] Trained 128 records in 0.098302399 seconds. Throughput is 1302.1045 records/second. Loss is 2.1520336. Sequentiale465b572's hyper parameters: Current learning rate is 3.351206434316354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 1986][Wall Clock 219.031764322s] Trained 128 records in 0.105363423 seconds. Throughput is 1214.8429 records/second. Loss is 2.1600251. Sequentiale465b572's hyper parameters: Current learning rate is 3.350083752093802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14208/60000][Iteration 1987][Wall Clock 219.131119973s] Trained 128 records in 0.099355651 seconds. Throughput is 1288.3011 records/second. Loss is 2.1371582. Sequentiale465b572's hyper parameters: Current learning rate is 3.3489618218352315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 1988][Wall Clock 219.232123704s] Trained 128 records in 0.101003731 seconds. Throughput is 1267.2799 records/second. Loss is 2.146974. Sequentiale465b572's hyper parameters: Current learning rate is 3.3478406427854036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14464/60000][Iteration 1989][Wall Clock 219.329686585s] Trained 128 records in 0.097562881 seconds. Throughput is 1311.9744 records/second. Loss is 2.1538124. Sequentiale465b572's hyper parameters: Current learning rate is 3.3467202141900936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 1990][Wall Clock 219.42887293s] Trained 128 records in 0.099186345 seconds. Throughput is 1290.5002 records/second. Loss is 2.1649377. Sequentiale465b572's hyper parameters: Current learning rate is 3.345600535296086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14720/60000][Iteration 1991][Wall Clock 219.532196428s] Trained 128 records in 0.103323498 seconds. Throughput is 1238.8276 records/second. Loss is 2.1561956. Sequentiale465b572's hyper parameters: Current learning rate is 3.3444816053511704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 1992][Wall Clock 219.635558549s] Trained 128 records in 0.103362121 seconds. Throughput is 1238.3646 records/second. Loss is 2.153057. Sequentiale465b572's hyper parameters: Current learning rate is 3.3433634236041456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:22 INFO  DistriOptimizer$:408 - [Epoch 5 14976/60000][Iteration 1993][Wall Clock 219.750347681s] Trained 128 records in 0.114789132 seconds. Throughput is 1115.0881 records/second. Loss is 2.160655. Sequentiale465b572's hyper parameters: Current learning rate is 3.342245989304813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 1994][Wall Clock 219.848836238s] Trained 128 records in 0.098488557 seconds. Throughput is 1299.6434 records/second. Loss is 2.147912. Sequentiale465b572's hyper parameters: Current learning rate is 3.341129301703976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15232/60000][Iteration 1995][Wall Clock 219.960848479s] Trained 128 records in 0.112012241 seconds. Throughput is 1142.7323 records/second. Loss is 2.1466935. Sequentiale465b572's hyper parameters: Current learning rate is 3.3400133600534405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 1996][Wall Clock 220.058578551s] Trained 128 records in 0.097730072 seconds. Throughput is 1309.73 records/second. Loss is 2.1473992. Sequentiale465b572's hyper parameters: Current learning rate is 3.33889816360601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15488/60000][Iteration 1997][Wall Clock 220.155756728s] Trained 128 records in 0.097178177 seconds. Throughput is 1317.1682 records/second. Loss is 2.1785614. Sequentiale465b572's hyper parameters: Current learning rate is 3.337783711615487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 1998][Wall Clock 220.251684125s] Trained 128 records in 0.095927397 seconds. Throughput is 1334.3425 records/second. Loss is 2.1486797. Sequentiale465b572's hyper parameters: Current learning rate is 3.33667000333667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15744/60000][Iteration 1999][Wall Clock 220.347180441s] Trained 128 records in 0.095496316 seconds. Throughput is 1340.3658 records/second. Loss is 2.1478522. Sequentiale465b572's hyper parameters: Current learning rate is 3.33555703802535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 2000][Wall Clock 220.442484847s] Trained 128 records in 0.095304406 seconds. Throughput is 1343.0648 records/second. Loss is 2.154633. Sequentiale465b572's hyper parameters: Current learning rate is 3.3344448149383126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 16000/60000][Iteration 2001][Wall Clock 220.537587658s] Trained 128 records in 0.095102811 seconds. Throughput is 1345.9119 records/second. Loss is 2.1656036. Sequentiale465b572's hyper parameters: Current learning rate is 3.333333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 2002][Wall Clock 220.631801275s] Trained 128 records in 0.094213617 seconds. Throughput is 1358.6146 records/second. Loss is 2.1710823. Sequentiale465b572's hyper parameters: Current learning rate is 3.332222592469177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 16256/60000][Iteration 2003][Wall Clock 220.731206315s] Trained 128 records in 0.09940504 seconds. Throughput is 1287.661 records/second. Loss is 2.1453872. Sequentiale465b572's hyper parameters: Current learning rate is 3.3311125916055963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:23 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 2004][Wall Clock 220.827509854s] Trained 128 records in 0.096303539 seconds. Throughput is 1329.1309 records/second. Loss is 2.157653. Sequentiale465b572's hyper parameters: Current learning rate is 3.33000333000333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 16512/60000][Iteration 2005][Wall Clock 220.921873098s] Trained 128 records in 0.094363244 seconds. Throughput is 1356.4603 records/second. Loss is 2.152661. Sequentiale465b572's hyper parameters: Current learning rate is 3.3288948069241014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 2006][Wall Clock 221.015068004s] Trained 128 records in 0.093194906 seconds. Throughput is 1373.4656 records/second. Loss is 2.1765354. Sequentiale465b572's hyper parameters: Current learning rate is 3.3277870216306157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 16768/60000][Iteration 2007][Wall Clock 221.114794192s] Trained 128 records in 0.099726188 seconds. Throughput is 1283.5144 records/second. Loss is 2.155673. Sequentiale465b572's hyper parameters: Current learning rate is 3.3266799733865603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 2008][Wall Clock 221.210779442s] Trained 128 records in 0.09598525 seconds. Throughput is 1333.5382 records/second. Loss is 2.159413. Sequentiale465b572's hyper parameters: Current learning rate is 3.325573661456601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 17024/60000][Iteration 2009][Wall Clock 221.309041216s] Trained 128 records in 0.098261774 seconds. Throughput is 1302.6428 records/second. Loss is 2.140739. Sequentiale465b572's hyper parameters: Current learning rate is 3.324468085106383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 2010][Wall Clock 221.41330813s] Trained 128 records in 0.104266914 seconds. Throughput is 1227.6187 records/second. Loss is 2.1479743. Sequentiale465b572's hyper parameters: Current learning rate is 3.323363243602526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 17280/60000][Iteration 2011][Wall Clock 221.506987663s] Trained 128 records in 0.093679533 seconds. Throughput is 1366.3604 records/second. Loss is 2.156648. Sequentiale465b572's hyper parameters: Current learning rate is 3.322259136212624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 2012][Wall Clock 221.612300652s] Trained 128 records in 0.105312989 seconds. Throughput is 1215.4247 records/second. Loss is 2.159334. Sequentiale465b572's hyper parameters: Current learning rate is 3.3211557622052476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 17536/60000][Iteration 2013][Wall Clock 221.706612179s] Trained 128 records in 0.094311527 seconds. Throughput is 1357.2042 records/second. Loss is 2.1549869. Sequentiale465b572's hyper parameters: Current learning rate is 3.320053120849934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:24 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 2014][Wall Clock 221.803817225s] Trained 128 records in 0.097205046 seconds. Throughput is 1316.8041 records/second. Loss is 2.1490738. Sequentiale465b572's hyper parameters: Current learning rate is 3.3189512114171923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 17792/60000][Iteration 2015][Wall Clock 221.899306662s] Trained 128 records in 0.095489437 seconds. Throughput is 1340.4624 records/second. Loss is 2.1327524. Sequentiale465b572's hyper parameters: Current learning rate is 3.3178500331785003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 2016][Wall Clock 221.995119857s] Trained 128 records in 0.095813195 seconds. Throughput is 1335.933 records/second. Loss is 2.1384346. Sequentiale465b572's hyper parameters: Current learning rate is 3.316749585406302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18048/60000][Iteration 2017][Wall Clock 222.09519339s] Trained 128 records in 0.100073533 seconds. Throughput is 1279.0594 records/second. Loss is 2.1489859. Sequentiale465b572's hyper parameters: Current learning rate is 3.315649867374005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 2018][Wall Clock 222.211284028s] Trained 128 records in 0.116090638 seconds. Throughput is 1102.5868 records/second. Loss is 2.1489978. Sequentiale465b572's hyper parameters: Current learning rate is 3.314550878355983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18304/60000][Iteration 2019][Wall Clock 222.311102965s] Trained 128 records in 0.099818937 seconds. Throughput is 1282.3218 records/second. Loss is 2.1506264. Sequentiale465b572's hyper parameters: Current learning rate is 3.313452617627568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 2020][Wall Clock 222.410186491s] Trained 128 records in 0.099083526 seconds. Throughput is 1291.8394 records/second. Loss is 2.1504302. Sequentiale465b572's hyper parameters: Current learning rate is 3.312355084465055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18560/60000][Iteration 2021][Wall Clock 222.512642396s] Trained 128 records in 0.102455905 seconds. Throughput is 1249.3179 records/second. Loss is 2.1392245. Sequentiale465b572's hyper parameters: Current learning rate is 3.3112582781456954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 2022][Wall Clock 222.623587625s] Trained 128 records in 0.110945229 seconds. Throughput is 1153.7224 records/second. Loss is 2.1557553. Sequentiale465b572's hyper parameters: Current learning rate is 3.3101621979476995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18816/60000][Iteration 2023][Wall Clock 222.720008098s] Trained 128 records in 0.096420473 seconds. Throughput is 1327.5189 records/second. Loss is 2.1410146. Sequentiale465b572's hyper parameters: Current learning rate is 3.3090668431502316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:25 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 2024][Wall Clock 222.81276562s] Trained 128 records in 0.092757522 seconds. Throughput is 1379.942 records/second. Loss is 2.1522777. Sequentiale465b572's hyper parameters: Current learning rate is 3.30797221303341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19072/60000][Iteration 2025][Wall Clock 222.909371065s] Trained 128 records in 0.096605445 seconds. Throughput is 1324.977 records/second. Loss is 2.1462226. Sequentiale465b572's hyper parameters: Current learning rate is 3.3068783068783067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 2026][Wall Clock 223.000525566s] Trained 128 records in 0.091154501 seconds. Throughput is 1404.2094 records/second. Loss is 2.1537504. Sequentiale465b572's hyper parameters: Current learning rate is 3.3057851239669424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19328/60000][Iteration 2027][Wall Clock 223.096971728s] Trained 128 records in 0.096446162 seconds. Throughput is 1327.1653 records/second. Loss is 2.166581. Sequentiale465b572's hyper parameters: Current learning rate is 3.3046926635822867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 2028][Wall Clock 223.19202795s] Trained 128 records in 0.095056222 seconds. Throughput is 1346.5715 records/second. Loss is 2.1584685. Sequentiale465b572's hyper parameters: Current learning rate is 3.303600925008259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19584/60000][Iteration 2029][Wall Clock 223.283917486s] Trained 128 records in 0.091889536 seconds. Throughput is 1392.9768 records/second. Loss is 2.1441627. Sequentiale465b572's hyper parameters: Current learning rate is 3.3025099075297226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 2030][Wall Clock 223.378632331s] Trained 128 records in 0.094714845 seconds. Throughput is 1351.4249 records/second. Loss is 2.1564229. Sequentiale465b572's hyper parameters: Current learning rate is 3.301419610432486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19840/60000][Iteration 2031][Wall Clock 223.473414842s] Trained 128 records in 0.094782511 seconds. Throughput is 1350.4601 records/second. Loss is 2.15795. Sequentiale465b572's hyper parameters: Current learning rate is 3.3003300330033004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 2032][Wall Clock 223.571995449s] Trained 128 records in 0.098580607 seconds. Throughput is 1298.4298 records/second. Loss is 2.1271234. Sequentiale465b572's hyper parameters: Current learning rate is 3.299241174529858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 20096/60000][Iteration 2033][Wall Clock 223.67418803s] Trained 128 records in 0.102192581 seconds. Throughput is 1252.5371 records/second. Loss is 2.1413817. Sequentiale465b572's hyper parameters: Current learning rate is 3.2981530343007914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:26 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 2034][Wall Clock 223.771520593s] Trained 128 records in 0.097332563 seconds. Throughput is 1315.079 records/second. Loss is 2.148135. Sequentiale465b572's hyper parameters: Current learning rate is 3.297065611605671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 20352/60000][Iteration 2035][Wall Clock 223.867501775s] Trained 128 records in 0.095981182 seconds. Throughput is 1333.5947 records/second. Loss is 2.1415944. Sequentiale465b572's hyper parameters: Current learning rate is 3.295978905735003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 2036][Wall Clock 223.973941451s] Trained 128 records in 0.106439676 seconds. Throughput is 1202.5591 records/second. Loss is 2.1498244. Sequentiale465b572's hyper parameters: Current learning rate is 3.2948929159802305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 20608/60000][Iteration 2037][Wall Clock 224.071450696s] Trained 128 records in 0.097509245 seconds. Throughput is 1312.696 records/second. Loss is 2.1491432. Sequentiale465b572's hyper parameters: Current learning rate is 3.2938076416337287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 2038][Wall Clock 224.168718787s] Trained 128 records in 0.097268091 seconds. Throughput is 1315.9506 records/second. Loss is 2.159344. Sequentiale465b572's hyper parameters: Current learning rate is 3.292723081988805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 20864/60000][Iteration 2039][Wall Clock 224.26944904s] Trained 128 records in 0.100730253 seconds. Throughput is 1270.7205 records/second. Loss is 2.1658692. Sequentiale465b572's hyper parameters: Current learning rate is 3.291639236339697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 2040][Wall Clock 224.366215296s] Trained 128 records in 0.096766256 seconds. Throughput is 1322.7751 records/second. Loss is 2.1404254. Sequentiale465b572's hyper parameters: Current learning rate is 3.290556103981573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 21120/60000][Iteration 2041][Wall Clock 224.4658596s] Trained 128 records in 0.099644304 seconds. Throughput is 1284.5692 records/second. Loss is 2.1588228. Sequentiale465b572's hyper parameters: Current learning rate is 3.289473684210526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 2042][Wall Clock 224.563762844s] Trained 128 records in 0.097903244 seconds. Throughput is 1307.4132 records/second. Loss is 2.1672082. Sequentiale465b572's hyper parameters: Current learning rate is 3.288391976323578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 21376/60000][Iteration 2043][Wall Clock 224.661221552s] Trained 128 records in 0.097458708 seconds. Throughput is 1313.3768 records/second. Loss is 2.1541924. Sequentiale465b572's hyper parameters: Current learning rate is 3.2873109796186715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:27 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 2044][Wall Clock 224.779093593s] Trained 128 records in 0.117872041 seconds. Throughput is 1085.9233 records/second. Loss is 2.1345096. Sequentiale465b572's hyper parameters: Current learning rate is 3.286230693394676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 21632/60000][Iteration 2045][Wall Clock 224.894943762s] Trained 128 records in 0.115850169 seconds. Throughput is 1104.8754 records/second. Loss is 2.1283898. Sequentiale465b572's hyper parameters: Current learning rate is 3.28515111695138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 2046][Wall Clock 224.999878052s] Trained 128 records in 0.10493429 seconds. Throughput is 1219.811 records/second. Loss is 2.143932. Sequentiale465b572's hyper parameters: Current learning rate is 3.284072249589491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 21888/60000][Iteration 2047][Wall Clock 225.104444447s] Trained 128 records in 0.104566395 seconds. Throughput is 1224.1027 records/second. Loss is 2.1509163. Sequentiale465b572's hyper parameters: Current learning rate is 3.2829940906106366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 2048][Wall Clock 225.21250616s] Trained 128 records in 0.108061713 seconds. Throughput is 1184.5083 records/second. Loss is 2.1669667. Sequentiale465b572's hyper parameters: Current learning rate is 3.281916639317361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 22144/60000][Iteration 2049][Wall Clock 225.315723683s] Trained 128 records in 0.103217523 seconds. Throughput is 1240.0996 records/second. Loss is 2.1647663. Sequentiale465b572's hyper parameters: Current learning rate is 3.2808398950131233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 2050][Wall Clock 225.417301693s] Trained 128 records in 0.10157801 seconds. Throughput is 1260.1152 records/second. Loss is 2.1220098. Sequentiale465b572's hyper parameters: Current learning rate is 3.2797638570022957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 22400/60000][Iteration 2051][Wall Clock 225.519157432s] Trained 128 records in 0.101855739 seconds. Throughput is 1256.6793 records/second. Loss is 2.1512277. Sequentiale465b572's hyper parameters: Current learning rate is 3.278688524590164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 2052][Wall Clock 225.620616956s] Trained 128 records in 0.101459524 seconds. Throughput is 1261.5868 records/second. Loss is 2.1479. Sequentiale465b572's hyper parameters: Current learning rate is 3.2776138970829236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:28 INFO  DistriOptimizer$:408 - [Epoch 5 22656/60000][Iteration 2053][Wall Clock 225.719770278s] Trained 128 records in 0.099153322 seconds. Throughput is 1290.9299 records/second. Loss is 2.150335. Sequentiale465b572's hyper parameters: Current learning rate is 3.27653997378768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 2054][Wall Clock 225.815049617s] Trained 128 records in 0.095279339 seconds. Throughput is 1343.4182 records/second. Loss is 2.1536908. Sequentiale465b572's hyper parameters: Current learning rate is 3.275466754012447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 22912/60000][Iteration 2055][Wall Clock 225.909284349s] Trained 128 records in 0.094234732 seconds. Throughput is 1358.3102 records/second. Loss is 2.1436665. Sequentiale465b572's hyper parameters: Current learning rate is 3.274394237066143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 2056][Wall Clock 226.004946488s] Trained 128 records in 0.095662139 seconds. Throughput is 1338.0424 records/second. Loss is 2.157294. Sequentiale465b572's hyper parameters: Current learning rate is 3.273322422258592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23168/60000][Iteration 2057][Wall Clock 226.105906579s] Trained 128 records in 0.100960091 seconds. Throughput is 1267.8278 records/second. Loss is 2.153861. Sequentiale465b572's hyper parameters: Current learning rate is 3.272251308900524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 2058][Wall Clock 226.201689965s] Trained 128 records in 0.095783386 seconds. Throughput is 1336.3488 records/second. Loss is 2.134706. Sequentiale465b572's hyper parameters: Current learning rate is 3.2711808963035657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23424/60000][Iteration 2059][Wall Clock 226.298797095s] Trained 128 records in 0.09710713 seconds. Throughput is 1318.1318 records/second. Loss is 2.1453586. Sequentiale465b572's hyper parameters: Current learning rate is 3.270111183780249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 2060][Wall Clock 226.397815082s] Trained 128 records in 0.099017987 seconds. Throughput is 1292.6945 records/second. Loss is 2.1708918. Sequentiale465b572's hyper parameters: Current learning rate is 3.2690421706440013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23680/60000][Iteration 2061][Wall Clock 226.506136748s] Trained 128 records in 0.108321666 seconds. Throughput is 1181.6658 records/second. Loss is 2.1588955. Sequentiale465b572's hyper parameters: Current learning rate is 3.26797385620915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 2062][Wall Clock 226.615856462s] Trained 128 records in 0.109719714 seconds. Throughput is 1166.6089 records/second. Loss is 2.145831. Sequentiale465b572's hyper parameters: Current learning rate is 3.266906239790918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:29 INFO  DistriOptimizer$:408 - [Epoch 5 23936/60000][Iteration 2063][Wall Clock 226.720419777s] Trained 128 records in 0.104563315 seconds. Throughput is 1224.1387 records/second. Loss is 2.153571. Sequentiale465b572's hyper parameters: Current learning rate is 3.2658393207054214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 2064][Wall Clock 226.819351348s] Trained 128 records in 0.098931571 seconds. Throughput is 1293.8236 records/second. Loss is 2.143932. Sequentiale465b572's hyper parameters: Current learning rate is 3.26477309826967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24192/60000][Iteration 2065][Wall Clock 226.917210912s] Trained 128 records in 0.097859564 seconds. Throughput is 1307.9968 records/second. Loss is 2.1411648. Sequentiale465b572's hyper parameters: Current learning rate is 3.2637075718015666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 2066][Wall Clock 227.014272199s] Trained 128 records in 0.097061287 seconds. Throughput is 1318.7544 records/second. Loss is 2.148985. Sequentiale465b572's hyper parameters: Current learning rate is 3.262642740619902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24448/60000][Iteration 2067][Wall Clock 227.11064629s] Trained 128 records in 0.096374091 seconds. Throughput is 1328.1577 records/second. Loss is 2.157938. Sequentiale465b572's hyper parameters: Current learning rate is 3.261578604044358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 2068][Wall Clock 227.20662866s] Trained 128 records in 0.09598237 seconds. Throughput is 1333.5782 records/second. Loss is 2.145467. Sequentiale465b572's hyper parameters: Current learning rate is 3.2605151613955004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24704/60000][Iteration 2069][Wall Clock 227.306319793s] Trained 128 records in 0.099691133 seconds. Throughput is 1283.9658 records/second. Loss is 2.1508327. Sequentiale465b572's hyper parameters: Current learning rate is 3.259452411994785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 2070][Wall Clock 227.417340228s] Trained 128 records in 0.111020435 seconds. Throughput is 1152.9409 records/second. Loss is 2.1552527. Sequentiale465b572's hyper parameters: Current learning rate is 3.2583903551645487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 24960/60000][Iteration 2071][Wall Clock 227.513718001s] Trained 128 records in 0.096377773 seconds. Throughput is 1328.107 records/second. Loss is 2.146131. Sequentiale465b572's hyper parameters: Current learning rate is 3.257328990228013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 2072][Wall Clock 227.608832671s] Trained 128 records in 0.09511467 seconds. Throughput is 1345.744 records/second. Loss is 2.1464913. Sequentiale465b572's hyper parameters: Current learning rate is 3.25626831650928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:30 INFO  DistriOptimizer$:408 - [Epoch 5 25216/60000][Iteration 2073][Wall Clock 227.706974242s] Trained 128 records in 0.098141571 seconds. Throughput is 1304.2383 records/second. Loss is 2.1473787. Sequentiale465b572's hyper parameters: Current learning rate is 3.255208333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 2074][Wall Clock 227.803170993s] Trained 128 records in 0.096196751 seconds. Throughput is 1330.6063 records/second. Loss is 2.14309. Sequentiale465b572's hyper parameters: Current learning rate is 3.2541490400260335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 25472/60000][Iteration 2075][Wall Clock 227.902860108s] Trained 128 records in 0.099689115 seconds. Throughput is 1283.9917 records/second. Loss is 2.1568875. Sequentiale465b572's hyper parameters: Current learning rate is 3.2530904359141186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 2076][Wall Clock 228.00273056s] Trained 128 records in 0.099870452 seconds. Throughput is 1281.6604 records/second. Loss is 2.1672657. Sequentiale465b572's hyper parameters: Current learning rate is 3.252032520325203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 25728/60000][Iteration 2077][Wall Clock 228.100844049s] Trained 128 records in 0.098113489 seconds. Throughput is 1304.6116 records/second. Loss is 2.146323. Sequentiale465b572's hyper parameters: Current learning rate is 3.2509752925877764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 2078][Wall Clock 228.192387849s] Trained 128 records in 0.0915438 seconds. Throughput is 1398.2378 records/second. Loss is 2.1198053. Sequentiale465b572's hyper parameters: Current learning rate is 3.2499187520311994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 25984/60000][Iteration 2079][Wall Clock 228.287542969s] Trained 128 records in 0.09515512 seconds. Throughput is 1345.172 records/second. Loss is 2.1316621. Sequentiale465b572's hyper parameters: Current learning rate is 3.2488628979857054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 2080][Wall Clock 228.384059969s] Trained 128 records in 0.096517 seconds. Throughput is 1326.1913 records/second. Loss is 2.1496706. Sequentiale465b572's hyper parameters: Current learning rate is 3.247807729782397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 26240/60000][Iteration 2081][Wall Clock 228.480459799s] Trained 128 records in 0.09639983 seconds. Throughput is 1327.8032 records/second. Loss is 2.127554. Sequentiale465b572's hyper parameters: Current learning rate is 3.246753246753247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 2082][Wall Clock 228.575018069s] Trained 128 records in 0.09455827 seconds. Throughput is 1353.6627 records/second. Loss is 2.156642. Sequentiale465b572's hyper parameters: Current learning rate is 3.245699448231094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 26496/60000][Iteration 2083][Wall Clock 228.666890207s] Trained 128 records in 0.091872138 seconds. Throughput is 1393.2406 records/second. Loss is 2.1508436. Sequentiale465b572's hyper parameters: Current learning rate is 3.2446463335496434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:31 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 2084][Wall Clock 228.758748208s] Trained 128 records in 0.091858001 seconds. Throughput is 1393.4551 records/second. Loss is 2.1504648. Sequentiale465b572's hyper parameters: Current learning rate is 3.243593902043464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 26752/60000][Iteration 2085][Wall Clock 228.860672387s] Trained 128 records in 0.101924179 seconds. Throughput is 1255.8354 records/second. Loss is 2.1581845. Sequentiale465b572's hyper parameters: Current learning rate is 3.2425421530479895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 2086][Wall Clock 228.963425944s] Trained 128 records in 0.102753557 seconds. Throughput is 1245.699 records/second. Loss is 2.1549995. Sequentiale465b572's hyper parameters: Current learning rate is 3.241491085899514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27008/60000][Iteration 2087][Wall Clock 229.074366488s] Trained 128 records in 0.110940544 seconds. Throughput is 1153.7711 records/second. Loss is 2.1528327. Sequentiale465b572's hyper parameters: Current learning rate is 3.240440699935191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 2088][Wall Clock 229.164728341s] Trained 128 records in 0.090361853 seconds. Throughput is 1416.5269 records/second. Loss is 2.1464357. Sequentiale465b572's hyper parameters: Current learning rate is 3.2393909944930353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27264/60000][Iteration 2089][Wall Clock 229.272852823s] Trained 128 records in 0.108124482 seconds. Throughput is 1183.8207 records/second. Loss is 2.15513. Sequentiale465b572's hyper parameters: Current learning rate is 3.238341968911917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 2090][Wall Clock 229.374614132s] Trained 128 records in 0.101761309 seconds. Throughput is 1257.8455 records/second. Loss is 2.1515155. Sequentiale465b572's hyper parameters: Current learning rate is 3.237293622531564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27520/60000][Iteration 2091][Wall Clock 229.473426241s] Trained 128 records in 0.098812109 seconds. Throughput is 1295.3878 records/second. Loss is 2.127187. Sequentiale465b572's hyper parameters: Current learning rate is 3.2362459546925567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 2092][Wall Clock 229.576006376s] Trained 128 records in 0.102580135 seconds. Throughput is 1247.8049 records/second. Loss is 2.1504874. Sequentiale465b572's hyper parameters: Current learning rate is 3.235198964736331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:32 INFO  DistriOptimizer$:408 - [Epoch 5 27776/60000][Iteration 2093][Wall Clock 229.681702873s] Trained 128 records in 0.105696497 seconds. Throughput is 1211.0145 records/second. Loss is 2.1476486. Sequentiale465b572's hyper parameters: Current learning rate is 3.2341526520051744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 2094][Wall Clock 229.792143718s] Trained 128 records in 0.110440845 seconds. Throughput is 1158.9916 records/second. Loss is 2.1449785. Sequentiale465b572's hyper parameters: Current learning rate is 3.2331070158422246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28032/60000][Iteration 2095][Wall Clock 229.90878626s] Trained 128 records in 0.116642542 seconds. Throughput is 1097.3698 records/second. Loss is 2.1503625. Sequentiale465b572's hyper parameters: Current learning rate is 3.232062055591468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 2096][Wall Clock 230.012600327s] Trained 128 records in 0.103814067 seconds. Throughput is 1232.9736 records/second. Loss is 2.1662889. Sequentiale465b572's hyper parameters: Current learning rate is 3.231017770597738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28288/60000][Iteration 2097][Wall Clock 230.113084934s] Trained 128 records in 0.100484607 seconds. Throughput is 1273.8269 records/second. Loss is 2.1494555. Sequentiale465b572's hyper parameters: Current learning rate is 3.2299741602067185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 2098][Wall Clock 230.213449501s] Trained 128 records in 0.100364567 seconds. Throughput is 1275.3505 records/second. Loss is 2.1542163. Sequentiale465b572's hyper parameters: Current learning rate is 3.2289312237649337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28544/60000][Iteration 2099][Wall Clock 230.31047667s] Trained 128 records in 0.097027169 seconds. Throughput is 1319.2181 records/second. Loss is 2.1285408. Sequentiale465b572's hyper parameters: Current learning rate is 3.227888960619755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 2100][Wall Clock 230.406254544s] Trained 128 records in 0.095777874 seconds. Throughput is 1336.4255 records/second. Loss is 2.1600258. Sequentiale465b572's hyper parameters: Current learning rate is 3.2268473701193933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28800/60000][Iteration 2101][Wall Clock 230.500564493s] Trained 128 records in 0.094309949 seconds. Throughput is 1357.2269 records/second. Loss is 2.1482935. Sequentiale465b572's hyper parameters: Current learning rate is 3.225806451612903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 2102][Wall Clock 230.605767758s] Trained 128 records in 0.105203265 seconds. Throughput is 1216.6923 records/second. Loss is 2.1435745. Sequentiale465b572's hyper parameters: Current learning rate is 3.2247662044501777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:33 INFO  DistriOptimizer$:408 - [Epoch 5 29056/60000][Iteration 2103][Wall Clock 230.703816026s] Trained 128 records in 0.098048268 seconds. Throughput is 1305.4795 records/second. Loss is 2.111861. Sequentiale465b572's hyper parameters: Current learning rate is 3.223726627981947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 2104][Wall Clock 230.798467274s] Trained 128 records in 0.094651248 seconds. Throughput is 1352.333 records/second. Loss is 2.1494937. Sequentiale465b572's hyper parameters: Current learning rate is 3.2226877215597806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29312/60000][Iteration 2105][Wall Clock 230.893805006s] Trained 128 records in 0.095337732 seconds. Throughput is 1342.5953 records/second. Loss is 2.143022. Sequentiale465b572's hyper parameters: Current learning rate is 3.2216494845360824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 2106][Wall Clock 230.986481958s] Trained 128 records in 0.092676952 seconds. Throughput is 1381.1416 records/second. Loss is 2.1246283. Sequentiale465b572's hyper parameters: Current learning rate is 3.2206119162640903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29568/60000][Iteration 2107][Wall Clock 231.078948141s] Trained 128 records in 0.092466183 seconds. Throughput is 1384.2899 records/second. Loss is 2.1535025. Sequentiale465b572's hyper parameters: Current learning rate is 3.2195750160978755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 2108][Wall Clock 231.16967642s] Trained 128 records in 0.090728279 seconds. Throughput is 1410.806 records/second. Loss is 2.1312091. Sequentiale465b572's hyper parameters: Current learning rate is 3.2185387833923396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29824/60000][Iteration 2109][Wall Clock 231.263282615s] Trained 128 records in 0.093606195 seconds. Throughput is 1367.4308 records/second. Loss is 2.135337. Sequentiale465b572's hyper parameters: Current learning rate is 3.2175032175032174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 2110][Wall Clock 231.356413543s] Trained 128 records in 0.093130928 seconds. Throughput is 1374.409 records/second. Loss is 2.1406476. Sequentiale465b572's hyper parameters: Current learning rate is 3.21646831778707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 30080/60000][Iteration 2111][Wall Clock 231.446411622s] Trained 128 records in 0.089998079 seconds. Throughput is 1422.2526 records/second. Loss is 2.1182158. Sequentiale465b572's hyper parameters: Current learning rate is 3.215434083601286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 2112][Wall Clock 231.536484247s] Trained 128 records in 0.090072625 seconds. Throughput is 1421.0756 records/second. Loss is 2.1370363. Sequentiale465b572's hyper parameters: Current learning rate is 3.214400514304082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 30336/60000][Iteration 2113][Wall Clock 231.646097803s] Trained 128 records in 0.109613556 seconds. Throughput is 1167.7388 records/second. Loss is 2.1496115. Sequentiale465b572's hyper parameters: Current learning rate is 3.2133676092544985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:34 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 2114][Wall Clock 231.741727985s] Trained 128 records in 0.095630182 seconds. Throughput is 1338.4895 records/second. Loss is 2.1386583. Sequentiale465b572's hyper parameters: Current learning rate is 3.2123353678124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 30592/60000][Iteration 2115][Wall Clock 231.831456893s] Trained 128 records in 0.089728908 seconds. Throughput is 1426.5192 records/second. Loss is 2.1292343. Sequentiale465b572's hyper parameters: Current learning rate is 3.211303789338472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 2116][Wall Clock 231.926537732s] Trained 128 records in 0.095080839 seconds. Throughput is 1346.2229 records/second. Loss is 2.1309836. Sequentiale465b572's hyper parameters: Current learning rate is 3.2102728731942215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 30848/60000][Iteration 2117][Wall Clock 232.017634763s] Trained 128 records in 0.091097031 seconds. Throughput is 1405.0951 records/second. Loss is 2.1297808. Sequentiale465b572's hyper parameters: Current learning rate is 3.2092426187419767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 2118][Wall Clock 232.109985979s] Trained 128 records in 0.092351216 seconds. Throughput is 1386.0132 records/second. Loss is 2.1224573. Sequentiale465b572's hyper parameters: Current learning rate is 3.208213025344883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 31104/60000][Iteration 2119][Wall Clock 232.215533355s] Trained 128 records in 0.105547376 seconds. Throughput is 1212.7256 records/second. Loss is 2.132103. Sequentiale465b572's hyper parameters: Current learning rate is 3.207184092366902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 2120][Wall Clock 232.314449844s] Trained 128 records in 0.098916489 seconds. Throughput is 1294.0209 records/second. Loss is 2.1761131. Sequentiale465b572's hyper parameters: Current learning rate is 3.206155819172812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 31360/60000][Iteration 2121][Wall Clock 232.449524352s] Trained 128 records in 0.135074508 seconds. Throughput is 947.6251 records/second. Loss is 2.168101. Sequentiale465b572's hyper parameters: Current learning rate is 3.205128205128205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 2122][Wall Clock 232.549664669s] Trained 128 records in 0.100140317 seconds. Throughput is 1278.2064 records/second. Loss is 2.1175966. Sequentiale465b572's hyper parameters: Current learning rate is 3.204101249599487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 31616/60000][Iteration 2123][Wall Clock 232.648595242s] Trained 128 records in 0.098930573 seconds. Throughput is 1293.8367 records/second. Loss is 2.1578276. Sequentiale465b572's hyper parameters: Current learning rate is 3.203074951953876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:35 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 2124][Wall Clock 232.742401567s] Trained 128 records in 0.093806325 seconds. Throughput is 1364.5135 records/second. Loss is 2.1365159. Sequentiale465b572's hyper parameters: Current learning rate is 3.202049311559398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 31872/60000][Iteration 2125][Wall Clock 232.840884713s] Trained 128 records in 0.098483146 seconds. Throughput is 1299.7148 records/second. Loss is 2.1239085. Sequentiale465b572's hyper parameters: Current learning rate is 3.201024327784891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 2126][Wall Clock 232.936181306s] Trained 128 records in 0.095296593 seconds. Throughput is 1343.175 records/second. Loss is 2.1662405. Sequentiale465b572's hyper parameters: Current learning rate is 3.2E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32128/60000][Iteration 2127][Wall Clock 233.038294273s] Trained 128 records in 0.102112967 seconds. Throughput is 1253.5137 records/second. Loss is 2.1445081. Sequentiale465b572's hyper parameters: Current learning rate is 3.1989763275751764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 2128][Wall Clock 233.137084357s] Trained 128 records in 0.098790084 seconds. Throughput is 1295.6765 records/second. Loss is 2.1453624. Sequentiale465b572's hyper parameters: Current learning rate is 3.1979533098816753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32384/60000][Iteration 2129][Wall Clock 233.234795039s] Trained 128 records in 0.097710682 seconds. Throughput is 1309.9897 records/second. Loss is 2.1325984. Sequentiale465b572's hyper parameters: Current learning rate is 3.19693094629156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 2130][Wall Clock 233.330899174s] Trained 128 records in 0.096104135 seconds. Throughput is 1331.8885 records/second. Loss is 2.1544597. Sequentiale465b572's hyper parameters: Current learning rate is 3.1959092361776926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32640/60000][Iteration 2131][Wall Clock 233.427495683s] Trained 128 records in 0.096596509 seconds. Throughput is 1325.0996 records/second. Loss is 2.1481326. Sequentiale465b572's hyper parameters: Current learning rate is 3.194888178913738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 2132][Wall Clock 233.52779806s] Trained 128 records in 0.100302377 seconds. Throughput is 1276.1412 records/second. Loss is 2.131352. Sequentiale465b572's hyper parameters: Current learning rate is 3.1938677738741617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 32896/60000][Iteration 2133][Wall Clock 233.633369545s] Trained 128 records in 0.105571485 seconds. Throughput is 1212.4486 records/second. Loss is 2.14496. Sequentiale465b572's hyper parameters: Current learning rate is 3.1928480204342275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:36 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 2134][Wall Clock 233.726002236s] Trained 128 records in 0.092632691 seconds. Throughput is 1381.8016 records/second. Loss is 2.1501355. Sequentiale465b572's hyper parameters: Current learning rate is 3.191828917969997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33152/60000][Iteration 2135][Wall Clock 233.819160527s] Trained 128 records in 0.093158291 seconds. Throughput is 1374.0055 records/second. Loss is 2.1368482. Sequentiale465b572's hyper parameters: Current learning rate is 3.190810465858328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 2136][Wall Clock 233.912391402s] Trained 128 records in 0.093230875 seconds. Throughput is 1372.9358 records/second. Loss is 2.1004999. Sequentiale465b572's hyper parameters: Current learning rate is 3.189792663476874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33408/60000][Iteration 2137][Wall Clock 234.004631809s] Trained 128 records in 0.092240407 seconds. Throughput is 1387.6782 records/second. Loss is 2.1313832. Sequentiale465b572's hyper parameters: Current learning rate is 3.1887755102040814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 2138][Wall Clock 234.103518038s] Trained 128 records in 0.098886229 seconds. Throughput is 1294.4169 records/second. Loss is 2.1456532. Sequentiale465b572's hyper parameters: Current learning rate is 3.18775900541919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33664/60000][Iteration 2139][Wall Clock 234.193710294s] Trained 128 records in 0.090192256 seconds. Throughput is 1419.1906 records/second. Loss is 2.1472676. Sequentiale465b572's hyper parameters: Current learning rate is 3.186743148502231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 2140][Wall Clock 234.280059378s] Trained 128 records in 0.086349084 seconds. Throughput is 1482.355 records/second. Loss is 2.1281893. Sequentiale465b572's hyper parameters: Current learning rate is 3.1857279388340236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 33920/60000][Iteration 2141][Wall Clock 234.380343592s] Trained 128 records in 0.100284214 seconds. Throughput is 1276.3724 records/second. Loss is 2.1454494. Sequentiale465b572's hyper parameters: Current learning rate is 3.184713375796178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 2142][Wall Clock 234.468488226s] Trained 128 records in 0.088144634 seconds. Throughput is 1452.1587 records/second. Loss is 2.1508868. Sequentiale465b572's hyper parameters: Current learning rate is 3.183699458771092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 34176/60000][Iteration 2143][Wall Clock 234.560278005s] Trained 128 records in 0.091789779 seconds. Throughput is 1394.4907 records/second. Loss is 2.139698. Sequentiale465b572's hyper parameters: Current learning rate is 3.182686187141948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 2144][Wall Clock 234.652894229s] Trained 128 records in 0.092616224 seconds. Throughput is 1382.0472 records/second. Loss is 2.171756. Sequentiale465b572's hyper parameters: Current learning rate is 3.181673560292714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:37 INFO  DistriOptimizer$:408 - [Epoch 5 34432/60000][Iteration 2145][Wall Clock 234.744093195s] Trained 128 records in 0.091198966 seconds. Throughput is 1403.5247 records/second. Loss is 2.1538103. Sequentiale465b572's hyper parameters: Current learning rate is 3.180661577608142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 2146][Wall Clock 234.845267023s] Trained 128 records in 0.101173828 seconds. Throughput is 1265.1494 records/second. Loss is 2.1590762. Sequentiale465b572's hyper parameters: Current learning rate is 3.179650238473768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 34688/60000][Iteration 2147][Wall Clock 234.938141898s] Trained 128 records in 0.092874875 seconds. Throughput is 1378.1984 records/second. Loss is 2.1331253. Sequentiale465b572's hyper parameters: Current learning rate is 3.178639542275906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 2148][Wall Clock 235.029976649s] Trained 128 records in 0.091834751 seconds. Throughput is 1393.8079 records/second. Loss is 2.1468. Sequentiale465b572's hyper parameters: Current learning rate is 3.177629488401652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 34944/60000][Iteration 2149][Wall Clock 235.124075142s] Trained 128 records in 0.094098493 seconds. Throughput is 1360.2769 records/second. Loss is 2.144701. Sequentiale465b572's hyper parameters: Current learning rate is 3.176620076238882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 2150][Wall Clock 235.214375315s] Trained 128 records in 0.090300173 seconds. Throughput is 1417.4945 records/second. Loss is 2.136063. Sequentiale465b572's hyper parameters: Current learning rate is 3.1756113051762465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 35200/60000][Iteration 2151][Wall Clock 235.307340212s] Trained 128 records in 0.092964897 seconds. Throughput is 1376.8638 records/second. Loss is 2.1376379. Sequentiale465b572's hyper parameters: Current learning rate is 3.1746031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 2152][Wall Clock 235.402250212s] Trained 128 records in 0.09491 seconds. Throughput is 1348.646 records/second. Loss is 2.1397998. Sequentiale465b572's hyper parameters: Current learning rate is 3.1735956839098697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 35456/60000][Iteration 2153][Wall Clock 235.504423332s] Trained 128 records in 0.10217312 seconds. Throughput is 1252.7756 records/second. Loss is 2.1445377. Sequentiale465b572's hyper parameters: Current learning rate is 3.1725888324873094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 2154][Wall Clock 235.603012356s] Trained 128 records in 0.098589024 seconds. Throughput is 1298.319 records/second. Loss is 2.1360612. Sequentiale465b572's hyper parameters: Current learning rate is 3.171582619727244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:38 INFO  DistriOptimizer$:408 - [Epoch 5 35712/60000][Iteration 2155][Wall Clock 235.696702714s] Trained 128 records in 0.093690358 seconds. Throughput is 1366.2025 records/second. Loss is 2.143761. Sequentiale465b572's hyper parameters: Current learning rate is 3.170577045022194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 2156][Wall Clock 235.791684734s] Trained 128 records in 0.09498202 seconds. Throughput is 1347.6234 records/second. Loss is 2.1187599. Sequentiale465b572's hyper parameters: Current learning rate is 3.169572107765451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 35968/60000][Iteration 2157][Wall Clock 235.887307357s] Trained 128 records in 0.095622623 seconds. Throughput is 1338.5953 records/second. Loss is 2.148393. Sequentiale465b572's hyper parameters: Current learning rate is 3.168567807351077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 2158][Wall Clock 235.98456693s] Trained 128 records in 0.097259573 seconds. Throughput is 1316.0658 records/second. Loss is 2.140422. Sequentiale465b572's hyper parameters: Current learning rate is 3.167564143173899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36224/60000][Iteration 2159][Wall Clock 236.078399115s] Trained 128 records in 0.093832185 seconds. Throughput is 1364.1375 records/second. Loss is 2.1196115. Sequentiale465b572's hyper parameters: Current learning rate is 3.1665611146295124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 2160][Wall Clock 236.1771538s] Trained 128 records in 0.098754685 seconds. Throughput is 1296.1411 records/second. Loss is 2.1560736. Sequentiale465b572's hyper parameters: Current learning rate is 3.1655587211142766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36480/60000][Iteration 2161][Wall Clock 236.275217702s] Trained 128 records in 0.098063902 seconds. Throughput is 1305.2714 records/second. Loss is 2.1381495. Sequentiale465b572's hyper parameters: Current learning rate is 3.1645569620253165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 2162][Wall Clock 236.375725073s] Trained 128 records in 0.100507371 seconds. Throughput is 1273.5385 records/second. Loss is 2.1305149. Sequentiale465b572's hyper parameters: Current learning rate is 3.1635558367605187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36736/60000][Iteration 2163][Wall Clock 236.471205011s] Trained 128 records in 0.095479938 seconds. Throughput is 1340.5958 records/second. Loss is 2.1389196. Sequentiale465b572's hyper parameters: Current learning rate is 3.1625553447185326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 2164][Wall Clock 236.580396278s] Trained 128 records in 0.109191267 seconds. Throughput is 1172.2549 records/second. Loss is 2.1509585. Sequentiale465b572's hyper parameters: Current learning rate is 3.1615554852987667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:39 INFO  DistriOptimizer$:408 - [Epoch 5 36992/60000][Iteration 2165][Wall Clock 236.670807021s] Trained 128 records in 0.090410743 seconds. Throughput is 1415.7609 records/second. Loss is 2.1315823. Sequentiale465b572's hyper parameters: Current learning rate is 3.1605562579013904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 2166][Wall Clock 236.75801926s] Trained 128 records in 0.087212239 seconds. Throughput is 1467.6838 records/second. Loss is 2.1553423. Sequentiale465b572's hyper parameters: Current learning rate is 3.1595576619273305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37248/60000][Iteration 2167][Wall Clock 236.854666642s] Trained 128 records in 0.096647382 seconds. Throughput is 1324.4021 records/second. Loss is 2.1590009. Sequentiale465b572's hyper parameters: Current learning rate is 3.1585596967782694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 2168][Wall Clock 236.949173764s] Trained 128 records in 0.094507122 seconds. Throughput is 1354.3953 records/second. Loss is 2.1751595. Sequentiale465b572's hyper parameters: Current learning rate is 3.1575623618566466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37504/60000][Iteration 2169][Wall Clock 237.040972248s] Trained 128 records in 0.091798484 seconds. Throughput is 1394.3585 records/second. Loss is 2.1292582. Sequentiale465b572's hyper parameters: Current learning rate is 3.1565656565656563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 2170][Wall Clock 237.133970656s] Trained 128 records in 0.092998408 seconds. Throughput is 1376.3677 records/second. Loss is 2.1375885. Sequentiale465b572's hyper parameters: Current learning rate is 3.155569580309246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37760/60000][Iteration 2171][Wall Clock 237.224897623s] Trained 128 records in 0.090926967 seconds. Throughput is 1407.7231 records/second. Loss is 2.138154. Sequentiale465b572's hyper parameters: Current learning rate is 3.154574132492114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 2172][Wall Clock 237.322293256s] Trained 128 records in 0.097395633 seconds. Throughput is 1314.2273 records/second. Loss is 2.1271083. Sequentiale465b572's hyper parameters: Current learning rate is 3.15357931251971E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 38016/60000][Iteration 2173][Wall Clock 237.419741522s] Trained 128 records in 0.097448266 seconds. Throughput is 1313.5175 records/second. Loss is 2.1251483. Sequentiale465b572's hyper parameters: Current learning rate is 3.1525851197982345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 2174][Wall Clock 237.513030279s] Trained 128 records in 0.093288757 seconds. Throughput is 1372.0839 records/second. Loss is 2.1233616. Sequentiale465b572's hyper parameters: Current learning rate is 3.151591553734636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 38272/60000][Iteration 2175][Wall Clock 237.606011253s] Trained 128 records in 0.092980974 seconds. Throughput is 1376.6257 records/second. Loss is 2.1161523. Sequentiale465b572's hyper parameters: Current learning rate is 3.15059861373661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:40 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 2176][Wall Clock 237.697560591s] Trained 128 records in 0.091549338 seconds. Throughput is 1398.1532 records/second. Loss is 2.1214237. Sequentiale465b572's hyper parameters: Current learning rate is 3.1496062992125983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 38528/60000][Iteration 2177][Wall Clock 237.798773546s] Trained 128 records in 0.101212955 seconds. Throughput is 1264.6603 records/second. Loss is 2.1367016. Sequentiale465b572's hyper parameters: Current learning rate is 3.1486146095717883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 2178][Wall Clock 237.896756592s] Trained 128 records in 0.097983046 seconds. Throughput is 1306.3484 records/second. Loss is 2.1384828. Sequentiale465b572's hyper parameters: Current learning rate is 3.147623544224111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 38784/60000][Iteration 2179][Wall Clock 237.995161101s] Trained 128 records in 0.098404509 seconds. Throughput is 1300.7534 records/second. Loss is 2.131484. Sequentiale465b572's hyper parameters: Current learning rate is 3.1466331025802394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 2180][Wall Clock 238.083582821s] Trained 128 records in 0.08842172 seconds. Throughput is 1447.6082 records/second. Loss is 2.1538131. Sequentiale465b572's hyper parameters: Current learning rate is 3.145643284051589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 39040/60000][Iteration 2181][Wall Clock 238.175061334s] Trained 128 records in 0.091478513 seconds. Throughput is 1399.2357 records/second. Loss is 2.1180816. Sequentiale465b572's hyper parameters: Current learning rate is 3.1446540880503143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 2182][Wall Clock 238.265814237s] Trained 128 records in 0.090752903 seconds. Throughput is 1410.4232 records/second. Loss is 2.1207511. Sequentiale465b572's hyper parameters: Current learning rate is 3.1436655139893113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 39296/60000][Iteration 2183][Wall Clock 238.356209955s] Trained 128 records in 0.090395718 seconds. Throughput is 1415.9962 records/second. Loss is 2.1528711. Sequentiale465b572's hyper parameters: Current learning rate is 3.1426775612822125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 2184][Wall Clock 238.447491339s] Trained 128 records in 0.091281384 seconds. Throughput is 1402.2574 records/second. Loss is 2.1288264. Sequentiale465b572's hyper parameters: Current learning rate is 3.141690229343387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 39552/60000][Iteration 2185][Wall Clock 238.539038282s] Trained 128 records in 0.091546943 seconds. Throughput is 1398.1897 records/second. Loss is 2.1397238. Sequentiale465b572's hyper parameters: Current learning rate is 3.14070351758794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:41 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 2186][Wall Clock 238.633806435s] Trained 128 records in 0.094768153 seconds. Throughput is 1350.6647 records/second. Loss is 2.1407204. Sequentiale465b572's hyper parameters: Current learning rate is 3.139717425431711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 39808/60000][Iteration 2187][Wall Clock 238.725402152s] Trained 128 records in 0.091595717 seconds. Throughput is 1397.4453 records/second. Loss is 2.1392. Sequentiale465b572's hyper parameters: Current learning rate is 3.1387319522912746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 2188][Wall Clock 238.819699523s] Trained 128 records in 0.094297371 seconds. Throughput is 1357.408 records/second. Loss is 2.130642. Sequentiale465b572's hyper parameters: Current learning rate is 3.137747097583935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40064/60000][Iteration 2189][Wall Clock 238.928829714s] Trained 128 records in 0.109130191 seconds. Throughput is 1172.911 records/second. Loss is 2.1478846. Sequentiale465b572's hyper parameters: Current learning rate is 3.136762860727729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 2190][Wall Clock 239.028699158s] Trained 128 records in 0.099869444 seconds. Throughput is 1281.6733 records/second. Loss is 2.1171682. Sequentiale465b572's hyper parameters: Current learning rate is 3.1357792411414236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40320/60000][Iteration 2191][Wall Clock 239.128665308s] Trained 128 records in 0.09996615 seconds. Throughput is 1280.4333 records/second. Loss is 2.1205237. Sequentiale465b572's hyper parameters: Current learning rate is 3.1347962382445143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 2192][Wall Clock 239.224326759s] Trained 128 records in 0.095661451 seconds. Throughput is 1338.052 records/second. Loss is 2.1548939. Sequentiale465b572's hyper parameters: Current learning rate is 3.133813851457224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40576/60000][Iteration 2193][Wall Clock 239.313247784s] Trained 128 records in 0.088921025 seconds. Throughput is 1439.4796 records/second. Loss is 2.1516712. Sequentiale465b572's hyper parameters: Current learning rate is 3.132832080200501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 2194][Wall Clock 239.407728045s] Trained 128 records in 0.094480261 seconds. Throughput is 1354.7804 records/second. Loss is 2.1316118. Sequentiale465b572's hyper parameters: Current learning rate is 3.1318509238960227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40832/60000][Iteration 2195][Wall Clock 239.502103671s] Trained 128 records in 0.094375626 seconds. Throughput is 1356.2823 records/second. Loss is 2.1322656. Sequentiale465b572's hyper parameters: Current learning rate is 3.1308703819661864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 2196][Wall Clock 239.599185036s] Trained 128 records in 0.097081365 seconds. Throughput is 1318.4817 records/second. Loss is 2.1379383. Sequentiale465b572's hyper parameters: Current learning rate is 3.129890453834116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:42 INFO  DistriOptimizer$:408 - [Epoch 5 41088/60000][Iteration 2197][Wall Clock 239.704536839s] Trained 128 records in 0.105351803 seconds. Throughput is 1214.9768 records/second. Loss is 2.1478906. Sequentiale465b572's hyper parameters: Current learning rate is 3.1289111389236547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 2198][Wall Clock 239.800956334s] Trained 128 records in 0.096419495 seconds. Throughput is 1327.5323 records/second. Loss is 2.1207006. Sequentiale465b572's hyper parameters: Current learning rate is 3.1279324366593683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41344/60000][Iteration 2199][Wall Clock 239.90031203s] Trained 128 records in 0.099355696 seconds. Throughput is 1288.3005 records/second. Loss is 2.151847. Sequentiale465b572's hyper parameters: Current learning rate is 3.1269543464665416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 2200][Wall Clock 239.996325978s] Trained 128 records in 0.096013948 seconds. Throughput is 1333.1396 records/second. Loss is 2.1472335. Sequentiale465b572's hyper parameters: Current learning rate is 3.125976867771179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41600/60000][Iteration 2201][Wall Clock 240.097544018s] Trained 128 records in 0.10121804 seconds. Throughput is 1264.5967 records/second. Loss is 2.150892. Sequentiale465b572's hyper parameters: Current learning rate is 3.125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 2202][Wall Clock 240.197486751s] Trained 128 records in 0.099942733 seconds. Throughput is 1280.7334 records/second. Loss is 2.135285. Sequentiale465b572's hyper parameters: Current learning rate is 3.1240237425804435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41856/60000][Iteration 2203][Wall Clock 240.289155707s] Trained 128 records in 0.091668956 seconds. Throughput is 1396.3287 records/second. Loss is 2.1266477. Sequentiale465b572's hyper parameters: Current learning rate is 3.1230480949406624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 2204][Wall Clock 240.383118592s] Trained 128 records in 0.093962885 seconds. Throughput is 1362.24 records/second. Loss is 2.1278784. Sequentiale465b572's hyper parameters: Current learning rate is 3.1220730565095225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 42112/60000][Iteration 2205][Wall Clock 240.48018763s] Trained 128 records in 0.097069038 seconds. Throughput is 1318.649 records/second. Loss is 2.1352384. Sequentiale465b572's hyper parameters: Current learning rate is 3.1210986267166043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 2206][Wall Clock 240.57399011s] Trained 128 records in 0.09380248 seconds. Throughput is 1364.5695 records/second. Loss is 2.1377568. Sequentiale465b572's hyper parameters: Current learning rate is 3.1201248049921997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:43 INFO  DistriOptimizer$:408 - [Epoch 5 42368/60000][Iteration 2207][Wall Clock 240.669737291s] Trained 128 records in 0.095747181 seconds. Throughput is 1336.854 records/second. Loss is 2.12933. Sequentiale465b572's hyper parameters: Current learning rate is 3.1191515907673113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 2208][Wall Clock 240.765181961s] Trained 128 records in 0.09544467 seconds. Throughput is 1341.0911 records/second. Loss is 2.146146. Sequentiale465b572's hyper parameters: Current learning rate is 3.118178983473652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 42624/60000][Iteration 2209][Wall Clock 240.861470061s] Trained 128 records in 0.0962881 seconds. Throughput is 1329.3439 records/second. Loss is 2.1242595. Sequentiale465b572's hyper parameters: Current learning rate is 3.117206982543641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 2210][Wall Clock 240.964215637s] Trained 128 records in 0.102745576 seconds. Throughput is 1245.7957 records/second. Loss is 2.1028206. Sequentiale465b572's hyper parameters: Current learning rate is 3.116235587410408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 42880/60000][Iteration 2211][Wall Clock 241.063629327s] Trained 128 records in 0.09941369 seconds. Throughput is 1287.549 records/second. Loss is 2.1210852. Sequentiale465b572's hyper parameters: Current learning rate is 3.1152647975077883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 2212][Wall Clock 241.15890869s] Trained 128 records in 0.095279363 seconds. Throughput is 1343.4178 records/second. Loss is 2.1335478. Sequentiale465b572's hyper parameters: Current learning rate is 3.114294612270321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 43136/60000][Iteration 2213][Wall Clock 241.256713487s] Trained 128 records in 0.097804797 seconds. Throughput is 1308.7292 records/second. Loss is 2.1317852. Sequentiale465b572's hyper parameters: Current learning rate is 3.1133250311332503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 2214][Wall Clock 241.353272834s] Trained 128 records in 0.096559347 seconds. Throughput is 1325.6096 records/second. Loss is 2.1283023. Sequentiale465b572's hyper parameters: Current learning rate is 3.112356053532524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 43392/60000][Iteration 2215][Wall Clock 241.464532113s] Trained 128 records in 0.111259279 seconds. Throughput is 1150.4658 records/second. Loss is 2.1331985. Sequentiale465b572's hyper parameters: Current learning rate is 3.1113876789047915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 2216][Wall Clock 241.564327349s] Trained 128 records in 0.099795236 seconds. Throughput is 1282.6263 records/second. Loss is 2.157417. Sequentiale465b572's hyper parameters: Current learning rate is 3.110419906687403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:44 INFO  DistriOptimizer$:408 - [Epoch 5 43648/60000][Iteration 2217][Wall Clock 241.667222803s] Trained 128 records in 0.102895454 seconds. Throughput is 1243.9811 records/second. Loss is 2.151962. Sequentiale465b572's hyper parameters: Current learning rate is 3.109452736318408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 2218][Wall Clock 241.77054583s] Trained 128 records in 0.103323027 seconds. Throughput is 1238.8333 records/second. Loss is 2.1486506. Sequentiale465b572's hyper parameters: Current learning rate is 3.1084861672365556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 43904/60000][Iteration 2219][Wall Clock 241.866816979s] Trained 128 records in 0.096271149 seconds. Throughput is 1329.578 records/second. Loss is 2.1556103. Sequentiale465b572's hyper parameters: Current learning rate is 3.107520198881293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 2220][Wall Clock 241.960636972s] Trained 128 records in 0.093819993 seconds. Throughput is 1364.3148 records/second. Loss is 2.1283045. Sequentiale465b572's hyper parameters: Current learning rate is 3.106554830692762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44160/60000][Iteration 2221][Wall Clock 242.052700211s] Trained 128 records in 0.092063239 seconds. Throughput is 1390.3486 records/second. Loss is 2.1726353. Sequentiale465b572's hyper parameters: Current learning rate is 3.1055900621118014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 2222][Wall Clock 242.147370131s] Trained 128 records in 0.09466992 seconds. Throughput is 1352.0662 records/second. Loss is 2.124109. Sequentiale465b572's hyper parameters: Current learning rate is 3.104625892579944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44416/60000][Iteration 2223][Wall Clock 242.250548593s] Trained 128 records in 0.103178462 seconds. Throughput is 1240.569 records/second. Loss is 2.1188014. Sequentiale465b572's hyper parameters: Current learning rate is 3.1036623215394165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 2224][Wall Clock 242.344901253s] Trained 128 records in 0.09435266 seconds. Throughput is 1356.6124 records/second. Loss is 2.1195245. Sequentiale465b572's hyper parameters: Current learning rate is 3.102699348433137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44672/60000][Iteration 2225][Wall Clock 242.443462271s] Trained 128 records in 0.098561018 seconds. Throughput is 1298.6879 records/second. Loss is 2.1212919. Sequentiale465b572's hyper parameters: Current learning rate is 3.1017369727047146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 2226][Wall Clock 242.549781275s] Trained 128 records in 0.106319004 seconds. Throughput is 1203.924 records/second. Loss is 2.1159344. Sequentiale465b572's hyper parameters: Current learning rate is 3.10077519379845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:45 INFO  DistriOptimizer$:408 - [Epoch 5 44928/60000][Iteration 2227][Wall Clock 242.644869974s] Trained 128 records in 0.095088699 seconds. Throughput is 1346.1116 records/second. Loss is 2.1265311. Sequentiale465b572's hyper parameters: Current learning rate is 3.0998140111593303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 2228][Wall Clock 242.744992857s] Trained 128 records in 0.100122883 seconds. Throughput is 1278.4291 records/second. Loss is 2.1527886. Sequentiale465b572's hyper parameters: Current learning rate is 3.098853424233034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45184/60000][Iteration 2229][Wall Clock 242.840658553s] Trained 128 records in 0.095665696 seconds. Throughput is 1337.9927 records/second. Loss is 2.143425. Sequentiale465b572's hyper parameters: Current learning rate is 3.097893432465923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 2230][Wall Clock 242.937817056s] Trained 128 records in 0.097158503 seconds. Throughput is 1317.4348 records/second. Loss is 2.1271389. Sequentiale465b572's hyper parameters: Current learning rate is 3.096934035305048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45440/60000][Iteration 2231][Wall Clock 243.038186857s] Trained 128 records in 0.100369801 seconds. Throughput is 1275.2839 records/second. Loss is 2.1434767. Sequentiale465b572's hyper parameters: Current learning rate is 3.0959752321981426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 2232][Wall Clock 243.13849323s] Trained 128 records in 0.100306373 seconds. Throughput is 1276.0905 records/second. Loss is 2.139355. Sequentiale465b572's hyper parameters: Current learning rate is 3.0950170225936243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45696/60000][Iteration 2233][Wall Clock 243.238702982s] Trained 128 records in 0.100209752 seconds. Throughput is 1277.3208 records/second. Loss is 2.1186793. Sequentiale465b572's hyper parameters: Current learning rate is 3.094059405940594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 2234][Wall Clock 243.336865721s] Trained 128 records in 0.098162739 seconds. Throughput is 1303.957 records/second. Loss is 2.1341558. Sequentiale465b572's hyper parameters: Current learning rate is 3.093102381688834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 45952/60000][Iteration 2235][Wall Clock 243.434906625s] Trained 128 records in 0.098040904 seconds. Throughput is 1305.5775 records/second. Loss is 2.1303897. Sequentiale465b572's hyper parameters: Current learning rate is 3.0921459492888067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 2236][Wall Clock 243.533705898s] Trained 128 records in 0.098799273 seconds. Throughput is 1295.556 records/second. Loss is 2.1101437. Sequentiale465b572's hyper parameters: Current learning rate is 3.091190108191654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:46 INFO  DistriOptimizer$:408 - [Epoch 5 46208/60000][Iteration 2237][Wall Clock 243.631446252s] Trained 128 records in 0.097740354 seconds. Throughput is 1309.5922 records/second. Loss is 2.1175675. Sequentiale465b572's hyper parameters: Current learning rate is 3.0902348578491963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 2238][Wall Clock 243.725923274s] Trained 128 records in 0.094477022 seconds. Throughput is 1354.8268 records/second. Loss is 2.1397955. Sequentiale465b572's hyper parameters: Current learning rate is 3.0892801977139327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 46464/60000][Iteration 2239][Wall Clock 243.820369852s] Trained 128 records in 0.094446578 seconds. Throughput is 1355.2635 records/second. Loss is 2.14536. Sequentiale465b572's hyper parameters: Current learning rate is 3.0883261272390367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 2240][Wall Clock 243.950186233s] Trained 128 records in 0.129816381 seconds. Throughput is 986.00806 records/second. Loss is 2.1330004. Sequentiale465b572's hyper parameters: Current learning rate is 3.0873726458783575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 46720/60000][Iteration 2241][Wall Clock 244.044952924s] Trained 128 records in 0.094766691 seconds. Throughput is 1350.6855 records/second. Loss is 2.1468797. Sequentiale465b572's hyper parameters: Current learning rate is 3.0864197530864197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 2242][Wall Clock 244.146054042s] Trained 128 records in 0.101101118 seconds. Throughput is 1266.0592 records/second. Loss is 2.1382208. Sequentiale465b572's hyper parameters: Current learning rate is 3.08546744831842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 46976/60000][Iteration 2243][Wall Clock 244.249456879s] Trained 128 records in 0.103402837 seconds. Throughput is 1237.8771 records/second. Loss is 2.1309614. Sequentiale465b572's hyper parameters: Current learning rate is 3.0845157310302283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 2244][Wall Clock 244.344349084s] Trained 128 records in 0.094892205 seconds. Throughput is 1348.899 records/second. Loss is 2.1445913. Sequentiale465b572's hyper parameters: Current learning rate is 3.0835646006783845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 47232/60000][Iteration 2245][Wall Clock 244.441392475s] Trained 128 records in 0.097043391 seconds. Throughput is 1318.9977 records/second. Loss is 2.1270034. Sequentiale465b572's hyper parameters: Current learning rate is 3.0826140567200987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 2246][Wall Clock 244.53952367s] Trained 128 records in 0.098131195 seconds. Throughput is 1304.3762 records/second. Loss is 2.1367025. Sequentiale465b572's hyper parameters: Current learning rate is 3.081664098613251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:47 INFO  DistriOptimizer$:408 - [Epoch 5 47488/60000][Iteration 2247][Wall Clock 244.633807384s] Trained 128 records in 0.094283714 seconds. Throughput is 1357.6045 records/second. Loss is 2.1071532. Sequentiale465b572's hyper parameters: Current learning rate is 3.0807147258163895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 2248][Wall Clock 244.738860708s] Trained 128 records in 0.105053324 seconds. Throughput is 1218.4288 records/second. Loss is 2.1244886. Sequentiale465b572's hyper parameters: Current learning rate is 3.079765937788728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 47744/60000][Iteration 2249][Wall Clock 244.848528915s] Trained 128 records in 0.109668207 seconds. Throughput is 1167.1569 records/second. Loss is 2.1582494. Sequentiale465b572's hyper parameters: Current learning rate is 3.078817733990148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 2250][Wall Clock 244.949030569s] Trained 128 records in 0.100501654 seconds. Throughput is 1273.6108 records/second. Loss is 2.133252. Sequentiale465b572's hyper parameters: Current learning rate is 3.077870113881194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48000/60000][Iteration 2251][Wall Clock 245.043643993s] Trained 128 records in 0.094613424 seconds. Throughput is 1352.8735 records/second. Loss is 2.135106. Sequentiale465b572's hyper parameters: Current learning rate is 3.076923076923077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 2252][Wall Clock 245.138781179s] Trained 128 records in 0.095137186 seconds. Throughput is 1345.4255 records/second. Loss is 2.1367736. Sequentiale465b572's hyper parameters: Current learning rate is 3.0759766225776686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48256/60000][Iteration 2253][Wall Clock 245.230543995s] Trained 128 records in 0.091762816 seconds. Throughput is 1394.9005 records/second. Loss is 2.1207988. Sequentiale465b572's hyper parameters: Current learning rate is 3.075030750307503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 2254][Wall Clock 245.327128253s] Trained 128 records in 0.096584258 seconds. Throughput is 1325.2677 records/second. Loss is 2.1376057. Sequentiale465b572's hyper parameters: Current learning rate is 3.074085459575776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48512/60000][Iteration 2255][Wall Clock 245.418888949s] Trained 128 records in 0.091760696 seconds. Throughput is 1394.9327 records/second. Loss is 2.147038. Sequentiale465b572's hyper parameters: Current learning rate is 3.073140749846343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 2256][Wall Clock 245.512528749s] Trained 128 records in 0.0936398 seconds. Throughput is 1366.9402 records/second. Loss is 2.1332822. Sequentiale465b572's hyper parameters: Current learning rate is 3.0721966205837174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:48 INFO  DistriOptimizer$:408 - [Epoch 5 48768/60000][Iteration 2257][Wall Clock 245.604883213s] Trained 128 records in 0.092354464 seconds. Throughput is 1385.9645 records/second. Loss is 2.150451. Sequentiale465b572's hyper parameters: Current learning rate is 3.071253071253071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 2258][Wall Clock 245.699296543s] Trained 128 records in 0.09441333 seconds. Throughput is 1355.7407 records/second. Loss is 2.1170554. Sequentiale465b572's hyper parameters: Current learning rate is 3.0703101013202335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49024/60000][Iteration 2259][Wall Clock 245.795534455s] Trained 128 records in 0.096237912 seconds. Throughput is 1330.0371 records/second. Loss is 2.1317458. Sequentiale465b572's hyper parameters: Current learning rate is 3.0693677102516884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 2260][Wall Clock 245.896651033s] Trained 128 records in 0.101116578 seconds. Throughput is 1265.8656 records/second. Loss is 2.1389053. Sequentiale465b572's hyper parameters: Current learning rate is 3.068425897514575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49280/60000][Iteration 2261][Wall Clock 245.994848438s] Trained 128 records in 0.098197405 seconds. Throughput is 1303.4967 records/second. Loss is 2.1428268. Sequentiale465b572's hyper parameters: Current learning rate is 3.067484662576687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 2262][Wall Clock 246.092123842s] Trained 128 records in 0.097275404 seconds. Throughput is 1315.8516 records/second. Loss is 2.1285157. Sequentiale465b572's hyper parameters: Current learning rate is 3.0665440049064706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49536/60000][Iteration 2263][Wall Clock 246.187059609s] Trained 128 records in 0.094935767 seconds. Throughput is 1348.28 records/second. Loss is 2.124585. Sequentiale465b572's hyper parameters: Current learning rate is 3.0656039239730225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 2264][Wall Clock 246.2860138s] Trained 128 records in 0.098954191 seconds. Throughput is 1293.5278 records/second. Loss is 2.132237. Sequentiale465b572's hyper parameters: Current learning rate is 3.064664419246093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49792/60000][Iteration 2265][Wall Clock 246.384134972s] Trained 128 records in 0.098121172 seconds. Throughput is 1304.5095 records/second. Loss is 2.1280255. Sequentiale465b572's hyper parameters: Current learning rate is 3.0637254901960784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 2266][Wall Clock 246.490599381s] Trained 128 records in 0.106464409 seconds. Throughput is 1202.2798 records/second. Loss is 2.1307905. Sequentiale465b572's hyper parameters: Current learning rate is 3.0627871362940275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:49 INFO  DistriOptimizer$:408 - [Epoch 5 50048/60000][Iteration 2267][Wall Clock 246.592973005s] Trained 128 records in 0.102373624 seconds. Throughput is 1250.322 records/second. Loss is 2.1417997. Sequentiale465b572's hyper parameters: Current learning rate is 3.061849357011635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 2268][Wall Clock 246.685378411s] Trained 128 records in 0.092405406 seconds. Throughput is 1385.2003 records/second. Loss is 2.1443186. Sequentiale465b572's hyper parameters: Current learning rate is 3.0609121518212427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50304/60000][Iteration 2269][Wall Clock 246.782439597s] Trained 128 records in 0.097061186 seconds. Throughput is 1318.7557 records/second. Loss is 2.122357. Sequentiale465b572's hyper parameters: Current learning rate is 3.059975520195838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 2270][Wall Clock 246.87561318s] Trained 128 records in 0.093173583 seconds. Throughput is 1373.7799 records/second. Loss is 2.1160588. Sequentiale465b572's hyper parameters: Current learning rate is 3.059039461609055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50560/60000][Iteration 2271][Wall Clock 246.968024454s] Trained 128 records in 0.092411274 seconds. Throughput is 1385.1124 records/second. Loss is 2.1291716. Sequentiale465b572's hyper parameters: Current learning rate is 3.058103975535168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 2272][Wall Clock 247.061559183s] Trained 128 records in 0.093534729 seconds. Throughput is 1368.4756 records/second. Loss is 2.1250165. Sequentiale465b572's hyper parameters: Current learning rate is 3.0571690614490985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50816/60000][Iteration 2273][Wall Clock 247.16390897s] Trained 128 records in 0.102349787 seconds. Throughput is 1250.6133 records/second. Loss is 2.1457827. Sequentiale465b572's hyper parameters: Current learning rate is 3.056234718826406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 2274][Wall Clock 247.287550974s] Trained 128 records in 0.123642004 seconds. Throughput is 1035.2468 records/second. Loss is 2.1302805. Sequentiale465b572's hyper parameters: Current learning rate is 3.0553009471432935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 51072/60000][Iteration 2275][Wall Clock 247.382640852s] Trained 128 records in 0.095089878 seconds. Throughput is 1346.095 records/second. Loss is 2.1202714. Sequentiale465b572's hyper parameters: Current learning rate is 3.0543677458766036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 2276][Wall Clock 247.474743581s] Trained 128 records in 0.092102729 seconds. Throughput is 1389.7526 records/second. Loss is 2.1483924. Sequentiale465b572's hyper parameters: Current learning rate is 3.053435114503817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 51328/60000][Iteration 2277][Wall Clock 247.565285612s] Trained 128 records in 0.090542031 seconds. Throughput is 1413.708 records/second. Loss is 2.132764. Sequentiale465b572's hyper parameters: Current learning rate is 3.0525030525030525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:50 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 2278][Wall Clock 247.6553319s] Trained 128 records in 0.090046288 seconds. Throughput is 1421.4912 records/second. Loss is 2.1189003. Sequentiale465b572's hyper parameters: Current learning rate is 3.051571559353067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 51584/60000][Iteration 2279][Wall Clock 247.744704179s] Trained 128 records in 0.089372279 seconds. Throughput is 1432.2114 records/second. Loss is 2.1318452. Sequentiale465b572's hyper parameters: Current learning rate is 3.050640634533252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 2280][Wall Clock 247.836794556s] Trained 128 records in 0.092090377 seconds. Throughput is 1389.939 records/second. Loss is 2.1249049. Sequentiale465b572's hyper parameters: Current learning rate is 3.049710277523635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 51840/60000][Iteration 2281][Wall Clock 247.930320963s] Trained 128 records in 0.093526407 seconds. Throughput is 1368.5974 records/second. Loss is 2.1250396. Sequentiale465b572's hyper parameters: Current learning rate is 3.048780487804878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 2282][Wall Clock 248.026961723s] Trained 128 records in 0.09664076 seconds. Throughput is 1324.4929 records/second. Loss is 2.1220703. Sequentiale465b572's hyper parameters: Current learning rate is 3.0478512648582747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 52096/60000][Iteration 2283][Wall Clock 248.118953937s] Trained 128 records in 0.091992214 seconds. Throughput is 1391.4221 records/second. Loss is 2.1230989. Sequentiale465b572's hyper parameters: Current learning rate is 3.046922608165753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 2284][Wall Clock 248.20829721s] Trained 128 records in 0.089343273 seconds. Throughput is 1432.6764 records/second. Loss is 2.1316307. Sequentiale465b572's hyper parameters: Current learning rate is 3.045994517209869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 52352/60000][Iteration 2285][Wall Clock 248.303289768s] Trained 128 records in 0.094992558 seconds. Throughput is 1347.474 records/second. Loss is 2.1281922. Sequentiale465b572's hyper parameters: Current learning rate is 3.045066991473812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 2286][Wall Clock 248.411716739s] Trained 128 records in 0.108426971 seconds. Throughput is 1180.5181 records/second. Loss is 2.1249044. Sequentiale465b572's hyper parameters: Current learning rate is 3.0441400304414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 52608/60000][Iteration 2287][Wall Clock 248.504322589s] Trained 128 records in 0.09260585 seconds. Throughput is 1382.202 records/second. Loss is 2.12504. Sequentiale465b572's hyper parameters: Current learning rate is 3.0432136335970786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:51 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 2288][Wall Clock 248.59813899s] Trained 128 records in 0.093816401 seconds. Throughput is 1364.367 records/second. Loss is 2.1193633. Sequentiale465b572's hyper parameters: Current learning rate is 3.04228780042592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 52864/60000][Iteration 2289][Wall Clock 248.69579251s] Trained 128 records in 0.09765352 seconds. Throughput is 1310.7566 records/second. Loss is 2.147333. Sequentiale465b572's hyper parameters: Current learning rate is 3.0413625304136254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 2290][Wall Clock 248.788225538s] Trained 128 records in 0.092433028 seconds. Throughput is 1384.7864 records/second. Loss is 2.1328208. Sequentiale465b572's hyper parameters: Current learning rate is 3.040437823046519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53120/60000][Iteration 2291][Wall Clock 248.893080253s] Trained 128 records in 0.104854715 seconds. Throughput is 1220.7367 records/second. Loss is 2.1077573. Sequentiale465b572's hyper parameters: Current learning rate is 3.0395136778115504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 2292][Wall Clock 248.984524513s] Trained 128 records in 0.09144426 seconds. Throughput is 1399.7598 records/second. Loss is 2.1136959. Sequentiale465b572's hyper parameters: Current learning rate is 3.038590094196293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53376/60000][Iteration 2293][Wall Clock 249.081222827s] Trained 128 records in 0.096698314 seconds. Throughput is 1323.7046 records/second. Loss is 2.1198635. Sequentiale465b572's hyper parameters: Current learning rate is 3.0376670716889426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 2294][Wall Clock 249.171464161s] Trained 128 records in 0.090241334 seconds. Throughput is 1418.4187 records/second. Loss is 2.1304665. Sequentiale465b572's hyper parameters: Current learning rate is 3.0367446097783173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53632/60000][Iteration 2295][Wall Clock 249.263182483s] Trained 128 records in 0.091718322 seconds. Throughput is 1395.5771 records/second. Loss is 2.105722. Sequentiale465b572's hyper parameters: Current learning rate is 3.0358227079538557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 2296][Wall Clock 249.354059538s] Trained 128 records in 0.090877055 seconds. Throughput is 1408.4963 records/second. Loss is 2.138258. Sequentiale465b572's hyper parameters: Current learning rate is 3.0349013657056146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 53888/60000][Iteration 2297][Wall Clock 249.451723117s] Trained 128 records in 0.097663579 seconds. Throughput is 1310.6216 records/second. Loss is 2.119288. Sequentiale465b572's hyper parameters: Current learning rate is 3.0339805825242716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:52 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 2298][Wall Clock 249.552130804s] Trained 128 records in 0.100407687 seconds. Throughput is 1274.8027 records/second. Loss is 2.124107. Sequentiale465b572's hyper parameters: Current learning rate is 3.0330603579011223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54144/60000][Iteration 2299][Wall Clock 249.66319203s] Trained 128 records in 0.111061226 seconds. Throughput is 1152.5175 records/second. Loss is 2.136718. Sequentiale465b572's hyper parameters: Current learning rate is 3.0321406913280777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 2300][Wall Clock 249.756664376s] Trained 128 records in 0.093472346 seconds. Throughput is 1369.3889 records/second. Loss is 2.1402571. Sequentiale465b572's hyper parameters: Current learning rate is 3.031221582297666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54400/60000][Iteration 2301][Wall Clock 249.850970971s] Trained 128 records in 0.094306595 seconds. Throughput is 1357.2751 records/second. Loss is 2.1295156. Sequentiale465b572's hyper parameters: Current learning rate is 3.0303030303030303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 2302][Wall Clock 249.946923542s] Trained 128 records in 0.095952571 seconds. Throughput is 1333.9924 records/second. Loss is 2.1253173. Sequentiale465b572's hyper parameters: Current learning rate is 3.029385034837928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54656/60000][Iteration 2303][Wall Clock 250.040409488s] Trained 128 records in 0.093485946 seconds. Throughput is 1369.1898 records/second. Loss is 2.1177695. Sequentiale465b572's hyper parameters: Current learning rate is 3.028467595396729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 2304][Wall Clock 250.138343218s] Trained 128 records in 0.09793373 seconds. Throughput is 1307.0062 records/second. Loss is 2.130529. Sequentiale465b572's hyper parameters: Current learning rate is 3.027550711474417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 54912/60000][Iteration 2305][Wall Clock 250.232005791s] Trained 128 records in 0.093662573 seconds. Throughput is 1366.6078 records/second. Loss is 2.1215498. Sequentiale465b572's hyper parameters: Current learning rate is 3.0266343825665856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 2306][Wall Clock 250.325404149s] Trained 128 records in 0.093398358 seconds. Throughput is 1370.4739 records/second. Loss is 2.1307814. Sequentiale465b572's hyper parameters: Current learning rate is 3.02571860816944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 55168/60000][Iteration 2307][Wall Clock 250.419532935s] Trained 128 records in 0.094128786 seconds. Throughput is 1359.839 records/second. Loss is 2.138002. Sequentiale465b572's hyper parameters: Current learning rate is 3.0248033877797946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 2308][Wall Clock 250.511704553s] Trained 128 records in 0.092171618 seconds. Throughput is 1388.7139 records/second. Loss is 2.1139808. Sequentiale465b572's hyper parameters: Current learning rate is 3.023888720895071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:53 INFO  DistriOptimizer$:408 - [Epoch 5 55424/60000][Iteration 2309][Wall Clock 250.606843086s] Trained 128 records in 0.095138533 seconds. Throughput is 1345.4065 records/second. Loss is 2.1208868. Sequentiale465b572's hyper parameters: Current learning rate is 3.0229746070133015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 2310][Wall Clock 250.700240894s] Trained 128 records in 0.093397808 seconds. Throughput is 1370.4818 records/second. Loss is 2.116644. Sequentiale465b572's hyper parameters: Current learning rate is 3.022061045633122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 55680/60000][Iteration 2311][Wall Clock 250.795058613s] Trained 128 records in 0.094817719 seconds. Throughput is 1349.9586 records/second. Loss is 2.1417854. Sequentiale465b572's hyper parameters: Current learning rate is 3.0211480362537764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 2312][Wall Clock 250.887221752s] Trained 128 records in 0.092163139 seconds. Throughput is 1388.8416 records/second. Loss is 2.1198127. Sequentiale465b572's hyper parameters: Current learning rate is 3.020235578375113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 55936/60000][Iteration 2313][Wall Clock 250.984461858s] Trained 128 records in 0.097240106 seconds. Throughput is 1316.3293 records/second. Loss is 2.1172287. Sequentiale465b572's hyper parameters: Current learning rate is 3.019323671497585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 2314][Wall Clock 251.076447195s] Trained 128 records in 0.091985337 seconds. Throughput is 1391.5261 records/second. Loss is 2.146395. Sequentiale465b572's hyper parameters: Current learning rate is 3.0184123151222455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56192/60000][Iteration 2315][Wall Clock 251.170535393s] Trained 128 records in 0.094088198 seconds. Throughput is 1360.4257 records/second. Loss is 2.1467993. Sequentiale465b572's hyper parameters: Current learning rate is 3.0175015087507544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 2316][Wall Clock 251.270386477s] Trained 128 records in 0.099851084 seconds. Throughput is 1281.9089 records/second. Loss is 2.1255314. Sequentiale465b572's hyper parameters: Current learning rate is 3.0165912518853697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56448/60000][Iteration 2317][Wall Clock 251.366304986s] Trained 128 records in 0.095918509 seconds. Throughput is 1334.4662 records/second. Loss is 2.1431677. Sequentiale465b572's hyper parameters: Current learning rate is 3.015681544028951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 2318][Wall Clock 251.456647068s] Trained 128 records in 0.090342082 seconds. Throughput is 1416.8369 records/second. Loss is 2.1378286. Sequentiale465b572's hyper parameters: Current learning rate is 3.0147723846849563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56704/60000][Iteration 2319][Wall Clock 251.552465307s] Trained 128 records in 0.095818239 seconds. Throughput is 1335.8627 records/second. Loss is 2.1205146. Sequentiale465b572's hyper parameters: Current learning rate is 3.013863773357444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:54 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 2320][Wall Clock 251.640425775s] Trained 128 records in 0.087960468 seconds. Throughput is 1455.1992 records/second. Loss is 2.13058. Sequentiale465b572's hyper parameters: Current learning rate is 3.0129557095510696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 56960/60000][Iteration 2321][Wall Clock 251.727703116s] Trained 128 records in 0.087277341 seconds. Throughput is 1466.5892 records/second. Loss is 2.1107323. Sequentiale465b572's hyper parameters: Current learning rate is 3.0120481927710846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 2322][Wall Clock 251.820628234s] Trained 128 records in 0.092925118 seconds. Throughput is 1377.4532 records/second. Loss is 2.1156662. Sequentiale465b572's hyper parameters: Current learning rate is 3.0111412225233364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57216/60000][Iteration 2323][Wall Clock 251.91713824s] Trained 128 records in 0.096510006 seconds. Throughput is 1326.2874 records/second. Loss is 2.1296387. Sequentiale465b572's hyper parameters: Current learning rate is 3.0102347983142685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 2324][Wall Clock 252.01308172s] Trained 128 records in 0.09594348 seconds. Throughput is 1334.1188 records/second. Loss is 2.129036. Sequentiale465b572's hyper parameters: Current learning rate is 3.009328919650918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57472/60000][Iteration 2325][Wall Clock 252.109928671s] Trained 128 records in 0.096846951 seconds. Throughput is 1321.673 records/second. Loss is 2.1419866. Sequentiale465b572's hyper parameters: Current learning rate is 3.0084235860409147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 2326][Wall Clock 252.20141451s] Trained 128 records in 0.091485839 seconds. Throughput is 1399.1237 records/second. Loss is 2.1233995. Sequentiale465b572's hyper parameters: Current learning rate is 3.007518796992481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57728/60000][Iteration 2327][Wall Clock 252.299471844s] Trained 128 records in 0.098057334 seconds. Throughput is 1305.3588 records/second. Loss is 2.1348355. Sequentiale465b572's hyper parameters: Current learning rate is 3.006614552014432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 2328][Wall Clock 252.391890087s] Trained 128 records in 0.092418243 seconds. Throughput is 1385.0079 records/second. Loss is 2.1377957. Sequentiale465b572's hyper parameters: Current learning rate is 3.0057108506161706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 57984/60000][Iteration 2329][Wall Clock 252.489075678s] Trained 128 records in 0.097185591 seconds. Throughput is 1317.0677 records/second. Loss is 2.123629. Sequentiale465b572's hyper parameters: Current learning rate is 3.0048076923076925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:55 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 2330][Wall Clock 252.586187442s] Trained 128 records in 0.097111764 seconds. Throughput is 1318.069 records/second. Loss is 2.1224363. Sequentiale465b572's hyper parameters: Current learning rate is 3.0039050765995795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 58240/60000][Iteration 2331][Wall Clock 252.679901221s] Trained 128 records in 0.093713779 seconds. Throughput is 1365.8611 records/second. Loss is 2.1271992. Sequentiale465b572's hyper parameters: Current learning rate is 3.003003003003003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 2332][Wall Clock 252.776317512s] Trained 128 records in 0.096416291 seconds. Throughput is 1327.5764 records/second. Loss is 2.1572955. Sequentiale465b572's hyper parameters: Current learning rate is 3.002101471029721E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 58496/60000][Iteration 2333][Wall Clock 252.873657066s] Trained 128 records in 0.097339554 seconds. Throughput is 1314.9844 records/second. Loss is 2.1146512. Sequentiale465b572's hyper parameters: Current learning rate is 3.001200480192077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 2334][Wall Clock 252.969285146s] Trained 128 records in 0.09562808 seconds. Throughput is 1338.5189 records/second. Loss is 2.1423154. Sequentiale465b572's hyper parameters: Current learning rate is 3.000300030003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 58752/60000][Iteration 2335][Wall Clock 253.065859056s] Trained 128 records in 0.09657391 seconds. Throughput is 1325.4097 records/second. Loss is 2.1150372. Sequentiale465b572's hyper parameters: Current learning rate is 2.9994001199760045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 2336][Wall Clock 253.158628604s] Trained 128 records in 0.092769548 seconds. Throughput is 1379.7631 records/second. Loss is 2.1188765. Sequentiale465b572's hyper parameters: Current learning rate is 2.998500749625188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 59008/60000][Iteration 2337][Wall Clock 253.256319878s] Trained 128 records in 0.097691274 seconds. Throughput is 1310.2501 records/second. Loss is 2.129678. Sequentiale465b572's hyper parameters: Current learning rate is 2.997601918465228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 2338][Wall Clock 253.358875463s] Trained 128 records in 0.102555585 seconds. Throughput is 1248.1036 records/second. Loss is 2.123152. Sequentiale465b572's hyper parameters: Current learning rate is 2.996703626011387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 59264/60000][Iteration 2339][Wall Clock 253.45132507s] Trained 128 records in 0.092449607 seconds. Throughput is 1384.5381 records/second. Loss is 2.1248825. Sequentiale465b572's hyper parameters: Current learning rate is 2.995805871779509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:56 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 2340][Wall Clock 253.539966877s] Trained 128 records in 0.088641807 seconds. Throughput is 1444.0139 records/second. Loss is 2.1286736. Sequentiale465b572's hyper parameters: Current learning rate is 2.994908655286014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:57 INFO  DistriOptimizer$:408 - [Epoch 5 59520/60000][Iteration 2341][Wall Clock 253.639098144s] Trained 128 records in 0.099131267 seconds. Throughput is 1291.2173 records/second. Loss is 2.1366572. Sequentiale465b572's hyper parameters: Current learning rate is 2.994011976047904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:57 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 2342][Wall Clock 253.743543673s] Trained 128 records in 0.104445529 seconds. Throughput is 1225.5192 records/second. Loss is 2.153194. Sequentiale465b572's hyper parameters: Current learning rate is 2.9931158335827593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:57 INFO  DistriOptimizer$:408 - [Epoch 5 59776/60000][Iteration 2343][Wall Clock 253.838408175s] Trained 128 records in 0.094864502 seconds. Throughput is 1349.2928 records/second. Loss is 2.1068852. Sequentiale465b572's hyper parameters: Current learning rate is 2.992220227408737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:57 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 2344][Wall Clock 253.931984582s] Trained 128 records in 0.093576407 seconds. Throughput is 1367.8661 records/second. Loss is 2.1479957. Sequentiale465b572's hyper parameters: Current learning rate is 2.991325157044571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:57 INFO  DistriOptimizer$:408 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 254.026171613s] Trained 128 records in 0.094187031 seconds. Throughput is 1358.9982 records/second. Loss is 2.1191216. Sequentiale465b572's hyper parameters: Current learning rate is 2.99043062200957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 20:08:57 INFO  DistriOptimizer$:452 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 254.026171613s] Epoch finished. Wall clock time is 255289.566989 ms
2019-10-15 20:08:57 INFO  DistriOptimizer$:111 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 254.026171613s] Validate model...
2019-10-15 20:08:58 INFO  DistriOptimizer$:178 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 254.026171613s] validate model throughput is 9679.863 records/second
2019-10-15 20:08:58 INFO  DistriOptimizer$:181 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 254.026171613s] Top1Accuracy is Accuracy(correct: 4917, count: 10000, accuracy: 0.4917)
2019-10-15 20:08:58 INFO  DistriOptimizer$:221 - [Wall Clock 255.289566989s] Save model to /tmp/lenet5/20191015_200441
2019-10-15 20:08:58 INFO  DistriOptimizer$:226 - [Wall Clock 255.289566989s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@c83982c to /tmp/lenet5/20191015_200441
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.49200001359, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.931999981403, total_num: 10000, method: Top5Accuracy
Evaluated result: 2.12074637413, total_num: 157, method: Loss
